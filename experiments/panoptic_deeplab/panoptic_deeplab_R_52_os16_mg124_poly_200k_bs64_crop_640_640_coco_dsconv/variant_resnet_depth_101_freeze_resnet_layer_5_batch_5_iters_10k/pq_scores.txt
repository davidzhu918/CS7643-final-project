Command Line Args: Namespace(config_file='./detectron2/projects/Panoptic-DeepLab/configs/COCO-PanopticSegmentation/panoptic_deeplab_R_52_os16_mg124_poly_200k_bs64_crop_640_640_coco_dsconv.yaml', dist_url='tcp://127.0.0.1:49152', eval_only=False, machine_rank=0, num_gpus=1, num_machines=1, opts=['MODEL.RESNETS.NORM', 'BN', 'MODEL.INS_EMBED_HEAD.NORM', 'BN', 'MODEL.SEM_SEG_HEAD.NORM', 'BN', 'SOLVER.MAX_ITER', '10000', 'SOLVER.IMS_PER_BATCH', '5', 'SOLVER.BASE_LR', '0.0025', 'MODEL.BACKBONE.FREEZE_AT', '5', 'MODEL.RESNETS.DEPTH', '101', 'MODEL.WEIGHTS', 'detectron2://DeepLab/R-103.pkl'], resume=False)
Loading config ./detectron2/projects/Panoptic-DeepLab/configs/COCO-PanopticSegmentation/panoptic_deeplab_R_52_os16_mg124_poly_200k_bs64_crop_640_640_coco_dsconv.yaml with yaml.unsafe_load. Your machine may be at risk if the file contains malicious content.
[12/10 22:52:50 detectron2]: Rank of current process: 0. World size: 1
[12/10 22:52:50 detectron2]: Environment info:
----------------------  ----------------------------------------------------------------
sys.platform            linux
Python                  3.7.12 (default, Jan 15 2022, 18:48:18) [GCC 7.5.0]
numpy                   1.21.5
detectron2              0.6 @/content/detectron2/detectron2
Compiler                GCC 7.5
CUDA compiler           CUDA 11.1
detectron2 arch flags   7.0
DETECTRON2_ENV_MODULE   <not set>
PyTorch                 1.10.0+cu111 @/usr/local/lib/python3.7/dist-packages/torch
PyTorch debug build     False
GPU available           Yes
GPU 0                   Tesla V100-SXM2-16GB (arch=7.0)
Driver version          460.32.03
CUDA_HOME               /usr/local/cuda
Pillow                  7.1.2
torchvision             0.11.1+cu111 @/usr/local/lib/python3.7/dist-packages/torchvision
torchvision arch flags  3.5, 5.0, 6.0, 7.0, 7.5, 8.0, 8.6
fvcore                  0.1.5.post20221122
iopath                  0.1.9
cv2                     4.1.2
----------------------  ----------------------------------------------------------------
PyTorch built with:
  - GCC 7.3
  - C++ Version: 201402
  - Intel(R) Math Kernel Library Version 2020.0.0 Product Build 20191122 for Intel(R) 64 architecture applications
  - Intel(R) MKL-DNN v2.2.3 (Git Hash 7336ca9f055cf1bfa13efb658fe15dc9b41f0740)
  - OpenMP 201511 (a.k.a. OpenMP 4.5)
  - LAPACK is enabled (usually provided by MKL)
  - NNPACK is enabled
  - CPU capability usage: AVX512
  - CUDA Runtime 11.1
  - NVCC architecture flags: -gencode;arch=compute_37,code=sm_37;-gencode;arch=compute_50,code=sm_50;-gencode;arch=compute_60,code=sm_60;-gencode;arch=compute_70,code=sm_70;-gencode;arch=compute_75,code=sm_75;-gencode;arch=compute_80,code=sm_80;-gencode;arch=compute_86,code=sm_86
  - CuDNN 8.0.5
  - Magma 2.5.2
  - Build settings: BLAS_INFO=mkl, BUILD_TYPE=Release, CUDA_VERSION=11.1, CUDNN_VERSION=8.0.5, CXX_COMPILER=/opt/rh/devtoolset-7/root/usr/bin/c++, CXX_FLAGS= -Wno-deprecated -fvisibility-inlines-hidden -DUSE_PTHREADPOOL -fopenmp -DNDEBUG -DUSE_KINETO -DUSE_FBGEMM -DUSE_QNNPACK -DUSE_PYTORCH_QNNPACK -DUSE_XNNPACK -DSYMBOLICATE_MOBILE_DEBUG_HANDLE -DEDGE_PROFILER_USE_KINETO -O2 -fPIC -Wno-narrowing -Wall -Wextra -Werror=return-type -Wno-missing-field-initializers -Wno-type-limits -Wno-array-bounds -Wno-unknown-pragmas -Wno-sign-compare -Wno-unused-parameter -Wno-unused-variable -Wno-unused-function -Wno-unused-result -Wno-unused-local-typedefs -Wno-strict-overflow -Wno-strict-aliasing -Wno-error=deprecated-declarations -Wno-stringop-overflow -Wno-psabi -Wno-error=pedantic -Wno-error=redundant-decls -Wno-error=old-style-cast -fdiagnostics-color=always -faligned-new -Wno-unused-but-set-variable -Wno-maybe-uninitialized -fno-math-errno -fno-trapping-math -Werror=format -Wno-stringop-overflow, LAPACK_INFO=mkl, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, TORCH_VERSION=1.10.0, USE_CUDA=ON, USE_CUDNN=ON, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_MKL=ON, USE_MKLDNN=ON, USE_MPI=OFF, USE_NCCL=ON, USE_NNPACK=ON, USE_OPENMP=ON, 

[12/10 22:52:50 detectron2]: Command line arguments: Namespace(config_file='./detectron2/projects/Panoptic-DeepLab/configs/COCO-PanopticSegmentation/panoptic_deeplab_R_52_os16_mg124_poly_200k_bs64_crop_640_640_coco_dsconv.yaml', dist_url='tcp://127.0.0.1:49152', eval_only=False, machine_rank=0, num_gpus=1, num_machines=1, opts=['MODEL.RESNETS.NORM', 'BN', 'MODEL.INS_EMBED_HEAD.NORM', 'BN', 'MODEL.SEM_SEG_HEAD.NORM', 'BN', 'SOLVER.MAX_ITER', '10000', 'SOLVER.IMS_PER_BATCH', '5', 'SOLVER.BASE_LR', '0.0025', 'MODEL.BACKBONE.FREEZE_AT', '5', 'MODEL.RESNETS.DEPTH', '101', 'MODEL.WEIGHTS', 'detectron2://DeepLab/R-103.pkl'], resume=False)
[12/10 22:52:50 detectron2]: Contents of args.config_file=./detectron2/projects/Panoptic-DeepLab/configs/COCO-PanopticSegmentation/panoptic_deeplab_R_52_os16_mg124_poly_200k_bs64_crop_640_640_coco_dsconv.yaml:
_BASE_: ../Cityscapes-PanopticSegmentation/Base-PanopticDeepLab-OS16.yaml
MODEL:
  WEIGHTS: "detectron2://DeepLab/R-52.pkl"
  PIXEL_MEAN: [123.675, 116.280, 103.530]
  PIXEL_STD: [58.395, 57.120, 57.375]
  BACKBONE:
    NAME: "build_resnet_deeplab_backbone"
  RESNETS:
    DEPTH: 50
    NORM: "SyncBN"
    RES5_MULTI_GRID: [1, 2, 4]
    STEM_TYPE: "deeplab"
    STEM_OUT_CHANNELS: 128
    STRIDE_IN_1X1: False
  SEM_SEG_HEAD:
    NUM_CLASSES: 133
    LOSS_TOP_K: 1.0
    USE_DEPTHWISE_SEPARABLE_CONV: True
  PANOPTIC_DEEPLAB:
    STUFF_AREA: 4096
    NMS_KERNEL: 41
    SIZE_DIVISIBILITY: 640
    USE_DEPTHWISE_SEPARABLE_CONV: True
DATASETS:
  TRAIN: ("coco_2017_train_panoptic",)
  TEST: ("coco_2017_val_panoptic",)
SOLVER:
  BASE_LR: 0.0005
  MAX_ITER: 200000
  IMS_PER_BATCH: 64
INPUT:
  FORMAT: "RGB"
  GAUSSIAN_SIGMA: 8
  MIN_SIZE_TRAIN: !!python/object/apply:eval ["[int(x * 0.1 * 640) for x in range(5, 16)]"]
  MIN_SIZE_TRAIN_SAMPLING: "choice"
  MIN_SIZE_TEST: 640
  MAX_SIZE_TRAIN: 960
  MAX_SIZE_TEST: 640
  CROP:
    ENABLED: True
    TYPE: "absolute"
    SIZE: (640, 640)

[12/10 22:52:50 detectron2]: Running with full config:
CUDNN_BENCHMARK: false
DATALOADER:
  ASPECT_RATIO_GROUPING: true
  FILTER_EMPTY_ANNOTATIONS: true
  NUM_WORKERS: 10
  REPEAT_THRESHOLD: 0.0
  SAMPLER_TRAIN: TrainingSampler
DATASETS:
  PRECOMPUTED_PROPOSAL_TOPK_TEST: 1000
  PRECOMPUTED_PROPOSAL_TOPK_TRAIN: 2000
  PROPOSAL_FILES_TEST: []
  PROPOSAL_FILES_TRAIN: []
  TEST:
  - coco_2017_val_panoptic
  TRAIN:
  - coco_2017_train_panoptic
GLOBAL:
  HACK: 1.0
INPUT:
  CROP:
    ENABLED: true
    SINGLE_CATEGORY_MAX_AREA: 1.0
    SIZE:
    - 640
    - 640
    TYPE: absolute
  FORMAT: RGB
  GAUSSIAN_SIGMA: 8
  IGNORE_CROWD_IN_SEMANTIC: false
  IGNORE_STUFF_IN_OFFSET: true
  MASK_FORMAT: polygon
  MAX_SIZE_TEST: 640
  MAX_SIZE_TRAIN: 960
  MIN_SIZE_TEST: 640
  MIN_SIZE_TRAIN:
  - 320
  - 384
  - 448
  - 512
  - 576
  - 640
  - 704
  - 768
  - 832
  - 896
  - 960
  MIN_SIZE_TRAIN_SAMPLING: choice
  RANDOM_FLIP: horizontal
  SMALL_INSTANCE_AREA: 4096
  SMALL_INSTANCE_WEIGHT: 3
MODEL:
  ANCHOR_GENERATOR:
    ANGLES:
    - - -90
      - 0
      - 90
    ASPECT_RATIOS:
    - - 0.5
      - 1.0
      - 2.0
    NAME: DefaultAnchorGenerator
    OFFSET: 0.0
    SIZES:
    - - 32
      - 64
      - 128
      - 256
      - 512
  BACKBONE:
    FREEZE_AT: 5
    NAME: build_resnet_deeplab_backbone
  DEVICE: cuda
  FPN:
    FUSE_TYPE: sum
    IN_FEATURES: []
    NORM: ''
    OUT_CHANNELS: 256
  INS_EMBED_HEAD:
    ASPP_CHANNELS: 256
    ASPP_DILATIONS:
    - 6
    - 12
    - 18
    ASPP_DROPOUT: 0.1
    CENTER_LOSS_WEIGHT: 200.0
    COMMON_STRIDE: 4
    CONVS_DIM: 128
    HEAD_CHANNELS: 32
    IN_FEATURES:
    - res2
    - res3
    - res5
    NAME: PanopticDeepLabInsEmbedHead
    NORM: BN
    OFFSET_LOSS_WEIGHT: 0.01
    PROJECT_CHANNELS:
    - 32
    - 64
    PROJECT_FEATURES:
    - res2
    - res3
  KEYPOINT_ON: false
  LOAD_PROPOSALS: false
  MASK_ON: false
  META_ARCHITECTURE: PanopticDeepLab
  PANOPTIC_DEEPLAB:
    BENCHMARK_NETWORK_SPEED: false
    CENTER_THRESHOLD: 0.1
    NMS_KERNEL: 41
    PREDICT_INSTANCES: true
    SIZE_DIVISIBILITY: 640
    STUFF_AREA: 4096
    TOP_K_INSTANCE: 200
    USE_DEPTHWISE_SEPARABLE_CONV: true
  PANOPTIC_FPN:
    COMBINE:
      ENABLED: true
      INSTANCES_CONFIDENCE_THRESH: 0.5
      OVERLAP_THRESH: 0.5
      STUFF_AREA_LIMIT: 4096
    INSTANCE_LOSS_WEIGHT: 1.0
  PIXEL_MEAN:
  - 123.675
  - 116.28
  - 103.53
  PIXEL_STD:
  - 58.395
  - 57.12
  - 57.375
  PROPOSAL_GENERATOR:
    MIN_SIZE: 0
    NAME: RPN
  RESNETS:
    DEFORM_MODULATED: false
    DEFORM_NUM_GROUPS: 1
    DEFORM_ON_PER_STAGE:
    - false
    - false
    - false
    - false
    DEPTH: 101
    NORM: BN
    NUM_GROUPS: 1
    OUT_FEATURES:
    - res2
    - res3
    - res5
    RES2_OUT_CHANNELS: 256
    RES4_DILATION: 1
    RES5_DILATION: 2
    RES5_MULTI_GRID:
    - 1
    - 2
    - 4
    STEM_OUT_CHANNELS: 128
    STEM_TYPE: deeplab
    STRIDE_IN_1X1: false
    WIDTH_PER_GROUP: 64
  RETINANET:
    BBOX_REG_LOSS_TYPE: smooth_l1
    BBOX_REG_WEIGHTS: &id001
    - 1.0
    - 1.0
    - 1.0
    - 1.0
    FOCAL_LOSS_ALPHA: 0.25
    FOCAL_LOSS_GAMMA: 2.0
    IN_FEATURES:
    - p3
    - p4
    - p5
    - p6
    - p7
    IOU_LABELS:
    - 0
    - -1
    - 1
    IOU_THRESHOLDS:
    - 0.4
    - 0.5
    NMS_THRESH_TEST: 0.5
    NORM: ''
    NUM_CLASSES: 80
    NUM_CONVS: 4
    PRIOR_PROB: 0.01
    SCORE_THRESH_TEST: 0.05
    SMOOTH_L1_LOSS_BETA: 0.1
    TOPK_CANDIDATES_TEST: 1000
  ROI_BOX_CASCADE_HEAD:
    BBOX_REG_WEIGHTS:
    - - 10.0
      - 10.0
      - 5.0
      - 5.0
    - - 20.0
      - 20.0
      - 10.0
      - 10.0
    - - 30.0
      - 30.0
      - 15.0
      - 15.0
    IOUS:
    - 0.5
    - 0.6
    - 0.7
  ROI_BOX_HEAD:
    BBOX_REG_LOSS_TYPE: smooth_l1
    BBOX_REG_LOSS_WEIGHT: 1.0
    BBOX_REG_WEIGHTS:
    - 10.0
    - 10.0
    - 5.0
    - 5.0
    CLS_AGNOSTIC_BBOX_REG: false
    CONV_DIM: 256
    FC_DIM: 1024
    FED_LOSS_FREQ_WEIGHT_POWER: 0.5
    FED_LOSS_NUM_CLASSES: 50
    NAME: ''
    NORM: ''
    NUM_CONV: 0
    NUM_FC: 0
    POOLER_RESOLUTION: 14
    POOLER_SAMPLING_RATIO: 0
    POOLER_TYPE: ROIAlignV2
    SMOOTH_L1_BETA: 0.0
    TRAIN_ON_PRED_BOXES: false
    USE_FED_LOSS: false
    USE_SIGMOID_CE: false
  ROI_HEADS:
    BATCH_SIZE_PER_IMAGE: 512
    IN_FEATURES:
    - res4
    IOU_LABELS:
    - 0
    - 1
    IOU_THRESHOLDS:
    - 0.5
    NAME: Res5ROIHeads
    NMS_THRESH_TEST: 0.5
    NUM_CLASSES: 80
    POSITIVE_FRACTION: 0.25
    PROPOSAL_APPEND_GT: true
    SCORE_THRESH_TEST: 0.05
  ROI_KEYPOINT_HEAD:
    CONV_DIMS:
    - 512
    - 512
    - 512
    - 512
    - 512
    - 512
    - 512
    - 512
    LOSS_WEIGHT: 1.0
    MIN_KEYPOINTS_PER_IMAGE: 1
    NAME: KRCNNConvDeconvUpsampleHead
    NORMALIZE_LOSS_BY_VISIBLE_KEYPOINTS: true
    NUM_KEYPOINTS: 17
    POOLER_RESOLUTION: 14
    POOLER_SAMPLING_RATIO: 0
    POOLER_TYPE: ROIAlignV2
  ROI_MASK_HEAD:
    CLS_AGNOSTIC_MASK: false
    CONV_DIM: 256
    NAME: MaskRCNNConvUpsampleHead
    NORM: ''
    NUM_CONV: 0
    POOLER_RESOLUTION: 14
    POOLER_SAMPLING_RATIO: 0
    POOLER_TYPE: ROIAlignV2
  RPN:
    BATCH_SIZE_PER_IMAGE: 256
    BBOX_REG_LOSS_TYPE: smooth_l1
    BBOX_REG_LOSS_WEIGHT: 1.0
    BBOX_REG_WEIGHTS: *id001
    BOUNDARY_THRESH: -1
    CONV_DIMS:
    - -1
    HEAD_NAME: StandardRPNHead
    IN_FEATURES:
    - res4
    IOU_LABELS:
    - 0
    - -1
    - 1
    IOU_THRESHOLDS:
    - 0.3
    - 0.7
    LOSS_WEIGHT: 1.0
    NMS_THRESH: 0.7
    POSITIVE_FRACTION: 0.5
    POST_NMS_TOPK_TEST: 1000
    POST_NMS_TOPK_TRAIN: 2000
    PRE_NMS_TOPK_TEST: 6000
    PRE_NMS_TOPK_TRAIN: 12000
    SMOOTH_L1_BETA: 0.0
  SEM_SEG_HEAD:
    ASPP_CHANNELS: 256
    ASPP_DILATIONS:
    - 6
    - 12
    - 18
    ASPP_DROPOUT: 0.1
    COMMON_STRIDE: 4
    CONVS_DIM: 256
    HEAD_CHANNELS: 256
    IGNORE_VALUE: 255
    IN_FEATURES:
    - res2
    - res3
    - res5
    LOSS_TOP_K: 1.0
    LOSS_TYPE: hard_pixel_mining
    LOSS_WEIGHT: 1.0
    NAME: PanopticDeepLabSemSegHead
    NORM: BN
    NUM_CLASSES: 133
    PROJECT_CHANNELS:
    - 32
    - 64
    PROJECT_FEATURES:
    - res2
    - res3
    USE_DEPTHWISE_SEPARABLE_CONV: true
  WEIGHTS: detectron2://DeepLab/R-103.pkl
OUTPUT_DIR: ./output
SEED: -1
SOLVER:
  AMP:
    ENABLED: false
  BASE_LR: 0.0025
  BASE_LR_END: 0.0
  BIAS_LR_FACTOR: 1.0
  CHECKPOINT_PERIOD: 5000
  CLIP_GRADIENTS:
    CLIP_TYPE: value
    CLIP_VALUE: 1.0
    ENABLED: false
    NORM_TYPE: 2.0
  GAMMA: 0.1
  IMS_PER_BATCH: 5
  LR_SCHEDULER_NAME: WarmupPolyLR
  MAX_ITER: 10000
  MOMENTUM: 0.9
  NESTEROV: false
  NUM_DECAYS: 3
  OPTIMIZER: ADAM
  POLY_LR_CONSTANT_ENDING: 0.0
  POLY_LR_POWER: 0.9
  REFERENCE_WORLD_SIZE: 0
  RESCALE_INTERVAL: false
  STEPS:
  - 30000
  WARMUP_FACTOR: 0.001
  WARMUP_ITERS: 1000
  WARMUP_METHOD: linear
  WEIGHT_DECAY: 0.0
  WEIGHT_DECAY_BIAS: 0.0
  WEIGHT_DECAY_NORM: 0.0
TEST:
  AUG:
    ENABLED: false
    FLIP: true
    MAX_SIZE: 4000
    MIN_SIZES:
    - 400
    - 500
    - 600
    - 700
    - 800
    - 900
    - 1000
    - 1100
    - 1200
  DETECTIONS_PER_IMAGE: 100
  EVAL_PERIOD: 0
  EXPECTED_RESULTS: []
  KEYPOINT_OKS_SIGMAS: []
  PRECISE_BN:
    ENABLED: false
    NUM_ITER: 200
VERSION: 2
VIS_PERIOD: 0

[12/10 22:52:51 detectron2]: Full config saved to ./output/config.yaml
[12/10 22:52:51 d2.utils.env]: Using a generated random seed 51146860
=== ResNet Feeze ===
Resnet stage idx: 2
Resnet stage idx: 3
Resnet stage idx: 4
Resnet stage idx: 5
=== ResNet Feeze ===
Resnet stage idx: 2
Resnet stage idx: 3
Resnet stage idx: 4
Resnet stage idx: 5
[12/10 22:52:55 d2.engine.defaults]: Model:
PanopticDeepLab(
  (backbone): ResNet(
    (stem): DeepLabStem(
      (conv1): Conv2d(
        3, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False
        (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
      )
      (conv2): Conv2d(
        64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
        (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
      )
      (conv3): Conv2d(
        64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
        (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
      )
    )
    (res2): Sequential(
      (0): BottleneckBlock(
        (shortcut): Conv2d(
          128, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv1): Conv2d(
          128, 64, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
        )
        (conv2): Conv2d(
          64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
        )
        (conv3): Conv2d(
          64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
      )
      (1): BottleneckBlock(
        (conv1): Conv2d(
          256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
        )
        (conv2): Conv2d(
          64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
        )
        (conv3): Conv2d(
          64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
      )
      (2): BottleneckBlock(
        (conv1): Conv2d(
          256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
        )
        (conv2): Conv2d(
          64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
        )
        (conv3): Conv2d(
          64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
      )
    )
    (res3): Sequential(
      (0): BottleneckBlock(
        (shortcut): Conv2d(
          256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False
          (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
        )
        (conv1): Conv2d(
          256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
        )
        (conv2): Conv2d(
          128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
        )
        (conv3): Conv2d(
          128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
        )
      )
      (1): BottleneckBlock(
        (conv1): Conv2d(
          512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
        )
        (conv2): Conv2d(
          128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
        )
        (conv3): Conv2d(
          128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
        )
      )
      (2): BottleneckBlock(
        (conv1): Conv2d(
          512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
        )
        (conv2): Conv2d(
          128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
        )
        (conv3): Conv2d(
          128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
        )
      )
      (3): BottleneckBlock(
        (conv1): Conv2d(
          512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
        )
        (conv2): Conv2d(
          128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
        )
        (conv3): Conv2d(
          128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
        )
      )
    )
    (res4): Sequential(
      (0): BottleneckBlock(
        (shortcut): Conv2d(
          512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False
          (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
        )
        (conv1): Conv2d(
          512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv2): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv3): Conv2d(
          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
        )
      )
      (1): BottleneckBlock(
        (conv1): Conv2d(
          1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv2): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv3): Conv2d(
          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
        )
      )
      (2): BottleneckBlock(
        (conv1): Conv2d(
          1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv2): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv3): Conv2d(
          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
        )
      )
      (3): BottleneckBlock(
        (conv1): Conv2d(
          1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv2): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv3): Conv2d(
          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
        )
      )
      (4): BottleneckBlock(
        (conv1): Conv2d(
          1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv2): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv3): Conv2d(
          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
        )
      )
      (5): BottleneckBlock(
        (conv1): Conv2d(
          1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv2): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv3): Conv2d(
          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
        )
      )
      (6): BottleneckBlock(
        (conv1): Conv2d(
          1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv2): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv3): Conv2d(
          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
        )
      )
      (7): BottleneckBlock(
        (conv1): Conv2d(
          1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv2): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv3): Conv2d(
          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
        )
      )
      (8): BottleneckBlock(
        (conv1): Conv2d(
          1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv2): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv3): Conv2d(
          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
        )
      )
      (9): BottleneckBlock(
        (conv1): Conv2d(
          1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv2): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv3): Conv2d(
          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
        )
      )
      (10): BottleneckBlock(
        (conv1): Conv2d(
          1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv2): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv3): Conv2d(
          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
        )
      )
      (11): BottleneckBlock(
        (conv1): Conv2d(
          1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv2): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv3): Conv2d(
          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
        )
      )
      (12): BottleneckBlock(
        (conv1): Conv2d(
          1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv2): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv3): Conv2d(
          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
        )
      )
      (13): BottleneckBlock(
        (conv1): Conv2d(
          1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv2): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv3): Conv2d(
          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
        )
      )
      (14): BottleneckBlock(
        (conv1): Conv2d(
          1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv2): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv3): Conv2d(
          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
        )
      )
      (15): BottleneckBlock(
        (conv1): Conv2d(
          1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv2): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv3): Conv2d(
          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
        )
      )
      (16): BottleneckBlock(
        (conv1): Conv2d(
          1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv2): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv3): Conv2d(
          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
        )
      )
      (17): BottleneckBlock(
        (conv1): Conv2d(
          1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv2): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv3): Conv2d(
          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
        )
      )
      (18): BottleneckBlock(
        (conv1): Conv2d(
          1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv2): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv3): Conv2d(
          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
        )
      )
      (19): BottleneckBlock(
        (conv1): Conv2d(
          1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv2): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv3): Conv2d(
          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
        )
      )
      (20): BottleneckBlock(
        (conv1): Conv2d(
          1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv2): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv3): Conv2d(
          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
        )
      )
      (21): BottleneckBlock(
        (conv1): Conv2d(
          1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv2): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv3): Conv2d(
          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
        )
      )
      (22): BottleneckBlock(
        (conv1): Conv2d(
          1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv2): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv3): Conv2d(
          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
        )
      )
    )
    (res5): Sequential(
      (0): BottleneckBlock(
        (shortcut): Conv2d(
          1024, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)
        )
        (conv1): Conv2d(
          1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
        )
        (conv2): Conv2d(
          512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2), dilation=(2, 2), bias=False
          (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
        )
        (conv3): Conv2d(
          512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)
        )
      )
      (1): BottleneckBlock(
        (conv1): Conv2d(
          2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
        )
        (conv2): Conv2d(
          512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(4, 4), dilation=(4, 4), bias=False
          (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
        )
        (conv3): Conv2d(
          512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)
        )
      )
      (2): BottleneckBlock(
        (conv1): Conv2d(
          2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
        )
        (conv2): Conv2d(
          512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(8, 8), dilation=(8, 8), bias=False
          (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
        )
        (conv3): Conv2d(
          512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)
        )
      )
    )
  )
  (sem_seg_head): PanopticDeepLabSemSegHead(
    (decoder): ModuleDict(
      (res2): ModuleDict(
        (project_conv): Conv2d(
          256, 32, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (fuse_conv): DepthwiseSeparableConv2d(
          (depthwise): Conv2d(
            288, 288, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=288, bias=False
            (norm): BatchNorm2d(288, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          )
          (pointwise): Conv2d(
            288, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
      )
      (res3): ModuleDict(
        (project_conv): Conv2d(
          512, 64, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (fuse_conv): DepthwiseSeparableConv2d(
          (depthwise): Conv2d(
            320, 320, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=320, bias=False
            (norm): BatchNorm2d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          )
          (pointwise): Conv2d(
            320, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
      )
      (res5): ModuleDict(
        (project_conv): ASPP(
          (convs): ModuleList(
            (0): Conv2d(
              2048, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
              (norm): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            )
            (1): DepthwiseSeparableConv2d(
              (depthwise): Conv2d(
                2048, 2048, kernel_size=(3, 3), stride=(1, 1), padding=(6, 6), dilation=(6, 6), groups=2048, bias=False
                (norm): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
              (pointwise): Conv2d(
                2048, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
            )
            (2): DepthwiseSeparableConv2d(
              (depthwise): Conv2d(
                2048, 2048, kernel_size=(3, 3), stride=(1, 1), padding=(12, 12), dilation=(12, 12), groups=2048, bias=False
                (norm): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
              (pointwise): Conv2d(
                2048, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
            )
            (3): DepthwiseSeparableConv2d(
              (depthwise): Conv2d(
                2048, 2048, kernel_size=(3, 3), stride=(1, 1), padding=(18, 18), dilation=(18, 18), groups=2048, bias=False
                (norm): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
              (pointwise): Conv2d(
                2048, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
            )
            (4): Sequential(
              (0): AvgPool2d(kernel_size=(40, 40), stride=1, padding=0)
              (1): Conv2d(2048, 256, kernel_size=(1, 1), stride=(1, 1))
            )
          )
          (project): Conv2d(
            1280, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (fuse_conv): None
      )
    )
    (head): DepthwiseSeparableConv2d(
      (depthwise): Conv2d(
        256, 256, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=256, bias=False
        (norm): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (pointwise): Conv2d(
        256, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
        (norm): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (predictor): Conv2d(256, 133, kernel_size=(1, 1), stride=(1, 1))
    (loss): DeepLabCE(
      (criterion): CrossEntropyLoss()
    )
  )
  (ins_embed_head): PanopticDeepLabInsEmbedHead(
    (decoder): ModuleDict(
      (res2): ModuleDict(
        (project_conv): Conv2d(
          256, 32, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (fuse_conv): DepthwiseSeparableConv2d(
          (depthwise): Conv2d(
            160, 160, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=160, bias=False
            (norm): BatchNorm2d(160, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          )
          (pointwise): Conv2d(
            160, 128, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
      )
      (res3): ModuleDict(
        (project_conv): Conv2d(
          512, 64, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (fuse_conv): DepthwiseSeparableConv2d(
          (depthwise): Conv2d(
            320, 320, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=320, bias=False
            (norm): BatchNorm2d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          )
          (pointwise): Conv2d(
            320, 128, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
      )
      (res5): ModuleDict(
        (project_conv): ASPP(
          (convs): ModuleList(
            (0): Conv2d(
              2048, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
              (norm): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            )
            (1): DepthwiseSeparableConv2d(
              (depthwise): Conv2d(
                2048, 2048, kernel_size=(3, 3), stride=(1, 1), padding=(6, 6), dilation=(6, 6), groups=2048, bias=False
                (norm): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
              (pointwise): Conv2d(
                2048, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
            )
            (2): DepthwiseSeparableConv2d(
              (depthwise): Conv2d(
                2048, 2048, kernel_size=(3, 3), stride=(1, 1), padding=(12, 12), dilation=(12, 12), groups=2048, bias=False
                (norm): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
              (pointwise): Conv2d(
                2048, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
            )
            (3): DepthwiseSeparableConv2d(
              (depthwise): Conv2d(
                2048, 2048, kernel_size=(3, 3), stride=(1, 1), padding=(18, 18), dilation=(18, 18), groups=2048, bias=False
                (norm): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
              (pointwise): Conv2d(
                2048, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
            )
            (4): Sequential(
              (0): AvgPool2d(kernel_size=(40, 40), stride=1, padding=0)
              (1): Conv2d(2048, 256, kernel_size=(1, 1), stride=(1, 1))
            )
          )
          (project): Conv2d(
            1280, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (fuse_conv): None
      )
    )
    (center_head): Sequential(
      (0): Conv2d(
        128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
        (norm): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (1): Conv2d(
        128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
        (norm): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (center_predictor): Conv2d(32, 1, kernel_size=(1, 1), stride=(1, 1))
    (offset_head): DepthwiseSeparableConv2d(
      (depthwise): Conv2d(
        128, 128, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=128, bias=False
        (norm): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (pointwise): Conv2d(
        128, 32, kernel_size=(1, 1), stride=(1, 1), bias=False
        (norm): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (offset_predictor): Conv2d(32, 2, kernel_size=(1, 1), stride=(1, 1))
    (center_loss): MSELoss()
    (offset_loss): L1Loss()
  )
)
[12/10 22:52:55 d2.projects.panoptic_deeplab.dataset_mapper]: Augmentations used in training: [ResizeShortestEdge(short_edge_length=(320, 384, 448, 512, 576, 640, 704, 768, 832, 896, 960), max_size=960, sample_style='choice'), RandomCrop(crop_type='absolute', crop_size=[640, 640]), RandomFlip()]
[12/10 22:53:02 d2.data.build]: Using training sampler TrainingSampler
[12/10 22:53:02 d2.data.common]: Serializing the dataset using: <class 'detectron2.data.common.NumpySerializedList'>
[12/10 22:53:02 d2.data.common]: Serializing 118287 elements to byte tensors and concatenating them all ...
[12/10 22:53:03 d2.data.common]: Serialized dataset takes 78.29 MiB
/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:481: UserWarning: This DataLoader will create 10 worker processes in total. Our suggested max number of worker in current system is 8, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.
  cpuset_checked))
[12/10 22:53:06 fvcore.common.checkpoint]: [Checkpointer] Loading from detectron2://DeepLab/R-103.pkl ...
R-103.pkl: 179MB [00:10, 16.5MB/s]               
[12/10 22:53:17 fvcore.common.checkpoint]: Reading a file from 'torchvision'
[12/10 22:53:17 d2.checkpoint.c2_model_loading]: Following weights matched with submodule backbone:
| Names in Model    | Names in Checkpoint                                                               | Shapes                                          |
|:------------------|:----------------------------------------------------------------------------------|:------------------------------------------------|
| res2.0.conv1.*    | res2.0.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (64,) (64,) (64,) (64,) (64,128,1,1)            |
| res2.0.conv2.*    | res2.0.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (64,) (64,) (64,) (64,) (64,64,3,3)             |
| res2.0.conv3.*    | res2.0.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) (256,) (256,) (256,) (256,64,1,1)        |
| res2.0.shortcut.* | res2.0.shortcut.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight} | (256,) (256,) (256,) (256,) (256,128,1,1)       |
| res2.1.conv1.*    | res2.1.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (64,) (64,) (64,) (64,) (64,256,1,1)            |
| res2.1.conv2.*    | res2.1.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (64,) (64,) (64,) (64,) (64,64,3,3)             |
| res2.1.conv3.*    | res2.1.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) (256,) (256,) (256,) (256,64,1,1)        |
| res2.2.conv1.*    | res2.2.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (64,) (64,) (64,) (64,) (64,256,1,1)            |
| res2.2.conv2.*    | res2.2.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (64,) (64,) (64,) (64,) (64,64,3,3)             |
| res2.2.conv3.*    | res2.2.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) (256,) (256,) (256,) (256,64,1,1)        |
| res3.0.conv1.*    | res3.0.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (128,) (128,) (128,) (128,) (128,256,1,1)       |
| res3.0.conv2.*    | res3.0.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (128,) (128,) (128,) (128,) (128,128,3,3)       |
| res3.0.conv3.*    | res3.0.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (512,) (512,) (512,) (512,) (512,128,1,1)       |
| res3.0.shortcut.* | res3.0.shortcut.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight} | (512,) (512,) (512,) (512,) (512,256,1,1)       |
| res3.1.conv1.*    | res3.1.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (128,) (128,) (128,) (128,) (128,512,1,1)       |
| res3.1.conv2.*    | res3.1.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (128,) (128,) (128,) (128,) (128,128,3,3)       |
| res3.1.conv3.*    | res3.1.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (512,) (512,) (512,) (512,) (512,128,1,1)       |
| res3.2.conv1.*    | res3.2.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (128,) (128,) (128,) (128,) (128,512,1,1)       |
| res3.2.conv2.*    | res3.2.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (128,) (128,) (128,) (128,) (128,128,3,3)       |
| res3.2.conv3.*    | res3.2.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (512,) (512,) (512,) (512,) (512,128,1,1)       |
| res3.3.conv1.*    | res3.3.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (128,) (128,) (128,) (128,) (128,512,1,1)       |
| res3.3.conv2.*    | res3.3.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (128,) (128,) (128,) (128,) (128,128,3,3)       |
| res3.3.conv3.*    | res3.3.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (512,) (512,) (512,) (512,) (512,128,1,1)       |
| res4.0.conv1.*    | res4.0.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) (256,) (256,) (256,) (256,512,1,1)       |
| res4.0.conv2.*    | res4.0.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) (256,) (256,) (256,) (256,256,3,3)       |
| res4.0.conv3.*    | res4.0.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (1024,) (1024,) (1024,) (1024,) (1024,256,1,1)  |
| res4.0.shortcut.* | res4.0.shortcut.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight} | (1024,) (1024,) (1024,) (1024,) (1024,512,1,1)  |
| res4.1.conv1.*    | res4.1.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) (256,) (256,) (256,) (256,1024,1,1)      |
| res4.1.conv2.*    | res4.1.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) (256,) (256,) (256,) (256,256,3,3)       |
| res4.1.conv3.*    | res4.1.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (1024,) (1024,) (1024,) (1024,) (1024,256,1,1)  |
| res4.10.conv1.*   | res4.10.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}   | (256,) (256,) (256,) (256,) (256,1024,1,1)      |
| res4.10.conv2.*   | res4.10.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}   | (256,) (256,) (256,) (256,) (256,256,3,3)       |
| res4.10.conv3.*   | res4.10.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}   | (1024,) (1024,) (1024,) (1024,) (1024,256,1,1)  |
| res4.11.conv1.*   | res4.11.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}   | (256,) (256,) (256,) (256,) (256,1024,1,1)      |
| res4.11.conv2.*   | res4.11.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}   | (256,) (256,) (256,) (256,) (256,256,3,3)       |
| res4.11.conv3.*   | res4.11.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}   | (1024,) (1024,) (1024,) (1024,) (1024,256,1,1)  |
| res4.12.conv1.*   | res4.12.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}   | (256,) (256,) (256,) (256,) (256,1024,1,1)      |
| res4.12.conv2.*   | res4.12.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}   | (256,) (256,) (256,) (256,) (256,256,3,3)       |
| res4.12.conv3.*   | res4.12.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}   | (1024,) (1024,) (1024,) (1024,) (1024,256,1,1)  |
| res4.13.conv1.*   | res4.13.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}   | (256,) (256,) (256,) (256,) (256,1024,1,1)      |
| res4.13.conv2.*   | res4.13.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}   | (256,) (256,) (256,) (256,) (256,256,3,3)       |
| res4.13.conv3.*   | res4.13.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}   | (1024,) (1024,) (1024,) (1024,) (1024,256,1,1)  |
| res4.14.conv1.*   | res4.14.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}   | (256,) (256,) (256,) (256,) (256,1024,1,1)      |
| res4.14.conv2.*   | res4.14.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}   | (256,) (256,) (256,) (256,) (256,256,3,3)       |
| res4.14.conv3.*   | res4.14.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}   | (1024,) (1024,) (1024,) (1024,) (1024,256,1,1)  |
| res4.15.conv1.*   | res4.15.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}   | (256,) (256,) (256,) (256,) (256,1024,1,1)      |
| res4.15.conv2.*   | res4.15.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}   | (256,) (256,) (256,) (256,) (256,256,3,3)       |
| res4.15.conv3.*   | res4.15.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}   | (1024,) (1024,) (1024,) (1024,) (1024,256,1,1)  |
| res4.16.conv1.*   | res4.16.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}   | (256,) (256,) (256,) (256,) (256,1024,1,1)      |
| res4.16.conv2.*   | res4.16.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}   | (256,) (256,) (256,) (256,) (256,256,3,3)       |
| res4.16.conv3.*   | res4.16.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}   | (1024,) (1024,) (1024,) (1024,) (1024,256,1,1)  |
| res4.17.conv1.*   | res4.17.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}   | (256,) (256,) (256,) (256,) (256,1024,1,1)      |
| res4.17.conv2.*   | res4.17.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}   | (256,) (256,) (256,) (256,) (256,256,3,3)       |
| res4.17.conv3.*   | res4.17.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}   | (1024,) (1024,) (1024,) (1024,) (1024,256,1,1)  |
| res4.18.conv1.*   | res4.18.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}   | (256,) (256,) (256,) (256,) (256,1024,1,1)      |
| res4.18.conv2.*   | res4.18.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}   | (256,) (256,) (256,) (256,) (256,256,3,3)       |
| res4.18.conv3.*   | res4.18.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}   | (1024,) (1024,) (1024,) (1024,) (1024,256,1,1)  |
| res4.19.conv1.*   | res4.19.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}   | (256,) (256,) (256,) (256,) (256,1024,1,1)      |
| res4.19.conv2.*   | res4.19.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}   | (256,) (256,) (256,) (256,) (256,256,3,3)       |
| res4.19.conv3.*   | res4.19.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}   | (1024,) (1024,) (1024,) (1024,) (1024,256,1,1)  |
| res4.2.conv1.*    | res4.2.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) (256,) (256,) (256,) (256,1024,1,1)      |
| res4.2.conv2.*    | res4.2.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) (256,) (256,) (256,) (256,256,3,3)       |
| res4.2.conv3.*    | res4.2.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (1024,) (1024,) (1024,) (1024,) (1024,256,1,1)  |
| res4.20.conv1.*   | res4.20.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}   | (256,) (256,) (256,) (256,) (256,1024,1,1)      |
| res4.20.conv2.*   | res4.20.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}   | (256,) (256,) (256,) (256,) (256,256,3,3)       |
| res4.20.conv3.*   | res4.20.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}   | (1024,) (1024,) (1024,) (1024,) (1024,256,1,1)  |
| res4.21.conv1.*   | res4.21.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}   | (256,) (256,) (256,) (256,) (256,1024,1,1)      |
| res4.21.conv2.*   | res4.21.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}   | (256,) (256,) (256,) (256,) (256,256,3,3)       |
| res4.21.conv3.*   | res4.21.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}   | (1024,) (1024,) (1024,) (1024,) (1024,256,1,1)  |
| res4.22.conv1.*   | res4.22.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}   | (256,) (256,) (256,) (256,) (256,1024,1,1)      |
| res4.22.conv2.*   | res4.22.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}   | (256,) (256,) (256,) (256,) (256,256,3,3)       |
| res4.22.conv3.*   | res4.22.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}   | (1024,) (1024,) (1024,) (1024,) (1024,256,1,1)  |
| res4.3.conv1.*    | res4.3.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) (256,) (256,) (256,) (256,1024,1,1)      |
| res4.3.conv2.*    | res4.3.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) (256,) (256,) (256,) (256,256,3,3)       |
| res4.3.conv3.*    | res4.3.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (1024,) (1024,) (1024,) (1024,) (1024,256,1,1)  |
| res4.4.conv1.*    | res4.4.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) (256,) (256,) (256,) (256,1024,1,1)      |
| res4.4.conv2.*    | res4.4.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) (256,) (256,) (256,) (256,256,3,3)       |
| res4.4.conv3.*    | res4.4.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (1024,) (1024,) (1024,) (1024,) (1024,256,1,1)  |
| res4.5.conv1.*    | res4.5.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) (256,) (256,) (256,) (256,1024,1,1)      |
| res4.5.conv2.*    | res4.5.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) (256,) (256,) (256,) (256,256,3,3)       |
| res4.5.conv3.*    | res4.5.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (1024,) (1024,) (1024,) (1024,) (1024,256,1,1)  |
| res4.6.conv1.*    | res4.6.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) (256,) (256,) (256,) (256,1024,1,1)      |
| res4.6.conv2.*    | res4.6.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) (256,) (256,) (256,) (256,256,3,3)       |
| res4.6.conv3.*    | res4.6.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (1024,) (1024,) (1024,) (1024,) (1024,256,1,1)  |
| res4.7.conv1.*    | res4.7.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) (256,) (256,) (256,) (256,1024,1,1)      |
| res4.7.conv2.*    | res4.7.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) (256,) (256,) (256,) (256,256,3,3)       |
| res4.7.conv3.*    | res4.7.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (1024,) (1024,) (1024,) (1024,) (1024,256,1,1)  |
| res4.8.conv1.*    | res4.8.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) (256,) (256,) (256,) (256,1024,1,1)      |
| res4.8.conv2.*    | res4.8.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) (256,) (256,) (256,) (256,256,3,3)       |
| res4.8.conv3.*    | res4.8.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (1024,) (1024,) (1024,) (1024,) (1024,256,1,1)  |
| res4.9.conv1.*    | res4.9.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) (256,) (256,) (256,) (256,1024,1,1)      |
| res4.9.conv2.*    | res4.9.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) (256,) (256,) (256,) (256,256,3,3)       |
| res4.9.conv3.*    | res4.9.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (1024,) (1024,) (1024,) (1024,) (1024,256,1,1)  |
| res5.0.conv1.*    | res5.0.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (512,) (512,) (512,) (512,) (512,1024,1,1)      |
| res5.0.conv2.*    | res5.0.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (512,) (512,) (512,) (512,) (512,512,3,3)       |
| res5.0.conv3.*    | res5.0.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (2048,) (2048,) (2048,) (2048,) (2048,512,1,1)  |
| res5.0.shortcut.* | res5.0.shortcut.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight} | (2048,) (2048,) (2048,) (2048,) (2048,1024,1,1) |
| res5.1.conv1.*    | res5.1.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (512,) (512,) (512,) (512,) (512,2048,1,1)      |
| res5.1.conv2.*    | res5.1.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (512,) (512,) (512,) (512,) (512,512,3,3)       |
| res5.1.conv3.*    | res5.1.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (2048,) (2048,) (2048,) (2048,) (2048,512,1,1)  |
| res5.2.conv1.*    | res5.2.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (512,) (512,) (512,) (512,) (512,2048,1,1)      |
| res5.2.conv2.*    | res5.2.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (512,) (512,) (512,) (512,) (512,512,3,3)       |
| res5.2.conv3.*    | res5.2.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (2048,) (2048,) (2048,) (2048,) (2048,512,1,1)  |
| stem.conv1.*      | stem.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}      | (64,) (64,) (64,) (64,) (64,3,3,3)              |
| stem.conv2.*      | stem.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}      | (64,) (64,) (64,) (64,) (64,64,3,3)             |
| stem.conv3.*      | stem.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}      | (128,) (128,) (128,) (128,) (128,64,3,3)        |
WARNING [12/10 22:53:18 fvcore.common.checkpoint]: Some model parameters or buffers are not found in the checkpoint:
ins_embed_head.center_head.0.norm.{bias, running_mean, running_var, weight}
ins_embed_head.center_head.0.weight
ins_embed_head.center_head.1.norm.{bias, running_mean, running_var, weight}
ins_embed_head.center_head.1.weight
ins_embed_head.center_predictor.{bias, weight}
ins_embed_head.decoder.res2.fuse_conv.depthwise.norm.{bias, running_mean, running_var, weight}
ins_embed_head.decoder.res2.fuse_conv.depthwise.weight
ins_embed_head.decoder.res2.fuse_conv.pointwise.norm.{bias, running_mean, running_var, weight}
ins_embed_head.decoder.res2.fuse_conv.pointwise.weight
ins_embed_head.decoder.res2.project_conv.norm.{bias, running_mean, running_var, weight}
ins_embed_head.decoder.res2.project_conv.weight
ins_embed_head.decoder.res3.fuse_conv.depthwise.norm.{bias, running_mean, running_var, weight}
ins_embed_head.decoder.res3.fuse_conv.depthwise.weight
ins_embed_head.decoder.res3.fuse_conv.pointwise.norm.{bias, running_mean, running_var, weight}
ins_embed_head.decoder.res3.fuse_conv.pointwise.weight
ins_embed_head.decoder.res3.project_conv.norm.{bias, running_mean, running_var, weight}
ins_embed_head.decoder.res3.project_conv.weight
ins_embed_head.decoder.res5.project_conv.convs.0.norm.{bias, running_mean, running_var, weight}
ins_embed_head.decoder.res5.project_conv.convs.0.weight
ins_embed_head.decoder.res5.project_conv.convs.1.depthwise.norm.{bias, running_mean, running_var, weight}
ins_embed_head.decoder.res5.project_conv.convs.1.depthwise.weight
ins_embed_head.decoder.res5.project_conv.convs.1.pointwise.norm.{bias, running_mean, running_var, weight}
ins_embed_head.decoder.res5.project_conv.convs.1.pointwise.weight
ins_embed_head.decoder.res5.project_conv.convs.2.depthwise.norm.{bias, running_mean, running_var, weight}
ins_embed_head.decoder.res5.project_conv.convs.2.depthwise.weight
ins_embed_head.decoder.res5.project_conv.convs.2.pointwise.norm.{bias, running_mean, running_var, weight}
ins_embed_head.decoder.res5.project_conv.convs.2.pointwise.weight
ins_embed_head.decoder.res5.project_conv.convs.3.depthwise.norm.{bias, running_mean, running_var, weight}
ins_embed_head.decoder.res5.project_conv.convs.3.depthwise.weight
ins_embed_head.decoder.res5.project_conv.convs.3.pointwise.norm.{bias, running_mean, running_var, weight}
ins_embed_head.decoder.res5.project_conv.convs.3.pointwise.weight
ins_embed_head.decoder.res5.project_conv.convs.4.1.{bias, weight}
ins_embed_head.decoder.res5.project_conv.project.norm.{bias, running_mean, running_var, weight}
ins_embed_head.decoder.res5.project_conv.project.weight
ins_embed_head.offset_head.depthwise.norm.{bias, running_mean, running_var, weight}
ins_embed_head.offset_head.depthwise.weight
ins_embed_head.offset_head.pointwise.norm.{bias, running_mean, running_var, weight}
ins_embed_head.offset_head.pointwise.weight
ins_embed_head.offset_predictor.{bias, weight}
sem_seg_head.decoder.res2.fuse_conv.depthwise.norm.{bias, running_mean, running_var, weight}
sem_seg_head.decoder.res2.fuse_conv.depthwise.weight
sem_seg_head.decoder.res2.fuse_conv.pointwise.norm.{bias, running_mean, running_var, weight}
sem_seg_head.decoder.res2.fuse_conv.pointwise.weight
sem_seg_head.decoder.res2.project_conv.norm.{bias, running_mean, running_var, weight}
sem_seg_head.decoder.res2.project_conv.weight
sem_seg_head.decoder.res3.fuse_conv.depthwise.norm.{bias, running_mean, running_var, weight}
sem_seg_head.decoder.res3.fuse_conv.depthwise.weight
sem_seg_head.decoder.res3.fuse_conv.pointwise.norm.{bias, running_mean, running_var, weight}
sem_seg_head.decoder.res3.fuse_conv.pointwise.weight
sem_seg_head.decoder.res3.project_conv.norm.{bias, running_mean, running_var, weight}
sem_seg_head.decoder.res3.project_conv.weight
sem_seg_head.decoder.res5.project_conv.convs.0.norm.{bias, running_mean, running_var, weight}
sem_seg_head.decoder.res5.project_conv.convs.0.weight
sem_seg_head.decoder.res5.project_conv.convs.1.depthwise.norm.{bias, running_mean, running_var, weight}
sem_seg_head.decoder.res5.project_conv.convs.1.depthwise.weight
sem_seg_head.decoder.res5.project_conv.convs.1.pointwise.norm.{bias, running_mean, running_var, weight}
sem_seg_head.decoder.res5.project_conv.convs.1.pointwise.weight
sem_seg_head.decoder.res5.project_conv.convs.2.depthwise.norm.{bias, running_mean, running_var, weight}
sem_seg_head.decoder.res5.project_conv.convs.2.depthwise.weight
sem_seg_head.decoder.res5.project_conv.convs.2.pointwise.norm.{bias, running_mean, running_var, weight}
sem_seg_head.decoder.res5.project_conv.convs.2.pointwise.weight
sem_seg_head.decoder.res5.project_conv.convs.3.depthwise.norm.{bias, running_mean, running_var, weight}
sem_seg_head.decoder.res5.project_conv.convs.3.depthwise.weight
sem_seg_head.decoder.res5.project_conv.convs.3.pointwise.norm.{bias, running_mean, running_var, weight}
sem_seg_head.decoder.res5.project_conv.convs.3.pointwise.weight
sem_seg_head.decoder.res5.project_conv.convs.4.1.{bias, weight}
sem_seg_head.decoder.res5.project_conv.project.norm.{bias, running_mean, running_var, weight}
sem_seg_head.decoder.res5.project_conv.project.weight
sem_seg_head.head.depthwise.norm.{bias, running_mean, running_var, weight}
sem_seg_head.head.depthwise.weight
sem_seg_head.head.pointwise.norm.{bias, running_mean, running_var, weight}
sem_seg_head.head.pointwise.weight
sem_seg_head.predictor.{bias, weight}
WARNING [12/10 22:53:18 fvcore.common.checkpoint]: The checkpoint state_dict contains keys that are not used by the model:
  res2.0.conv1.norm.num_batches_tracked
  res2.0.conv2.norm.num_batches_tracked
  res2.0.conv3.norm.num_batches_tracked
  res2.0.shortcut.norm.num_batches_tracked
  res2.1.conv1.norm.num_batches_tracked
  res2.1.conv2.norm.num_batches_tracked
  res2.1.conv3.norm.num_batches_tracked
  res2.2.conv1.norm.num_batches_tracked
  res2.2.conv2.norm.num_batches_tracked
  res2.2.conv3.norm.num_batches_tracked
  res3.0.conv1.norm.num_batches_tracked
  res3.0.conv2.norm.num_batches_tracked
  res3.0.conv3.norm.num_batches_tracked
  res3.0.shortcut.norm.num_batches_tracked
  res3.1.conv1.norm.num_batches_tracked
  res3.1.conv2.norm.num_batches_tracked
  res3.1.conv3.norm.num_batches_tracked
  res3.2.conv1.norm.num_batches_tracked
  res3.2.conv2.norm.num_batches_tracked
  res3.2.conv3.norm.num_batches_tracked
  res3.3.conv1.norm.num_batches_tracked
  res3.3.conv2.norm.num_batches_tracked
  res3.3.conv3.norm.num_batches_tracked
  res4.0.conv1.norm.num_batches_tracked
  res4.0.conv2.norm.num_batches_tracked
  res4.0.conv3.norm.num_batches_tracked
  res4.0.shortcut.norm.num_batches_tracked
  res4.1.conv1.norm.num_batches_tracked
  res4.1.conv2.norm.num_batches_tracked
  res4.1.conv3.norm.num_batches_tracked
  res4.10.conv1.norm.num_batches_tracked
  res4.10.conv2.norm.num_batches_tracked
  res4.10.conv3.norm.num_batches_tracked
  res4.11.conv1.norm.num_batches_tracked
  res4.11.conv2.norm.num_batches_tracked
  res4.11.conv3.norm.num_batches_tracked
  res4.12.conv1.norm.num_batches_tracked
  res4.12.conv2.norm.num_batches_tracked
  res4.12.conv3.norm.num_batches_tracked
  res4.13.conv1.norm.num_batches_tracked
  res4.13.conv2.norm.num_batches_tracked
  res4.13.conv3.norm.num_batches_tracked
  res4.14.conv1.norm.num_batches_tracked
  res4.14.conv2.norm.num_batches_tracked
  res4.14.conv3.norm.num_batches_tracked
  res4.15.conv1.norm.num_batches_tracked
  res4.15.conv2.norm.num_batches_tracked
  res4.15.conv3.norm.num_batches_tracked
  res4.16.conv1.norm.num_batches_tracked
  res4.16.conv2.norm.num_batches_tracked
  res4.16.conv3.norm.num_batches_tracked
  res4.17.conv1.norm.num_batches_tracked
  res4.17.conv2.norm.num_batches_tracked
  res4.17.conv3.norm.num_batches_tracked
  res4.18.conv1.norm.num_batches_tracked
  res4.18.conv2.norm.num_batches_tracked
  res4.18.conv3.norm.num_batches_tracked
  res4.19.conv1.norm.num_batches_tracked
  res4.19.conv2.norm.num_batches_tracked
  res4.19.conv3.norm.num_batches_tracked
  res4.2.conv1.norm.num_batches_tracked
  res4.2.conv2.norm.num_batches_tracked
  res4.2.conv3.norm.num_batches_tracked
  res4.20.conv1.norm.num_batches_tracked
  res4.20.conv2.norm.num_batches_tracked
  res4.20.conv3.norm.num_batches_tracked
  res4.21.conv1.norm.num_batches_tracked
  res4.21.conv2.norm.num_batches_tracked
  res4.21.conv3.norm.num_batches_tracked
  res4.22.conv1.norm.num_batches_tracked
  res4.22.conv2.norm.num_batches_tracked
  res4.22.conv3.norm.num_batches_tracked
  res4.3.conv1.norm.num_batches_tracked
  res4.3.conv2.norm.num_batches_tracked
  res4.3.conv3.norm.num_batches_tracked
  res4.4.conv1.norm.num_batches_tracked
  res4.4.conv2.norm.num_batches_tracked
  res4.4.conv3.norm.num_batches_tracked
  res4.5.conv1.norm.num_batches_tracked
  res4.5.conv2.norm.num_batches_tracked
  res4.5.conv3.norm.num_batches_tracked
  res4.6.conv1.norm.num_batches_tracked
  res4.6.conv2.norm.num_batches_tracked
  res4.6.conv3.norm.num_batches_tracked
  res4.7.conv1.norm.num_batches_tracked
  res4.7.conv2.norm.num_batches_tracked
  res4.7.conv3.norm.num_batches_tracked
  res4.8.conv1.norm.num_batches_tracked
  res4.8.conv2.norm.num_batches_tracked
  res4.8.conv3.norm.num_batches_tracked
  res4.9.conv1.norm.num_batches_tracked
  res4.9.conv2.norm.num_batches_tracked
  res4.9.conv3.norm.num_batches_tracked
  res5.0.conv1.norm.num_batches_tracked
  res5.0.conv2.norm.num_batches_tracked
  res5.0.conv3.norm.num_batches_tracked
  res5.0.shortcut.norm.num_batches_tracked
  res5.1.conv1.norm.num_batches_tracked
  res5.1.conv2.norm.num_batches_tracked
  res5.1.conv3.norm.num_batches_tracked
  res5.2.conv1.norm.num_batches_tracked
  res5.2.conv2.norm.num_batches_tracked
  res5.2.conv3.norm.num_batches_tracked
  stem.conv1.norm.num_batches_tracked
  stem.conv2.norm.num_batches_tracked
  stem.conv3.norm.num_batches_tracked
  stem.fc.{bias, weight}
[12/10 22:53:18 d2.engine.train_loop]: Starting training from iteration 0
/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:481: UserWarning: This DataLoader will create 10 worker processes in total. Our suggested max number of worker in current system is 8, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.
  cpuset_checked))
[12/10 22:53:24 d2.utils.events]:  eta: 0:48:25  iter: 19  total_loss: 6.322  loss_sem_seg: 3.775  loss_center: 0.7533  loss_offset: 1.844  time: 0.2982  data_time: 0.0641  lr: 4.9867e-05  max_mem: 6587M
[12/10 22:53:30 d2.utils.events]:  eta: 0:48:29  iter: 39  total_loss: 5.932  loss_sem_seg: 3.733  loss_center: 0.6563  loss_offset: 1.685  time: 0.2957  data_time: 0.0243  lr: 9.9552e-05  max_mem: 6587M
[12/10 22:53:36 d2.utils.events]:  eta: 0:48:34  iter: 59  total_loss: 5.796  loss_sem_seg: 3.54  loss_center: 0.7464  loss_offset: 1.445  time: 0.2964  data_time: 0.0253  lr: 0.00014906  max_mem: 6587M
[12/10 22:53:42 d2.utils.events]:  eta: 0:48:23  iter: 79  total_loss: 5.638  loss_sem_seg: 3.494  loss_center: 0.6757  loss_offset: 1.382  time: 0.2965  data_time: 0.0254  lr: 0.00019838  max_mem: 6587M
[12/10 22:53:48 d2.utils.events]:  eta: 0:48:18  iter: 99  total_loss: 5.251  loss_sem_seg: 3.16  loss_center: 0.6067  loss_offset: 1.544  time: 0.2961  data_time: 0.0235  lr: 0.00024753  max_mem: 6587M
[12/10 22:53:54 d2.utils.events]:  eta: 0:48:23  iter: 119  total_loss: 5.372  loss_sem_seg: 3.018  loss_center: 0.7483  loss_offset: 1.539  time: 0.2963  data_time: 0.0263  lr: 0.00029649  max_mem: 6587M
[12/10 22:54:00 d2.utils.events]:  eta: 0:48:30  iter: 139  total_loss: 4.866  loss_sem_seg: 2.861  loss_center: 0.5807  loss_offset: 1.561  time: 0.2968  data_time: 0.0252  lr: 0.00034528  max_mem: 6587M
[12/10 22:54:06 d2.utils.events]:  eta: 0:48:22  iter: 159  total_loss: 4.996  loss_sem_seg: 2.812  loss_center: 0.5959  loss_offset: 1.686  time: 0.2965  data_time: 0.0251  lr: 0.00039388  max_mem: 6587M
[12/10 22:54:12 d2.utils.events]:  eta: 0:48:18  iter: 179  total_loss: 4.649  loss_sem_seg: 2.65  loss_center: 0.6417  loss_offset: 1.545  time: 0.2965  data_time: 0.0258  lr: 0.0004423  max_mem: 6587M
[12/10 22:54:18 d2.utils.events]:  eta: 0:48:10  iter: 199  total_loss: 4.97  loss_sem_seg: 2.393  loss_center: 0.7686  loss_offset: 1.791  time: 0.2962  data_time: 0.0227  lr: 0.00049055  max_mem: 6587M
[12/10 22:54:24 d2.utils.events]:  eta: 0:48:02  iter: 219  total_loss: 4.763  loss_sem_seg: 2.299  loss_center: 0.7669  loss_offset: 1.581  time: 0.2962  data_time: 0.0246  lr: 0.00053861  max_mem: 6587M
[12/10 22:54:30 d2.utils.events]:  eta: 0:47:51  iter: 239  total_loss: 4.583  loss_sem_seg: 2.228  loss_center: 0.653  loss_offset: 1.598  time: 0.2961  data_time: 0.0243  lr: 0.00058649  max_mem: 6587M
[12/10 22:54:36 d2.utils.events]:  eta: 0:47:44  iter: 259  total_loss: 4.701  loss_sem_seg: 2.355  loss_center: 0.7248  loss_offset: 1.344  time: 0.2959  data_time: 0.0247  lr: 0.0006342  max_mem: 6587M
[12/10 22:54:42 d2.utils.events]:  eta: 0:47:38  iter: 279  total_loss: 4.67  loss_sem_seg: 2.473  loss_center: 0.6757  loss_offset: 1.471  time: 0.2963  data_time: 0.0263  lr: 0.00068172  max_mem: 6588M
[12/10 22:54:48 d2.utils.events]:  eta: 0:47:32  iter: 299  total_loss: 4.287  loss_sem_seg: 2.231  loss_center: 0.5676  loss_offset: 1.428  time: 0.2964  data_time: 0.0261  lr: 0.00072906  max_mem: 6588M
[12/10 22:54:53 d2.utils.events]:  eta: 0:47:28  iter: 319  total_loss: 4.362  loss_sem_seg: 2.139  loss_center: 0.6493  loss_offset: 1.339  time: 0.2963  data_time: 0.0257  lr: 0.00077622  max_mem: 6588M
[12/10 22:54:59 d2.utils.events]:  eta: 0:47:21  iter: 339  total_loss: 4.38  loss_sem_seg: 2.062  loss_center: 0.6639  loss_offset: 1.656  time: 0.2963  data_time: 0.0248  lr: 0.0008232  max_mem: 6588M
[12/10 22:55:05 d2.utils.events]:  eta: 0:47:16  iter: 359  total_loss: 3.998  loss_sem_seg: 1.95  loss_center: 0.6869  loss_offset: 1.247  time: 0.2963  data_time: 0.0245  lr: 0.00087  max_mem: 6588M
[12/10 22:55:11 d2.utils.events]:  eta: 0:47:10  iter: 379  total_loss: 3.93  loss_sem_seg: 2.045  loss_center: 0.6102  loss_offset: 1.177  time: 0.2962  data_time: 0.0229  lr: 0.00091662  max_mem: 6588M
[12/10 22:55:17 d2.utils.events]:  eta: 0:47:05  iter: 399  total_loss: 3.799  loss_sem_seg: 1.848  loss_center: 0.6298  loss_offset: 1.098  time: 0.2962  data_time: 0.0249  lr: 0.00096306  max_mem: 6588M
[12/10 22:55:23 d2.utils.events]:  eta: 0:46:58  iter: 419  total_loss: 3.871  loss_sem_seg: 1.942  loss_center: 0.743  loss_offset: 1.069  time: 0.2962  data_time: 0.0255  lr: 0.0010093  max_mem: 6588M
[12/10 22:55:29 d2.utils.events]:  eta: 0:46:55  iter: 439  total_loss: 3.969  loss_sem_seg: 1.939  loss_center: 0.7654  loss_offset: 1.079  time: 0.2963  data_time: 0.0256  lr: 0.0010554  max_mem: 6588M
[12/10 22:55:35 d2.utils.events]:  eta: 0:46:49  iter: 459  total_loss: 3.594  loss_sem_seg: 1.728  loss_center: 0.7246  loss_offset: 1.092  time: 0.2964  data_time: 0.0254  lr: 0.0011013  max_mem: 6588M
[12/10 22:55:41 d2.utils.events]:  eta: 0:46:42  iter: 479  total_loss: 3.774  loss_sem_seg: 1.839  loss_center: 0.5828  loss_offset: 1.244  time: 0.2963  data_time: 0.0241  lr: 0.001147  max_mem: 6588M
[12/10 22:55:47 d2.utils.events]:  eta: 0:46:38  iter: 499  total_loss: 3.805  loss_sem_seg: 1.857  loss_center: 0.8966  loss_offset: 0.9536  time: 0.2964  data_time: 0.0250  lr: 0.0011925  max_mem: 6588M
[12/10 22:55:53 d2.utils.events]:  eta: 0:46:33  iter: 519  total_loss: 3.699  loss_sem_seg: 1.859  loss_center: 0.5462  loss_offset: 1.184  time: 0.2964  data_time: 0.0260  lr: 0.0012379  max_mem: 6588M
[12/10 22:55:59 d2.utils.events]:  eta: 0:46:28  iter: 539  total_loss: 3.654  loss_sem_seg: 1.783  loss_center: 0.7724  loss_offset: 1.073  time: 0.2964  data_time: 0.0264  lr: 0.001283  max_mem: 6588M
[12/10 22:56:05 d2.utils.events]:  eta: 0:46:25  iter: 559  total_loss: 3.335  loss_sem_seg: 1.59  loss_center: 0.6607  loss_offset: 0.8951  time: 0.2965  data_time: 0.0254  lr: 0.001328  max_mem: 6588M
[12/10 22:56:11 d2.utils.events]:  eta: 0:46:20  iter: 579  total_loss: 3.256  loss_sem_seg: 1.653  loss_center: 0.5292  loss_offset: 1.028  time: 0.2966  data_time: 0.0261  lr: 0.0013728  max_mem: 6588M
[12/10 22:56:17 d2.utils.events]:  eta: 0:46:13  iter: 599  total_loss: 3.705  loss_sem_seg: 1.918  loss_center: 0.7568  loss_offset: 1.138  time: 0.2965  data_time: 0.0244  lr: 0.0014175  max_mem: 6588M
[12/10 22:56:23 d2.utils.events]:  eta: 0:46:07  iter: 619  total_loss: 3.277  loss_sem_seg: 1.64  loss_center: 0.5463  loss_offset: 0.9504  time: 0.2965  data_time: 0.0231  lr: 0.0014619  max_mem: 6588M
[12/10 22:56:29 d2.utils.events]:  eta: 0:46:01  iter: 639  total_loss: 3.347  loss_sem_seg: 1.668  loss_center: 0.5704  loss_offset: 0.983  time: 0.2965  data_time: 0.0264  lr: 0.0015062  max_mem: 6588M
[12/10 22:56:35 d2.utils.events]:  eta: 0:45:56  iter: 659  total_loss: 3.471  loss_sem_seg: 1.604  loss_center: 0.7405  loss_offset: 0.9997  time: 0.2966  data_time: 0.0281  lr: 0.0015503  max_mem: 6588M
[12/10 22:56:41 d2.utils.events]:  eta: 0:45:50  iter: 679  total_loss: 3.444  loss_sem_seg: 1.684  loss_center: 0.6734  loss_offset: 0.9117  time: 0.2966  data_time: 0.0247  lr: 0.0015942  max_mem: 6588M
[12/10 22:56:46 d2.utils.events]:  eta: 0:45:44  iter: 699  total_loss: 3.364  loss_sem_seg: 1.695  loss_center: 0.6706  loss_offset: 1.046  time: 0.2965  data_time: 0.0231  lr: 0.0016379  max_mem: 6588M
[12/10 22:56:52 d2.utils.events]:  eta: 0:45:38  iter: 719  total_loss: 3.336  loss_sem_seg: 1.768  loss_center: 0.5615  loss_offset: 1.016  time: 0.2966  data_time: 0.0260  lr: 0.0016814  max_mem: 6588M
[12/10 22:56:58 d2.utils.events]:  eta: 0:45:32  iter: 739  total_loss: 3.471  loss_sem_seg: 1.917  loss_center: 0.5796  loss_offset: 0.92  time: 0.2965  data_time: 0.0250  lr: 0.0017248  max_mem: 6588M
[12/10 22:57:04 d2.utils.events]:  eta: 0:45:26  iter: 759  total_loss: 3.329  loss_sem_seg: 1.71  loss_center: 0.5117  loss_offset: 0.8386  time: 0.2965  data_time: 0.0256  lr: 0.0017679  max_mem: 6588M
[12/10 22:57:10 d2.utils.events]:  eta: 0:45:20  iter: 779  total_loss: 3.295  loss_sem_seg: 1.624  loss_center: 0.6518  loss_offset: 0.8334  time: 0.2965  data_time: 0.0248  lr: 0.0018109  max_mem: 6588M
[12/10 22:57:16 d2.utils.events]:  eta: 0:45:14  iter: 799  total_loss: 3.276  loss_sem_seg: 1.719  loss_center: 0.7997  loss_offset: 0.818  time: 0.2965  data_time: 0.0246  lr: 0.0018537  max_mem: 6588M
[12/10 22:57:22 d2.utils.events]:  eta: 0:45:08  iter: 819  total_loss: 3.406  loss_sem_seg: 1.671  loss_center: 0.6395  loss_offset: 0.9176  time: 0.2965  data_time: 0.0253  lr: 0.0018964  max_mem: 6588M
[12/10 22:57:28 d2.utils.events]:  eta: 0:45:02  iter: 839  total_loss: 3.533  loss_sem_seg: 1.673  loss_center: 0.7954  loss_offset: 0.909  time: 0.2965  data_time: 0.0252  lr: 0.0019388  max_mem: 6588M
[12/10 22:57:34 d2.utils.events]:  eta: 0:44:57  iter: 859  total_loss: 3.686  loss_sem_seg: 1.952  loss_center: 0.6226  loss_offset: 1.013  time: 0.2966  data_time: 0.0245  lr: 0.0019811  max_mem: 6588M
[12/10 22:57:40 d2.utils.events]:  eta: 0:44:51  iter: 879  total_loss: 3.208  loss_sem_seg: 1.545  loss_center: 0.6121  loss_offset: 0.9288  time: 0.2967  data_time: 0.0256  lr: 0.0020231  max_mem: 6588M
[12/10 22:57:46 d2.utils.events]:  eta: 0:44:46  iter: 899  total_loss: 3.099  loss_sem_seg: 1.627  loss_center: 0.5191  loss_offset: 1.047  time: 0.2968  data_time: 0.0251  lr: 0.002065  max_mem: 6588M
[12/10 22:57:52 d2.utils.events]:  eta: 0:44:40  iter: 919  total_loss: 3.266  loss_sem_seg: 1.609  loss_center: 0.6527  loss_offset: 0.8713  time: 0.2968  data_time: 0.0249  lr: 0.0021068  max_mem: 6588M
[12/10 22:57:58 d2.utils.events]:  eta: 0:44:33  iter: 939  total_loss: 3.175  loss_sem_seg: 1.638  loss_center: 0.6028  loss_offset: 0.9803  time: 0.2967  data_time: 0.0242  lr: 0.0021483  max_mem: 6588M
[12/10 22:58:04 d2.utils.events]:  eta: 0:44:28  iter: 959  total_loss: 3.023  loss_sem_seg: 1.517  loss_center: 0.5885  loss_offset: 0.8519  time: 0.2968  data_time: 0.0264  lr: 0.0021896  max_mem: 6588M
[12/10 22:58:10 d2.utils.events]:  eta: 0:44:22  iter: 979  total_loss: 3.271  loss_sem_seg: 1.522  loss_center: 0.7257  loss_offset: 0.9482  time: 0.2968  data_time: 0.0257  lr: 0.0022308  max_mem: 6588M
[12/10 22:58:16 d2.utils.events]:  eta: 0:44:16  iter: 999  total_loss: 2.906  loss_sem_seg: 1.403  loss_center: 0.7233  loss_offset: 0.8576  time: 0.2968  data_time: 0.0277  lr: 0.0022718  max_mem: 6588M
[12/10 22:58:22 d2.utils.events]:  eta: 0:44:11  iter: 1019  total_loss: 3.186  loss_sem_seg: 1.508  loss_center: 0.6823  loss_offset: 0.892  time: 0.2968  data_time: 0.0240  lr: 0.0022695  max_mem: 6588M
[12/10 22:58:28 d2.utils.events]:  eta: 0:44:07  iter: 1039  total_loss: 3.165  loss_sem_seg: 1.598  loss_center: 0.6748  loss_offset: 0.834  time: 0.2969  data_time: 0.0269  lr: 0.002265  max_mem: 6588M
[12/10 22:58:34 d2.utils.events]:  eta: 0:44:01  iter: 1059  total_loss: 3.28  loss_sem_seg: 1.63  loss_center: 0.6434  loss_offset: 0.785  time: 0.2969  data_time: 0.0241  lr: 0.0022604  max_mem: 6588M
[12/10 22:58:40 d2.utils.events]:  eta: 0:43:56  iter: 1079  total_loss: 3.395  loss_sem_seg: 1.791  loss_center: 0.6849  loss_offset: 0.9131  time: 0.2969  data_time: 0.0258  lr: 0.0022559  max_mem: 6588M
[12/10 22:58:46 d2.utils.events]:  eta: 0:43:50  iter: 1099  total_loss: 3.218  loss_sem_seg: 1.661  loss_center: 0.6576  loss_offset: 0.9629  time: 0.2969  data_time: 0.0256  lr: 0.0022513  max_mem: 6588M
[12/10 22:58:52 d2.utils.events]:  eta: 0:43:46  iter: 1119  total_loss: 3.067  loss_sem_seg: 1.43  loss_center: 0.623  loss_offset: 0.9982  time: 0.2970  data_time: 0.0282  lr: 0.0022468  max_mem: 6588M
[12/10 22:58:58 d2.utils.events]:  eta: 0:43:39  iter: 1139  total_loss: 3.001  loss_sem_seg: 1.563  loss_center: 0.5309  loss_offset: 0.8876  time: 0.2970  data_time: 0.0252  lr: 0.0022422  max_mem: 6588M
[12/10 22:59:04 d2.utils.events]:  eta: 0:43:34  iter: 1159  total_loss: 2.83  loss_sem_seg: 1.356  loss_center: 0.4972  loss_offset: 0.7748  time: 0.2970  data_time: 0.0257  lr: 0.0022376  max_mem: 6588M
[12/10 22:59:10 d2.utils.events]:  eta: 0:43:28  iter: 1179  total_loss: 2.87  loss_sem_seg: 1.305  loss_center: 0.6306  loss_offset: 0.796  time: 0.2970  data_time: 0.0262  lr: 0.0022331  max_mem: 6588M
[12/10 22:59:15 d2.utils.events]:  eta: 0:43:23  iter: 1199  total_loss: 3.082  loss_sem_seg: 1.491  loss_center: 0.5677  loss_offset: 0.8553  time: 0.2970  data_time: 0.0254  lr: 0.0022285  max_mem: 6588M
[12/10 22:59:21 d2.utils.events]:  eta: 0:43:17  iter: 1219  total_loss: 3.429  loss_sem_seg: 1.74  loss_center: 0.624  loss_offset: 0.9567  time: 0.2970  data_time: 0.0251  lr: 0.002224  max_mem: 6588M
[12/10 22:59:27 d2.utils.events]:  eta: 0:43:13  iter: 1239  total_loss: 2.762  loss_sem_seg: 1.39  loss_center: 0.5768  loss_offset: 0.8344  time: 0.2970  data_time: 0.0267  lr: 0.0022194  max_mem: 6588M
[12/10 22:59:33 d2.utils.events]:  eta: 0:43:07  iter: 1259  total_loss: 2.856  loss_sem_seg: 1.26  loss_center: 0.6253  loss_offset: 0.9434  time: 0.2970  data_time: 0.0240  lr: 0.0022149  max_mem: 6588M
[12/10 22:59:39 d2.utils.events]:  eta: 0:43:03  iter: 1279  total_loss: 2.798  loss_sem_seg: 1.358  loss_center: 0.6521  loss_offset: 0.8691  time: 0.2970  data_time: 0.0256  lr: 0.0022103  max_mem: 6588M
[12/10 22:59:45 d2.utils.events]:  eta: 0:42:58  iter: 1299  total_loss: 2.897  loss_sem_seg: 1.301  loss_center: 0.6141  loss_offset: 0.9189  time: 0.2970  data_time: 0.0254  lr: 0.0022057  max_mem: 6588M
[12/10 22:59:51 d2.utils.events]:  eta: 0:42:52  iter: 1319  total_loss: 2.859  loss_sem_seg: 1.411  loss_center: 0.5486  loss_offset: 0.8613  time: 0.2970  data_time: 0.0262  lr: 0.0022012  max_mem: 6588M
[12/10 22:59:57 d2.utils.events]:  eta: 0:42:46  iter: 1339  total_loss: 3.037  loss_sem_seg: 1.436  loss_center: 0.635  loss_offset: 0.8569  time: 0.2970  data_time: 0.0241  lr: 0.0021966  max_mem: 6588M
[12/10 23:00:03 d2.utils.events]:  eta: 0:42:40  iter: 1359  total_loss: 2.745  loss_sem_seg: 1.24  loss_center: 0.687  loss_offset: 0.816  time: 0.2971  data_time: 0.0272  lr: 0.002192  max_mem: 6588M
[12/10 23:00:09 d2.utils.events]:  eta: 0:42:35  iter: 1379  total_loss: 2.86  loss_sem_seg: 1.282  loss_center: 0.6829  loss_offset: 0.774  time: 0.2971  data_time: 0.0250  lr: 0.0021875  max_mem: 6588M
[12/10 23:00:15 d2.utils.events]:  eta: 0:42:30  iter: 1399  total_loss: 2.911  loss_sem_seg: 1.381  loss_center: 0.5238  loss_offset: 0.9428  time: 0.2971  data_time: 0.0265  lr: 0.0021829  max_mem: 6588M
[12/10 23:00:21 d2.utils.events]:  eta: 0:42:25  iter: 1419  total_loss: 2.657  loss_sem_seg: 1.413  loss_center: 0.5451  loss_offset: 0.7571  time: 0.2970  data_time: 0.0252  lr: 0.0021783  max_mem: 6588M
[12/10 23:00:27 d2.utils.events]:  eta: 0:42:19  iter: 1439  total_loss: 2.675  loss_sem_seg: 1.304  loss_center: 0.6619  loss_offset: 0.8218  time: 0.2970  data_time: 0.0245  lr: 0.0021738  max_mem: 6588M
[12/10 23:00:33 d2.utils.events]:  eta: 0:42:13  iter: 1459  total_loss: 3.115  loss_sem_seg: 1.519  loss_center: 0.6284  loss_offset: 0.9438  time: 0.2970  data_time: 0.0255  lr: 0.0021692  max_mem: 6588M
[12/10 23:00:39 d2.utils.events]:  eta: 0:42:07  iter: 1479  total_loss: 2.658  loss_sem_seg: 1.204  loss_center: 0.5901  loss_offset: 0.8053  time: 0.2970  data_time: 0.0246  lr: 0.0021646  max_mem: 6588M
[12/10 23:00:45 d2.utils.events]:  eta: 0:42:02  iter: 1499  total_loss: 2.925  loss_sem_seg: 1.227  loss_center: 0.6234  loss_offset: 0.8418  time: 0.2970  data_time: 0.0265  lr: 0.00216  max_mem: 6588M
[12/10 23:00:51 d2.utils.events]:  eta: 0:41:56  iter: 1519  total_loss: 2.801  loss_sem_seg: 1.39  loss_center: 0.5778  loss_offset: 0.8389  time: 0.2970  data_time: 0.0239  lr: 0.0021555  max_mem: 6588M
[12/10 23:00:56 d2.utils.events]:  eta: 0:41:49  iter: 1539  total_loss: 3.041  loss_sem_seg: 1.401  loss_center: 0.6326  loss_offset: 0.8732  time: 0.2969  data_time: 0.0250  lr: 0.0021509  max_mem: 6588M
[12/10 23:01:02 d2.utils.events]:  eta: 0:41:42  iter: 1559  total_loss: 2.835  loss_sem_seg: 1.275  loss_center: 0.5434  loss_offset: 0.921  time: 0.2969  data_time: 0.0246  lr: 0.0021463  max_mem: 6588M
[12/10 23:01:08 d2.utils.events]:  eta: 0:41:35  iter: 1579  total_loss: 2.771  loss_sem_seg: 1.245  loss_center: 0.6252  loss_offset: 0.745  time: 0.2970  data_time: 0.0266  lr: 0.0021417  max_mem: 6588M
[12/10 23:01:14 d2.utils.events]:  eta: 0:41:31  iter: 1599  total_loss: 2.842  loss_sem_seg: 1.201  loss_center: 0.6893  loss_offset: 0.8469  time: 0.2970  data_time: 0.0241  lr: 0.0021372  max_mem: 6588M
[12/10 23:01:20 d2.utils.events]:  eta: 0:41:26  iter: 1619  total_loss: 2.536  loss_sem_seg: 1.177  loss_center: 0.6773  loss_offset: 0.7246  time: 0.2970  data_time: 0.0260  lr: 0.0021326  max_mem: 6588M
[12/10 23:01:26 d2.utils.events]:  eta: 0:41:20  iter: 1639  total_loss: 2.826  loss_sem_seg: 1.377  loss_center: 0.5552  loss_offset: 0.8124  time: 0.2970  data_time: 0.0256  lr: 0.002128  max_mem: 6588M
[12/10 23:01:32 d2.utils.events]:  eta: 0:41:14  iter: 1659  total_loss: 2.675  loss_sem_seg: 1.314  loss_center: 0.5916  loss_offset: 0.8754  time: 0.2970  data_time: 0.0258  lr: 0.0021234  max_mem: 6588M
[12/10 23:01:38 d2.utils.events]:  eta: 0:41:08  iter: 1679  total_loss: 2.962  loss_sem_seg: 1.472  loss_center: 0.5055  loss_offset: 0.8562  time: 0.2970  data_time: 0.0269  lr: 0.0021188  max_mem: 6588M
[12/10 23:01:44 d2.utils.events]:  eta: 0:41:03  iter: 1699  total_loss: 2.87  loss_sem_seg: 1.422  loss_center: 0.6277  loss_offset: 0.8957  time: 0.2970  data_time: 0.0249  lr: 0.0021143  max_mem: 6588M
[12/10 23:01:50 d2.utils.events]:  eta: 0:40:57  iter: 1719  total_loss: 2.975  loss_sem_seg: 1.405  loss_center: 0.6236  loss_offset: 0.8795  time: 0.2969  data_time: 0.0234  lr: 0.0021097  max_mem: 6588M
[12/10 23:01:56 d2.utils.events]:  eta: 0:40:51  iter: 1739  total_loss: 2.703  loss_sem_seg: 1.211  loss_center: 0.6465  loss_offset: 0.7809  time: 0.2969  data_time: 0.0248  lr: 0.0021051  max_mem: 6588M
[12/10 23:02:02 d2.utils.events]:  eta: 0:40:46  iter: 1759  total_loss: 2.63  loss_sem_seg: 1.162  loss_center: 0.6617  loss_offset: 0.8841  time: 0.2969  data_time: 0.0258  lr: 0.0021005  max_mem: 6588M
[12/10 23:02:08 d2.utils.events]:  eta: 0:40:41  iter: 1779  total_loss: 2.907  loss_sem_seg: 1.254  loss_center: 0.6733  loss_offset: 0.8334  time: 0.2969  data_time: 0.0266  lr: 0.0020959  max_mem: 6588M
[12/10 23:02:14 d2.utils.events]:  eta: 0:40:35  iter: 1799  total_loss: 2.582  loss_sem_seg: 1.192  loss_center: 0.6009  loss_offset: 0.7905  time: 0.2969  data_time: 0.0238  lr: 0.0020913  max_mem: 6588M
[12/10 23:02:20 d2.utils.events]:  eta: 0:40:29  iter: 1819  total_loss: 2.836  loss_sem_seg: 1.27  loss_center: 0.6888  loss_offset: 0.8382  time: 0.2969  data_time: 0.0260  lr: 0.0020867  max_mem: 6588M
[12/10 23:02:26 d2.utils.events]:  eta: 0:40:21  iter: 1839  total_loss: 2.683  loss_sem_seg: 1.239  loss_center: 0.5726  loss_offset: 0.8004  time: 0.2969  data_time: 0.0251  lr: 0.0020821  max_mem: 6588M
[12/10 23:02:32 d2.utils.events]:  eta: 0:40:16  iter: 1859  total_loss: 2.978  loss_sem_seg: 1.37  loss_center: 0.5169  loss_offset: 0.9927  time: 0.2970  data_time: 0.0281  lr: 0.0020775  max_mem: 6588M
[12/10 23:02:38 d2.utils.events]:  eta: 0:40:10  iter: 1879  total_loss: 2.633  loss_sem_seg: 1.302  loss_center: 0.6153  loss_offset: 0.8136  time: 0.2970  data_time: 0.0246  lr: 0.0020729  max_mem: 6588M
[12/10 23:02:44 d2.utils.events]:  eta: 0:40:04  iter: 1899  total_loss: 3.027  loss_sem_seg: 1.329  loss_center: 0.724  loss_offset: 0.8413  time: 0.2970  data_time: 0.0257  lr: 0.0020684  max_mem: 6588M
[12/10 23:02:50 d2.utils.events]:  eta: 0:40:00  iter: 1919  total_loss: 2.916  loss_sem_seg: 1.352  loss_center: 0.6679  loss_offset: 0.8272  time: 0.2970  data_time: 0.0274  lr: 0.0020638  max_mem: 6588M
[12/10 23:02:56 d2.utils.events]:  eta: 0:39:54  iter: 1939  total_loss: 2.652  loss_sem_seg: 1.195  loss_center: 0.6271  loss_offset: 0.7437  time: 0.2970  data_time: 0.0252  lr: 0.0020592  max_mem: 6588M
[12/10 23:03:01 d2.utils.events]:  eta: 0:39:47  iter: 1959  total_loss: 2.574  loss_sem_seg: 1.142  loss_center: 0.6521  loss_offset: 0.7535  time: 0.2970  data_time: 0.0243  lr: 0.0020546  max_mem: 6588M
[12/10 23:03:07 d2.utils.events]:  eta: 0:39:42  iter: 1979  total_loss: 2.594  loss_sem_seg: 1.192  loss_center: 0.5146  loss_offset: 0.8355  time: 0.2970  data_time: 0.0267  lr: 0.00205  max_mem: 6588M
[12/10 23:03:13 d2.utils.events]:  eta: 0:39:35  iter: 1999  total_loss: 2.558  loss_sem_seg: 1.077  loss_center: 0.5387  loss_offset: 0.8259  time: 0.2970  data_time: 0.0241  lr: 0.0020454  max_mem: 6588M
[12/10 23:03:19 d2.utils.events]:  eta: 0:39:29  iter: 2019  total_loss: 2.599  loss_sem_seg: 1.08  loss_center: 0.6657  loss_offset: 0.9364  time: 0.2970  data_time: 0.0275  lr: 0.0020408  max_mem: 6588M
[12/10 23:03:25 d2.utils.events]:  eta: 0:39:22  iter: 2039  total_loss: 2.554  loss_sem_seg: 1.158  loss_center: 0.5574  loss_offset: 0.8085  time: 0.2971  data_time: 0.0268  lr: 0.0020362  max_mem: 6588M
[12/10 23:03:31 d2.utils.events]:  eta: 0:39:16  iter: 2059  total_loss: 2.54  loss_sem_seg: 1.018  loss_center: 0.5903  loss_offset: 0.7533  time: 0.2971  data_time: 0.0256  lr: 0.0020316  max_mem: 6588M
[12/10 23:03:37 d2.utils.events]:  eta: 0:39:10  iter: 2079  total_loss: 2.667  loss_sem_seg: 1.247  loss_center: 0.6278  loss_offset: 0.7616  time: 0.2971  data_time: 0.0257  lr: 0.0020269  max_mem: 6588M
[12/10 23:03:43 d2.utils.events]:  eta: 0:39:04  iter: 2099  total_loss: 2.662  loss_sem_seg: 1.133  loss_center: 0.6368  loss_offset: 0.8007  time: 0.2971  data_time: 0.0254  lr: 0.0020223  max_mem: 6588M
[12/10 23:03:49 d2.utils.events]:  eta: 0:38:58  iter: 2119  total_loss: 2.548  loss_sem_seg: 1.099  loss_center: 0.6792  loss_offset: 0.8065  time: 0.2971  data_time: 0.0264  lr: 0.0020177  max_mem: 6588M
[12/10 23:03:55 d2.utils.events]:  eta: 0:38:52  iter: 2139  total_loss: 2.631  loss_sem_seg: 1.05  loss_center: 0.6423  loss_offset: 0.7618  time: 0.2971  data_time: 0.0244  lr: 0.0020131  max_mem: 6588M
[12/10 23:04:01 d2.utils.events]:  eta: 0:38:45  iter: 2159  total_loss: 2.694  loss_sem_seg: 1.222  loss_center: 0.6864  loss_offset: 0.8524  time: 0.2971  data_time: 0.0252  lr: 0.0020085  max_mem: 6588M
[12/10 23:04:07 d2.utils.events]:  eta: 0:38:38  iter: 2179  total_loss: 2.769  loss_sem_seg: 1.225  loss_center: 0.6614  loss_offset: 0.8449  time: 0.2970  data_time: 0.0248  lr: 0.0020039  max_mem: 6588M
[12/10 23:04:13 d2.utils.events]:  eta: 0:38:32  iter: 2199  total_loss: 2.692  loss_sem_seg: 1.207  loss_center: 0.5807  loss_offset: 0.7978  time: 0.2970  data_time: 0.0254  lr: 0.0019993  max_mem: 6588M
[12/10 23:04:19 d2.utils.events]:  eta: 0:38:26  iter: 2219  total_loss: 2.589  loss_sem_seg: 1.232  loss_center: 0.6064  loss_offset: 0.882  time: 0.2970  data_time: 0.0267  lr: 0.0019947  max_mem: 6588M
[12/10 23:04:25 d2.utils.events]:  eta: 0:38:19  iter: 2239  total_loss: 2.593  loss_sem_seg: 1.08  loss_center: 0.5873  loss_offset: 0.78  time: 0.2970  data_time: 0.0244  lr: 0.0019901  max_mem: 6588M
[12/10 23:04:31 d2.utils.events]:  eta: 0:38:14  iter: 2259  total_loss: 2.809  loss_sem_seg: 1.049  loss_center: 0.6733  loss_offset: 0.8044  time: 0.2970  data_time: 0.0259  lr: 0.0019854  max_mem: 6588M
[12/10 23:04:37 d2.utils.events]:  eta: 0:38:08  iter: 2279  total_loss: 2.703  loss_sem_seg: 1.055  loss_center: 0.6059  loss_offset: 0.7755  time: 0.2970  data_time: 0.0270  lr: 0.0019808  max_mem: 6588M
[12/10 23:04:43 d2.utils.events]:  eta: 0:38:02  iter: 2299  total_loss: 2.832  loss_sem_seg: 1.354  loss_center: 0.6864  loss_offset: 0.7472  time: 0.2970  data_time: 0.0247  lr: 0.0019762  max_mem: 6588M
[12/10 23:04:49 d2.utils.events]:  eta: 0:37:56  iter: 2319  total_loss: 2.64  loss_sem_seg: 1.427  loss_center: 0.5085  loss_offset: 0.7735  time: 0.2970  data_time: 0.0258  lr: 0.0019716  max_mem: 6588M
[12/10 23:04:55 d2.utils.events]:  eta: 0:37:49  iter: 2339  total_loss: 2.633  loss_sem_seg: 1.192  loss_center: 0.5326  loss_offset: 0.782  time: 0.2970  data_time: 0.0245  lr: 0.001967  max_mem: 6588M
[12/10 23:05:00 d2.utils.events]:  eta: 0:37:42  iter: 2359  total_loss: 2.654  loss_sem_seg: 1.277  loss_center: 0.6125  loss_offset: 0.8089  time: 0.2970  data_time: 0.0243  lr: 0.0019623  max_mem: 6588M
[12/10 23:05:06 d2.utils.events]:  eta: 0:37:36  iter: 2379  total_loss: 2.657  loss_sem_seg: 1.216  loss_center: 0.5394  loss_offset: 0.8042  time: 0.2970  data_time: 0.0263  lr: 0.0019577  max_mem: 6588M
[12/10 23:05:12 d2.utils.events]:  eta: 0:37:31  iter: 2399  total_loss: 2.603  loss_sem_seg: 1.127  loss_center: 0.6192  loss_offset: 0.7497  time: 0.2970  data_time: 0.0259  lr: 0.0019531  max_mem: 6588M
[12/10 23:05:18 d2.utils.events]:  eta: 0:37:25  iter: 2419  total_loss: 2.669  loss_sem_seg: 1.182  loss_center: 0.618  loss_offset: 0.8873  time: 0.2970  data_time: 0.0250  lr: 0.0019485  max_mem: 6588M
[12/10 23:05:24 d2.utils.events]:  eta: 0:37:19  iter: 2439  total_loss: 2.588  loss_sem_seg: 1.208  loss_center: 0.5886  loss_offset: 0.7417  time: 0.2970  data_time: 0.0250  lr: 0.0019438  max_mem: 6588M
[12/10 23:05:30 d2.utils.events]:  eta: 0:37:13  iter: 2459  total_loss: 2.88  loss_sem_seg: 1.259  loss_center: 0.5961  loss_offset: 0.7822  time: 0.2970  data_time: 0.0254  lr: 0.0019392  max_mem: 6588M
[12/10 23:05:36 d2.utils.events]:  eta: 0:37:08  iter: 2479  total_loss: 2.556  loss_sem_seg: 1.16  loss_center: 0.5791  loss_offset: 0.7947  time: 0.2970  data_time: 0.0268  lr: 0.0019346  max_mem: 6588M
[12/10 23:05:42 d2.utils.events]:  eta: 0:37:01  iter: 2499  total_loss: 2.605  loss_sem_seg: 1.274  loss_center: 0.5611  loss_offset: 0.7021  time: 0.2970  data_time: 0.0252  lr: 0.00193  max_mem: 6588M
[12/10 23:05:48 d2.utils.events]:  eta: 0:36:55  iter: 2519  total_loss: 2.99  loss_sem_seg: 1.279  loss_center: 0.7031  loss_offset: 0.8438  time: 0.2970  data_time: 0.0247  lr: 0.0019253  max_mem: 6588M
[12/10 23:05:54 d2.utils.events]:  eta: 0:36:49  iter: 2539  total_loss: 2.697  loss_sem_seg: 1.225  loss_center: 0.6694  loss_offset: 0.7365  time: 0.2970  data_time: 0.0242  lr: 0.0019207  max_mem: 6588M
[12/10 23:06:00 d2.utils.events]:  eta: 0:36:44  iter: 2559  total_loss: 2.366  loss_sem_seg: 1.016  loss_center: 0.4903  loss_offset: 0.7346  time: 0.2970  data_time: 0.0268  lr: 0.0019161  max_mem: 6588M
[12/10 23:06:06 d2.utils.events]:  eta: 0:36:37  iter: 2579  total_loss: 2.718  loss_sem_seg: 1.085  loss_center: 0.6797  loss_offset: 0.7775  time: 0.2970  data_time: 0.0248  lr: 0.0019114  max_mem: 6588M
[12/10 23:06:12 d2.utils.events]:  eta: 0:36:30  iter: 2599  total_loss: 2.526  loss_sem_seg: 1.063  loss_center: 0.6065  loss_offset: 0.6697  time: 0.2970  data_time: 0.0251  lr: 0.0019068  max_mem: 6588M
[12/10 23:06:18 d2.utils.events]:  eta: 0:36:24  iter: 2619  total_loss: 2.682  loss_sem_seg: 1.149  loss_center: 0.6102  loss_offset: 0.7656  time: 0.2970  data_time: 0.0245  lr: 0.0019021  max_mem: 6588M
[12/10 23:06:24 d2.utils.events]:  eta: 0:36:18  iter: 2639  total_loss: 2.818  loss_sem_seg: 1.183  loss_center: 0.5543  loss_offset: 0.7937  time: 0.2970  data_time: 0.0268  lr: 0.0018975  max_mem: 6588M
[12/10 23:06:30 d2.utils.events]:  eta: 0:36:12  iter: 2659  total_loss: 2.586  loss_sem_seg: 1.193  loss_center: 0.4292  loss_offset: 0.8088  time: 0.2970  data_time: 0.0238  lr: 0.0018929  max_mem: 6588M
[12/10 23:06:36 d2.utils.events]:  eta: 0:36:06  iter: 2679  total_loss: 2.572  loss_sem_seg: 1.043  loss_center: 0.5607  loss_offset: 0.7251  time: 0.2970  data_time: 0.0258  lr: 0.0018882  max_mem: 6588M
[12/10 23:06:41 d2.utils.events]:  eta: 0:35:59  iter: 2699  total_loss: 2.487  loss_sem_seg: 1.265  loss_center: 0.663  loss_offset: 0.7006  time: 0.2970  data_time: 0.0263  lr: 0.0018836  max_mem: 6588M
[12/10 23:06:47 d2.utils.events]:  eta: 0:35:53  iter: 2719  total_loss: 2.466  loss_sem_seg: 1.156  loss_center: 0.5483  loss_offset: 0.7162  time: 0.2970  data_time: 0.0256  lr: 0.0018789  max_mem: 6588M
[12/10 23:06:53 d2.utils.events]:  eta: 0:35:48  iter: 2739  total_loss: 2.465  loss_sem_seg: 0.9749  loss_center: 0.5625  loss_offset: 0.7867  time: 0.2970  data_time: 0.0251  lr: 0.0018743  max_mem: 6588M
[12/10 23:06:59 d2.utils.events]:  eta: 0:35:42  iter: 2759  total_loss: 2.631  loss_sem_seg: 1.293  loss_center: 0.666  loss_offset: 0.8008  time: 0.2970  data_time: 0.0279  lr: 0.0018696  max_mem: 6588M
[12/10 23:07:05 d2.utils.events]:  eta: 0:35:36  iter: 2779  total_loss: 2.396  loss_sem_seg: 0.9979  loss_center: 0.6109  loss_offset: 0.7503  time: 0.2970  data_time: 0.0236  lr: 0.001865  max_mem: 6588M
[12/10 23:07:11 d2.utils.events]:  eta: 0:35:32  iter: 2799  total_loss: 2.814  loss_sem_seg: 1.211  loss_center: 0.5413  loss_offset: 0.7837  time: 0.2970  data_time: 0.0262  lr: 0.0018603  max_mem: 6588M
[12/10 23:07:17 d2.utils.events]:  eta: 0:35:24  iter: 2819  total_loss: 2.505  loss_sem_seg: 1.138  loss_center: 0.5495  loss_offset: 0.7009  time: 0.2970  data_time: 0.0252  lr: 0.0018557  max_mem: 6588M
[12/10 23:07:23 d2.utils.events]:  eta: 0:35:18  iter: 2839  total_loss: 2.582  loss_sem_seg: 1.111  loss_center: 0.4952  loss_offset: 0.7765  time: 0.2970  data_time: 0.0264  lr: 0.001851  max_mem: 6588M
[12/10 23:07:29 d2.utils.events]:  eta: 0:35:12  iter: 2859  total_loss: 2.717  loss_sem_seg: 1.154  loss_center: 0.5568  loss_offset: 0.8026  time: 0.2970  data_time: 0.0261  lr: 0.0018464  max_mem: 6588M
[12/10 23:07:35 d2.utils.events]:  eta: 0:35:06  iter: 2879  total_loss: 2.527  loss_sem_seg: 1.177  loss_center: 0.5979  loss_offset: 0.7545  time: 0.2970  data_time: 0.0254  lr: 0.0018417  max_mem: 6588M
[12/10 23:07:41 d2.utils.events]:  eta: 0:35:00  iter: 2899  total_loss: 2.428  loss_sem_seg: 1.056  loss_center: 0.5782  loss_offset: 0.7395  time: 0.2970  data_time: 0.0257  lr: 0.0018371  max_mem: 6588M
[12/10 23:07:47 d2.utils.events]:  eta: 0:34:53  iter: 2919  total_loss: 2.553  loss_sem_seg: 1.143  loss_center: 0.5948  loss_offset: 0.7417  time: 0.2970  data_time: 0.0248  lr: 0.0018324  max_mem: 6588M
[12/10 23:07:53 d2.utils.events]:  eta: 0:34:47  iter: 2939  total_loss: 2.36  loss_sem_seg: 0.9389  loss_center: 0.5516  loss_offset: 0.7664  time: 0.2970  data_time: 0.0246  lr: 0.0018278  max_mem: 6588M
[12/10 23:07:59 d2.utils.events]:  eta: 0:34:41  iter: 2959  total_loss: 2.5  loss_sem_seg: 1.062  loss_center: 0.4857  loss_offset: 0.9009  time: 0.2970  data_time: 0.0259  lr: 0.0018231  max_mem: 6588M
[12/10 23:08:05 d2.utils.events]:  eta: 0:34:35  iter: 2979  total_loss: 2.509  loss_sem_seg: 1.185  loss_center: 0.5523  loss_offset: 0.6787  time: 0.2970  data_time: 0.0251  lr: 0.0018184  max_mem: 6588M
[12/10 23:08:11 d2.utils.events]:  eta: 0:34:30  iter: 2999  total_loss: 2.497  loss_sem_seg: 1.099  loss_center: 0.5643  loss_offset: 0.7976  time: 0.2970  data_time: 0.0265  lr: 0.0018138  max_mem: 6588M
[12/10 23:08:17 d2.utils.events]:  eta: 0:34:23  iter: 3019  total_loss: 2.508  loss_sem_seg: 1.211  loss_center: 0.6279  loss_offset: 0.7231  time: 0.2970  data_time: 0.0263  lr: 0.0018091  max_mem: 6588M
[12/10 23:08:23 d2.utils.events]:  eta: 0:34:17  iter: 3039  total_loss: 2.412  loss_sem_seg: 1.043  loss_center: 0.5351  loss_offset: 0.7712  time: 0.2969  data_time: 0.0238  lr: 0.0018044  max_mem: 6588M
[12/10 23:08:28 d2.utils.events]:  eta: 0:34:11  iter: 3059  total_loss: 2.705  loss_sem_seg: 1.256  loss_center: 0.6313  loss_offset: 0.7673  time: 0.2969  data_time: 0.0245  lr: 0.0017998  max_mem: 6588M
[12/10 23:08:35 d2.utils.events]:  eta: 0:34:05  iter: 3079  total_loss: 2.961  loss_sem_seg: 1.439  loss_center: 0.5405  loss_offset: 0.846  time: 0.2970  data_time: 0.0265  lr: 0.0017951  max_mem: 6588M
[12/10 23:08:40 d2.utils.events]:  eta: 0:33:59  iter: 3099  total_loss: 2.401  loss_sem_seg: 0.9665  loss_center: 0.6298  loss_offset: 0.7606  time: 0.2970  data_time: 0.0259  lr: 0.0017904  max_mem: 6588M
[12/10 23:08:46 d2.utils.events]:  eta: 0:33:53  iter: 3119  total_loss: 2.699  loss_sem_seg: 1.206  loss_center: 0.5306  loss_offset: 0.7851  time: 0.2970  data_time: 0.0253  lr: 0.0017858  max_mem: 6588M
[12/10 23:08:52 d2.utils.events]:  eta: 0:33:47  iter: 3139  total_loss: 2.421  loss_sem_seg: 0.9912  loss_center: 0.5726  loss_offset: 0.7081  time: 0.2970  data_time: 0.0243  lr: 0.0017811  max_mem: 6588M
[12/10 23:08:58 d2.utils.events]:  eta: 0:33:41  iter: 3159  total_loss: 2.561  loss_sem_seg: 1.067  loss_center: 0.5532  loss_offset: 0.6429  time: 0.2969  data_time: 0.0258  lr: 0.0017764  max_mem: 6588M
[12/10 23:09:04 d2.utils.events]:  eta: 0:33:36  iter: 3179  total_loss: 2.482  loss_sem_seg: 1.055  loss_center: 0.707  loss_offset: 0.7473  time: 0.2969  data_time: 0.0255  lr: 0.0017718  max_mem: 6588M
[12/10 23:09:10 d2.utils.events]:  eta: 0:33:30  iter: 3199  total_loss: 2.585  loss_sem_seg: 0.9798  loss_center: 0.6618  loss_offset: 0.7869  time: 0.2969  data_time: 0.0246  lr: 0.0017671  max_mem: 6588M
[12/10 23:09:16 d2.utils.events]:  eta: 0:33:24  iter: 3219  total_loss: 2.555  loss_sem_seg: 1.159  loss_center: 0.5419  loss_offset: 0.7387  time: 0.2969  data_time: 0.0242  lr: 0.0017624  max_mem: 6588M
[12/10 23:09:22 d2.utils.events]:  eta: 0:33:18  iter: 3239  total_loss: 2.65  loss_sem_seg: 1.186  loss_center: 0.6092  loss_offset: 0.7522  time: 0.2969  data_time: 0.0254  lr: 0.0017577  max_mem: 6588M
[12/10 23:09:28 d2.utils.events]:  eta: 0:33:12  iter: 3259  total_loss: 2.393  loss_sem_seg: 1.272  loss_center: 0.5005  loss_offset: 0.6725  time: 0.2970  data_time: 0.0258  lr: 0.001753  max_mem: 6588M
[12/10 23:09:34 d2.utils.events]:  eta: 0:33:06  iter: 3279  total_loss: 2.466  loss_sem_seg: 1.186  loss_center: 0.551  loss_offset: 0.6769  time: 0.2970  data_time: 0.0254  lr: 0.0017484  max_mem: 6588M
[12/10 23:09:40 d2.utils.events]:  eta: 0:33:00  iter: 3299  total_loss: 2.547  loss_sem_seg: 1.062  loss_center: 0.5249  loss_offset: 0.689  time: 0.2970  data_time: 0.0255  lr: 0.0017437  max_mem: 6588M
[12/10 23:09:46 d2.utils.events]:  eta: 0:32:55  iter: 3319  total_loss: 2.22  loss_sem_seg: 1.001  loss_center: 0.4739  loss_offset: 0.7484  time: 0.2970  data_time: 0.0271  lr: 0.001739  max_mem: 6588M
[12/10 23:09:52 d2.utils.events]:  eta: 0:32:49  iter: 3339  total_loss: 2.317  loss_sem_seg: 0.9613  loss_center: 0.5303  loss_offset: 0.8117  time: 0.2970  data_time: 0.0236  lr: 0.0017343  max_mem: 6588M
[12/10 23:09:58 d2.utils.events]:  eta: 0:32:44  iter: 3359  total_loss: 2.484  loss_sem_seg: 1.008  loss_center: 0.601  loss_offset: 0.7363  time: 0.2970  data_time: 0.0276  lr: 0.0017296  max_mem: 6588M
[12/10 23:10:04 d2.utils.events]:  eta: 0:32:37  iter: 3379  total_loss: 2.423  loss_sem_seg: 1.052  loss_center: 0.5469  loss_offset: 0.6526  time: 0.2970  data_time: 0.0257  lr: 0.0017249  max_mem: 6588M
[12/10 23:10:10 d2.utils.events]:  eta: 0:32:31  iter: 3399  total_loss: 2.339  loss_sem_seg: 1.028  loss_center: 0.4834  loss_offset: 0.6698  time: 0.2970  data_time: 0.0261  lr: 0.0017202  max_mem: 6588M
[12/10 23:10:16 d2.utils.events]:  eta: 0:32:25  iter: 3419  total_loss: 2.649  loss_sem_seg: 1.184  loss_center: 0.5449  loss_offset: 0.7748  time: 0.2970  data_time: 0.0257  lr: 0.0017155  max_mem: 6588M
[12/10 23:10:22 d2.utils.events]:  eta: 0:32:19  iter: 3439  total_loss: 2.35  loss_sem_seg: 0.9264  loss_center: 0.5558  loss_offset: 0.693  time: 0.2970  data_time: 0.0254  lr: 0.0017109  max_mem: 6588M
[12/10 23:10:28 d2.utils.events]:  eta: 0:32:13  iter: 3459  total_loss: 2.408  loss_sem_seg: 0.9638  loss_center: 0.6948  loss_offset: 0.7749  time: 0.2970  data_time: 0.0254  lr: 0.0017062  max_mem: 6588M
[12/10 23:10:34 d2.utils.events]:  eta: 0:32:08  iter: 3479  total_loss: 2.295  loss_sem_seg: 1.071  loss_center: 0.5782  loss_offset: 0.7567  time: 0.2970  data_time: 0.0250  lr: 0.0017015  max_mem: 6588M
[12/10 23:10:39 d2.utils.events]:  eta: 0:32:02  iter: 3499  total_loss: 2.5  loss_sem_seg: 1.058  loss_center: 0.5331  loss_offset: 0.7831  time: 0.2970  data_time: 0.0249  lr: 0.0016968  max_mem: 6588M
[12/10 23:10:45 d2.utils.events]:  eta: 0:31:56  iter: 3519  total_loss: 2.359  loss_sem_seg: 1.218  loss_center: 0.4427  loss_offset: 0.7248  time: 0.2970  data_time: 0.0261  lr: 0.0016921  max_mem: 6588M
[12/10 23:10:51 d2.utils.events]:  eta: 0:31:51  iter: 3539  total_loss: 2.552  loss_sem_seg: 1.092  loss_center: 0.5489  loss_offset: 0.7875  time: 0.2970  data_time: 0.0255  lr: 0.0016874  max_mem: 6588M
[12/10 23:10:57 d2.utils.events]:  eta: 0:31:44  iter: 3559  total_loss: 2.468  loss_sem_seg: 1.017  loss_center: 0.7066  loss_offset: 0.8401  time: 0.2970  data_time: 0.0257  lr: 0.0016827  max_mem: 6588M
[12/10 23:11:03 d2.utils.events]:  eta: 0:31:38  iter: 3579  total_loss: 2.404  loss_sem_seg: 1.002  loss_center: 0.6226  loss_offset: 0.6874  time: 0.2970  data_time: 0.0247  lr: 0.001678  max_mem: 6588M
[12/10 23:11:09 d2.utils.events]:  eta: 0:31:32  iter: 3599  total_loss: 2.711  loss_sem_seg: 1.261  loss_center: 0.5611  loss_offset: 0.7804  time: 0.2970  data_time: 0.0245  lr: 0.0016733  max_mem: 6588M
[12/10 23:11:15 d2.utils.events]:  eta: 0:31:25  iter: 3619  total_loss: 2.698  loss_sem_seg: 1.135  loss_center: 0.6858  loss_offset: 0.7556  time: 0.2969  data_time: 0.0249  lr: 0.0016686  max_mem: 6588M
[12/10 23:11:21 d2.utils.events]:  eta: 0:31:19  iter: 3639  total_loss: 2.451  loss_sem_seg: 1  loss_center: 0.5662  loss_offset: 0.7348  time: 0.2969  data_time: 0.0249  lr: 0.0016638  max_mem: 6588M
[12/10 23:11:27 d2.utils.events]:  eta: 0:31:13  iter: 3659  total_loss: 2.599  loss_sem_seg: 1.021  loss_center: 0.6016  loss_offset: 0.7614  time: 0.2969  data_time: 0.0252  lr: 0.0016591  max_mem: 6588M
[12/10 23:11:33 d2.utils.events]:  eta: 0:31:07  iter: 3679  total_loss: 2.455  loss_sem_seg: 1.131  loss_center: 0.4893  loss_offset: 0.742  time: 0.2969  data_time: 0.0262  lr: 0.0016544  max_mem: 6588M
[12/10 23:11:39 d2.utils.events]:  eta: 0:31:02  iter: 3699  total_loss: 2.406  loss_sem_seg: 1.148  loss_center: 0.4774  loss_offset: 0.7886  time: 0.2969  data_time: 0.0267  lr: 0.0016497  max_mem: 6588M
[12/10 23:11:45 d2.utils.events]:  eta: 0:30:56  iter: 3719  total_loss: 2.566  loss_sem_seg: 1.112  loss_center: 0.4986  loss_offset: 0.7859  time: 0.2969  data_time: 0.0244  lr: 0.001645  max_mem: 6588M
[12/10 23:11:51 d2.utils.events]:  eta: 0:30:50  iter: 3739  total_loss: 2.588  loss_sem_seg: 1.025  loss_center: 0.6811  loss_offset: 0.7506  time: 0.2969  data_time: 0.0247  lr: 0.0016403  max_mem: 6588M
[12/10 23:11:57 d2.utils.events]:  eta: 0:30:44  iter: 3759  total_loss: 2.492  loss_sem_seg: 1.098  loss_center: 0.5591  loss_offset: 0.7217  time: 0.2969  data_time: 0.0249  lr: 0.0016356  max_mem: 6588M
[12/10 23:12:03 d2.utils.events]:  eta: 0:30:38  iter: 3779  total_loss: 2.366  loss_sem_seg: 1.097  loss_center: 0.5849  loss_offset: 0.7292  time: 0.2969  data_time: 0.0241  lr: 0.0016309  max_mem: 6588M
[12/10 23:12:08 d2.utils.events]:  eta: 0:30:32  iter: 3799  total_loss: 2.401  loss_sem_seg: 0.9398  loss_center: 0.7015  loss_offset: 0.7138  time: 0.2969  data_time: 0.0256  lr: 0.0016261  max_mem: 6588M
[12/10 23:12:14 d2.utils.events]:  eta: 0:30:26  iter: 3819  total_loss: 2.531  loss_sem_seg: 1.08  loss_center: 0.6637  loss_offset: 0.742  time: 0.2969  data_time: 0.0256  lr: 0.0016214  max_mem: 6588M
[12/10 23:12:20 d2.utils.events]:  eta: 0:30:20  iter: 3839  total_loss: 2.673  loss_sem_seg: 1.192  loss_center: 0.5654  loss_offset: 0.8732  time: 0.2969  data_time: 0.0258  lr: 0.0016167  max_mem: 6588M
[12/10 23:12:26 d2.utils.events]:  eta: 0:30:16  iter: 3859  total_loss: 2.579  loss_sem_seg: 1.108  loss_center: 0.5663  loss_offset: 0.8516  time: 0.2970  data_time: 0.0261  lr: 0.001612  max_mem: 6588M
[12/10 23:12:32 d2.utils.events]:  eta: 0:30:10  iter: 3879  total_loss: 2.516  loss_sem_seg: 1.235  loss_center: 0.5236  loss_offset: 0.764  time: 0.2970  data_time: 0.0259  lr: 0.0016072  max_mem: 6588M
[12/10 23:12:38 d2.utils.events]:  eta: 0:30:05  iter: 3899  total_loss: 2.616  loss_sem_seg: 1.271  loss_center: 0.5944  loss_offset: 0.7269  time: 0.2970  data_time: 0.0258  lr: 0.0016025  max_mem: 6588M
[12/10 23:12:44 d2.utils.events]:  eta: 0:29:59  iter: 3919  total_loss: 2.383  loss_sem_seg: 1.007  loss_center: 0.6209  loss_offset: 0.7545  time: 0.2970  data_time: 0.0246  lr: 0.0015978  max_mem: 6588M
[12/10 23:12:50 d2.utils.events]:  eta: 0:29:53  iter: 3939  total_loss: 2.481  loss_sem_seg: 1.081  loss_center: 0.6284  loss_offset: 0.791  time: 0.2969  data_time: 0.0244  lr: 0.0015931  max_mem: 6588M
[12/10 23:12:56 d2.utils.events]:  eta: 0:29:47  iter: 3959  total_loss: 2.317  loss_sem_seg: 1.042  loss_center: 0.4894  loss_offset: 0.7171  time: 0.2970  data_time: 0.0260  lr: 0.0015883  max_mem: 6588M
[12/10 23:13:02 d2.utils.events]:  eta: 0:29:40  iter: 3979  total_loss: 2.393  loss_sem_seg: 0.9332  loss_center: 0.5695  loss_offset: 0.7301  time: 0.2969  data_time: 0.0245  lr: 0.0015836  max_mem: 6588M
[12/10 23:13:08 d2.utils.events]:  eta: 0:29:35  iter: 3999  total_loss: 2.717  loss_sem_seg: 1.341  loss_center: 0.5574  loss_offset: 0.7514  time: 0.2970  data_time: 0.0248  lr: 0.0015789  max_mem: 6588M
[12/10 23:13:14 d2.utils.events]:  eta: 0:29:30  iter: 4019  total_loss: 2.346  loss_sem_seg: 1.1  loss_center: 0.6122  loss_offset: 0.6817  time: 0.2970  data_time: 0.0253  lr: 0.0015741  max_mem: 6588M
[12/10 23:13:20 d2.utils.events]:  eta: 0:29:25  iter: 4039  total_loss: 2.595  loss_sem_seg: 1.164  loss_center: 0.4339  loss_offset: 0.9161  time: 0.2970  data_time: 0.0279  lr: 0.0015694  max_mem: 6588M
[12/10 23:13:26 d2.utils.events]:  eta: 0:29:19  iter: 4059  total_loss: 2.472  loss_sem_seg: 1.044  loss_center: 0.6818  loss_offset: 0.7278  time: 0.2970  data_time: 0.0242  lr: 0.0015646  max_mem: 6588M
[12/10 23:13:32 d2.utils.events]:  eta: 0:29:13  iter: 4079  total_loss: 2.391  loss_sem_seg: 1.025  loss_center: 0.4861  loss_offset: 0.7683  time: 0.2970  data_time: 0.0255  lr: 0.0015599  max_mem: 6588M
[12/10 23:13:38 d2.utils.events]:  eta: 0:29:07  iter: 4099  total_loss: 2.797  loss_sem_seg: 1.2  loss_center: 0.6605  loss_offset: 0.816  time: 0.2970  data_time: 0.0253  lr: 0.0015552  max_mem: 6588M
[12/10 23:13:44 d2.utils.events]:  eta: 0:29:01  iter: 4119  total_loss: 2.278  loss_sem_seg: 1.136  loss_center: 0.5047  loss_offset: 0.6699  time: 0.2970  data_time: 0.0245  lr: 0.0015504  max_mem: 6588M
[12/10 23:13:50 d2.utils.events]:  eta: 0:28:55  iter: 4139  total_loss: 2.644  loss_sem_seg: 0.9913  loss_center: 0.6317  loss_offset: 0.8006  time: 0.2970  data_time: 0.0253  lr: 0.0015457  max_mem: 6588M
[12/10 23:13:56 d2.utils.events]:  eta: 0:28:50  iter: 4159  total_loss: 2.543  loss_sem_seg: 1.066  loss_center: 0.6459  loss_offset: 0.6918  time: 0.2970  data_time: 0.0245  lr: 0.0015409  max_mem: 6588M
[12/10 23:14:02 d2.utils.events]:  eta: 0:28:44  iter: 4179  total_loss: 2.249  loss_sem_seg: 0.9501  loss_center: 0.5513  loss_offset: 0.7329  time: 0.2970  data_time: 0.0247  lr: 0.0015362  max_mem: 6588M
[12/10 23:14:08 d2.utils.events]:  eta: 0:28:38  iter: 4199  total_loss: 2.307  loss_sem_seg: 0.934  loss_center: 0.5796  loss_offset: 0.7932  time: 0.2969  data_time: 0.0242  lr: 0.0015314  max_mem: 6588M
[12/10 23:14:13 d2.utils.events]:  eta: 0:28:32  iter: 4219  total_loss: 2.327  loss_sem_seg: 0.9469  loss_center: 0.5911  loss_offset: 0.8196  time: 0.2970  data_time: 0.0267  lr: 0.0015267  max_mem: 6588M
[12/10 23:14:19 d2.utils.events]:  eta: 0:28:25  iter: 4239  total_loss: 2.246  loss_sem_seg: 0.9087  loss_center: 0.5361  loss_offset: 0.6869  time: 0.2970  data_time: 0.0235  lr: 0.0015219  max_mem: 6588M
[12/10 23:14:25 d2.utils.events]:  eta: 0:28:19  iter: 4259  total_loss: 2.565  loss_sem_seg: 1.068  loss_center: 0.6489  loss_offset: 0.7555  time: 0.2969  data_time: 0.0237  lr: 0.0015172  max_mem: 6588M
[12/10 23:14:31 d2.utils.events]:  eta: 0:28:13  iter: 4279  total_loss: 2.431  loss_sem_seg: 1.007  loss_center: 0.6348  loss_offset: 0.7657  time: 0.2969  data_time: 0.0250  lr: 0.0015124  max_mem: 6588M
[12/10 23:14:37 d2.utils.events]:  eta: 0:28:07  iter: 4299  total_loss: 2.416  loss_sem_seg: 1.01  loss_center: 0.5813  loss_offset: 0.7555  time: 0.2969  data_time: 0.0244  lr: 0.0015076  max_mem: 6588M
[12/10 23:14:43 d2.utils.events]:  eta: 0:28:01  iter: 4319  total_loss: 2.333  loss_sem_seg: 0.976  loss_center: 0.6069  loss_offset: 0.698  time: 0.2969  data_time: 0.0261  lr: 0.0015029  max_mem: 6588M
[12/10 23:14:49 d2.utils.events]:  eta: 0:27:55  iter: 4339  total_loss: 2.332  loss_sem_seg: 0.7708  loss_center: 0.6061  loss_offset: 0.6762  time: 0.2969  data_time: 0.0250  lr: 0.0014981  max_mem: 6588M
[12/10 23:14:55 d2.utils.events]:  eta: 0:27:49  iter: 4359  total_loss: 2.331  loss_sem_seg: 0.9517  loss_center: 0.5834  loss_offset: 0.7595  time: 0.2969  data_time: 0.0229  lr: 0.0014933  max_mem: 6588M
[12/10 23:15:01 d2.utils.events]:  eta: 0:27:43  iter: 4379  total_loss: 2.638  loss_sem_seg: 1.112  loss_center: 0.6047  loss_offset: 0.6927  time: 0.2970  data_time: 0.0280  lr: 0.0014886  max_mem: 6588M
[12/10 23:15:07 d2.utils.events]:  eta: 0:27:38  iter: 4399  total_loss: 2.679  loss_sem_seg: 1.107  loss_center: 0.5505  loss_offset: 0.7928  time: 0.2970  data_time: 0.0267  lr: 0.0014838  max_mem: 6588M
[12/10 23:15:13 d2.utils.events]:  eta: 0:27:32  iter: 4419  total_loss: 2.396  loss_sem_seg: 0.9122  loss_center: 0.6563  loss_offset: 0.7619  time: 0.2970  data_time: 0.0240  lr: 0.001479  max_mem: 6588M
[12/10 23:15:19 d2.utils.events]:  eta: 0:27:26  iter: 4439  total_loss: 2.535  loss_sem_seg: 1.066  loss_center: 0.5817  loss_offset: 0.862  time: 0.2970  data_time: 0.0247  lr: 0.0014743  max_mem: 6588M
[12/10 23:15:25 d2.utils.events]:  eta: 0:27:21  iter: 4459  total_loss: 2.07  loss_sem_seg: 0.8942  loss_center: 0.5261  loss_offset: 0.7606  time: 0.2970  data_time: 0.0260  lr: 0.0014695  max_mem: 6588M
[12/10 23:15:31 d2.utils.events]:  eta: 0:27:14  iter: 4479  total_loss: 2.414  loss_sem_seg: 0.9814  loss_center: 0.5911  loss_offset: 0.7682  time: 0.2970  data_time: 0.0237  lr: 0.0014647  max_mem: 6588M
[12/10 23:15:37 d2.utils.events]:  eta: 0:27:09  iter: 4499  total_loss: 2.158  loss_sem_seg: 0.9269  loss_center: 0.4809  loss_offset: 0.6898  time: 0.2970  data_time: 0.0287  lr: 0.0014599  max_mem: 6588M
[12/10 23:15:43 d2.utils.events]:  eta: 0:27:03  iter: 4519  total_loss: 2.489  loss_sem_seg: 1.079  loss_center: 0.591  loss_offset: 0.7184  time: 0.2970  data_time: 0.0246  lr: 0.0014552  max_mem: 6588M
[12/10 23:15:49 d2.utils.events]:  eta: 0:26:56  iter: 4539  total_loss: 2.288  loss_sem_seg: 0.8729  loss_center: 0.6183  loss_offset: 0.6669  time: 0.2970  data_time: 0.0252  lr: 0.0014504  max_mem: 6588M
[12/10 23:15:55 d2.utils.events]:  eta: 0:26:52  iter: 4559  total_loss: 2.538  loss_sem_seg: 1.126  loss_center: 0.4947  loss_offset: 0.7605  time: 0.2970  data_time: 0.0273  lr: 0.0014456  max_mem: 6588M
[12/10 23:16:01 d2.utils.events]:  eta: 0:26:46  iter: 4579  total_loss: 2.6  loss_sem_seg: 1.073  loss_center: 0.7761  loss_offset: 0.7083  time: 0.2970  data_time: 0.0247  lr: 0.0014408  max_mem: 6588M
[12/10 23:16:07 d2.utils.events]:  eta: 0:26:40  iter: 4599  total_loss: 2.387  loss_sem_seg: 0.9927  loss_center: 0.4933  loss_offset: 0.7788  time: 0.2970  data_time: 0.0266  lr: 0.001436  max_mem: 6588M
[12/10 23:16:13 d2.utils.events]:  eta: 0:26:34  iter: 4619  total_loss: 2.492  loss_sem_seg: 1.269  loss_center: 0.5658  loss_offset: 0.5886  time: 0.2970  data_time: 0.0248  lr: 0.0014313  max_mem: 6588M
[12/10 23:16:19 d2.utils.events]:  eta: 0:26:29  iter: 4639  total_loss: 2.341  loss_sem_seg: 0.8771  loss_center: 0.6183  loss_offset: 0.7584  time: 0.2970  data_time: 0.0255  lr: 0.0014265  max_mem: 6588M
[12/10 23:16:24 d2.utils.events]:  eta: 0:26:23  iter: 4659  total_loss: 2.33  loss_sem_seg: 1.059  loss_center: 0.6301  loss_offset: 0.6078  time: 0.2970  data_time: 0.0245  lr: 0.0014217  max_mem: 6588M
[12/10 23:16:30 d2.utils.events]:  eta: 0:26:17  iter: 4679  total_loss: 2.662  loss_sem_seg: 1.014  loss_center: 0.6429  loss_offset: 0.7528  time: 0.2970  data_time: 0.0254  lr: 0.0014169  max_mem: 6588M
[12/10 23:16:36 d2.utils.events]:  eta: 0:26:10  iter: 4699  total_loss: 2.667  loss_sem_seg: 1.106  loss_center: 0.6282  loss_offset: 0.7517  time: 0.2970  data_time: 0.0241  lr: 0.0014121  max_mem: 6588M
[12/10 23:16:42 d2.utils.events]:  eta: 0:26:05  iter: 4719  total_loss: 2.21  loss_sem_seg: 0.7834  loss_center: 0.6126  loss_offset: 0.6471  time: 0.2970  data_time: 0.0251  lr: 0.0014073  max_mem: 6588M
[12/10 23:16:48 d2.utils.events]:  eta: 0:26:00  iter: 4739  total_loss: 2.418  loss_sem_seg: 1.124  loss_center: 0.5694  loss_offset: 0.694  time: 0.2970  data_time: 0.0246  lr: 0.0014025  max_mem: 6588M
[12/10 23:16:54 d2.utils.events]:  eta: 0:25:54  iter: 4759  total_loss: 2.449  loss_sem_seg: 0.9989  loss_center: 0.6861  loss_offset: 0.7135  time: 0.2970  data_time: 0.0258  lr: 0.0013977  max_mem: 6588M
[12/10 23:17:00 d2.utils.events]:  eta: 0:25:48  iter: 4779  total_loss: 2.162  loss_sem_seg: 1.036  loss_center: 0.5696  loss_offset: 0.7326  time: 0.2970  data_time: 0.0253  lr: 0.0013929  max_mem: 6588M
[12/10 23:17:06 d2.utils.events]:  eta: 0:25:42  iter: 4799  total_loss: 2.231  loss_sem_seg: 0.8711  loss_center: 0.5448  loss_offset: 0.731  time: 0.2970  data_time: 0.0253  lr: 0.0013881  max_mem: 6588M
[12/10 23:17:12 d2.utils.events]:  eta: 0:25:36  iter: 4819  total_loss: 2.347  loss_sem_seg: 0.9146  loss_center: 0.4921  loss_offset: 0.7781  time: 0.2970  data_time: 0.0240  lr: 0.0013833  max_mem: 6588M
[12/10 23:17:18 d2.utils.events]:  eta: 0:25:30  iter: 4839  total_loss: 2.404  loss_sem_seg: 1.046  loss_center: 0.4996  loss_offset: 0.7821  time: 0.2970  data_time: 0.0282  lr: 0.0013785  max_mem: 6588M
[12/10 23:17:24 d2.utils.events]:  eta: 0:25:23  iter: 4859  total_loss: 2.41  loss_sem_seg: 0.9828  loss_center: 0.5473  loss_offset: 0.7034  time: 0.2970  data_time: 0.0242  lr: 0.0013737  max_mem: 6588M
[12/10 23:17:30 d2.utils.events]:  eta: 0:25:18  iter: 4879  total_loss: 2.138  loss_sem_seg: 0.9811  loss_center: 0.5239  loss_offset: 0.6613  time: 0.2970  data_time: 0.0263  lr: 0.0013689  max_mem: 6588M
[12/10 23:17:36 d2.utils.events]:  eta: 0:25:12  iter: 4899  total_loss: 2.329  loss_sem_seg: 1.02  loss_center: 0.5683  loss_offset: 0.7489  time: 0.2970  data_time: 0.0256  lr: 0.001364  max_mem: 6588M
[12/10 23:17:42 d2.utils.events]:  eta: 0:25:07  iter: 4919  total_loss: 2.471  loss_sem_seg: 1.088  loss_center: 0.6256  loss_offset: 0.744  time: 0.2970  data_time: 0.0277  lr: 0.0013592  max_mem: 6588M
[12/10 23:17:48 d2.utils.events]:  eta: 0:25:02  iter: 4939  total_loss: 2.269  loss_sem_seg: 1.013  loss_center: 0.564  loss_offset: 0.6971  time: 0.2970  data_time: 0.0251  lr: 0.0013544  max_mem: 6588M
[12/10 23:17:54 d2.utils.events]:  eta: 0:24:56  iter: 4959  total_loss: 2.463  loss_sem_seg: 1.003  loss_center: 0.6627  loss_offset: 0.74  time: 0.2970  data_time: 0.0252  lr: 0.0013496  max_mem: 6588M
[12/10 23:18:00 d2.utils.events]:  eta: 0:24:50  iter: 4979  total_loss: 2.645  loss_sem_seg: 1.164  loss_center: 0.6661  loss_offset: 0.7544  time: 0.2970  data_time: 0.0259  lr: 0.0013448  max_mem: 6588M
[12/10 23:18:06 fvcore.common.checkpoint]: Saving checkpoint to ./output/model_0004999.pth
[12/10 23:18:06 d2.utils.events]:  eta: 0:24:44  iter: 4999  total_loss: 2.639  loss_sem_seg: 1.083  loss_center: 0.5117  loss_offset: 0.7654  time: 0.2970  data_time: 0.0251  lr: 0.00134  max_mem: 6588M
[12/10 23:18:13 d2.utils.events]:  eta: 0:24:38  iter: 5019  total_loss: 2.517  loss_sem_seg: 0.9484  loss_center: 0.7044  loss_offset: 0.7368  time: 0.2970  data_time: 0.0245  lr: 0.0013351  max_mem: 6588M
[12/10 23:18:19 d2.utils.events]:  eta: 0:24:31  iter: 5039  total_loss: 2.359  loss_sem_seg: 0.8967  loss_center: 0.6032  loss_offset: 0.8003  time: 0.2970  data_time: 0.0241  lr: 0.0013303  max_mem: 6588M
[12/10 23:18:25 d2.utils.events]:  eta: 0:24:25  iter: 5059  total_loss: 2.226  loss_sem_seg: 0.921  loss_center: 0.5416  loss_offset: 0.7178  time: 0.2970  data_time: 0.0248  lr: 0.0013255  max_mem: 6588M
[12/10 23:18:31 d2.utils.events]:  eta: 0:24:19  iter: 5079  total_loss: 2.566  loss_sem_seg: 1.003  loss_center: 0.6635  loss_offset: 0.6886  time: 0.2970  data_time: 0.0239  lr: 0.0013207  max_mem: 6588M
[12/10 23:18:36 d2.utils.events]:  eta: 0:24:13  iter: 5099  total_loss: 2.37  loss_sem_seg: 0.8805  loss_center: 0.6327  loss_offset: 0.7567  time: 0.2970  data_time: 0.0247  lr: 0.0013158  max_mem: 6588M
[12/10 23:18:43 d2.utils.events]:  eta: 0:24:07  iter: 5119  total_loss: 2.458  loss_sem_seg: 0.8896  loss_center: 0.7521  loss_offset: 0.6561  time: 0.2970  data_time: 0.0259  lr: 0.001311  max_mem: 6588M
[12/10 23:18:48 d2.utils.events]:  eta: 0:24:02  iter: 5139  total_loss: 2.247  loss_sem_seg: 0.9506  loss_center: 0.6174  loss_offset: 0.6915  time: 0.2970  data_time: 0.0251  lr: 0.0013062  max_mem: 6588M
[12/10 23:18:54 d2.utils.events]:  eta: 0:23:56  iter: 5159  total_loss: 2.267  loss_sem_seg: 1.053  loss_center: 0.4964  loss_offset: 0.7116  time: 0.2970  data_time: 0.0255  lr: 0.0013013  max_mem: 6588M
[12/10 23:19:00 d2.utils.events]:  eta: 0:23:49  iter: 5179  total_loss: 2.43  loss_sem_seg: 0.9715  loss_center: 0.5761  loss_offset: 0.7714  time: 0.2970  data_time: 0.0267  lr: 0.0012965  max_mem: 6588M
[12/10 23:19:06 d2.utils.events]:  eta: 0:23:43  iter: 5199  total_loss: 2.387  loss_sem_seg: 0.8552  loss_center: 0.5826  loss_offset: 0.7144  time: 0.2970  data_time: 0.0239  lr: 0.0012916  max_mem: 6588M
[12/10 23:19:12 d2.utils.events]:  eta: 0:23:37  iter: 5219  total_loss: 2.315  loss_sem_seg: 0.9592  loss_center: 0.6435  loss_offset: 0.7734  time: 0.2970  data_time: 0.0244  lr: 0.0012868  max_mem: 6588M
[12/10 23:19:18 d2.utils.events]:  eta: 0:23:32  iter: 5239  total_loss: 2.439  loss_sem_seg: 1.005  loss_center: 0.6519  loss_offset: 0.7038  time: 0.2970  data_time: 0.0260  lr: 0.0012819  max_mem: 6588M
[12/10 23:19:24 d2.utils.events]:  eta: 0:23:25  iter: 5259  total_loss: 2.504  loss_sem_seg: 0.9672  loss_center: 0.556  loss_offset: 0.7408  time: 0.2970  data_time: 0.0230  lr: 0.0012771  max_mem: 6588M
[12/10 23:19:30 d2.utils.events]:  eta: 0:23:20  iter: 5279  total_loss: 2.362  loss_sem_seg: 1.013  loss_center: 0.5986  loss_offset: 0.6864  time: 0.2970  data_time: 0.0272  lr: 0.0012722  max_mem: 6588M
[12/10 23:19:36 d2.utils.events]:  eta: 0:23:15  iter: 5299  total_loss: 2.524  loss_sem_seg: 1.099  loss_center: 0.5802  loss_offset: 0.8309  time: 0.2970  data_time: 0.0238  lr: 0.0012674  max_mem: 6588M
[12/10 23:19:42 d2.utils.events]:  eta: 0:23:09  iter: 5319  total_loss: 2.156  loss_sem_seg: 0.8407  loss_center: 0.5885  loss_offset: 0.6965  time: 0.2970  data_time: 0.0264  lr: 0.0012625  max_mem: 6588M
[12/10 23:19:48 d2.utils.events]:  eta: 0:23:02  iter: 5339  total_loss: 2.206  loss_sem_seg: 0.9793  loss_center: 0.5897  loss_offset: 0.7683  time: 0.2970  data_time: 0.0248  lr: 0.0012577  max_mem: 6588M
[12/10 23:19:54 d2.utils.events]:  eta: 0:22:57  iter: 5359  total_loss: 2.294  loss_sem_seg: 1.104  loss_center: 0.4846  loss_offset: 0.7779  time: 0.2970  data_time: 0.0247  lr: 0.0012528  max_mem: 6588M
[12/10 23:20:00 d2.utils.events]:  eta: 0:22:51  iter: 5379  total_loss: 2.458  loss_sem_seg: 1.013  loss_center: 0.575  loss_offset: 0.7402  time: 0.2970  data_time: 0.0265  lr: 0.001248  max_mem: 6588M
[12/10 23:20:06 d2.utils.events]:  eta: 0:22:44  iter: 5399  total_loss: 2.265  loss_sem_seg: 0.9106  loss_center: 0.5646  loss_offset: 0.7647  time: 0.2970  data_time: 0.0257  lr: 0.0012431  max_mem: 6588M
[12/10 23:20:12 d2.utils.events]:  eta: 0:22:38  iter: 5419  total_loss: 2.342  loss_sem_seg: 0.9361  loss_center: 0.607  loss_offset: 0.7107  time: 0.2970  data_time: 0.0248  lr: 0.0012382  max_mem: 6588M
[12/10 23:20:18 d2.utils.events]:  eta: 0:22:32  iter: 5439  total_loss: 2.23  loss_sem_seg: 0.9601  loss_center: 0.6164  loss_offset: 0.7086  time: 0.2970  data_time: 0.0257  lr: 0.0012334  max_mem: 6588M
[12/10 23:20:24 d2.utils.events]:  eta: 0:22:26  iter: 5459  total_loss: 2.561  loss_sem_seg: 1.028  loss_center: 0.6737  loss_offset: 0.7002  time: 0.2970  data_time: 0.0257  lr: 0.0012285  max_mem: 6588M
[12/10 23:20:29 d2.utils.events]:  eta: 0:22:20  iter: 5479  total_loss: 2.245  loss_sem_seg: 1.01  loss_center: 0.5365  loss_offset: 0.7496  time: 0.2970  data_time: 0.0244  lr: 0.0012236  max_mem: 6588M
[12/10 23:20:35 d2.utils.events]:  eta: 0:22:14  iter: 5499  total_loss: 2.255  loss_sem_seg: 0.906  loss_center: 0.5765  loss_offset: 0.6498  time: 0.2970  data_time: 0.0253  lr: 0.0012188  max_mem: 6588M
[12/10 23:20:41 d2.utils.events]:  eta: 0:22:08  iter: 5519  total_loss: 2.242  loss_sem_seg: 1.02  loss_center: 0.619  loss_offset: 0.6975  time: 0.2970  data_time: 0.0239  lr: 0.0012139  max_mem: 6588M
[12/10 23:20:47 d2.utils.events]:  eta: 0:22:03  iter: 5539  total_loss: 2.332  loss_sem_seg: 0.955  loss_center: 0.6524  loss_offset: 0.6637  time: 0.2970  data_time: 0.0252  lr: 0.001209  max_mem: 6588M
[12/10 23:20:53 d2.utils.events]:  eta: 0:21:56  iter: 5559  total_loss: 2.384  loss_sem_seg: 1.103  loss_center: 0.4876  loss_offset: 0.7306  time: 0.2970  data_time: 0.0255  lr: 0.0012041  max_mem: 6588M
[12/10 23:20:59 d2.utils.events]:  eta: 0:21:50  iter: 5579  total_loss: 2.277  loss_sem_seg: 0.9557  loss_center: 0.5566  loss_offset: 0.7024  time: 0.2970  data_time: 0.0246  lr: 0.0011992  max_mem: 6588M
[12/10 23:21:05 d2.utils.events]:  eta: 0:21:44  iter: 5599  total_loss: 2.09  loss_sem_seg: 1.026  loss_center: 0.5467  loss_offset: 0.6695  time: 0.2970  data_time: 0.0261  lr: 0.0011944  max_mem: 6588M
[12/10 23:21:11 d2.utils.events]:  eta: 0:21:38  iter: 5619  total_loss: 2.152  loss_sem_seg: 0.8795  loss_center: 0.5333  loss_offset: 0.7113  time: 0.2970  data_time: 0.0244  lr: 0.0011895  max_mem: 6588M
[12/10 23:21:17 d2.utils.events]:  eta: 0:21:32  iter: 5639  total_loss: 2.409  loss_sem_seg: 0.9582  loss_center: 0.6502  loss_offset: 0.746  time: 0.2970  data_time: 0.0258  lr: 0.0011846  max_mem: 6588M
[12/10 23:21:23 d2.utils.events]:  eta: 0:21:26  iter: 5659  total_loss: 2.357  loss_sem_seg: 1.08  loss_center: 0.6178  loss_offset: 0.7183  time: 0.2970  data_time: 0.0256  lr: 0.0011797  max_mem: 6588M
[12/10 23:21:29 d2.utils.events]:  eta: 0:21:20  iter: 5679  total_loss: 2.37  loss_sem_seg: 1.183  loss_center: 0.5101  loss_offset: 0.6707  time: 0.2970  data_time: 0.0248  lr: 0.0011748  max_mem: 6588M
[12/10 23:21:35 d2.utils.events]:  eta: 0:21:14  iter: 5699  total_loss: 2.438  loss_sem_seg: 1.021  loss_center: 0.6627  loss_offset: 0.8888  time: 0.2970  data_time: 0.0255  lr: 0.0011699  max_mem: 6588M
[12/10 23:21:41 d2.utils.events]:  eta: 0:21:07  iter: 5719  total_loss: 2.258  loss_sem_seg: 0.8788  loss_center: 0.6457  loss_offset: 0.7466  time: 0.2970  data_time: 0.0257  lr: 0.001165  max_mem: 6588M
[12/10 23:21:47 d2.utils.events]:  eta: 0:21:01  iter: 5739  total_loss: 2.436  loss_sem_seg: 0.9406  loss_center: 0.5206  loss_offset: 0.7638  time: 0.2970  data_time: 0.0245  lr: 0.0011601  max_mem: 6588M
[12/10 23:21:53 d2.utils.events]:  eta: 0:20:55  iter: 5759  total_loss: 2.336  loss_sem_seg: 1.021  loss_center: 0.5865  loss_offset: 0.6763  time: 0.2970  data_time: 0.0254  lr: 0.0011552  max_mem: 6588M
[12/10 23:21:59 d2.utils.events]:  eta: 0:20:50  iter: 5779  total_loss: 2.594  loss_sem_seg: 1.065  loss_center: 0.6147  loss_offset: 0.756  time: 0.2970  data_time: 0.0241  lr: 0.0011503  max_mem: 6588M
[12/10 23:22:05 d2.utils.events]:  eta: 0:20:44  iter: 5799  total_loss: 2.362  loss_sem_seg: 1.05  loss_center: 0.5487  loss_offset: 0.7136  time: 0.2970  data_time: 0.0267  lr: 0.0011454  max_mem: 6588M
[12/10 23:22:11 d2.utils.events]:  eta: 0:20:38  iter: 5819  total_loss: 2.432  loss_sem_seg: 0.9531  loss_center: 0.5693  loss_offset: 0.6808  time: 0.2970  data_time: 0.0252  lr: 0.0011405  max_mem: 6588M
[12/10 23:22:17 d2.utils.events]:  eta: 0:20:32  iter: 5839  total_loss: 2.237  loss_sem_seg: 0.9138  loss_center: 0.501  loss_offset: 0.6876  time: 0.2970  data_time: 0.0275  lr: 0.0011356  max_mem: 6588M
[12/10 23:22:23 d2.utils.events]:  eta: 0:20:26  iter: 5859  total_loss: 2.274  loss_sem_seg: 0.9536  loss_center: 0.6554  loss_offset: 0.6636  time: 0.2970  data_time: 0.0274  lr: 0.0011307  max_mem: 6588M
[12/10 23:22:28 d2.utils.events]:  eta: 0:20:20  iter: 5879  total_loss: 2.301  loss_sem_seg: 1.034  loss_center: 0.6276  loss_offset: 0.7497  time: 0.2970  data_time: 0.0244  lr: 0.0011258  max_mem: 6588M
[12/10 23:22:34 d2.utils.events]:  eta: 0:20:14  iter: 5899  total_loss: 2.265  loss_sem_seg: 0.8413  loss_center: 0.7085  loss_offset: 0.7275  time: 0.2970  data_time: 0.0244  lr: 0.0011208  max_mem: 6588M
[12/10 23:22:40 d2.utils.events]:  eta: 0:20:08  iter: 5919  total_loss: 2.12  loss_sem_seg: 0.8802  loss_center: 0.5358  loss_offset: 0.6147  time: 0.2970  data_time: 0.0251  lr: 0.0011159  max_mem: 6588M
[12/10 23:22:46 d2.utils.events]:  eta: 0:20:02  iter: 5939  total_loss: 2.375  loss_sem_seg: 0.9651  loss_center: 0.5871  loss_offset: 0.6644  time: 0.2970  data_time: 0.0245  lr: 0.001111  max_mem: 6588M
[12/10 23:22:52 d2.utils.events]:  eta: 0:19:56  iter: 5959  total_loss: 2.173  loss_sem_seg: 0.8425  loss_center: 0.5828  loss_offset: 0.6673  time: 0.2970  data_time: 0.0255  lr: 0.0011061  max_mem: 6588M
[12/10 23:22:58 d2.utils.events]:  eta: 0:19:50  iter: 5979  total_loss: 2.108  loss_sem_seg: 0.9484  loss_center: 0.4484  loss_offset: 0.6282  time: 0.2970  data_time: 0.0234  lr: 0.0011011  max_mem: 6588M
[12/10 23:23:04 d2.utils.events]:  eta: 0:19:44  iter: 5999  total_loss: 2.288  loss_sem_seg: 0.9354  loss_center: 0.5227  loss_offset: 0.6796  time: 0.2970  data_time: 0.0268  lr: 0.0010962  max_mem: 6588M
[12/10 23:23:10 d2.utils.events]:  eta: 0:19:38  iter: 6019  total_loss: 2.35  loss_sem_seg: 1.023  loss_center: 0.5617  loss_offset: 0.6186  time: 0.2970  data_time: 0.0254  lr: 0.0010913  max_mem: 6588M
[12/10 23:23:16 d2.utils.events]:  eta: 0:19:32  iter: 6039  total_loss: 2.432  loss_sem_seg: 0.8702  loss_center: 0.6563  loss_offset: 0.6997  time: 0.2970  data_time: 0.0245  lr: 0.0010863  max_mem: 6588M
[12/10 23:23:22 d2.utils.events]:  eta: 0:19:26  iter: 6059  total_loss: 2.017  loss_sem_seg: 0.9394  loss_center: 0.4635  loss_offset: 0.6304  time: 0.2970  data_time: 0.0247  lr: 0.0010814  max_mem: 6588M
[12/10 23:23:28 d2.utils.events]:  eta: 0:19:20  iter: 6079  total_loss: 2.209  loss_sem_seg: 0.9756  loss_center: 0.419  loss_offset: 0.6471  time: 0.2970  data_time: 0.0236  lr: 0.0010765  max_mem: 6588M
[12/10 23:23:34 d2.utils.events]:  eta: 0:19:14  iter: 6099  total_loss: 2.384  loss_sem_seg: 0.9788  loss_center: 0.6124  loss_offset: 0.6389  time: 0.2970  data_time: 0.0253  lr: 0.0010715  max_mem: 6588M
[12/10 23:23:40 d2.utils.events]:  eta: 0:19:08  iter: 6119  total_loss: 2.261  loss_sem_seg: 0.9446  loss_center: 0.6165  loss_offset: 0.7438  time: 0.2969  data_time: 0.0228  lr: 0.0010666  max_mem: 6588M
[12/10 23:23:46 d2.utils.events]:  eta: 0:19:02  iter: 6139  total_loss: 2.187  loss_sem_seg: 0.9356  loss_center: 0.5702  loss_offset: 0.6255  time: 0.2969  data_time: 0.0260  lr: 0.0010616  max_mem: 6588M
[12/10 23:23:51 d2.utils.events]:  eta: 0:18:56  iter: 6159  total_loss: 2.212  loss_sem_seg: 0.9061  loss_center: 0.7128  loss_offset: 0.6919  time: 0.2969  data_time: 0.0254  lr: 0.0010567  max_mem: 6588M
[12/10 23:23:57 d2.utils.events]:  eta: 0:18:50  iter: 6179  total_loss: 2.194  loss_sem_seg: 0.8754  loss_center: 0.5331  loss_offset: 0.6477  time: 0.2969  data_time: 0.0255  lr: 0.0010517  max_mem: 6588M
[12/10 23:24:03 d2.utils.events]:  eta: 0:18:44  iter: 6199  total_loss: 2.147  loss_sem_seg: 1.026  loss_center: 0.5472  loss_offset: 0.7274  time: 0.2969  data_time: 0.0262  lr: 0.0010468  max_mem: 6588M
[12/10 23:24:09 d2.utils.events]:  eta: 0:18:39  iter: 6219  total_loss: 2.183  loss_sem_seg: 0.8783  loss_center: 0.5613  loss_offset: 0.7302  time: 0.2969  data_time: 0.0249  lr: 0.0010418  max_mem: 6588M
[12/10 23:24:15 d2.utils.events]:  eta: 0:18:32  iter: 6239  total_loss: 2.202  loss_sem_seg: 1.01  loss_center: 0.5633  loss_offset: 0.6857  time: 0.2969  data_time: 0.0260  lr: 0.0010368  max_mem: 6588M
[12/10 23:24:21 d2.utils.events]:  eta: 0:18:27  iter: 6259  total_loss: 2.325  loss_sem_seg: 1.084  loss_center: 0.6237  loss_offset: 0.6712  time: 0.2969  data_time: 0.0265  lr: 0.0010319  max_mem: 6588M
[12/10 23:24:27 d2.utils.events]:  eta: 0:18:21  iter: 6279  total_loss: 2.178  loss_sem_seg: 0.8903  loss_center: 0.6269  loss_offset: 0.7413  time: 0.2969  data_time: 0.0251  lr: 0.0010269  max_mem: 6588M
[12/10 23:24:33 d2.utils.events]:  eta: 0:18:15  iter: 6299  total_loss: 2.097  loss_sem_seg: 0.8272  loss_center: 0.5136  loss_offset: 0.6455  time: 0.2969  data_time: 0.0241  lr: 0.0010219  max_mem: 6588M
[12/10 23:24:39 d2.utils.events]:  eta: 0:18:08  iter: 6319  total_loss: 2.284  loss_sem_seg: 1.12  loss_center: 0.6278  loss_offset: 0.6599  time: 0.2969  data_time: 0.0241  lr: 0.001017  max_mem: 6588M
[12/10 23:24:45 d2.utils.events]:  eta: 0:18:02  iter: 6339  total_loss: 2.403  loss_sem_seg: 0.9914  loss_center: 0.5944  loss_offset: 0.6465  time: 0.2969  data_time: 0.0254  lr: 0.001012  max_mem: 6588M
[12/10 23:24:51 d2.utils.events]:  eta: 0:17:56  iter: 6359  total_loss: 2.173  loss_sem_seg: 0.8788  loss_center: 0.5323  loss_offset: 0.7119  time: 0.2969  data_time: 0.0238  lr: 0.001007  max_mem: 6588M
[12/10 23:24:57 d2.utils.events]:  eta: 0:17:49  iter: 6379  total_loss: 2.127  loss_sem_seg: 0.9669  loss_center: 0.4656  loss_offset: 0.6675  time: 0.2969  data_time: 0.0267  lr: 0.001002  max_mem: 6588M
[12/10 23:25:03 d2.utils.events]:  eta: 0:17:43  iter: 6399  total_loss: 2.059  loss_sem_seg: 0.7691  loss_center: 0.5817  loss_offset: 0.6737  time: 0.2969  data_time: 0.0239  lr: 0.00099706  max_mem: 6588M
[12/10 23:25:09 d2.utils.events]:  eta: 0:17:37  iter: 6419  total_loss: 2.203  loss_sem_seg: 0.9342  loss_center: 0.585  loss_offset: 0.7112  time: 0.2969  data_time: 0.0241  lr: 0.00099207  max_mem: 6588M
[12/10 23:25:14 d2.utils.events]:  eta: 0:17:31  iter: 6439  total_loss: 2.491  loss_sem_seg: 1.013  loss_center: 0.5992  loss_offset: 0.7167  time: 0.2969  data_time: 0.0249  lr: 0.00098709  max_mem: 6588M
[12/10 23:25:20 d2.utils.events]:  eta: 0:17:25  iter: 6459  total_loss: 2.451  loss_sem_seg: 0.9341  loss_center: 0.7401  loss_offset: 0.6729  time: 0.2969  data_time: 0.0249  lr: 0.00098209  max_mem: 6588M
[12/10 23:25:26 d2.utils.events]:  eta: 0:17:19  iter: 6479  total_loss: 2.028  loss_sem_seg: 0.9182  loss_center: 0.4587  loss_offset: 0.6515  time: 0.2969  data_time: 0.0251  lr: 0.0009771  max_mem: 6588M
[12/10 23:25:32 d2.utils.events]:  eta: 0:17:13  iter: 6499  total_loss: 2.261  loss_sem_seg: 0.9263  loss_center: 0.6549  loss_offset: 0.7096  time: 0.2969  data_time: 0.0251  lr: 0.0009721  max_mem: 6588M
[12/10 23:25:38 d2.utils.events]:  eta: 0:17:07  iter: 6519  total_loss: 2.211  loss_sem_seg: 0.9385  loss_center: 0.6216  loss_offset: 0.746  time: 0.2969  data_time: 0.0242  lr: 0.00096711  max_mem: 6588M
[12/10 23:25:44 d2.utils.events]:  eta: 0:17:01  iter: 6539  total_loss: 2.287  loss_sem_seg: 0.9318  loss_center: 0.5749  loss_offset: 0.7022  time: 0.2969  data_time: 0.0248  lr: 0.0009621  max_mem: 6588M
[12/10 23:25:50 d2.utils.events]:  eta: 0:16:55  iter: 6559  total_loss: 2.217  loss_sem_seg: 0.9736  loss_center: 0.5876  loss_offset: 0.6964  time: 0.2969  data_time: 0.0254  lr: 0.0009571  max_mem: 6588M
[12/10 23:25:56 d2.utils.events]:  eta: 0:16:50  iter: 6579  total_loss: 2.259  loss_sem_seg: 0.936  loss_center: 0.6341  loss_offset: 0.5984  time: 0.2969  data_time: 0.0275  lr: 0.00095209  max_mem: 6588M
[12/10 23:26:02 d2.utils.events]:  eta: 0:16:44  iter: 6599  total_loss: 2.236  loss_sem_seg: 0.8608  loss_center: 0.622  loss_offset: 0.7276  time: 0.2969  data_time: 0.0237  lr: 0.00094708  max_mem: 6588M
[12/10 23:26:08 d2.utils.events]:  eta: 0:16:38  iter: 6619  total_loss: 2.332  loss_sem_seg: 1.052  loss_center: 0.6471  loss_offset: 0.7774  time: 0.2969  data_time: 0.0248  lr: 0.00094206  max_mem: 6588M
[12/10 23:26:14 d2.utils.events]:  eta: 0:16:32  iter: 6639  total_loss: 2.271  loss_sem_seg: 0.8828  loss_center: 0.6012  loss_offset: 0.6976  time: 0.2969  data_time: 0.0240  lr: 0.00093705  max_mem: 6588M
[12/10 23:26:20 d2.utils.events]:  eta: 0:16:26  iter: 6659  total_loss: 2.303  loss_sem_seg: 0.8987  loss_center: 0.604  loss_offset: 0.8282  time: 0.2969  data_time: 0.0257  lr: 0.00093203  max_mem: 6588M
[12/10 23:26:26 d2.utils.events]:  eta: 0:16:20  iter: 6679  total_loss: 2.119  loss_sem_seg: 0.81  loss_center: 0.6024  loss_offset: 0.666  time: 0.2969  data_time: 0.0260  lr: 0.000927  max_mem: 6588M
[12/10 23:26:32 d2.utils.events]:  eta: 0:16:14  iter: 6699  total_loss: 2.077  loss_sem_seg: 0.813  loss_center: 0.5672  loss_offset: 0.6101  time: 0.2969  data_time: 0.0248  lr: 0.00092198  max_mem: 6588M
[12/10 23:26:38 d2.utils.events]:  eta: 0:16:08  iter: 6719  total_loss: 2.391  loss_sem_seg: 0.9307  loss_center: 0.5466  loss_offset: 0.8045  time: 0.2969  data_time: 0.0243  lr: 0.00091695  max_mem: 6588M
[12/10 23:26:44 d2.utils.events]:  eta: 0:16:02  iter: 6739  total_loss: 2.446  loss_sem_seg: 1.008  loss_center: 0.4698  loss_offset: 0.8095  time: 0.2969  data_time: 0.0289  lr: 0.00091192  max_mem: 6588M
[12/10 23:26:50 d2.utils.events]:  eta: 0:15:57  iter: 6759  total_loss: 2.584  loss_sem_seg: 1.145  loss_center: 0.6429  loss_offset: 0.7148  time: 0.2969  data_time: 0.0290  lr: 0.00090688  max_mem: 6588M
[12/10 23:26:56 d2.utils.events]:  eta: 0:15:50  iter: 6779  total_loss: 2.152  loss_sem_seg: 0.7754  loss_center: 0.6091  loss_offset: 0.6728  time: 0.2969  data_time: 0.0248  lr: 0.00090184  max_mem: 6588M
[12/10 23:27:02 d2.utils.events]:  eta: 0:15:45  iter: 6799  total_loss: 2.219  loss_sem_seg: 0.8846  loss_center: 0.664  loss_offset: 0.7296  time: 0.2969  data_time: 0.0249  lr: 0.0008968  max_mem: 6588M
[12/10 23:27:08 d2.utils.events]:  eta: 0:15:39  iter: 6819  total_loss: 1.978  loss_sem_seg: 0.8864  loss_center: 0.5826  loss_offset: 0.6271  time: 0.2969  data_time: 0.0254  lr: 0.00089176  max_mem: 6588M
[12/10 23:27:14 d2.utils.events]:  eta: 0:15:33  iter: 6839  total_loss: 2.259  loss_sem_seg: 0.9112  loss_center: 0.6273  loss_offset: 0.6359  time: 0.2969  data_time: 0.0246  lr: 0.00088671  max_mem: 6588M
[12/10 23:27:20 d2.utils.events]:  eta: 0:15:27  iter: 6859  total_loss: 2.543  loss_sem_seg: 0.9127  loss_center: 0.656  loss_offset: 0.7213  time: 0.2969  data_time: 0.0245  lr: 0.00088166  max_mem: 6588M
[12/10 23:27:26 d2.utils.events]:  eta: 0:15:21  iter: 6879  total_loss: 2.318  loss_sem_seg: 0.9047  loss_center: 0.5443  loss_offset: 0.7072  time: 0.2969  data_time: 0.0263  lr: 0.00087661  max_mem: 6588M
[12/10 23:27:32 d2.utils.events]:  eta: 0:15:15  iter: 6899  total_loss: 2.248  loss_sem_seg: 0.7864  loss_center: 0.5759  loss_offset: 0.5867  time: 0.2969  data_time: 0.0257  lr: 0.00087155  max_mem: 6588M
[12/10 23:27:37 d2.utils.events]:  eta: 0:15:09  iter: 6919  total_loss: 2.152  loss_sem_seg: 0.9251  loss_center: 0.614  loss_offset: 0.6331  time: 0.2969  data_time: 0.0255  lr: 0.00086649  max_mem: 6588M
[12/10 23:27:43 d2.utils.events]:  eta: 0:15:03  iter: 6939  total_loss: 2.387  loss_sem_seg: 0.9999  loss_center: 0.4996  loss_offset: 0.6719  time: 0.2969  data_time: 0.0252  lr: 0.00086142  max_mem: 6588M
[12/10 23:27:49 d2.utils.events]:  eta: 0:14:58  iter: 6959  total_loss: 2.378  loss_sem_seg: 0.7883  loss_center: 0.6531  loss_offset: 0.738  time: 0.2969  data_time: 0.0242  lr: 0.00085636  max_mem: 6588M
[12/10 23:27:55 d2.utils.events]:  eta: 0:14:51  iter: 6979  total_loss: 2.449  loss_sem_seg: 0.8587  loss_center: 0.583  loss_offset: 0.7089  time: 0.2969  data_time: 0.0243  lr: 0.00085129  max_mem: 6588M
[12/10 23:28:01 d2.utils.events]:  eta: 0:14:45  iter: 6999  total_loss: 2.305  loss_sem_seg: 1.033  loss_center: 0.5749  loss_offset: 0.6474  time: 0.2969  data_time: 0.0254  lr: 0.00084621  max_mem: 6588M
[12/10 23:28:07 d2.utils.events]:  eta: 0:14:39  iter: 7019  total_loss: 1.996  loss_sem_seg: 0.8976  loss_center: 0.4295  loss_offset: 0.6376  time: 0.2969  data_time: 0.0240  lr: 0.00084114  max_mem: 6588M
[12/10 23:28:13 d2.utils.events]:  eta: 0:14:34  iter: 7039  total_loss: 2.355  loss_sem_seg: 0.8752  loss_center: 0.5438  loss_offset: 0.7118  time: 0.2969  data_time: 0.0264  lr: 0.00083605  max_mem: 6588M
[12/10 23:28:19 d2.utils.events]:  eta: 0:14:28  iter: 7059  total_loss: 2.325  loss_sem_seg: 0.9124  loss_center: 0.6283  loss_offset: 0.7043  time: 0.2969  data_time: 0.0254  lr: 0.00083097  max_mem: 6588M
[12/10 23:28:25 d2.utils.events]:  eta: 0:14:22  iter: 7079  total_loss: 1.993  loss_sem_seg: 0.8082  loss_center: 0.5687  loss_offset: 0.6718  time: 0.2969  data_time: 0.0257  lr: 0.00082588  max_mem: 6588M
[12/10 23:28:31 d2.utils.events]:  eta: 0:14:16  iter: 7099  total_loss: 2.124  loss_sem_seg: 0.7739  loss_center: 0.5556  loss_offset: 0.6879  time: 0.2969  data_time: 0.0260  lr: 0.00082079  max_mem: 6588M
[12/10 23:28:37 d2.utils.events]:  eta: 0:14:11  iter: 7119  total_loss: 2.38  loss_sem_seg: 1.047  loss_center: 0.4905  loss_offset: 0.6882  time: 0.2969  data_time: 0.0249  lr: 0.0008157  max_mem: 6588M
[12/10 23:28:43 d2.utils.events]:  eta: 0:14:05  iter: 7139  total_loss: 2.084  loss_sem_seg: 0.7158  loss_center: 0.6015  loss_offset: 0.7768  time: 0.2969  data_time: 0.0257  lr: 0.0008106  max_mem: 6588M
[12/10 23:28:49 d2.utils.events]:  eta: 0:13:59  iter: 7159  total_loss: 2.23  loss_sem_seg: 0.9719  loss_center: 0.6285  loss_offset: 0.7268  time: 0.2970  data_time: 0.0274  lr: 0.0008055  max_mem: 6588M
[12/10 23:28:55 d2.utils.events]:  eta: 0:13:53  iter: 7179  total_loss: 2.033  loss_sem_seg: 0.8477  loss_center: 0.6051  loss_offset: 0.664  time: 0.2970  data_time: 0.0284  lr: 0.00080039  max_mem: 6588M
[12/10 23:29:01 d2.utils.events]:  eta: 0:13:47  iter: 7199  total_loss: 2.087  loss_sem_seg: 0.8904  loss_center: 0.5756  loss_offset: 0.6199  time: 0.2970  data_time: 0.0265  lr: 0.00079528  max_mem: 6588M
[12/10 23:29:07 d2.utils.events]:  eta: 0:13:42  iter: 7219  total_loss: 2.183  loss_sem_seg: 0.8946  loss_center: 0.5113  loss_offset: 0.7309  time: 0.2970  data_time: 0.0262  lr: 0.00079017  max_mem: 6588M
[12/10 23:29:13 d2.utils.events]:  eta: 0:13:36  iter: 7239  total_loss: 2.015  loss_sem_seg: 0.8696  loss_center: 0.4915  loss_offset: 0.6365  time: 0.2970  data_time: 0.0264  lr: 0.00078505  max_mem: 6588M
[12/10 23:29:19 d2.utils.events]:  eta: 0:13:30  iter: 7259  total_loss: 2.286  loss_sem_seg: 0.9514  loss_center: 0.5772  loss_offset: 0.6172  time: 0.2970  data_time: 0.0257  lr: 0.00077993  max_mem: 6588M
[12/10 23:29:25 d2.utils.events]:  eta: 0:13:24  iter: 7279  total_loss: 2.355  loss_sem_seg: 0.889  loss_center: 0.6479  loss_offset: 0.6178  time: 0.2970  data_time: 0.0253  lr: 0.00077481  max_mem: 6588M
[12/10 23:29:31 d2.utils.events]:  eta: 0:13:18  iter: 7299  total_loss: 2.243  loss_sem_seg: 0.7865  loss_center: 0.5831  loss_offset: 0.7177  time: 0.2970  data_time: 0.0250  lr: 0.00076968  max_mem: 6588M
[12/10 23:29:37 d2.utils.events]:  eta: 0:13:12  iter: 7319  total_loss: 2.059  loss_sem_seg: 0.7932  loss_center: 0.551  loss_offset: 0.592  time: 0.2970  data_time: 0.0256  lr: 0.00076455  max_mem: 6588M
[12/10 23:29:43 d2.utils.events]:  eta: 0:13:06  iter: 7339  total_loss: 2.3  loss_sem_seg: 1.001  loss_center: 0.5518  loss_offset: 0.6947  time: 0.2970  data_time: 0.0249  lr: 0.00075942  max_mem: 6588M
[12/10 23:29:48 d2.utils.events]:  eta: 0:13:01  iter: 7359  total_loss: 2.196  loss_sem_seg: 0.8756  loss_center: 0.5817  loss_offset: 0.6831  time: 0.2970  data_time: 0.0236  lr: 0.00075428  max_mem: 6588M
[12/10 23:29:54 d2.utils.events]:  eta: 0:12:55  iter: 7379  total_loss: 2.147  loss_sem_seg: 0.8131  loss_center: 0.5896  loss_offset: 0.6926  time: 0.2970  data_time: 0.0250  lr: 0.00074914  max_mem: 6588M
[12/10 23:30:00 d2.utils.events]:  eta: 0:12:49  iter: 7399  total_loss: 2.43  loss_sem_seg: 0.8714  loss_center: 0.6237  loss_offset: 0.7258  time: 0.2970  data_time: 0.0264  lr: 0.00074399  max_mem: 6588M
[12/10 23:30:06 d2.utils.events]:  eta: 0:12:43  iter: 7419  total_loss: 2.01  loss_sem_seg: 0.8802  loss_center: 0.6106  loss_offset: 0.6107  time: 0.2970  data_time: 0.0265  lr: 0.00073884  max_mem: 6588M
[12/10 23:30:12 d2.utils.events]:  eta: 0:12:37  iter: 7439  total_loss: 2.212  loss_sem_seg: 0.9811  loss_center: 0.5492  loss_offset: 0.6804  time: 0.2970  data_time: 0.0258  lr: 0.00073368  max_mem: 6588M
[12/10 23:30:18 d2.utils.events]:  eta: 0:12:32  iter: 7459  total_loss: 2.396  loss_sem_seg: 0.9503  loss_center: 0.7215  loss_offset: 0.735  time: 0.2970  data_time: 0.0245  lr: 0.00072852  max_mem: 6588M
[12/10 23:30:24 d2.utils.events]:  eta: 0:12:26  iter: 7479  total_loss: 2.193  loss_sem_seg: 0.8431  loss_center: 0.5458  loss_offset: 0.6928  time: 0.2970  data_time: 0.0255  lr: 0.00072336  max_mem: 6588M
[12/10 23:30:30 d2.utils.events]:  eta: 0:12:20  iter: 7499  total_loss: 2.361  loss_sem_seg: 0.8832  loss_center: 0.5422  loss_offset: 0.7227  time: 0.2970  data_time: 0.0274  lr: 0.00071819  max_mem: 6588M
[12/10 23:30:36 d2.utils.events]:  eta: 0:12:14  iter: 7519  total_loss: 2.36  loss_sem_seg: 0.9109  loss_center: 0.6247  loss_offset: 0.7695  time: 0.2970  data_time: 0.0266  lr: 0.00071302  max_mem: 6588M
[12/10 23:30:42 d2.utils.events]:  eta: 0:12:08  iter: 7539  total_loss: 2.278  loss_sem_seg: 0.9418  loss_center: 0.4934  loss_offset: 0.6483  time: 0.2970  data_time: 0.0258  lr: 0.00070785  max_mem: 6588M
[12/10 23:30:48 d2.utils.events]:  eta: 0:12:03  iter: 7559  total_loss: 2.34  loss_sem_seg: 0.904  loss_center: 0.6806  loss_offset: 0.7033  time: 0.2970  data_time: 0.0249  lr: 0.00070267  max_mem: 6588M
[12/10 23:30:54 d2.utils.events]:  eta: 0:11:57  iter: 7579  total_loss: 2.213  loss_sem_seg: 1.053  loss_center: 0.4639  loss_offset: 0.7133  time: 0.2970  data_time: 0.0269  lr: 0.00069749  max_mem: 6588M
[12/10 23:31:00 d2.utils.events]:  eta: 0:11:51  iter: 7599  total_loss: 2.095  loss_sem_seg: 0.842  loss_center: 0.6151  loss_offset: 0.594  time: 0.2970  data_time: 0.0279  lr: 0.0006923  max_mem: 6588M
[12/10 23:31:06 d2.utils.events]:  eta: 0:11:45  iter: 7619  total_loss: 2.166  loss_sem_seg: 0.8905  loss_center: 0.4992  loss_offset: 0.6087  time: 0.2970  data_time: 0.0252  lr: 0.00068711  max_mem: 6588M
[12/10 23:31:12 d2.utils.events]:  eta: 0:11:39  iter: 7639  total_loss: 2.135  loss_sem_seg: 0.8086  loss_center: 0.6316  loss_offset: 0.7286  time: 0.2970  data_time: 0.0258  lr: 0.00068191  max_mem: 6588M
[12/10 23:31:18 d2.utils.events]:  eta: 0:11:33  iter: 7659  total_loss: 2.012  loss_sem_seg: 0.7114  loss_center: 0.5587  loss_offset: 0.6472  time: 0.2970  data_time: 0.0265  lr: 0.00067671  max_mem: 6588M
[12/10 23:31:24 d2.utils.events]:  eta: 0:11:27  iter: 7679  total_loss: 2.13  loss_sem_seg: 0.7655  loss_center: 0.535  loss_offset: 0.7607  time: 0.2970  data_time: 0.0276  lr: 0.0006715  max_mem: 6588M
[12/10 23:31:30 d2.utils.events]:  eta: 0:11:22  iter: 7699  total_loss: 2.238  loss_sem_seg: 0.8103  loss_center: 0.7128  loss_offset: 0.6695  time: 0.2970  data_time: 0.0254  lr: 0.00066629  max_mem: 6588M
[12/10 23:31:36 d2.utils.events]:  eta: 0:11:16  iter: 7719  total_loss: 2.363  loss_sem_seg: 1  loss_center: 0.5425  loss_offset: 0.682  time: 0.2970  data_time: 0.0246  lr: 0.00066108  max_mem: 6588M
[12/10 23:31:42 d2.utils.events]:  eta: 0:11:10  iter: 7739  total_loss: 2.087  loss_sem_seg: 0.8424  loss_center: 0.6171  loss_offset: 0.6154  time: 0.2970  data_time: 0.0250  lr: 0.00065586  max_mem: 6588M
[12/10 23:31:48 d2.utils.events]:  eta: 0:11:04  iter: 7759  total_loss: 2.291  loss_sem_seg: 0.9304  loss_center: 0.5876  loss_offset: 0.698  time: 0.2970  data_time: 0.0262  lr: 0.00065064  max_mem: 6588M
[12/10 23:31:54 d2.utils.events]:  eta: 0:10:58  iter: 7779  total_loss: 1.995  loss_sem_seg: 0.8338  loss_center: 0.5742  loss_offset: 0.5526  time: 0.2970  data_time: 0.0269  lr: 0.00064541  max_mem: 6588M
[12/10 23:32:00 d2.utils.events]:  eta: 0:10:52  iter: 7799  total_loss: 2.139  loss_sem_seg: 0.753  loss_center: 0.5981  loss_offset: 0.6515  time: 0.2970  data_time: 0.0259  lr: 0.00064017  max_mem: 6588M
[12/10 23:32:06 d2.utils.events]:  eta: 0:10:46  iter: 7819  total_loss: 2.243  loss_sem_seg: 0.8825  loss_center: 0.6354  loss_offset: 0.7165  time: 0.2970  data_time: 0.0254  lr: 0.00063494  max_mem: 6588M
[12/10 23:32:12 d2.utils.events]:  eta: 0:10:41  iter: 7839  total_loss: 2.326  loss_sem_seg: 0.9982  loss_center: 0.4666  loss_offset: 0.675  time: 0.2970  data_time: 0.0263  lr: 0.00062969  max_mem: 6588M
[12/10 23:32:18 d2.utils.events]:  eta: 0:10:35  iter: 7859  total_loss: 2.365  loss_sem_seg: 1.036  loss_center: 0.5754  loss_offset: 0.6907  time: 0.2970  data_time: 0.0255  lr: 0.00062445  max_mem: 6588M
[12/10 23:32:24 d2.utils.events]:  eta: 0:10:29  iter: 7879  total_loss: 2.201  loss_sem_seg: 0.9349  loss_center: 0.5341  loss_offset: 0.6873  time: 0.2970  data_time: 0.0280  lr: 0.00061919  max_mem: 6588M
[12/10 23:32:30 d2.utils.events]:  eta: 0:10:23  iter: 7899  total_loss: 2.037  loss_sem_seg: 0.8086  loss_center: 0.4881  loss_offset: 0.6472  time: 0.2970  data_time: 0.0257  lr: 0.00061394  max_mem: 6588M
[12/10 23:32:36 d2.utils.events]:  eta: 0:10:17  iter: 7919  total_loss: 2.238  loss_sem_seg: 0.927  loss_center: 0.5773  loss_offset: 0.7118  time: 0.2971  data_time: 0.0272  lr: 0.00060867  max_mem: 6588M
[12/10 23:32:42 d2.utils.events]:  eta: 0:10:11  iter: 7939  total_loss: 2.183  loss_sem_seg: 0.6872  loss_center: 0.6066  loss_offset: 0.7156  time: 0.2971  data_time: 0.0243  lr: 0.00060341  max_mem: 6588M
[12/10 23:32:48 d2.utils.events]:  eta: 0:10:05  iter: 7959  total_loss: 2.33  loss_sem_seg: 0.99  loss_center: 0.6283  loss_offset: 0.7352  time: 0.2971  data_time: 0.0264  lr: 0.00059813  max_mem: 6588M
[12/10 23:32:54 d2.utils.events]:  eta: 0:10:00  iter: 7979  total_loss: 2.268  loss_sem_seg: 0.9175  loss_center: 0.5101  loss_offset: 0.7366  time: 0.2971  data_time: 0.0274  lr: 0.00059286  max_mem: 6588M
[12/10 23:33:00 d2.utils.events]:  eta: 0:09:54  iter: 7999  total_loss: 2.286  loss_sem_seg: 0.9577  loss_center: 0.6134  loss_offset: 0.677  time: 0.2971  data_time: 0.0267  lr: 0.00058757  max_mem: 6588M
[12/10 23:33:06 d2.utils.events]:  eta: 0:09:48  iter: 8019  total_loss: 2.261  loss_sem_seg: 1.111  loss_center: 0.4802  loss_offset: 0.74  time: 0.2971  data_time: 0.0267  lr: 0.00058229  max_mem: 6588M
[12/10 23:33:12 d2.utils.events]:  eta: 0:09:42  iter: 8039  total_loss: 2.593  loss_sem_seg: 1.074  loss_center: 0.5484  loss_offset: 0.7477  time: 0.2971  data_time: 0.0275  lr: 0.00057699  max_mem: 6588M
[12/10 23:33:18 d2.utils.events]:  eta: 0:09:36  iter: 8059  total_loss: 2.017  loss_sem_seg: 0.8  loss_center: 0.4376  loss_offset: 0.7732  time: 0.2971  data_time: 0.0267  lr: 0.00057169  max_mem: 6588M
[12/10 23:33:24 d2.utils.events]:  eta: 0:09:30  iter: 8079  total_loss: 2.191  loss_sem_seg: 0.8268  loss_center: 0.5474  loss_offset: 0.6659  time: 0.2971  data_time: 0.0253  lr: 0.00056639  max_mem: 6588M
[12/10 23:33:30 d2.utils.events]:  eta: 0:09:24  iter: 8099  total_loss: 2.163  loss_sem_seg: 0.876  loss_center: 0.5019  loss_offset: 0.6884  time: 0.2971  data_time: 0.0282  lr: 0.00056108  max_mem: 6588M
[12/10 23:33:36 d2.utils.events]:  eta: 0:09:19  iter: 8119  total_loss: 2.153  loss_sem_seg: 0.8135  loss_center: 0.5718  loss_offset: 0.6743  time: 0.2971  data_time: 0.0253  lr: 0.00055576  max_mem: 6588M
[12/10 23:33:42 d2.utils.events]:  eta: 0:09:12  iter: 8139  total_loss: 2.323  loss_sem_seg: 0.9829  loss_center: 0.5768  loss_offset: 0.7318  time: 0.2971  data_time: 0.0253  lr: 0.00055044  max_mem: 6588M
[12/10 23:33:47 d2.utils.events]:  eta: 0:09:06  iter: 8159  total_loss: 2.089  loss_sem_seg: 0.8483  loss_center: 0.5123  loss_offset: 0.6995  time: 0.2971  data_time: 0.0258  lr: 0.00054512  max_mem: 6588M
[12/10 23:33:53 d2.utils.events]:  eta: 0:09:00  iter: 8179  total_loss: 1.928  loss_sem_seg: 0.8  loss_center: 0.4856  loss_offset: 0.5505  time: 0.2971  data_time: 0.0247  lr: 0.00053978  max_mem: 6588M
[12/10 23:33:59 d2.utils.events]:  eta: 0:08:54  iter: 8199  total_loss: 2.207  loss_sem_seg: 0.8279  loss_center: 0.6903  loss_offset: 0.6251  time: 0.2971  data_time: 0.0232  lr: 0.00053444  max_mem: 6588M
[12/10 23:34:05 d2.utils.events]:  eta: 0:08:48  iter: 8219  total_loss: 1.994  loss_sem_seg: 0.8201  loss_center: 0.5564  loss_offset: 0.6197  time: 0.2971  data_time: 0.0258  lr: 0.0005291  max_mem: 6588M
[12/10 23:34:11 d2.utils.events]:  eta: 0:08:42  iter: 8239  total_loss: 2.185  loss_sem_seg: 0.962  loss_center: 0.624  loss_offset: 0.5635  time: 0.2971  data_time: 0.0239  lr: 0.00052375  max_mem: 6588M
[12/10 23:34:17 d2.utils.events]:  eta: 0:08:36  iter: 8259  total_loss: 1.995  loss_sem_seg: 0.8415  loss_center: 0.4823  loss_offset: 0.6232  time: 0.2971  data_time: 0.0244  lr: 0.00051839  max_mem: 6588M
[12/10 23:34:23 d2.utils.events]:  eta: 0:08:30  iter: 8279  total_loss: 2.032  loss_sem_seg: 0.8835  loss_center: 0.4614  loss_offset: 0.6551  time: 0.2970  data_time: 0.0259  lr: 0.00051303  max_mem: 6588M
[12/10 23:34:29 d2.utils.events]:  eta: 0:08:24  iter: 8299  total_loss: 2.318  loss_sem_seg: 1.093  loss_center: 0.5426  loss_offset: 0.6879  time: 0.2970  data_time: 0.0251  lr: 0.00050766  max_mem: 6588M
[12/10 23:34:35 d2.utils.events]:  eta: 0:08:18  iter: 8319  total_loss: 1.935  loss_sem_seg: 0.7458  loss_center: 0.4827  loss_offset: 0.6122  time: 0.2970  data_time: 0.0261  lr: 0.00050229  max_mem: 6588M
[12/10 23:34:41 d2.utils.events]:  eta: 0:08:12  iter: 8339  total_loss: 2.264  loss_sem_seg: 0.9852  loss_center: 0.5183  loss_offset: 0.6792  time: 0.2971  data_time: 0.0261  lr: 0.0004969  max_mem: 6588M
[12/10 23:34:47 d2.utils.events]:  eta: 0:08:06  iter: 8359  total_loss: 2.456  loss_sem_seg: 0.9415  loss_center: 0.7026  loss_offset: 0.7032  time: 0.2970  data_time: 0.0239  lr: 0.00049152  max_mem: 6588M
[12/10 23:34:53 d2.utils.events]:  eta: 0:08:00  iter: 8379  total_loss: 2.054  loss_sem_seg: 0.7709  loss_center: 0.5518  loss_offset: 0.6575  time: 0.2971  data_time: 0.0263  lr: 0.00048612  max_mem: 6588M
[12/10 23:34:59 d2.utils.events]:  eta: 0:07:54  iter: 8399  total_loss: 2.186  loss_sem_seg: 0.8585  loss_center: 0.583  loss_offset: 0.6838  time: 0.2970  data_time: 0.0251  lr: 0.00048072  max_mem: 6588M
[12/10 23:35:04 d2.utils.events]:  eta: 0:07:48  iter: 8419  total_loss: 2.102  loss_sem_seg: 0.7727  loss_center: 0.5365  loss_offset: 0.6744  time: 0.2970  data_time: 0.0269  lr: 0.00047531  max_mem: 6588M
[12/10 23:35:10 d2.utils.events]:  eta: 0:07:42  iter: 8439  total_loss: 1.984  loss_sem_seg: 0.9267  loss_center: 0.5053  loss_offset: 0.6421  time: 0.2971  data_time: 0.0269  lr: 0.0004699  max_mem: 6588M
[12/10 23:35:16 d2.utils.events]:  eta: 0:07:36  iter: 8459  total_loss: 2.213  loss_sem_seg: 0.9526  loss_center: 0.6522  loss_offset: 0.6953  time: 0.2970  data_time: 0.0248  lr: 0.00046448  max_mem: 6588M
[12/10 23:35:22 d2.utils.events]:  eta: 0:07:30  iter: 8479  total_loss: 2.127  loss_sem_seg: 0.9287  loss_center: 0.5639  loss_offset: 0.6458  time: 0.2971  data_time: 0.0257  lr: 0.00045905  max_mem: 6588M
[12/10 23:35:28 d2.utils.events]:  eta: 0:07:24  iter: 8499  total_loss: 1.916  loss_sem_seg: 0.8106  loss_center: 0.5379  loss_offset: 0.5572  time: 0.2971  data_time: 0.0251  lr: 0.00045361  max_mem: 6588M
[12/10 23:35:34 d2.utils.events]:  eta: 0:07:18  iter: 8519  total_loss: 2.061  loss_sem_seg: 0.8139  loss_center: 0.6236  loss_offset: 0.6517  time: 0.2970  data_time: 0.0239  lr: 0.00044817  max_mem: 6588M
[12/10 23:35:40 d2.utils.events]:  eta: 0:07:12  iter: 8539  total_loss: 2.192  loss_sem_seg: 0.8738  loss_center: 0.5743  loss_offset: 0.766  time: 0.2971  data_time: 0.0260  lr: 0.00044272  max_mem: 6588M
[12/10 23:35:46 d2.utils.events]:  eta: 0:07:06  iter: 8559  total_loss: 1.984  loss_sem_seg: 0.9382  loss_center: 0.554  loss_offset: 0.598  time: 0.2970  data_time: 0.0246  lr: 0.00043726  max_mem: 6588M
[12/10 23:35:52 d2.utils.events]:  eta: 0:07:00  iter: 8579  total_loss: 2.094  loss_sem_seg: 0.8105  loss_center: 0.5986  loss_offset: 0.5998  time: 0.2970  data_time: 0.0257  lr: 0.00043179  max_mem: 6588M
[12/10 23:35:58 d2.utils.events]:  eta: 0:06:54  iter: 8599  total_loss: 2.233  loss_sem_seg: 0.9095  loss_center: 0.5446  loss_offset: 0.7604  time: 0.2970  data_time: 0.0249  lr: 0.00042632  max_mem: 6588M
[12/10 23:36:04 d2.utils.events]:  eta: 0:06:48  iter: 8619  total_loss: 2.152  loss_sem_seg: 0.8428  loss_center: 0.6521  loss_offset: 0.7164  time: 0.2970  data_time: 0.0237  lr: 0.00042084  max_mem: 6588M
[12/10 23:36:10 d2.utils.events]:  eta: 0:06:42  iter: 8639  total_loss: 2.307  loss_sem_seg: 1.025  loss_center: 0.6665  loss_offset: 0.6078  time: 0.2970  data_time: 0.0258  lr: 0.00041535  max_mem: 6588M
[12/10 23:36:16 d2.utils.events]:  eta: 0:06:36  iter: 8659  total_loss: 2.169  loss_sem_seg: 1.04  loss_center: 0.4516  loss_offset: 0.6119  time: 0.2970  data_time: 0.0257  lr: 0.00040985  max_mem: 6588M
[12/10 23:36:22 d2.utils.events]:  eta: 0:06:30  iter: 8679  total_loss: 2.108  loss_sem_seg: 0.9305  loss_center: 0.5861  loss_offset: 0.7234  time: 0.2970  data_time: 0.0245  lr: 0.00040435  max_mem: 6588M
[12/10 23:36:28 d2.utils.events]:  eta: 0:06:24  iter: 8699  total_loss: 1.934  loss_sem_seg: 0.7754  loss_center: 0.6204  loss_offset: 0.6242  time: 0.2970  data_time: 0.0267  lr: 0.00039883  max_mem: 6588M
[12/10 23:36:34 d2.utils.events]:  eta: 0:06:18  iter: 8719  total_loss: 2.159  loss_sem_seg: 0.847  loss_center: 0.6072  loss_offset: 0.6977  time: 0.2970  data_time: 0.0259  lr: 0.00039331  max_mem: 6588M
[12/10 23:36:40 d2.utils.events]:  eta: 0:06:12  iter: 8739  total_loss: 2.491  loss_sem_seg: 0.9331  loss_center: 0.5933  loss_offset: 0.7751  time: 0.2971  data_time: 0.0267  lr: 0.00038778  max_mem: 6588M
[12/10 23:36:46 d2.utils.events]:  eta: 0:06:06  iter: 8759  total_loss: 2.084  loss_sem_seg: 0.8998  loss_center: 0.6778  loss_offset: 0.6706  time: 0.2970  data_time: 0.0252  lr: 0.00038224  max_mem: 6588M
[12/10 23:36:52 d2.utils.events]:  eta: 0:06:00  iter: 8779  total_loss: 2.213  loss_sem_seg: 1.034  loss_center: 0.5612  loss_offset: 0.6225  time: 0.2971  data_time: 0.0260  lr: 0.00037669  max_mem: 6588M
[12/10 23:36:57 d2.utils.events]:  eta: 0:05:54  iter: 8799  total_loss: 2.2  loss_sem_seg: 0.8168  loss_center: 0.5749  loss_offset: 0.7708  time: 0.2970  data_time: 0.0232  lr: 0.00037113  max_mem: 6588M
[12/10 23:37:03 d2.utils.events]:  eta: 0:05:48  iter: 8819  total_loss: 2.106  loss_sem_seg: 0.7424  loss_center: 0.5431  loss_offset: 0.7535  time: 0.2970  data_time: 0.0258  lr: 0.00036557  max_mem: 6588M
[12/10 23:37:09 d2.utils.events]:  eta: 0:05:42  iter: 8839  total_loss: 2.219  loss_sem_seg: 0.9306  loss_center: 0.5437  loss_offset: 0.6617  time: 0.2970  data_time: 0.0252  lr: 0.00035999  max_mem: 6588M
[12/10 23:37:15 d2.utils.events]:  eta: 0:05:36  iter: 8859  total_loss: 2.088  loss_sem_seg: 0.78  loss_center: 0.4838  loss_offset: 0.7771  time: 0.2970  data_time: 0.0246  lr: 0.0003544  max_mem: 6588M
[12/10 23:37:21 d2.utils.events]:  eta: 0:05:30  iter: 8879  total_loss: 2.182  loss_sem_seg: 0.8497  loss_center: 0.5141  loss_offset: 0.5964  time: 0.2970  data_time: 0.0269  lr: 0.00034881  max_mem: 6588M
[12/10 23:37:27 d2.utils.events]:  eta: 0:05:24  iter: 8899  total_loss: 2.097  loss_sem_seg: 0.8687  loss_center: 0.5958  loss_offset: 0.6498  time: 0.2970  data_time: 0.0242  lr: 0.0003432  max_mem: 6588M
[12/10 23:37:33 d2.utils.events]:  eta: 0:05:19  iter: 8919  total_loss: 2.222  loss_sem_seg: 0.9132  loss_center: 0.6221  loss_offset: 0.6285  time: 0.2970  data_time: 0.0244  lr: 0.00033758  max_mem: 6588M
[12/10 23:37:39 d2.utils.events]:  eta: 0:05:13  iter: 8939  total_loss: 2.186  loss_sem_seg: 0.892  loss_center: 0.5344  loss_offset: 0.6486  time: 0.2970  data_time: 0.0249  lr: 0.00033196  max_mem: 6588M
[12/10 23:37:45 d2.utils.events]:  eta: 0:05:07  iter: 8959  total_loss: 2.027  loss_sem_seg: 0.7894  loss_center: 0.4925  loss_offset: 0.6726  time: 0.2970  data_time: 0.0261  lr: 0.00032632  max_mem: 6588M
[12/10 23:37:51 d2.utils.events]:  eta: 0:05:01  iter: 8979  total_loss: 2.162  loss_sem_seg: 0.9396  loss_center: 0.5325  loss_offset: 0.7111  time: 0.2970  data_time: 0.0246  lr: 0.00032067  max_mem: 6588M
[12/10 23:37:57 d2.utils.events]:  eta: 0:04:55  iter: 8999  total_loss: 2.217  loss_sem_seg: 0.8754  loss_center: 0.5898  loss_offset: 0.6559  time: 0.2970  data_time: 0.0256  lr: 0.00031501  max_mem: 6588M
[12/10 23:38:03 d2.utils.events]:  eta: 0:04:49  iter: 9019  total_loss: 1.988  loss_sem_seg: 0.8012  loss_center: 0.5487  loss_offset: 0.6419  time: 0.2970  data_time: 0.0241  lr: 0.00030934  max_mem: 6588M
[12/10 23:38:09 d2.utils.events]:  eta: 0:04:43  iter: 9039  total_loss: 2.068  loss_sem_seg: 0.8357  loss_center: 0.5416  loss_offset: 0.6479  time: 0.2970  data_time: 0.0254  lr: 0.00030366  max_mem: 6588M
[12/10 23:38:15 d2.utils.events]:  eta: 0:04:37  iter: 9059  total_loss: 2.033  loss_sem_seg: 0.7763  loss_center: 0.4971  loss_offset: 0.6235  time: 0.2970  data_time: 0.0258  lr: 0.00029797  max_mem: 6588M
[12/10 23:38:21 d2.utils.events]:  eta: 0:04:31  iter: 9079  total_loss: 2.185  loss_sem_seg: 0.8336  loss_center: 0.5383  loss_offset: 0.6753  time: 0.2970  data_time: 0.0252  lr: 0.00029226  max_mem: 6588M
[12/10 23:38:26 d2.utils.events]:  eta: 0:04:25  iter: 9099  total_loss: 2.129  loss_sem_seg: 0.8563  loss_center: 0.4553  loss_offset: 0.6028  time: 0.2970  data_time: 0.0230  lr: 0.00028654  max_mem: 6588M
[12/10 23:38:32 d2.utils.events]:  eta: 0:04:19  iter: 9119  total_loss: 1.937  loss_sem_seg: 0.8002  loss_center: 0.3874  loss_offset: 0.6108  time: 0.2970  data_time: 0.0243  lr: 0.00028081  max_mem: 6588M
[12/10 23:38:38 d2.utils.events]:  eta: 0:04:13  iter: 9139  total_loss: 2.241  loss_sem_seg: 0.8817  loss_center: 0.5499  loss_offset: 0.6734  time: 0.2970  data_time: 0.0226  lr: 0.00027507  max_mem: 6588M
[12/10 23:38:44 d2.utils.events]:  eta: 0:04:07  iter: 9159  total_loss: 2.083  loss_sem_seg: 0.8933  loss_center: 0.5515  loss_offset: 0.6007  time: 0.2970  data_time: 0.0239  lr: 0.00026931  max_mem: 6588M
[12/10 23:38:50 d2.utils.events]:  eta: 0:04:01  iter: 9179  total_loss: 1.953  loss_sem_seg: 0.8067  loss_center: 0.5086  loss_offset: 0.5366  time: 0.2970  data_time: 0.0249  lr: 0.00026354  max_mem: 6588M
[12/10 23:38:56 d2.utils.events]:  eta: 0:03:55  iter: 9199  total_loss: 2.239  loss_sem_seg: 0.9942  loss_center: 0.427  loss_offset: 0.6697  time: 0.2970  data_time: 0.0258  lr: 0.00025776  max_mem: 6588M
[12/10 23:39:02 d2.utils.events]:  eta: 0:03:50  iter: 9219  total_loss: 2.32  loss_sem_seg: 0.9394  loss_center: 0.6521  loss_offset: 0.6721  time: 0.2970  data_time: 0.0252  lr: 0.00025196  max_mem: 6588M
[12/10 23:39:08 d2.utils.events]:  eta: 0:03:44  iter: 9239  total_loss: 2.292  loss_sem_seg: 0.8494  loss_center: 0.6661  loss_offset: 0.645  time: 0.2970  data_time: 0.0238  lr: 0.00024614  max_mem: 6588M
[12/10 23:39:14 d2.utils.events]:  eta: 0:03:38  iter: 9259  total_loss: 2.16  loss_sem_seg: 0.8367  loss_center: 0.5713  loss_offset: 0.6924  time: 0.2970  data_time: 0.0250  lr: 0.00024031  max_mem: 6588M
[12/10 23:39:20 d2.utils.events]:  eta: 0:03:32  iter: 9279  total_loss: 2.319  loss_sem_seg: 0.8269  loss_center: 0.6578  loss_offset: 0.6882  time: 0.2970  data_time: 0.0236  lr: 0.00023447  max_mem: 6588M
[12/10 23:39:26 d2.utils.events]:  eta: 0:03:26  iter: 9299  total_loss: 2.207  loss_sem_seg: 0.8939  loss_center: 0.5516  loss_offset: 0.6385  time: 0.2970  data_time: 0.0247  lr: 0.00022861  max_mem: 6588M
[12/10 23:39:31 d2.utils.events]:  eta: 0:03:20  iter: 9319  total_loss: 2.202  loss_sem_seg: 0.9015  loss_center: 0.5247  loss_offset: 0.6693  time: 0.2970  data_time: 0.0253  lr: 0.00022273  max_mem: 6588M
[12/10 23:39:37 d2.utils.events]:  eta: 0:03:14  iter: 9339  total_loss: 2.059  loss_sem_seg: 0.7817  loss_center: 0.6551  loss_offset: 0.5754  time: 0.2970  data_time: 0.0250  lr: 0.00021683  max_mem: 6588M
[12/10 23:39:43 d2.utils.events]:  eta: 0:03:08  iter: 9359  total_loss: 2.162  loss_sem_seg: 0.8617  loss_center: 0.5985  loss_offset: 0.7079  time: 0.2970  data_time: 0.0262  lr: 0.00021092  max_mem: 6588M
[12/10 23:39:49 d2.utils.events]:  eta: 0:03:02  iter: 9379  total_loss: 2.111  loss_sem_seg: 0.7359  loss_center: 0.594  loss_offset: 0.685  time: 0.2970  data_time: 0.0254  lr: 0.00020499  max_mem: 6588M
[12/10 23:39:55 d2.utils.events]:  eta: 0:02:56  iter: 9399  total_loss: 2.249  loss_sem_seg: 0.9181  loss_center: 0.6169  loss_offset: 0.7024  time: 0.2970  data_time: 0.0242  lr: 0.00019903  max_mem: 6588M
[12/10 23:40:01 d2.utils.events]:  eta: 0:02:51  iter: 9419  total_loss: 2.253  loss_sem_seg: 0.8799  loss_center: 0.6269  loss_offset: 0.7349  time: 0.2970  data_time: 0.0273  lr: 0.00019306  max_mem: 6588M
[12/10 23:40:07 d2.utils.events]:  eta: 0:02:45  iter: 9439  total_loss: 2.222  loss_sem_seg: 0.9561  loss_center: 0.5097  loss_offset: 0.6378  time: 0.2969  data_time: 0.0225  lr: 0.00018707  max_mem: 6588M
[12/10 23:40:13 d2.utils.events]:  eta: 0:02:39  iter: 9459  total_loss: 2.153  loss_sem_seg: 0.8381  loss_center: 0.5535  loss_offset: 0.6292  time: 0.2969  data_time: 0.0247  lr: 0.00018106  max_mem: 6588M
[12/10 23:40:19 d2.utils.events]:  eta: 0:02:33  iter: 9479  total_loss: 1.868  loss_sem_seg: 0.6917  loss_center: 0.498  loss_offset: 0.5788  time: 0.2969  data_time: 0.0245  lr: 0.00017502  max_mem: 6588M
[12/10 23:40:25 d2.utils.events]:  eta: 0:02:27  iter: 9499  total_loss: 1.999  loss_sem_seg: 0.8059  loss_center: 0.5193  loss_offset: 0.6088  time: 0.2969  data_time: 0.0263  lr: 0.00016896  max_mem: 6588M
[12/10 23:40:31 d2.utils.events]:  eta: 0:02:21  iter: 9519  total_loss: 1.98  loss_sem_seg: 0.7669  loss_center: 0.5449  loss_offset: 0.6316  time: 0.2969  data_time: 0.0255  lr: 0.00016288  max_mem: 6588M
[12/10 23:40:37 d2.utils.events]:  eta: 0:02:15  iter: 9539  total_loss: 2.022  loss_sem_seg: 0.8242  loss_center: 0.5679  loss_offset: 0.5105  time: 0.2969  data_time: 0.0248  lr: 0.00015677  max_mem: 6588M
[12/10 23:40:42 d2.utils.events]:  eta: 0:02:09  iter: 9559  total_loss: 2.325  loss_sem_seg: 0.7903  loss_center: 0.55  loss_offset: 0.7567  time: 0.2969  data_time: 0.0228  lr: 0.00015064  max_mem: 6588M
[12/10 23:40:48 d2.utils.events]:  eta: 0:02:03  iter: 9579  total_loss: 2.031  loss_sem_seg: 0.7657  loss_center: 0.687  loss_offset: 0.5835  time: 0.2969  data_time: 0.0250  lr: 0.00014448  max_mem: 6588M
[12/10 23:40:54 d2.utils.events]:  eta: 0:01:57  iter: 9599  total_loss: 2.085  loss_sem_seg: 0.8562  loss_center: 0.625  loss_offset: 0.6394  time: 0.2969  data_time: 0.0259  lr: 0.00013828  max_mem: 6588M
[12/10 23:41:00 d2.utils.events]:  eta: 0:01:51  iter: 9619  total_loss: 2.091  loss_sem_seg: 0.6795  loss_center: 0.6302  loss_offset: 0.6518  time: 0.2969  data_time: 0.0245  lr: 0.00013206  max_mem: 6588M
[12/10 23:41:06 d2.utils.events]:  eta: 0:01:46  iter: 9639  total_loss: 2.012  loss_sem_seg: 0.8662  loss_center: 0.652  loss_offset: 0.5614  time: 0.2969  data_time: 0.0252  lr: 0.0001258  max_mem: 6588M
[12/10 23:41:12 d2.utils.events]:  eta: 0:01:40  iter: 9659  total_loss: 1.924  loss_sem_seg: 0.7935  loss_center: 0.5435  loss_offset: 0.5998  time: 0.2969  data_time: 0.0241  lr: 0.00011951  max_mem: 6588M
[12/10 23:41:18 d2.utils.events]:  eta: 0:01:34  iter: 9679  total_loss: 1.988  loss_sem_seg: 0.7556  loss_center: 0.5472  loss_offset: 0.636  time: 0.2969  data_time: 0.0237  lr: 0.00011319  max_mem: 6588M
[12/10 23:41:24 d2.utils.events]:  eta: 0:01:28  iter: 9699  total_loss: 2.263  loss_sem_seg: 0.6504  loss_center: 0.682  loss_offset: 0.7654  time: 0.2969  data_time: 0.0255  lr: 0.00010682  max_mem: 6588M
[12/10 23:41:30 d2.utils.events]:  eta: 0:01:22  iter: 9719  total_loss: 1.995  loss_sem_seg: 0.9101  loss_center: 0.5273  loss_offset: 0.586  time: 0.2969  data_time: 0.0255  lr: 0.00010041  max_mem: 6588M
[12/10 23:41:36 d2.utils.events]:  eta: 0:01:16  iter: 9739  total_loss: 1.977  loss_sem_seg: 0.8976  loss_center: 0.4765  loss_offset: 0.5961  time: 0.2969  data_time: 0.0258  lr: 9.3954e-05  max_mem: 6588M
[12/10 23:41:42 d2.utils.events]:  eta: 0:01:10  iter: 9759  total_loss: 2.023  loss_sem_seg: 0.6532  loss_center: 0.5708  loss_offset: 0.6306  time: 0.2969  data_time: 0.0235  lr: 8.7449e-05  max_mem: 6588M
[12/10 23:41:48 d2.utils.events]:  eta: 0:01:04  iter: 9779  total_loss: 1.888  loss_sem_seg: 0.7326  loss_center: 0.5641  loss_offset: 0.6131  time: 0.2969  data_time: 0.0262  lr: 8.089e-05  max_mem: 6588M
[12/10 23:41:54 d2.utils.events]:  eta: 0:00:58  iter: 9799  total_loss: 2.112  loss_sem_seg: 0.8391  loss_center: 0.5595  loss_offset: 0.6775  time: 0.2969  data_time: 0.0252  lr: 7.4271e-05  max_mem: 6588M
[12/10 23:42:00 d2.utils.events]:  eta: 0:00:53  iter: 9819  total_loss: 2.181  loss_sem_seg: 0.8384  loss_center: 0.6871  loss_offset: 0.6613  time: 0.2969  data_time: 0.0266  lr: 6.7585e-05  max_mem: 6588M
[12/10 23:42:06 d2.utils.events]:  eta: 0:00:47  iter: 9839  total_loss: 2.02  loss_sem_seg: 0.8852  loss_center: 0.6036  loss_offset: 0.6371  time: 0.2969  data_time: 0.0260  lr: 6.0825e-05  max_mem: 6588M
[12/10 23:42:12 d2.utils.events]:  eta: 0:00:41  iter: 9859  total_loss: 2.171  loss_sem_seg: 0.839  loss_center: 0.5508  loss_offset: 0.6343  time: 0.2969  data_time: 0.0257  lr: 5.3981e-05  max_mem: 6588M
[12/10 23:42:18 d2.utils.events]:  eta: 0:00:35  iter: 9879  total_loss: 2.137  loss_sem_seg: 0.8731  loss_center: 0.5166  loss_offset: 0.6415  time: 0.2969  data_time: 0.0243  lr: 4.7038e-05  max_mem: 6588M
[12/10 23:42:23 d2.utils.events]:  eta: 0:00:29  iter: 9899  total_loss: 2.203  loss_sem_seg: 0.8785  loss_center: 0.6226  loss_offset: 0.6646  time: 0.2969  data_time: 0.0239  lr: 3.9979e-05  max_mem: 6588M
[12/10 23:42:29 d2.utils.events]:  eta: 0:00:23  iter: 9919  total_loss: 1.828  loss_sem_seg: 0.6968  loss_center: 0.4129  loss_offset: 0.6202  time: 0.2969  data_time: 0.0255  lr: 3.2778e-05  max_mem: 6588M
[12/10 23:42:35 d2.utils.events]:  eta: 0:00:17  iter: 9939  total_loss: 2.106  loss_sem_seg: 0.908  loss_center: 0.4126  loss_offset: 0.6274  time: 0.2969  data_time: 0.0270  lr: 2.5394e-05  max_mem: 6588M
[12/10 23:42:41 d2.utils.events]:  eta: 0:00:11  iter: 9959  total_loss: 1.985  loss_sem_seg: 0.8675  loss_center: 0.4765  loss_offset: 0.68  time: 0.2969  data_time: 0.0243  lr: 1.776e-05  max_mem: 6588M
[12/10 23:42:47 d2.utils.events]:  eta: 0:00:05  iter: 9979  total_loss: 2.315  loss_sem_seg: 0.8422  loss_center: 0.5168  loss_offset: 0.7695  time: 0.2969  data_time: 0.0255  lr: 9.7261e-06  max_mem: 6588M
[12/10 23:42:53 fvcore.common.checkpoint]: Saving checkpoint to ./output/model_0009999.pth
[12/10 23:42:54 fvcore.common.checkpoint]: Saving checkpoint to ./output/model_final.pth
[12/10 23:42:54 d2.utils.events]:  eta: 0:00:00  iter: 9999  total_loss: 2.15  loss_sem_seg: 0.9046  loss_center: 0.5147  loss_offset: 0.7141  time: 0.2969  data_time: 0.0269  lr: 6.2797e-07  max_mem: 6588M
[12/10 23:42:55 d2.engine.hooks]: Overall training speed: 9998 iterations in 0:49:28 (0.2969 s / it)
[12/10 23:42:55 d2.engine.hooks]: Total training time: 0:49:35 (0:00:07 on hooks)
[12/10 23:42:55 d2.data.dataset_mapper]: [DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(640, 640), max_size=640, sample_style='choice')]
[12/10 23:42:55 d2.data.common]: Serializing the dataset using: <class 'detectron2.data.common.NumpySerializedList'>
[12/10 23:42:55 d2.data.common]: Serializing 5000 elements to byte tensors and concatenating them all ...
[12/10 23:42:56 d2.data.common]: Serialized dataset takes 3.31 MiB
/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:481: UserWarning: This DataLoader will create 10 worker processes in total. Our suggested max number of worker in current system is 8, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.
  cpuset_checked))
[12/10 23:42:56 d2.evaluation.evaluator]: Start inference on 5000 batches
/usr/local/lib/python3.7/dist-packages/torch/functional.py:445: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at  ../aten/src/ATen/native/TensorShape.cpp:2157.)
  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]
[12/10 23:42:58 d2.evaluation.evaluator]: Inference done 11/5000. Dataloading: 0.0012 s/iter. Inference: 0.0636 s/iter. Eval: 0.0346 s/iter. Total: 0.0994 s/iter. ETA=0:08:16
[12/10 23:43:03 d2.evaluation.evaluator]: Inference done 67/5000. Dataloading: 0.0010 s/iter. Inference: 0.0599 s/iter. Eval: 0.0301 s/iter. Total: 0.0910 s/iter. ETA=0:07:28
[12/10 23:43:08 d2.evaluation.evaluator]: Inference done 119/5000. Dataloading: 0.0010 s/iter. Inference: 0.0608 s/iter. Eval: 0.0318 s/iter. Total: 0.0937 s/iter. ETA=0:07:37
[12/10 23:43:13 d2.evaluation.evaluator]: Inference done 170/5000. Dataloading: 0.0011 s/iter. Inference: 0.0617 s/iter. Eval: 0.0326 s/iter. Total: 0.0954 s/iter. ETA=0:07:40
[12/10 23:43:18 d2.evaluation.evaluator]: Inference done 223/5000. Dataloading: 0.0011 s/iter. Inference: 0.0618 s/iter. Eval: 0.0326 s/iter. Total: 0.0956 s/iter. ETA=0:07:36
[12/10 23:43:23 d2.evaluation.evaluator]: Inference done 277/5000. Dataloading: 0.0011 s/iter. Inference: 0.0616 s/iter. Eval: 0.0324 s/iter. Total: 0.0952 s/iter. ETA=0:07:29
[12/10 23:43:28 d2.evaluation.evaluator]: Inference done 326/5000. Dataloading: 0.0011 s/iter. Inference: 0.0628 s/iter. Eval: 0.0325 s/iter. Total: 0.0964 s/iter. ETA=0:07:30
[12/10 23:43:33 d2.evaluation.evaluator]: Inference done 378/5000. Dataloading: 0.0011 s/iter. Inference: 0.0627 s/iter. Eval: 0.0325 s/iter. Total: 0.0964 s/iter. ETA=0:07:25
[12/10 23:43:39 d2.evaluation.evaluator]: Inference done 434/5000. Dataloading: 0.0011 s/iter. Inference: 0.0623 s/iter. Eval: 0.0322 s/iter. Total: 0.0956 s/iter. ETA=0:07:16
[12/10 23:43:44 d2.evaluation.evaluator]: Inference done 490/5000. Dataloading: 0.0011 s/iter. Inference: 0.0619 s/iter. Eval: 0.0320 s/iter. Total: 0.0950 s/iter. ETA=0:07:08
[12/10 23:43:49 d2.evaluation.evaluator]: Inference done 541/5000. Dataloading: 0.0011 s/iter. Inference: 0.0621 s/iter. Eval: 0.0322 s/iter. Total: 0.0954 s/iter. ETA=0:07:05
[12/10 23:43:54 d2.evaluation.evaluator]: Inference done 592/5000. Dataloading: 0.0011 s/iter. Inference: 0.0622 s/iter. Eval: 0.0324 s/iter. Total: 0.0958 s/iter. ETA=0:07:02
[12/10 23:43:59 d2.evaluation.evaluator]: Inference done 643/5000. Dataloading: 0.0011 s/iter. Inference: 0.0624 s/iter. Eval: 0.0325 s/iter. Total: 0.0960 s/iter. ETA=0:06:58
[12/10 23:44:04 d2.evaluation.evaluator]: Inference done 695/5000. Dataloading: 0.0011 s/iter. Inference: 0.0624 s/iter. Eval: 0.0325 s/iter. Total: 0.0960 s/iter. ETA=0:06:53
[12/10 23:44:09 d2.evaluation.evaluator]: Inference done 749/5000. Dataloading: 0.0011 s/iter. Inference: 0.0622 s/iter. Eval: 0.0324 s/iter. Total: 0.0958 s/iter. ETA=0:06:47
[12/10 23:44:14 d2.evaluation.evaluator]: Inference done 802/5000. Dataloading: 0.0011 s/iter. Inference: 0.0621 s/iter. Eval: 0.0324 s/iter. Total: 0.0957 s/iter. ETA=0:06:41
[12/10 23:44:19 d2.evaluation.evaluator]: Inference done 858/5000. Dataloading: 0.0011 s/iter. Inference: 0.0619 s/iter. Eval: 0.0323 s/iter. Total: 0.0954 s/iter. ETA=0:06:34
[12/10 23:44:24 d2.evaluation.evaluator]: Inference done 914/5000. Dataloading: 0.0011 s/iter. Inference: 0.0617 s/iter. Eval: 0.0322 s/iter. Total: 0.0950 s/iter. ETA=0:06:28
[12/10 23:44:29 d2.evaluation.evaluator]: Inference done 968/5000. Dataloading: 0.0011 s/iter. Inference: 0.0616 s/iter. Eval: 0.0321 s/iter. Total: 0.0949 s/iter. ETA=0:06:22
[12/10 23:44:34 d2.evaluation.evaluator]: Inference done 1021/5000. Dataloading: 0.0011 s/iter. Inference: 0.0616 s/iter. Eval: 0.0321 s/iter. Total: 0.0949 s/iter. ETA=0:06:17
[12/10 23:44:39 d2.evaluation.evaluator]: Inference done 1072/5000. Dataloading: 0.0011 s/iter. Inference: 0.0618 s/iter. Eval: 0.0321 s/iter. Total: 0.0951 s/iter. ETA=0:06:13
[12/10 23:44:44 d2.evaluation.evaluator]: Inference done 1127/5000. Dataloading: 0.0011 s/iter. Inference: 0.0617 s/iter. Eval: 0.0321 s/iter. Total: 0.0949 s/iter. ETA=0:06:07
[12/10 23:44:49 d2.evaluation.evaluator]: Inference done 1180/5000. Dataloading: 0.0011 s/iter. Inference: 0.0617 s/iter. Eval: 0.0321 s/iter. Total: 0.0949 s/iter. ETA=0:06:02
[12/10 23:44:54 d2.evaluation.evaluator]: Inference done 1231/5000. Dataloading: 0.0011 s/iter. Inference: 0.0619 s/iter. Eval: 0.0321 s/iter. Total: 0.0951 s/iter. ETA=0:05:58
[12/10 23:44:59 d2.evaluation.evaluator]: Inference done 1281/5000. Dataloading: 0.0011 s/iter. Inference: 0.0620 s/iter. Eval: 0.0322 s/iter. Total: 0.0953 s/iter. ETA=0:05:54
[12/10 23:45:04 d2.evaluation.evaluator]: Inference done 1334/5000. Dataloading: 0.0011 s/iter. Inference: 0.0620 s/iter. Eval: 0.0322 s/iter. Total: 0.0954 s/iter. ETA=0:05:49
[12/10 23:45:09 d2.evaluation.evaluator]: Inference done 1390/5000. Dataloading: 0.0011 s/iter. Inference: 0.0619 s/iter. Eval: 0.0321 s/iter. Total: 0.0952 s/iter. ETA=0:05:43
[12/10 23:45:14 d2.evaluation.evaluator]: Inference done 1444/5000. Dataloading: 0.0011 s/iter. Inference: 0.0618 s/iter. Eval: 0.0321 s/iter. Total: 0.0951 s/iter. ETA=0:05:38
[12/10 23:45:19 d2.evaluation.evaluator]: Inference done 1498/5000. Dataloading: 0.0011 s/iter. Inference: 0.0617 s/iter. Eval: 0.0321 s/iter. Total: 0.0950 s/iter. ETA=0:05:32
[12/10 23:45:24 d2.evaluation.evaluator]: Inference done 1550/5000. Dataloading: 0.0011 s/iter. Inference: 0.0618 s/iter. Eval: 0.0322 s/iter. Total: 0.0951 s/iter. ETA=0:05:27
[12/10 23:45:29 d2.evaluation.evaluator]: Inference done 1599/5000. Dataloading: 0.0011 s/iter. Inference: 0.0619 s/iter. Eval: 0.0322 s/iter. Total: 0.0953 s/iter. ETA=0:05:24
[12/10 23:45:34 d2.evaluation.evaluator]: Inference done 1654/5000. Dataloading: 0.0011 s/iter. Inference: 0.0618 s/iter. Eval: 0.0322 s/iter. Total: 0.0952 s/iter. ETA=0:05:18
[12/10 23:45:39 d2.evaluation.evaluator]: Inference done 1707/5000. Dataloading: 0.0011 s/iter. Inference: 0.0618 s/iter. Eval: 0.0322 s/iter. Total: 0.0952 s/iter. ETA=0:05:13
[12/10 23:45:45 d2.evaluation.evaluator]: Inference done 1761/5000. Dataloading: 0.0011 s/iter. Inference: 0.0618 s/iter. Eval: 0.0322 s/iter. Total: 0.0951 s/iter. ETA=0:05:08
[12/10 23:45:50 d2.evaluation.evaluator]: Inference done 1815/5000. Dataloading: 0.0011 s/iter. Inference: 0.0617 s/iter. Eval: 0.0321 s/iter. Total: 0.0950 s/iter. ETA=0:05:02
[12/10 23:45:55 d2.evaluation.evaluator]: Inference done 1868/5000. Dataloading: 0.0011 s/iter. Inference: 0.0617 s/iter. Eval: 0.0322 s/iter. Total: 0.0951 s/iter. ETA=0:04:57
[12/10 23:46:00 d2.evaluation.evaluator]: Inference done 1921/5000. Dataloading: 0.0011 s/iter. Inference: 0.0618 s/iter. Eval: 0.0322 s/iter. Total: 0.0951 s/iter. ETA=0:04:52
[12/10 23:46:05 d2.evaluation.evaluator]: Inference done 1976/5000. Dataloading: 0.0011 s/iter. Inference: 0.0617 s/iter. Eval: 0.0321 s/iter. Total: 0.0950 s/iter. ETA=0:04:47
[12/10 23:46:10 d2.evaluation.evaluator]: Inference done 2029/5000. Dataloading: 0.0011 s/iter. Inference: 0.0617 s/iter. Eval: 0.0321 s/iter. Total: 0.0950 s/iter. ETA=0:04:42
[12/10 23:46:15 d2.evaluation.evaluator]: Inference done 2084/5000. Dataloading: 0.0011 s/iter. Inference: 0.0617 s/iter. Eval: 0.0321 s/iter. Total: 0.0949 s/iter. ETA=0:04:36
[12/10 23:46:20 d2.evaluation.evaluator]: Inference done 2139/5000. Dataloading: 0.0011 s/iter. Inference: 0.0616 s/iter. Eval: 0.0321 s/iter. Total: 0.0948 s/iter. ETA=0:04:31
[12/10 23:46:25 d2.evaluation.evaluator]: Inference done 2194/5000. Dataloading: 0.0011 s/iter. Inference: 0.0615 s/iter. Eval: 0.0321 s/iter. Total: 0.0948 s/iter. ETA=0:04:25
[12/10 23:46:30 d2.evaluation.evaluator]: Inference done 2248/5000. Dataloading: 0.0011 s/iter. Inference: 0.0615 s/iter. Eval: 0.0321 s/iter. Total: 0.0947 s/iter. ETA=0:04:20
[12/10 23:46:35 d2.evaluation.evaluator]: Inference done 2304/5000. Dataloading: 0.0011 s/iter. Inference: 0.0615 s/iter. Eval: 0.0320 s/iter. Total: 0.0946 s/iter. ETA=0:04:15
[12/10 23:46:40 d2.evaluation.evaluator]: Inference done 2363/5000. Dataloading: 0.0011 s/iter. Inference: 0.0613 s/iter. Eval: 0.0320 s/iter. Total: 0.0944 s/iter. ETA=0:04:09
[12/10 23:46:45 d2.evaluation.evaluator]: Inference done 2415/5000. Dataloading: 0.0011 s/iter. Inference: 0.0614 s/iter. Eval: 0.0320 s/iter. Total: 0.0945 s/iter. ETA=0:04:04
[12/10 23:46:50 d2.evaluation.evaluator]: Inference done 2468/5000. Dataloading: 0.0011 s/iter. Inference: 0.0614 s/iter. Eval: 0.0320 s/iter. Total: 0.0945 s/iter. ETA=0:03:59
[12/10 23:46:55 d2.evaluation.evaluator]: Inference done 2522/5000. Dataloading: 0.0011 s/iter. Inference: 0.0614 s/iter. Eval: 0.0320 s/iter. Total: 0.0945 s/iter. ETA=0:03:54
[12/10 23:47:00 d2.evaluation.evaluator]: Inference done 2576/5000. Dataloading: 0.0011 s/iter. Inference: 0.0613 s/iter. Eval: 0.0320 s/iter. Total: 0.0945 s/iter. ETA=0:03:49
[12/10 23:47:05 d2.evaluation.evaluator]: Inference done 2629/5000. Dataloading: 0.0011 s/iter. Inference: 0.0614 s/iter. Eval: 0.0320 s/iter. Total: 0.0945 s/iter. ETA=0:03:44
[12/10 23:47:11 d2.evaluation.evaluator]: Inference done 2685/5000. Dataloading: 0.0011 s/iter. Inference: 0.0613 s/iter. Eval: 0.0320 s/iter. Total: 0.0944 s/iter. ETA=0:03:38
[12/10 23:47:16 d2.evaluation.evaluator]: Inference done 2740/5000. Dataloading: 0.0011 s/iter. Inference: 0.0613 s/iter. Eval: 0.0319 s/iter. Total: 0.0944 s/iter. ETA=0:03:33
[12/10 23:47:21 d2.evaluation.evaluator]: Inference done 2794/5000. Dataloading: 0.0011 s/iter. Inference: 0.0613 s/iter. Eval: 0.0319 s/iter. Total: 0.0944 s/iter. ETA=0:03:28
[12/10 23:47:26 d2.evaluation.evaluator]: Inference done 2848/5000. Dataloading: 0.0011 s/iter. Inference: 0.0613 s/iter. Eval: 0.0319 s/iter. Total: 0.0943 s/iter. ETA=0:03:23
[12/10 23:47:31 d2.evaluation.evaluator]: Inference done 2902/5000. Dataloading: 0.0011 s/iter. Inference: 0.0613 s/iter. Eval: 0.0319 s/iter. Total: 0.0943 s/iter. ETA=0:03:17
[12/10 23:47:36 d2.evaluation.evaluator]: Inference done 2956/5000. Dataloading: 0.0011 s/iter. Inference: 0.0613 s/iter. Eval: 0.0319 s/iter. Total: 0.0943 s/iter. ETA=0:03:12
[12/10 23:47:41 d2.evaluation.evaluator]: Inference done 3012/5000. Dataloading: 0.0011 s/iter. Inference: 0.0612 s/iter. Eval: 0.0319 s/iter. Total: 0.0942 s/iter. ETA=0:03:07
[12/10 23:47:46 d2.evaluation.evaluator]: Inference done 3070/5000. Dataloading: 0.0011 s/iter. Inference: 0.0611 s/iter. Eval: 0.0318 s/iter. Total: 0.0941 s/iter. ETA=0:03:01
[12/10 23:47:51 d2.evaluation.evaluator]: Inference done 3125/5000. Dataloading: 0.0011 s/iter. Inference: 0.0611 s/iter. Eval: 0.0318 s/iter. Total: 0.0940 s/iter. ETA=0:02:56
[12/10 23:47:56 d2.evaluation.evaluator]: Inference done 3179/5000. Dataloading: 0.0011 s/iter. Inference: 0.0611 s/iter. Eval: 0.0318 s/iter. Total: 0.0940 s/iter. ETA=0:02:51
[12/10 23:48:01 d2.evaluation.evaluator]: Inference done 3230/5000. Dataloading: 0.0011 s/iter. Inference: 0.0611 s/iter. Eval: 0.0319 s/iter. Total: 0.0941 s/iter. ETA=0:02:46
[12/10 23:48:06 d2.evaluation.evaluator]: Inference done 3284/5000. Dataloading: 0.0011 s/iter. Inference: 0.0611 s/iter. Eval: 0.0319 s/iter. Total: 0.0941 s/iter. ETA=0:02:41
[12/10 23:48:11 d2.evaluation.evaluator]: Inference done 3336/5000. Dataloading: 0.0011 s/iter. Inference: 0.0611 s/iter. Eval: 0.0319 s/iter. Total: 0.0941 s/iter. ETA=0:02:36
[12/10 23:48:16 d2.evaluation.evaluator]: Inference done 3389/5000. Dataloading: 0.0011 s/iter. Inference: 0.0611 s/iter. Eval: 0.0319 s/iter. Total: 0.0942 s/iter. ETA=0:02:31
[12/10 23:48:21 d2.evaluation.evaluator]: Inference done 3443/5000. Dataloading: 0.0011 s/iter. Inference: 0.0611 s/iter. Eval: 0.0319 s/iter. Total: 0.0942 s/iter. ETA=0:02:26
[12/10 23:48:26 d2.evaluation.evaluator]: Inference done 3499/5000. Dataloading: 0.0011 s/iter. Inference: 0.0611 s/iter. Eval: 0.0319 s/iter. Total: 0.0941 s/iter. ETA=0:02:21
[12/10 23:48:31 d2.evaluation.evaluator]: Inference done 3552/5000. Dataloading: 0.0011 s/iter. Inference: 0.0611 s/iter. Eval: 0.0319 s/iter. Total: 0.0941 s/iter. ETA=0:02:16
[12/10 23:48:36 d2.evaluation.evaluator]: Inference done 3604/5000. Dataloading: 0.0011 s/iter. Inference: 0.0611 s/iter. Eval: 0.0319 s/iter. Total: 0.0942 s/iter. ETA=0:02:11
[12/10 23:48:41 d2.evaluation.evaluator]: Inference done 3658/5000. Dataloading: 0.0011 s/iter. Inference: 0.0611 s/iter. Eval: 0.0319 s/iter. Total: 0.0941 s/iter. ETA=0:02:06
[12/10 23:48:46 d2.evaluation.evaluator]: Inference done 3712/5000. Dataloading: 0.0011 s/iter. Inference: 0.0611 s/iter. Eval: 0.0319 s/iter. Total: 0.0941 s/iter. ETA=0:02:01
[12/10 23:48:52 d2.evaluation.evaluator]: Inference done 3766/5000. Dataloading: 0.0011 s/iter. Inference: 0.0611 s/iter. Eval: 0.0319 s/iter. Total: 0.0941 s/iter. ETA=0:01:56
[12/10 23:48:57 d2.evaluation.evaluator]: Inference done 3818/5000. Dataloading: 0.0011 s/iter. Inference: 0.0611 s/iter. Eval: 0.0319 s/iter. Total: 0.0942 s/iter. ETA=0:01:51
[12/10 23:49:02 d2.evaluation.evaluator]: Inference done 3874/5000. Dataloading: 0.0011 s/iter. Inference: 0.0611 s/iter. Eval: 0.0319 s/iter. Total: 0.0941 s/iter. ETA=0:01:45
[12/10 23:49:07 d2.evaluation.evaluator]: Inference done 3929/5000. Dataloading: 0.0011 s/iter. Inference: 0.0611 s/iter. Eval: 0.0319 s/iter. Total: 0.0941 s/iter. ETA=0:01:40
[12/10 23:49:12 d2.evaluation.evaluator]: Inference done 3986/5000. Dataloading: 0.0011 s/iter. Inference: 0.0610 s/iter. Eval: 0.0318 s/iter. Total: 0.0940 s/iter. ETA=0:01:35
[12/10 23:49:17 d2.evaluation.evaluator]: Inference done 4041/5000. Dataloading: 0.0011 s/iter. Inference: 0.0610 s/iter. Eval: 0.0318 s/iter. Total: 0.0940 s/iter. ETA=0:01:30
[12/10 23:49:22 d2.evaluation.evaluator]: Inference done 4094/5000. Dataloading: 0.0011 s/iter. Inference: 0.0610 s/iter. Eval: 0.0319 s/iter. Total: 0.0940 s/iter. ETA=0:01:25
[12/10 23:49:27 d2.evaluation.evaluator]: Inference done 4149/5000. Dataloading: 0.0011 s/iter. Inference: 0.0610 s/iter. Eval: 0.0319 s/iter. Total: 0.0940 s/iter. ETA=0:01:19
[12/10 23:49:32 d2.evaluation.evaluator]: Inference done 4199/5000. Dataloading: 0.0011 s/iter. Inference: 0.0610 s/iter. Eval: 0.0319 s/iter. Total: 0.0941 s/iter. ETA=0:01:15
[12/10 23:49:37 d2.evaluation.evaluator]: Inference done 4253/5000. Dataloading: 0.0011 s/iter. Inference: 0.0610 s/iter. Eval: 0.0319 s/iter. Total: 0.0940 s/iter. ETA=0:01:10
[12/10 23:49:42 d2.evaluation.evaluator]: Inference done 4307/5000. Dataloading: 0.0011 s/iter. Inference: 0.0610 s/iter. Eval: 0.0319 s/iter. Total: 0.0940 s/iter. ETA=0:01:05
[12/10 23:49:47 d2.evaluation.evaluator]: Inference done 4364/5000. Dataloading: 0.0011 s/iter. Inference: 0.0610 s/iter. Eval: 0.0318 s/iter. Total: 0.0940 s/iter. ETA=0:00:59
[12/10 23:49:52 d2.evaluation.evaluator]: Inference done 4418/5000. Dataloading: 0.0011 s/iter. Inference: 0.0610 s/iter. Eval: 0.0318 s/iter. Total: 0.0940 s/iter. ETA=0:00:54
[12/10 23:49:57 d2.evaluation.evaluator]: Inference done 4471/5000. Dataloading: 0.0011 s/iter. Inference: 0.0610 s/iter. Eval: 0.0319 s/iter. Total: 0.0940 s/iter. ETA=0:00:49
[12/10 23:50:02 d2.evaluation.evaluator]: Inference done 4525/5000. Dataloading: 0.0011 s/iter. Inference: 0.0610 s/iter. Eval: 0.0319 s/iter. Total: 0.0940 s/iter. ETA=0:00:44
[12/10 23:50:07 d2.evaluation.evaluator]: Inference done 4578/5000. Dataloading: 0.0011 s/iter. Inference: 0.0610 s/iter. Eval: 0.0319 s/iter. Total: 0.0940 s/iter. ETA=0:00:39
[12/10 23:50:12 d2.evaluation.evaluator]: Inference done 4634/5000. Dataloading: 0.0011 s/iter. Inference: 0.0610 s/iter. Eval: 0.0318 s/iter. Total: 0.0939 s/iter. ETA=0:00:34
[12/10 23:50:17 d2.evaluation.evaluator]: Inference done 4688/5000. Dataloading: 0.0011 s/iter. Inference: 0.0610 s/iter. Eval: 0.0318 s/iter. Total: 0.0939 s/iter. ETA=0:00:29
[12/10 23:50:22 d2.evaluation.evaluator]: Inference done 4743/5000. Dataloading: 0.0011 s/iter. Inference: 0.0609 s/iter. Eval: 0.0318 s/iter. Total: 0.0939 s/iter. ETA=0:00:24
[12/10 23:50:28 d2.evaluation.evaluator]: Inference done 4797/5000. Dataloading: 0.0011 s/iter. Inference: 0.0610 s/iter. Eval: 0.0318 s/iter. Total: 0.0939 s/iter. ETA=0:00:19
[12/10 23:50:33 d2.evaluation.evaluator]: Inference done 4850/5000. Dataloading: 0.0011 s/iter. Inference: 0.0610 s/iter. Eval: 0.0319 s/iter. Total: 0.0940 s/iter. ETA=0:00:14
[12/10 23:50:38 d2.evaluation.evaluator]: Inference done 4906/5000. Dataloading: 0.0011 s/iter. Inference: 0.0609 s/iter. Eval: 0.0318 s/iter. Total: 0.0939 s/iter. ETA=0:00:08
[12/10 23:50:43 d2.evaluation.evaluator]: Inference done 4956/5000. Dataloading: 0.0011 s/iter. Inference: 0.0610 s/iter. Eval: 0.0318 s/iter. Total: 0.0940 s/iter. ETA=0:00:04
[12/10 23:50:47 d2.evaluation.evaluator]: Total inference time: 0:07:49.422322 (0.093978 s / iter per device, on 1 devices)
[12/10 23:50:47 d2.evaluation.evaluator]: Total inference pure compute time: 0:05:04 (0.060973 s / iter per device, on 1 devices)
[12/10 23:50:47 d2.evaluation.panoptic_evaluation]: Writing all panoptic predictions to /tmp/panoptic_evalcq2snew8 ...
[12/10 23:51:09 d2.evaluation.panoptic_evaluation]: Panoptic Evaluation Results:
|        |   PQ   |   SQ   |   RQ   |  #categories  |
|:------:|:------:|:------:|:------:|:-------------:|
|  All   | 17.731 | 64.397 | 23.763 |      133      |
| Things | 16.865 | 64.764 | 23.002 |      80       |
| Stuff  | 19.037 | 63.845 | 24.912 |      53       |
[12/10 23:51:09 d2.evaluation.coco_evaluation]: Preparing results for COCO format ...
[12/10 23:51:09 d2.evaluation.coco_evaluation]: Saving results to ./output/inference/coco_instances_results.json
[12/10 23:51:10 d2.evaluation.coco_evaluation]: Evaluating predictions with unofficial COCO API...
Loading and preparing results...
DONE (t=0.03s)
creating index...
index created!
[12/10 23:51:10 d2.evaluation.fast_eval_api]: Evaluate annotation type *bbox*
[12/10 23:51:17 d2.evaluation.fast_eval_api]: COCOeval_opt.evaluate() finished in 7.73 seconds.
[12/10 23:51:17 d2.evaluation.fast_eval_api]: Accumulating evaluation results...
[12/10 23:51:18 d2.evaluation.fast_eval_api]: COCOeval_opt.accumulate() finished in 0.61 seconds.
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.046
 Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.106
 Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.035
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.011
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.050
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.077
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.071
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.102
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.104
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.014
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.086
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.184
[12/10 23:51:18 d2.evaluation.coco_evaluation]: Evaluation results for bbox: 
|  AP   |  AP50  |  AP75  |  APs  |  APm  |  APl  |
|:-----:|:------:|:------:|:-----:|:-----:|:-----:|
| 4.643 | 10.623 | 3.513  | 1.142 | 5.008 | 7.705 |
[12/10 23:51:18 d2.evaluation.coco_evaluation]: Per-category bbox AP: 
| category      | AP     | category     | AP     | category       | AP     |
|:--------------|:-------|:-------------|:-------|:---------------|:-------|
| person        | 10.215 | bicycle      | 3.968  | car            | 3.612  |
| motorcycle    | 5.297  | airplane     | 21.727 | bus            | 18.940 |
| train         | 12.569 | truck        | 3.780  | boat           | 1.019  |
| traffic light | 1.416  | fire hydrant | 15.647 | stop sign      | 21.022 |
| parking meter | 4.983  | bench        | 1.430  | bird           | 5.491  |
| cat           | 7.928  | dog          | 13.833 | horse          | 11.024 |
| sheep         | 10.534 | cow          | 10.111 | elephant       | 14.861 |
| bear          | 18.725 | zebra        | 16.659 | giraffe        | 17.614 |
| backpack      | 0.069  | umbrella     | 4.120  | handbag        | 0.000  |
| tie           | 0.000  | suitcase     | 1.699  | frisbee        | 7.914  |
| skis          | 0.493  | snowboard    | 0.000  | sports ball    | 3.765  |
| kite          | 8.147  | baseball bat | 0.771  | baseball glove | 2.358  |
| skateboard    | 2.469  | surfboard    | 2.048  | tennis racket  | 4.328  |
| bottle        | 0.246  | wine glass   | 0.160  | cup            | 0.642  |
| fork          | 0.616  | knife        | 0.000  | spoon          | 0.000  |
| bowl          | 0.971  | banana       | 1.157  | apple          | 0.494  |
| sandwich      | 0.831  | orange       | 1.239  | broccoli       | 1.117  |
| carrot        | 0.494  | hot dog      | 0.330  | pizza          | 3.206  |
| donut         | 1.672  | cake         | 0.720  | chair          | 0.819  |
| couch         | 6.547  | potted plant | 0.884  | bed            | 10.338 |
| dining table  | 2.245  | toilet       | 9.388  | tv             | 9.913  |
| laptop        | 2.522  | mouse        | 3.615  | remote         | 0.050  |
| keyboard      | 1.573  | cell phone   | 1.068  | microwave      | 2.002  |
| oven          | 2.321  | toaster      | 0.000  | sink           | 2.454  |
| refrigerator  | 2.733  | book         | 0.229  | clock          | 4.272  |
| vase          | 1.226  | scissors     | 0.692  | teddy bear     | 2.066  |
| hair drier    | 0.000  | toothbrush   | 0.000  |                |        |
Loading and preparing results...
DONE (t=0.43s)
creating index...
index created!
[12/10 23:51:19 d2.evaluation.fast_eval_api]: Evaluate annotation type *segm*
[12/10 23:51:28 d2.evaluation.fast_eval_api]: COCOeval_opt.evaluate() finished in 8.93 seconds.
[12/10 23:51:28 d2.evaluation.fast_eval_api]: Accumulating evaluation results...
[12/10 23:51:29 d2.evaluation.fast_eval_api]: COCOeval_opt.accumulate() finished in 0.65 seconds.
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.048
 Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.115
 Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.033
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.006
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.048
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.120
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.070
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.095
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.096
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.009
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.084
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.174
[12/10 23:51:31 d2.evaluation.coco_evaluation]: Evaluation results for segm: 
|  AP   |  AP50  |  AP75  |  APs  |  APm  |  APl   |
|:-----:|:------:|:------:|:-----:|:-----:|:------:|
| 4.750 | 11.539 | 3.324  | 0.568 | 4.775 | 11.978 |
[12/10 23:51:31 d2.evaluation.coco_evaluation]: Per-category segm AP: 
| category      | AP     | category     | AP     | category       | AP     |
|:--------------|:-------|:-------------|:-------|:---------------|:-------|
| person        | 6.736  | bicycle      | 1.933  | car            | 3.710  |
| motorcycle    | 3.228  | airplane     | 12.440 | bus            | 17.238 |
| train         | 18.709 | truck        | 3.487  | boat           | 0.841  |
| traffic light | 2.106  | fire hydrant | 20.726 | stop sign      | 27.316 |
| parking meter | 8.559  | bench        | 0.871  | bird           | 2.799  |
| cat           | 11.749 | dog          | 16.793 | horse          | 6.827  |
| sheep         | 7.030  | cow          | 8.972  | elephant       | 13.381 |
| bear          | 20.440 | zebra        | 11.023 | giraffe        | 13.942 |
| backpack      | 0.040  | umbrella     | 6.043  | handbag        | 0.000  |
| tie           | 0.000  | suitcase     | 3.336  | frisbee        | 7.918  |
| skis          | 0.020  | snowboard    | 0.000  | sports ball    | 5.009  |
| kite          | 3.247  | baseball bat | 0.307  | baseball glove | 3.996  |
| skateboard    | 1.133  | surfboard    | 1.732  | tennis racket  | 8.770  |
| bottle        | 0.500  | wine glass   | 0.434  | cup            | 1.532  |
| fork          | 0.244  | knife        | 0.000  | spoon          | 0.000  |
| bowl          | 0.994  | banana       | 0.685  | apple          | 0.065  |
| sandwich      | 1.291  | orange       | 2.141  | broccoli       | 1.006  |
| carrot        | 0.130  | hot dog      | 0.165  | pizza          | 2.375  |
| donut         | 4.019  | cake         | 1.072  | chair          | 0.523  |
| couch         | 5.352  | potted plant | 0.964  | bed            | 7.796  |
| dining table  | 0.166  | toilet       | 14.783 | tv             | 12.495 |
| laptop        | 3.852  | mouse        | 4.437  | remote         | 0.178  |
| keyboard      | 2.165  | cell phone   | 1.433  | microwave      | 6.313  |
| oven          | 1.559  | toaster      | 0.000  | sink           | 3.345  |
| refrigerator  | 2.941  | book         | 0.261  | clock          | 6.702  |
| vase          | 1.859  | scissors     | 0.788  | teddy bear     | 3.063  |
| hair drier    | 0.000  | toothbrush   | 0.000  |                |        |
[12/10 23:51:34 d2.engine.defaults]: Evaluation results for coco_2017_val_panoptic in csv format:
[12/10 23:51:34 d2.evaluation.testing]: copypaste: Task: panoptic_seg
[12/10 23:51:34 d2.evaluation.testing]: copypaste: PQ,SQ,RQ,PQ_th,SQ_th,RQ_th,PQ_st,SQ_st,RQ_st
[12/10 23:51:34 d2.evaluation.testing]: copypaste: 17.7307,64.3975,23.7633,16.8654,64.7636,23.0024,19.0367,63.8449,24.9119
[12/10 23:51:34 d2.evaluation.testing]: copypaste: Task: bbox
[12/10 23:51:34 d2.evaluation.testing]: copypaste: AP,AP50,AP75,APs,APm,APl
[12/10 23:51:34 d2.evaluation.testing]: copypaste: 4.6430,10.6230,3.5135,1.1424,5.0085,7.7047
[12/10 23:51:34 d2.evaluation.testing]: copypaste: Task: segm
[12/10 23:51:34 d2.evaluation.testing]: copypaste: AP,AP50,AP75,APs,APm,APl
[12/10 23:51:34 d2.evaluation.testing]: copypaste: 4.7504,11.5394,3.3236,0.5682,4.7746,11.9777