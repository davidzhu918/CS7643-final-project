env: DETECTRON2_DATASETS=/content/datasets
Command Line Args: Namespace(config_file='./detectron2/projects/Panoptic-DeepLab/configs/COCO-PanopticSegmentation/panoptic_deeplab_R_52_os16_mg124_poly_200k_bs64_crop_640_640_coco_dsconv.yaml', dist_url='tcp://127.0.0.1:49152', eval_only=False, machine_rank=0, num_gpus=1, num_machines=1, opts=['MODEL.RESNETS.NORM', 'BN', 'MODEL.INS_EMBED_HEAD.NORM', 'BN', 'MODEL.SEM_SEG_HEAD.NORM', 'BN', 'SOLVER.MAX_ITER', '10000', 'SOLVER.IMS_PER_BATCH', '5', 'SOLVER.BASE_LR', '0.0025', 'MODEL.BACKBONE.FREEZE_AT', '4', 'MODEL.RESNETS.DEPTH', '101', 'MODEL.WEIGHTS', 'detectron2://DeepLab/R-103.pkl', 'MODEL.SEM_SEG_HEAD.ASPP_DILATIONS', '[18, 24, 30]', 'MODEL.INS_EMBED_HEAD.ASPP_DILATIONS', '[18, 24, 30]'], resume=False)
Loading config ./detectron2/projects/Panoptic-DeepLab/configs/COCO-PanopticSegmentation/panoptic_deeplab_R_52_os16_mg124_poly_200k_bs64_crop_640_640_coco_dsconv.yaml with yaml.unsafe_load. Your machine may be at risk if the file contains malicious content.
[12/11 23:05:49 detectron2]: Rank of current process: 0. World size: 1
[12/11 23:05:51 detectron2]: Environment info:
----------------------  ----------------------------------------------------------------
sys.platform            linux
Python                  3.7.12 (default, Jan 15 2022, 18:48:18) [GCC 7.5.0]
numpy                   1.21.5
detectron2              0.6 @/content/detectron2/detectron2
Compiler                GCC 7.5
CUDA compiler           CUDA 11.1
detectron2 arch flags   7.0
DETECTRON2_ENV_MODULE   <not set>
PyTorch                 1.10.0+cu111 @/usr/local/lib/python3.7/dist-packages/torch
PyTorch debug build     False
GPU available           Yes
GPU 0                   Tesla V100-SXM2-16GB (arch=7.0)
Driver version          460.32.03
CUDA_HOME               /usr/local/cuda
Pillow                  7.1.2
torchvision             0.11.1+cu111 @/usr/local/lib/python3.7/dist-packages/torchvision
torchvision arch flags  3.5, 5.0, 6.0, 7.0, 7.5, 8.0, 8.6
fvcore                  0.1.5.post20221122
iopath                  0.1.9
cv2                     4.1.2
----------------------  ----------------------------------------------------------------
PyTorch built with:
  - GCC 7.3
  - C++ Version: 201402
  - Intel(R) Math Kernel Library Version 2020.0.0 Product Build 20191122 for Intel(R) 64 architecture applications
  - Intel(R) MKL-DNN v2.2.3 (Git Hash 7336ca9f055cf1bfa13efb658fe15dc9b41f0740)
  - OpenMP 201511 (a.k.a. OpenMP 4.5)
  - LAPACK is enabled (usually provided by MKL)
  - NNPACK is enabled
  - CPU capability usage: AVX2
  - CUDA Runtime 11.1
  - NVCC architecture flags: -gencode;arch=compute_37,code=sm_37;-gencode;arch=compute_50,code=sm_50;-gencode;arch=compute_60,code=sm_60;-gencode;arch=compute_70,code=sm_70;-gencode;arch=compute_75,code=sm_75;-gencode;arch=compute_80,code=sm_80;-gencode;arch=compute_86,code=sm_86
  - CuDNN 8.0.5
  - Magma 2.5.2
  - Build settings: BLAS_INFO=mkl, BUILD_TYPE=Release, CUDA_VERSION=11.1, CUDNN_VERSION=8.0.5, CXX_COMPILER=/opt/rh/devtoolset-7/root/usr/bin/c++, CXX_FLAGS= -Wno-deprecated -fvisibility-inlines-hidden -DUSE_PTHREADPOOL -fopenmp -DNDEBUG -DUSE_KINETO -DUSE_FBGEMM -DUSE_QNNPACK -DUSE_PYTORCH_QNNPACK -DUSE_XNNPACK -DSYMBOLICATE_MOBILE_DEBUG_HANDLE -DEDGE_PROFILER_USE_KINETO -O2 -fPIC -Wno-narrowing -Wall -Wextra -Werror=return-type -Wno-missing-field-initializers -Wno-type-limits -Wno-array-bounds -Wno-unknown-pragmas -Wno-sign-compare -Wno-unused-parameter -Wno-unused-variable -Wno-unused-function -Wno-unused-result -Wno-unused-local-typedefs -Wno-strict-overflow -Wno-strict-aliasing -Wno-error=deprecated-declarations -Wno-stringop-overflow -Wno-psabi -Wno-error=pedantic -Wno-error=redundant-decls -Wno-error=old-style-cast -fdiagnostics-color=always -faligned-new -Wno-unused-but-set-variable -Wno-maybe-uninitialized -fno-math-errno -fno-trapping-math -Werror=format -Wno-stringop-overflow, LAPACK_INFO=mkl, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, TORCH_VERSION=1.10.0, USE_CUDA=ON, USE_CUDNN=ON, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_MKL=ON, USE_MKLDNN=ON, USE_MPI=OFF, USE_NCCL=ON, USE_NNPACK=ON, USE_OPENMP=ON, 

[12/11 23:05:51 detectron2]: Command line arguments: Namespace(config_file='./detectron2/projects/Panoptic-DeepLab/configs/COCO-PanopticSegmentation/panoptic_deeplab_R_52_os16_mg124_poly_200k_bs64_crop_640_640_coco_dsconv.yaml', dist_url='tcp://127.0.0.1:49152', eval_only=False, machine_rank=0, num_gpus=1, num_machines=1, opts=['MODEL.RESNETS.NORM', 'BN', 'MODEL.INS_EMBED_HEAD.NORM', 'BN', 'MODEL.SEM_SEG_HEAD.NORM', 'BN', 'SOLVER.MAX_ITER', '10000', 'SOLVER.IMS_PER_BATCH', '5', 'SOLVER.BASE_LR', '0.0025', 'MODEL.BACKBONE.FREEZE_AT', '4', 'MODEL.RESNETS.DEPTH', '101', 'MODEL.WEIGHTS', 'detectron2://DeepLab/R-103.pkl', 'MODEL.SEM_SEG_HEAD.ASPP_DILATIONS', '[18, 24, 30]', 'MODEL.INS_EMBED_HEAD.ASPP_DILATIONS', '[18, 24, 30]'], resume=False)
[12/11 23:05:51 detectron2]: Contents of args.config_file=./detectron2/projects/Panoptic-DeepLab/configs/COCO-PanopticSegmentation/panoptic_deeplab_R_52_os16_mg124_poly_200k_bs64_crop_640_640_coco_dsconv.yaml:
_BASE_: ../Cityscapes-PanopticSegmentation/Base-PanopticDeepLab-OS16.yaml
MODEL:
  WEIGHTS: "detectron2://DeepLab/R-52.pkl"
  PIXEL_MEAN: [123.675, 116.280, 103.530]
  PIXEL_STD: [58.395, 57.120, 57.375]
  BACKBONE:
    NAME: "build_resnet_deeplab_backbone"
  RESNETS:
    DEPTH: 50
    NORM: "SyncBN"
    RES5_MULTI_GRID: [1, 2, 4]
    STEM_TYPE: "deeplab"
    STEM_OUT_CHANNELS: 128
    STRIDE_IN_1X1: False
  SEM_SEG_HEAD:
    NUM_CLASSES: 133
    LOSS_TOP_K: 1.0
    USE_DEPTHWISE_SEPARABLE_CONV: True
  PANOPTIC_DEEPLAB:
    STUFF_AREA: 4096
    NMS_KERNEL: 41
    SIZE_DIVISIBILITY: 640
    USE_DEPTHWISE_SEPARABLE_CONV: True
DATASETS:
  TRAIN: ("coco_2017_train_panoptic",)
  TEST: ("coco_2017_val_panoptic",)
SOLVER:
  BASE_LR: 0.0005
  MAX_ITER: 200000
  IMS_PER_BATCH: 64
INPUT:
  FORMAT: "RGB"
  GAUSSIAN_SIGMA: 8
  MIN_SIZE_TRAIN: !!python/object/apply:eval ["[int(x * 0.1 * 640) for x in range(5, 16)]"]
  MIN_SIZE_TRAIN_SAMPLING: "choice"
  MIN_SIZE_TEST: 640
  MAX_SIZE_TRAIN: 960
  MAX_SIZE_TEST: 640
  CROP:
    ENABLED: True
    TYPE: "absolute"
    SIZE: (640, 640)

[12/11 23:05:51 detectron2]: Running with full config:
CUDNN_BENCHMARK: false
DATALOADER:
  ASPECT_RATIO_GROUPING: true
  FILTER_EMPTY_ANNOTATIONS: true
  NUM_WORKERS: 10
  REPEAT_THRESHOLD: 0.0
  SAMPLER_TRAIN: TrainingSampler
DATASETS:
  PRECOMPUTED_PROPOSAL_TOPK_TEST: 1000
  PRECOMPUTED_PROPOSAL_TOPK_TRAIN: 2000
  PROPOSAL_FILES_TEST: []
  PROPOSAL_FILES_TRAIN: []
  TEST:
  - coco_2017_val_panoptic
  TRAIN:
  - coco_2017_train_panoptic
GLOBAL:
  HACK: 1.0
INPUT:
  CROP:
    ENABLED: true
    SINGLE_CATEGORY_MAX_AREA: 1.0
    SIZE:
    - 640
    - 640
    TYPE: absolute
  FORMAT: RGB
  GAUSSIAN_SIGMA: 8
  IGNORE_CROWD_IN_SEMANTIC: false
  IGNORE_STUFF_IN_OFFSET: true
  MASK_FORMAT: polygon
  MAX_SIZE_TEST: 640
  MAX_SIZE_TRAIN: 960
  MIN_SIZE_TEST: 640
  MIN_SIZE_TRAIN:
  - 320
  - 384
  - 448
  - 512
  - 576
  - 640
  - 704
  - 768
  - 832
  - 896
  - 960
  MIN_SIZE_TRAIN_SAMPLING: choice
  RANDOM_FLIP: horizontal
  SMALL_INSTANCE_AREA: 4096
  SMALL_INSTANCE_WEIGHT: 3
MODEL:
  ANCHOR_GENERATOR:
    ANGLES:
    - - -90
      - 0
      - 90
    ASPECT_RATIOS:
    - - 0.5
      - 1.0
      - 2.0
    NAME: DefaultAnchorGenerator
    OFFSET: 0.0
    SIZES:
    - - 32
      - 64
      - 128
      - 256
      - 512
  BACKBONE:
    FREEZE_AT: 4
    NAME: build_resnet_deeplab_backbone
  DEVICE: cuda
  FPN:
    FUSE_TYPE: sum
    IN_FEATURES: []
    NORM: ''
    OUT_CHANNELS: 256
  INS_EMBED_HEAD:
    ASPP_CHANNELS: 256
    ASPP_DILATIONS:
    - 18
    - 24
    - 30
    ASPP_DROPOUT: 0.1
    CENTER_LOSS_WEIGHT: 200.0
    COMMON_STRIDE: 4
    CONVS_DIM: 128
    HEAD_CHANNELS: 32
    IN_FEATURES:
    - res2
    - res3
    - res5
    NAME: PanopticDeepLabInsEmbedHead
    NORM: BN
    OFFSET_LOSS_WEIGHT: 0.01
    PROJECT_CHANNELS:
    - 32
    - 64
    PROJECT_FEATURES:
    - res2
    - res3
  KEYPOINT_ON: false
  LOAD_PROPOSALS: false
  MASK_ON: false
  META_ARCHITECTURE: PanopticDeepLab
  PANOPTIC_DEEPLAB:
    BENCHMARK_NETWORK_SPEED: false
    CENTER_THRESHOLD: 0.1
    NMS_KERNEL: 41
    PREDICT_INSTANCES: true
    SIZE_DIVISIBILITY: 640
    STUFF_AREA: 4096
    TOP_K_INSTANCE: 200
    USE_DEPTHWISE_SEPARABLE_CONV: true
  PANOPTIC_FPN:
    COMBINE:
      ENABLED: true
      INSTANCES_CONFIDENCE_THRESH: 0.5
      OVERLAP_THRESH: 0.5
      STUFF_AREA_LIMIT: 4096
    INSTANCE_LOSS_WEIGHT: 1.0
  PIXEL_MEAN:
  - 123.675
  - 116.28
  - 103.53
  PIXEL_STD:
  - 58.395
  - 57.12
  - 57.375
  PROPOSAL_GENERATOR:
    MIN_SIZE: 0
    NAME: RPN
  RESNETS:
    DEFORM_MODULATED: false
    DEFORM_NUM_GROUPS: 1
    DEFORM_ON_PER_STAGE:
    - false
    - false
    - false
    - false
    DEPTH: 101
    NORM: BN
    NUM_GROUPS: 1
    OUT_FEATURES:
    - res2
    - res3
    - res5
    RES2_OUT_CHANNELS: 256
    RES4_DILATION: 1
    RES5_DILATION: 2
    RES5_MULTI_GRID:
    - 1
    - 2
    - 4
    STEM_OUT_CHANNELS: 128
    STEM_TYPE: deeplab
    STRIDE_IN_1X1: false
    WIDTH_PER_GROUP: 64
  RETINANET:
    BBOX_REG_LOSS_TYPE: smooth_l1
    BBOX_REG_WEIGHTS: &id001
    - 1.0
    - 1.0
    - 1.0
    - 1.0
    FOCAL_LOSS_ALPHA: 0.25
    FOCAL_LOSS_GAMMA: 2.0
    IN_FEATURES:
    - p3
    - p4
    - p5
    - p6
    - p7
    IOU_LABELS:
    - 0
    - -1
    - 1
    IOU_THRESHOLDS:
    - 0.4
    - 0.5
    NMS_THRESH_TEST: 0.5
    NORM: ''
    NUM_CLASSES: 80
    NUM_CONVS: 4
    PRIOR_PROB: 0.01
    SCORE_THRESH_TEST: 0.05
    SMOOTH_L1_LOSS_BETA: 0.1
    TOPK_CANDIDATES_TEST: 1000
  ROI_BOX_CASCADE_HEAD:
    BBOX_REG_WEIGHTS:
    - - 10.0
      - 10.0
      - 5.0
      - 5.0
    - - 20.0
      - 20.0
      - 10.0
      - 10.0
    - - 30.0
      - 30.0
      - 15.0
      - 15.0
    IOUS:
    - 0.5
    - 0.6
    - 0.7
  ROI_BOX_HEAD:
    BBOX_REG_LOSS_TYPE: smooth_l1
    BBOX_REG_LOSS_WEIGHT: 1.0
    BBOX_REG_WEIGHTS:
    - 10.0
    - 10.0
    - 5.0
    - 5.0
    CLS_AGNOSTIC_BBOX_REG: false
    CONV_DIM: 256
    FC_DIM: 1024
    FED_LOSS_FREQ_WEIGHT_POWER: 0.5
    FED_LOSS_NUM_CLASSES: 50
    NAME: ''
    NORM: ''
    NUM_CONV: 0
    NUM_FC: 0
    POOLER_RESOLUTION: 14
    POOLER_SAMPLING_RATIO: 0
    POOLER_TYPE: ROIAlignV2
    SMOOTH_L1_BETA: 0.0
    TRAIN_ON_PRED_BOXES: false
    USE_FED_LOSS: false
    USE_SIGMOID_CE: false
  ROI_HEADS:
    BATCH_SIZE_PER_IMAGE: 512
    IN_FEATURES:
    - res4
    IOU_LABELS:
    - 0
    - 1
    IOU_THRESHOLDS:
    - 0.5
    NAME: Res5ROIHeads
    NMS_THRESH_TEST: 0.5
    NUM_CLASSES: 80
    POSITIVE_FRACTION: 0.25
    PROPOSAL_APPEND_GT: true
    SCORE_THRESH_TEST: 0.05
  ROI_KEYPOINT_HEAD:
    CONV_DIMS:
    - 512
    - 512
    - 512
    - 512
    - 512
    - 512
    - 512
    - 512
    LOSS_WEIGHT: 1.0
    MIN_KEYPOINTS_PER_IMAGE: 1
    NAME: KRCNNConvDeconvUpsampleHead
    NORMALIZE_LOSS_BY_VISIBLE_KEYPOINTS: true
    NUM_KEYPOINTS: 17
    POOLER_RESOLUTION: 14
    POOLER_SAMPLING_RATIO: 0
    POOLER_TYPE: ROIAlignV2
  ROI_MASK_HEAD:
    CLS_AGNOSTIC_MASK: false
    CONV_DIM: 256
    NAME: MaskRCNNConvUpsampleHead
    NORM: ''
    NUM_CONV: 0
    POOLER_RESOLUTION: 14
    POOLER_SAMPLING_RATIO: 0
    POOLER_TYPE: ROIAlignV2
  RPN:
    BATCH_SIZE_PER_IMAGE: 256
    BBOX_REG_LOSS_TYPE: smooth_l1
    BBOX_REG_LOSS_WEIGHT: 1.0
    BBOX_REG_WEIGHTS: *id001
    BOUNDARY_THRESH: -1
    CONV_DIMS:
    - -1
    HEAD_NAME: StandardRPNHead
    IN_FEATURES:
    - res4
    IOU_LABELS:
    - 0
    - -1
    - 1
    IOU_THRESHOLDS:
    - 0.3
    - 0.7
    LOSS_WEIGHT: 1.0
    NMS_THRESH: 0.7
    POSITIVE_FRACTION: 0.5
    POST_NMS_TOPK_TEST: 1000
    POST_NMS_TOPK_TRAIN: 2000
    PRE_NMS_TOPK_TEST: 6000
    PRE_NMS_TOPK_TRAIN: 12000
    SMOOTH_L1_BETA: 0.0
  SEM_SEG_HEAD:
    ASPP_CHANNELS: 256
    ASPP_DILATIONS:
    - 18
    - 24
    - 30
    ASPP_DROPOUT: 0.1
    COMMON_STRIDE: 4
    CONVS_DIM: 256
    HEAD_CHANNELS: 256
    IGNORE_VALUE: 255
    IN_FEATURES:
    - res2
    - res3
    - res5
    LOSS_TOP_K: 1.0
    LOSS_TYPE: hard_pixel_mining
    LOSS_WEIGHT: 1.0
    NAME: PanopticDeepLabSemSegHead
    NORM: BN
    NUM_CLASSES: 133
    PROJECT_CHANNELS:
    - 32
    - 64
    PROJECT_FEATURES:
    - res2
    - res3
    USE_DEPTHWISE_SEPARABLE_CONV: true
  WEIGHTS: detectron2://DeepLab/R-103.pkl
OUTPUT_DIR: ./output
SEED: -1
SOLVER:
  AMP:
    ENABLED: false
  BASE_LR: 0.0025
  BASE_LR_END: 0.0
  BIAS_LR_FACTOR: 1.0
  CHECKPOINT_PERIOD: 5000
  CLIP_GRADIENTS:
    CLIP_TYPE: value
    CLIP_VALUE: 1.0
    ENABLED: false
    NORM_TYPE: 2.0
  GAMMA: 0.1
  IMS_PER_BATCH: 5
  LR_SCHEDULER_NAME: WarmupPolyLR
  MAX_ITER: 10000
  MOMENTUM: 0.9
  NESTEROV: false
  NUM_DECAYS: 3
  OPTIMIZER: ADAM
  POLY_LR_CONSTANT_ENDING: 0.0
  POLY_LR_POWER: 0.9
  REFERENCE_WORLD_SIZE: 0
  RESCALE_INTERVAL: false
  STEPS:
  - 30000
  WARMUP_FACTOR: 0.001
  WARMUP_ITERS: 1000
  WARMUP_METHOD: linear
  WEIGHT_DECAY: 0.0
  WEIGHT_DECAY_BIAS: 0.0
  WEIGHT_DECAY_NORM: 0.0
TEST:
  AUG:
    ENABLED: false
    FLIP: true
    MAX_SIZE: 4000
    MIN_SIZES:
    - 400
    - 500
    - 600
    - 700
    - 800
    - 900
    - 1000
    - 1100
    - 1200
  DETECTIONS_PER_IMAGE: 100
  EVAL_PERIOD: 0
  EXPECTED_RESULTS: []
  KEYPOINT_OKS_SIGMAS: []
  PRECISE_BN:
    ENABLED: false
    NUM_ITER: 200
VERSION: 2
VIS_PERIOD: 0

[12/11 23:05:51 detectron2]: Full config saved to ./output/config.yaml
[12/11 23:05:51 d2.utils.env]: Using a generated random seed 51392080
[12/11 23:05:56 d2.engine.defaults]: Model:
PanopticDeepLab(
  (backbone): ResNet(
    (stem): DeepLabStem(
      (conv1): Conv2d(
        3, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False
        (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
      )
      (conv2): Conv2d(
        64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
        (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
      )
      (conv3): Conv2d(
        64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
        (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
      )
    )
    (res2): Sequential(
      (0): BottleneckBlock(
        (shortcut): Conv2d(
          128, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv1): Conv2d(
          128, 64, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
        )
        (conv2): Conv2d(
          64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
        )
        (conv3): Conv2d(
          64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
      )
      (1): BottleneckBlock(
        (conv1): Conv2d(
          256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
        )
        (conv2): Conv2d(
          64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
        )
        (conv3): Conv2d(
          64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
      )
      (2): BottleneckBlock(
        (conv1): Conv2d(
          256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
        )
        (conv2): Conv2d(
          64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
        )
        (conv3): Conv2d(
          64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
      )
    )
    (res3): Sequential(
      (0): BottleneckBlock(
        (shortcut): Conv2d(
          256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False
          (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
        )
        (conv1): Conv2d(
          256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
        )
        (conv2): Conv2d(
          128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
        )
        (conv3): Conv2d(
          128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
        )
      )
      (1): BottleneckBlock(
        (conv1): Conv2d(
          512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
        )
        (conv2): Conv2d(
          128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
        )
        (conv3): Conv2d(
          128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
        )
      )
      (2): BottleneckBlock(
        (conv1): Conv2d(
          512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
        )
        (conv2): Conv2d(
          128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
        )
        (conv3): Conv2d(
          128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
        )
      )
      (3): BottleneckBlock(
        (conv1): Conv2d(
          512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
        )
        (conv2): Conv2d(
          128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
        )
        (conv3): Conv2d(
          128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
        )
      )
    )
    (res4): Sequential(
      (0): BottleneckBlock(
        (shortcut): Conv2d(
          512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False
          (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
        )
        (conv1): Conv2d(
          512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv2): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv3): Conv2d(
          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
        )
      )
      (1): BottleneckBlock(
        (conv1): Conv2d(
          1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv2): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv3): Conv2d(
          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
        )
      )
      (2): BottleneckBlock(
        (conv1): Conv2d(
          1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv2): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv3): Conv2d(
          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
        )
      )
      (3): BottleneckBlock(
        (conv1): Conv2d(
          1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv2): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv3): Conv2d(
          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
        )
      )
      (4): BottleneckBlock(
        (conv1): Conv2d(
          1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv2): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv3): Conv2d(
          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
        )
      )
      (5): BottleneckBlock(
        (conv1): Conv2d(
          1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv2): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv3): Conv2d(
          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
        )
      )
      (6): BottleneckBlock(
        (conv1): Conv2d(
          1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv2): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv3): Conv2d(
          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
        )
      )
      (7): BottleneckBlock(
        (conv1): Conv2d(
          1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv2): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv3): Conv2d(
          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
        )
      )
      (8): BottleneckBlock(
        (conv1): Conv2d(
          1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv2): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv3): Conv2d(
          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
        )
      )
      (9): BottleneckBlock(
        (conv1): Conv2d(
          1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv2): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv3): Conv2d(
          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
        )
      )
      (10): BottleneckBlock(
        (conv1): Conv2d(
          1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv2): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv3): Conv2d(
          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
        )
      )
      (11): BottleneckBlock(
        (conv1): Conv2d(
          1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv2): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv3): Conv2d(
          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
        )
      )
      (12): BottleneckBlock(
        (conv1): Conv2d(
          1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv2): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv3): Conv2d(
          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
        )
      )
      (13): BottleneckBlock(
        (conv1): Conv2d(
          1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv2): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv3): Conv2d(
          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
        )
      )
      (14): BottleneckBlock(
        (conv1): Conv2d(
          1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv2): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv3): Conv2d(
          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
        )
      )
      (15): BottleneckBlock(
        (conv1): Conv2d(
          1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv2): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv3): Conv2d(
          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
        )
      )
      (16): BottleneckBlock(
        (conv1): Conv2d(
          1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv2): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv3): Conv2d(
          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
        )
      )
      (17): BottleneckBlock(
        (conv1): Conv2d(
          1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv2): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv3): Conv2d(
          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
        )
      )
      (18): BottleneckBlock(
        (conv1): Conv2d(
          1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv2): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv3): Conv2d(
          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
        )
      )
      (19): BottleneckBlock(
        (conv1): Conv2d(
          1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv2): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv3): Conv2d(
          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
        )
      )
      (20): BottleneckBlock(
        (conv1): Conv2d(
          1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv2): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv3): Conv2d(
          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
        )
      )
      (21): BottleneckBlock(
        (conv1): Conv2d(
          1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv2): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv3): Conv2d(
          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
        )
      )
      (22): BottleneckBlock(
        (conv1): Conv2d(
          1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv2): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv3): Conv2d(
          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
        )
      )
    )
    (res5): Sequential(
      (0): BottleneckBlock(
        (shortcut): Conv2d(
          1024, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv1): Conv2d(
          1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv2): Conv2d(
          512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2), dilation=(2, 2), bias=False
          (norm): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv3): Conv2d(
          512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (1): BottleneckBlock(
        (conv1): Conv2d(
          2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv2): Conv2d(
          512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(4, 4), dilation=(4, 4), bias=False
          (norm): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv3): Conv2d(
          512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (2): BottleneckBlock(
        (conv1): Conv2d(
          2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv2): Conv2d(
          512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(8, 8), dilation=(8, 8), bias=False
          (norm): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv3): Conv2d(
          512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
    )
  )
  (sem_seg_head): PanopticDeepLabSemSegHead(
    (decoder): ModuleDict(
      (res2): ModuleDict(
        (project_conv): Conv2d(
          256, 32, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (fuse_conv): DepthwiseSeparableConv2d(
          (depthwise): Conv2d(
            288, 288, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=288, bias=False
            (norm): BatchNorm2d(288, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          )
          (pointwise): Conv2d(
            288, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
      )
      (res3): ModuleDict(
        (project_conv): Conv2d(
          512, 64, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (fuse_conv): DepthwiseSeparableConv2d(
          (depthwise): Conv2d(
            320, 320, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=320, bias=False
            (norm): BatchNorm2d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          )
          (pointwise): Conv2d(
            320, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
      )
      (res5): ModuleDict(
        (project_conv): ASPP(
          (convs): ModuleList(
            (0): Conv2d(
              2048, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
              (norm): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            )
            (1): DepthwiseSeparableConv2d(
              (depthwise): Conv2d(
                2048, 2048, kernel_size=(3, 3), stride=(1, 1), padding=(18, 18), dilation=(18, 18), groups=2048, bias=False
                (norm): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
              (pointwise): Conv2d(
                2048, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
            )
            (2): DepthwiseSeparableConv2d(
              (depthwise): Conv2d(
                2048, 2048, kernel_size=(3, 3), stride=(1, 1), padding=(24, 24), dilation=(24, 24), groups=2048, bias=False
                (norm): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
              (pointwise): Conv2d(
                2048, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
            )
            (3): DepthwiseSeparableConv2d(
              (depthwise): Conv2d(
                2048, 2048, kernel_size=(3, 3), stride=(1, 1), padding=(30, 30), dilation=(30, 30), groups=2048, bias=False
                (norm): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
              (pointwise): Conv2d(
                2048, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
            )
            (4): Sequential(
              (0): AvgPool2d(kernel_size=(40, 40), stride=1, padding=0)
              (1): Conv2d(2048, 256, kernel_size=(1, 1), stride=(1, 1))
            )
          )
          (project): Conv2d(
            1280, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (fuse_conv): None
      )
    )
    (head): DepthwiseSeparableConv2d(
      (depthwise): Conv2d(
        256, 256, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=256, bias=False
        (norm): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (pointwise): Conv2d(
        256, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
        (norm): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (predictor): Conv2d(256, 133, kernel_size=(1, 1), stride=(1, 1))
    (loss): DeepLabCE(
      (criterion): CrossEntropyLoss()
    )
  )
  (ins_embed_head): PanopticDeepLabInsEmbedHead(
    (decoder): ModuleDict(
      (res2): ModuleDict(
        (project_conv): Conv2d(
          256, 32, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (fuse_conv): DepthwiseSeparableConv2d(
          (depthwise): Conv2d(
            160, 160, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=160, bias=False
            (norm): BatchNorm2d(160, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          )
          (pointwise): Conv2d(
            160, 128, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
      )
      (res3): ModuleDict(
        (project_conv): Conv2d(
          512, 64, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (fuse_conv): DepthwiseSeparableConv2d(
          (depthwise): Conv2d(
            320, 320, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=320, bias=False
            (norm): BatchNorm2d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          )
          (pointwise): Conv2d(
            320, 128, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
      )
      (res5): ModuleDict(
        (project_conv): ASPP(
          (convs): ModuleList(
            (0): Conv2d(
              2048, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
              (norm): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            )
            (1): DepthwiseSeparableConv2d(
              (depthwise): Conv2d(
                2048, 2048, kernel_size=(3, 3), stride=(1, 1), padding=(18, 18), dilation=(18, 18), groups=2048, bias=False
                (norm): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
              (pointwise): Conv2d(
                2048, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
            )
            (2): DepthwiseSeparableConv2d(
              (depthwise): Conv2d(
                2048, 2048, kernel_size=(3, 3), stride=(1, 1), padding=(24, 24), dilation=(24, 24), groups=2048, bias=False
                (norm): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
              (pointwise): Conv2d(
                2048, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
            )
            (3): DepthwiseSeparableConv2d(
              (depthwise): Conv2d(
                2048, 2048, kernel_size=(3, 3), stride=(1, 1), padding=(30, 30), dilation=(30, 30), groups=2048, bias=False
                (norm): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
              (pointwise): Conv2d(
                2048, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
            )
            (4): Sequential(
              (0): AvgPool2d(kernel_size=(40, 40), stride=1, padding=0)
              (1): Conv2d(2048, 256, kernel_size=(1, 1), stride=(1, 1))
            )
          )
          (project): Conv2d(
            1280, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (fuse_conv): None
      )
    )
    (center_head): Sequential(
      (0): Conv2d(
        128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
        (norm): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (1): Conv2d(
        128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
        (norm): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (center_predictor): Conv2d(32, 1, kernel_size=(1, 1), stride=(1, 1))
    (offset_head): DepthwiseSeparableConv2d(
      (depthwise): Conv2d(
        128, 128, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=128, bias=False
        (norm): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (pointwise): Conv2d(
        128, 32, kernel_size=(1, 1), stride=(1, 1), bias=False
        (norm): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (offset_predictor): Conv2d(32, 2, kernel_size=(1, 1), stride=(1, 1))
    (center_loss): MSELoss()
    (offset_loss): L1Loss()
  )
)
[12/11 23:05:56 d2.projects.panoptic_deeplab.dataset_mapper]: Augmentations used in training: [ResizeShortestEdge(short_edge_length=(320, 384, 448, 512, 576, 640, 704, 768, 832, 896, 960), max_size=960, sample_style='choice'), RandomCrop(crop_type='absolute', crop_size=[640, 640]), RandomFlip()]
[12/11 23:06:04 d2.data.build]: Using training sampler TrainingSampler
[12/11 23:06:04 d2.data.common]: Serializing the dataset using: <class 'detectron2.data.common.NumpySerializedList'>
[12/11 23:06:04 d2.data.common]: Serializing 118287 elements to byte tensors and concatenating them all ...
[12/11 23:06:05 d2.data.common]: Serialized dataset takes 80.32 MiB
/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:481: UserWarning: This DataLoader will create 10 worker processes in total. Our suggested max number of worker in current system is 8, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.
  cpuset_checked))
[12/11 23:06:10 fvcore.common.checkpoint]: [Checkpointer] Loading from detectron2://DeepLab/R-103.pkl ...
[12/11 23:06:10 fvcore.common.checkpoint]: Reading a file from 'torchvision'
[12/11 23:06:11 d2.checkpoint.c2_model_loading]: Following weights matched with submodule backbone:
| Names in Model    | Names in Checkpoint                                                                                        | Shapes                                             |
|:------------------|:-----------------------------------------------------------------------------------------------------------|:---------------------------------------------------|
| res2.0.conv1.*    | res2.0.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}                             | (64,) (64,) (64,) (64,) (64,128,1,1)               |
| res2.0.conv2.*    | res2.0.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}                             | (64,) (64,) (64,) (64,) (64,64,3,3)                |
| res2.0.conv3.*    | res2.0.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}                             | (256,) (256,) (256,) (256,) (256,64,1,1)           |
| res2.0.shortcut.* | res2.0.shortcut.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}                          | (256,) (256,) (256,) (256,) (256,128,1,1)          |
| res2.1.conv1.*    | res2.1.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}                             | (64,) (64,) (64,) (64,) (64,256,1,1)               |
| res2.1.conv2.*    | res2.1.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}                             | (64,) (64,) (64,) (64,) (64,64,3,3)                |
| res2.1.conv3.*    | res2.1.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}                             | (256,) (256,) (256,) (256,) (256,64,1,1)           |
| res2.2.conv1.*    | res2.2.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}                             | (64,) (64,) (64,) (64,) (64,256,1,1)               |
| res2.2.conv2.*    | res2.2.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}                             | (64,) (64,) (64,) (64,) (64,64,3,3)                |
| res2.2.conv3.*    | res2.2.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}                             | (256,) (256,) (256,) (256,) (256,64,1,1)           |
| res3.0.conv1.*    | res3.0.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}                             | (128,) (128,) (128,) (128,) (128,256,1,1)          |
| res3.0.conv2.*    | res3.0.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}                             | (128,) (128,) (128,) (128,) (128,128,3,3)          |
| res3.0.conv3.*    | res3.0.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}                             | (512,) (512,) (512,) (512,) (512,128,1,1)          |
| res3.0.shortcut.* | res3.0.shortcut.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}                          | (512,) (512,) (512,) (512,) (512,256,1,1)          |
| res3.1.conv1.*    | res3.1.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}                             | (128,) (128,) (128,) (128,) (128,512,1,1)          |
| res3.1.conv2.*    | res3.1.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}                             | (128,) (128,) (128,) (128,) (128,128,3,3)          |
| res3.1.conv3.*    | res3.1.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}                             | (512,) (512,) (512,) (512,) (512,128,1,1)          |
| res3.2.conv1.*    | res3.2.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}                             | (128,) (128,) (128,) (128,) (128,512,1,1)          |
| res3.2.conv2.*    | res3.2.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}                             | (128,) (128,) (128,) (128,) (128,128,3,3)          |
| res3.2.conv3.*    | res3.2.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}                             | (512,) (512,) (512,) (512,) (512,128,1,1)          |
| res3.3.conv1.*    | res3.3.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}                             | (128,) (128,) (128,) (128,) (128,512,1,1)          |
| res3.3.conv2.*    | res3.3.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}                             | (128,) (128,) (128,) (128,) (128,128,3,3)          |
| res3.3.conv3.*    | res3.3.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}                             | (512,) (512,) (512,) (512,) (512,128,1,1)          |
| res4.0.conv1.*    | res4.0.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}                             | (256,) (256,) (256,) (256,) (256,512,1,1)          |
| res4.0.conv2.*    | res4.0.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}                             | (256,) (256,) (256,) (256,) (256,256,3,3)          |
| res4.0.conv3.*    | res4.0.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}                             | (1024,) (1024,) (1024,) (1024,) (1024,256,1,1)     |
| res4.0.shortcut.* | res4.0.shortcut.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}                          | (1024,) (1024,) (1024,) (1024,) (1024,512,1,1)     |
| res4.1.conv1.*    | res4.1.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}                             | (256,) (256,) (256,) (256,) (256,1024,1,1)         |
| res4.1.conv2.*    | res4.1.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}                             | (256,) (256,) (256,) (256,) (256,256,3,3)          |
| res4.1.conv3.*    | res4.1.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}                             | (1024,) (1024,) (1024,) (1024,) (1024,256,1,1)     |
| res4.10.conv1.*   | res4.10.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}                            | (256,) (256,) (256,) (256,) (256,1024,1,1)         |
| res4.10.conv2.*   | res4.10.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}                            | (256,) (256,) (256,) (256,) (256,256,3,3)          |
| res4.10.conv3.*   | res4.10.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}                            | (1024,) (1024,) (1024,) (1024,) (1024,256,1,1)     |
| res4.11.conv1.*   | res4.11.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}                            | (256,) (256,) (256,) (256,) (256,1024,1,1)         |
| res4.11.conv2.*   | res4.11.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}                            | (256,) (256,) (256,) (256,) (256,256,3,3)          |
| res4.11.conv3.*   | res4.11.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}                            | (1024,) (1024,) (1024,) (1024,) (1024,256,1,1)     |
| res4.12.conv1.*   | res4.12.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}                            | (256,) (256,) (256,) (256,) (256,1024,1,1)         |
| res4.12.conv2.*   | res4.12.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}                            | (256,) (256,) (256,) (256,) (256,256,3,3)          |
| res4.12.conv3.*   | res4.12.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}                            | (1024,) (1024,) (1024,) (1024,) (1024,256,1,1)     |
| res4.13.conv1.*   | res4.13.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}                            | (256,) (256,) (256,) (256,) (256,1024,1,1)         |
| res4.13.conv2.*   | res4.13.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}                            | (256,) (256,) (256,) (256,) (256,256,3,3)          |
| res4.13.conv3.*   | res4.13.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}                            | (1024,) (1024,) (1024,) (1024,) (1024,256,1,1)     |
| res4.14.conv1.*   | res4.14.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}                            | (256,) (256,) (256,) (256,) (256,1024,1,1)         |
| res4.14.conv2.*   | res4.14.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}                            | (256,) (256,) (256,) (256,) (256,256,3,3)          |
| res4.14.conv3.*   | res4.14.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}                            | (1024,) (1024,) (1024,) (1024,) (1024,256,1,1)     |
| res4.15.conv1.*   | res4.15.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}                            | (256,) (256,) (256,) (256,) (256,1024,1,1)         |
| res4.15.conv2.*   | res4.15.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}                            | (256,) (256,) (256,) (256,) (256,256,3,3)          |
| res4.15.conv3.*   | res4.15.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}                            | (1024,) (1024,) (1024,) (1024,) (1024,256,1,1)     |
| res4.16.conv1.*   | res4.16.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}                            | (256,) (256,) (256,) (256,) (256,1024,1,1)         |
| res4.16.conv2.*   | res4.16.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}                            | (256,) (256,) (256,) (256,) (256,256,3,3)          |
| res4.16.conv3.*   | res4.16.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}                            | (1024,) (1024,) (1024,) (1024,) (1024,256,1,1)     |
| res4.17.conv1.*   | res4.17.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}                            | (256,) (256,) (256,) (256,) (256,1024,1,1)         |
| res4.17.conv2.*   | res4.17.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}                            | (256,) (256,) (256,) (256,) (256,256,3,3)          |
| res4.17.conv3.*   | res4.17.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}                            | (1024,) (1024,) (1024,) (1024,) (1024,256,1,1)     |
| res4.18.conv1.*   | res4.18.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}                            | (256,) (256,) (256,) (256,) (256,1024,1,1)         |
| res4.18.conv2.*   | res4.18.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}                            | (256,) (256,) (256,) (256,) (256,256,3,3)          |
| res4.18.conv3.*   | res4.18.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}                            | (1024,) (1024,) (1024,) (1024,) (1024,256,1,1)     |
| res4.19.conv1.*   | res4.19.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}                            | (256,) (256,) (256,) (256,) (256,1024,1,1)         |
| res4.19.conv2.*   | res4.19.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}                            | (256,) (256,) (256,) (256,) (256,256,3,3)          |
| res4.19.conv3.*   | res4.19.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}                            | (1024,) (1024,) (1024,) (1024,) (1024,256,1,1)     |
| res4.2.conv1.*    | res4.2.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}                             | (256,) (256,) (256,) (256,) (256,1024,1,1)         |
| res4.2.conv2.*    | res4.2.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}                             | (256,) (256,) (256,) (256,) (256,256,3,3)          |
| res4.2.conv3.*    | res4.2.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}                             | (1024,) (1024,) (1024,) (1024,) (1024,256,1,1)     |
| res4.20.conv1.*   | res4.20.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}                            | (256,) (256,) (256,) (256,) (256,1024,1,1)         |
| res4.20.conv2.*   | res4.20.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}                            | (256,) (256,) (256,) (256,) (256,256,3,3)          |
| res4.20.conv3.*   | res4.20.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}                            | (1024,) (1024,) (1024,) (1024,) (1024,256,1,1)     |
| res4.21.conv1.*   | res4.21.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}                            | (256,) (256,) (256,) (256,) (256,1024,1,1)         |
| res4.21.conv2.*   | res4.21.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}                            | (256,) (256,) (256,) (256,) (256,256,3,3)          |
| res4.21.conv3.*   | res4.21.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}                            | (1024,) (1024,) (1024,) (1024,) (1024,256,1,1)     |
| res4.22.conv1.*   | res4.22.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}                            | (256,) (256,) (256,) (256,) (256,1024,1,1)         |
| res4.22.conv2.*   | res4.22.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}                            | (256,) (256,) (256,) (256,) (256,256,3,3)          |
| res4.22.conv3.*   | res4.22.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}                            | (1024,) (1024,) (1024,) (1024,) (1024,256,1,1)     |
| res4.3.conv1.*    | res4.3.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}                             | (256,) (256,) (256,) (256,) (256,1024,1,1)         |
| res4.3.conv2.*    | res4.3.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}                             | (256,) (256,) (256,) (256,) (256,256,3,3)          |
| res4.3.conv3.*    | res4.3.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}                             | (1024,) (1024,) (1024,) (1024,) (1024,256,1,1)     |
| res4.4.conv1.*    | res4.4.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}                             | (256,) (256,) (256,) (256,) (256,1024,1,1)         |
| res4.4.conv2.*    | res4.4.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}                             | (256,) (256,) (256,) (256,) (256,256,3,3)          |
| res4.4.conv3.*    | res4.4.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}                             | (1024,) (1024,) (1024,) (1024,) (1024,256,1,1)     |
| res4.5.conv1.*    | res4.5.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}                             | (256,) (256,) (256,) (256,) (256,1024,1,1)         |
| res4.5.conv2.*    | res4.5.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}                             | (256,) (256,) (256,) (256,) (256,256,3,3)          |
| res4.5.conv3.*    | res4.5.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}                             | (1024,) (1024,) (1024,) (1024,) (1024,256,1,1)     |
| res4.6.conv1.*    | res4.6.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}                             | (256,) (256,) (256,) (256,) (256,1024,1,1)         |
| res4.6.conv2.*    | res4.6.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}                             | (256,) (256,) (256,) (256,) (256,256,3,3)          |
| res4.6.conv3.*    | res4.6.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}                             | (1024,) (1024,) (1024,) (1024,) (1024,256,1,1)     |
| res4.7.conv1.*    | res4.7.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}                             | (256,) (256,) (256,) (256,) (256,1024,1,1)         |
| res4.7.conv2.*    | res4.7.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}                             | (256,) (256,) (256,) (256,) (256,256,3,3)          |
| res4.7.conv3.*    | res4.7.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}                             | (1024,) (1024,) (1024,) (1024,) (1024,256,1,1)     |
| res4.8.conv1.*    | res4.8.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}                             | (256,) (256,) (256,) (256,) (256,1024,1,1)         |
| res4.8.conv2.*    | res4.8.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}                             | (256,) (256,) (256,) (256,) (256,256,3,3)          |
| res4.8.conv3.*    | res4.8.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}                             | (1024,) (1024,) (1024,) (1024,) (1024,256,1,1)     |
| res4.9.conv1.*    | res4.9.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}                             | (256,) (256,) (256,) (256,) (256,1024,1,1)         |
| res4.9.conv2.*    | res4.9.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}                             | (256,) (256,) (256,) (256,) (256,256,3,3)          |
| res4.9.conv3.*    | res4.9.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}                             | (1024,) (1024,) (1024,) (1024,) (1024,256,1,1)     |
| res5.0.conv1.*    | res5.0.conv1.{norm.bias,norm.num_batches_tracked,norm.running_mean,norm.running_var,norm.weight,weight}    | (512,) () (512,) (512,) (512,) (512,1024,1,1)      |
| res5.0.conv2.*    | res5.0.conv2.{norm.bias,norm.num_batches_tracked,norm.running_mean,norm.running_var,norm.weight,weight}    | (512,) () (512,) (512,) (512,) (512,512,3,3)       |
| res5.0.conv3.*    | res5.0.conv3.{norm.bias,norm.num_batches_tracked,norm.running_mean,norm.running_var,norm.weight,weight}    | (2048,) () (2048,) (2048,) (2048,) (2048,512,1,1)  |
| res5.0.shortcut.* | res5.0.shortcut.{norm.bias,norm.num_batches_tracked,norm.running_mean,norm.running_var,norm.weight,weight} | (2048,) () (2048,) (2048,) (2048,) (2048,1024,1,1) |
| res5.1.conv1.*    | res5.1.conv1.{norm.bias,norm.num_batches_tracked,norm.running_mean,norm.running_var,norm.weight,weight}    | (512,) () (512,) (512,) (512,) (512,2048,1,1)      |
| res5.1.conv2.*    | res5.1.conv2.{norm.bias,norm.num_batches_tracked,norm.running_mean,norm.running_var,norm.weight,weight}    | (512,) () (512,) (512,) (512,) (512,512,3,3)       |
| res5.1.conv3.*    | res5.1.conv3.{norm.bias,norm.num_batches_tracked,norm.running_mean,norm.running_var,norm.weight,weight}    | (2048,) () (2048,) (2048,) (2048,) (2048,512,1,1)  |
| res5.2.conv1.*    | res5.2.conv1.{norm.bias,norm.num_batches_tracked,norm.running_mean,norm.running_var,norm.weight,weight}    | (512,) () (512,) (512,) (512,) (512,2048,1,1)      |
| res5.2.conv2.*    | res5.2.conv2.{norm.bias,norm.num_batches_tracked,norm.running_mean,norm.running_var,norm.weight,weight}    | (512,) () (512,) (512,) (512,) (512,512,3,3)       |
| res5.2.conv3.*    | res5.2.conv3.{norm.bias,norm.num_batches_tracked,norm.running_mean,norm.running_var,norm.weight,weight}    | (2048,) () (2048,) (2048,) (2048,) (2048,512,1,1)  |
| stem.conv1.*      | stem.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}                               | (64,) (64,) (64,) (64,) (64,3,3,3)                 |
| stem.conv2.*      | stem.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}                               | (64,) (64,) (64,) (64,) (64,64,3,3)                |
| stem.conv3.*      | stem.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}                               | (128,) (128,) (128,) (128,) (128,64,3,3)           |
WARNING [12/11 23:06:11 fvcore.common.checkpoint]: Some model parameters or buffers are not found in the checkpoint:
ins_embed_head.center_head.0.norm.{bias, running_mean, running_var, weight}
ins_embed_head.center_head.0.weight
ins_embed_head.center_head.1.norm.{bias, running_mean, running_var, weight}
ins_embed_head.center_head.1.weight
ins_embed_head.center_predictor.{bias, weight}
ins_embed_head.decoder.res2.fuse_conv.depthwise.norm.{bias, running_mean, running_var, weight}
ins_embed_head.decoder.res2.fuse_conv.depthwise.weight
ins_embed_head.decoder.res2.fuse_conv.pointwise.norm.{bias, running_mean, running_var, weight}
ins_embed_head.decoder.res2.fuse_conv.pointwise.weight
ins_embed_head.decoder.res2.project_conv.norm.{bias, running_mean, running_var, weight}
ins_embed_head.decoder.res2.project_conv.weight
ins_embed_head.decoder.res3.fuse_conv.depthwise.norm.{bias, running_mean, running_var, weight}
ins_embed_head.decoder.res3.fuse_conv.depthwise.weight
ins_embed_head.decoder.res3.fuse_conv.pointwise.norm.{bias, running_mean, running_var, weight}
ins_embed_head.decoder.res3.fuse_conv.pointwise.weight
ins_embed_head.decoder.res3.project_conv.norm.{bias, running_mean, running_var, weight}
ins_embed_head.decoder.res3.project_conv.weight
ins_embed_head.decoder.res5.project_conv.convs.0.norm.{bias, running_mean, running_var, weight}
ins_embed_head.decoder.res5.project_conv.convs.0.weight
ins_embed_head.decoder.res5.project_conv.convs.1.depthwise.norm.{bias, running_mean, running_var, weight}
ins_embed_head.decoder.res5.project_conv.convs.1.depthwise.weight
ins_embed_head.decoder.res5.project_conv.convs.1.pointwise.norm.{bias, running_mean, running_var, weight}
ins_embed_head.decoder.res5.project_conv.convs.1.pointwise.weight
ins_embed_head.decoder.res5.project_conv.convs.2.depthwise.norm.{bias, running_mean, running_var, weight}
ins_embed_head.decoder.res5.project_conv.convs.2.depthwise.weight
ins_embed_head.decoder.res5.project_conv.convs.2.pointwise.norm.{bias, running_mean, running_var, weight}
ins_embed_head.decoder.res5.project_conv.convs.2.pointwise.weight
ins_embed_head.decoder.res5.project_conv.convs.3.depthwise.norm.{bias, running_mean, running_var, weight}
ins_embed_head.decoder.res5.project_conv.convs.3.depthwise.weight
ins_embed_head.decoder.res5.project_conv.convs.3.pointwise.norm.{bias, running_mean, running_var, weight}
ins_embed_head.decoder.res5.project_conv.convs.3.pointwise.weight
ins_embed_head.decoder.res5.project_conv.convs.4.1.{bias, weight}
ins_embed_head.decoder.res5.project_conv.project.norm.{bias, running_mean, running_var, weight}
ins_embed_head.decoder.res5.project_conv.project.weight
ins_embed_head.offset_head.depthwise.norm.{bias, running_mean, running_var, weight}
ins_embed_head.offset_head.depthwise.weight
ins_embed_head.offset_head.pointwise.norm.{bias, running_mean, running_var, weight}
ins_embed_head.offset_head.pointwise.weight
ins_embed_head.offset_predictor.{bias, weight}
sem_seg_head.decoder.res2.fuse_conv.depthwise.norm.{bias, running_mean, running_var, weight}
sem_seg_head.decoder.res2.fuse_conv.depthwise.weight
sem_seg_head.decoder.res2.fuse_conv.pointwise.norm.{bias, running_mean, running_var, weight}
sem_seg_head.decoder.res2.fuse_conv.pointwise.weight
sem_seg_head.decoder.res2.project_conv.norm.{bias, running_mean, running_var, weight}
sem_seg_head.decoder.res2.project_conv.weight
sem_seg_head.decoder.res3.fuse_conv.depthwise.norm.{bias, running_mean, running_var, weight}
sem_seg_head.decoder.res3.fuse_conv.depthwise.weight
sem_seg_head.decoder.res3.fuse_conv.pointwise.norm.{bias, running_mean, running_var, weight}
sem_seg_head.decoder.res3.fuse_conv.pointwise.weight
sem_seg_head.decoder.res3.project_conv.norm.{bias, running_mean, running_var, weight}
sem_seg_head.decoder.res3.project_conv.weight
sem_seg_head.decoder.res5.project_conv.convs.0.norm.{bias, running_mean, running_var, weight}
sem_seg_head.decoder.res5.project_conv.convs.0.weight
sem_seg_head.decoder.res5.project_conv.convs.1.depthwise.norm.{bias, running_mean, running_var, weight}
sem_seg_head.decoder.res5.project_conv.convs.1.depthwise.weight
sem_seg_head.decoder.res5.project_conv.convs.1.pointwise.norm.{bias, running_mean, running_var, weight}
sem_seg_head.decoder.res5.project_conv.convs.1.pointwise.weight
sem_seg_head.decoder.res5.project_conv.convs.2.depthwise.norm.{bias, running_mean, running_var, weight}
sem_seg_head.decoder.res5.project_conv.convs.2.depthwise.weight
sem_seg_head.decoder.res5.project_conv.convs.2.pointwise.norm.{bias, running_mean, running_var, weight}
sem_seg_head.decoder.res5.project_conv.convs.2.pointwise.weight
sem_seg_head.decoder.res5.project_conv.convs.3.depthwise.norm.{bias, running_mean, running_var, weight}
sem_seg_head.decoder.res5.project_conv.convs.3.depthwise.weight
sem_seg_head.decoder.res5.project_conv.convs.3.pointwise.norm.{bias, running_mean, running_var, weight}
sem_seg_head.decoder.res5.project_conv.convs.3.pointwise.weight
sem_seg_head.decoder.res5.project_conv.convs.4.1.{bias, weight}
sem_seg_head.decoder.res5.project_conv.project.norm.{bias, running_mean, running_var, weight}
sem_seg_head.decoder.res5.project_conv.project.weight
sem_seg_head.head.depthwise.norm.{bias, running_mean, running_var, weight}
sem_seg_head.head.depthwise.weight
sem_seg_head.head.pointwise.norm.{bias, running_mean, running_var, weight}
sem_seg_head.head.pointwise.weight
sem_seg_head.predictor.{bias, weight}
WARNING [12/11 23:06:11 fvcore.common.checkpoint]: The checkpoint state_dict contains keys that are not used by the model:
  res2.0.conv1.norm.num_batches_tracked
  res2.0.conv2.norm.num_batches_tracked
  res2.0.conv3.norm.num_batches_tracked
  res2.0.shortcut.norm.num_batches_tracked
  res2.1.conv1.norm.num_batches_tracked
  res2.1.conv2.norm.num_batches_tracked
  res2.1.conv3.norm.num_batches_tracked
  res2.2.conv1.norm.num_batches_tracked
  res2.2.conv2.norm.num_batches_tracked
  res2.2.conv3.norm.num_batches_tracked
  res3.0.conv1.norm.num_batches_tracked
  res3.0.conv2.norm.num_batches_tracked
  res3.0.conv3.norm.num_batches_tracked
  res3.0.shortcut.norm.num_batches_tracked
  res3.1.conv1.norm.num_batches_tracked
  res3.1.conv2.norm.num_batches_tracked
  res3.1.conv3.norm.num_batches_tracked
  res3.2.conv1.norm.num_batches_tracked
  res3.2.conv2.norm.num_batches_tracked
  res3.2.conv3.norm.num_batches_tracked
  res3.3.conv1.norm.num_batches_tracked
  res3.3.conv2.norm.num_batches_tracked
  res3.3.conv3.norm.num_batches_tracked
  res4.0.conv1.norm.num_batches_tracked
  res4.0.conv2.norm.num_batches_tracked
  res4.0.conv3.norm.num_batches_tracked
  res4.0.shortcut.norm.num_batches_tracked
  res4.1.conv1.norm.num_batches_tracked
  res4.1.conv2.norm.num_batches_tracked
  res4.1.conv3.norm.num_batches_tracked
  res4.10.conv1.norm.num_batches_tracked
  res4.10.conv2.norm.num_batches_tracked
  res4.10.conv3.norm.num_batches_tracked
  res4.11.conv1.norm.num_batches_tracked
  res4.11.conv2.norm.num_batches_tracked
  res4.11.conv3.norm.num_batches_tracked
  res4.12.conv1.norm.num_batches_tracked
  res4.12.conv2.norm.num_batches_tracked
  res4.12.conv3.norm.num_batches_tracked
  res4.13.conv1.norm.num_batches_tracked
  res4.13.conv2.norm.num_batches_tracked
  res4.13.conv3.norm.num_batches_tracked
  res4.14.conv1.norm.num_batches_tracked
  res4.14.conv2.norm.num_batches_tracked
  res4.14.conv3.norm.num_batches_tracked
  res4.15.conv1.norm.num_batches_tracked
  res4.15.conv2.norm.num_batches_tracked
  res4.15.conv3.norm.num_batches_tracked
  res4.16.conv1.norm.num_batches_tracked
  res4.16.conv2.norm.num_batches_tracked
  res4.16.conv3.norm.num_batches_tracked
  res4.17.conv1.norm.num_batches_tracked
  res4.17.conv2.norm.num_batches_tracked
  res4.17.conv3.norm.num_batches_tracked
  res4.18.conv1.norm.num_batches_tracked
  res4.18.conv2.norm.num_batches_tracked
  res4.18.conv3.norm.num_batches_tracked
  res4.19.conv1.norm.num_batches_tracked
  res4.19.conv2.norm.num_batches_tracked
  res4.19.conv3.norm.num_batches_tracked
  res4.2.conv1.norm.num_batches_tracked
  res4.2.conv2.norm.num_batches_tracked
  res4.2.conv3.norm.num_batches_tracked
  res4.20.conv1.norm.num_batches_tracked
  res4.20.conv2.norm.num_batches_tracked
  res4.20.conv3.norm.num_batches_tracked
  res4.21.conv1.norm.num_batches_tracked
  res4.21.conv2.norm.num_batches_tracked
  res4.21.conv3.norm.num_batches_tracked
  res4.22.conv1.norm.num_batches_tracked
  res4.22.conv2.norm.num_batches_tracked
  res4.22.conv3.norm.num_batches_tracked
  res4.3.conv1.norm.num_batches_tracked
  res4.3.conv2.norm.num_batches_tracked
  res4.3.conv3.norm.num_batches_tracked
  res4.4.conv1.norm.num_batches_tracked
  res4.4.conv2.norm.num_batches_tracked
  res4.4.conv3.norm.num_batches_tracked
  res4.5.conv1.norm.num_batches_tracked
  res4.5.conv2.norm.num_batches_tracked
  res4.5.conv3.norm.num_batches_tracked
  res4.6.conv1.norm.num_batches_tracked
  res4.6.conv2.norm.num_batches_tracked
  res4.6.conv3.norm.num_batches_tracked
  res4.7.conv1.norm.num_batches_tracked
  res4.7.conv2.norm.num_batches_tracked
  res4.7.conv3.norm.num_batches_tracked
  res4.8.conv1.norm.num_batches_tracked
  res4.8.conv2.norm.num_batches_tracked
  res4.8.conv3.norm.num_batches_tracked
  res4.9.conv1.norm.num_batches_tracked
  res4.9.conv2.norm.num_batches_tracked
  res4.9.conv3.norm.num_batches_tracked
  stem.conv1.norm.num_batches_tracked
  stem.conv2.norm.num_batches_tracked
  stem.conv3.norm.num_batches_tracked
  stem.fc.{bias, weight}
[12/11 23:06:11 d2.engine.train_loop]: Starting training from iteration 0
/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:481: UserWarning: This DataLoader will create 10 worker processes in total. Our suggested max number of worker in current system is 8, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.
  cpuset_checked))
[12/11 23:06:19 d2.utils.events]:  eta: 0:57:11  iter: 19  total_loss: 6.011  loss_sem_seg: 3.549  loss_center: 0.8396  loss_offset: 1.594  time: 0.3479  data_time: 0.0773  lr: 4.9867e-05  max_mem: 7418M
[12/11 23:06:26 d2.utils.events]:  eta: 0:57:44  iter: 39  total_loss: 5.989  loss_sem_seg: 3.406  loss_center: 0.692  loss_offset: 1.675  time: 0.3491  data_time: 0.0261  lr: 9.9552e-05  max_mem: 7419M
[12/11 23:06:33 d2.utils.events]:  eta: 0:57:59  iter: 59  total_loss: 5.864  loss_sem_seg: 3.615  loss_center: 0.5714  loss_offset: 1.586  time: 0.3497  data_time: 0.0257  lr: 0.00014906  max_mem: 7419M
[12/11 23:06:41 d2.utils.events]:  eta: 0:57:55  iter: 79  total_loss: 5.708  loss_sem_seg: 3.287  loss_center: 0.6848  loss_offset: 1.702  time: 0.3504  data_time: 0.0279  lr: 0.00019838  max_mem: 7419M
[12/11 23:06:47 d2.utils.events]:  eta: 0:57:45  iter: 99  total_loss: 5.292  loss_sem_seg: 3.103  loss_center: 0.6514  loss_offset: 1.547  time: 0.3501  data_time: 0.0245  lr: 0.00024753  max_mem: 7419M
[12/11 23:06:55 d2.utils.events]:  eta: 0:57:42  iter: 119  total_loss: 5.573  loss_sem_seg: 3.089  loss_center: 0.7301  loss_offset: 1.68  time: 0.3506  data_time: 0.0283  lr: 0.00029649  max_mem: 7419M
[12/11 23:07:02 d2.utils.events]:  eta: 0:57:31  iter: 139  total_loss: 4.99  loss_sem_seg: 2.904  loss_center: 0.6904  loss_offset: 1.375  time: 0.3504  data_time: 0.0269  lr: 0.00034528  max_mem: 7419M
[12/11 23:07:09 d2.utils.events]:  eta: 0:57:24  iter: 159  total_loss: 5.129  loss_sem_seg: 2.655  loss_center: 0.7379  loss_offset: 1.72  time: 0.3505  data_time: 0.0277  lr: 0.00039388  max_mem: 7419M
[12/11 23:07:16 d2.utils.events]:  eta: 0:57:11  iter: 179  total_loss: 4.771  loss_sem_seg: 2.764  loss_center: 0.63  loss_offset: 1.414  time: 0.3508  data_time: 0.0282  lr: 0.0004423  max_mem: 7419M
[12/11 23:07:23 d2.utils.events]:  eta: 0:56:54  iter: 199  total_loss: 4.406  loss_sem_seg: 2.469  loss_center: 0.558  loss_offset: 1.25  time: 0.3506  data_time: 0.0250  lr: 0.00049055  max_mem: 7419M
[12/11 23:07:30 d2.utils.events]:  eta: 0:56:58  iter: 219  total_loss: 4.66  loss_sem_seg: 2.369  loss_center: 0.6085  loss_offset: 1.566  time: 0.3505  data_time: 0.0262  lr: 0.00053861  max_mem: 7419M
[12/11 23:07:37 d2.utils.events]:  eta: 0:56:40  iter: 239  total_loss: 4.629  loss_sem_seg: 2.422  loss_center: 0.5845  loss_offset: 1.372  time: 0.3505  data_time: 0.0282  lr: 0.00058649  max_mem: 7419M
[12/11 23:07:44 d2.utils.events]:  eta: 0:56:42  iter: 259  total_loss: 4.705  loss_sem_seg: 2.486  loss_center: 0.6192  loss_offset: 1.559  time: 0.3507  data_time: 0.0280  lr: 0.0006342  max_mem: 7419M
[12/11 23:07:51 d2.utils.events]:  eta: 0:56:35  iter: 279  total_loss: 4.449  loss_sem_seg: 2.384  loss_center: 0.556  loss_offset: 1.511  time: 0.3507  data_time: 0.0262  lr: 0.00068172  max_mem: 7419M
[12/11 23:07:58 d2.utils.events]:  eta: 0:56:24  iter: 299  total_loss: 4.124  loss_sem_seg: 2.183  loss_center: 0.6844  loss_offset: 1.279  time: 0.3507  data_time: 0.0273  lr: 0.00072906  max_mem: 7419M
[12/11 23:08:05 d2.utils.events]:  eta: 0:56:20  iter: 319  total_loss: 4.051  loss_sem_seg: 2.172  loss_center: 0.6044  loss_offset: 1.25  time: 0.3509  data_time: 0.0292  lr: 0.00077622  max_mem: 7419M
[12/11 23:08:12 d2.utils.events]:  eta: 0:56:16  iter: 339  total_loss: 4.104  loss_sem_seg: 2.169  loss_center: 0.4609  loss_offset: 1.325  time: 0.3508  data_time: 0.0271  lr: 0.0008232  max_mem: 7419M
[12/11 23:08:19 d2.utils.events]:  eta: 0:56:10  iter: 359  total_loss: 4.175  loss_sem_seg: 2.193  loss_center: 0.6787  loss_offset: 1.251  time: 0.3508  data_time: 0.0274  lr: 0.00087  max_mem: 7419M
[12/11 23:08:26 d2.utils.events]:  eta: 0:56:02  iter: 379  total_loss: 3.972  loss_sem_seg: 2.117  loss_center: 0.4646  loss_offset: 1.248  time: 0.3509  data_time: 0.0257  lr: 0.00091662  max_mem: 7419M
[12/11 23:08:33 d2.utils.events]:  eta: 0:55:55  iter: 399  total_loss: 3.987  loss_sem_seg: 2.107  loss_center: 0.6017  loss_offset: 1.218  time: 0.3508  data_time: 0.0256  lr: 0.00096306  max_mem: 7419M
[12/11 23:08:40 d2.utils.events]:  eta: 0:55:50  iter: 419  total_loss: 3.975  loss_sem_seg: 1.927  loss_center: 0.5803  loss_offset: 1.161  time: 0.3510  data_time: 0.0281  lr: 0.0010093  max_mem: 7419M
[12/11 23:08:47 d2.utils.events]:  eta: 0:55:42  iter: 439  total_loss: 4.115  loss_sem_seg: 2.332  loss_center: 0.5657  loss_offset: 1.077  time: 0.3509  data_time: 0.0261  lr: 0.0010554  max_mem: 7419M
[12/11 23:08:54 d2.utils.events]:  eta: 0:55:37  iter: 459  total_loss: 3.962  loss_sem_seg: 2.078  loss_center: 0.6644  loss_offset: 1.204  time: 0.3510  data_time: 0.0267  lr: 0.0011013  max_mem: 7419M
[12/11 23:09:01 d2.utils.events]:  eta: 0:55:30  iter: 479  total_loss: 3.76  loss_sem_seg: 1.928  loss_center: 0.6609  loss_offset: 0.9134  time: 0.3510  data_time: 0.0264  lr: 0.001147  max_mem: 7419M
[12/11 23:09:08 d2.utils.events]:  eta: 0:55:23  iter: 499  total_loss: 4.19  loss_sem_seg: 2.37  loss_center: 0.607  loss_offset: 1.07  time: 0.3510  data_time: 0.0277  lr: 0.0011925  max_mem: 7419M
[12/11 23:09:15 d2.utils.events]:  eta: 0:55:14  iter: 519  total_loss: 3.563  loss_sem_seg: 1.817  loss_center: 0.6085  loss_offset: 1.068  time: 0.3509  data_time: 0.0256  lr: 0.0012379  max_mem: 7419M
[12/11 23:09:22 d2.utils.events]:  eta: 0:55:07  iter: 539  total_loss: 3.705  loss_sem_seg: 2.095  loss_center: 0.6334  loss_offset: 0.9364  time: 0.3510  data_time: 0.0285  lr: 0.001283  max_mem: 7419M
[12/11 23:09:29 d2.utils.events]:  eta: 0:55:00  iter: 559  total_loss: 3.553  loss_sem_seg: 1.764  loss_center: 0.7207  loss_offset: 1.009  time: 0.3509  data_time: 0.0269  lr: 0.001328  max_mem: 7419M
[12/11 23:09:36 d2.utils.events]:  eta: 0:54:55  iter: 579  total_loss: 3.728  loss_sem_seg: 2.037  loss_center: 0.5749  loss_offset: 0.9185  time: 0.3510  data_time: 0.0271  lr: 0.0013728  max_mem: 7419M
[12/11 23:09:43 d2.utils.events]:  eta: 0:54:49  iter: 599  total_loss: 3.632  loss_sem_seg: 1.892  loss_center: 0.6055  loss_offset: 1.024  time: 0.3511  data_time: 0.0297  lr: 0.0014175  max_mem: 7419M
[12/11 23:09:50 d2.utils.events]:  eta: 0:54:41  iter: 619  total_loss: 3.848  loss_sem_seg: 2.007  loss_center: 0.6812  loss_offset: 0.9146  time: 0.3511  data_time: 0.0283  lr: 0.0014619  max_mem: 7419M
[12/11 23:09:57 d2.utils.events]:  eta: 0:54:36  iter: 639  total_loss: 3.468  loss_sem_seg: 1.781  loss_center: 0.7484  loss_offset: 0.9256  time: 0.3512  data_time: 0.0289  lr: 0.0015062  max_mem: 7419M
[12/11 23:10:05 d2.utils.events]:  eta: 0:54:29  iter: 659  total_loss: 3.469  loss_sem_seg: 1.837  loss_center: 0.5523  loss_offset: 0.956  time: 0.3513  data_time: 0.0291  lr: 0.0015503  max_mem: 7419M
[12/11 23:10:12 d2.utils.events]:  eta: 0:54:22  iter: 679  total_loss: 3.675  loss_sem_seg: 2.042  loss_center: 0.5301  loss_offset: 1.078  time: 0.3513  data_time: 0.0276  lr: 0.0015942  max_mem: 7419M
[12/11 23:10:19 d2.utils.events]:  eta: 0:54:15  iter: 699  total_loss: 3.398  loss_sem_seg: 1.823  loss_center: 0.5091  loss_offset: 0.9858  time: 0.3513  data_time: 0.0274  lr: 0.0016379  max_mem: 7419M
[12/11 23:10:26 d2.utils.events]:  eta: 0:54:09  iter: 719  total_loss: 3.195  loss_sem_seg: 1.688  loss_center: 0.5941  loss_offset: 0.7846  time: 0.3514  data_time: 0.0286  lr: 0.0016814  max_mem: 7419M
[12/11 23:10:33 d2.utils.events]:  eta: 0:54:02  iter: 739  total_loss: 3.541  loss_sem_seg: 2.005  loss_center: 0.6788  loss_offset: 0.8596  time: 0.3514  data_time: 0.0289  lr: 0.0017248  max_mem: 7419M
[12/11 23:10:40 d2.utils.events]:  eta: 0:53:55  iter: 759  total_loss: 3.515  loss_sem_seg: 1.881  loss_center: 0.6536  loss_offset: 0.9885  time: 0.3514  data_time: 0.0265  lr: 0.0017679  max_mem: 7419M
[12/11 23:10:47 d2.utils.events]:  eta: 0:53:49  iter: 779  total_loss: 3.419  loss_sem_seg: 1.814  loss_center: 0.6339  loss_offset: 0.8683  time: 0.3515  data_time: 0.0278  lr: 0.0018109  max_mem: 7419M
[12/11 23:10:54 d2.utils.events]:  eta: 0:53:44  iter: 799  total_loss: 3.275  loss_sem_seg: 1.834  loss_center: 0.6246  loss_offset: 0.856  time: 0.3515  data_time: 0.0272  lr: 0.0018537  max_mem: 7419M
[12/11 23:11:01 d2.utils.events]:  eta: 0:53:37  iter: 819  total_loss: 3.338  loss_sem_seg: 1.678  loss_center: 0.5469  loss_offset: 0.7981  time: 0.3515  data_time: 0.0285  lr: 0.0018964  max_mem: 7419M
[12/11 23:11:08 d2.utils.events]:  eta: 0:53:30  iter: 839  total_loss: 3.516  loss_sem_seg: 1.847  loss_center: 0.7227  loss_offset: 0.835  time: 0.3516  data_time: 0.0292  lr: 0.0019388  max_mem: 7419M
[12/11 23:11:15 d2.utils.events]:  eta: 0:53:24  iter: 859  total_loss: 3.164  loss_sem_seg: 1.808  loss_center: 0.5713  loss_offset: 0.87  time: 0.3516  data_time: 0.0268  lr: 0.0019811  max_mem: 7419M
[12/11 23:11:22 d2.utils.events]:  eta: 0:53:17  iter: 879  total_loss: 3.58  loss_sem_seg: 1.959  loss_center: 0.5806  loss_offset: 0.9083  time: 0.3516  data_time: 0.0284  lr: 0.0020231  max_mem: 7419M
[12/11 23:11:29 d2.utils.events]:  eta: 0:53:10  iter: 899  total_loss: 3.291  loss_sem_seg: 1.828  loss_center: 0.5829  loss_offset: 0.8024  time: 0.3516  data_time: 0.0272  lr: 0.002065  max_mem: 7419M
[12/11 23:11:36 d2.utils.events]:  eta: 0:53:05  iter: 919  total_loss: 3.36  loss_sem_seg: 1.782  loss_center: 0.5675  loss_offset: 0.7473  time: 0.3517  data_time: 0.0292  lr: 0.0021068  max_mem: 7419M
[12/11 23:11:43 d2.utils.events]:  eta: 0:52:58  iter: 939  total_loss: 3.329  loss_sem_seg: 1.87  loss_center: 0.5043  loss_offset: 0.8206  time: 0.3517  data_time: 0.0276  lr: 0.0021483  max_mem: 7419M
[12/11 23:11:50 d2.utils.events]:  eta: 0:52:52  iter: 959  total_loss: 3.097  loss_sem_seg: 1.787  loss_center: 0.6837  loss_offset: 0.7839  time: 0.3517  data_time: 0.0287  lr: 0.0021896  max_mem: 7419M
[12/11 23:11:58 d2.utils.events]:  eta: 0:52:45  iter: 979  total_loss: 3.476  loss_sem_seg: 1.789  loss_center: 0.5966  loss_offset: 0.8077  time: 0.3517  data_time: 0.0282  lr: 0.0022308  max_mem: 7419M
[12/11 23:12:05 d2.utils.events]:  eta: 0:52:39  iter: 999  total_loss: 2.951  loss_sem_seg: 1.508  loss_center: 0.6197  loss_offset: 0.6397  time: 0.3518  data_time: 0.0283  lr: 0.0022718  max_mem: 7419M
[12/11 23:12:12 d2.utils.events]:  eta: 0:52:32  iter: 1019  total_loss: 3.229  loss_sem_seg: 1.768  loss_center: 0.5761  loss_offset: 0.7368  time: 0.3517  data_time: 0.0269  lr: 0.0022695  max_mem: 7419M
[12/11 23:12:19 d2.utils.events]:  eta: 0:52:25  iter: 1039  total_loss: 3.105  loss_sem_seg: 1.654  loss_center: 0.6318  loss_offset: 0.9526  time: 0.3518  data_time: 0.0264  lr: 0.002265  max_mem: 7419M
[12/11 23:12:26 d2.utils.events]:  eta: 0:52:17  iter: 1059  total_loss: 3.299  loss_sem_seg: 1.676  loss_center: 0.5505  loss_offset: 0.9202  time: 0.3517  data_time: 0.0265  lr: 0.0022604  max_mem: 7419M
[12/11 23:12:33 d2.utils.events]:  eta: 0:52:09  iter: 1079  total_loss: 3.006  loss_sem_seg: 1.795  loss_center: 0.5949  loss_offset: 0.735  time: 0.3517  data_time: 0.0285  lr: 0.0022559  max_mem: 7419M
[12/11 23:12:40 d2.utils.events]:  eta: 0:52:04  iter: 1099  total_loss: 2.898  loss_sem_seg: 1.709  loss_center: 0.4963  loss_offset: 0.7624  time: 0.3517  data_time: 0.0273  lr: 0.0022513  max_mem: 7419M
[12/11 23:12:47 d2.utils.events]:  eta: 0:51:57  iter: 1119  total_loss: 3.014  loss_sem_seg: 1.84  loss_center: 0.528  loss_offset: 0.6724  time: 0.3518  data_time: 0.0274  lr: 0.0022468  max_mem: 7419M
[12/11 23:12:54 d2.utils.events]:  eta: 0:51:51  iter: 1139  total_loss: 3.174  loss_sem_seg: 1.603  loss_center: 0.6784  loss_offset: 0.7659  time: 0.3518  data_time: 0.0278  lr: 0.0022422  max_mem: 7419M
[12/11 23:13:01 d2.utils.events]:  eta: 0:51:46  iter: 1159  total_loss: 3.132  loss_sem_seg: 1.622  loss_center: 0.5392  loss_offset: 0.7432  time: 0.3518  data_time: 0.0295  lr: 0.0022376  max_mem: 7419M
[12/11 23:13:08 d2.utils.events]:  eta: 0:51:40  iter: 1179  total_loss: 3.206  loss_sem_seg: 1.769  loss_center: 0.5724  loss_offset: 0.7923  time: 0.3518  data_time: 0.0271  lr: 0.0022331  max_mem: 7419M
[12/11 23:13:15 d2.utils.events]:  eta: 0:51:33  iter: 1199  total_loss: 3.219  loss_sem_seg: 1.815  loss_center: 0.5486  loss_offset: 0.7035  time: 0.3518  data_time: 0.0274  lr: 0.0022285  max_mem: 7419M
[12/11 23:13:22 d2.utils.events]:  eta: 0:51:26  iter: 1219  total_loss: 2.867  loss_sem_seg: 1.518  loss_center: 0.5564  loss_offset: 0.7426  time: 0.3518  data_time: 0.0285  lr: 0.002224  max_mem: 7419M
[12/11 23:13:29 d2.utils.events]:  eta: 0:51:20  iter: 1239  total_loss: 3.2  loss_sem_seg: 1.657  loss_center: 0.4915  loss_offset: 0.7308  time: 0.3518  data_time: 0.0288  lr: 0.0022194  max_mem: 7419M
[12/11 23:13:36 d2.utils.events]:  eta: 0:51:13  iter: 1259  total_loss: 3.142  loss_sem_seg: 1.705  loss_center: 0.5682  loss_offset: 0.656  time: 0.3519  data_time: 0.0279  lr: 0.0022149  max_mem: 7419M
[12/11 23:13:43 d2.utils.events]:  eta: 0:51:06  iter: 1279  total_loss: 3.253  loss_sem_seg: 1.653  loss_center: 0.6475  loss_offset: 0.7858  time: 0.3518  data_time: 0.0261  lr: 0.0022103  max_mem: 7419M
[12/11 23:13:50 d2.utils.events]:  eta: 0:51:01  iter: 1299  total_loss: 2.972  loss_sem_seg: 1.614  loss_center: 0.5383  loss_offset: 0.7476  time: 0.3519  data_time: 0.0285  lr: 0.0022057  max_mem: 7419M
[12/11 23:13:58 d2.utils.events]:  eta: 0:50:54  iter: 1319  total_loss: 3.131  loss_sem_seg: 1.482  loss_center: 0.6789  loss_offset: 0.7515  time: 0.3519  data_time: 0.0283  lr: 0.0022012  max_mem: 7419M
[12/11 23:14:05 d2.utils.events]:  eta: 0:50:47  iter: 1339  total_loss: 2.728  loss_sem_seg: 1.34  loss_center: 0.5539  loss_offset: 0.6309  time: 0.3519  data_time: 0.0261  lr: 0.0021966  max_mem: 7419M
[12/11 23:14:12 d2.utils.events]:  eta: 0:50:42  iter: 1359  total_loss: 3.093  loss_sem_seg: 1.757  loss_center: 0.4242  loss_offset: 0.8877  time: 0.3519  data_time: 0.0283  lr: 0.002192  max_mem: 7419M
[12/11 23:14:19 d2.utils.events]:  eta: 0:50:37  iter: 1379  total_loss: 2.998  loss_sem_seg: 1.717  loss_center: 0.5215  loss_offset: 0.7534  time: 0.3520  data_time: 0.0298  lr: 0.0021875  max_mem: 7419M
[12/11 23:14:26 d2.utils.events]:  eta: 0:50:30  iter: 1399  total_loss: 2.947  loss_sem_seg: 1.351  loss_center: 0.6529  loss_offset: 0.766  time: 0.3520  data_time: 0.0288  lr: 0.0021829  max_mem: 7419M
[12/11 23:14:33 d2.utils.events]:  eta: 0:50:23  iter: 1419  total_loss: 2.884  loss_sem_seg: 1.718  loss_center: 0.4912  loss_offset: 0.7291  time: 0.3520  data_time: 0.0291  lr: 0.0021783  max_mem: 7419M
[12/11 23:14:40 d2.utils.events]:  eta: 0:50:16  iter: 1439  total_loss: 2.73  loss_sem_seg: 1.363  loss_center: 0.523  loss_offset: 0.5597  time: 0.3520  data_time: 0.0270  lr: 0.0021738  max_mem: 7419M
[12/11 23:14:47 d2.utils.events]:  eta: 0:50:09  iter: 1459  total_loss: 2.834  loss_sem_seg: 1.516  loss_center: 0.5364  loss_offset: 0.71  time: 0.3521  data_time: 0.0284  lr: 0.0021692  max_mem: 7419M
[12/11 23:14:54 d2.utils.events]:  eta: 0:50:02  iter: 1479  total_loss: 3.164  loss_sem_seg: 1.761  loss_center: 0.5631  loss_offset: 0.7356  time: 0.3520  data_time: 0.0268  lr: 0.0021646  max_mem: 7419M
[12/11 23:15:01 d2.utils.events]:  eta: 0:49:54  iter: 1499  total_loss: 2.834  loss_sem_seg: 1.386  loss_center: 0.7517  loss_offset: 0.67  time: 0.3520  data_time: 0.0281  lr: 0.00216  max_mem: 7419M
[12/11 23:15:08 d2.utils.events]:  eta: 0:49:48  iter: 1519  total_loss: 2.593  loss_sem_seg: 1.257  loss_center: 0.5025  loss_offset: 0.8126  time: 0.3521  data_time: 0.0278  lr: 0.0021555  max_mem: 7419M
[12/11 23:15:15 d2.utils.events]:  eta: 0:49:41  iter: 1539  total_loss: 2.944  loss_sem_seg: 1.659  loss_center: 0.5108  loss_offset: 0.7597  time: 0.3520  data_time: 0.0268  lr: 0.0021509  max_mem: 7419M
[12/11 23:15:22 d2.utils.events]:  eta: 0:49:34  iter: 1559  total_loss: 2.866  loss_sem_seg: 1.497  loss_center: 0.6478  loss_offset: 0.7353  time: 0.3520  data_time: 0.0276  lr: 0.0021463  max_mem: 7419M
[12/11 23:15:29 d2.utils.events]:  eta: 0:49:27  iter: 1579  total_loss: 2.724  loss_sem_seg: 1.397  loss_center: 0.6109  loss_offset: 0.6947  time: 0.3520  data_time: 0.0278  lr: 0.0021417  max_mem: 7419M
[12/11 23:15:36 d2.utils.events]:  eta: 0:49:19  iter: 1599  total_loss: 2.842  loss_sem_seg: 1.493  loss_center: 0.5431  loss_offset: 0.7239  time: 0.3521  data_time: 0.0291  lr: 0.0021372  max_mem: 7419M
[12/11 23:15:44 d2.utils.events]:  eta: 0:49:12  iter: 1619  total_loss: 3.091  loss_sem_seg: 1.603  loss_center: 0.583  loss_offset: 0.792  time: 0.3521  data_time: 0.0286  lr: 0.0021326  max_mem: 7419M
[12/11 23:15:51 d2.utils.events]:  eta: 0:49:05  iter: 1639  total_loss: 2.848  loss_sem_seg: 1.5  loss_center: 0.6187  loss_offset: 0.6597  time: 0.3521  data_time: 0.0279  lr: 0.002128  max_mem: 7419M
[12/11 23:15:58 d2.utils.events]:  eta: 0:48:57  iter: 1659  total_loss: 2.976  loss_sem_seg: 1.715  loss_center: 0.6069  loss_offset: 0.6956  time: 0.3521  data_time: 0.0281  lr: 0.0021234  max_mem: 7419M
[12/11 23:16:05 d2.utils.events]:  eta: 0:48:51  iter: 1679  total_loss: 2.777  loss_sem_seg: 1.484  loss_center: 0.5872  loss_offset: 0.7163  time: 0.3521  data_time: 0.0292  lr: 0.0021188  max_mem: 7419M
[12/11 23:16:12 d2.utils.events]:  eta: 0:48:44  iter: 1699  total_loss: 3.103  loss_sem_seg: 1.736  loss_center: 0.4888  loss_offset: 0.7947  time: 0.3521  data_time: 0.0293  lr: 0.0021143  max_mem: 7419M
[12/11 23:16:19 d2.utils.events]:  eta: 0:48:37  iter: 1719  total_loss: 2.802  loss_sem_seg: 1.361  loss_center: 0.6436  loss_offset: 0.7682  time: 0.3521  data_time: 0.0301  lr: 0.0021097  max_mem: 7419M
[12/11 23:16:26 d2.utils.events]:  eta: 0:48:30  iter: 1739  total_loss: 2.404  loss_sem_seg: 1.219  loss_center: 0.4527  loss_offset: 0.783  time: 0.3521  data_time: 0.0267  lr: 0.0021051  max_mem: 7419M
[12/11 23:16:33 d2.utils.events]:  eta: 0:48:23  iter: 1759  total_loss: 3.002  loss_sem_seg: 1.419  loss_center: 0.646  loss_offset: 0.7884  time: 0.3521  data_time: 0.0267  lr: 0.0021005  max_mem: 7419M
[12/11 23:16:40 d2.utils.events]:  eta: 0:48:16  iter: 1779  total_loss: 3.153  loss_sem_seg: 1.655  loss_center: 0.5196  loss_offset: 0.9026  time: 0.3521  data_time: 0.0297  lr: 0.0020959  max_mem: 7419M
[12/11 23:16:47 d2.utils.events]:  eta: 0:48:09  iter: 1799  total_loss: 3.068  loss_sem_seg: 1.43  loss_center: 0.8463  loss_offset: 0.712  time: 0.3521  data_time: 0.0279  lr: 0.0020913  max_mem: 7419M
[12/11 23:16:54 d2.utils.events]:  eta: 0:48:00  iter: 1819  total_loss: 3.191  loss_sem_seg: 1.837  loss_center: 0.6821  loss_offset: 0.723  time: 0.3521  data_time: 0.0281  lr: 0.0020867  max_mem: 7419M
[12/11 23:17:01 d2.utils.events]:  eta: 0:47:54  iter: 1839  total_loss: 2.863  loss_sem_seg: 1.414  loss_center: 0.5544  loss_offset: 0.7478  time: 0.3521  data_time: 0.0286  lr: 0.0020821  max_mem: 7419M
[12/11 23:17:08 d2.utils.events]:  eta: 0:47:47  iter: 1859  total_loss: 2.801  loss_sem_seg: 1.558  loss_center: 0.5184  loss_offset: 0.6965  time: 0.3522  data_time: 0.0291  lr: 0.0020775  max_mem: 7419M
[12/11 23:17:15 d2.utils.events]:  eta: 0:47:39  iter: 1879  total_loss: 2.652  loss_sem_seg: 1.55  loss_center: 0.605  loss_offset: 0.6686  time: 0.3522  data_time: 0.0315  lr: 0.0020729  max_mem: 7419M
[12/11 23:17:22 d2.utils.events]:  eta: 0:47:32  iter: 1899  total_loss: 2.787  loss_sem_seg: 1.544  loss_center: 0.5262  loss_offset: 0.6623  time: 0.3522  data_time: 0.0280  lr: 0.0020684  max_mem: 7419M
[12/11 23:17:30 d2.utils.events]:  eta: 0:47:24  iter: 1919  total_loss: 2.713  loss_sem_seg: 1.506  loss_center: 0.6267  loss_offset: 0.6802  time: 0.3522  data_time: 0.0291  lr: 0.0020638  max_mem: 7419M
[12/11 23:17:37 d2.utils.events]:  eta: 0:47:17  iter: 1939  total_loss: 2.585  loss_sem_seg: 1.47  loss_center: 0.5181  loss_offset: 0.5366  time: 0.3522  data_time: 0.0271  lr: 0.0020592  max_mem: 7419M
[12/11 23:17:44 d2.utils.events]:  eta: 0:47:10  iter: 1959  total_loss: 2.999  loss_sem_seg: 1.528  loss_center: 0.5911  loss_offset: 0.706  time: 0.3522  data_time: 0.0277  lr: 0.0020546  max_mem: 7419M
[12/11 23:17:51 d2.utils.events]:  eta: 0:47:03  iter: 1979  total_loss: 2.71  loss_sem_seg: 1.371  loss_center: 0.5462  loss_offset: 0.7371  time: 0.3522  data_time: 0.0284  lr: 0.00205  max_mem: 7419M
[12/11 23:17:58 d2.utils.events]:  eta: 0:46:56  iter: 1999  total_loss: 2.849  loss_sem_seg: 1.441  loss_center: 0.597  loss_offset: 0.7336  time: 0.3522  data_time: 0.0273  lr: 0.0020454  max_mem: 7419M
[12/11 23:18:05 d2.utils.events]:  eta: 0:46:50  iter: 2019  total_loss: 2.714  loss_sem_seg: 1.426  loss_center: 0.514  loss_offset: 0.6968  time: 0.3522  data_time: 0.0291  lr: 0.0020408  max_mem: 7419M
[12/11 23:18:12 d2.utils.events]:  eta: 0:46:45  iter: 2039  total_loss: 2.726  loss_sem_seg: 1.443  loss_center: 0.5061  loss_offset: 0.769  time: 0.3522  data_time: 0.0284  lr: 0.0020362  max_mem: 7419M
[12/11 23:18:19 d2.utils.events]:  eta: 0:46:38  iter: 2059  total_loss: 2.909  loss_sem_seg: 1.512  loss_center: 0.5829  loss_offset: 0.8001  time: 0.3522  data_time: 0.0282  lr: 0.0020316  max_mem: 7419M
[12/11 23:18:26 d2.utils.events]:  eta: 0:46:31  iter: 2079  total_loss: 2.785  loss_sem_seg: 1.73  loss_center: 0.4262  loss_offset: 0.6768  time: 0.3523  data_time: 0.0309  lr: 0.0020269  max_mem: 7419M
[12/11 23:18:33 d2.utils.events]:  eta: 0:46:24  iter: 2099  total_loss: 2.94  loss_sem_seg: 1.515  loss_center: 0.6309  loss_offset: 0.7052  time: 0.3523  data_time: 0.0285  lr: 0.0020223  max_mem: 7419M
[12/11 23:18:40 d2.utils.events]:  eta: 0:46:17  iter: 2119  total_loss: 2.822  loss_sem_seg: 1.443  loss_center: 0.4569  loss_offset: 0.7907  time: 0.3523  data_time: 0.0283  lr: 0.0020177  max_mem: 7419M
[12/11 23:18:47 d2.utils.events]:  eta: 0:46:09  iter: 2139  total_loss: 2.779  loss_sem_seg: 1.407  loss_center: 0.5181  loss_offset: 0.6467  time: 0.3523  data_time: 0.0269  lr: 0.0020131  max_mem: 7419M
[12/11 23:18:54 d2.utils.events]:  eta: 0:46:02  iter: 2159  total_loss: 2.58  loss_sem_seg: 1.349  loss_center: 0.6305  loss_offset: 0.718  time: 0.3523  data_time: 0.0284  lr: 0.0020085  max_mem: 7419M
[12/11 23:19:01 d2.utils.events]:  eta: 0:45:55  iter: 2179  total_loss: 2.96  loss_sem_seg: 1.437  loss_center: 0.677  loss_offset: 0.6975  time: 0.3523  data_time: 0.0274  lr: 0.0020039  max_mem: 7419M
[12/11 23:19:09 d2.utils.events]:  eta: 0:45:50  iter: 2199  total_loss: 2.6  loss_sem_seg: 1.297  loss_center: 0.5973  loss_offset: 0.6739  time: 0.3524  data_time: 0.0297  lr: 0.0019993  max_mem: 7419M
[12/11 23:19:16 d2.utils.events]:  eta: 0:45:43  iter: 2219  total_loss: 2.765  loss_sem_seg: 1.433  loss_center: 0.558  loss_offset: 0.7307  time: 0.3523  data_time: 0.0275  lr: 0.0019947  max_mem: 7419M
[12/11 23:19:23 d2.utils.events]:  eta: 0:45:36  iter: 2239  total_loss: 2.756  loss_sem_seg: 1.55  loss_center: 0.6535  loss_offset: 0.7125  time: 0.3523  data_time: 0.0266  lr: 0.0019901  max_mem: 7419M
[12/11 23:19:30 d2.utils.events]:  eta: 0:45:28  iter: 2259  total_loss: 2.647  loss_sem_seg: 1.377  loss_center: 0.655  loss_offset: 0.6474  time: 0.3523  data_time: 0.0284  lr: 0.0019854  max_mem: 7419M
[12/11 23:19:37 d2.utils.events]:  eta: 0:45:21  iter: 2279  total_loss: 2.752  loss_sem_seg: 1.412  loss_center: 0.5945  loss_offset: 0.7088  time: 0.3523  data_time: 0.0267  lr: 0.0019808  max_mem: 7419M
[12/11 23:19:44 d2.utils.events]:  eta: 0:45:13  iter: 2299  total_loss: 2.688  loss_sem_seg: 1.213  loss_center: 0.5355  loss_offset: 0.7671  time: 0.3523  data_time: 0.0279  lr: 0.0019762  max_mem: 7419M
[12/11 23:19:51 d2.utils.events]:  eta: 0:45:06  iter: 2319  total_loss: 2.739  loss_sem_seg: 1.425  loss_center: 0.6559  loss_offset: 0.7362  time: 0.3523  data_time: 0.0271  lr: 0.0019716  max_mem: 7419M
[12/11 23:19:58 d2.utils.events]:  eta: 0:44:59  iter: 2339  total_loss: 2.927  loss_sem_seg: 1.293  loss_center: 0.678  loss_offset: 0.7698  time: 0.3523  data_time: 0.0282  lr: 0.001967  max_mem: 7419M
[12/11 23:20:05 d2.utils.events]:  eta: 0:44:52  iter: 2359  total_loss: 2.668  loss_sem_seg: 1.318  loss_center: 0.5704  loss_offset: 0.6849  time: 0.3523  data_time: 0.0277  lr: 0.0019623  max_mem: 7419M
[12/11 23:20:12 d2.utils.events]:  eta: 0:44:42  iter: 2379  total_loss: 3.012  loss_sem_seg: 1.301  loss_center: 0.7301  loss_offset: 0.7326  time: 0.3523  data_time: 0.0258  lr: 0.0019577  max_mem: 7419M
[12/11 23:20:19 d2.utils.events]:  eta: 0:44:35  iter: 2399  total_loss: 2.728  loss_sem_seg: 1.408  loss_center: 0.5841  loss_offset: 0.7721  time: 0.3523  data_time: 0.0267  lr: 0.0019531  max_mem: 7419M
[12/11 23:20:26 d2.utils.events]:  eta: 0:44:28  iter: 2419  total_loss: 2.468  loss_sem_seg: 1.319  loss_center: 0.4652  loss_offset: 0.7363  time: 0.3522  data_time: 0.0274  lr: 0.0019485  max_mem: 7419M
[12/11 23:20:33 d2.utils.events]:  eta: 0:44:21  iter: 2439  total_loss: 2.442  loss_sem_seg: 1.255  loss_center: 0.5413  loss_offset: 0.6582  time: 0.3522  data_time: 0.0288  lr: 0.0019438  max_mem: 7419M
[12/11 23:20:40 d2.utils.events]:  eta: 0:44:14  iter: 2459  total_loss: 2.613  loss_sem_seg: 1.451  loss_center: 0.573  loss_offset: 0.5826  time: 0.3522  data_time: 0.0284  lr: 0.0019392  max_mem: 7419M
[12/11 23:20:47 d2.utils.events]:  eta: 0:44:07  iter: 2479  total_loss: 2.509  loss_sem_seg: 1.43  loss_center: 0.5278  loss_offset: 0.7517  time: 0.3522  data_time: 0.0277  lr: 0.0019346  max_mem: 7419M
[12/11 23:20:54 d2.utils.events]:  eta: 0:44:00  iter: 2499  total_loss: 2.648  loss_sem_seg: 1.384  loss_center: 0.4641  loss_offset: 0.7993  time: 0.3522  data_time: 0.0266  lr: 0.00193  max_mem: 7419M
[12/11 23:21:01 d2.utils.events]:  eta: 0:43:53  iter: 2519  total_loss: 2.847  loss_sem_seg: 1.387  loss_center: 0.6697  loss_offset: 0.6834  time: 0.3522  data_time: 0.0284  lr: 0.0019253  max_mem: 7419M
[12/11 23:21:08 d2.utils.events]:  eta: 0:43:46  iter: 2539  total_loss: 2.675  loss_sem_seg: 1.253  loss_center: 0.5116  loss_offset: 0.7095  time: 0.3522  data_time: 0.0264  lr: 0.0019207  max_mem: 7419M
[12/11 23:21:15 d2.utils.events]:  eta: 0:43:39  iter: 2559  total_loss: 2.847  loss_sem_seg: 1.314  loss_center: 0.5226  loss_offset: 0.6603  time: 0.3522  data_time: 0.0284  lr: 0.0019161  max_mem: 7419M
[12/11 23:21:22 d2.utils.events]:  eta: 0:43:32  iter: 2579  total_loss: 2.911  loss_sem_seg: 1.491  loss_center: 0.6229  loss_offset: 0.6408  time: 0.3523  data_time: 0.0287  lr: 0.0019114  max_mem: 7419M
[12/11 23:21:29 d2.utils.events]:  eta: 0:43:25  iter: 2599  total_loss: 2.661  loss_sem_seg: 1.253  loss_center: 0.6946  loss_offset: 0.5816  time: 0.3523  data_time: 0.0260  lr: 0.0019068  max_mem: 7419M
[12/11 23:21:36 d2.utils.events]:  eta: 0:43:18  iter: 2619  total_loss: 2.342  loss_sem_seg: 1.116  loss_center: 0.4807  loss_offset: 0.5702  time: 0.3522  data_time: 0.0271  lr: 0.0019021  max_mem: 7419M
[12/11 23:21:44 d2.utils.events]:  eta: 0:43:11  iter: 2639  total_loss: 2.599  loss_sem_seg: 1.322  loss_center: 0.4418  loss_offset: 0.682  time: 0.3523  data_time: 0.0287  lr: 0.0018975  max_mem: 7419M
[12/11 23:21:51 d2.utils.events]:  eta: 0:43:05  iter: 2659  total_loss: 2.628  loss_sem_seg: 1.215  loss_center: 0.5538  loss_offset: 0.612  time: 0.3523  data_time: 0.0273  lr: 0.0018929  max_mem: 7419M
[12/11 23:21:58 d2.utils.events]:  eta: 0:42:58  iter: 2679  total_loss: 2.623  loss_sem_seg: 1.307  loss_center: 0.5142  loss_offset: 0.6567  time: 0.3523  data_time: 0.0275  lr: 0.0018882  max_mem: 7419M
[12/11 23:22:05 d2.utils.events]:  eta: 0:42:50  iter: 2699  total_loss: 2.572  loss_sem_seg: 1.235  loss_center: 0.4856  loss_offset: 0.7041  time: 0.3523  data_time: 0.0287  lr: 0.0018836  max_mem: 7419M
[12/11 23:22:12 d2.utils.events]:  eta: 0:42:43  iter: 2719  total_loss: 2.601  loss_sem_seg: 1.458  loss_center: 0.4523  loss_offset: 0.5653  time: 0.3523  data_time: 0.0280  lr: 0.0018789  max_mem: 7419M
[12/11 23:22:19 d2.utils.events]:  eta: 0:42:36  iter: 2739  total_loss: 2.504  loss_sem_seg: 1.184  loss_center: 0.6037  loss_offset: 0.6104  time: 0.3523  data_time: 0.0285  lr: 0.0018743  max_mem: 7419M
[12/11 23:22:26 d2.utils.events]:  eta: 0:42:29  iter: 2759  total_loss: 2.494  loss_sem_seg: 1.328  loss_center: 0.5091  loss_offset: 0.7184  time: 0.3523  data_time: 0.0263  lr: 0.0018696  max_mem: 7419M
[12/11 23:22:33 d2.utils.events]:  eta: 0:42:21  iter: 2779  total_loss: 2.401  loss_sem_seg: 1.116  loss_center: 0.5682  loss_offset: 0.6494  time: 0.3523  data_time: 0.0257  lr: 0.001865  max_mem: 7419M
[12/11 23:22:40 d2.utils.events]:  eta: 0:42:14  iter: 2799  total_loss: 2.466  loss_sem_seg: 1.25  loss_center: 0.521  loss_offset: 0.5222  time: 0.3523  data_time: 0.0300  lr: 0.0018603  max_mem: 7419M
[12/11 23:22:47 d2.utils.events]:  eta: 0:42:07  iter: 2819  total_loss: 2.313  loss_sem_seg: 1.266  loss_center: 0.4775  loss_offset: 0.5079  time: 0.3523  data_time: 0.0273  lr: 0.0018557  max_mem: 7419M
[12/11 23:22:54 d2.utils.events]:  eta: 0:42:00  iter: 2839  total_loss: 2.585  loss_sem_seg: 1.369  loss_center: 0.5962  loss_offset: 0.5  time: 0.3523  data_time: 0.0284  lr: 0.001851  max_mem: 7419M
[12/11 23:23:01 d2.utils.events]:  eta: 0:41:53  iter: 2859  total_loss: 2.584  loss_sem_seg: 1.203  loss_center: 0.5617  loss_offset: 0.696  time: 0.3523  data_time: 0.0268  lr: 0.0018464  max_mem: 7419M
[12/11 23:23:08 d2.utils.events]:  eta: 0:41:46  iter: 2879  total_loss: 2.744  loss_sem_seg: 1.341  loss_center: 0.5447  loss_offset: 0.7004  time: 0.3523  data_time: 0.0282  lr: 0.0018417  max_mem: 7419M
[12/11 23:23:15 d2.utils.events]:  eta: 0:41:39  iter: 2899  total_loss: 2.585  loss_sem_seg: 1.303  loss_center: 0.5737  loss_offset: 0.7482  time: 0.3523  data_time: 0.0276  lr: 0.0018371  max_mem: 7419M
[12/11 23:23:22 d2.utils.events]:  eta: 0:41:32  iter: 2919  total_loss: 2.764  loss_sem_seg: 1.366  loss_center: 0.6131  loss_offset: 0.7045  time: 0.3523  data_time: 0.0284  lr: 0.0018324  max_mem: 7419M
[12/11 23:23:29 d2.utils.events]:  eta: 0:41:25  iter: 2939  total_loss: 2.716  loss_sem_seg: 1.516  loss_center: 0.4865  loss_offset: 0.7182  time: 0.3523  data_time: 0.0288  lr: 0.0018278  max_mem: 7419M
[12/11 23:23:37 d2.utils.events]:  eta: 0:41:18  iter: 2959  total_loss: 2.58  loss_sem_seg: 1.271  loss_center: 0.6374  loss_offset: 0.687  time: 0.3523  data_time: 0.0279  lr: 0.0018231  max_mem: 7419M
[12/11 23:23:44 d2.utils.events]:  eta: 0:41:11  iter: 2979  total_loss: 2.549  loss_sem_seg: 1.199  loss_center: 0.549  loss_offset: 0.6125  time: 0.3523  data_time: 0.0285  lr: 0.0018184  max_mem: 7419M
[12/11 23:23:51 d2.utils.events]:  eta: 0:41:04  iter: 2999  total_loss: 2.425  loss_sem_seg: 1.218  loss_center: 0.5494  loss_offset: 0.6902  time: 0.3523  data_time: 0.0276  lr: 0.0018138  max_mem: 7419M
[12/11 23:23:58 d2.utils.events]:  eta: 0:40:55  iter: 3019  total_loss: 2.592  loss_sem_seg: 1.392  loss_center: 0.4895  loss_offset: 0.6603  time: 0.3523  data_time: 0.0275  lr: 0.0018091  max_mem: 7419M
[12/11 23:24:05 d2.utils.events]:  eta: 0:40:46  iter: 3039  total_loss: 2.515  loss_sem_seg: 1.216  loss_center: 0.5488  loss_offset: 0.6576  time: 0.3523  data_time: 0.0277  lr: 0.0018044  max_mem: 7419M
[12/11 23:24:12 d2.utils.events]:  eta: 0:40:39  iter: 3059  total_loss: 2.576  loss_sem_seg: 1.288  loss_center: 0.4394  loss_offset: 0.6668  time: 0.3523  data_time: 0.0274  lr: 0.0017998  max_mem: 7419M
[12/11 23:24:19 d2.utils.events]:  eta: 0:40:32  iter: 3079  total_loss: 2.599  loss_sem_seg: 1.34  loss_center: 0.5997  loss_offset: 0.6276  time: 0.3523  data_time: 0.0281  lr: 0.0017951  max_mem: 7419M
[12/11 23:24:26 d2.utils.events]:  eta: 0:40:25  iter: 3099  total_loss: 2.462  loss_sem_seg: 1.086  loss_center: 0.6969  loss_offset: 0.5811  time: 0.3523  data_time: 0.0271  lr: 0.0017904  max_mem: 7419M
[12/11 23:24:33 d2.utils.events]:  eta: 0:40:18  iter: 3119  total_loss: 2.503  loss_sem_seg: 1.331  loss_center: 0.5096  loss_offset: 0.6876  time: 0.3523  data_time: 0.0288  lr: 0.0017858  max_mem: 7419M
[12/11 23:24:40 d2.utils.events]:  eta: 0:40:10  iter: 3139  total_loss: 2.266  loss_sem_seg: 1.157  loss_center: 0.4743  loss_offset: 0.5469  time: 0.3523  data_time: 0.0277  lr: 0.0017811  max_mem: 7419M
[12/11 23:24:47 d2.utils.events]:  eta: 0:40:02  iter: 3159  total_loss: 2.654  loss_sem_seg: 1.522  loss_center: 0.492  loss_offset: 0.6287  time: 0.3523  data_time: 0.0274  lr: 0.0017764  max_mem: 7419M
[12/11 23:24:54 d2.utils.events]:  eta: 0:39:56  iter: 3179  total_loss: 2.279  loss_sem_seg: 1.163  loss_center: 0.6053  loss_offset: 0.5473  time: 0.3523  data_time: 0.0281  lr: 0.0017718  max_mem: 7419M
[12/11 23:25:01 d2.utils.events]:  eta: 0:39:48  iter: 3199  total_loss: 2.68  loss_sem_seg: 1.228  loss_center: 0.583  loss_offset: 0.8262  time: 0.3523  data_time: 0.0280  lr: 0.0017671  max_mem: 7419M
[12/11 23:25:08 d2.utils.events]:  eta: 0:39:41  iter: 3219  total_loss: 2.485  loss_sem_seg: 1.096  loss_center: 0.5666  loss_offset: 0.7745  time: 0.3523  data_time: 0.0273  lr: 0.0017624  max_mem: 7419M
[12/11 23:25:15 d2.utils.events]:  eta: 0:39:34  iter: 3239  total_loss: 2.167  loss_sem_seg: 1.103  loss_center: 0.5362  loss_offset: 0.5317  time: 0.3523  data_time: 0.0293  lr: 0.0017577  max_mem: 7419M
[12/11 23:25:22 d2.utils.events]:  eta: 0:39:28  iter: 3259  total_loss: 2.708  loss_sem_seg: 1.26  loss_center: 0.5784  loss_offset: 0.631  time: 0.3523  data_time: 0.0288  lr: 0.001753  max_mem: 7419M
[12/11 23:25:29 d2.utils.events]:  eta: 0:39:21  iter: 3279  total_loss: 2.779  loss_sem_seg: 1.412  loss_center: 0.6221  loss_offset: 0.6181  time: 0.3523  data_time: 0.0270  lr: 0.0017484  max_mem: 7419M
[12/11 23:25:36 d2.utils.events]:  eta: 0:39:14  iter: 3299  total_loss: 2.481  loss_sem_seg: 1.266  loss_center: 0.4221  loss_offset: 0.591  time: 0.3523  data_time: 0.0282  lr: 0.0017437  max_mem: 7419M
[12/11 23:25:43 d2.utils.events]:  eta: 0:39:07  iter: 3319  total_loss: 2.766  loss_sem_seg: 1.43  loss_center: 0.6341  loss_offset: 0.5992  time: 0.3523  data_time: 0.0286  lr: 0.001739  max_mem: 7419M
[12/11 23:25:50 d2.utils.events]:  eta: 0:39:00  iter: 3339  total_loss: 2.816  loss_sem_seg: 1.31  loss_center: 0.66  loss_offset: 0.5592  time: 0.3523  data_time: 0.0271  lr: 0.0017343  max_mem: 7419M
[12/11 23:25:58 d2.utils.events]:  eta: 0:38:53  iter: 3359  total_loss: 2.615  loss_sem_seg: 1.333  loss_center: 0.5719  loss_offset: 0.6455  time: 0.3523  data_time: 0.0265  lr: 0.0017296  max_mem: 7419M
[12/11 23:26:05 d2.utils.events]:  eta: 0:38:46  iter: 3379  total_loss: 2.614  loss_sem_seg: 1.424  loss_center: 0.5928  loss_offset: 0.5703  time: 0.3523  data_time: 0.0271  lr: 0.0017249  max_mem: 7419M
[12/11 23:26:12 d2.utils.events]:  eta: 0:38:38  iter: 3399  total_loss: 2.49  loss_sem_seg: 1.156  loss_center: 0.5463  loss_offset: 0.646  time: 0.3523  data_time: 0.0285  lr: 0.0017202  max_mem: 7419M
[12/11 23:26:19 d2.utils.events]:  eta: 0:38:31  iter: 3419  total_loss: 2.434  loss_sem_seg: 1.177  loss_center: 0.4972  loss_offset: 0.6508  time: 0.3523  data_time: 0.0267  lr: 0.0017155  max_mem: 7419M
[12/11 23:26:26 d2.utils.events]:  eta: 0:38:24  iter: 3439  total_loss: 2.728  loss_sem_seg: 1.22  loss_center: 0.765  loss_offset: 0.6553  time: 0.3523  data_time: 0.0280  lr: 0.0017109  max_mem: 7419M
[12/11 23:26:33 d2.utils.events]:  eta: 0:38:17  iter: 3459  total_loss: 2.223  loss_sem_seg: 1.185  loss_center: 0.5696  loss_offset: 0.5898  time: 0.3523  data_time: 0.0293  lr: 0.0017062  max_mem: 7419M
[12/11 23:26:40 d2.utils.events]:  eta: 0:38:10  iter: 3479  total_loss: 2.332  loss_sem_seg: 1.217  loss_center: 0.6419  loss_offset: 0.6533  time: 0.3523  data_time: 0.0279  lr: 0.0017015  max_mem: 7419M
[12/11 23:26:47 d2.utils.events]:  eta: 0:38:03  iter: 3499  total_loss: 2.465  loss_sem_seg: 1.183  loss_center: 0.565  loss_offset: 0.5674  time: 0.3523  data_time: 0.0280  lr: 0.0016968  max_mem: 7419M
[12/11 23:26:54 d2.utils.events]:  eta: 0:37:56  iter: 3519  total_loss: 2.676  loss_sem_seg: 1.297  loss_center: 0.6143  loss_offset: 0.6471  time: 0.3523  data_time: 0.0274  lr: 0.0016921  max_mem: 7419M
[12/11 23:27:01 d2.utils.events]:  eta: 0:37:48  iter: 3539  total_loss: 2.47  loss_sem_seg: 1.227  loss_center: 0.5594  loss_offset: 0.6268  time: 0.3523  data_time: 0.0271  lr: 0.0016874  max_mem: 7419M
[12/11 23:27:08 d2.utils.events]:  eta: 0:37:41  iter: 3559  total_loss: 2.626  loss_sem_seg: 1.388  loss_center: 0.5827  loss_offset: 0.6639  time: 0.3523  data_time: 0.0285  lr: 0.0016827  max_mem: 7419M
[12/11 23:27:15 d2.utils.events]:  eta: 0:37:34  iter: 3579  total_loss: 2.489  loss_sem_seg: 1.001  loss_center: 0.6156  loss_offset: 0.626  time: 0.3523  data_time: 0.0269  lr: 0.001678  max_mem: 7419M
[12/11 23:27:22 d2.utils.events]:  eta: 0:37:28  iter: 3599  total_loss: 2.66  loss_sem_seg: 1.411  loss_center: 0.3655  loss_offset: 0.6126  time: 0.3523  data_time: 0.0273  lr: 0.0016733  max_mem: 7419M
[12/11 23:27:29 d2.utils.events]:  eta: 0:37:21  iter: 3619  total_loss: 2.54  loss_sem_seg: 1.214  loss_center: 0.5181  loss_offset: 0.6791  time: 0.3523  data_time: 0.0292  lr: 0.0016686  max_mem: 7419M
[12/11 23:27:36 d2.utils.events]:  eta: 0:37:14  iter: 3639  total_loss: 2.375  loss_sem_seg: 1.273  loss_center: 0.578  loss_offset: 0.5713  time: 0.3523  data_time: 0.0278  lr: 0.0016638  max_mem: 7419M
[12/11 23:27:43 d2.utils.events]:  eta: 0:37:07  iter: 3659  total_loss: 2.301  loss_sem_seg: 1.324  loss_center: 0.552  loss_offset: 0.571  time: 0.3523  data_time: 0.0273  lr: 0.0016591  max_mem: 7419M
[12/11 23:27:51 d2.utils.events]:  eta: 0:37:00  iter: 3679  total_loss: 2.758  loss_sem_seg: 1.34  loss_center: 0.5565  loss_offset: 0.6602  time: 0.3523  data_time: 0.0293  lr: 0.0016544  max_mem: 7419M
[12/11 23:27:58 d2.utils.events]:  eta: 0:36:53  iter: 3699  total_loss: 2.293  loss_sem_seg: 1.179  loss_center: 0.4822  loss_offset: 0.5346  time: 0.3523  data_time: 0.0275  lr: 0.0016497  max_mem: 7419M
[12/11 23:28:05 d2.utils.events]:  eta: 0:36:45  iter: 3719  total_loss: 2.292  loss_sem_seg: 1.196  loss_center: 0.5169  loss_offset: 0.6799  time: 0.3523  data_time: 0.0265  lr: 0.001645  max_mem: 7419M
[12/11 23:28:12 d2.utils.events]:  eta: 0:36:38  iter: 3739  total_loss: 2.453  loss_sem_seg: 1.136  loss_center: 0.4963  loss_offset: 0.5404  time: 0.3523  data_time: 0.0273  lr: 0.0016403  max_mem: 7419M
[12/11 23:28:19 d2.utils.events]:  eta: 0:36:31  iter: 3759  total_loss: 2.415  loss_sem_seg: 1.263  loss_center: 0.4713  loss_offset: 0.6688  time: 0.3523  data_time: 0.0273  lr: 0.0016356  max_mem: 7419M
[12/11 23:28:26 d2.utils.events]:  eta: 0:36:24  iter: 3779  total_loss: 2.569  loss_sem_seg: 1.376  loss_center: 0.6104  loss_offset: 0.6087  time: 0.3523  data_time: 0.0273  lr: 0.0016309  max_mem: 7419M
[12/11 23:28:33 d2.utils.events]:  eta: 0:36:16  iter: 3799  total_loss: 2.504  loss_sem_seg: 1.229  loss_center: 0.6298  loss_offset: 0.6893  time: 0.3523  data_time: 0.0280  lr: 0.0016261  max_mem: 7419M
[12/11 23:28:40 d2.utils.events]:  eta: 0:36:09  iter: 3819  total_loss: 2.326  loss_sem_seg: 1.117  loss_center: 0.459  loss_offset: 0.553  time: 0.3523  data_time: 0.0298  lr: 0.0016214  max_mem: 7419M
[12/11 23:28:47 d2.utils.events]:  eta: 0:36:01  iter: 3839  total_loss: 2.297  loss_sem_seg: 0.9906  loss_center: 0.5849  loss_offset: 0.5673  time: 0.3523  data_time: 0.0268  lr: 0.0016167  max_mem: 7419M
[12/11 23:28:54 d2.utils.events]:  eta: 0:35:55  iter: 3859  total_loss: 2.507  loss_sem_seg: 1.225  loss_center: 0.5229  loss_offset: 0.6243  time: 0.3523  data_time: 0.0282  lr: 0.001612  max_mem: 7419M
[12/11 23:29:01 d2.utils.events]:  eta: 0:35:48  iter: 3879  total_loss: 2.493  loss_sem_seg: 1.212  loss_center: 0.525  loss_offset: 0.6243  time: 0.3523  data_time: 0.0271  lr: 0.0016072  max_mem: 7419M
[12/11 23:29:08 d2.utils.events]:  eta: 0:35:41  iter: 3899  total_loss: 2.58  loss_sem_seg: 1.407  loss_center: 0.6212  loss_offset: 0.6506  time: 0.3523  data_time: 0.0286  lr: 0.0016025  max_mem: 7419M
[12/11 23:29:15 d2.utils.events]:  eta: 0:35:35  iter: 3919  total_loss: 2.329  loss_sem_seg: 1.255  loss_center: 0.5167  loss_offset: 0.5732  time: 0.3523  data_time: 0.0270  lr: 0.0015978  max_mem: 7419M
[12/11 23:29:22 d2.utils.events]:  eta: 0:35:28  iter: 3939  total_loss: 2.62  loss_sem_seg: 1.244  loss_center: 0.5947  loss_offset: 0.5686  time: 0.3523  data_time: 0.0265  lr: 0.0015931  max_mem: 7419M
[12/11 23:29:29 d2.utils.events]:  eta: 0:35:20  iter: 3959  total_loss: 2.594  loss_sem_seg: 1.37  loss_center: 0.5845  loss_offset: 0.5818  time: 0.3523  data_time: 0.0268  lr: 0.0015883  max_mem: 7419M
[12/11 23:29:36 d2.utils.events]:  eta: 0:35:13  iter: 3979  total_loss: 2.465  loss_sem_seg: 1.198  loss_center: 0.4681  loss_offset: 0.5839  time: 0.3523  data_time: 0.0261  lr: 0.0015836  max_mem: 7419M
[12/11 23:29:43 d2.utils.events]:  eta: 0:35:06  iter: 3999  total_loss: 2.139  loss_sem_seg: 1.142  loss_center: 0.4744  loss_offset: 0.5524  time: 0.3523  data_time: 0.0280  lr: 0.0015789  max_mem: 7419M
[12/11 23:29:50 d2.utils.events]:  eta: 0:34:59  iter: 4019  total_loss: 2.422  loss_sem_seg: 1.048  loss_center: 0.5593  loss_offset: 0.6818  time: 0.3523  data_time: 0.0287  lr: 0.0015741  max_mem: 7419M
[12/11 23:29:57 d2.utils.events]:  eta: 0:34:52  iter: 4039  total_loss: 2.589  loss_sem_seg: 1.309  loss_center: 0.5267  loss_offset: 0.6074  time: 0.3523  data_time: 0.0287  lr: 0.0015694  max_mem: 7419M
[12/11 23:30:05 d2.utils.events]:  eta: 0:34:46  iter: 4059  total_loss: 2.45  loss_sem_seg: 1.132  loss_center: 0.5022  loss_offset: 0.6478  time: 0.3523  data_time: 0.0284  lr: 0.0015646  max_mem: 7419M
[12/11 23:30:12 d2.utils.events]:  eta: 0:34:38  iter: 4079  total_loss: 2.311  loss_sem_seg: 1.059  loss_center: 0.722  loss_offset: 0.5784  time: 0.3523  data_time: 0.0262  lr: 0.0015599  max_mem: 7419M
[12/11 23:30:19 d2.utils.events]:  eta: 0:34:32  iter: 4099  total_loss: 2.247  loss_sem_seg: 1.07  loss_center: 0.55  loss_offset: 0.6048  time: 0.3523  data_time: 0.0277  lr: 0.0015552  max_mem: 7419M
[12/11 23:30:26 d2.utils.events]:  eta: 0:34:24  iter: 4119  total_loss: 2.321  loss_sem_seg: 1.057  loss_center: 0.6152  loss_offset: 0.5396  time: 0.3523  data_time: 0.0267  lr: 0.0015504  max_mem: 7419M
[12/11 23:30:33 d2.utils.events]:  eta: 0:34:17  iter: 4139  total_loss: 2.83  loss_sem_seg: 1.162  loss_center: 0.6226  loss_offset: 0.6778  time: 0.3523  data_time: 0.0285  lr: 0.0015457  max_mem: 7419M
[12/11 23:30:40 d2.utils.events]:  eta: 0:34:10  iter: 4159  total_loss: 2.616  loss_sem_seg: 1.173  loss_center: 0.6063  loss_offset: 0.5129  time: 0.3523  data_time: 0.0276  lr: 0.0015409  max_mem: 7419M
[12/11 23:30:47 d2.utils.events]:  eta: 0:34:04  iter: 4179  total_loss: 2.504  loss_sem_seg: 1.167  loss_center: 0.5361  loss_offset: 0.6335  time: 0.3523  data_time: 0.0272  lr: 0.0015362  max_mem: 7419M
[12/11 23:30:54 d2.utils.events]:  eta: 0:33:56  iter: 4199  total_loss: 2.821  loss_sem_seg: 1.292  loss_center: 0.6174  loss_offset: 0.6178  time: 0.3523  data_time: 0.0280  lr: 0.0015314  max_mem: 7419M
[12/11 23:31:01 d2.utils.events]:  eta: 0:33:50  iter: 4219  total_loss: 2.444  loss_sem_seg: 1.218  loss_center: 0.6087  loss_offset: 0.6023  time: 0.3523  data_time: 0.0280  lr: 0.0015267  max_mem: 7419M
[12/11 23:31:08 d2.utils.events]:  eta: 0:33:43  iter: 4239  total_loss: 2.506  loss_sem_seg: 1.249  loss_center: 0.4823  loss_offset: 0.6691  time: 0.3523  data_time: 0.0266  lr: 0.0015219  max_mem: 7419M
[12/11 23:31:15 d2.utils.events]:  eta: 0:33:36  iter: 4259  total_loss: 2.375  loss_sem_seg: 1.257  loss_center: 0.483  loss_offset: 0.6072  time: 0.3523  data_time: 0.0281  lr: 0.0015172  max_mem: 7419M
[12/11 23:31:22 d2.utils.events]:  eta: 0:33:30  iter: 4279  total_loss: 2.299  loss_sem_seg: 1.142  loss_center: 0.5276  loss_offset: 0.5784  time: 0.3523  data_time: 0.0286  lr: 0.0015124  max_mem: 7419M
[12/11 23:31:29 d2.utils.events]:  eta: 0:33:23  iter: 4299  total_loss: 2.195  loss_sem_seg: 1.101  loss_center: 0.4422  loss_offset: 0.5553  time: 0.3523  data_time: 0.0274  lr: 0.0015076  max_mem: 7419M
[12/11 23:31:36 d2.utils.events]:  eta: 0:33:16  iter: 4319  total_loss: 2.569  loss_sem_seg: 1.246  loss_center: 0.6367  loss_offset: 0.5869  time: 0.3523  data_time: 0.0273  lr: 0.0015029  max_mem: 7419M
[12/11 23:31:43 d2.utils.events]:  eta: 0:33:09  iter: 4339  total_loss: 2.676  loss_sem_seg: 1.335  loss_center: 0.7465  loss_offset: 0.6105  time: 0.3523  data_time: 0.0283  lr: 0.0014981  max_mem: 7419M
[12/11 23:31:50 d2.utils.events]:  eta: 0:33:02  iter: 4359  total_loss: 2.564  loss_sem_seg: 1.183  loss_center: 0.6189  loss_offset: 0.6046  time: 0.3523  data_time: 0.0282  lr: 0.0014933  max_mem: 7419M
[12/11 23:31:57 d2.utils.events]:  eta: 0:32:55  iter: 4379  total_loss: 2.33  loss_sem_seg: 1.18  loss_center: 0.6015  loss_offset: 0.5817  time: 0.3523  data_time: 0.0274  lr: 0.0014886  max_mem: 7419M
[12/11 23:32:04 d2.utils.events]:  eta: 0:32:48  iter: 4399  total_loss: 2.548  loss_sem_seg: 1.283  loss_center: 0.6719  loss_offset: 0.5688  time: 0.3523  data_time: 0.0269  lr: 0.0014838  max_mem: 7419M
[12/11 23:32:11 d2.utils.events]:  eta: 0:32:41  iter: 4419  total_loss: 2.412  loss_sem_seg: 1.213  loss_center: 0.4906  loss_offset: 0.5463  time: 0.3523  data_time: 0.0280  lr: 0.001479  max_mem: 7419M
[12/11 23:32:18 d2.utils.events]:  eta: 0:32:34  iter: 4439  total_loss: 2.327  loss_sem_seg: 1.212  loss_center: 0.4247  loss_offset: 0.6386  time: 0.3523  data_time: 0.0276  lr: 0.0014743  max_mem: 7419M
[12/11 23:32:25 d2.utils.events]:  eta: 0:32:27  iter: 4459  total_loss: 2.341  loss_sem_seg: 1.129  loss_center: 0.5597  loss_offset: 0.4797  time: 0.3523  data_time: 0.0274  lr: 0.0014695  max_mem: 7419M
[12/11 23:32:33 d2.utils.events]:  eta: 0:32:20  iter: 4479  total_loss: 2.474  loss_sem_seg: 1.081  loss_center: 0.6582  loss_offset: 0.5686  time: 0.3523  data_time: 0.0280  lr: 0.0014647  max_mem: 7419M
[12/11 23:32:40 d2.utils.events]:  eta: 0:32:13  iter: 4499  total_loss: 2.304  loss_sem_seg: 1.051  loss_center: 0.5525  loss_offset: 0.5227  time: 0.3523  data_time: 0.0283  lr: 0.0014599  max_mem: 7419M
[12/11 23:32:47 d2.utils.events]:  eta: 0:32:06  iter: 4519  total_loss: 2.282  loss_sem_seg: 1.189  loss_center: 0.569  loss_offset: 0.6651  time: 0.3523  data_time: 0.0275  lr: 0.0014552  max_mem: 7419M
[12/11 23:32:54 d2.utils.events]:  eta: 0:31:59  iter: 4539  total_loss: 2.646  loss_sem_seg: 1.206  loss_center: 0.6176  loss_offset: 0.6372  time: 0.3523  data_time: 0.0274  lr: 0.0014504  max_mem: 7419M
[12/11 23:33:01 d2.utils.events]:  eta: 0:31:52  iter: 4559  total_loss: 2.163  loss_sem_seg: 1.046  loss_center: 0.4886  loss_offset: 0.6015  time: 0.3523  data_time: 0.0296  lr: 0.0014456  max_mem: 7419M
[12/11 23:33:08 d2.utils.events]:  eta: 0:31:46  iter: 4579  total_loss: 2.38  loss_sem_seg: 1.192  loss_center: 0.5239  loss_offset: 0.5195  time: 0.3523  data_time: 0.0265  lr: 0.0014408  max_mem: 7419M
[12/11 23:33:15 d2.utils.events]:  eta: 0:31:38  iter: 4599  total_loss: 2.264  loss_sem_seg: 1.11  loss_center: 0.4726  loss_offset: 0.5775  time: 0.3522  data_time: 0.0265  lr: 0.001436  max_mem: 7419M
[12/11 23:33:22 d2.utils.events]:  eta: 0:31:31  iter: 4619  total_loss: 2.441  loss_sem_seg: 1.105  loss_center: 0.5246  loss_offset: 0.5353  time: 0.3523  data_time: 0.0283  lr: 0.0014313  max_mem: 7419M
[12/11 23:33:29 d2.utils.events]:  eta: 0:31:24  iter: 4639  total_loss: 2.423  loss_sem_seg: 1.182  loss_center: 0.5027  loss_offset: 0.6321  time: 0.3522  data_time: 0.0282  lr: 0.0014265  max_mem: 7419M
[12/11 23:33:36 d2.utils.events]:  eta: 0:31:17  iter: 4659  total_loss: 2.25  loss_sem_seg: 1.171  loss_center: 0.5217  loss_offset: 0.6182  time: 0.3522  data_time: 0.0266  lr: 0.0014217  max_mem: 7419M
[12/11 23:33:43 d2.utils.events]:  eta: 0:31:09  iter: 4679  total_loss: 2.449  loss_sem_seg: 1.082  loss_center: 0.6012  loss_offset: 0.6793  time: 0.3522  data_time: 0.0282  lr: 0.0014169  max_mem: 7419M
[12/11 23:33:50 d2.utils.events]:  eta: 0:31:03  iter: 4699  total_loss: 2.283  loss_sem_seg: 1.065  loss_center: 0.6309  loss_offset: 0.5986  time: 0.3522  data_time: 0.0286  lr: 0.0014121  max_mem: 7419M
[12/11 23:33:57 d2.utils.events]:  eta: 0:30:56  iter: 4719  total_loss: 2.467  loss_sem_seg: 1.246  loss_center: 0.5196  loss_offset: 0.6915  time: 0.3522  data_time: 0.0297  lr: 0.0014073  max_mem: 7419M
[12/11 23:34:04 d2.utils.events]:  eta: 0:30:50  iter: 4739  total_loss: 2.308  loss_sem_seg: 1.064  loss_center: 0.4941  loss_offset: 0.58  time: 0.3522  data_time: 0.0276  lr: 0.0014025  max_mem: 7419M
[12/11 23:34:11 d2.utils.events]:  eta: 0:30:42  iter: 4759  total_loss: 2.455  loss_sem_seg: 1.29  loss_center: 0.5165  loss_offset: 0.6608  time: 0.3522  data_time: 0.0280  lr: 0.0013977  max_mem: 7419M
[12/11 23:34:18 d2.utils.events]:  eta: 0:30:35  iter: 4779  total_loss: 2.55  loss_sem_seg: 1.23  loss_center: 0.5546  loss_offset: 0.6656  time: 0.3522  data_time: 0.0279  lr: 0.0013929  max_mem: 7419M
[12/11 23:34:25 d2.utils.events]:  eta: 0:30:28  iter: 4799  total_loss: 2.105  loss_sem_seg: 0.9057  loss_center: 0.5024  loss_offset: 0.5147  time: 0.3522  data_time: 0.0268  lr: 0.0013881  max_mem: 7419M
[12/11 23:34:32 d2.utils.events]:  eta: 0:30:22  iter: 4819  total_loss: 2.082  loss_sem_seg: 1.158  loss_center: 0.5037  loss_offset: 0.4447  time: 0.3522  data_time: 0.0287  lr: 0.0013833  max_mem: 7419M
[12/11 23:34:39 d2.utils.events]:  eta: 0:30:16  iter: 4839  total_loss: 2.662  loss_sem_seg: 1.423  loss_center: 0.5909  loss_offset: 0.6878  time: 0.3522  data_time: 0.0283  lr: 0.0013785  max_mem: 7419M
[12/11 23:34:46 d2.utils.events]:  eta: 0:30:08  iter: 4859  total_loss: 2.306  loss_sem_seg: 1.141  loss_center: 0.5266  loss_offset: 0.4944  time: 0.3522  data_time: 0.0284  lr: 0.0013737  max_mem: 7419M
[12/11 23:34:54 d2.utils.events]:  eta: 0:30:01  iter: 4879  total_loss: 2.273  loss_sem_seg: 1.007  loss_center: 0.5785  loss_offset: 0.5731  time: 0.3522  data_time: 0.0278  lr: 0.0013689  max_mem: 7419M
[12/11 23:35:01 d2.utils.events]:  eta: 0:29:54  iter: 4899  total_loss: 2.652  loss_sem_seg: 1.165  loss_center: 0.5162  loss_offset: 0.6191  time: 0.3522  data_time: 0.0272  lr: 0.001364  max_mem: 7419M
[12/11 23:35:08 d2.utils.events]:  eta: 0:29:47  iter: 4919  total_loss: 2.337  loss_sem_seg: 1.227  loss_center: 0.5477  loss_offset: 0.5428  time: 0.3522  data_time: 0.0271  lr: 0.0013592  max_mem: 7419M
[12/11 23:35:15 d2.utils.events]:  eta: 0:29:41  iter: 4939  total_loss: 2.429  loss_sem_seg: 1.129  loss_center: 0.4881  loss_offset: 0.649  time: 0.3523  data_time: 0.0292  lr: 0.0013544  max_mem: 7419M
[12/11 23:35:22 d2.utils.events]:  eta: 0:29:34  iter: 4959  total_loss: 2.596  loss_sem_seg: 1.289  loss_center: 0.4815  loss_offset: 0.6852  time: 0.3523  data_time: 0.0285  lr: 0.0013496  max_mem: 7419M
[12/11 23:35:29 d2.utils.events]:  eta: 0:29:27  iter: 4979  total_loss: 2.387  loss_sem_seg: 1.094  loss_center: 0.4533  loss_offset: 0.54  time: 0.3523  data_time: 0.0288  lr: 0.0013448  max_mem: 7419M
[12/11 23:35:36 fvcore.common.checkpoint]: Saving checkpoint to ./output/model_0004999.pth
[12/11 23:35:37 d2.utils.events]:  eta: 0:29:21  iter: 4999  total_loss: 2.443  loss_sem_seg: 1.166  loss_center: 0.4682  loss_offset: 0.6637  time: 0.3523  data_time: 0.0298  lr: 0.00134  max_mem: 7419M
[12/11 23:35:44 d2.utils.events]:  eta: 0:29:13  iter: 5019  total_loss: 2.522  loss_sem_seg: 1.198  loss_center: 0.5243  loss_offset: 0.7508  time: 0.3523  data_time: 0.0287  lr: 0.0013351  max_mem: 7419M
[12/11 23:35:52 d2.utils.events]:  eta: 0:29:06  iter: 5039  total_loss: 2.165  loss_sem_seg: 1.056  loss_center: 0.4845  loss_offset: 0.5141  time: 0.3523  data_time: 0.0275  lr: 0.0013303  max_mem: 7419M
[12/11 23:35:59 d2.utils.events]:  eta: 0:28:58  iter: 5059  total_loss: 2.141  loss_sem_seg: 0.9119  loss_center: 0.4352  loss_offset: 0.521  time: 0.3523  data_time: 0.0268  lr: 0.0013255  max_mem: 7419M
[12/11 23:36:06 d2.utils.events]:  eta: 0:28:51  iter: 5079  total_loss: 2.346  loss_sem_seg: 1.27  loss_center: 0.513  loss_offset: 0.518  time: 0.3523  data_time: 0.0298  lr: 0.0013207  max_mem: 7419M
[12/11 23:36:13 d2.utils.events]:  eta: 0:28:44  iter: 5099  total_loss: 2.507  loss_sem_seg: 1.145  loss_center: 0.5045  loss_offset: 0.7338  time: 0.3523  data_time: 0.0259  lr: 0.0013158  max_mem: 7419M
[12/11 23:36:20 d2.utils.events]:  eta: 0:28:36  iter: 5119  total_loss: 2.272  loss_sem_seg: 1.204  loss_center: 0.6015  loss_offset: 0.547  time: 0.3523  data_time: 0.0293  lr: 0.001311  max_mem: 7419M
[12/11 23:36:27 d2.utils.events]:  eta: 0:28:29  iter: 5139  total_loss: 2.554  loss_sem_seg: 1.162  loss_center: 0.5875  loss_offset: 0.6133  time: 0.3523  data_time: 0.0278  lr: 0.0013062  max_mem: 7419M
[12/11 23:36:34 d2.utils.events]:  eta: 0:28:22  iter: 5159  total_loss: 2.604  loss_sem_seg: 1.173  loss_center: 0.5523  loss_offset: 0.692  time: 0.3523  data_time: 0.0273  lr: 0.0013013  max_mem: 7419M
[12/11 23:36:41 d2.utils.events]:  eta: 0:28:15  iter: 5179  total_loss: 1.923  loss_sem_seg: 0.9221  loss_center: 0.4742  loss_offset: 0.509  time: 0.3523  data_time: 0.0265  lr: 0.0012965  max_mem: 7419M
[12/11 23:36:48 d2.utils.events]:  eta: 0:28:07  iter: 5199  total_loss: 2.197  loss_sem_seg: 1.105  loss_center: 0.5071  loss_offset: 0.587  time: 0.3523  data_time: 0.0267  lr: 0.0012916  max_mem: 7419M
[12/11 23:36:55 d2.utils.events]:  eta: 0:28:00  iter: 5219  total_loss: 2.588  loss_sem_seg: 1.227  loss_center: 0.5354  loss_offset: 0.675  time: 0.3523  data_time: 0.0284  lr: 0.0012868  max_mem: 7419M
[12/11 23:37:02 d2.utils.events]:  eta: 0:27:53  iter: 5239  total_loss: 2.299  loss_sem_seg: 1.025  loss_center: 0.4901  loss_offset: 0.5991  time: 0.3523  data_time: 0.0276  lr: 0.0012819  max_mem: 7419M
[12/11 23:37:09 d2.utils.events]:  eta: 0:27:46  iter: 5259  total_loss: 2.447  loss_sem_seg: 1.246  loss_center: 0.5562  loss_offset: 0.6232  time: 0.3523  data_time: 0.0284  lr: 0.0012771  max_mem: 7419M
[12/11 23:37:16 d2.utils.events]:  eta: 0:27:39  iter: 5279  total_loss: 2.181  loss_sem_seg: 1.082  loss_center: 0.4248  loss_offset: 0.6007  time: 0.3523  data_time: 0.0268  lr: 0.0012722  max_mem: 7419M
[12/11 23:37:23 d2.utils.events]:  eta: 0:27:32  iter: 5299  total_loss: 2.04  loss_sem_seg: 1.031  loss_center: 0.6287  loss_offset: 0.495  time: 0.3523  data_time: 0.0278  lr: 0.0012674  max_mem: 7419M
[12/11 23:37:30 d2.utils.events]:  eta: 0:27:24  iter: 5319  total_loss: 2.396  loss_sem_seg: 1.059  loss_center: 0.4917  loss_offset: 0.6034  time: 0.3523  data_time: 0.0276  lr: 0.0012625  max_mem: 7419M
[12/11 23:37:37 d2.utils.events]:  eta: 0:27:16  iter: 5339  total_loss: 2.447  loss_sem_seg: 1.151  loss_center: 0.5368  loss_offset: 0.5601  time: 0.3523  data_time: 0.0274  lr: 0.0012577  max_mem: 7419M
[12/11 23:37:44 d2.utils.events]:  eta: 0:27:09  iter: 5359  total_loss: 2.062  loss_sem_seg: 1.117  loss_center: 0.508  loss_offset: 0.5647  time: 0.3523  data_time: 0.0273  lr: 0.0012528  max_mem: 7419M
[12/11 23:37:51 d2.utils.events]:  eta: 0:27:03  iter: 5379  total_loss: 2.437  loss_sem_seg: 1.078  loss_center: 0.5047  loss_offset: 0.6979  time: 0.3523  data_time: 0.0278  lr: 0.001248  max_mem: 7419M
[12/11 23:37:58 d2.utils.events]:  eta: 0:26:56  iter: 5399  total_loss: 2.332  loss_sem_seg: 1.049  loss_center: 0.4573  loss_offset: 0.6237  time: 0.3523  data_time: 0.0272  lr: 0.0012431  max_mem: 7419M
[12/11 23:38:06 d2.utils.events]:  eta: 0:26:49  iter: 5419  total_loss: 2.138  loss_sem_seg: 1.064  loss_center: 0.486  loss_offset: 0.5458  time: 0.3523  data_time: 0.0274  lr: 0.0012382  max_mem: 7419M
[12/11 23:38:12 d2.utils.events]:  eta: 0:26:41  iter: 5439  total_loss: 2.296  loss_sem_seg: 1.13  loss_center: 0.6057  loss_offset: 0.5463  time: 0.3523  data_time: 0.0259  lr: 0.0012334  max_mem: 7419M
[12/11 23:38:20 d2.utils.events]:  eta: 0:26:34  iter: 5459  total_loss: 2.313  loss_sem_seg: 1.04  loss_center: 0.5422  loss_offset: 0.5675  time: 0.3523  data_time: 0.0292  lr: 0.0012285  max_mem: 7419M
[12/11 23:38:27 d2.utils.events]:  eta: 0:26:27  iter: 5479  total_loss: 2.383  loss_sem_seg: 1.219  loss_center: 0.5111  loss_offset: 0.5916  time: 0.3523  data_time: 0.0292  lr: 0.0012236  max_mem: 7419M
[12/11 23:38:34 d2.utils.events]:  eta: 0:26:20  iter: 5499  total_loss: 2.326  loss_sem_seg: 1.122  loss_center: 0.5089  loss_offset: 0.5578  time: 0.3523  data_time: 0.0270  lr: 0.0012188  max_mem: 7419M
[12/11 23:38:41 d2.utils.events]:  eta: 0:26:13  iter: 5519  total_loss: 2.263  loss_sem_seg: 1.014  loss_center: 0.6607  loss_offset: 0.6147  time: 0.3523  data_time: 0.0277  lr: 0.0012139  max_mem: 7419M
[12/11 23:38:48 d2.utils.events]:  eta: 0:26:06  iter: 5539  total_loss: 2.261  loss_sem_seg: 1.086  loss_center: 0.4885  loss_offset: 0.641  time: 0.3523  data_time: 0.0282  lr: 0.001209  max_mem: 7419M
[12/11 23:38:55 d2.utils.events]:  eta: 0:25:59  iter: 5559  total_loss: 2.192  loss_sem_seg: 1.18  loss_center: 0.5139  loss_offset: 0.5834  time: 0.3523  data_time: 0.0275  lr: 0.0012041  max_mem: 7419M
[12/11 23:39:02 d2.utils.events]:  eta: 0:25:52  iter: 5579  total_loss: 2.454  loss_sem_seg: 1.179  loss_center: 0.671  loss_offset: 0.4869  time: 0.3522  data_time: 0.0260  lr: 0.0011992  max_mem: 7419M
[12/11 23:39:09 d2.utils.events]:  eta: 0:25:45  iter: 5599  total_loss: 2.323  loss_sem_seg: 1.095  loss_center: 0.5878  loss_offset: 0.5901  time: 0.3522  data_time: 0.0277  lr: 0.0011944  max_mem: 7419M
[12/11 23:39:16 d2.utils.events]:  eta: 0:25:37  iter: 5619  total_loss: 2.162  loss_sem_seg: 1.118  loss_center: 0.4501  loss_offset: 0.5616  time: 0.3522  data_time: 0.0280  lr: 0.0011895  max_mem: 7419M
[12/11 23:39:23 d2.utils.events]:  eta: 0:25:30  iter: 5639  total_loss: 2.083  loss_sem_seg: 0.9997  loss_center: 0.5529  loss_offset: 0.4622  time: 0.3522  data_time: 0.0263  lr: 0.0011846  max_mem: 7419M
[12/11 23:39:30 d2.utils.events]:  eta: 0:25:23  iter: 5659  total_loss: 2.567  loss_sem_seg: 1.351  loss_center: 0.5946  loss_offset: 0.5862  time: 0.3522  data_time: 0.0276  lr: 0.0011797  max_mem: 7419M
[12/11 23:39:37 d2.utils.events]:  eta: 0:25:15  iter: 5679  total_loss: 2.486  loss_sem_seg: 1.018  loss_center: 0.4909  loss_offset: 0.6268  time: 0.3522  data_time: 0.0281  lr: 0.0011748  max_mem: 7419M
[12/11 23:39:44 d2.utils.events]:  eta: 0:25:08  iter: 5699  total_loss: 2.239  loss_sem_seg: 1.137  loss_center: 0.5052  loss_offset: 0.6118  time: 0.3522  data_time: 0.0268  lr: 0.0011699  max_mem: 7419M
[12/11 23:39:51 d2.utils.events]:  eta: 0:25:01  iter: 5719  total_loss: 2.1  loss_sem_seg: 0.9923  loss_center: 0.4653  loss_offset: 0.5465  time: 0.3522  data_time: 0.0276  lr: 0.001165  max_mem: 7419M
[12/11 23:39:58 d2.utils.events]:  eta: 0:24:54  iter: 5739  total_loss: 2.107  loss_sem_seg: 1.193  loss_center: 0.4995  loss_offset: 0.5401  time: 0.3522  data_time: 0.0269  lr: 0.0011601  max_mem: 7419M
[12/11 23:40:05 d2.utils.events]:  eta: 0:24:46  iter: 5759  total_loss: 2.086  loss_sem_seg: 0.9988  loss_center: 0.4409  loss_offset: 0.6017  time: 0.3522  data_time: 0.0267  lr: 0.0011552  max_mem: 7419M
[12/11 23:40:12 d2.utils.events]:  eta: 0:24:39  iter: 5779  total_loss: 2.519  loss_sem_seg: 1.254  loss_center: 0.5197  loss_offset: 0.6379  time: 0.3522  data_time: 0.0283  lr: 0.0011503  max_mem: 7419M
[12/11 23:40:19 d2.utils.events]:  eta: 0:24:33  iter: 5799  total_loss: 2.406  loss_sem_seg: 1.198  loss_center: 0.4687  loss_offset: 0.5416  time: 0.3522  data_time: 0.0282  lr: 0.0011454  max_mem: 7419M
[12/11 23:40:26 d2.utils.events]:  eta: 0:24:26  iter: 5819  total_loss: 2.233  loss_sem_seg: 1.109  loss_center: 0.5028  loss_offset: 0.6045  time: 0.3522  data_time: 0.0285  lr: 0.0011405  max_mem: 7419M
[12/11 23:40:33 d2.utils.events]:  eta: 0:24:19  iter: 5839  total_loss: 2.398  loss_sem_seg: 1.142  loss_center: 0.6509  loss_offset: 0.5519  time: 0.3522  data_time: 0.0267  lr: 0.0011356  max_mem: 7419M
[12/11 23:40:40 d2.utils.events]:  eta: 0:24:12  iter: 5859  total_loss: 2.2  loss_sem_seg: 0.9403  loss_center: 0.5713  loss_offset: 0.6121  time: 0.3522  data_time: 0.0285  lr: 0.0011307  max_mem: 7419M
[12/11 23:40:47 d2.utils.events]:  eta: 0:24:04  iter: 5879  total_loss: 2.249  loss_sem_seg: 0.9927  loss_center: 0.5589  loss_offset: 0.4354  time: 0.3522  data_time: 0.0267  lr: 0.0011258  max_mem: 7419M
[12/11 23:40:54 d2.utils.events]:  eta: 0:23:57  iter: 5899  total_loss: 2.258  loss_sem_seg: 1.085  loss_center: 0.551  loss_offset: 0.5209  time: 0.3522  data_time: 0.0254  lr: 0.0011208  max_mem: 7419M
[12/11 23:41:01 d2.utils.events]:  eta: 0:23:51  iter: 5919  total_loss: 2.166  loss_sem_seg: 1.118  loss_center: 0.4747  loss_offset: 0.5836  time: 0.3522  data_time: 0.0279  lr: 0.0011159  max_mem: 7419M
[12/11 23:41:09 d2.utils.events]:  eta: 0:23:43  iter: 5939  total_loss: 2.431  loss_sem_seg: 1.244  loss_center: 0.4686  loss_offset: 0.6012  time: 0.3522  data_time: 0.0278  lr: 0.001111  max_mem: 7419M
[12/11 23:41:16 d2.utils.events]:  eta: 0:23:36  iter: 5959  total_loss: 2.5  loss_sem_seg: 1.264  loss_center: 0.4978  loss_offset: 0.6351  time: 0.3522  data_time: 0.0273  lr: 0.0011061  max_mem: 7419M
[12/11 23:41:23 d2.utils.events]:  eta: 0:23:30  iter: 5979  total_loss: 2.266  loss_sem_seg: 1.102  loss_center: 0.5142  loss_offset: 0.6027  time: 0.3522  data_time: 0.0282  lr: 0.0011011  max_mem: 7419M
[12/11 23:41:30 d2.utils.events]:  eta: 0:23:23  iter: 5999  total_loss: 2.074  loss_sem_seg: 1.021  loss_center: 0.4592  loss_offset: 0.547  time: 0.3522  data_time: 0.0301  lr: 0.0010962  max_mem: 7419M
[12/11 23:41:37 d2.utils.events]:  eta: 0:23:16  iter: 6019  total_loss: 2.008  loss_sem_seg: 0.9273  loss_center: 0.4809  loss_offset: 0.5362  time: 0.3522  data_time: 0.0283  lr: 0.0010913  max_mem: 7419M
[12/11 23:41:44 d2.utils.events]:  eta: 0:23:09  iter: 6039  total_loss: 2.545  loss_sem_seg: 1.247  loss_center: 0.4961  loss_offset: 0.7399  time: 0.3522  data_time: 0.0288  lr: 0.0010863  max_mem: 7419M
[12/11 23:41:51 d2.utils.events]:  eta: 0:23:03  iter: 6059  total_loss: 2.331  loss_sem_seg: 1.133  loss_center: 0.4507  loss_offset: 0.5609  time: 0.3522  data_time: 0.0290  lr: 0.0010814  max_mem: 7419M
[12/11 23:41:58 d2.utils.events]:  eta: 0:22:56  iter: 6079  total_loss: 2.216  loss_sem_seg: 1.117  loss_center: 0.571  loss_offset: 0.5197  time: 0.3522  data_time: 0.0280  lr: 0.0010765  max_mem: 7419M
[12/11 23:42:05 d2.utils.events]:  eta: 0:22:49  iter: 6099  total_loss: 2.133  loss_sem_seg: 1.025  loss_center: 0.5241  loss_offset: 0.5122  time: 0.3522  data_time: 0.0285  lr: 0.0010715  max_mem: 7419M
[12/11 23:42:12 d2.utils.events]:  eta: 0:22:42  iter: 6119  total_loss: 2.441  loss_sem_seg: 1.079  loss_center: 0.5419  loss_offset: 0.7186  time: 0.3522  data_time: 0.0275  lr: 0.0010666  max_mem: 7419M
[12/11 23:42:19 d2.utils.events]:  eta: 0:22:35  iter: 6139  total_loss: 2.254  loss_sem_seg: 1.002  loss_center: 0.5567  loss_offset: 0.5941  time: 0.3522  data_time: 0.0280  lr: 0.0010616  max_mem: 7419M
[12/11 23:42:26 d2.utils.events]:  eta: 0:22:28  iter: 6159  total_loss: 2.389  loss_sem_seg: 1.363  loss_center: 0.5099  loss_offset: 0.5669  time: 0.3522  data_time: 0.0268  lr: 0.0010567  max_mem: 7419M
[12/11 23:42:33 d2.utils.events]:  eta: 0:22:21  iter: 6179  total_loss: 2.215  loss_sem_seg: 1.178  loss_center: 0.525  loss_offset: 0.5669  time: 0.3522  data_time: 0.0258  lr: 0.0010517  max_mem: 7419M
[12/11 23:42:40 d2.utils.events]:  eta: 0:22:14  iter: 6199  total_loss: 2.26  loss_sem_seg: 1.204  loss_center: 0.364  loss_offset: 0.5682  time: 0.3522  data_time: 0.0282  lr: 0.0010468  max_mem: 7419M
[12/11 23:42:47 d2.utils.events]:  eta: 0:22:07  iter: 6219  total_loss: 2.418  loss_sem_seg: 1.023  loss_center: 0.5344  loss_offset: 0.5489  time: 0.3522  data_time: 0.0271  lr: 0.0010418  max_mem: 7419M
[12/11 23:42:54 d2.utils.events]:  eta: 0:22:00  iter: 6239  total_loss: 2.197  loss_sem_seg: 1.017  loss_center: 0.5709  loss_offset: 0.4714  time: 0.3522  data_time: 0.0256  lr: 0.0010368  max_mem: 7419M
[12/11 23:43:01 d2.utils.events]:  eta: 0:21:53  iter: 6259  total_loss: 2.29  loss_sem_seg: 1.155  loss_center: 0.4429  loss_offset: 0.6177  time: 0.3522  data_time: 0.0288  lr: 0.0010319  max_mem: 7419M
[12/11 23:43:09 d2.utils.events]:  eta: 0:21:46  iter: 6279  total_loss: 2.413  loss_sem_seg: 1.211  loss_center: 0.5888  loss_offset: 0.7279  time: 0.3522  data_time: 0.0287  lr: 0.0010269  max_mem: 7419M
[12/11 23:43:16 d2.utils.events]:  eta: 0:21:39  iter: 6299  total_loss: 2.199  loss_sem_seg: 1.041  loss_center: 0.6664  loss_offset: 0.5764  time: 0.3522  data_time: 0.0268  lr: 0.0010219  max_mem: 7419M
[12/11 23:43:23 d2.utils.events]:  eta: 0:21:33  iter: 6319  total_loss: 2.302  loss_sem_seg: 1.157  loss_center: 0.5854  loss_offset: 0.5071  time: 0.3522  data_time: 0.0265  lr: 0.001017  max_mem: 7419M
[12/11 23:43:30 d2.utils.events]:  eta: 0:21:26  iter: 6339  total_loss: 2.252  loss_sem_seg: 1.122  loss_center: 0.5213  loss_offset: 0.5007  time: 0.3522  data_time: 0.0282  lr: 0.001012  max_mem: 7419M
[12/11 23:43:37 d2.utils.events]:  eta: 0:21:19  iter: 6359  total_loss: 1.853  loss_sem_seg: 0.8587  loss_center: 0.5391  loss_offset: 0.3812  time: 0.3522  data_time: 0.0290  lr: 0.001007  max_mem: 7419M
[12/11 23:43:44 d2.utils.events]:  eta: 0:21:12  iter: 6379  total_loss: 2.442  loss_sem_seg: 1.282  loss_center: 0.5746  loss_offset: 0.5034  time: 0.3522  data_time: 0.0278  lr: 0.001002  max_mem: 7419M
[12/11 23:43:51 d2.utils.events]:  eta: 0:21:05  iter: 6399  total_loss: 2.193  loss_sem_seg: 1.085  loss_center: 0.4829  loss_offset: 0.577  time: 0.3522  data_time: 0.0279  lr: 0.00099706  max_mem: 7419M
[12/11 23:43:58 d2.utils.events]:  eta: 0:20:57  iter: 6419  total_loss: 2.267  loss_sem_seg: 1.06  loss_center: 0.5281  loss_offset: 0.5211  time: 0.3522  data_time: 0.0266  lr: 0.00099207  max_mem: 7419M
[12/11 23:44:05 d2.utils.events]:  eta: 0:20:51  iter: 6439  total_loss: 2.137  loss_sem_seg: 0.9903  loss_center: 0.4801  loss_offset: 0.5076  time: 0.3522  data_time: 0.0275  lr: 0.00098709  max_mem: 7419M
[12/11 23:44:12 d2.utils.events]:  eta: 0:20:44  iter: 6459  total_loss: 2.386  loss_sem_seg: 1.065  loss_center: 0.5381  loss_offset: 0.6219  time: 0.3522  data_time: 0.0277  lr: 0.00098209  max_mem: 7419M
[12/11 23:44:19 d2.utils.events]:  eta: 0:20:37  iter: 6479  total_loss: 2.183  loss_sem_seg: 1.141  loss_center: 0.518  loss_offset: 0.5817  time: 0.3522  data_time: 0.0268  lr: 0.0009771  max_mem: 7419M
[12/11 23:44:26 d2.utils.events]:  eta: 0:20:30  iter: 6499  total_loss: 2.007  loss_sem_seg: 1.091  loss_center: 0.4579  loss_offset: 0.5242  time: 0.3522  data_time: 0.0268  lr: 0.0009721  max_mem: 7419M
[12/11 23:44:33 d2.utils.events]:  eta: 0:20:23  iter: 6519  total_loss: 2.116  loss_sem_seg: 1.048  loss_center: 0.4209  loss_offset: 0.6048  time: 0.3522  data_time: 0.0304  lr: 0.00096711  max_mem: 7419M
[12/11 23:44:40 d2.utils.events]:  eta: 0:20:15  iter: 6539  total_loss: 2.075  loss_sem_seg: 0.8666  loss_center: 0.5591  loss_offset: 0.5241  time: 0.3522  data_time: 0.0243  lr: 0.0009621  max_mem: 7419M
[12/11 23:44:47 d2.utils.events]:  eta: 0:20:08  iter: 6559  total_loss: 2.432  loss_sem_seg: 1.202  loss_center: 0.6438  loss_offset: 0.686  time: 0.3522  data_time: 0.0266  lr: 0.0009571  max_mem: 7419M
[12/11 23:44:54 d2.utils.events]:  eta: 0:20:01  iter: 6579  total_loss: 2.166  loss_sem_seg: 0.9907  loss_center: 0.4806  loss_offset: 0.6465  time: 0.3522  data_time: 0.0279  lr: 0.00095209  max_mem: 7419M
[12/11 23:45:01 d2.utils.events]:  eta: 0:19:54  iter: 6599  total_loss: 2.261  loss_sem_seg: 1.19  loss_center: 0.4759  loss_offset: 0.5411  time: 0.3522  data_time: 0.0278  lr: 0.00094708  max_mem: 7419M
[12/11 23:45:08 d2.utils.events]:  eta: 0:19:47  iter: 6619  total_loss: 2.201  loss_sem_seg: 0.9495  loss_center: 0.5228  loss_offset: 0.6454  time: 0.3522  data_time: 0.0288  lr: 0.00094206  max_mem: 7419M
[12/11 23:45:15 d2.utils.events]:  eta: 0:19:41  iter: 6639  total_loss: 2.247  loss_sem_seg: 1.126  loss_center: 0.4777  loss_offset: 0.5784  time: 0.3522  data_time: 0.0282  lr: 0.00093705  max_mem: 7419M
[12/11 23:45:22 d2.utils.events]:  eta: 0:19:34  iter: 6659  total_loss: 2.437  loss_sem_seg: 1.037  loss_center: 0.4924  loss_offset: 0.5544  time: 0.3522  data_time: 0.0270  lr: 0.00093203  max_mem: 7419M
[12/11 23:45:29 d2.utils.events]:  eta: 0:19:27  iter: 6679  total_loss: 2.258  loss_sem_seg: 1.276  loss_center: 0.5072  loss_offset: 0.5276  time: 0.3522  data_time: 0.0286  lr: 0.000927  max_mem: 7419M
[12/11 23:45:37 d2.utils.events]:  eta: 0:19:20  iter: 6699  total_loss: 2.125  loss_sem_seg: 0.9826  loss_center: 0.4904  loss_offset: 0.5456  time: 0.3522  data_time: 0.0281  lr: 0.00092198  max_mem: 7419M
[12/11 23:45:44 d2.utils.events]:  eta: 0:19:13  iter: 6719  total_loss: 2.269  loss_sem_seg: 1.053  loss_center: 0.55  loss_offset: 0.5245  time: 0.3522  data_time: 0.0275  lr: 0.00091695  max_mem: 7419M
[12/11 23:45:51 d2.utils.events]:  eta: 0:19:06  iter: 6739  total_loss: 2.32  loss_sem_seg: 0.9657  loss_center: 0.5345  loss_offset: 0.4936  time: 0.3522  data_time: 0.0269  lr: 0.00091192  max_mem: 7419M
[12/11 23:45:58 d2.utils.events]:  eta: 0:18:59  iter: 6759  total_loss: 1.918  loss_sem_seg: 0.973  loss_center: 0.4755  loss_offset: 0.4833  time: 0.3522  data_time: 0.0296  lr: 0.00090688  max_mem: 7419M
[12/11 23:46:05 d2.utils.events]:  eta: 0:18:52  iter: 6779  total_loss: 2.189  loss_sem_seg: 0.985  loss_center: 0.4481  loss_offset: 0.6103  time: 0.3522  data_time: 0.0268  lr: 0.00090184  max_mem: 7419M
[12/11 23:46:12 d2.utils.events]:  eta: 0:18:45  iter: 6799  total_loss: 2.087  loss_sem_seg: 1.015  loss_center: 0.5711  loss_offset: 0.5882  time: 0.3522  data_time: 0.0293  lr: 0.0008968  max_mem: 7419M
[12/11 23:46:19 d2.utils.events]:  eta: 0:18:38  iter: 6819  total_loss: 2.44  loss_sem_seg: 1.195  loss_center: 0.4592  loss_offset: 0.7373  time: 0.3522  data_time: 0.0259  lr: 0.00089176  max_mem: 7419M
[12/11 23:46:26 d2.utils.events]:  eta: 0:18:31  iter: 6839  total_loss: 2.281  loss_sem_seg: 1.208  loss_center: 0.4626  loss_offset: 0.5263  time: 0.3522  data_time: 0.0286  lr: 0.00088671  max_mem: 7419M
[12/11 23:46:33 d2.utils.events]:  eta: 0:18:24  iter: 6859  total_loss: 2.234  loss_sem_seg: 1.051  loss_center: 0.5233  loss_offset: 0.5646  time: 0.3522  data_time: 0.0278  lr: 0.00088166  max_mem: 7419M
[12/11 23:46:40 d2.utils.events]:  eta: 0:18:17  iter: 6879  total_loss: 2.143  loss_sem_seg: 0.9784  loss_center: 0.513  loss_offset: 0.5076  time: 0.3522  data_time: 0.0266  lr: 0.00087661  max_mem: 7419M
[12/11 23:46:47 d2.utils.events]:  eta: 0:18:10  iter: 6899  total_loss: 2.524  loss_sem_seg: 1.136  loss_center: 0.5315  loss_offset: 0.6306  time: 0.3522  data_time: 0.0269  lr: 0.00087155  max_mem: 7419M
[12/11 23:46:54 d2.utils.events]:  eta: 0:18:03  iter: 6919  total_loss: 2.041  loss_sem_seg: 0.9199  loss_center: 0.4558  loss_offset: 0.532  time: 0.3522  data_time: 0.0266  lr: 0.00086649  max_mem: 7419M
[12/11 23:47:01 d2.utils.events]:  eta: 0:17:56  iter: 6939  total_loss: 2.056  loss_sem_seg: 0.9772  loss_center: 0.5335  loss_offset: 0.5899  time: 0.3522  data_time: 0.0281  lr: 0.00086142  max_mem: 7419M
[12/11 23:47:08 d2.utils.events]:  eta: 0:17:49  iter: 6959  total_loss: 2.214  loss_sem_seg: 1.081  loss_center: 0.4833  loss_offset: 0.5808  time: 0.3522  data_time: 0.0262  lr: 0.00085636  max_mem: 7419M
[12/11 23:47:15 d2.utils.events]:  eta: 0:17:41  iter: 6979  total_loss: 2.135  loss_sem_seg: 1.101  loss_center: 0.424  loss_offset: 0.5136  time: 0.3522  data_time: 0.0273  lr: 0.00085129  max_mem: 7419M
[12/11 23:47:22 d2.utils.events]:  eta: 0:17:34  iter: 6999  total_loss: 2.408  loss_sem_seg: 1.081  loss_center: 0.5823  loss_offset: 0.5541  time: 0.3522  data_time: 0.0278  lr: 0.00084621  max_mem: 7419M
[12/11 23:47:29 d2.utils.events]:  eta: 0:17:27  iter: 7019  total_loss: 2.321  loss_sem_seg: 1.055  loss_center: 0.5668  loss_offset: 0.56  time: 0.3522  data_time: 0.0269  lr: 0.00084114  max_mem: 7419M
[12/11 23:47:36 d2.utils.events]:  eta: 0:17:21  iter: 7039  total_loss: 1.884  loss_sem_seg: 0.9594  loss_center: 0.4546  loss_offset: 0.4603  time: 0.3522  data_time: 0.0289  lr: 0.00083605  max_mem: 7419M
[12/11 23:47:43 d2.utils.events]:  eta: 0:17:13  iter: 7059  total_loss: 2.247  loss_sem_seg: 0.9893  loss_center: 0.5789  loss_offset: 0.5692  time: 0.3522  data_time: 0.0278  lr: 0.00083097  max_mem: 7419M
[12/11 23:47:50 d2.utils.events]:  eta: 0:17:06  iter: 7079  total_loss: 2.378  loss_sem_seg: 1.008  loss_center: 0.5761  loss_offset: 0.5389  time: 0.3522  data_time: 0.0292  lr: 0.00082588  max_mem: 7419M
[12/11 23:47:58 d2.utils.events]:  eta: 0:16:59  iter: 7099  total_loss: 2.146  loss_sem_seg: 1.097  loss_center: 0.478  loss_offset: 0.5832  time: 0.3522  data_time: 0.0285  lr: 0.00082079  max_mem: 7419M
[12/11 23:48:05 d2.utils.events]:  eta: 0:16:52  iter: 7119  total_loss: 2.195  loss_sem_seg: 0.9952  loss_center: 0.4992  loss_offset: 0.5403  time: 0.3522  data_time: 0.0276  lr: 0.0008157  max_mem: 7419M
[12/11 23:48:12 d2.utils.events]:  eta: 0:16:45  iter: 7139  total_loss: 2.157  loss_sem_seg: 0.9384  loss_center: 0.4229  loss_offset: 0.5738  time: 0.3522  data_time: 0.0284  lr: 0.0008106  max_mem: 7419M
[12/11 23:48:19 d2.utils.events]:  eta: 0:16:38  iter: 7159  total_loss: 2.126  loss_sem_seg: 0.9579  loss_center: 0.5153  loss_offset: 0.5389  time: 0.3522  data_time: 0.0275  lr: 0.0008055  max_mem: 7419M
[12/11 23:48:26 d2.utils.events]:  eta: 0:16:31  iter: 7179  total_loss: 2.142  loss_sem_seg: 0.9161  loss_center: 0.5084  loss_offset: 0.5359  time: 0.3522  data_time: 0.0288  lr: 0.00080039  max_mem: 7419M
[12/11 23:48:33 d2.utils.events]:  eta: 0:16:24  iter: 7199  total_loss: 2.209  loss_sem_seg: 1.02  loss_center: 0.4447  loss_offset: 0.5726  time: 0.3522  data_time: 0.0275  lr: 0.00079528  max_mem: 7419M
[12/11 23:48:40 d2.utils.events]:  eta: 0:16:17  iter: 7219  total_loss: 2.02  loss_sem_seg: 0.9458  loss_center: 0.5103  loss_offset: 0.516  time: 0.3522  data_time: 0.0275  lr: 0.00079017  max_mem: 7419M
[12/11 23:48:47 d2.utils.events]:  eta: 0:16:10  iter: 7239  total_loss: 2.306  loss_sem_seg: 1.066  loss_center: 0.5512  loss_offset: 0.5733  time: 0.3522  data_time: 0.0270  lr: 0.00078505  max_mem: 7419M
[12/11 23:48:54 d2.utils.events]:  eta: 0:16:03  iter: 7259  total_loss: 2.268  loss_sem_seg: 1.095  loss_center: 0.4371  loss_offset: 0.5944  time: 0.3522  data_time: 0.0296  lr: 0.00077993  max_mem: 7419M
[12/11 23:49:01 d2.utils.events]:  eta: 0:15:56  iter: 7279  total_loss: 2.033  loss_sem_seg: 0.9664  loss_center: 0.5056  loss_offset: 0.5842  time: 0.3522  data_time: 0.0272  lr: 0.00077481  max_mem: 7419M
[12/11 23:49:08 d2.utils.events]:  eta: 0:15:49  iter: 7299  total_loss: 2.087  loss_sem_seg: 1.036  loss_center: 0.5469  loss_offset: 0.4863  time: 0.3522  data_time: 0.0275  lr: 0.00076968  max_mem: 7419M
[12/11 23:49:15 d2.utils.events]:  eta: 0:15:42  iter: 7319  total_loss: 2.076  loss_sem_seg: 0.8976  loss_center: 0.604  loss_offset: 0.5762  time: 0.3522  data_time: 0.0261  lr: 0.00076455  max_mem: 7419M
[12/11 23:49:22 d2.utils.events]:  eta: 0:15:34  iter: 7339  total_loss: 1.97  loss_sem_seg: 1.076  loss_center: 0.436  loss_offset: 0.5261  time: 0.3522  data_time: 0.0267  lr: 0.00075942  max_mem: 7419M
[12/11 23:49:29 d2.utils.events]:  eta: 0:15:28  iter: 7359  total_loss: 1.931  loss_sem_seg: 0.9488  loss_center: 0.4399  loss_offset: 0.612  time: 0.3522  data_time: 0.0271  lr: 0.00075428  max_mem: 7419M
[12/11 23:49:36 d2.utils.events]:  eta: 0:15:21  iter: 7379  total_loss: 2.25  loss_sem_seg: 1.091  loss_center: 0.6314  loss_offset: 0.5485  time: 0.3522  data_time: 0.0263  lr: 0.00074914  max_mem: 7419M
[12/11 23:49:43 d2.utils.events]:  eta: 0:15:13  iter: 7399  total_loss: 2.374  loss_sem_seg: 1.149  loss_center: 0.5191  loss_offset: 0.6235  time: 0.3522  data_time: 0.0272  lr: 0.00074399  max_mem: 7419M
[12/11 23:49:50 d2.utils.events]:  eta: 0:15:07  iter: 7419  total_loss: 2.278  loss_sem_seg: 1.191  loss_center: 0.5009  loss_offset: 0.6254  time: 0.3522  data_time: 0.0279  lr: 0.00073884  max_mem: 7419M
[12/11 23:49:57 d2.utils.events]:  eta: 0:15:00  iter: 7439  total_loss: 2.115  loss_sem_seg: 1.142  loss_center: 0.5107  loss_offset: 0.5059  time: 0.3522  data_time: 0.0286  lr: 0.00073368  max_mem: 7419M
[12/11 23:50:04 d2.utils.events]:  eta: 0:14:52  iter: 7459  total_loss: 2.157  loss_sem_seg: 0.9677  loss_center: 0.4803  loss_offset: 0.6264  time: 0.3522  data_time: 0.0259  lr: 0.00072852  max_mem: 7419M
[12/11 23:50:11 d2.utils.events]:  eta: 0:14:45  iter: 7479  total_loss: 2.3  loss_sem_seg: 1.054  loss_center: 0.6039  loss_offset: 0.5048  time: 0.3522  data_time: 0.0287  lr: 0.00072336  max_mem: 7419M
[12/11 23:50:18 d2.utils.events]:  eta: 0:14:38  iter: 7499  total_loss: 2.109  loss_sem_seg: 0.9077  loss_center: 0.7324  loss_offset: 0.4441  time: 0.3522  data_time: 0.0270  lr: 0.00071819  max_mem: 7419M
[12/11 23:50:25 d2.utils.events]:  eta: 0:14:30  iter: 7519  total_loss: 1.897  loss_sem_seg: 0.7959  loss_center: 0.4912  loss_offset: 0.4967  time: 0.3521  data_time: 0.0272  lr: 0.00071302  max_mem: 7419M
[12/11 23:50:32 d2.utils.events]:  eta: 0:14:23  iter: 7539  total_loss: 2.265  loss_sem_seg: 1.025  loss_center: 0.5192  loss_offset: 0.6167  time: 0.3521  data_time: 0.0275  lr: 0.00070785  max_mem: 7419M
[12/11 23:50:39 d2.utils.events]:  eta: 0:14:17  iter: 7559  total_loss: 2.113  loss_sem_seg: 0.918  loss_center: 0.5255  loss_offset: 0.6166  time: 0.3522  data_time: 0.0287  lr: 0.00070267  max_mem: 7419M
[12/11 23:50:47 d2.utils.events]:  eta: 0:14:10  iter: 7579  total_loss: 2.258  loss_sem_seg: 1.122  loss_center: 0.4268  loss_offset: 0.5448  time: 0.3522  data_time: 0.0281  lr: 0.00069749  max_mem: 7419M
[12/11 23:50:54 d2.utils.events]:  eta: 0:14:03  iter: 7599  total_loss: 2.191  loss_sem_seg: 0.9613  loss_center: 0.6193  loss_offset: 0.6373  time: 0.3522  data_time: 0.0270  lr: 0.0006923  max_mem: 7419M
[12/11 23:51:01 d2.utils.events]:  eta: 0:13:56  iter: 7619  total_loss: 2.327  loss_sem_seg: 1.126  loss_center: 0.6076  loss_offset: 0.5878  time: 0.3522  data_time: 0.0283  lr: 0.00068711  max_mem: 7419M
[12/11 23:51:08 d2.utils.events]:  eta: 0:13:49  iter: 7639  total_loss: 2.394  loss_sem_seg: 1.024  loss_center: 0.5785  loss_offset: 0.5958  time: 0.3522  data_time: 0.0272  lr: 0.00068191  max_mem: 7419M
[12/11 23:51:15 d2.utils.events]:  eta: 0:13:42  iter: 7659  total_loss: 1.926  loss_sem_seg: 0.9548  loss_center: 0.5342  loss_offset: 0.4212  time: 0.3522  data_time: 0.0283  lr: 0.00067671  max_mem: 7419M
[12/11 23:51:22 d2.utils.events]:  eta: 0:13:35  iter: 7679  total_loss: 2.195  loss_sem_seg: 0.9376  loss_center: 0.5731  loss_offset: 0.5563  time: 0.3522  data_time: 0.0290  lr: 0.0006715  max_mem: 7419M
[12/11 23:51:29 d2.utils.events]:  eta: 0:13:28  iter: 7699  total_loss: 2.138  loss_sem_seg: 1.026  loss_center: 0.495  loss_offset: 0.5644  time: 0.3522  data_time: 0.0268  lr: 0.00066629  max_mem: 7419M
[12/11 23:51:36 d2.utils.events]:  eta: 0:13:21  iter: 7719  total_loss: 2.064  loss_sem_seg: 0.9146  loss_center: 0.4793  loss_offset: 0.5487  time: 0.3522  data_time: 0.0279  lr: 0.00066108  max_mem: 7419M
[12/11 23:51:43 d2.utils.events]:  eta: 0:13:13  iter: 7739  total_loss: 2.276  loss_sem_seg: 1.007  loss_center: 0.623  loss_offset: 0.714  time: 0.3522  data_time: 0.0269  lr: 0.00065586  max_mem: 7419M
[12/11 23:51:50 d2.utils.events]:  eta: 0:13:06  iter: 7759  total_loss: 2.209  loss_sem_seg: 1.036  loss_center: 0.5137  loss_offset: 0.4919  time: 0.3521  data_time: 0.0266  lr: 0.00065064  max_mem: 7419M
[12/11 23:51:57 d2.utils.events]:  eta: 0:12:59  iter: 7779  total_loss: 1.913  loss_sem_seg: 0.856  loss_center: 0.5466  loss_offset: 0.4875  time: 0.3521  data_time: 0.0263  lr: 0.00064541  max_mem: 7419M
[12/11 23:52:04 d2.utils.events]:  eta: 0:12:52  iter: 7799  total_loss: 2.387  loss_sem_seg: 1.027  loss_center: 0.4888  loss_offset: 0.5455  time: 0.3521  data_time: 0.0266  lr: 0.00064017  max_mem: 7419M
[12/11 23:52:11 d2.utils.events]:  eta: 0:12:44  iter: 7819  total_loss: 2.129  loss_sem_seg: 0.875  loss_center: 0.5108  loss_offset: 0.5669  time: 0.3521  data_time: 0.0289  lr: 0.00063494  max_mem: 7419M
[12/11 23:52:18 d2.utils.events]:  eta: 0:12:37  iter: 7839  total_loss: 2.265  loss_sem_seg: 1.046  loss_center: 0.5418  loss_offset: 0.5614  time: 0.3521  data_time: 0.0263  lr: 0.00062969  max_mem: 7419M
[12/11 23:52:25 d2.utils.events]:  eta: 0:12:30  iter: 7859  total_loss: 1.997  loss_sem_seg: 0.8512  loss_center: 0.6388  loss_offset: 0.4214  time: 0.3521  data_time: 0.0286  lr: 0.00062445  max_mem: 7419M
[12/11 23:52:32 d2.utils.events]:  eta: 0:12:23  iter: 7879  total_loss: 1.957  loss_sem_seg: 0.965  loss_center: 0.4398  loss_offset: 0.5152  time: 0.3521  data_time: 0.0277  lr: 0.00061919  max_mem: 7419M
[12/11 23:52:39 d2.utils.events]:  eta: 0:12:16  iter: 7899  total_loss: 2.215  loss_sem_seg: 1.03  loss_center: 0.5259  loss_offset: 0.5893  time: 0.3521  data_time: 0.0272  lr: 0.00061394  max_mem: 7419M
[12/11 23:52:46 d2.utils.events]:  eta: 0:12:09  iter: 7919  total_loss: 2.5  loss_sem_seg: 1.134  loss_center: 0.5484  loss_offset: 0.6979  time: 0.3521  data_time: 0.0278  lr: 0.00060867  max_mem: 7419M
[12/11 23:52:53 d2.utils.events]:  eta: 0:12:02  iter: 7939  total_loss: 2.04  loss_sem_seg: 1.024  loss_center: 0.4926  loss_offset: 0.5338  time: 0.3521  data_time: 0.0285  lr: 0.00060341  max_mem: 7419M
[12/11 23:53:00 d2.utils.events]:  eta: 0:11:55  iter: 7959  total_loss: 2.291  loss_sem_seg: 1.025  loss_center: 0.4775  loss_offset: 0.5459  time: 0.3521  data_time: 0.0293  lr: 0.00059813  max_mem: 7419M
[12/11 23:53:07 d2.utils.events]:  eta: 0:11:48  iter: 7979  total_loss: 2.24  loss_sem_seg: 1.009  loss_center: 0.533  loss_offset: 0.5737  time: 0.3521  data_time: 0.0271  lr: 0.00059286  max_mem: 7419M
[12/11 23:53:14 d2.utils.events]:  eta: 0:11:41  iter: 7999  total_loss: 2.313  loss_sem_seg: 0.9811  loss_center: 0.5766  loss_offset: 0.552  time: 0.3521  data_time: 0.0282  lr: 0.00058757  max_mem: 7419M
[12/11 23:53:21 d2.utils.events]:  eta: 0:11:34  iter: 8019  total_loss: 2.1  loss_sem_seg: 1.033  loss_center: 0.4445  loss_offset: 0.4437  time: 0.3521  data_time: 0.0286  lr: 0.00058229  max_mem: 7419M
[12/11 23:53:29 d2.utils.events]:  eta: 0:11:27  iter: 8039  total_loss: 2.112  loss_sem_seg: 0.8542  loss_center: 0.5476  loss_offset: 0.6267  time: 0.3521  data_time: 0.0284  lr: 0.00057699  max_mem: 7419M
[12/11 23:53:36 d2.utils.events]:  eta: 0:11:20  iter: 8059  total_loss: 2.437  loss_sem_seg: 1.087  loss_center: 0.633  loss_offset: 0.7126  time: 0.3521  data_time: 0.0294  lr: 0.00057169  max_mem: 7419M
[12/11 23:53:43 d2.utils.events]:  eta: 0:11:13  iter: 8079  total_loss: 2.131  loss_sem_seg: 0.9521  loss_center: 0.5437  loss_offset: 0.4657  time: 0.3521  data_time: 0.0256  lr: 0.00056639  max_mem: 7419M
[12/11 23:53:50 d2.utils.events]:  eta: 0:11:06  iter: 8099  total_loss: 2.088  loss_sem_seg: 1.081  loss_center: 0.5371  loss_offset: 0.5479  time: 0.3521  data_time: 0.0274  lr: 0.00056108  max_mem: 7419M
[12/11 23:53:57 d2.utils.events]:  eta: 0:10:59  iter: 8119  total_loss: 1.915  loss_sem_seg: 0.9149  loss_center: 0.4744  loss_offset: 0.4314  time: 0.3521  data_time: 0.0280  lr: 0.00055576  max_mem: 7419M
[12/11 23:54:04 d2.utils.events]:  eta: 0:10:52  iter: 8139  total_loss: 2.447  loss_sem_seg: 1.073  loss_center: 0.5687  loss_offset: 0.6373  time: 0.3521  data_time: 0.0288  lr: 0.00055044  max_mem: 7419M
[12/11 23:54:11 d2.utils.events]:  eta: 0:10:45  iter: 8159  total_loss: 2.33  loss_sem_seg: 1.011  loss_center: 0.6212  loss_offset: 0.542  time: 0.3521  data_time: 0.0278  lr: 0.00054512  max_mem: 7419M
[12/11 23:54:18 d2.utils.events]:  eta: 0:10:38  iter: 8179  total_loss: 2.162  loss_sem_seg: 1.097  loss_center: 0.5632  loss_offset: 0.514  time: 0.3521  data_time: 0.0284  lr: 0.00053978  max_mem: 7419M
[12/11 23:54:25 d2.utils.events]:  eta: 0:10:31  iter: 8199  total_loss: 2.029  loss_sem_seg: 0.8611  loss_center: 0.4579  loss_offset: 0.5968  time: 0.3521  data_time: 0.0287  lr: 0.00053444  max_mem: 7419M
[12/11 23:54:32 d2.utils.events]:  eta: 0:10:24  iter: 8219  total_loss: 2.176  loss_sem_seg: 1.008  loss_center: 0.4898  loss_offset: 0.4956  time: 0.3521  data_time: 0.0285  lr: 0.0005291  max_mem: 7419M
[12/11 23:54:39 d2.utils.events]:  eta: 0:10:17  iter: 8239  total_loss: 2.197  loss_sem_seg: 1.027  loss_center: 0.4708  loss_offset: 0.5216  time: 0.3521  data_time: 0.0284  lr: 0.00052375  max_mem: 7419M
[12/11 23:54:46 d2.utils.events]:  eta: 0:10:10  iter: 8259  total_loss: 2.26  loss_sem_seg: 0.9778  loss_center: 0.6096  loss_offset: 0.6448  time: 0.3521  data_time: 0.0267  lr: 0.00051839  max_mem: 7419M
[12/11 23:54:53 d2.utils.events]:  eta: 0:10:03  iter: 8279  total_loss: 2.121  loss_sem_seg: 1.034  loss_center: 0.4011  loss_offset: 0.5  time: 0.3521  data_time: 0.0278  lr: 0.00051303  max_mem: 7419M
[12/11 23:55:00 d2.utils.events]:  eta: 0:09:56  iter: 8299  total_loss: 1.937  loss_sem_seg: 1.037  loss_center: 0.4414  loss_offset: 0.4836  time: 0.3521  data_time: 0.0285  lr: 0.00050766  max_mem: 7419M
[12/11 23:55:07 d2.utils.events]:  eta: 0:09:49  iter: 8319  total_loss: 2.258  loss_sem_seg: 1.028  loss_center: 0.5317  loss_offset: 0.5594  time: 0.3521  data_time: 0.0279  lr: 0.00050229  max_mem: 7419M
[12/11 23:55:14 d2.utils.events]:  eta: 0:09:42  iter: 8339  total_loss: 2.2  loss_sem_seg: 1.034  loss_center: 0.5358  loss_offset: 0.5374  time: 0.3521  data_time: 0.0274  lr: 0.0004969  max_mem: 7419M
[12/11 23:55:21 d2.utils.events]:  eta: 0:09:35  iter: 8359  total_loss: 2.269  loss_sem_seg: 1.01  loss_center: 0.562  loss_offset: 0.5954  time: 0.3521  data_time: 0.0279  lr: 0.00049152  max_mem: 7419M
[12/11 23:55:28 d2.utils.events]:  eta: 0:09:28  iter: 8379  total_loss: 2.266  loss_sem_seg: 1.098  loss_center: 0.4802  loss_offset: 0.6064  time: 0.3521  data_time: 0.0261  lr: 0.00048612  max_mem: 7419M
[12/11 23:55:35 d2.utils.events]:  eta: 0:09:21  iter: 8399  total_loss: 2.091  loss_sem_seg: 0.9491  loss_center: 0.5104  loss_offset: 0.5375  time: 0.3521  data_time: 0.0282  lr: 0.00048072  max_mem: 7419M
[12/11 23:55:42 d2.utils.events]:  eta: 0:09:13  iter: 8419  total_loss: 1.981  loss_sem_seg: 0.9754  loss_center: 0.5892  loss_offset: 0.4746  time: 0.3521  data_time: 0.0257  lr: 0.00047531  max_mem: 7419M
[12/11 23:55:49 d2.utils.events]:  eta: 0:09:06  iter: 8439  total_loss: 1.819  loss_sem_seg: 0.7886  loss_center: 0.4551  loss_offset: 0.4717  time: 0.3521  data_time: 0.0277  lr: 0.0004699  max_mem: 7419M
[12/11 23:55:56 d2.utils.events]:  eta: 0:08:59  iter: 8459  total_loss: 2.14  loss_sem_seg: 1.019  loss_center: 0.6354  loss_offset: 0.494  time: 0.3521  data_time: 0.0275  lr: 0.00046448  max_mem: 7419M
[12/11 23:56:03 d2.utils.events]:  eta: 0:08:52  iter: 8479  total_loss: 2.054  loss_sem_seg: 0.9596  loss_center: 0.5315  loss_offset: 0.4872  time: 0.3521  data_time: 0.0272  lr: 0.00045905  max_mem: 7419M
[12/11 23:56:10 d2.utils.events]:  eta: 0:08:45  iter: 8499  total_loss: 2.163  loss_sem_seg: 0.9341  loss_center: 0.5152  loss_offset: 0.5172  time: 0.3521  data_time: 0.0278  lr: 0.00045361  max_mem: 7419M
[12/11 23:56:18 d2.utils.events]:  eta: 0:08:39  iter: 8519  total_loss: 2.022  loss_sem_seg: 0.9012  loss_center: 0.5576  loss_offset: 0.4883  time: 0.3521  data_time: 0.0275  lr: 0.00044817  max_mem: 7419M
[12/11 23:56:25 d2.utils.events]:  eta: 0:08:32  iter: 8539  total_loss: 2.137  loss_sem_seg: 1.078  loss_center: 0.4244  loss_offset: 0.5908  time: 0.3521  data_time: 0.0279  lr: 0.00044272  max_mem: 7419M
[12/11 23:56:32 d2.utils.events]:  eta: 0:08:25  iter: 8559  total_loss: 2.289  loss_sem_seg: 1.002  loss_center: 0.5305  loss_offset: 0.5572  time: 0.3521  data_time: 0.0264  lr: 0.00043726  max_mem: 7419M
[12/11 23:56:39 d2.utils.events]:  eta: 0:08:17  iter: 8579  total_loss: 2.142  loss_sem_seg: 0.92  loss_center: 0.4871  loss_offset: 0.5945  time: 0.3521  data_time: 0.0278  lr: 0.00043179  max_mem: 7419M
[12/11 23:56:46 d2.utils.events]:  eta: 0:08:10  iter: 8599  total_loss: 2.203  loss_sem_seg: 1.006  loss_center: 0.5484  loss_offset: 0.5906  time: 0.3521  data_time: 0.0274  lr: 0.00042632  max_mem: 7419M
[12/11 23:56:53 d2.utils.events]:  eta: 0:08:03  iter: 8619  total_loss: 1.758  loss_sem_seg: 0.8645  loss_center: 0.3128  loss_offset: 0.5895  time: 0.3521  data_time: 0.0291  lr: 0.00042084  max_mem: 7419M
[12/11 23:57:00 d2.utils.events]:  eta: 0:07:56  iter: 8639  total_loss: 2.206  loss_sem_seg: 0.9417  loss_center: 0.5006  loss_offset: 0.5941  time: 0.3521  data_time: 0.0265  lr: 0.00041535  max_mem: 7419M
[12/11 23:57:07 d2.utils.events]:  eta: 0:07:49  iter: 8659  total_loss: 2.032  loss_sem_seg: 0.9533  loss_center: 0.5505  loss_offset: 0.5438  time: 0.3521  data_time: 0.0276  lr: 0.00040985  max_mem: 7419M
[12/11 23:57:14 d2.utils.events]:  eta: 0:07:42  iter: 8679  total_loss: 1.97  loss_sem_seg: 0.9564  loss_center: 0.3537  loss_offset: 0.4458  time: 0.3521  data_time: 0.0279  lr: 0.00040435  max_mem: 7419M
[12/11 23:57:21 d2.utils.events]:  eta: 0:07:35  iter: 8699  total_loss: 1.99  loss_sem_seg: 0.9218  loss_center: 0.5381  loss_offset: 0.5152  time: 0.3521  data_time: 0.0273  lr: 0.00039883  max_mem: 7419M
[12/11 23:57:28 d2.utils.events]:  eta: 0:07:28  iter: 8719  total_loss: 2.029  loss_sem_seg: 1.032  loss_center: 0.5293  loss_offset: 0.4399  time: 0.3521  data_time: 0.0275  lr: 0.00039331  max_mem: 7419M
[12/11 23:57:35 d2.utils.events]:  eta: 0:07:21  iter: 8739  total_loss: 1.959  loss_sem_seg: 0.9662  loss_center: 0.5177  loss_offset: 0.5611  time: 0.3521  data_time: 0.0277  lr: 0.00038778  max_mem: 7419M
[12/11 23:57:42 d2.utils.events]:  eta: 0:07:14  iter: 8759  total_loss: 2.13  loss_sem_seg: 1.044  loss_center: 0.4209  loss_offset: 0.5103  time: 0.3521  data_time: 0.0277  lr: 0.00038224  max_mem: 7419M
[12/11 23:57:49 d2.utils.events]:  eta: 0:07:07  iter: 8779  total_loss: 1.925  loss_sem_seg: 0.9527  loss_center: 0.4898  loss_offset: 0.5012  time: 0.3521  data_time: 0.0272  lr: 0.00037669  max_mem: 7419M
[12/11 23:57:56 d2.utils.events]:  eta: 0:07:01  iter: 8799  total_loss: 2.115  loss_sem_seg: 1.031  loss_center: 0.5709  loss_offset: 0.5481  time: 0.3521  data_time: 0.0297  lr: 0.00037113  max_mem: 7419M
[12/11 23:58:03 d2.utils.events]:  eta: 0:06:54  iter: 8819  total_loss: 2.214  loss_sem_seg: 1.012  loss_center: 0.5938  loss_offset: 0.5406  time: 0.3521  data_time: 0.0291  lr: 0.00036557  max_mem: 7419M
[12/11 23:58:10 d2.utils.events]:  eta: 0:06:47  iter: 8839  total_loss: 2.021  loss_sem_seg: 0.9531  loss_center: 0.4692  loss_offset: 0.555  time: 0.3521  data_time: 0.0273  lr: 0.00035999  max_mem: 7419M
[12/11 23:58:18 d2.utils.events]:  eta: 0:06:40  iter: 8859  total_loss: 2.239  loss_sem_seg: 1.052  loss_center: 0.5088  loss_offset: 0.5668  time: 0.3521  data_time: 0.0290  lr: 0.0003544  max_mem: 7419M
[12/11 23:58:25 d2.utils.events]:  eta: 0:06:33  iter: 8879  total_loss: 1.985  loss_sem_seg: 0.9864  loss_center: 0.4407  loss_offset: 0.4798  time: 0.3521  data_time: 0.0264  lr: 0.00034881  max_mem: 7419M
[12/11 23:58:32 d2.utils.events]:  eta: 0:06:26  iter: 8899  total_loss: 2.134  loss_sem_seg: 0.908  loss_center: 0.5587  loss_offset: 0.5692  time: 0.3521  data_time: 0.0277  lr: 0.0003432  max_mem: 7419M
[12/11 23:58:39 d2.utils.events]:  eta: 0:06:19  iter: 8919  total_loss: 1.967  loss_sem_seg: 0.9298  loss_center: 0.4732  loss_offset: 0.5015  time: 0.3521  data_time: 0.0251  lr: 0.00033758  max_mem: 7419M
[12/11 23:58:46 d2.utils.events]:  eta: 0:06:11  iter: 8939  total_loss: 2.365  loss_sem_seg: 0.9694  loss_center: 0.5473  loss_offset: 0.5501  time: 0.3521  data_time: 0.0300  lr: 0.00033196  max_mem: 7419M
[12/11 23:58:53 d2.utils.events]:  eta: 0:06:04  iter: 8959  total_loss: 2.53  loss_sem_seg: 0.9753  loss_center: 0.5872  loss_offset: 0.5805  time: 0.3521  data_time: 0.0258  lr: 0.00032632  max_mem: 7419M
[12/11 23:59:00 d2.utils.events]:  eta: 0:05:57  iter: 8979  total_loss: 2.104  loss_sem_seg: 0.9412  loss_center: 0.5506  loss_offset: 0.5152  time: 0.3521  data_time: 0.0276  lr: 0.00032067  max_mem: 7419M
[12/11 23:59:07 d2.utils.events]:  eta: 0:05:50  iter: 8999  total_loss: 1.927  loss_sem_seg: 0.7874  loss_center: 0.5416  loss_offset: 0.5353  time: 0.3521  data_time: 0.0285  lr: 0.00031501  max_mem: 7419M
[12/11 23:59:14 d2.utils.events]:  eta: 0:05:43  iter: 9019  total_loss: 2.316  loss_sem_seg: 1.038  loss_center: 0.4225  loss_offset: 0.5372  time: 0.3521  data_time: 0.0274  lr: 0.00030934  max_mem: 7419M
[12/11 23:59:21 d2.utils.events]:  eta: 0:05:36  iter: 9039  total_loss: 2.013  loss_sem_seg: 0.9219  loss_center: 0.4849  loss_offset: 0.5417  time: 0.3521  data_time: 0.0266  lr: 0.00030366  max_mem: 7419M
[12/11 23:59:28 d2.utils.events]:  eta: 0:05:29  iter: 9059  total_loss: 1.895  loss_sem_seg: 0.7863  loss_center: 0.4751  loss_offset: 0.4931  time: 0.3521  data_time: 0.0276  lr: 0.00029797  max_mem: 7419M
[12/11 23:59:35 d2.utils.events]:  eta: 0:05:22  iter: 9079  total_loss: 2.243  loss_sem_seg: 0.9705  loss_center: 0.6134  loss_offset: 0.4809  time: 0.3521  data_time: 0.0270  lr: 0.00029226  max_mem: 7419M
[12/11 23:59:42 d2.utils.events]:  eta: 0:05:15  iter: 9099  total_loss: 2.169  loss_sem_seg: 0.9364  loss_center: 0.4748  loss_offset: 0.4747  time: 0.3521  data_time: 0.0262  lr: 0.00028654  max_mem: 7419M
[12/11 23:59:49 d2.utils.events]:  eta: 0:05:08  iter: 9119  total_loss: 1.931  loss_sem_seg: 0.9063  loss_center: 0.5039  loss_offset: 0.5364  time: 0.3521  data_time: 0.0271  lr: 0.00028081  max_mem: 7419M
[12/11 23:59:56 d2.utils.events]:  eta: 0:05:01  iter: 9139  total_loss: 2.033  loss_sem_seg: 0.9033  loss_center: 0.5078  loss_offset: 0.4997  time: 0.3521  data_time: 0.0278  lr: 0.00027507  max_mem: 7419M
[12/12 00:00:03 d2.utils.events]:  eta: 0:04:54  iter: 9159  total_loss: 2.177  loss_sem_seg: 0.9881  loss_center: 0.4173  loss_offset: 0.6211  time: 0.3521  data_time: 0.0284  lr: 0.00026931  max_mem: 7419M
[12/12 00:00:10 d2.utils.events]:  eta: 0:04:47  iter: 9179  total_loss: 1.793  loss_sem_seg: 0.7793  loss_center: 0.5221  loss_offset: 0.4459  time: 0.3521  data_time: 0.0279  lr: 0.00026354  max_mem: 7419M
[12/12 00:00:17 d2.utils.events]:  eta: 0:04:40  iter: 9199  total_loss: 2.05  loss_sem_seg: 0.8033  loss_center: 0.4551  loss_offset: 0.5818  time: 0.3521  data_time: 0.0275  lr: 0.00025776  max_mem: 7419M
[12/12 00:00:24 d2.utils.events]:  eta: 0:04:33  iter: 9219  total_loss: 2.251  loss_sem_seg: 1.11  loss_center: 0.62  loss_offset: 0.5021  time: 0.3521  data_time: 0.0263  lr: 0.00025196  max_mem: 7419M
[12/12 00:00:31 d2.utils.events]:  eta: 0:04:26  iter: 9239  total_loss: 2.171  loss_sem_seg: 1.085  loss_center: 0.4149  loss_offset: 0.4954  time: 0.3521  data_time: 0.0264  lr: 0.00024614  max_mem: 7419M
[12/12 00:00:38 d2.utils.events]:  eta: 0:04:19  iter: 9259  total_loss: 2  loss_sem_seg: 0.9179  loss_center: 0.5359  loss_offset: 0.4345  time: 0.3521  data_time: 0.0256  lr: 0.00024031  max_mem: 7419M
[12/12 00:00:45 d2.utils.events]:  eta: 0:04:12  iter: 9279  total_loss: 1.73  loss_sem_seg: 0.7608  loss_center: 0.485  loss_offset: 0.3842  time: 0.3521  data_time: 0.0282  lr: 0.00023447  max_mem: 7419M
[12/12 00:00:52 d2.utils.events]:  eta: 0:04:05  iter: 9299  total_loss: 2.061  loss_sem_seg: 0.9595  loss_center: 0.6071  loss_offset: 0.4478  time: 0.3521  data_time: 0.0278  lr: 0.00022861  max_mem: 7419M
[12/12 00:00:59 d2.utils.events]:  eta: 0:03:58  iter: 9319  total_loss: 1.969  loss_sem_seg: 0.8023  loss_center: 0.5399  loss_offset: 0.4836  time: 0.3521  data_time: 0.0278  lr: 0.00022273  max_mem: 7419M
[12/12 00:01:06 d2.utils.events]:  eta: 0:03:51  iter: 9339  total_loss: 1.879  loss_sem_seg: 0.9238  loss_center: 0.4613  loss_offset: 0.3903  time: 0.3521  data_time: 0.0261  lr: 0.00021683  max_mem: 7419M
[12/12 00:01:13 d2.utils.events]:  eta: 0:03:44  iter: 9359  total_loss: 1.97  loss_sem_seg: 0.8349  loss_center: 0.5761  loss_offset: 0.56  time: 0.3521  data_time: 0.0267  lr: 0.00021092  max_mem: 7419M
[12/12 00:01:20 d2.utils.events]:  eta: 0:03:37  iter: 9379  total_loss: 2.109  loss_sem_seg: 1  loss_center: 0.5043  loss_offset: 0.5304  time: 0.3521  data_time: 0.0270  lr: 0.00020499  max_mem: 7419M
[12/12 00:01:28 d2.utils.events]:  eta: 0:03:30  iter: 9399  total_loss: 1.921  loss_sem_seg: 0.9982  loss_center: 0.4571  loss_offset: 0.4966  time: 0.3521  data_time: 0.0288  lr: 0.00019903  max_mem: 7419M
[12/12 00:01:35 d2.utils.events]:  eta: 0:03:23  iter: 9419  total_loss: 2.063  loss_sem_seg: 1.062  loss_center: 0.4605  loss_offset: 0.5572  time: 0.3521  data_time: 0.0254  lr: 0.00019306  max_mem: 7419M
[12/12 00:01:42 d2.utils.events]:  eta: 0:03:16  iter: 9439  total_loss: 1.933  loss_sem_seg: 0.8049  loss_center: 0.5249  loss_offset: 0.4775  time: 0.3521  data_time: 0.0281  lr: 0.00018707  max_mem: 7419M
[12/12 00:01:49 d2.utils.events]:  eta: 0:03:09  iter: 9459  total_loss: 2.038  loss_sem_seg: 0.8509  loss_center: 0.6106  loss_offset: 0.5242  time: 0.3521  data_time: 0.0255  lr: 0.00018106  max_mem: 7419M
[12/12 00:01:56 d2.utils.events]:  eta: 0:03:02  iter: 9479  total_loss: 1.82  loss_sem_seg: 0.8655  loss_center: 0.5589  loss_offset: 0.4509  time: 0.3521  data_time: 0.0266  lr: 0.00017502  max_mem: 7419M
[12/12 00:02:03 d2.utils.events]:  eta: 0:02:55  iter: 9499  total_loss: 1.718  loss_sem_seg: 0.8985  loss_center: 0.3904  loss_offset: 0.4559  time: 0.3521  data_time: 0.0272  lr: 0.00016896  max_mem: 7419M
[12/12 00:02:10 d2.utils.events]:  eta: 0:02:48  iter: 9519  total_loss: 1.984  loss_sem_seg: 0.9459  loss_center: 0.4515  loss_offset: 0.4839  time: 0.3521  data_time: 0.0270  lr: 0.00016288  max_mem: 7419M
[12/12 00:02:17 d2.utils.events]:  eta: 0:02:41  iter: 9539  total_loss: 1.91  loss_sem_seg: 0.7993  loss_center: 0.5486  loss_offset: 0.4088  time: 0.3521  data_time: 0.0250  lr: 0.00015677  max_mem: 7419M
[12/12 00:02:24 d2.utils.events]:  eta: 0:02:34  iter: 9559  total_loss: 1.781  loss_sem_seg: 0.7695  loss_center: 0.5438  loss_offset: 0.4714  time: 0.3521  data_time: 0.0270  lr: 0.00015064  max_mem: 7419M
[12/12 00:02:31 d2.utils.events]:  eta: 0:02:27  iter: 9579  total_loss: 2.013  loss_sem_seg: 0.9616  loss_center: 0.4814  loss_offset: 0.4339  time: 0.3521  data_time: 0.0266  lr: 0.00014448  max_mem: 7419M
[12/12 00:02:38 d2.utils.events]:  eta: 0:02:20  iter: 9599  total_loss: 1.845  loss_sem_seg: 0.8362  loss_center: 0.4243  loss_offset: 0.5481  time: 0.3520  data_time: 0.0269  lr: 0.00013828  max_mem: 7419M
[12/12 00:02:45 d2.utils.events]:  eta: 0:02:13  iter: 9619  total_loss: 1.86  loss_sem_seg: 0.8086  loss_center: 0.5391  loss_offset: 0.502  time: 0.3520  data_time: 0.0269  lr: 0.00013206  max_mem: 7419M
[12/12 00:02:52 d2.utils.events]:  eta: 0:02:06  iter: 9639  total_loss: 1.88  loss_sem_seg: 0.8258  loss_center: 0.4529  loss_offset: 0.5113  time: 0.3520  data_time: 0.0273  lr: 0.0001258  max_mem: 7419M
[12/12 00:02:59 d2.utils.events]:  eta: 0:01:59  iter: 9659  total_loss: 1.727  loss_sem_seg: 0.8421  loss_center: 0.4633  loss_offset: 0.4922  time: 0.3520  data_time: 0.0267  lr: 0.00011951  max_mem: 7419M
[12/12 00:03:06 d2.utils.events]:  eta: 0:01:52  iter: 9679  total_loss: 1.871  loss_sem_seg: 0.943  loss_center: 0.3761  loss_offset: 0.5205  time: 0.3520  data_time: 0.0270  lr: 0.00011319  max_mem: 7419M
[12/12 00:03:13 d2.utils.events]:  eta: 0:01:45  iter: 9699  total_loss: 2.414  loss_sem_seg: 1.042  loss_center: 0.5307  loss_offset: 0.6558  time: 0.3520  data_time: 0.0286  lr: 0.00010682  max_mem: 7419M
[12/12 00:03:20 d2.utils.events]:  eta: 0:01:38  iter: 9719  total_loss: 2.009  loss_sem_seg: 0.9273  loss_center: 0.5398  loss_offset: 0.4097  time: 0.3520  data_time: 0.0276  lr: 0.00010041  max_mem: 7419M
[12/12 00:03:27 d2.utils.events]:  eta: 0:01:31  iter: 9739  total_loss: 1.71  loss_sem_seg: 0.7473  loss_center: 0.4728  loss_offset: 0.4472  time: 0.3520  data_time: 0.0266  lr: 9.3954e-05  max_mem: 7419M
[12/12 00:03:34 d2.utils.events]:  eta: 0:01:24  iter: 9759  total_loss: 2.051  loss_sem_seg: 0.9846  loss_center: 0.5924  loss_offset: 0.465  time: 0.3520  data_time: 0.0265  lr: 8.7449e-05  max_mem: 7419M
[12/12 00:03:41 d2.utils.events]:  eta: 0:01:17  iter: 9779  total_loss: 1.874  loss_sem_seg: 0.9153  loss_center: 0.6118  loss_offset: 0.4033  time: 0.3520  data_time: 0.0267  lr: 8.089e-05  max_mem: 7419M
[12/12 00:03:48 d2.utils.events]:  eta: 0:01:10  iter: 9799  total_loss: 1.931  loss_sem_seg: 0.8625  loss_center: 0.4285  loss_offset: 0.5342  time: 0.3520  data_time: 0.0282  lr: 7.4271e-05  max_mem: 7419M
[12/12 00:03:55 d2.utils.events]:  eta: 0:01:03  iter: 9819  total_loss: 2.109  loss_sem_seg: 0.9765  loss_center: 0.4941  loss_offset: 0.5623  time: 0.3520  data_time: 0.0281  lr: 6.7585e-05  max_mem: 7419M
[12/12 00:04:02 d2.utils.events]:  eta: 0:00:56  iter: 9839  total_loss: 2.097  loss_sem_seg: 0.924  loss_center: 0.5168  loss_offset: 0.5888  time: 0.3520  data_time: 0.0258  lr: 6.0825e-05  max_mem: 7419M
[12/12 00:04:09 d2.utils.events]:  eta: 0:00:49  iter: 9859  total_loss: 1.975  loss_sem_seg: 0.9232  loss_center: 0.5411  loss_offset: 0.4597  time: 0.3520  data_time: 0.0286  lr: 5.3981e-05  max_mem: 7419M
[12/12 00:04:16 d2.utils.events]:  eta: 0:00:42  iter: 9879  total_loss: 1.879  loss_sem_seg: 0.8762  loss_center: 0.4333  loss_offset: 0.5102  time: 0.3520  data_time: 0.0268  lr: 4.7038e-05  max_mem: 7419M
[12/12 00:04:23 d2.utils.events]:  eta: 0:00:35  iter: 9899  total_loss: 1.981  loss_sem_seg: 0.8475  loss_center: 0.5336  loss_offset: 0.4477  time: 0.3520  data_time: 0.0274  lr: 3.9979e-05  max_mem: 7419M
[12/12 00:04:30 d2.utils.events]:  eta: 0:00:28  iter: 9919  total_loss: 2.104  loss_sem_seg: 0.9922  loss_center: 0.5272  loss_offset: 0.4631  time: 0.3520  data_time: 0.0271  lr: 3.2778e-05  max_mem: 7419M
[12/12 00:04:37 d2.utils.events]:  eta: 0:00:21  iter: 9939  total_loss: 2.02  loss_sem_seg: 0.9582  loss_center: 0.4627  loss_offset: 0.5249  time: 0.3520  data_time: 0.0263  lr: 2.5394e-05  max_mem: 7419M
[12/12 00:04:44 d2.utils.events]:  eta: 0:00:14  iter: 9959  total_loss: 2.152  loss_sem_seg: 0.9416  loss_center: 0.44  loss_offset: 0.5389  time: 0.3520  data_time: 0.0268  lr: 1.776e-05  max_mem: 7419M
[12/12 00:04:51 d2.utils.events]:  eta: 0:00:07  iter: 9979  total_loss: 1.976  loss_sem_seg: 0.8319  loss_center: 0.5433  loss_offset: 0.5849  time: 0.3520  data_time: 0.0278  lr: 9.7261e-06  max_mem: 7419M
[12/12 00:04:58 fvcore.common.checkpoint]: Saving checkpoint to ./output/model_0009999.pth
[12/12 00:04:59 fvcore.common.checkpoint]: Saving checkpoint to ./output/model_final.pth
[12/12 00:05:00 d2.utils.events]:  eta: 0:00:00  iter: 9999  total_loss: 2.094  loss_sem_seg: 1.009  loss_center: 0.5725  loss_offset: 0.5038  time: 0.3520  data_time: 0.0267  lr: 6.2797e-07  max_mem: 7419M
[12/12 00:05:01 d2.engine.hooks]: Overall training speed: 9998 iterations in 0:58:39 (0.3520 s / it)
[12/12 00:05:01 d2.engine.hooks]: Total training time: 0:58:47 (0:00:07 on hooks)
[12/12 00:05:01 d2.data.dataset_mapper]: [DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(640, 640), max_size=640, sample_style='choice')]
[12/12 00:05:01 d2.data.common]: Serializing the dataset using: <class 'detectron2.data.common.NumpySerializedList'>
[12/12 00:05:01 d2.data.common]: Serializing 5000 elements to byte tensors and concatenating them all ...
[12/12 00:05:01 d2.data.common]: Serialized dataset takes 3.40 MiB
/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:481: UserWarning: This DataLoader will create 10 worker processes in total. Our suggested max number of worker in current system is 8, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.
  cpuset_checked))
[12/12 00:05:02 d2.evaluation.evaluator]: Start inference on 5000 batches
/usr/local/lib/python3.7/dist-packages/torch/functional.py:445: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at  ../aten/src/ATen/native/TensorShape.cpp:2157.)
  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]
[12/12 00:05:04 d2.evaluation.evaluator]: Inference done 11/5000. Dataloading: 0.0008 s/iter. Inference: 0.0651 s/iter. Eval: 0.0382 s/iter. Total: 0.1040 s/iter. ETA=0:08:38
[12/12 00:05:09 d2.evaluation.evaluator]: Inference done 64/5000. Dataloading: 0.0011 s/iter. Inference: 0.0623 s/iter. Eval: 0.0324 s/iter. Total: 0.0958 s/iter. ETA=0:07:52
[12/12 00:05:14 d2.evaluation.evaluator]: Inference done 114/5000. Dataloading: 0.0012 s/iter. Inference: 0.0628 s/iter. Eval: 0.0344 s/iter. Total: 0.0984 s/iter. ETA=0:08:00
[12/12 00:05:19 d2.evaluation.evaluator]: Inference done 163/5000. Dataloading: 0.0012 s/iter. Inference: 0.0636 s/iter. Eval: 0.0353 s/iter. Total: 0.1001 s/iter. ETA=0:08:04
[12/12 00:05:24 d2.evaluation.evaluator]: Inference done 215/5000. Dataloading: 0.0012 s/iter. Inference: 0.0632 s/iter. Eval: 0.0349 s/iter. Total: 0.0994 s/iter. ETA=0:07:55
[12/12 00:05:29 d2.evaluation.evaluator]: Inference done 266/5000. Dataloading: 0.0012 s/iter. Inference: 0.0631 s/iter. Eval: 0.0348 s/iter. Total: 0.0991 s/iter. ETA=0:07:49
[12/12 00:05:34 d2.evaluation.evaluator]: Inference done 313/5000. Dataloading: 0.0012 s/iter. Inference: 0.0642 s/iter. Eval: 0.0348 s/iter. Total: 0.1004 s/iter. ETA=0:07:50
[12/12 00:05:39 d2.evaluation.evaluator]: Inference done 363/5000. Dataloading: 0.0012 s/iter. Inference: 0.0643 s/iter. Eval: 0.0349 s/iter. Total: 0.1005 s/iter. ETA=0:07:45
[12/12 00:05:44 d2.evaluation.evaluator]: Inference done 416/5000. Dataloading: 0.0012 s/iter. Inference: 0.0639 s/iter. Eval: 0.0346 s/iter. Total: 0.0998 s/iter. ETA=0:07:37
[12/12 00:05:49 d2.evaluation.evaluator]: Inference done 470/5000. Dataloading: 0.0012 s/iter. Inference: 0.0634 s/iter. Eval: 0.0342 s/iter. Total: 0.0990 s/iter. ETA=0:07:28
[12/12 00:05:54 d2.evaluation.evaluator]: Inference done 521/5000. Dataloading: 0.0013 s/iter. Inference: 0.0634 s/iter. Eval: 0.0343 s/iter. Total: 0.0990 s/iter. ETA=0:07:23
[12/12 00:05:59 d2.evaluation.evaluator]: Inference done 571/5000. Dataloading: 0.0013 s/iter. Inference: 0.0635 s/iter. Eval: 0.0344 s/iter. Total: 0.0992 s/iter. ETA=0:07:19
[12/12 00:06:04 d2.evaluation.evaluator]: Inference done 621/5000. Dataloading: 0.0013 s/iter. Inference: 0.0636 s/iter. Eval: 0.0345 s/iter. Total: 0.0994 s/iter. ETA=0:07:15
[12/12 00:06:10 d2.evaluation.evaluator]: Inference done 668/5000. Dataloading: 0.0013 s/iter. Inference: 0.0639 s/iter. Eval: 0.0348 s/iter. Total: 0.1000 s/iter. ETA=0:07:13
[12/12 00:06:15 d2.evaluation.evaluator]: Inference done 719/5000. Dataloading: 0.0013 s/iter. Inference: 0.0638 s/iter. Eval: 0.0348 s/iter. Total: 0.0999 s/iter. ETA=0:07:07
[12/12 00:06:20 d2.evaluation.evaluator]: Inference done 772/5000. Dataloading: 0.0013 s/iter. Inference: 0.0636 s/iter. Eval: 0.0347 s/iter. Total: 0.0995 s/iter. ETA=0:07:00
[12/12 00:06:25 d2.evaluation.evaluator]: Inference done 825/5000. Dataloading: 0.0013 s/iter. Inference: 0.0634 s/iter. Eval: 0.0346 s/iter. Total: 0.0993 s/iter. ETA=0:06:54
[12/12 00:06:30 d2.evaluation.evaluator]: Inference done 878/5000. Dataloading: 0.0013 s/iter. Inference: 0.0633 s/iter. Eval: 0.0344 s/iter. Total: 0.0991 s/iter. ETA=0:06:48
[12/12 00:06:35 d2.evaluation.evaluator]: Inference done 932/5000. Dataloading: 0.0013 s/iter. Inference: 0.0631 s/iter. Eval: 0.0343 s/iter. Total: 0.0988 s/iter. ETA=0:06:41
[12/12 00:06:40 d2.evaluation.evaluator]: Inference done 984/5000. Dataloading: 0.0013 s/iter. Inference: 0.0631 s/iter. Eval: 0.0343 s/iter. Total: 0.0987 s/iter. ETA=0:06:36
[12/12 00:06:45 d2.evaluation.evaluator]: Inference done 1035/5000. Dataloading: 0.0013 s/iter. Inference: 0.0631 s/iter. Eval: 0.0343 s/iter. Total: 0.0987 s/iter. ETA=0:06:31
[12/12 00:06:50 d2.evaluation.evaluator]: Inference done 1086/5000. Dataloading: 0.0013 s/iter. Inference: 0.0631 s/iter. Eval: 0.0343 s/iter. Total: 0.0987 s/iter. ETA=0:06:26
[12/12 00:06:55 d2.evaluation.evaluator]: Inference done 1138/5000. Dataloading: 0.0013 s/iter. Inference: 0.0631 s/iter. Eval: 0.0342 s/iter. Total: 0.0986 s/iter. ETA=0:06:20
[12/12 00:07:00 d2.evaluation.evaluator]: Inference done 1189/5000. Dataloading: 0.0013 s/iter. Inference: 0.0631 s/iter. Eval: 0.0342 s/iter. Total: 0.0986 s/iter. ETA=0:06:15
[12/12 00:07:05 d2.evaluation.evaluator]: Inference done 1237/5000. Dataloading: 0.0013 s/iter. Inference: 0.0633 s/iter. Eval: 0.0343 s/iter. Total: 0.0989 s/iter. ETA=0:06:12
[12/12 00:07:10 d2.evaluation.evaluator]: Inference done 1287/5000. Dataloading: 0.0013 s/iter. Inference: 0.0633 s/iter. Eval: 0.0343 s/iter. Total: 0.0990 s/iter. ETA=0:06:07
[12/12 00:07:15 d2.evaluation.evaluator]: Inference done 1338/5000. Dataloading: 0.0013 s/iter. Inference: 0.0633 s/iter. Eval: 0.0343 s/iter. Total: 0.0990 s/iter. ETA=0:06:02
[12/12 00:07:20 d2.evaluation.evaluator]: Inference done 1389/5000. Dataloading: 0.0013 s/iter. Inference: 0.0633 s/iter. Eval: 0.0343 s/iter. Total: 0.0990 s/iter. ETA=0:05:57
[12/12 00:07:25 d2.evaluation.evaluator]: Inference done 1440/5000. Dataloading: 0.0013 s/iter. Inference: 0.0633 s/iter. Eval: 0.0343 s/iter. Total: 0.0990 s/iter. ETA=0:05:52
[12/12 00:07:30 d2.evaluation.evaluator]: Inference done 1492/5000. Dataloading: 0.0013 s/iter. Inference: 0.0632 s/iter. Eval: 0.0344 s/iter. Total: 0.0989 s/iter. ETA=0:05:47
[12/12 00:07:35 d2.evaluation.evaluator]: Inference done 1542/5000. Dataloading: 0.0013 s/iter. Inference: 0.0632 s/iter. Eval: 0.0344 s/iter. Total: 0.0990 s/iter. ETA=0:05:42
[12/12 00:07:40 d2.evaluation.evaluator]: Inference done 1591/5000. Dataloading: 0.0013 s/iter. Inference: 0.0633 s/iter. Eval: 0.0345 s/iter. Total: 0.0991 s/iter. ETA=0:05:37
[12/12 00:07:46 d2.evaluation.evaluator]: Inference done 1643/5000. Dataloading: 0.0013 s/iter. Inference: 0.0633 s/iter. Eval: 0.0345 s/iter. Total: 0.0991 s/iter. ETA=0:05:32
[12/12 00:07:51 d2.evaluation.evaluator]: Inference done 1693/5000. Dataloading: 0.0013 s/iter. Inference: 0.0633 s/iter. Eval: 0.0345 s/iter. Total: 0.0991 s/iter. ETA=0:05:27
[12/12 00:07:56 d2.evaluation.evaluator]: Inference done 1745/5000. Dataloading: 0.0013 s/iter. Inference: 0.0633 s/iter. Eval: 0.0345 s/iter. Total: 0.0991 s/iter. ETA=0:05:22
[12/12 00:08:01 d2.evaluation.evaluator]: Inference done 1798/5000. Dataloading: 0.0013 s/iter. Inference: 0.0632 s/iter. Eval: 0.0344 s/iter. Total: 0.0990 s/iter. ETA=0:05:16
[12/12 00:08:06 d2.evaluation.evaluator]: Inference done 1848/5000. Dataloading: 0.0013 s/iter. Inference: 0.0632 s/iter. Eval: 0.0345 s/iter. Total: 0.0990 s/iter. ETA=0:05:12
[12/12 00:08:11 d2.evaluation.evaluator]: Inference done 1898/5000. Dataloading: 0.0013 s/iter. Inference: 0.0632 s/iter. Eval: 0.0345 s/iter. Total: 0.0991 s/iter. ETA=0:05:07
[12/12 00:08:16 d2.evaluation.evaluator]: Inference done 1952/5000. Dataloading: 0.0013 s/iter. Inference: 0.0631 s/iter. Eval: 0.0344 s/iter. Total: 0.0989 s/iter. ETA=0:05:01
[12/12 00:08:21 d2.evaluation.evaluator]: Inference done 2002/5000. Dataloading: 0.0013 s/iter. Inference: 0.0632 s/iter. Eval: 0.0344 s/iter. Total: 0.0990 s/iter. ETA=0:04:56
[12/12 00:08:26 d2.evaluation.evaluator]: Inference done 2053/5000. Dataloading: 0.0013 s/iter. Inference: 0.0632 s/iter. Eval: 0.0345 s/iter. Total: 0.0990 s/iter. ETA=0:04:51
[12/12 00:08:31 d2.evaluation.evaluator]: Inference done 2106/5000. Dataloading: 0.0013 s/iter. Inference: 0.0631 s/iter. Eval: 0.0344 s/iter. Total: 0.0989 s/iter. ETA=0:04:46
[12/12 00:08:36 d2.evaluation.evaluator]: Inference done 2158/5000. Dataloading: 0.0013 s/iter. Inference: 0.0631 s/iter. Eval: 0.0344 s/iter. Total: 0.0989 s/iter. ETA=0:04:40
[12/12 00:08:41 d2.evaluation.evaluator]: Inference done 2209/5000. Dataloading: 0.0013 s/iter. Inference: 0.0631 s/iter. Eval: 0.0344 s/iter. Total: 0.0989 s/iter. ETA=0:04:35
[12/12 00:08:46 d2.evaluation.evaluator]: Inference done 2262/5000. Dataloading: 0.0013 s/iter. Inference: 0.0631 s/iter. Eval: 0.0344 s/iter. Total: 0.0988 s/iter. ETA=0:04:30
[12/12 00:08:51 d2.evaluation.evaluator]: Inference done 2315/5000. Dataloading: 0.0013 s/iter. Inference: 0.0630 s/iter. Eval: 0.0343 s/iter. Total: 0.0987 s/iter. ETA=0:04:24
[12/12 00:08:56 d2.evaluation.evaluator]: Inference done 2370/5000. Dataloading: 0.0013 s/iter. Inference: 0.0629 s/iter. Eval: 0.0343 s/iter. Total: 0.0985 s/iter. ETA=0:04:19
[12/12 00:09:01 d2.evaluation.evaluator]: Inference done 2419/5000. Dataloading: 0.0013 s/iter. Inference: 0.0630 s/iter. Eval: 0.0343 s/iter. Total: 0.0986 s/iter. ETA=0:04:14
[12/12 00:09:07 d2.evaluation.evaluator]: Inference done 2472/5000. Dataloading: 0.0013 s/iter. Inference: 0.0630 s/iter. Eval: 0.0343 s/iter. Total: 0.0986 s/iter. ETA=0:04:09
[12/12 00:09:12 d2.evaluation.evaluator]: Inference done 2523/5000. Dataloading: 0.0013 s/iter. Inference: 0.0630 s/iter. Eval: 0.0343 s/iter. Total: 0.0986 s/iter. ETA=0:04:04
[12/12 00:09:17 d2.evaluation.evaluator]: Inference done 2574/5000. Dataloading: 0.0013 s/iter. Inference: 0.0630 s/iter. Eval: 0.0343 s/iter. Total: 0.0986 s/iter. ETA=0:03:59
[12/12 00:09:22 d2.evaluation.evaluator]: Inference done 2625/5000. Dataloading: 0.0013 s/iter. Inference: 0.0630 s/iter. Eval: 0.0343 s/iter. Total: 0.0986 s/iter. ETA=0:03:54
[12/12 00:09:27 d2.evaluation.evaluator]: Inference done 2677/5000. Dataloading: 0.0013 s/iter. Inference: 0.0630 s/iter. Eval: 0.0343 s/iter. Total: 0.0986 s/iter. ETA=0:03:49
[12/12 00:09:32 d2.evaluation.evaluator]: Inference done 2731/5000. Dataloading: 0.0013 s/iter. Inference: 0.0629 s/iter. Eval: 0.0342 s/iter. Total: 0.0985 s/iter. ETA=0:03:43
[12/12 00:09:37 d2.evaluation.evaluator]: Inference done 2783/5000. Dataloading: 0.0013 s/iter. Inference: 0.0629 s/iter. Eval: 0.0342 s/iter. Total: 0.0985 s/iter. ETA=0:03:38
[12/12 00:09:42 d2.evaluation.evaluator]: Inference done 2835/5000. Dataloading: 0.0013 s/iter. Inference: 0.0629 s/iter. Eval: 0.0342 s/iter. Total: 0.0985 s/iter. ETA=0:03:33
[12/12 00:09:47 d2.evaluation.evaluator]: Inference done 2887/5000. Dataloading: 0.0013 s/iter. Inference: 0.0629 s/iter. Eval: 0.0342 s/iter. Total: 0.0984 s/iter. ETA=0:03:28
[12/12 00:09:52 d2.evaluation.evaluator]: Inference done 2938/5000. Dataloading: 0.0013 s/iter. Inference: 0.0629 s/iter. Eval: 0.0342 s/iter. Total: 0.0985 s/iter. ETA=0:03:23
[12/12 00:09:57 d2.evaluation.evaluator]: Inference done 2990/5000. Dataloading: 0.0013 s/iter. Inference: 0.0629 s/iter. Eval: 0.0342 s/iter. Total: 0.0984 s/iter. ETA=0:03:17
[12/12 00:10:02 d2.evaluation.evaluator]: Inference done 3045/5000. Dataloading: 0.0013 s/iter. Inference: 0.0628 s/iter. Eval: 0.0342 s/iter. Total: 0.0983 s/iter. ETA=0:03:12
[12/12 00:10:07 d2.evaluation.evaluator]: Inference done 3099/5000. Dataloading: 0.0013 s/iter. Inference: 0.0628 s/iter. Eval: 0.0341 s/iter. Total: 0.0982 s/iter. ETA=0:03:06
[12/12 00:10:12 d2.evaluation.evaluator]: Inference done 3149/5000. Dataloading: 0.0013 s/iter. Inference: 0.0628 s/iter. Eval: 0.0342 s/iter. Total: 0.0983 s/iter. ETA=0:03:01
[12/12 00:10:17 d2.evaluation.evaluator]: Inference done 3200/5000. Dataloading: 0.0013 s/iter. Inference: 0.0628 s/iter. Eval: 0.0342 s/iter. Total: 0.0983 s/iter. ETA=0:02:56
[12/12 00:10:22 d2.evaluation.evaluator]: Inference done 3250/5000. Dataloading: 0.0013 s/iter. Inference: 0.0628 s/iter. Eval: 0.0342 s/iter. Total: 0.0983 s/iter. ETA=0:02:52
[12/12 00:10:27 d2.evaluation.evaluator]: Inference done 3299/5000. Dataloading: 0.0013 s/iter. Inference: 0.0628 s/iter. Eval: 0.0342 s/iter. Total: 0.0984 s/iter. ETA=0:02:47
[12/12 00:10:32 d2.evaluation.evaluator]: Inference done 3349/5000. Dataloading: 0.0013 s/iter. Inference: 0.0628 s/iter. Eval: 0.0342 s/iter. Total: 0.0984 s/iter. ETA=0:02:42
[12/12 00:10:37 d2.evaluation.evaluator]: Inference done 3399/5000. Dataloading: 0.0013 s/iter. Inference: 0.0629 s/iter. Eval: 0.0343 s/iter. Total: 0.0984 s/iter. ETA=0:02:37
[12/12 00:10:42 d2.evaluation.evaluator]: Inference done 3448/5000. Dataloading: 0.0013 s/iter. Inference: 0.0629 s/iter. Eval: 0.0343 s/iter. Total: 0.0985 s/iter. ETA=0:02:32
[12/12 00:10:47 d2.evaluation.evaluator]: Inference done 3502/5000. Dataloading: 0.0013 s/iter. Inference: 0.0629 s/iter. Eval: 0.0343 s/iter. Total: 0.0984 s/iter. ETA=0:02:27
[12/12 00:10:52 d2.evaluation.evaluator]: Inference done 3552/5000. Dataloading: 0.0013 s/iter. Inference: 0.0629 s/iter. Eval: 0.0343 s/iter. Total: 0.0985 s/iter. ETA=0:02:22
[12/12 00:10:57 d2.evaluation.evaluator]: Inference done 3602/5000. Dataloading: 0.0013 s/iter. Inference: 0.0629 s/iter. Eval: 0.0343 s/iter. Total: 0.0985 s/iter. ETA=0:02:17
[12/12 00:11:03 d2.evaluation.evaluator]: Inference done 3655/5000. Dataloading: 0.0013 s/iter. Inference: 0.0629 s/iter. Eval: 0.0343 s/iter. Total: 0.0984 s/iter. ETA=0:02:12
[12/12 00:11:08 d2.evaluation.evaluator]: Inference done 3706/5000. Dataloading: 0.0013 s/iter. Inference: 0.0629 s/iter. Eval: 0.0343 s/iter. Total: 0.0985 s/iter. ETA=0:02:07
[12/12 00:11:13 d2.evaluation.evaluator]: Inference done 3758/5000. Dataloading: 0.0013 s/iter. Inference: 0.0629 s/iter. Eval: 0.0342 s/iter. Total: 0.0984 s/iter. ETA=0:02:02
[12/12 00:11:18 d2.evaluation.evaluator]: Inference done 3808/5000. Dataloading: 0.0013 s/iter. Inference: 0.0629 s/iter. Eval: 0.0343 s/iter. Total: 0.0985 s/iter. ETA=0:01:57
[12/12 00:11:23 d2.evaluation.evaluator]: Inference done 3863/5000. Dataloading: 0.0013 s/iter. Inference: 0.0628 s/iter. Eval: 0.0342 s/iter. Total: 0.0984 s/iter. ETA=0:01:51
[12/12 00:11:28 d2.evaluation.evaluator]: Inference done 3916/5000. Dataloading: 0.0013 s/iter. Inference: 0.0628 s/iter. Eval: 0.0342 s/iter. Total: 0.0983 s/iter. ETA=0:01:46
[12/12 00:11:33 d2.evaluation.evaluator]: Inference done 3969/5000. Dataloading: 0.0013 s/iter. Inference: 0.0628 s/iter. Eval: 0.0342 s/iter. Total: 0.0983 s/iter. ETA=0:01:41
[12/12 00:11:38 d2.evaluation.evaluator]: Inference done 4021/5000. Dataloading: 0.0013 s/iter. Inference: 0.0628 s/iter. Eval: 0.0342 s/iter. Total: 0.0983 s/iter. ETA=0:01:36
[12/12 00:11:43 d2.evaluation.evaluator]: Inference done 4072/5000. Dataloading: 0.0013 s/iter. Inference: 0.0628 s/iter. Eval: 0.0342 s/iter. Total: 0.0983 s/iter. ETA=0:01:31
[12/12 00:11:48 d2.evaluation.evaluator]: Inference done 4125/5000. Dataloading: 0.0013 s/iter. Inference: 0.0628 s/iter. Eval: 0.0342 s/iter. Total: 0.0983 s/iter. ETA=0:01:26
[12/12 00:11:53 d2.evaluation.evaluator]: Inference done 4174/5000. Dataloading: 0.0013 s/iter. Inference: 0.0628 s/iter. Eval: 0.0342 s/iter. Total: 0.0984 s/iter. ETA=0:01:21
[12/12 00:11:58 d2.evaluation.evaluator]: Inference done 4226/5000. Dataloading: 0.0013 s/iter. Inference: 0.0628 s/iter. Eval: 0.0342 s/iter. Total: 0.0983 s/iter. ETA=0:01:16
[12/12 00:12:03 d2.evaluation.evaluator]: Inference done 4278/5000. Dataloading: 0.0013 s/iter. Inference: 0.0628 s/iter. Eval: 0.0342 s/iter. Total: 0.0983 s/iter. ETA=0:01:11
[12/12 00:12:08 d2.evaluation.evaluator]: Inference done 4329/5000. Dataloading: 0.0013 s/iter. Inference: 0.0628 s/iter. Eval: 0.0342 s/iter. Total: 0.0983 s/iter. ETA=0:01:05
[12/12 00:12:13 d2.evaluation.evaluator]: Inference done 4383/5000. Dataloading: 0.0013 s/iter. Inference: 0.0627 s/iter. Eval: 0.0342 s/iter. Total: 0.0983 s/iter. ETA=0:01:00
[12/12 00:12:19 d2.evaluation.evaluator]: Inference done 4435/5000. Dataloading: 0.0013 s/iter. Inference: 0.0627 s/iter. Eval: 0.0342 s/iter. Total: 0.0983 s/iter. ETA=0:00:55
[12/12 00:12:24 d2.evaluation.evaluator]: Inference done 4487/5000. Dataloading: 0.0013 s/iter. Inference: 0.0627 s/iter. Eval: 0.0342 s/iter. Total: 0.0982 s/iter. ETA=0:00:50
[12/12 00:12:29 d2.evaluation.evaluator]: Inference done 4540/5000. Dataloading: 0.0013 s/iter. Inference: 0.0627 s/iter. Eval: 0.0342 s/iter. Total: 0.0982 s/iter. ETA=0:00:45
[12/12 00:12:34 d2.evaluation.evaluator]: Inference done 4590/5000. Dataloading: 0.0013 s/iter. Inference: 0.0627 s/iter. Eval: 0.0342 s/iter. Total: 0.0982 s/iter. ETA=0:00:40
[12/12 00:12:39 d2.evaluation.evaluator]: Inference done 4642/5000. Dataloading: 0.0013 s/iter. Inference: 0.0627 s/iter. Eval: 0.0342 s/iter. Total: 0.0982 s/iter. ETA=0:00:35
[12/12 00:12:44 d2.evaluation.evaluator]: Inference done 4690/5000. Dataloading: 0.0013 s/iter. Inference: 0.0628 s/iter. Eval: 0.0342 s/iter. Total: 0.0983 s/iter. ETA=0:00:30
[12/12 00:12:49 d2.evaluation.evaluator]: Inference done 4742/5000. Dataloading: 0.0013 s/iter. Inference: 0.0628 s/iter. Eval: 0.0342 s/iter. Total: 0.0983 s/iter. ETA=0:00:25
[12/12 00:12:54 d2.evaluation.evaluator]: Inference done 4794/5000. Dataloading: 0.0013 s/iter. Inference: 0.0627 s/iter. Eval: 0.0342 s/iter. Total: 0.0983 s/iter. ETA=0:00:20
[12/12 00:12:59 d2.evaluation.evaluator]: Inference done 4843/5000. Dataloading: 0.0013 s/iter. Inference: 0.0628 s/iter. Eval: 0.0342 s/iter. Total: 0.0983 s/iter. ETA=0:00:15
[12/12 00:13:04 d2.evaluation.evaluator]: Inference done 4897/5000. Dataloading: 0.0013 s/iter. Inference: 0.0627 s/iter. Eval: 0.0342 s/iter. Total: 0.0983 s/iter. ETA=0:00:10
[12/12 00:13:09 d2.evaluation.evaluator]: Inference done 4946/5000. Dataloading: 0.0013 s/iter. Inference: 0.0628 s/iter. Eval: 0.0342 s/iter. Total: 0.0983 s/iter. ETA=0:00:05
[12/12 00:13:14 d2.evaluation.evaluator]: Inference done 4998/5000. Dataloading: 0.0013 s/iter. Inference: 0.0627 s/iter. Eval: 0.0342 s/iter. Total: 0.0983 s/iter. ETA=0:00:00
[12/12 00:13:14 d2.evaluation.evaluator]: Total inference time: 0:08:11.149205 (0.098328 s / iter per device, on 1 devices)
[12/12 00:13:14 d2.evaluation.evaluator]: Total inference pure compute time: 0:05:13 (0.062747 s / iter per device, on 1 devices)
[12/12 00:13:14 d2.evaluation.panoptic_evaluation]: Writing all panoptic predictions to /tmp/panoptic_eval0i1bw1zj ...
[12/12 00:13:38 d2.evaluation.panoptic_evaluation]: Panoptic Evaluation Results:
|        |   PQ   |   SQ   |   RQ   |  #categories  |
|:------:|:------:|:------:|:------:|:-------------:|
|  All   | 18.185 | 63.080 | 23.757 |      133      |
| Things | 18.409 | 66.104 | 24.119 |      80       |
| Stuff  | 17.847 | 58.515 | 23.212 |      53       |
[12/12 00:13:39 d2.evaluation.coco_evaluation]: Preparing results for COCO format ...
[12/12 00:13:39 d2.evaluation.coco_evaluation]: Saving results to ./output/inference/coco_instances_results.json
[12/12 00:13:39 d2.evaluation.coco_evaluation]: Evaluating predictions with unofficial COCO API...
Loading and preparing results...
DONE (t=0.05s)
creating index...
index created!
[12/12 00:13:39 d2.evaluation.fast_eval_api]: Evaluate annotation type *bbox*
[12/12 00:13:47 d2.evaluation.fast_eval_api]: COCOeval_opt.evaluate() finished in 8.15 seconds.
[12/12 00:13:47 d2.evaluation.fast_eval_api]: Accumulating evaluation results...
[12/12 00:13:48 d2.evaluation.fast_eval_api]: COCOeval_opt.accumulate() finished in 0.66 seconds.
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.071
 Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.139
 Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.065
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.013
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.067
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.116
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.092
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.126
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.127
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.016
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.106
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.211
[12/12 00:13:48 d2.evaluation.coco_evaluation]: Evaluation results for bbox: 
|  AP   |  AP50  |  AP75  |  APs  |  APm  |  APl   |
|:-----:|:------:|:------:|:-----:|:-----:|:------:|
| 7.148 | 13.886 | 6.479  | 1.340 | 6.657 | 11.581 |
[12/12 00:13:48 d2.evaluation.coco_evaluation]: Per-category bbox AP: 
| category      | AP     | category     | AP     | category       | AP     |
|:--------------|:-------|:-------------|:-------|:---------------|:-------|
| person        | 15.735 | bicycle      | 3.562  | car            | 7.336  |
| motorcycle    | 8.650  | airplane     | 24.855 | bus            | 30.413 |
| train         | 26.900 | truck        | 4.701  | boat           | 2.455  |
| traffic light | 2.392  | fire hydrant | 28.965 | stop sign      | 27.297 |
| parking meter | 2.312  | bench        | 3.688  | bird           | 6.401  |
| cat           | 12.597 | dog          | 15.561 | horse          | 14.324 |
| sheep         | 14.948 | cow          | 5.662  | elephant       | 22.693 |
| bear          | 25.249 | zebra        | 32.022 | giraffe        | 30.401 |
| backpack      | 0.000  | umbrella     | 7.893  | handbag        | 0.099  |
| tie           | 0.000  | suitcase     | 2.999  | frisbee        | 12.801 |
| skis          | 1.037  | snowboard    | 1.188  | sports ball    | 3.860  |
| kite          | 8.657  | baseball bat | 0.700  | baseball glove | 2.999  |
| skateboard    | 4.768  | surfboard    | 3.641  | tennis racket  | 8.220  |
| bottle        | 1.291  | wine glass   | 0.079  | cup            | 2.203  |
| fork          | 0.099  | knife        | 0.006  | spoon          | 0.000  |
| bowl          | 1.789  | banana       | 1.604  | apple          | 0.267  |
| sandwich      | 0.319  | orange       | 3.017  | broccoli       | 2.036  |
| carrot        | 0.337  | hot dog      | 0.000  | pizza          | 5.216  |
| donut         | 2.138  | cake         | 1.126  | chair          | 2.719  |
| couch         | 11.690 | potted plant | 1.802  | bed            | 18.690 |
| dining table  | 2.538  | toilet       | 18.950 | tv             | 16.143 |
| laptop        | 10.164 | mouse        | 0.569  | remote         | 0.305  |
| keyboard      | 2.211  | cell phone   | 2.216  | microwave      | 3.881  |
| oven          | 3.582  | toaster      | 0.000  | sink           | 4.169  |
| refrigerator  | 4.924  | book         | 0.365  | clock          | 10.617 |
| vase          | 1.205  | scissors     | 0.891  | teddy bear     | 4.733  |
| hair drier    | 0.000  | toothbrush   | 0.000  |                |        |
Loading and preparing results...
DONE (t=0.46s)
creating index...
index created!
[12/12 00:13:49 d2.evaluation.fast_eval_api]: Evaluate annotation type *segm*
[12/12 00:13:59 d2.evaluation.fast_eval_api]: COCOeval_opt.evaluate() finished in 9.34 seconds.
[12/12 00:13:59 d2.evaluation.fast_eval_api]: Accumulating evaluation results...
[12/12 00:13:59 d2.evaluation.fast_eval_api]: COCOeval_opt.accumulate() finished in 0.72 seconds.
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.073
 Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.148
 Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.066
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.006
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.063
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.156
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.090
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.117
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.117
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.010
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.100
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.209
[12/12 00:14:02 d2.evaluation.coco_evaluation]: Evaluation results for segm: 
|  AP   |  AP50  |  AP75  |  APs  |  APm  |  APl   |
|:-----:|:------:|:------:|:-----:|:-----:|:------:|
| 7.301 | 14.776 | 6.607  | 0.606 | 6.348 | 15.573 |
[12/12 00:14:02 d2.evaluation.coco_evaluation]: Per-category segm AP: 
| category      | AP     | category     | AP     | category       | AP     |
|:--------------|:-------|:-------------|:-------|:---------------|:-------|
| person        | 11.606 | bicycle      | 2.122  | car            | 7.174  |
| motorcycle    | 5.623  | airplane     | 17.542 | bus            | 31.852 |
| train         | 32.817 | truck        | 4.381  | boat           | 1.912  |
| traffic light | 2.815  | fire hydrant | 31.685 | stop sign      | 34.225 |
| parking meter | 5.840  | bench        | 2.398  | bird           | 3.910  |
| cat           | 17.557 | dog          | 16.095 | horse          | 9.305  |
| sheep         | 12.891 | cow          | 4.125  | elephant       | 21.896 |
| bear          | 31.365 | zebra        | 20.298 | giraffe        | 22.739 |
| backpack      | 0.000  | umbrella     | 9.641  | handbag        | 0.000  |
| tie           | 0.000  | suitcase     | 4.603  | frisbee        | 9.776  |
| skis          | 0.050  | snowboard    | 0.528  | sports ball    | 4.158  |
| kite          | 3.951  | baseball bat | 0.420  | baseball glove | 3.565  |
| skateboard    | 1.200  | surfboard    | 3.558  | tennis racket  | 15.712 |
| bottle        | 2.192  | wine glass   | 0.678  | cup            | 4.693  |
| fork          | 0.000  | knife        | 0.000  | spoon          | 0.000  |
| bowl          | 3.719  | banana       | 0.963  | apple          | 0.287  |
| sandwich      | 0.952  | orange       | 4.995  | broccoli       | 2.434  |
| carrot        | 0.211  | hot dog      | 0.594  | pizza          | 5.915  |
| donut         | 3.111  | cake         | 1.411  | chair          | 1.648  |
| couch         | 10.492 | potted plant | 1.607  | bed            | 13.272 |
| dining table  | 0.261  | toilet       | 27.453 | tv             | 21.577 |
| laptop        | 15.420 | mouse        | 1.812  | remote         | 0.398  |
| keyboard      | 7.454  | cell phone   | 2.858  | microwave      | 4.251  |
| oven          | 2.660  | toaster      | 0.000  | sink           | 5.129  |
| refrigerator  | 2.973  | book         | 0.195  | clock          | 12.228 |
| vase          | 4.059  | scissors     | 0.396  | teddy bear     | 6.243  |
| hair drier    | 0.000  | toothbrush   | 0.198  |                |        |
[12/12 00:14:06 d2.engine.defaults]: Evaluation results for coco_2017_val_panoptic in csv format:
[12/12 00:14:06 d2.evaluation.testing]: copypaste: Task: panoptic_seg
[12/12 00:14:06 d2.evaluation.testing]: copypaste: PQ,SQ,RQ,PQ_th,SQ_th,RQ_th,PQ_st,SQ_st,RQ_st
[12/12 00:14:06 d2.evaluation.testing]: copypaste: 18.1854,63.0800,23.7571,18.4093,66.1043,24.1185,17.8474,58.5151,23.2116
[12/12 00:14:06 d2.evaluation.testing]: copypaste: Task: bbox
[12/12 00:14:06 d2.evaluation.testing]: copypaste: AP,AP50,AP75,APs,APm,APl
[12/12 00:14:06 d2.evaluation.testing]: copypaste: 7.1484,13.8864,6.4787,1.3400,6.6565,11.5812
[12/12 00:14:06 d2.evaluation.testing]: copypaste: Task: segm
[12/12 00:14:06 d2.evaluation.testing]: copypaste: AP,AP50,AP75,APs,APm,APl
[12/12 00:14:06 d2.evaluation.testing]: copypaste: 7.3009,14.7762,6.6068,0.6060,6.3482,15.5734