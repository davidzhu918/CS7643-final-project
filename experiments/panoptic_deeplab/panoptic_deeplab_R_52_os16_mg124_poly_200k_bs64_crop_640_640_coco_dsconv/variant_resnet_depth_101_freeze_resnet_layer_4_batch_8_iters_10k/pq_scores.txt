env: DETECTRON2_DATASETS=/content/datasets
Command Line Args: Namespace(config_file='./detectron2/projects/Panoptic-DeepLab/configs/COCO-PanopticSegmentation/panoptic_deeplab_R_52_os16_mg124_poly_200k_bs64_crop_640_640_coco_dsconv.yaml', dist_url='tcp://127.0.0.1:49152', eval_only=False, machine_rank=0, num_gpus=1, num_machines=1, opts=['MODEL.RESNETS.NORM', 'BN', 'MODEL.INS_EMBED_HEAD.NORM', 'BN', 'MODEL.SEM_SEG_HEAD.NORM', 'BN', 'SOLVER.MAX_ITER', '10000', 'SOLVER.IMS_PER_BATCH', '8', 'SOLVER.BASE_LR', '0.0025', 'MODEL.BACKBONE.FREEZE_AT', '4', 'MODEL.RESNETS.DEPTH', '101', 'MODEL.WEIGHTS', 'detectron2://DeepLab/R-103.pkl'], resume=False)
Loading config ./detectron2/projects/Panoptic-DeepLab/configs/COCO-PanopticSegmentation/panoptic_deeplab_R_52_os16_mg124_poly_200k_bs64_crop_640_640_coco_dsconv.yaml with yaml.unsafe_load. Your machine may be at risk if the file contains malicious content.
[12/11 21:17:36 detectron2]: Rank of current process: 0. World size: 1
[12/11 21:17:37 detectron2]: Environment info:
----------------------  ----------------------------------------------------------------
sys.platform            linux
Python                  3.7.12 (default, Jan 15 2022, 18:48:18) [GCC 7.5.0]
numpy                   1.21.5
detectron2              0.6 @/content/detectron2/detectron2
Compiler                GCC 7.5
CUDA compiler           CUDA 11.1
detectron2 arch flags   7.0
DETECTRON2_ENV_MODULE   <not set>
PyTorch                 1.10.0+cu111 @/usr/local/lib/python3.7/dist-packages/torch
PyTorch debug build     False
GPU available           Yes
GPU 0                   Tesla V100-SXM2-16GB (arch=7.0)
Driver version          460.32.03
CUDA_HOME               /usr/local/cuda
Pillow                  7.1.2
torchvision             0.11.1+cu111 @/usr/local/lib/python3.7/dist-packages/torchvision
torchvision arch flags  3.5, 5.0, 6.0, 7.0, 7.5, 8.0, 8.6
fvcore                  0.1.5.post20221122
iopath                  0.1.9
cv2                     4.1.2
----------------------  ----------------------------------------------------------------
PyTorch built with:
  - GCC 7.3
  - C++ Version: 201402
  - Intel(R) Math Kernel Library Version 2020.0.0 Product Build 20191122 for Intel(R) 64 architecture applications
  - Intel(R) MKL-DNN v2.2.3 (Git Hash 7336ca9f055cf1bfa13efb658fe15dc9b41f0740)
  - OpenMP 201511 (a.k.a. OpenMP 4.5)
  - LAPACK is enabled (usually provided by MKL)
  - NNPACK is enabled
  - CPU capability usage: AVX2
  - CUDA Runtime 11.1
  - NVCC architecture flags: -gencode;arch=compute_37,code=sm_37;-gencode;arch=compute_50,code=sm_50;-gencode;arch=compute_60,code=sm_60;-gencode;arch=compute_70,code=sm_70;-gencode;arch=compute_75,code=sm_75;-gencode;arch=compute_80,code=sm_80;-gencode;arch=compute_86,code=sm_86
  - CuDNN 8.0.5
  - Magma 2.5.2
  - Build settings: BLAS_INFO=mkl, BUILD_TYPE=Release, CUDA_VERSION=11.1, CUDNN_VERSION=8.0.5, CXX_COMPILER=/opt/rh/devtoolset-7/root/usr/bin/c++, CXX_FLAGS= -Wno-deprecated -fvisibility-inlines-hidden -DUSE_PTHREADPOOL -fopenmp -DNDEBUG -DUSE_KINETO -DUSE_FBGEMM -DUSE_QNNPACK -DUSE_PYTORCH_QNNPACK -DUSE_XNNPACK -DSYMBOLICATE_MOBILE_DEBUG_HANDLE -DEDGE_PROFILER_USE_KINETO -O2 -fPIC -Wno-narrowing -Wall -Wextra -Werror=return-type -Wno-missing-field-initializers -Wno-type-limits -Wno-array-bounds -Wno-unknown-pragmas -Wno-sign-compare -Wno-unused-parameter -Wno-unused-variable -Wno-unused-function -Wno-unused-result -Wno-unused-local-typedefs -Wno-strict-overflow -Wno-strict-aliasing -Wno-error=deprecated-declarations -Wno-stringop-overflow -Wno-psabi -Wno-error=pedantic -Wno-error=redundant-decls -Wno-error=old-style-cast -fdiagnostics-color=always -faligned-new -Wno-unused-but-set-variable -Wno-maybe-uninitialized -fno-math-errno -fno-trapping-math -Werror=format -Wno-stringop-overflow, LAPACK_INFO=mkl, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, TORCH_VERSION=1.10.0, USE_CUDA=ON, USE_CUDNN=ON, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_MKL=ON, USE_MKLDNN=ON, USE_MPI=OFF, USE_NCCL=ON, USE_NNPACK=ON, USE_OPENMP=ON, 

[12/11 21:17:37 detectron2]: Command line arguments: Namespace(config_file='./detectron2/projects/Panoptic-DeepLab/configs/COCO-PanopticSegmentation/panoptic_deeplab_R_52_os16_mg124_poly_200k_bs64_crop_640_640_coco_dsconv.yaml', dist_url='tcp://127.0.0.1:49152', eval_only=False, machine_rank=0, num_gpus=1, num_machines=1, opts=['MODEL.RESNETS.NORM', 'BN', 'MODEL.INS_EMBED_HEAD.NORM', 'BN', 'MODEL.SEM_SEG_HEAD.NORM', 'BN', 'SOLVER.MAX_ITER', '10000', 'SOLVER.IMS_PER_BATCH', '8', 'SOLVER.BASE_LR', '0.0025', 'MODEL.BACKBONE.FREEZE_AT', '4', 'MODEL.RESNETS.DEPTH', '101', 'MODEL.WEIGHTS', 'detectron2://DeepLab/R-103.pkl'], resume=False)
[12/11 21:17:37 detectron2]: Contents of args.config_file=./detectron2/projects/Panoptic-DeepLab/configs/COCO-PanopticSegmentation/panoptic_deeplab_R_52_os16_mg124_poly_200k_bs64_crop_640_640_coco_dsconv.yaml:
_BASE_: ../Cityscapes-PanopticSegmentation/Base-PanopticDeepLab-OS16.yaml
MODEL:
  WEIGHTS: "detectron2://DeepLab/R-52.pkl"
  PIXEL_MEAN: [123.675, 116.280, 103.530]
  PIXEL_STD: [58.395, 57.120, 57.375]
  BACKBONE:
    NAME: "build_resnet_deeplab_backbone"
  RESNETS:
    DEPTH: 50
    NORM: "SyncBN"
    RES5_MULTI_GRID: [1, 2, 4]
    STEM_TYPE: "deeplab"
    STEM_OUT_CHANNELS: 128
    STRIDE_IN_1X1: False
  SEM_SEG_HEAD:
    NUM_CLASSES: 133
    LOSS_TOP_K: 1.0
    USE_DEPTHWISE_SEPARABLE_CONV: True
  PANOPTIC_DEEPLAB:
    STUFF_AREA: 4096
    NMS_KERNEL: 41
    SIZE_DIVISIBILITY: 640
    USE_DEPTHWISE_SEPARABLE_CONV: True
DATASETS:
  TRAIN: ("coco_2017_train_panoptic",)
  TEST: ("coco_2017_val_panoptic",)
SOLVER:
  BASE_LR: 0.0005
  MAX_ITER: 200000
  IMS_PER_BATCH: 64
INPUT:
  FORMAT: "RGB"
  GAUSSIAN_SIGMA: 8
  MIN_SIZE_TRAIN: !!python/object/apply:eval ["[int(x * 0.1 * 640) for x in range(5, 16)]"]
  MIN_SIZE_TRAIN_SAMPLING: "choice"
  MIN_SIZE_TEST: 640
  MAX_SIZE_TRAIN: 960
  MAX_SIZE_TEST: 640
  CROP:
    ENABLED: True
    TYPE: "absolute"
    SIZE: (640, 640)

[12/11 21:17:37 detectron2]: Running with full config:
CUDNN_BENCHMARK: false
DATALOADER:
  ASPECT_RATIO_GROUPING: true
  FILTER_EMPTY_ANNOTATIONS: true
  NUM_WORKERS: 10
  REPEAT_THRESHOLD: 0.0
  SAMPLER_TRAIN: TrainingSampler
DATASETS:
  PRECOMPUTED_PROPOSAL_TOPK_TEST: 1000
  PRECOMPUTED_PROPOSAL_TOPK_TRAIN: 2000
  PROPOSAL_FILES_TEST: []
  PROPOSAL_FILES_TRAIN: []
  TEST:
  - coco_2017_val_panoptic
  TRAIN:
  - coco_2017_train_panoptic
GLOBAL:
  HACK: 1.0
INPUT:
  CROP:
    ENABLED: true
    SINGLE_CATEGORY_MAX_AREA: 1.0
    SIZE:
    - 640
    - 640
    TYPE: absolute
  FORMAT: RGB
  GAUSSIAN_SIGMA: 8
  IGNORE_CROWD_IN_SEMANTIC: false
  IGNORE_STUFF_IN_OFFSET: true
  MASK_FORMAT: polygon
  MAX_SIZE_TEST: 640
  MAX_SIZE_TRAIN: 960
  MIN_SIZE_TEST: 640
  MIN_SIZE_TRAIN:
  - 320
  - 384
  - 448
  - 512
  - 576
  - 640
  - 704
  - 768
  - 832
  - 896
  - 960
  MIN_SIZE_TRAIN_SAMPLING: choice
  RANDOM_FLIP: horizontal
  SMALL_INSTANCE_AREA: 4096
  SMALL_INSTANCE_WEIGHT: 3
MODEL:
  ANCHOR_GENERATOR:
    ANGLES:
    - - -90
      - 0
      - 90
    ASPECT_RATIOS:
    - - 0.5
      - 1.0
      - 2.0
    NAME: DefaultAnchorGenerator
    OFFSET: 0.0
    SIZES:
    - - 32
      - 64
      - 128
      - 256
      - 512
  BACKBONE:
    FREEZE_AT: 4
    NAME: build_resnet_deeplab_backbone
  DEVICE: cuda
  FPN:
    FUSE_TYPE: sum
    IN_FEATURES: []
    NORM: ''
    OUT_CHANNELS: 256
  INS_EMBED_HEAD:
    ASPP_CHANNELS: 256
    ASPP_DILATIONS:
    - 6
    - 12
    - 18
    ASPP_DROPOUT: 0.1
    CENTER_LOSS_WEIGHT: 200.0
    COMMON_STRIDE: 4
    CONVS_DIM: 128
    HEAD_CHANNELS: 32
    IN_FEATURES:
    - res2
    - res3
    - res5
    NAME: PanopticDeepLabInsEmbedHead
    NORM: BN
    OFFSET_LOSS_WEIGHT: 0.01
    PROJECT_CHANNELS:
    - 32
    - 64
    PROJECT_FEATURES:
    - res2
    - res3
  KEYPOINT_ON: false
  LOAD_PROPOSALS: false
  MASK_ON: false
  META_ARCHITECTURE: PanopticDeepLab
  PANOPTIC_DEEPLAB:
    BENCHMARK_NETWORK_SPEED: false
    CENTER_THRESHOLD: 0.1
    NMS_KERNEL: 41
    PREDICT_INSTANCES: true
    SIZE_DIVISIBILITY: 640
    STUFF_AREA: 4096
    TOP_K_INSTANCE: 200
    USE_DEPTHWISE_SEPARABLE_CONV: true
  PANOPTIC_FPN:
    COMBINE:
      ENABLED: true
      INSTANCES_CONFIDENCE_THRESH: 0.5
      OVERLAP_THRESH: 0.5
      STUFF_AREA_LIMIT: 4096
    INSTANCE_LOSS_WEIGHT: 1.0
  PIXEL_MEAN:
  - 123.675
  - 116.28
  - 103.53
  PIXEL_STD:
  - 58.395
  - 57.12
  - 57.375
  PROPOSAL_GENERATOR:
    MIN_SIZE: 0
    NAME: RPN
  RESNETS:
    DEFORM_MODULATED: false
    DEFORM_NUM_GROUPS: 1
    DEFORM_ON_PER_STAGE:
    - false
    - false
    - false
    - false
    DEPTH: 101
    NORM: BN
    NUM_GROUPS: 1
    OUT_FEATURES:
    - res2
    - res3
    - res5
    RES2_OUT_CHANNELS: 256
    RES4_DILATION: 1
    RES5_DILATION: 2
    RES5_MULTI_GRID:
    - 1
    - 2
    - 4
    STEM_OUT_CHANNELS: 128
    STEM_TYPE: deeplab
    STRIDE_IN_1X1: false
    WIDTH_PER_GROUP: 64
  RETINANET:
    BBOX_REG_LOSS_TYPE: smooth_l1
    BBOX_REG_WEIGHTS: &id001
    - 1.0
    - 1.0
    - 1.0
    - 1.0
    FOCAL_LOSS_ALPHA: 0.25
    FOCAL_LOSS_GAMMA: 2.0
    IN_FEATURES:
    - p3
    - p4
    - p5
    - p6
    - p7
    IOU_LABELS:
    - 0
    - -1
    - 1
    IOU_THRESHOLDS:
    - 0.4
    - 0.5
    NMS_THRESH_TEST: 0.5
    NORM: ''
    NUM_CLASSES: 80
    NUM_CONVS: 4
    PRIOR_PROB: 0.01
    SCORE_THRESH_TEST: 0.05
    SMOOTH_L1_LOSS_BETA: 0.1
    TOPK_CANDIDATES_TEST: 1000
  ROI_BOX_CASCADE_HEAD:
    BBOX_REG_WEIGHTS:
    - - 10.0
      - 10.0
      - 5.0
      - 5.0
    - - 20.0
      - 20.0
      - 10.0
      - 10.0
    - - 30.0
      - 30.0
      - 15.0
      - 15.0
    IOUS:
    - 0.5
    - 0.6
    - 0.7
  ROI_BOX_HEAD:
    BBOX_REG_LOSS_TYPE: smooth_l1
    BBOX_REG_LOSS_WEIGHT: 1.0
    BBOX_REG_WEIGHTS:
    - 10.0
    - 10.0
    - 5.0
    - 5.0
    CLS_AGNOSTIC_BBOX_REG: false
    CONV_DIM: 256
    FC_DIM: 1024
    FED_LOSS_FREQ_WEIGHT_POWER: 0.5
    FED_LOSS_NUM_CLASSES: 50
    NAME: ''
    NORM: ''
    NUM_CONV: 0
    NUM_FC: 0
    POOLER_RESOLUTION: 14
    POOLER_SAMPLING_RATIO: 0
    POOLER_TYPE: ROIAlignV2
    SMOOTH_L1_BETA: 0.0
    TRAIN_ON_PRED_BOXES: false
    USE_FED_LOSS: false
    USE_SIGMOID_CE: false
  ROI_HEADS:
    BATCH_SIZE_PER_IMAGE: 512
    IN_FEATURES:
    - res4
    IOU_LABELS:
    - 0
    - 1
    IOU_THRESHOLDS:
    - 0.5
    NAME: Res5ROIHeads
    NMS_THRESH_TEST: 0.5
    NUM_CLASSES: 80
    POSITIVE_FRACTION: 0.25
    PROPOSAL_APPEND_GT: true
    SCORE_THRESH_TEST: 0.05
  ROI_KEYPOINT_HEAD:
    CONV_DIMS:
    - 512
    - 512
    - 512
    - 512
    - 512
    - 512
    - 512
    - 512
    LOSS_WEIGHT: 1.0
    MIN_KEYPOINTS_PER_IMAGE: 1
    NAME: KRCNNConvDeconvUpsampleHead
    NORMALIZE_LOSS_BY_VISIBLE_KEYPOINTS: true
    NUM_KEYPOINTS: 17
    POOLER_RESOLUTION: 14
    POOLER_SAMPLING_RATIO: 0
    POOLER_TYPE: ROIAlignV2
  ROI_MASK_HEAD:
    CLS_AGNOSTIC_MASK: false
    CONV_DIM: 256
    NAME: MaskRCNNConvUpsampleHead
    NORM: ''
    NUM_CONV: 0
    POOLER_RESOLUTION: 14
    POOLER_SAMPLING_RATIO: 0
    POOLER_TYPE: ROIAlignV2
  RPN:
    BATCH_SIZE_PER_IMAGE: 256
    BBOX_REG_LOSS_TYPE: smooth_l1
    BBOX_REG_LOSS_WEIGHT: 1.0
    BBOX_REG_WEIGHTS: *id001
    BOUNDARY_THRESH: -1
    CONV_DIMS:
    - -1
    HEAD_NAME: StandardRPNHead
    IN_FEATURES:
    - res4
    IOU_LABELS:
    - 0
    - -1
    - 1
    IOU_THRESHOLDS:
    - 0.3
    - 0.7
    LOSS_WEIGHT: 1.0
    NMS_THRESH: 0.7
    POSITIVE_FRACTION: 0.5
    POST_NMS_TOPK_TEST: 1000
    POST_NMS_TOPK_TRAIN: 2000
    PRE_NMS_TOPK_TEST: 6000
    PRE_NMS_TOPK_TRAIN: 12000
    SMOOTH_L1_BETA: 0.0
  SEM_SEG_HEAD:
    ASPP_CHANNELS: 256
    ASPP_DILATIONS:
    - 6
    - 12
    - 18
    ASPP_DROPOUT: 0.1
    COMMON_STRIDE: 4
    CONVS_DIM: 256
    HEAD_CHANNELS: 256
    IGNORE_VALUE: 255
    IN_FEATURES:
    - res2
    - res3
    - res5
    LOSS_TOP_K: 1.0
    LOSS_TYPE: hard_pixel_mining
    LOSS_WEIGHT: 1.0
    NAME: PanopticDeepLabSemSegHead
    NORM: BN
    NUM_CLASSES: 133
    PROJECT_CHANNELS:
    - 32
    - 64
    PROJECT_FEATURES:
    - res2
    - res3
    USE_DEPTHWISE_SEPARABLE_CONV: true
  WEIGHTS: detectron2://DeepLab/R-103.pkl
OUTPUT_DIR: ./output
SEED: -1
SOLVER:
  AMP:
    ENABLED: false
  BASE_LR: 0.0025
  BASE_LR_END: 0.0
  BIAS_LR_FACTOR: 1.0
  CHECKPOINT_PERIOD: 5000
  CLIP_GRADIENTS:
    CLIP_TYPE: value
    CLIP_VALUE: 1.0
    ENABLED: false
    NORM_TYPE: 2.0
  GAMMA: 0.1
  IMS_PER_BATCH: 8
  LR_SCHEDULER_NAME: WarmupPolyLR
  MAX_ITER: 10000
  MOMENTUM: 0.9
  NESTEROV: false
  NUM_DECAYS: 3
  OPTIMIZER: ADAM
  POLY_LR_CONSTANT_ENDING: 0.0
  POLY_LR_POWER: 0.9
  REFERENCE_WORLD_SIZE: 0
  RESCALE_INTERVAL: false
  STEPS:
  - 30000
  WARMUP_FACTOR: 0.001
  WARMUP_ITERS: 1000
  WARMUP_METHOD: linear
  WEIGHT_DECAY: 0.0
  WEIGHT_DECAY_BIAS: 0.0
  WEIGHT_DECAY_NORM: 0.0
TEST:
  AUG:
    ENABLED: false
    FLIP: true
    MAX_SIZE: 4000
    MIN_SIZES:
    - 400
    - 500
    - 600
    - 700
    - 800
    - 900
    - 1000
    - 1100
    - 1200
  DETECTIONS_PER_IMAGE: 100
  EVAL_PERIOD: 0
  EXPECTED_RESULTS: []
  KEYPOINT_OKS_SIGMAS: []
  PRECISE_BN:
    ENABLED: false
    NUM_ITER: 200
VERSION: 2
VIS_PERIOD: 0

[12/11 21:17:37 detectron2]: Full config saved to ./output/config.yaml
[12/11 21:17:37 d2.utils.env]: Using a generated random seed 37549283
[12/11 21:17:41 d2.engine.defaults]: Model:
PanopticDeepLab(
  (backbone): ResNet(
    (stem): DeepLabStem(
      (conv1): Conv2d(
        3, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False
        (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
      )
      (conv2): Conv2d(
        64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
        (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
      )
      (conv3): Conv2d(
        64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
        (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
      )
    )
    (res2): Sequential(
      (0): BottleneckBlock(
        (shortcut): Conv2d(
          128, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv1): Conv2d(
          128, 64, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
        )
        (conv2): Conv2d(
          64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
        )
        (conv3): Conv2d(
          64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
      )
      (1): BottleneckBlock(
        (conv1): Conv2d(
          256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
        )
        (conv2): Conv2d(
          64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
        )
        (conv3): Conv2d(
          64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
      )
      (2): BottleneckBlock(
        (conv1): Conv2d(
          256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
        )
        (conv2): Conv2d(
          64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
        )
        (conv3): Conv2d(
          64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
      )
    )
    (res3): Sequential(
      (0): BottleneckBlock(
        (shortcut): Conv2d(
          256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False
          (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
        )
        (conv1): Conv2d(
          256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
        )
        (conv2): Conv2d(
          128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
        )
        (conv3): Conv2d(
          128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
        )
      )
      (1): BottleneckBlock(
        (conv1): Conv2d(
          512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
        )
        (conv2): Conv2d(
          128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
        )
        (conv3): Conv2d(
          128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
        )
      )
      (2): BottleneckBlock(
        (conv1): Conv2d(
          512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
        )
        (conv2): Conv2d(
          128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
        )
        (conv3): Conv2d(
          128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
        )
      )
      (3): BottleneckBlock(
        (conv1): Conv2d(
          512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
        )
        (conv2): Conv2d(
          128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
        )
        (conv3): Conv2d(
          128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
        )
      )
    )
    (res4): Sequential(
      (0): BottleneckBlock(
        (shortcut): Conv2d(
          512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False
          (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
        )
        (conv1): Conv2d(
          512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv2): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv3): Conv2d(
          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
        )
      )
      (1): BottleneckBlock(
        (conv1): Conv2d(
          1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv2): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv3): Conv2d(
          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
        )
      )
      (2): BottleneckBlock(
        (conv1): Conv2d(
          1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv2): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv3): Conv2d(
          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
        )
      )
      (3): BottleneckBlock(
        (conv1): Conv2d(
          1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv2): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv3): Conv2d(
          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
        )
      )
      (4): BottleneckBlock(
        (conv1): Conv2d(
          1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv2): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv3): Conv2d(
          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
        )
      )
      (5): BottleneckBlock(
        (conv1): Conv2d(
          1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv2): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv3): Conv2d(
          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
        )
      )
      (6): BottleneckBlock(
        (conv1): Conv2d(
          1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv2): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv3): Conv2d(
          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
        )
      )
      (7): BottleneckBlock(
        (conv1): Conv2d(
          1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv2): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv3): Conv2d(
          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
        )
      )
      (8): BottleneckBlock(
        (conv1): Conv2d(
          1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv2): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv3): Conv2d(
          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
        )
      )
      (9): BottleneckBlock(
        (conv1): Conv2d(
          1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv2): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv3): Conv2d(
          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
        )
      )
      (10): BottleneckBlock(
        (conv1): Conv2d(
          1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv2): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv3): Conv2d(
          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
        )
      )
      (11): BottleneckBlock(
        (conv1): Conv2d(
          1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv2): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv3): Conv2d(
          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
        )
      )
      (12): BottleneckBlock(
        (conv1): Conv2d(
          1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv2): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv3): Conv2d(
          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
        )
      )
      (13): BottleneckBlock(
        (conv1): Conv2d(
          1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv2): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv3): Conv2d(
          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
        )
      )
      (14): BottleneckBlock(
        (conv1): Conv2d(
          1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv2): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv3): Conv2d(
          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
        )
      )
      (15): BottleneckBlock(
        (conv1): Conv2d(
          1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv2): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv3): Conv2d(
          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
        )
      )
      (16): BottleneckBlock(
        (conv1): Conv2d(
          1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv2): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv3): Conv2d(
          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
        )
      )
      (17): BottleneckBlock(
        (conv1): Conv2d(
          1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv2): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv3): Conv2d(
          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
        )
      )
      (18): BottleneckBlock(
        (conv1): Conv2d(
          1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv2): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv3): Conv2d(
          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
        )
      )
      (19): BottleneckBlock(
        (conv1): Conv2d(
          1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv2): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv3): Conv2d(
          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
        )
      )
      (20): BottleneckBlock(
        (conv1): Conv2d(
          1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv2): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv3): Conv2d(
          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
        )
      )
      (21): BottleneckBlock(
        (conv1): Conv2d(
          1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv2): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv3): Conv2d(
          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
        )
      )
      (22): BottleneckBlock(
        (conv1): Conv2d(
          1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv2): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv3): Conv2d(
          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
        )
      )
    )
    (res5): Sequential(
      (0): BottleneckBlock(
        (shortcut): Conv2d(
          1024, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv1): Conv2d(
          1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv2): Conv2d(
          512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2), dilation=(2, 2), bias=False
          (norm): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv3): Conv2d(
          512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (1): BottleneckBlock(
        (conv1): Conv2d(
          2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv2): Conv2d(
          512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(4, 4), dilation=(4, 4), bias=False
          (norm): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv3): Conv2d(
          512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (2): BottleneckBlock(
        (conv1): Conv2d(
          2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv2): Conv2d(
          512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(8, 8), dilation=(8, 8), bias=False
          (norm): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv3): Conv2d(
          512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
    )
  )
  (sem_seg_head): PanopticDeepLabSemSegHead(
    (decoder): ModuleDict(
      (res2): ModuleDict(
        (project_conv): Conv2d(
          256, 32, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (fuse_conv): DepthwiseSeparableConv2d(
          (depthwise): Conv2d(
            288, 288, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=288, bias=False
            (norm): BatchNorm2d(288, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          )
          (pointwise): Conv2d(
            288, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
      )
      (res3): ModuleDict(
        (project_conv): Conv2d(
          512, 64, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (fuse_conv): DepthwiseSeparableConv2d(
          (depthwise): Conv2d(
            320, 320, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=320, bias=False
            (norm): BatchNorm2d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          )
          (pointwise): Conv2d(
            320, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
      )
      (res5): ModuleDict(
        (project_conv): ASPP(
          (convs): ModuleList(
            (0): Conv2d(
              2048, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
              (norm): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            )
            (1): DepthwiseSeparableConv2d(
              (depthwise): Conv2d(
                2048, 2048, kernel_size=(3, 3), stride=(1, 1), padding=(6, 6), dilation=(6, 6), groups=2048, bias=False
                (norm): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
              (pointwise): Conv2d(
                2048, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
            )
            (2): DepthwiseSeparableConv2d(
              (depthwise): Conv2d(
                2048, 2048, kernel_size=(3, 3), stride=(1, 1), padding=(12, 12), dilation=(12, 12), groups=2048, bias=False
                (norm): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
              (pointwise): Conv2d(
                2048, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
            )
            (3): DepthwiseSeparableConv2d(
              (depthwise): Conv2d(
                2048, 2048, kernel_size=(3, 3), stride=(1, 1), padding=(18, 18), dilation=(18, 18), groups=2048, bias=False
                (norm): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
              (pointwise): Conv2d(
                2048, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
            )
            (4): Sequential(
              (0): AvgPool2d(kernel_size=(40, 40), stride=1, padding=0)
              (1): Conv2d(2048, 256, kernel_size=(1, 1), stride=(1, 1))
            )
          )
          (project): Conv2d(
            1280, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (fuse_conv): None
      )
    )
    (head): DepthwiseSeparableConv2d(
      (depthwise): Conv2d(
        256, 256, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=256, bias=False
        (norm): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (pointwise): Conv2d(
        256, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
        (norm): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (predictor): Conv2d(256, 133, kernel_size=(1, 1), stride=(1, 1))
    (loss): DeepLabCE(
      (criterion): CrossEntropyLoss()
    )
  )
  (ins_embed_head): PanopticDeepLabInsEmbedHead(
    (decoder): ModuleDict(
      (res2): ModuleDict(
        (project_conv): Conv2d(
          256, 32, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (fuse_conv): DepthwiseSeparableConv2d(
          (depthwise): Conv2d(
            160, 160, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=160, bias=False
            (norm): BatchNorm2d(160, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          )
          (pointwise): Conv2d(
            160, 128, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
      )
      (res3): ModuleDict(
        (project_conv): Conv2d(
          512, 64, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (fuse_conv): DepthwiseSeparableConv2d(
          (depthwise): Conv2d(
            320, 320, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=320, bias=False
            (norm): BatchNorm2d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          )
          (pointwise): Conv2d(
            320, 128, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
      )
      (res5): ModuleDict(
        (project_conv): ASPP(
          (convs): ModuleList(
            (0): Conv2d(
              2048, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
              (norm): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            )
            (1): DepthwiseSeparableConv2d(
              (depthwise): Conv2d(
                2048, 2048, kernel_size=(3, 3), stride=(1, 1), padding=(6, 6), dilation=(6, 6), groups=2048, bias=False
                (norm): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
              (pointwise): Conv2d(
                2048, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
            )
            (2): DepthwiseSeparableConv2d(
              (depthwise): Conv2d(
                2048, 2048, kernel_size=(3, 3), stride=(1, 1), padding=(12, 12), dilation=(12, 12), groups=2048, bias=False
                (norm): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
              (pointwise): Conv2d(
                2048, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
            )
            (3): DepthwiseSeparableConv2d(
              (depthwise): Conv2d(
                2048, 2048, kernel_size=(3, 3), stride=(1, 1), padding=(18, 18), dilation=(18, 18), groups=2048, bias=False
                (norm): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
              (pointwise): Conv2d(
                2048, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
            )
            (4): Sequential(
              (0): AvgPool2d(kernel_size=(40, 40), stride=1, padding=0)
              (1): Conv2d(2048, 256, kernel_size=(1, 1), stride=(1, 1))
            )
          )
          (project): Conv2d(
            1280, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (fuse_conv): None
      )
    )
    (center_head): Sequential(
      (0): Conv2d(
        128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
        (norm): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (1): Conv2d(
        128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
        (norm): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (center_predictor): Conv2d(32, 1, kernel_size=(1, 1), stride=(1, 1))
    (offset_head): DepthwiseSeparableConv2d(
      (depthwise): Conv2d(
        128, 128, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=128, bias=False
        (norm): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (pointwise): Conv2d(
        128, 32, kernel_size=(1, 1), stride=(1, 1), bias=False
        (norm): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (offset_predictor): Conv2d(32, 2, kernel_size=(1, 1), stride=(1, 1))
    (center_loss): MSELoss()
    (offset_loss): L1Loss()
  )
)
[12/11 21:17:42 d2.projects.panoptic_deeplab.dataset_mapper]: Augmentations used in training: [ResizeShortestEdge(short_edge_length=(320, 384, 448, 512, 576, 640, 704, 768, 832, 896, 960), max_size=960, sample_style='choice'), RandomCrop(crop_type='absolute', crop_size=[640, 640]), RandomFlip()]
[12/11 21:17:49 d2.data.build]: Using training sampler TrainingSampler
[12/11 21:17:49 d2.data.common]: Serializing the dataset using: <class 'detectron2.data.common.NumpySerializedList'>
[12/11 21:17:49 d2.data.common]: Serializing 118287 elements to byte tensors and concatenating them all ...
[12/11 21:17:50 d2.data.common]: Serialized dataset takes 80.32 MiB
/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:481: UserWarning: This DataLoader will create 10 worker processes in total. Our suggested max number of worker in current system is 8, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.
  cpuset_checked))
[12/11 21:17:52 fvcore.common.checkpoint]: [Checkpointer] Loading from detectron2://DeepLab/R-103.pkl ...
[12/11 21:17:52 fvcore.common.checkpoint]: Reading a file from 'torchvision'
[12/11 21:17:52 d2.checkpoint.c2_model_loading]: Following weights matched with submodule backbone:
| Names in Model    | Names in Checkpoint                                                                                        | Shapes                                             |
|:------------------|:-----------------------------------------------------------------------------------------------------------|:---------------------------------------------------|
| res2.0.conv1.*    | res2.0.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}                             | (64,) (64,) (64,) (64,) (64,128,1,1)               |
| res2.0.conv2.*    | res2.0.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}                             | (64,) (64,) (64,) (64,) (64,64,3,3)                |
| res2.0.conv3.*    | res2.0.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}                             | (256,) (256,) (256,) (256,) (256,64,1,1)           |
| res2.0.shortcut.* | res2.0.shortcut.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}                          | (256,) (256,) (256,) (256,) (256,128,1,1)          |
| res2.1.conv1.*    | res2.1.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}                             | (64,) (64,) (64,) (64,) (64,256,1,1)               |
| res2.1.conv2.*    | res2.1.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}                             | (64,) (64,) (64,) (64,) (64,64,3,3)                |
| res2.1.conv3.*    | res2.1.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}                             | (256,) (256,) (256,) (256,) (256,64,1,1)           |
| res2.2.conv1.*    | res2.2.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}                             | (64,) (64,) (64,) (64,) (64,256,1,1)               |
| res2.2.conv2.*    | res2.2.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}                             | (64,) (64,) (64,) (64,) (64,64,3,3)                |
| res2.2.conv3.*    | res2.2.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}                             | (256,) (256,) (256,) (256,) (256,64,1,1)           |
| res3.0.conv1.*    | res3.0.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}                             | (128,) (128,) (128,) (128,) (128,256,1,1)          |
| res3.0.conv2.*    | res3.0.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}                             | (128,) (128,) (128,) (128,) (128,128,3,3)          |
| res3.0.conv3.*    | res3.0.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}                             | (512,) (512,) (512,) (512,) (512,128,1,1)          |
| res3.0.shortcut.* | res3.0.shortcut.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}                          | (512,) (512,) (512,) (512,) (512,256,1,1)          |
| res3.1.conv1.*    | res3.1.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}                             | (128,) (128,) (128,) (128,) (128,512,1,1)          |
| res3.1.conv2.*    | res3.1.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}                             | (128,) (128,) (128,) (128,) (128,128,3,3)          |
| res3.1.conv3.*    | res3.1.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}                             | (512,) (512,) (512,) (512,) (512,128,1,1)          |
| res3.2.conv1.*    | res3.2.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}                             | (128,) (128,) (128,) (128,) (128,512,1,1)          |
| res3.2.conv2.*    | res3.2.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}                             | (128,) (128,) (128,) (128,) (128,128,3,3)          |
| res3.2.conv3.*    | res3.2.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}                             | (512,) (512,) (512,) (512,) (512,128,1,1)          |
| res3.3.conv1.*    | res3.3.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}                             | (128,) (128,) (128,) (128,) (128,512,1,1)          |
| res3.3.conv2.*    | res3.3.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}                             | (128,) (128,) (128,) (128,) (128,128,3,3)          |
| res3.3.conv3.*    | res3.3.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}                             | (512,) (512,) (512,) (512,) (512,128,1,1)          |
| res4.0.conv1.*    | res4.0.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}                             | (256,) (256,) (256,) (256,) (256,512,1,1)          |
| res4.0.conv2.*    | res4.0.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}                             | (256,) (256,) (256,) (256,) (256,256,3,3)          |
| res4.0.conv3.*    | res4.0.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}                             | (1024,) (1024,) (1024,) (1024,) (1024,256,1,1)     |
| res4.0.shortcut.* | res4.0.shortcut.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}                          | (1024,) (1024,) (1024,) (1024,) (1024,512,1,1)     |
| res4.1.conv1.*    | res4.1.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}                             | (256,) (256,) (256,) (256,) (256,1024,1,1)         |
| res4.1.conv2.*    | res4.1.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}                             | (256,) (256,) (256,) (256,) (256,256,3,3)          |
| res4.1.conv3.*    | res4.1.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}                             | (1024,) (1024,) (1024,) (1024,) (1024,256,1,1)     |
| res4.10.conv1.*   | res4.10.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}                            | (256,) (256,) (256,) (256,) (256,1024,1,1)         |
| res4.10.conv2.*   | res4.10.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}                            | (256,) (256,) (256,) (256,) (256,256,3,3)          |
| res4.10.conv3.*   | res4.10.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}                            | (1024,) (1024,) (1024,) (1024,) (1024,256,1,1)     |
| res4.11.conv1.*   | res4.11.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}                            | (256,) (256,) (256,) (256,) (256,1024,1,1)         |
| res4.11.conv2.*   | res4.11.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}                            | (256,) (256,) (256,) (256,) (256,256,3,3)          |
| res4.11.conv3.*   | res4.11.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}                            | (1024,) (1024,) (1024,) (1024,) (1024,256,1,1)     |
| res4.12.conv1.*   | res4.12.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}                            | (256,) (256,) (256,) (256,) (256,1024,1,1)         |
| res4.12.conv2.*   | res4.12.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}                            | (256,) (256,) (256,) (256,) (256,256,3,3)          |
| res4.12.conv3.*   | res4.12.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}                            | (1024,) (1024,) (1024,) (1024,) (1024,256,1,1)     |
| res4.13.conv1.*   | res4.13.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}                            | (256,) (256,) (256,) (256,) (256,1024,1,1)         |
| res4.13.conv2.*   | res4.13.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}                            | (256,) (256,) (256,) (256,) (256,256,3,3)          |
| res4.13.conv3.*   | res4.13.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}                            | (1024,) (1024,) (1024,) (1024,) (1024,256,1,1)     |
| res4.14.conv1.*   | res4.14.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}                            | (256,) (256,) (256,) (256,) (256,1024,1,1)         |
| res4.14.conv2.*   | res4.14.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}                            | (256,) (256,) (256,) (256,) (256,256,3,3)          |
| res4.14.conv3.*   | res4.14.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}                            | (1024,) (1024,) (1024,) (1024,) (1024,256,1,1)     |
| res4.15.conv1.*   | res4.15.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}                            | (256,) (256,) (256,) (256,) (256,1024,1,1)         |
| res4.15.conv2.*   | res4.15.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}                            | (256,) (256,) (256,) (256,) (256,256,3,3)          |
| res4.15.conv3.*   | res4.15.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}                            | (1024,) (1024,) (1024,) (1024,) (1024,256,1,1)     |
| res4.16.conv1.*   | res4.16.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}                            | (256,) (256,) (256,) (256,) (256,1024,1,1)         |
| res4.16.conv2.*   | res4.16.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}                            | (256,) (256,) (256,) (256,) (256,256,3,3)          |
| res4.16.conv3.*   | res4.16.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}                            | (1024,) (1024,) (1024,) (1024,) (1024,256,1,1)     |
| res4.17.conv1.*   | res4.17.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}                            | (256,) (256,) (256,) (256,) (256,1024,1,1)         |
| res4.17.conv2.*   | res4.17.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}                            | (256,) (256,) (256,) (256,) (256,256,3,3)          |
| res4.17.conv3.*   | res4.17.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}                            | (1024,) (1024,) (1024,) (1024,) (1024,256,1,1)     |
| res4.18.conv1.*   | res4.18.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}                            | (256,) (256,) (256,) (256,) (256,1024,1,1)         |
| res4.18.conv2.*   | res4.18.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}                            | (256,) (256,) (256,) (256,) (256,256,3,3)          |
| res4.18.conv3.*   | res4.18.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}                            | (1024,) (1024,) (1024,) (1024,) (1024,256,1,1)     |
| res4.19.conv1.*   | res4.19.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}                            | (256,) (256,) (256,) (256,) (256,1024,1,1)         |
| res4.19.conv2.*   | res4.19.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}                            | (256,) (256,) (256,) (256,) (256,256,3,3)          |
| res4.19.conv3.*   | res4.19.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}                            | (1024,) (1024,) (1024,) (1024,) (1024,256,1,1)     |
| res4.2.conv1.*    | res4.2.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}                             | (256,) (256,) (256,) (256,) (256,1024,1,1)         |
| res4.2.conv2.*    | res4.2.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}                             | (256,) (256,) (256,) (256,) (256,256,3,3)          |
| res4.2.conv3.*    | res4.2.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}                             | (1024,) (1024,) (1024,) (1024,) (1024,256,1,1)     |
| res4.20.conv1.*   | res4.20.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}                            | (256,) (256,) (256,) (256,) (256,1024,1,1)         |
| res4.20.conv2.*   | res4.20.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}                            | (256,) (256,) (256,) (256,) (256,256,3,3)          |
| res4.20.conv3.*   | res4.20.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}                            | (1024,) (1024,) (1024,) (1024,) (1024,256,1,1)     |
| res4.21.conv1.*   | res4.21.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}                            | (256,) (256,) (256,) (256,) (256,1024,1,1)         |
| res4.21.conv2.*   | res4.21.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}                            | (256,) (256,) (256,) (256,) (256,256,3,3)          |
| res4.21.conv3.*   | res4.21.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}                            | (1024,) (1024,) (1024,) (1024,) (1024,256,1,1)     |
| res4.22.conv1.*   | res4.22.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}                            | (256,) (256,) (256,) (256,) (256,1024,1,1)         |
| res4.22.conv2.*   | res4.22.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}                            | (256,) (256,) (256,) (256,) (256,256,3,3)          |
| res4.22.conv3.*   | res4.22.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}                            | (1024,) (1024,) (1024,) (1024,) (1024,256,1,1)     |
| res4.3.conv1.*    | res4.3.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}                             | (256,) (256,) (256,) (256,) (256,1024,1,1)         |
| res4.3.conv2.*    | res4.3.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}                             | (256,) (256,) (256,) (256,) (256,256,3,3)          |
| res4.3.conv3.*    | res4.3.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}                             | (1024,) (1024,) (1024,) (1024,) (1024,256,1,1)     |
| res4.4.conv1.*    | res4.4.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}                             | (256,) (256,) (256,) (256,) (256,1024,1,1)         |
| res4.4.conv2.*    | res4.4.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}                             | (256,) (256,) (256,) (256,) (256,256,3,3)          |
| res4.4.conv3.*    | res4.4.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}                             | (1024,) (1024,) (1024,) (1024,) (1024,256,1,1)     |
| res4.5.conv1.*    | res4.5.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}                             | (256,) (256,) (256,) (256,) (256,1024,1,1)         |
| res4.5.conv2.*    | res4.5.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}                             | (256,) (256,) (256,) (256,) (256,256,3,3)          |
| res4.5.conv3.*    | res4.5.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}                             | (1024,) (1024,) (1024,) (1024,) (1024,256,1,1)     |
| res4.6.conv1.*    | res4.6.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}                             | (256,) (256,) (256,) (256,) (256,1024,1,1)         |
| res4.6.conv2.*    | res4.6.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}                             | (256,) (256,) (256,) (256,) (256,256,3,3)          |
| res4.6.conv3.*    | res4.6.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}                             | (1024,) (1024,) (1024,) (1024,) (1024,256,1,1)     |
| res4.7.conv1.*    | res4.7.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}                             | (256,) (256,) (256,) (256,) (256,1024,1,1)         |
| res4.7.conv2.*    | res4.7.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}                             | (256,) (256,) (256,) (256,) (256,256,3,3)          |
| res4.7.conv3.*    | res4.7.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}                             | (1024,) (1024,) (1024,) (1024,) (1024,256,1,1)     |
| res4.8.conv1.*    | res4.8.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}                             | (256,) (256,) (256,) (256,) (256,1024,1,1)         |
| res4.8.conv2.*    | res4.8.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}                             | (256,) (256,) (256,) (256,) (256,256,3,3)          |
| res4.8.conv3.*    | res4.8.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}                             | (1024,) (1024,) (1024,) (1024,) (1024,256,1,1)     |
| res4.9.conv1.*    | res4.9.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}                             | (256,) (256,) (256,) (256,) (256,1024,1,1)         |
| res4.9.conv2.*    | res4.9.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}                             | (256,) (256,) (256,) (256,) (256,256,3,3)          |
| res4.9.conv3.*    | res4.9.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}                             | (1024,) (1024,) (1024,) (1024,) (1024,256,1,1)     |
| res5.0.conv1.*    | res5.0.conv1.{norm.bias,norm.num_batches_tracked,norm.running_mean,norm.running_var,norm.weight,weight}    | (512,) () (512,) (512,) (512,) (512,1024,1,1)      |
| res5.0.conv2.*    | res5.0.conv2.{norm.bias,norm.num_batches_tracked,norm.running_mean,norm.running_var,norm.weight,weight}    | (512,) () (512,) (512,) (512,) (512,512,3,3)       |
| res5.0.conv3.*    | res5.0.conv3.{norm.bias,norm.num_batches_tracked,norm.running_mean,norm.running_var,norm.weight,weight}    | (2048,) () (2048,) (2048,) (2048,) (2048,512,1,1)  |
| res5.0.shortcut.* | res5.0.shortcut.{norm.bias,norm.num_batches_tracked,norm.running_mean,norm.running_var,norm.weight,weight} | (2048,) () (2048,) (2048,) (2048,) (2048,1024,1,1) |
| res5.1.conv1.*    | res5.1.conv1.{norm.bias,norm.num_batches_tracked,norm.running_mean,norm.running_var,norm.weight,weight}    | (512,) () (512,) (512,) (512,) (512,2048,1,1)      |
| res5.1.conv2.*    | res5.1.conv2.{norm.bias,norm.num_batches_tracked,norm.running_mean,norm.running_var,norm.weight,weight}    | (512,) () (512,) (512,) (512,) (512,512,3,3)       |
| res5.1.conv3.*    | res5.1.conv3.{norm.bias,norm.num_batches_tracked,norm.running_mean,norm.running_var,norm.weight,weight}    | (2048,) () (2048,) (2048,) (2048,) (2048,512,1,1)  |
| res5.2.conv1.*    | res5.2.conv1.{norm.bias,norm.num_batches_tracked,norm.running_mean,norm.running_var,norm.weight,weight}    | (512,) () (512,) (512,) (512,) (512,2048,1,1)      |
| res5.2.conv2.*    | res5.2.conv2.{norm.bias,norm.num_batches_tracked,norm.running_mean,norm.running_var,norm.weight,weight}    | (512,) () (512,) (512,) (512,) (512,512,3,3)       |
| res5.2.conv3.*    | res5.2.conv3.{norm.bias,norm.num_batches_tracked,norm.running_mean,norm.running_var,norm.weight,weight}    | (2048,) () (2048,) (2048,) (2048,) (2048,512,1,1)  |
| stem.conv1.*      | stem.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}                               | (64,) (64,) (64,) (64,) (64,3,3,3)                 |
| stem.conv2.*      | stem.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}                               | (64,) (64,) (64,) (64,) (64,64,3,3)                |
| stem.conv3.*      | stem.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}                               | (128,) (128,) (128,) (128,) (128,64,3,3)           |
WARNING [12/11 21:17:53 fvcore.common.checkpoint]: Some model parameters or buffers are not found in the checkpoint:
ins_embed_head.center_head.0.norm.{bias, running_mean, running_var, weight}
ins_embed_head.center_head.0.weight
ins_embed_head.center_head.1.norm.{bias, running_mean, running_var, weight}
ins_embed_head.center_head.1.weight
ins_embed_head.center_predictor.{bias, weight}
ins_embed_head.decoder.res2.fuse_conv.depthwise.norm.{bias, running_mean, running_var, weight}
ins_embed_head.decoder.res2.fuse_conv.depthwise.weight
ins_embed_head.decoder.res2.fuse_conv.pointwise.norm.{bias, running_mean, running_var, weight}
ins_embed_head.decoder.res2.fuse_conv.pointwise.weight
ins_embed_head.decoder.res2.project_conv.norm.{bias, running_mean, running_var, weight}
ins_embed_head.decoder.res2.project_conv.weight
ins_embed_head.decoder.res3.fuse_conv.depthwise.norm.{bias, running_mean, running_var, weight}
ins_embed_head.decoder.res3.fuse_conv.depthwise.weight
ins_embed_head.decoder.res3.fuse_conv.pointwise.norm.{bias, running_mean, running_var, weight}
ins_embed_head.decoder.res3.fuse_conv.pointwise.weight
ins_embed_head.decoder.res3.project_conv.norm.{bias, running_mean, running_var, weight}
ins_embed_head.decoder.res3.project_conv.weight
ins_embed_head.decoder.res5.project_conv.convs.0.norm.{bias, running_mean, running_var, weight}
ins_embed_head.decoder.res5.project_conv.convs.0.weight
ins_embed_head.decoder.res5.project_conv.convs.1.depthwise.norm.{bias, running_mean, running_var, weight}
ins_embed_head.decoder.res5.project_conv.convs.1.depthwise.weight
ins_embed_head.decoder.res5.project_conv.convs.1.pointwise.norm.{bias, running_mean, running_var, weight}
ins_embed_head.decoder.res5.project_conv.convs.1.pointwise.weight
ins_embed_head.decoder.res5.project_conv.convs.2.depthwise.norm.{bias, running_mean, running_var, weight}
ins_embed_head.decoder.res5.project_conv.convs.2.depthwise.weight
ins_embed_head.decoder.res5.project_conv.convs.2.pointwise.norm.{bias, running_mean, running_var, weight}
ins_embed_head.decoder.res5.project_conv.convs.2.pointwise.weight
ins_embed_head.decoder.res5.project_conv.convs.3.depthwise.norm.{bias, running_mean, running_var, weight}
ins_embed_head.decoder.res5.project_conv.convs.3.depthwise.weight
ins_embed_head.decoder.res5.project_conv.convs.3.pointwise.norm.{bias, running_mean, running_var, weight}
ins_embed_head.decoder.res5.project_conv.convs.3.pointwise.weight
ins_embed_head.decoder.res5.project_conv.convs.4.1.{bias, weight}
ins_embed_head.decoder.res5.project_conv.project.norm.{bias, running_mean, running_var, weight}
ins_embed_head.decoder.res5.project_conv.project.weight
ins_embed_head.offset_head.depthwise.norm.{bias, running_mean, running_var, weight}
ins_embed_head.offset_head.depthwise.weight
ins_embed_head.offset_head.pointwise.norm.{bias, running_mean, running_var, weight}
ins_embed_head.offset_head.pointwise.weight
ins_embed_head.offset_predictor.{bias, weight}
sem_seg_head.decoder.res2.fuse_conv.depthwise.norm.{bias, running_mean, running_var, weight}
sem_seg_head.decoder.res2.fuse_conv.depthwise.weight
sem_seg_head.decoder.res2.fuse_conv.pointwise.norm.{bias, running_mean, running_var, weight}
sem_seg_head.decoder.res2.fuse_conv.pointwise.weight
sem_seg_head.decoder.res2.project_conv.norm.{bias, running_mean, running_var, weight}
sem_seg_head.decoder.res2.project_conv.weight
sem_seg_head.decoder.res3.fuse_conv.depthwise.norm.{bias, running_mean, running_var, weight}
sem_seg_head.decoder.res3.fuse_conv.depthwise.weight
sem_seg_head.decoder.res3.fuse_conv.pointwise.norm.{bias, running_mean, running_var, weight}
sem_seg_head.decoder.res3.fuse_conv.pointwise.weight
sem_seg_head.decoder.res3.project_conv.norm.{bias, running_mean, running_var, weight}
sem_seg_head.decoder.res3.project_conv.weight
sem_seg_head.decoder.res5.project_conv.convs.0.norm.{bias, running_mean, running_var, weight}
sem_seg_head.decoder.res5.project_conv.convs.0.weight
sem_seg_head.decoder.res5.project_conv.convs.1.depthwise.norm.{bias, running_mean, running_var, weight}
sem_seg_head.decoder.res5.project_conv.convs.1.depthwise.weight
sem_seg_head.decoder.res5.project_conv.convs.1.pointwise.norm.{bias, running_mean, running_var, weight}
sem_seg_head.decoder.res5.project_conv.convs.1.pointwise.weight
sem_seg_head.decoder.res5.project_conv.convs.2.depthwise.norm.{bias, running_mean, running_var, weight}
sem_seg_head.decoder.res5.project_conv.convs.2.depthwise.weight
sem_seg_head.decoder.res5.project_conv.convs.2.pointwise.norm.{bias, running_mean, running_var, weight}
sem_seg_head.decoder.res5.project_conv.convs.2.pointwise.weight
sem_seg_head.decoder.res5.project_conv.convs.3.depthwise.norm.{bias, running_mean, running_var, weight}
sem_seg_head.decoder.res5.project_conv.convs.3.depthwise.weight
sem_seg_head.decoder.res5.project_conv.convs.3.pointwise.norm.{bias, running_mean, running_var, weight}
sem_seg_head.decoder.res5.project_conv.convs.3.pointwise.weight
sem_seg_head.decoder.res5.project_conv.convs.4.1.{bias, weight}
sem_seg_head.decoder.res5.project_conv.project.norm.{bias, running_mean, running_var, weight}
sem_seg_head.decoder.res5.project_conv.project.weight
sem_seg_head.head.depthwise.norm.{bias, running_mean, running_var, weight}
sem_seg_head.head.depthwise.weight
sem_seg_head.head.pointwise.norm.{bias, running_mean, running_var, weight}
sem_seg_head.head.pointwise.weight
sem_seg_head.predictor.{bias, weight}
WARNING [12/11 21:17:53 fvcore.common.checkpoint]: The checkpoint state_dict contains keys that are not used by the model:
  res2.0.conv1.norm.num_batches_tracked
  res2.0.conv2.norm.num_batches_tracked
  res2.0.conv3.norm.num_batches_tracked
  res2.0.shortcut.norm.num_batches_tracked
  res2.1.conv1.norm.num_batches_tracked
  res2.1.conv2.norm.num_batches_tracked
  res2.1.conv3.norm.num_batches_tracked
  res2.2.conv1.norm.num_batches_tracked
  res2.2.conv2.norm.num_batches_tracked
  res2.2.conv3.norm.num_batches_tracked
  res3.0.conv1.norm.num_batches_tracked
  res3.0.conv2.norm.num_batches_tracked
  res3.0.conv3.norm.num_batches_tracked
  res3.0.shortcut.norm.num_batches_tracked
  res3.1.conv1.norm.num_batches_tracked
  res3.1.conv2.norm.num_batches_tracked
  res3.1.conv3.norm.num_batches_tracked
  res3.2.conv1.norm.num_batches_tracked
  res3.2.conv2.norm.num_batches_tracked
  res3.2.conv3.norm.num_batches_tracked
  res3.3.conv1.norm.num_batches_tracked
  res3.3.conv2.norm.num_batches_tracked
  res3.3.conv3.norm.num_batches_tracked
  res4.0.conv1.norm.num_batches_tracked
  res4.0.conv2.norm.num_batches_tracked
  res4.0.conv3.norm.num_batches_tracked
  res4.0.shortcut.norm.num_batches_tracked
  res4.1.conv1.norm.num_batches_tracked
  res4.1.conv2.norm.num_batches_tracked
  res4.1.conv3.norm.num_batches_tracked
  res4.10.conv1.norm.num_batches_tracked
  res4.10.conv2.norm.num_batches_tracked
  res4.10.conv3.norm.num_batches_tracked
  res4.11.conv1.norm.num_batches_tracked
  res4.11.conv2.norm.num_batches_tracked
  res4.11.conv3.norm.num_batches_tracked
  res4.12.conv1.norm.num_batches_tracked
  res4.12.conv2.norm.num_batches_tracked
  res4.12.conv3.norm.num_batches_tracked
  res4.13.conv1.norm.num_batches_tracked
  res4.13.conv2.norm.num_batches_tracked
  res4.13.conv3.norm.num_batches_tracked
  res4.14.conv1.norm.num_batches_tracked
  res4.14.conv2.norm.num_batches_tracked
  res4.14.conv3.norm.num_batches_tracked
  res4.15.conv1.norm.num_batches_tracked
  res4.15.conv2.norm.num_batches_tracked
  res4.15.conv3.norm.num_batches_tracked
  res4.16.conv1.norm.num_batches_tracked
  res4.16.conv2.norm.num_batches_tracked
  res4.16.conv3.norm.num_batches_tracked
  res4.17.conv1.norm.num_batches_tracked
  res4.17.conv2.norm.num_batches_tracked
  res4.17.conv3.norm.num_batches_tracked
  res4.18.conv1.norm.num_batches_tracked
  res4.18.conv2.norm.num_batches_tracked
  res4.18.conv3.norm.num_batches_tracked
  res4.19.conv1.norm.num_batches_tracked
  res4.19.conv2.norm.num_batches_tracked
  res4.19.conv3.norm.num_batches_tracked
  res4.2.conv1.norm.num_batches_tracked
  res4.2.conv2.norm.num_batches_tracked
  res4.2.conv3.norm.num_batches_tracked
  res4.20.conv1.norm.num_batches_tracked
  res4.20.conv2.norm.num_batches_tracked
  res4.20.conv3.norm.num_batches_tracked
  res4.21.conv1.norm.num_batches_tracked
  res4.21.conv2.norm.num_batches_tracked
  res4.21.conv3.norm.num_batches_tracked
  res4.22.conv1.norm.num_batches_tracked
  res4.22.conv2.norm.num_batches_tracked
  res4.22.conv3.norm.num_batches_tracked
  res4.3.conv1.norm.num_batches_tracked
  res4.3.conv2.norm.num_batches_tracked
  res4.3.conv3.norm.num_batches_tracked
  res4.4.conv1.norm.num_batches_tracked
  res4.4.conv2.norm.num_batches_tracked
  res4.4.conv3.norm.num_batches_tracked
  res4.5.conv1.norm.num_batches_tracked
  res4.5.conv2.norm.num_batches_tracked
  res4.5.conv3.norm.num_batches_tracked
  res4.6.conv1.norm.num_batches_tracked
  res4.6.conv2.norm.num_batches_tracked
  res4.6.conv3.norm.num_batches_tracked
  res4.7.conv1.norm.num_batches_tracked
  res4.7.conv2.norm.num_batches_tracked
  res4.7.conv3.norm.num_batches_tracked
  res4.8.conv1.norm.num_batches_tracked
  res4.8.conv2.norm.num_batches_tracked
  res4.8.conv3.norm.num_batches_tracked
  res4.9.conv1.norm.num_batches_tracked
  res4.9.conv2.norm.num_batches_tracked
  res4.9.conv3.norm.num_batches_tracked
  stem.conv1.norm.num_batches_tracked
  stem.conv2.norm.num_batches_tracked
  stem.conv3.norm.num_batches_tracked
  stem.fc.{bias, weight}
[12/11 21:17:53 d2.engine.train_loop]: Starting training from iteration 0
/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:481: UserWarning: This DataLoader will create 10 worker processes in total. Our suggested max number of worker in current system is 8, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.
  cpuset_checked))
[12/11 21:18:04 d2.utils.events]:  eta: 1:26:33  iter: 19  total_loss: 6.252  loss_sem_seg: 3.865  loss_center: 0.7131  loss_offset: 1.716  time: 0.5240  data_time: 0.0731  lr: 4.9867e-05  max_mem: 11575M
[12/11 21:18:15 d2.utils.events]:  eta: 1:27:02  iter: 39  total_loss: 5.911  loss_sem_seg: 3.573  loss_center: 0.6717  loss_offset: 1.61  time: 0.5261  data_time: 0.0437  lr: 9.9552e-05  max_mem: 11575M
[12/11 21:18:25 d2.utils.events]:  eta: 1:26:52  iter: 59  total_loss: 5.894  loss_sem_seg: 3.648  loss_center: 0.6545  loss_offset: 1.619  time: 0.5267  data_time: 0.0415  lr: 0.00014906  max_mem: 11575M
[12/11 21:18:36 d2.utils.events]:  eta: 1:26:43  iter: 79  total_loss: 5.701  loss_sem_seg: 3.317  loss_center: 0.6958  loss_offset: 1.702  time: 0.5268  data_time: 0.0422  lr: 0.00019838  max_mem: 11575M
[12/11 21:18:47 d2.utils.events]:  eta: 1:26:51  iter: 99  total_loss: 5.167  loss_sem_seg: 2.96  loss_center: 0.7143  loss_offset: 1.671  time: 0.5294  data_time: 0.0499  lr: 0.00024753  max_mem: 11575M
[12/11 21:18:57 d2.utils.events]:  eta: 1:26:38  iter: 119  total_loss: 5.027  loss_sem_seg: 2.772  loss_center: 0.6866  loss_offset: 1.554  time: 0.5291  data_time: 0.0433  lr: 0.00029649  max_mem: 11575M
[12/11 21:19:08 d2.utils.events]:  eta: 1:26:30  iter: 139  total_loss: 5.192  loss_sem_seg: 2.887  loss_center: 0.5079  loss_offset: 1.817  time: 0.5300  data_time: 0.0480  lr: 0.00034528  max_mem: 11575M
[12/11 21:19:19 d2.utils.events]:  eta: 1:26:33  iter: 159  total_loss: 4.92  loss_sem_seg: 2.504  loss_center: 0.5808  loss_offset: 1.661  time: 0.5302  data_time: 0.0461  lr: 0.00039388  max_mem: 11575M
[12/11 21:19:29 d2.utils.events]:  eta: 1:26:26  iter: 179  total_loss: 4.709  loss_sem_seg: 2.53  loss_center: 0.6168  loss_offset: 1.649  time: 0.5301  data_time: 0.0449  lr: 0.0004423  max_mem: 11575M
[12/11 21:19:40 d2.utils.events]:  eta: 1:26:10  iter: 199  total_loss: 4.51  loss_sem_seg: 2.312  loss_center: 0.6278  loss_offset: 1.594  time: 0.5300  data_time: 0.0421  lr: 0.00049055  max_mem: 11576M
[12/11 21:19:50 d2.utils.events]:  eta: 1:26:05  iter: 219  total_loss: 4.576  loss_sem_seg: 2.251  loss_center: 0.6618  loss_offset: 1.605  time: 0.5300  data_time: 0.0439  lr: 0.00053861  max_mem: 11576M
[12/11 21:20:01 d2.utils.events]:  eta: 1:25:58  iter: 239  total_loss: 4.627  loss_sem_seg: 2.311  loss_center: 0.5637  loss_offset: 1.665  time: 0.5304  data_time: 0.0469  lr: 0.00058649  max_mem: 11576M
[12/11 21:20:12 d2.utils.events]:  eta: 1:25:49  iter: 259  total_loss: 4.433  loss_sem_seg: 2.352  loss_center: 0.6399  loss_offset: 1.479  time: 0.5308  data_time: 0.0478  lr: 0.0006342  max_mem: 11576M
[12/11 21:20:23 d2.utils.events]:  eta: 1:25:42  iter: 279  total_loss: 4.28  loss_sem_seg: 2.183  loss_center: 0.5879  loss_offset: 1.638  time: 0.5310  data_time: 0.0469  lr: 0.00068172  max_mem: 11576M
[12/11 21:20:33 d2.utils.events]:  eta: 1:25:35  iter: 299  total_loss: 4.358  loss_sem_seg: 2.165  loss_center: 0.6378  loss_offset: 1.511  time: 0.5311  data_time: 0.0480  lr: 0.00072906  max_mem: 11576M
[12/11 21:20:44 d2.utils.events]:  eta: 1:25:24  iter: 319  total_loss: 3.762  loss_sem_seg: 1.864  loss_center: 0.4663  loss_offset: 1.349  time: 0.5313  data_time: 0.0486  lr: 0.00077622  max_mem: 11576M
[12/11 21:20:55 d2.utils.events]:  eta: 1:25:15  iter: 339  total_loss: 3.934  loss_sem_seg: 1.895  loss_center: 0.6126  loss_offset: 1.226  time: 0.5315  data_time: 0.0496  lr: 0.0008232  max_mem: 11576M
[12/11 21:21:05 d2.utils.events]:  eta: 1:25:09  iter: 359  total_loss: 4.056  loss_sem_seg: 1.902  loss_center: 0.5806  loss_offset: 1.423  time: 0.5316  data_time: 0.0443  lr: 0.00087  max_mem: 11576M
[12/11 21:21:16 d2.utils.events]:  eta: 1:24:59  iter: 379  total_loss: 3.659  loss_sem_seg: 1.803  loss_center: 0.6884  loss_offset: 1.138  time: 0.5315  data_time: 0.0423  lr: 0.00091662  max_mem: 11576M
[12/11 21:21:27 d2.utils.events]:  eta: 1:24:48  iter: 399  total_loss: 3.897  loss_sem_seg: 1.941  loss_center: 0.6426  loss_offset: 1.221  time: 0.5314  data_time: 0.0453  lr: 0.00096306  max_mem: 11576M
[12/11 21:21:37 d2.utils.events]:  eta: 1:24:38  iter: 419  total_loss: 3.449  loss_sem_seg: 1.72  loss_center: 0.6586  loss_offset: 1.218  time: 0.5316  data_time: 0.0520  lr: 0.0010093  max_mem: 11576M
[12/11 21:21:48 d2.utils.events]:  eta: 1:24:28  iter: 439  total_loss: 3.659  loss_sem_seg: 1.863  loss_center: 0.6964  loss_offset: 1.118  time: 0.5316  data_time: 0.0425  lr: 0.0010554  max_mem: 11576M
[12/11 21:21:59 d2.utils.events]:  eta: 1:24:17  iter: 459  total_loss: 3.517  loss_sem_seg: 1.795  loss_center: 0.6349  loss_offset: 0.991  time: 0.5315  data_time: 0.0469  lr: 0.0011013  max_mem: 11576M
[12/11 21:22:09 d2.utils.events]:  eta: 1:24:06  iter: 479  total_loss: 3.462  loss_sem_seg: 1.742  loss_center: 0.5362  loss_offset: 1.148  time: 0.5315  data_time: 0.0461  lr: 0.001147  max_mem: 11576M
[12/11 21:22:20 d2.utils.events]:  eta: 1:23:55  iter: 499  total_loss: 3.558  loss_sem_seg: 1.795  loss_center: 0.6006  loss_offset: 1.075  time: 0.5317  data_time: 0.0497  lr: 0.0011925  max_mem: 11576M
[12/11 21:22:31 d2.utils.events]:  eta: 1:23:44  iter: 519  total_loss: 3.446  loss_sem_seg: 1.679  loss_center: 0.5879  loss_offset: 1.081  time: 0.5316  data_time: 0.0452  lr: 0.0012379  max_mem: 11576M
[12/11 21:22:41 d2.utils.events]:  eta: 1:23:34  iter: 539  total_loss: 3.419  loss_sem_seg: 1.681  loss_center: 0.5625  loss_offset: 0.9974  time: 0.5317  data_time: 0.0475  lr: 0.001283  max_mem: 11576M
[12/11 21:22:52 d2.utils.events]:  eta: 1:23:23  iter: 559  total_loss: 3.407  loss_sem_seg: 1.834  loss_center: 0.5567  loss_offset: 0.8284  time: 0.5316  data_time: 0.0422  lr: 0.001328  max_mem: 11576M
[12/11 21:23:03 d2.utils.events]:  eta: 1:23:13  iter: 579  total_loss: 3.145  loss_sem_seg: 1.706  loss_center: 0.516  loss_offset: 0.8612  time: 0.5317  data_time: 0.0468  lr: 0.0013728  max_mem: 11576M
[12/11 21:23:13 d2.utils.events]:  eta: 1:23:02  iter: 599  total_loss: 3.372  loss_sem_seg: 1.748  loss_center: 0.6599  loss_offset: 0.8801  time: 0.5316  data_time: 0.0420  lr: 0.0014175  max_mem: 11576M
[12/11 21:23:24 d2.utils.events]:  eta: 1:22:50  iter: 619  total_loss: 3.147  loss_sem_seg: 1.635  loss_center: 0.5293  loss_offset: 0.835  time: 0.5316  data_time: 0.0463  lr: 0.0014619  max_mem: 11576M
[12/11 21:23:35 d2.utils.events]:  eta: 1:22:40  iter: 639  total_loss: 3.305  loss_sem_seg: 1.87  loss_center: 0.5311  loss_offset: 0.9614  time: 0.5316  data_time: 0.0462  lr: 0.0015062  max_mem: 11576M
[12/11 21:23:45 d2.utils.events]:  eta: 1:22:29  iter: 659  total_loss: 2.929  loss_sem_seg: 1.579  loss_center: 0.6526  loss_offset: 0.8727  time: 0.5316  data_time: 0.0460  lr: 0.0015503  max_mem: 11576M
[12/11 21:23:56 d2.utils.events]:  eta: 1:22:19  iter: 679  total_loss: 3.354  loss_sem_seg: 1.762  loss_center: 0.5177  loss_offset: 0.8721  time: 0.5317  data_time: 0.0494  lr: 0.0015942  max_mem: 11576M
[12/11 21:24:06 d2.utils.events]:  eta: 1:22:09  iter: 699  total_loss: 3.147  loss_sem_seg: 1.774  loss_center: 0.5367  loss_offset: 0.8614  time: 0.5316  data_time: 0.0434  lr: 0.0016379  max_mem: 11576M
[12/11 21:24:17 d2.utils.events]:  eta: 1:21:59  iter: 719  total_loss: 3.174  loss_sem_seg: 1.575  loss_center: 0.6077  loss_offset: 0.8036  time: 0.5316  data_time: 0.0443  lr: 0.0016814  max_mem: 11576M
[12/11 21:24:28 d2.utils.events]:  eta: 1:21:49  iter: 739  total_loss: 3.1  loss_sem_seg: 1.723  loss_center: 0.4914  loss_offset: 0.7875  time: 0.5316  data_time: 0.0453  lr: 0.0017248  max_mem: 11576M
[12/11 21:24:38 d2.utils.events]:  eta: 1:21:38  iter: 759  total_loss: 3.21  loss_sem_seg: 1.702  loss_center: 0.5909  loss_offset: 0.8904  time: 0.5315  data_time: 0.0448  lr: 0.0017679  max_mem: 11576M
[12/11 21:24:49 d2.utils.events]:  eta: 1:21:29  iter: 779  total_loss: 2.954  loss_sem_seg: 1.638  loss_center: 0.5242  loss_offset: 0.779  time: 0.5316  data_time: 0.0480  lr: 0.0018109  max_mem: 11576M
[12/11 21:25:00 d2.utils.events]:  eta: 1:21:18  iter: 799  total_loss: 3.02  loss_sem_seg: 1.634  loss_center: 0.5196  loss_offset: 0.8348  time: 0.5315  data_time: 0.0431  lr: 0.0018537  max_mem: 11576M
[12/11 21:25:10 d2.utils.events]:  eta: 1:21:08  iter: 819  total_loss: 3.001  loss_sem_seg: 1.496  loss_center: 0.5303  loss_offset: 0.8503  time: 0.5315  data_time: 0.0461  lr: 0.0018964  max_mem: 11576M
[12/11 21:25:21 d2.utils.events]:  eta: 1:20:56  iter: 839  total_loss: 3.222  loss_sem_seg: 1.567  loss_center: 0.5875  loss_offset: 0.8417  time: 0.5315  data_time: 0.0464  lr: 0.0019388  max_mem: 11576M
[12/11 21:25:32 d2.utils.events]:  eta: 1:20:46  iter: 859  total_loss: 3.057  loss_sem_seg: 1.608  loss_center: 0.633  loss_offset: 0.8394  time: 0.5314  data_time: 0.0457  lr: 0.0019811  max_mem: 11576M
[12/11 21:25:42 d2.utils.events]:  eta: 1:20:35  iter: 879  total_loss: 3.09  loss_sem_seg: 1.492  loss_center: 0.6896  loss_offset: 0.8106  time: 0.5314  data_time: 0.0500  lr: 0.0020231  max_mem: 11576M
[12/11 21:25:53 d2.utils.events]:  eta: 1:20:23  iter: 899  total_loss: 2.982  loss_sem_seg: 1.48  loss_center: 0.5025  loss_offset: 0.8079  time: 0.5314  data_time: 0.0442  lr: 0.002065  max_mem: 11576M
[12/11 21:26:03 d2.utils.events]:  eta: 1:20:13  iter: 919  total_loss: 3.178  loss_sem_seg: 1.555  loss_center: 0.6676  loss_offset: 0.8291  time: 0.5314  data_time: 0.0459  lr: 0.0021068  max_mem: 11576M
[12/11 21:26:14 d2.utils.events]:  eta: 1:20:02  iter: 939  total_loss: 2.924  loss_sem_seg: 1.526  loss_center: 0.5813  loss_offset: 0.7887  time: 0.5314  data_time: 0.0448  lr: 0.0021483  max_mem: 11576M
[12/11 21:26:25 d2.utils.events]:  eta: 1:19:51  iter: 959  total_loss: 2.89  loss_sem_seg: 1.582  loss_center: 0.5451  loss_offset: 0.7618  time: 0.5313  data_time: 0.0452  lr: 0.0021896  max_mem: 11576M
[12/11 21:26:35 d2.utils.events]:  eta: 1:19:41  iter: 979  total_loss: 2.897  loss_sem_seg: 1.508  loss_center: 0.4872  loss_offset: 0.8246  time: 0.5314  data_time: 0.0469  lr: 0.0022308  max_mem: 11576M
[12/11 21:26:46 d2.utils.events]:  eta: 1:19:30  iter: 999  total_loss: 3.284  loss_sem_seg: 1.666  loss_center: 0.6423  loss_offset: 0.8002  time: 0.5314  data_time: 0.0473  lr: 0.0022718  max_mem: 11576M
[12/11 21:26:57 d2.utils.events]:  eta: 1:19:20  iter: 1019  total_loss: 3.102  loss_sem_seg: 1.573  loss_center: 0.6793  loss_offset: 0.8393  time: 0.5315  data_time: 0.0477  lr: 0.0022695  max_mem: 11576M
[12/11 21:27:07 d2.utils.events]:  eta: 1:19:10  iter: 1039  total_loss: 3.094  loss_sem_seg: 1.754  loss_center: 0.5498  loss_offset: 0.7552  time: 0.5315  data_time: 0.0444  lr: 0.002265  max_mem: 11576M
[12/11 21:27:18 d2.utils.events]:  eta: 1:19:00  iter: 1059  total_loss: 2.764  loss_sem_seg: 1.31  loss_center: 0.6115  loss_offset: 0.7637  time: 0.5315  data_time: 0.0460  lr: 0.0022604  max_mem: 11576M
[12/11 21:27:29 d2.utils.events]:  eta: 1:18:50  iter: 1079  total_loss: 3.004  loss_sem_seg: 1.608  loss_center: 0.5931  loss_offset: 0.7853  time: 0.5315  data_time: 0.0440  lr: 0.0022559  max_mem: 11576M
[12/11 21:27:39 d2.utils.events]:  eta: 1:18:40  iter: 1099  total_loss: 3.161  loss_sem_seg: 1.658  loss_center: 0.7317  loss_offset: 0.7994  time: 0.5314  data_time: 0.0458  lr: 0.0022513  max_mem: 11576M
[12/11 21:27:50 d2.utils.events]:  eta: 1:18:31  iter: 1119  total_loss: 3.031  loss_sem_seg: 1.545  loss_center: 0.6468  loss_offset: 0.8181  time: 0.5314  data_time: 0.0476  lr: 0.0022468  max_mem: 11576M
[12/11 21:28:01 d2.utils.events]:  eta: 1:18:21  iter: 1139  total_loss: 3.226  loss_sem_seg: 1.66  loss_center: 0.6006  loss_offset: 0.7807  time: 0.5315  data_time: 0.0495  lr: 0.0022422  max_mem: 11576M
[12/11 21:28:11 d2.utils.events]:  eta: 1:18:08  iter: 1159  total_loss: 2.71  loss_sem_seg: 1.344  loss_center: 0.6356  loss_offset: 0.6478  time: 0.5315  data_time: 0.0453  lr: 0.0022376  max_mem: 11576M
[12/11 21:28:22 d2.utils.events]:  eta: 1:17:57  iter: 1179  total_loss: 2.834  loss_sem_seg: 1.447  loss_center: 0.5585  loss_offset: 0.7436  time: 0.5314  data_time: 0.0455  lr: 0.0022331  max_mem: 11576M
[12/11 21:28:33 d2.utils.events]:  eta: 1:17:47  iter: 1199  total_loss: 2.692  loss_sem_seg: 1.398  loss_center: 0.5601  loss_offset: 0.716  time: 0.5315  data_time: 0.0460  lr: 0.0022285  max_mem: 11576M
[12/11 21:28:43 d2.utils.events]:  eta: 1:17:36  iter: 1219  total_loss: 2.834  loss_sem_seg: 1.368  loss_center: 0.5412  loss_offset: 0.7211  time: 0.5314  data_time: 0.0432  lr: 0.002224  max_mem: 11576M
[12/11 21:28:54 d2.utils.events]:  eta: 1:17:24  iter: 1239  total_loss: 2.821  loss_sem_seg: 1.491  loss_center: 0.6395  loss_offset: 0.6636  time: 0.5314  data_time: 0.0451  lr: 0.0022194  max_mem: 11576M
[12/11 21:29:04 d2.utils.events]:  eta: 1:17:13  iter: 1259  total_loss: 3.017  loss_sem_seg: 1.584  loss_center: 0.5825  loss_offset: 0.7821  time: 0.5314  data_time: 0.0465  lr: 0.0022149  max_mem: 11576M
[12/11 21:29:15 d2.utils.events]:  eta: 1:17:02  iter: 1279  total_loss: 2.689  loss_sem_seg: 1.357  loss_center: 0.5476  loss_offset: 0.7479  time: 0.5314  data_time: 0.0443  lr: 0.0022103  max_mem: 11576M
[12/11 21:29:26 d2.utils.events]:  eta: 1:16:52  iter: 1299  total_loss: 2.879  loss_sem_seg: 1.42  loss_center: 0.6614  loss_offset: 0.7589  time: 0.5314  data_time: 0.0440  lr: 0.0022057  max_mem: 11576M
[12/11 21:29:36 d2.utils.events]:  eta: 1:16:41  iter: 1319  total_loss: 2.981  loss_sem_seg: 1.524  loss_center: 0.6257  loss_offset: 0.7366  time: 0.5313  data_time: 0.0461  lr: 0.0022012  max_mem: 11576M
[12/11 21:29:47 d2.utils.events]:  eta: 1:16:30  iter: 1339  total_loss: 2.676  loss_sem_seg: 1.355  loss_center: 0.5987  loss_offset: 0.689  time: 0.5313  data_time: 0.0430  lr: 0.0021966  max_mem: 11576M
[12/11 21:29:58 d2.utils.events]:  eta: 1:16:19  iter: 1359  total_loss: 2.796  loss_sem_seg: 1.437  loss_center: 0.6054  loss_offset: 0.7399  time: 0.5313  data_time: 0.0449  lr: 0.002192  max_mem: 11576M
[12/11 21:30:08 d2.utils.events]:  eta: 1:16:08  iter: 1379  total_loss: 2.723  loss_sem_seg: 1.223  loss_center: 0.586  loss_offset: 0.6605  time: 0.5313  data_time: 0.0438  lr: 0.0021875  max_mem: 11576M
[12/11 21:30:19 d2.utils.events]:  eta: 1:15:57  iter: 1399  total_loss: 2.66  loss_sem_seg: 1.335  loss_center: 0.6143  loss_offset: 0.6084  time: 0.5313  data_time: 0.0467  lr: 0.0021829  max_mem: 11576M
[12/11 21:30:29 d2.utils.events]:  eta: 1:15:47  iter: 1419  total_loss: 2.744  loss_sem_seg: 1.234  loss_center: 0.6498  loss_offset: 0.6688  time: 0.5312  data_time: 0.0426  lr: 0.0021783  max_mem: 11576M
[12/11 21:30:40 d2.utils.events]:  eta: 1:15:36  iter: 1439  total_loss: 2.824  loss_sem_seg: 1.563  loss_center: 0.5663  loss_offset: 0.6772  time: 0.5312  data_time: 0.0436  lr: 0.0021738  max_mem: 11576M
[12/11 21:30:51 d2.utils.events]:  eta: 1:15:25  iter: 1459  total_loss: 2.679  loss_sem_seg: 1.302  loss_center: 0.5726  loss_offset: 0.6809  time: 0.5311  data_time: 0.0440  lr: 0.0021692  max_mem: 11576M
[12/11 21:31:01 d2.utils.events]:  eta: 1:15:15  iter: 1479  total_loss: 2.782  loss_sem_seg: 1.454  loss_center: 0.5728  loss_offset: 0.783  time: 0.5312  data_time: 0.0453  lr: 0.0021646  max_mem: 11576M
[12/11 21:31:12 d2.utils.events]:  eta: 1:15:05  iter: 1499  total_loss: 2.803  loss_sem_seg: 1.358  loss_center: 0.5997  loss_offset: 0.6712  time: 0.5312  data_time: 0.0464  lr: 0.00216  max_mem: 11576M
[12/11 21:31:23 d2.utils.events]:  eta: 1:14:55  iter: 1519  total_loss: 2.676  loss_sem_seg: 1.346  loss_center: 0.55  loss_offset: 0.7895  time: 0.5313  data_time: 0.0502  lr: 0.0021555  max_mem: 11576M
[12/11 21:31:33 d2.utils.events]:  eta: 1:14:44  iter: 1539  total_loss: 2.671  loss_sem_seg: 1.168  loss_center: 0.6236  loss_offset: 0.7432  time: 0.5312  data_time: 0.0420  lr: 0.0021509  max_mem: 11576M
[12/11 21:31:44 d2.utils.events]:  eta: 1:14:33  iter: 1559  total_loss: 2.875  loss_sem_seg: 1.453  loss_center: 0.5358  loss_offset: 0.7557  time: 0.5312  data_time: 0.0422  lr: 0.0021463  max_mem: 11576M
[12/11 21:31:54 d2.utils.events]:  eta: 1:14:21  iter: 1579  total_loss: 2.641  loss_sem_seg: 1.296  loss_center: 0.6398  loss_offset: 0.6104  time: 0.5312  data_time: 0.0447  lr: 0.0021417  max_mem: 11576M
[12/11 21:32:05 d2.utils.events]:  eta: 1:14:11  iter: 1599  total_loss: 2.465  loss_sem_seg: 1.265  loss_center: 0.4706  loss_offset: 0.6672  time: 0.5312  data_time: 0.0437  lr: 0.0021372  max_mem: 11576M
[12/11 21:32:16 d2.utils.events]:  eta: 1:14:02  iter: 1619  total_loss: 2.621  loss_sem_seg: 1.277  loss_center: 0.5415  loss_offset: 0.7004  time: 0.5312  data_time: 0.0455  lr: 0.0021326  max_mem: 11576M
[12/11 21:32:26 d2.utils.events]:  eta: 1:13:50  iter: 1639  total_loss: 2.633  loss_sem_seg: 1.229  loss_center: 0.6328  loss_offset: 0.7027  time: 0.5311  data_time: 0.0422  lr: 0.002128  max_mem: 11576M
[12/11 21:32:37 d2.utils.events]:  eta: 1:13:40  iter: 1659  total_loss: 2.513  loss_sem_seg: 1.147  loss_center: 0.5607  loss_offset: 0.6593  time: 0.5312  data_time: 0.0515  lr: 0.0021234  max_mem: 11576M
[12/11 21:32:48 d2.utils.events]:  eta: 1:13:29  iter: 1679  total_loss: 2.711  loss_sem_seg: 1.392  loss_center: 0.5934  loss_offset: 0.7647  time: 0.5312  data_time: 0.0482  lr: 0.0021188  max_mem: 11576M
[12/11 21:32:58 d2.utils.events]:  eta: 1:13:18  iter: 1699  total_loss: 2.763  loss_sem_seg: 1.35  loss_center: 0.5013  loss_offset: 0.7623  time: 0.5311  data_time: 0.0454  lr: 0.0021143  max_mem: 11576M
[12/11 21:33:09 d2.utils.events]:  eta: 1:13:07  iter: 1719  total_loss: 2.81  loss_sem_seg: 1.415  loss_center: 0.5493  loss_offset: 0.7784  time: 0.5312  data_time: 0.0480  lr: 0.0021097  max_mem: 11576M
[12/11 21:33:20 d2.utils.events]:  eta: 1:12:57  iter: 1739  total_loss: 2.501  loss_sem_seg: 1.304  loss_center: 0.4525  loss_offset: 0.778  time: 0.5312  data_time: 0.0470  lr: 0.0021051  max_mem: 11576M
[12/11 21:33:30 d2.utils.events]:  eta: 1:12:46  iter: 1759  total_loss: 2.509  loss_sem_seg: 1.249  loss_center: 0.5781  loss_offset: 0.7266  time: 0.5312  data_time: 0.0418  lr: 0.0021005  max_mem: 11576M
[12/11 21:33:41 d2.utils.events]:  eta: 1:12:35  iter: 1779  total_loss: 2.691  loss_sem_seg: 1.253  loss_center: 0.6621  loss_offset: 0.6964  time: 0.5312  data_time: 0.0486  lr: 0.0020959  max_mem: 11576M
[12/11 21:33:52 d2.utils.events]:  eta: 1:12:25  iter: 1799  total_loss: 2.556  loss_sem_seg: 1.206  loss_center: 0.5554  loss_offset: 0.681  time: 0.5313  data_time: 0.0526  lr: 0.0020913  max_mem: 11576M
[12/11 21:34:02 d2.utils.events]:  eta: 1:12:13  iter: 1819  total_loss: 2.389  loss_sem_seg: 1.159  loss_center: 0.6958  loss_offset: 0.6655  time: 0.5313  data_time: 0.0428  lr: 0.0020867  max_mem: 11576M
[12/11 21:34:13 d2.utils.events]:  eta: 1:12:04  iter: 1839  total_loss: 2.448  loss_sem_seg: 1.227  loss_center: 0.5762  loss_offset: 0.7124  time: 0.5313  data_time: 0.0430  lr: 0.0020821  max_mem: 11576M
[12/11 21:34:24 d2.utils.events]:  eta: 1:11:52  iter: 1859  total_loss: 2.499  loss_sem_seg: 1.177  loss_center: 0.6192  loss_offset: 0.7265  time: 0.5312  data_time: 0.0455  lr: 0.0020775  max_mem: 11576M
[12/11 21:34:34 d2.utils.events]:  eta: 1:11:42  iter: 1879  total_loss: 2.856  loss_sem_seg: 1.438  loss_center: 0.5399  loss_offset: 0.7783  time: 0.5313  data_time: 0.0501  lr: 0.0020729  max_mem: 11576M
[12/11 21:34:45 d2.utils.events]:  eta: 1:11:32  iter: 1899  total_loss: 2.467  loss_sem_seg: 1.137  loss_center: 0.6798  loss_offset: 0.6922  time: 0.5313  data_time: 0.0453  lr: 0.0020684  max_mem: 11576M
[12/11 21:34:55 d2.utils.events]:  eta: 1:11:22  iter: 1919  total_loss: 2.502  loss_sem_seg: 1.305  loss_center: 0.6186  loss_offset: 0.5818  time: 0.5313  data_time: 0.0438  lr: 0.0020638  max_mem: 11576M
[12/11 21:35:06 d2.utils.events]:  eta: 1:11:13  iter: 1939  total_loss: 2.525  loss_sem_seg: 1.177  loss_center: 0.5217  loss_offset: 0.637  time: 0.5314  data_time: 0.0493  lr: 0.0020592  max_mem: 11576M
[12/11 21:35:17 d2.utils.events]:  eta: 1:11:02  iter: 1959  total_loss: 2.372  loss_sem_seg: 1.245  loss_center: 0.543  loss_offset: 0.6825  time: 0.5313  data_time: 0.0446  lr: 0.0020546  max_mem: 11576M
[12/11 21:35:27 d2.utils.events]:  eta: 1:10:50  iter: 1979  total_loss: 2.451  loss_sem_seg: 1.169  loss_center: 0.5631  loss_offset: 0.6584  time: 0.5313  data_time: 0.0432  lr: 0.00205  max_mem: 11576M
[12/11 21:35:38 d2.utils.events]:  eta: 1:10:40  iter: 1999  total_loss: 2.593  loss_sem_seg: 1.296  loss_center: 0.6292  loss_offset: 0.6114  time: 0.5313  data_time: 0.0452  lr: 0.0020454  max_mem: 11576M
[12/11 21:35:49 d2.utils.events]:  eta: 1:10:29  iter: 2019  total_loss: 2.362  loss_sem_seg: 1.227  loss_center: 0.4912  loss_offset: 0.6268  time: 0.5313  data_time: 0.0542  lr: 0.0020408  max_mem: 11576M
[12/11 21:36:00 d2.utils.events]:  eta: 1:10:18  iter: 2039  total_loss: 2.524  loss_sem_seg: 1.299  loss_center: 0.5548  loss_offset: 0.6589  time: 0.5314  data_time: 0.0476  lr: 0.0020362  max_mem: 11576M
[12/11 21:36:10 d2.utils.events]:  eta: 1:10:07  iter: 2059  total_loss: 2.662  loss_sem_seg: 1.333  loss_center: 0.6396  loss_offset: 0.7497  time: 0.5314  data_time: 0.0510  lr: 0.0020316  max_mem: 11576M
[12/11 21:36:21 d2.utils.events]:  eta: 1:09:57  iter: 2079  total_loss: 2.613  loss_sem_seg: 1.32  loss_center: 0.6066  loss_offset: 0.6252  time: 0.5314  data_time: 0.0493  lr: 0.0020269  max_mem: 11576M
[12/11 21:36:32 d2.utils.events]:  eta: 1:09:45  iter: 2099  total_loss: 2.587  loss_sem_seg: 1.303  loss_center: 0.5232  loss_offset: 0.6643  time: 0.5314  data_time: 0.0491  lr: 0.0020223  max_mem: 11576M
[12/11 21:36:42 d2.utils.events]:  eta: 1:09:33  iter: 2119  total_loss: 2.548  loss_sem_seg: 1.289  loss_center: 0.5471  loss_offset: 0.6546  time: 0.5315  data_time: 0.0496  lr: 0.0020177  max_mem: 11576M
[12/11 21:36:53 d2.utils.events]:  eta: 1:09:22  iter: 2139  total_loss: 2.61  loss_sem_seg: 1.294  loss_center: 0.6658  loss_offset: 0.6665  time: 0.5315  data_time: 0.0470  lr: 0.0020131  max_mem: 11576M
[12/11 21:37:04 d2.utils.events]:  eta: 1:09:12  iter: 2159  total_loss: 2.703  loss_sem_seg: 1.169  loss_center: 0.6442  loss_offset: 0.6806  time: 0.5315  data_time: 0.0529  lr: 0.0020085  max_mem: 11576M
[12/11 21:37:15 d2.utils.events]:  eta: 1:09:03  iter: 2179  total_loss: 2.32  loss_sem_seg: 1.004  loss_center: 0.5667  loss_offset: 0.6449  time: 0.5316  data_time: 0.0496  lr: 0.0020039  max_mem: 11576M
[12/11 21:37:25 d2.utils.events]:  eta: 1:08:53  iter: 2199  total_loss: 2.51  loss_sem_seg: 1.175  loss_center: 0.5845  loss_offset: 0.6457  time: 0.5316  data_time: 0.0510  lr: 0.0019993  max_mem: 11576M
[12/11 21:37:36 d2.utils.events]:  eta: 1:08:44  iter: 2219  total_loss: 2.451  loss_sem_seg: 1.291  loss_center: 0.4895  loss_offset: 0.6264  time: 0.5317  data_time: 0.0508  lr: 0.0019947  max_mem: 11576M
[12/11 21:37:47 d2.utils.events]:  eta: 1:08:34  iter: 2239  total_loss: 2.392  loss_sem_seg: 1.205  loss_center: 0.5478  loss_offset: 0.609  time: 0.5317  data_time: 0.0492  lr: 0.0019901  max_mem: 11576M
[12/11 21:37:57 d2.utils.events]:  eta: 1:08:24  iter: 2259  total_loss: 2.354  loss_sem_seg: 1.13  loss_center: 0.5992  loss_offset: 0.6662  time: 0.5317  data_time: 0.0454  lr: 0.0019854  max_mem: 11576M
[12/11 21:38:08 d2.utils.events]:  eta: 1:08:13  iter: 2279  total_loss: 2.081  loss_sem_seg: 1.012  loss_center: 0.4805  loss_offset: 0.6001  time: 0.5317  data_time: 0.0446  lr: 0.0019808  max_mem: 11576M
[12/11 21:38:19 d2.utils.events]:  eta: 1:08:02  iter: 2299  total_loss: 2.455  loss_sem_seg: 1.256  loss_center: 0.477  loss_offset: 0.6088  time: 0.5317  data_time: 0.0466  lr: 0.0019762  max_mem: 11576M
[12/11 21:38:29 d2.utils.events]:  eta: 1:07:52  iter: 2319  total_loss: 2.361  loss_sem_seg: 1.155  loss_center: 0.5227  loss_offset: 0.6165  time: 0.5317  data_time: 0.0461  lr: 0.0019716  max_mem: 11576M
[12/11 21:38:40 d2.utils.events]:  eta: 1:07:43  iter: 2339  total_loss: 2.46  loss_sem_seg: 1.252  loss_center: 0.5121  loss_offset: 0.6636  time: 0.5317  data_time: 0.0495  lr: 0.001967  max_mem: 11576M
[12/11 21:38:51 d2.utils.events]:  eta: 1:07:33  iter: 2359  total_loss: 2.34  loss_sem_seg: 1.201  loss_center: 0.5806  loss_offset: 0.5814  time: 0.5317  data_time: 0.0474  lr: 0.0019623  max_mem: 11576M
[12/11 21:39:02 d2.utils.events]:  eta: 1:07:23  iter: 2379  total_loss: 2.387  loss_sem_seg: 1.137  loss_center: 0.567  loss_offset: 0.6573  time: 0.5318  data_time: 0.0498  lr: 0.0019577  max_mem: 11576M
[12/11 21:39:12 d2.utils.events]:  eta: 1:07:12  iter: 2399  total_loss: 2.498  loss_sem_seg: 1.061  loss_center: 0.7221  loss_offset: 0.6403  time: 0.5318  data_time: 0.0475  lr: 0.0019531  max_mem: 11576M
[12/11 21:39:23 d2.utils.events]:  eta: 1:07:02  iter: 2419  total_loss: 2.531  loss_sem_seg: 1.199  loss_center: 0.5174  loss_offset: 0.6989  time: 0.5318  data_time: 0.0506  lr: 0.0019485  max_mem: 11576M
[12/11 21:39:34 d2.utils.events]:  eta: 1:06:51  iter: 2439  total_loss: 2.676  loss_sem_seg: 1.322  loss_center: 0.6429  loss_offset: 0.6373  time: 0.5318  data_time: 0.0493  lr: 0.0019438  max_mem: 11576M
[12/11 21:39:44 d2.utils.events]:  eta: 1:06:41  iter: 2459  total_loss: 2.426  loss_sem_seg: 1.292  loss_center: 0.555  loss_offset: 0.6407  time: 0.5318  data_time: 0.0460  lr: 0.0019392  max_mem: 11576M
[12/11 21:39:55 d2.utils.events]:  eta: 1:06:32  iter: 2479  total_loss: 2.58  loss_sem_seg: 1.107  loss_center: 0.6116  loss_offset: 0.6575  time: 0.5318  data_time: 0.0454  lr: 0.0019346  max_mem: 11576M
[12/11 21:40:06 d2.utils.events]:  eta: 1:06:20  iter: 2499  total_loss: 2.532  loss_sem_seg: 1.204  loss_center: 0.6848  loss_offset: 0.6664  time: 0.5318  data_time: 0.0450  lr: 0.00193  max_mem: 11576M
[12/11 21:40:16 d2.utils.events]:  eta: 1:06:09  iter: 2519  total_loss: 2.285  loss_sem_seg: 1.126  loss_center: 0.5715  loss_offset: 0.6392  time: 0.5319  data_time: 0.0546  lr: 0.0019253  max_mem: 11576M
[12/11 21:40:27 d2.utils.events]:  eta: 1:05:59  iter: 2539  total_loss: 2.203  loss_sem_seg: 1.164  loss_center: 0.413  loss_offset: 0.6054  time: 0.5319  data_time: 0.0464  lr: 0.0019207  max_mem: 11576M
[12/11 21:40:38 d2.utils.events]:  eta: 1:05:50  iter: 2559  total_loss: 2.612  loss_sem_seg: 1.295  loss_center: 0.5082  loss_offset: 0.7186  time: 0.5319  data_time: 0.0510  lr: 0.0019161  max_mem: 11576M
[12/11 21:40:48 d2.utils.events]:  eta: 1:05:41  iter: 2579  total_loss: 2.399  loss_sem_seg: 1.278  loss_center: 0.5447  loss_offset: 0.6132  time: 0.5319  data_time: 0.0467  lr: 0.0019114  max_mem: 11576M
[12/11 21:40:59 d2.utils.events]:  eta: 1:05:31  iter: 2599  total_loss: 2.345  loss_sem_seg: 1.046  loss_center: 0.6549  loss_offset: 0.576  time: 0.5319  data_time: 0.0480  lr: 0.0019068  max_mem: 11576M
[12/11 21:41:10 d2.utils.events]:  eta: 1:05:22  iter: 2619  total_loss: 2.65  loss_sem_seg: 1.448  loss_center: 0.5572  loss_offset: 0.641  time: 0.5320  data_time: 0.0498  lr: 0.0019021  max_mem: 11576M
[12/11 21:41:21 d2.utils.events]:  eta: 1:05:12  iter: 2639  total_loss: 2.508  loss_sem_seg: 1.382  loss_center: 0.4852  loss_offset: 0.7035  time: 0.5320  data_time: 0.0479  lr: 0.0018975  max_mem: 11576M
[12/11 21:41:31 d2.utils.events]:  eta: 1:05:02  iter: 2659  total_loss: 2.245  loss_sem_seg: 1.015  loss_center: 0.5994  loss_offset: 0.5651  time: 0.5320  data_time: 0.0525  lr: 0.0018929  max_mem: 11576M
[12/11 21:41:42 d2.utils.events]:  eta: 1:04:51  iter: 2679  total_loss: 2.5  loss_sem_seg: 1.213  loss_center: 0.6173  loss_offset: 0.6972  time: 0.5320  data_time: 0.0451  lr: 0.0018882  max_mem: 11576M
[12/11 21:41:53 d2.utils.events]:  eta: 1:04:41  iter: 2699  total_loss: 2.322  loss_sem_seg: 1.117  loss_center: 0.5847  loss_offset: 0.6569  time: 0.5320  data_time: 0.0483  lr: 0.0018836  max_mem: 11576M
[12/11 21:42:04 d2.utils.events]:  eta: 1:04:30  iter: 2719  total_loss: 2.261  loss_sem_seg: 1.018  loss_center: 0.4836  loss_offset: 0.5419  time: 0.5321  data_time: 0.0499  lr: 0.0018789  max_mem: 11576M
[12/11 21:42:14 d2.utils.events]:  eta: 1:04:20  iter: 2739  total_loss: 2.378  loss_sem_seg: 1.118  loss_center: 0.4914  loss_offset: 0.6535  time: 0.5321  data_time: 0.0529  lr: 0.0018743  max_mem: 11576M
[12/11 21:42:25 d2.utils.events]:  eta: 1:04:08  iter: 2759  total_loss: 2.445  loss_sem_seg: 1.147  loss_center: 0.5276  loss_offset: 0.6626  time: 0.5322  data_time: 0.0565  lr: 0.0018696  max_mem: 11576M
[12/11 21:42:36 d2.utils.events]:  eta: 1:03:59  iter: 2779  total_loss: 2.467  loss_sem_seg: 1.253  loss_center: 0.5936  loss_offset: 0.6148  time: 0.5322  data_time: 0.0504  lr: 0.001865  max_mem: 11576M
[12/11 21:42:47 d2.utils.events]:  eta: 1:03:48  iter: 2799  total_loss: 2.369  loss_sem_seg: 1.197  loss_center: 0.6326  loss_offset: 0.5557  time: 0.5322  data_time: 0.0439  lr: 0.0018603  max_mem: 11576M
[12/11 21:42:57 d2.utils.events]:  eta: 1:03:38  iter: 2819  total_loss: 2.214  loss_sem_seg: 1.141  loss_center: 0.5284  loss_offset: 0.6498  time: 0.5323  data_time: 0.0523  lr: 0.0018557  max_mem: 11576M
[12/11 21:43:08 d2.utils.events]:  eta: 1:03:28  iter: 2839  total_loss: 2.481  loss_sem_seg: 1.204  loss_center: 0.5936  loss_offset: 0.6655  time: 0.5323  data_time: 0.0450  lr: 0.001851  max_mem: 11576M
[12/11 21:43:19 d2.utils.events]:  eta: 1:03:19  iter: 2859  total_loss: 2.259  loss_sem_seg: 1.136  loss_center: 0.5127  loss_offset: 0.6375  time: 0.5322  data_time: 0.0440  lr: 0.0018464  max_mem: 11576M
[12/11 21:43:29 d2.utils.events]:  eta: 1:03:08  iter: 2879  total_loss: 2.29  loss_sem_seg: 1.1  loss_center: 0.5007  loss_offset: 0.638  time: 0.5322  data_time: 0.0482  lr: 0.0018417  max_mem: 11576M
[12/11 21:43:40 d2.utils.events]:  eta: 1:02:59  iter: 2899  total_loss: 2.228  loss_sem_seg: 1.014  loss_center: 0.532  loss_offset: 0.6064  time: 0.5323  data_time: 0.0569  lr: 0.0018371  max_mem: 11576M
[12/11 21:43:51 d2.utils.events]:  eta: 1:02:49  iter: 2919  total_loss: 2.385  loss_sem_seg: 1.058  loss_center: 0.526  loss_offset: 0.6247  time: 0.5323  data_time: 0.0479  lr: 0.0018324  max_mem: 11576M
[12/11 21:44:01 d2.utils.events]:  eta: 1:02:37  iter: 2939  total_loss: 2.297  loss_sem_seg: 1.142  loss_center: 0.5532  loss_offset: 0.6381  time: 0.5323  data_time: 0.0486  lr: 0.0018278  max_mem: 11576M
[12/11 21:44:12 d2.utils.events]:  eta: 1:02:28  iter: 2959  total_loss: 2.407  loss_sem_seg: 1.143  loss_center: 0.6255  loss_offset: 0.5473  time: 0.5324  data_time: 0.0534  lr: 0.0018231  max_mem: 11576M
[12/11 21:44:23 d2.utils.events]:  eta: 1:02:19  iter: 2979  total_loss: 2.28  loss_sem_seg: 1.204  loss_center: 0.5324  loss_offset: 0.5966  time: 0.5324  data_time: 0.0509  lr: 0.0018184  max_mem: 11576M
[12/11 21:44:34 d2.utils.events]:  eta: 1:02:10  iter: 2999  total_loss: 2.277  loss_sem_seg: 0.9923  loss_center: 0.513  loss_offset: 0.6408  time: 0.5324  data_time: 0.0503  lr: 0.0018138  max_mem: 11576M
[12/11 21:44:44 d2.utils.events]:  eta: 1:02:00  iter: 3019  total_loss: 2.395  loss_sem_seg: 1.111  loss_center: 0.5057  loss_offset: 0.6264  time: 0.5324  data_time: 0.0463  lr: 0.0018091  max_mem: 11576M
[12/11 21:44:55 d2.utils.events]:  eta: 1:01:51  iter: 3039  total_loss: 2.13  loss_sem_seg: 1.097  loss_center: 0.583  loss_offset: 0.5697  time: 0.5324  data_time: 0.0490  lr: 0.0018044  max_mem: 11576M
[12/11 21:45:06 d2.utils.events]:  eta: 1:01:39  iter: 3059  total_loss: 2.341  loss_sem_seg: 1.106  loss_center: 0.5984  loss_offset: 0.7124  time: 0.5324  data_time: 0.0486  lr: 0.0017998  max_mem: 11576M
[12/11 21:45:16 d2.utils.events]:  eta: 1:01:27  iter: 3079  total_loss: 2.302  loss_sem_seg: 1.057  loss_center: 0.6597  loss_offset: 0.5907  time: 0.5324  data_time: 0.0447  lr: 0.0017951  max_mem: 11576M
[12/11 21:45:27 d2.utils.events]:  eta: 1:01:19  iter: 3099  total_loss: 2.454  loss_sem_seg: 1.075  loss_center: 0.6492  loss_offset: 0.6357  time: 0.5324  data_time: 0.0465  lr: 0.0017904  max_mem: 11576M
[12/11 21:45:38 d2.utils.events]:  eta: 1:01:11  iter: 3119  total_loss: 2.272  loss_sem_seg: 1.037  loss_center: 0.5818  loss_offset: 0.6682  time: 0.5324  data_time: 0.0485  lr: 0.0017858  max_mem: 11576M
[12/11 21:45:48 d2.utils.events]:  eta: 1:00:59  iter: 3139  total_loss: 2.3  loss_sem_seg: 1.075  loss_center: 0.5204  loss_offset: 0.6615  time: 0.5324  data_time: 0.0461  lr: 0.0017811  max_mem: 11576M
[12/11 21:45:59 d2.utils.events]:  eta: 1:00:47  iter: 3159  total_loss: 2.432  loss_sem_seg: 1.092  loss_center: 0.66  loss_offset: 0.6415  time: 0.5324  data_time: 0.0456  lr: 0.0017764  max_mem: 11576M
[12/11 21:46:10 d2.utils.events]:  eta: 1:00:37  iter: 3179  total_loss: 2.241  loss_sem_seg: 1.1  loss_center: 0.554  loss_offset: 0.5438  time: 0.5325  data_time: 0.0498  lr: 0.0017718  max_mem: 11576M
[12/11 21:46:21 d2.utils.events]:  eta: 1:00:26  iter: 3199  total_loss: 2.352  loss_sem_seg: 1.042  loss_center: 0.5243  loss_offset: 0.5945  time: 0.5325  data_time: 0.0511  lr: 0.0017671  max_mem: 11576M
[12/11 21:46:31 d2.utils.events]:  eta: 1:00:12  iter: 3219  total_loss: 2.354  loss_sem_seg: 1.1  loss_center: 0.5676  loss_offset: 0.666  time: 0.5325  data_time: 0.0443  lr: 0.0017624  max_mem: 11576M
[12/11 21:46:42 d2.utils.events]:  eta: 1:00:02  iter: 3239  total_loss: 2.224  loss_sem_seg: 1.006  loss_center: 0.559  loss_offset: 0.6766  time: 0.5325  data_time: 0.0472  lr: 0.0017577  max_mem: 11576M
[12/11 21:46:52 d2.utils.events]:  eta: 0:59:50  iter: 3259  total_loss: 2.329  loss_sem_seg: 1.17  loss_center: 0.626  loss_offset: 0.5626  time: 0.5324  data_time: 0.0426  lr: 0.001753  max_mem: 11576M
[12/11 21:47:03 d2.utils.events]:  eta: 0:59:39  iter: 3279  total_loss: 2.233  loss_sem_seg: 1.096  loss_center: 0.6312  loss_offset: 0.6045  time: 0.5324  data_time: 0.0494  lr: 0.0017484  max_mem: 11576M
[12/11 21:47:14 d2.utils.events]:  eta: 0:59:28  iter: 3299  total_loss: 2.185  loss_sem_seg: 1.059  loss_center: 0.4474  loss_offset: 0.5939  time: 0.5324  data_time: 0.0444  lr: 0.0017437  max_mem: 11576M
[12/11 21:47:24 d2.utils.events]:  eta: 0:59:18  iter: 3319  total_loss: 2.197  loss_sem_seg: 1.059  loss_center: 0.5523  loss_offset: 0.6054  time: 0.5324  data_time: 0.0469  lr: 0.001739  max_mem: 11576M
[12/11 21:47:35 d2.utils.events]:  eta: 0:59:07  iter: 3339  total_loss: 2.178  loss_sem_seg: 0.9885  loss_center: 0.468  loss_offset: 0.5737  time: 0.5324  data_time: 0.0482  lr: 0.0017343  max_mem: 11576M
[12/11 21:47:46 d2.utils.events]:  eta: 0:58:57  iter: 3359  total_loss: 2.189  loss_sem_seg: 1.073  loss_center: 0.5245  loss_offset: 0.6413  time: 0.5324  data_time: 0.0465  lr: 0.0017296  max_mem: 11576M
[12/11 21:47:56 d2.utils.events]:  eta: 0:58:45  iter: 3379  total_loss: 2.109  loss_sem_seg: 1.018  loss_center: 0.4936  loss_offset: 0.567  time: 0.5324  data_time: 0.0472  lr: 0.0017249  max_mem: 11576M
[12/11 21:48:07 d2.utils.events]:  eta: 0:58:34  iter: 3399  total_loss: 2.251  loss_sem_seg: 0.9299  loss_center: 0.6171  loss_offset: 0.6012  time: 0.5324  data_time: 0.0547  lr: 0.0017202  max_mem: 11576M
[12/11 21:48:18 d2.utils.events]:  eta: 0:58:23  iter: 3419  total_loss: 2.276  loss_sem_seg: 1.002  loss_center: 0.5613  loss_offset: 0.5787  time: 0.5324  data_time: 0.0449  lr: 0.0017155  max_mem: 11576M
[12/11 21:48:29 d2.utils.events]:  eta: 0:58:14  iter: 3439  total_loss: 2.354  loss_sem_seg: 1.007  loss_center: 0.5317  loss_offset: 0.6671  time: 0.5325  data_time: 0.0521  lr: 0.0017109  max_mem: 11576M
[12/11 21:48:39 d2.utils.events]:  eta: 0:58:03  iter: 3459  total_loss: 2.188  loss_sem_seg: 1.06  loss_center: 0.5247  loss_offset: 0.5016  time: 0.5325  data_time: 0.0506  lr: 0.0017062  max_mem: 11576M
[12/11 21:48:50 d2.utils.events]:  eta: 0:57:52  iter: 3479  total_loss: 2.267  loss_sem_seg: 1.098  loss_center: 0.5143  loss_offset: 0.6547  time: 0.5325  data_time: 0.0547  lr: 0.0017015  max_mem: 11576M
[12/11 21:49:01 d2.utils.events]:  eta: 0:57:40  iter: 3499  total_loss: 2.118  loss_sem_seg: 1.029  loss_center: 0.5424  loss_offset: 0.6241  time: 0.5325  data_time: 0.0449  lr: 0.0016968  max_mem: 11576M
[12/11 21:49:12 d2.utils.events]:  eta: 0:57:29  iter: 3519  total_loss: 2.392  loss_sem_seg: 1.03  loss_center: 0.6071  loss_offset: 0.6665  time: 0.5326  data_time: 0.0529  lr: 0.0016921  max_mem: 11576M
[12/11 21:49:22 d2.utils.events]:  eta: 0:57:18  iter: 3539  total_loss: 2.524  loss_sem_seg: 1.06  loss_center: 0.5762  loss_offset: 0.6817  time: 0.5326  data_time: 0.0531  lr: 0.0016874  max_mem: 11576M
[12/11 21:49:33 d2.utils.events]:  eta: 0:57:08  iter: 3559  total_loss: 2.383  loss_sem_seg: 1.069  loss_center: 0.5526  loss_offset: 0.6452  time: 0.5326  data_time: 0.0481  lr: 0.0016827  max_mem: 11576M
[12/11 21:49:44 d2.utils.events]:  eta: 0:56:56  iter: 3579  total_loss: 2.402  loss_sem_seg: 1.055  loss_center: 0.5006  loss_offset: 0.6243  time: 0.5326  data_time: 0.0482  lr: 0.001678  max_mem: 11576M
[12/11 21:49:54 d2.utils.events]:  eta: 0:56:46  iter: 3599  total_loss: 2.462  loss_sem_seg: 1.092  loss_center: 0.6941  loss_offset: 0.6155  time: 0.5326  data_time: 0.0459  lr: 0.0016733  max_mem: 11576M
[12/11 21:50:05 d2.utils.events]:  eta: 0:56:34  iter: 3619  total_loss: 2.163  loss_sem_seg: 1.021  loss_center: 0.5302  loss_offset: 0.5208  time: 0.5326  data_time: 0.0431  lr: 0.0016686  max_mem: 11576M
[12/11 21:50:16 d2.utils.events]:  eta: 0:56:24  iter: 3639  total_loss: 2.018  loss_sem_seg: 0.9871  loss_center: 0.4904  loss_offset: 0.4713  time: 0.5326  data_time: 0.0492  lr: 0.0016638  max_mem: 11576M
[12/11 21:50:26 d2.utils.events]:  eta: 0:56:13  iter: 3659  total_loss: 2.178  loss_sem_seg: 1.108  loss_center: 0.4097  loss_offset: 0.6326  time: 0.5326  data_time: 0.0515  lr: 0.0016591  max_mem: 11576M
[12/11 21:50:37 d2.utils.events]:  eta: 0:56:03  iter: 3679  total_loss: 2.266  loss_sem_seg: 1.029  loss_center: 0.5633  loss_offset: 0.6385  time: 0.5326  data_time: 0.0471  lr: 0.0016544  max_mem: 11576M
[12/11 21:50:48 d2.utils.events]:  eta: 0:55:52  iter: 3699  total_loss: 2.347  loss_sem_seg: 1.127  loss_center: 0.5199  loss_offset: 0.6704  time: 0.5326  data_time: 0.0484  lr: 0.0016497  max_mem: 11576M
[12/11 21:50:58 d2.utils.events]:  eta: 0:55:41  iter: 3719  total_loss: 2.262  loss_sem_seg: 1.114  loss_center: 0.5753  loss_offset: 0.6283  time: 0.5326  data_time: 0.0448  lr: 0.001645  max_mem: 11576M
[12/11 21:51:09 d2.utils.events]:  eta: 0:55:31  iter: 3739  total_loss: 2.282  loss_sem_seg: 1.206  loss_center: 0.4583  loss_offset: 0.5794  time: 0.5326  data_time: 0.0482  lr: 0.0016403  max_mem: 11576M
[12/11 21:51:20 d2.utils.events]:  eta: 0:55:20  iter: 3759  total_loss: 2.189  loss_sem_seg: 1.024  loss_center: 0.5513  loss_offset: 0.6145  time: 0.5326  data_time: 0.0455  lr: 0.0016356  max_mem: 11576M
[12/11 21:51:30 d2.utils.events]:  eta: 0:55:08  iter: 3779  total_loss: 2.292  loss_sem_seg: 1.041  loss_center: 0.5098  loss_offset: 0.6119  time: 0.5326  data_time: 0.0444  lr: 0.0016309  max_mem: 11576M
[12/11 21:51:41 d2.utils.events]:  eta: 0:54:58  iter: 3799  total_loss: 2.248  loss_sem_seg: 1.037  loss_center: 0.574  loss_offset: 0.5313  time: 0.5326  data_time: 0.0457  lr: 0.0016261  max_mem: 11576M
[12/11 21:51:52 d2.utils.events]:  eta: 0:54:47  iter: 3819  total_loss: 2.366  loss_sem_seg: 1.058  loss_center: 0.4861  loss_offset: 0.6274  time: 0.5326  data_time: 0.0469  lr: 0.0016214  max_mem: 11576M
[12/11 21:52:02 d2.utils.events]:  eta: 0:54:34  iter: 3839  total_loss: 2.107  loss_sem_seg: 0.9283  loss_center: 0.6302  loss_offset: 0.5522  time: 0.5326  data_time: 0.0499  lr: 0.0016167  max_mem: 11576M
[12/11 21:52:13 d2.utils.events]:  eta: 0:54:24  iter: 3859  total_loss: 1.945  loss_sem_seg: 0.8116  loss_center: 0.5735  loss_offset: 0.5314  time: 0.5326  data_time: 0.0452  lr: 0.001612  max_mem: 11576M
[12/11 21:52:24 d2.utils.events]:  eta: 0:54:13  iter: 3879  total_loss: 2.148  loss_sem_seg: 0.9581  loss_center: 0.5053  loss_offset: 0.5138  time: 0.5326  data_time: 0.0449  lr: 0.0016072  max_mem: 11576M
[12/11 21:52:34 d2.utils.events]:  eta: 0:54:02  iter: 3899  total_loss: 2.313  loss_sem_seg: 1.02  loss_center: 0.5749  loss_offset: 0.7317  time: 0.5326  data_time: 0.0476  lr: 0.0016025  max_mem: 11576M
[12/11 21:52:45 d2.utils.events]:  eta: 0:53:51  iter: 3919  total_loss: 2.464  loss_sem_seg: 0.9999  loss_center: 0.6321  loss_offset: 0.5963  time: 0.5326  data_time: 0.0468  lr: 0.0015978  max_mem: 11576M
[12/11 21:52:56 d2.utils.events]:  eta: 0:53:40  iter: 3939  total_loss: 2.177  loss_sem_seg: 0.9423  loss_center: 0.5002  loss_offset: 0.591  time: 0.5326  data_time: 0.0469  lr: 0.0015931  max_mem: 11576M
[12/11 21:53:06 d2.utils.events]:  eta: 0:53:29  iter: 3959  total_loss: 2.374  loss_sem_seg: 1.095  loss_center: 0.6267  loss_offset: 0.6023  time: 0.5326  data_time: 0.0483  lr: 0.0015883  max_mem: 11576M
[12/11 21:53:17 d2.utils.events]:  eta: 0:53:18  iter: 3979  total_loss: 2.146  loss_sem_seg: 0.9067  loss_center: 0.5858  loss_offset: 0.5874  time: 0.5326  data_time: 0.0430  lr: 0.0015836  max_mem: 11576M
[12/11 21:53:28 d2.utils.events]:  eta: 0:53:07  iter: 3999  total_loss: 2.209  loss_sem_seg: 1.035  loss_center: 0.5083  loss_offset: 0.6287  time: 0.5326  data_time: 0.0497  lr: 0.0015789  max_mem: 11576M
[12/11 21:53:38 d2.utils.events]:  eta: 0:52:57  iter: 4019  total_loss: 2.201  loss_sem_seg: 1.02  loss_center: 0.5371  loss_offset: 0.6075  time: 0.5326  data_time: 0.0515  lr: 0.0015741  max_mem: 11576M
[12/11 21:53:49 d2.utils.events]:  eta: 0:52:46  iter: 4039  total_loss: 2.421  loss_sem_seg: 0.9178  loss_center: 0.6836  loss_offset: 0.6485  time: 0.5326  data_time: 0.0494  lr: 0.0015694  max_mem: 11576M
[12/11 21:54:00 d2.utils.events]:  eta: 0:52:36  iter: 4059  total_loss: 2.178  loss_sem_seg: 0.9648  loss_center: 0.6021  loss_offset: 0.6371  time: 0.5326  data_time: 0.0507  lr: 0.0015646  max_mem: 11576M
[12/11 21:54:11 d2.utils.events]:  eta: 0:52:25  iter: 4079  total_loss: 2.337  loss_sem_seg: 1.025  loss_center: 0.5858  loss_offset: 0.6516  time: 0.5327  data_time: 0.0524  lr: 0.0015599  max_mem: 11576M
[12/11 21:54:21 d2.utils.events]:  eta: 0:52:13  iter: 4099  total_loss: 2.119  loss_sem_seg: 0.942  loss_center: 0.5907  loss_offset: 0.5678  time: 0.5326  data_time: 0.0451  lr: 0.0015552  max_mem: 11576M
[12/11 21:54:32 d2.utils.events]:  eta: 0:52:01  iter: 4119  total_loss: 2.069  loss_sem_seg: 1.045  loss_center: 0.4983  loss_offset: 0.5852  time: 0.5326  data_time: 0.0459  lr: 0.0015504  max_mem: 11576M
[12/11 21:54:43 d2.utils.events]:  eta: 0:51:51  iter: 4139  total_loss: 2.133  loss_sem_seg: 1.083  loss_center: 0.493  loss_offset: 0.5681  time: 0.5326  data_time: 0.0478  lr: 0.0015457  max_mem: 11576M
[12/11 21:54:53 d2.utils.events]:  eta: 0:51:41  iter: 4159  total_loss: 2.094  loss_sem_seg: 0.9737  loss_center: 0.4267  loss_offset: 0.6124  time: 0.5327  data_time: 0.0492  lr: 0.0015409  max_mem: 11576M
[12/11 21:55:04 d2.utils.events]:  eta: 0:51:30  iter: 4179  total_loss: 2.22  loss_sem_seg: 1.049  loss_center: 0.5235  loss_offset: 0.625  time: 0.5327  data_time: 0.0512  lr: 0.0015362  max_mem: 11576M
[12/11 21:55:15 d2.utils.events]:  eta: 0:51:20  iter: 4199  total_loss: 2.352  loss_sem_seg: 0.9763  loss_center: 0.5834  loss_offset: 0.5544  time: 0.5327  data_time: 0.0442  lr: 0.0015314  max_mem: 11576M
[12/11 21:55:26 d2.utils.events]:  eta: 0:51:11  iter: 4219  total_loss: 2.183  loss_sem_seg: 1.045  loss_center: 0.5028  loss_offset: 0.5787  time: 0.5327  data_time: 0.0501  lr: 0.0015267  max_mem: 11576M
[12/11 21:55:36 d2.utils.events]:  eta: 0:50:59  iter: 4239  total_loss: 2.067  loss_sem_seg: 0.8745  loss_center: 0.4744  loss_offset: 0.6224  time: 0.5327  data_time: 0.0500  lr: 0.0015219  max_mem: 11576M
[12/11 21:55:47 d2.utils.events]:  eta: 0:50:48  iter: 4259  total_loss: 2.049  loss_sem_seg: 0.9014  loss_center: 0.5706  loss_offset: 0.5931  time: 0.5327  data_time: 0.0471  lr: 0.0015172  max_mem: 11576M
[12/11 21:55:57 d2.utils.events]:  eta: 0:50:37  iter: 4279  total_loss: 1.987  loss_sem_seg: 0.8735  loss_center: 0.4771  loss_offset: 0.5112  time: 0.5327  data_time: 0.0435  lr: 0.0015124  max_mem: 11576M
[12/11 21:56:08 d2.utils.events]:  eta: 0:50:26  iter: 4299  total_loss: 2.272  loss_sem_seg: 1.105  loss_center: 0.4931  loss_offset: 0.5939  time: 0.5327  data_time: 0.0522  lr: 0.0015076  max_mem: 11576M
[12/11 21:56:19 d2.utils.events]:  eta: 0:50:15  iter: 4319  total_loss: 2.1  loss_sem_seg: 0.9806  loss_center: 0.5026  loss_offset: 0.5883  time: 0.5327  data_time: 0.0464  lr: 0.0015029  max_mem: 11576M
[12/11 21:56:30 d2.utils.events]:  eta: 0:50:04  iter: 4339  total_loss: 2.173  loss_sem_seg: 0.9843  loss_center: 0.6386  loss_offset: 0.5736  time: 0.5327  data_time: 0.0498  lr: 0.0014981  max_mem: 11576M
[12/11 21:56:40 d2.utils.events]:  eta: 0:49:53  iter: 4359  total_loss: 2.186  loss_sem_seg: 0.9806  loss_center: 0.5306  loss_offset: 0.6187  time: 0.5327  data_time: 0.0499  lr: 0.0014933  max_mem: 11576M
[12/11 21:56:51 d2.utils.events]:  eta: 0:49:43  iter: 4379  total_loss: 2.179  loss_sem_seg: 1.056  loss_center: 0.5975  loss_offset: 0.6344  time: 0.5327  data_time: 0.0506  lr: 0.0014886  max_mem: 11576M
[12/11 21:57:02 d2.utils.events]:  eta: 0:49:32  iter: 4399  total_loss: 2.231  loss_sem_seg: 1.076  loss_center: 0.5231  loss_offset: 0.5766  time: 0.5327  data_time: 0.0513  lr: 0.0014838  max_mem: 11576M
[12/11 21:57:13 d2.utils.events]:  eta: 0:49:22  iter: 4419  total_loss: 2.29  loss_sem_seg: 1.114  loss_center: 0.5211  loss_offset: 0.6235  time: 0.5328  data_time: 0.0507  lr: 0.001479  max_mem: 11576M
[12/11 21:57:23 d2.utils.events]:  eta: 0:49:11  iter: 4439  total_loss: 2.101  loss_sem_seg: 0.8316  loss_center: 0.5553  loss_offset: 0.5887  time: 0.5328  data_time: 0.0509  lr: 0.0014743  max_mem: 11576M
[12/11 21:57:34 d2.utils.events]:  eta: 0:49:01  iter: 4459  total_loss: 2.013  loss_sem_seg: 0.927  loss_center: 0.4978  loss_offset: 0.6114  time: 0.5328  data_time: 0.0513  lr: 0.0014695  max_mem: 11576M
[12/11 21:57:45 d2.utils.events]:  eta: 0:48:50  iter: 4479  total_loss: 1.945  loss_sem_seg: 0.875  loss_center: 0.5582  loss_offset: 0.5351  time: 0.5328  data_time: 0.0518  lr: 0.0014647  max_mem: 11576M
[12/11 21:57:56 d2.utils.events]:  eta: 0:48:40  iter: 4499  total_loss: 2.135  loss_sem_seg: 1.044  loss_center: 0.5495  loss_offset: 0.5436  time: 0.5328  data_time: 0.0533  lr: 0.0014599  max_mem: 11576M
[12/11 21:58:06 d2.utils.events]:  eta: 0:48:29  iter: 4519  total_loss: 2.048  loss_sem_seg: 0.9564  loss_center: 0.47  loss_offset: 0.6511  time: 0.5329  data_time: 0.0529  lr: 0.0014552  max_mem: 11576M
[12/11 21:58:17 d2.utils.events]:  eta: 0:48:20  iter: 4539  total_loss: 2.059  loss_sem_seg: 1.055  loss_center: 0.4366  loss_offset: 0.6069  time: 0.5329  data_time: 0.0500  lr: 0.0014504  max_mem: 11576M
[12/11 21:58:28 d2.utils.events]:  eta: 0:48:08  iter: 4559  total_loss: 2.318  loss_sem_seg: 1.08  loss_center: 0.5588  loss_offset: 0.6146  time: 0.5329  data_time: 0.0469  lr: 0.0014456  max_mem: 11576M
[12/11 21:58:39 d2.utils.events]:  eta: 0:47:57  iter: 4579  total_loss: 2.179  loss_sem_seg: 1.047  loss_center: 0.5946  loss_offset: 0.5605  time: 0.5329  data_time: 0.0470  lr: 0.0014408  max_mem: 11576M
[12/11 21:58:49 d2.utils.events]:  eta: 0:47:47  iter: 4599  total_loss: 2.302  loss_sem_seg: 1.059  loss_center: 0.5884  loss_offset: 0.5977  time: 0.5329  data_time: 0.0538  lr: 0.001436  max_mem: 11576M
[12/11 21:59:00 d2.utils.events]:  eta: 0:47:36  iter: 4619  total_loss: 2.067  loss_sem_seg: 0.9437  loss_center: 0.4711  loss_offset: 0.5324  time: 0.5329  data_time: 0.0483  lr: 0.0014313  max_mem: 11576M
[12/11 21:59:11 d2.utils.events]:  eta: 0:47:26  iter: 4639  total_loss: 2.239  loss_sem_seg: 1.013  loss_center: 0.448  loss_offset: 0.5906  time: 0.5329  data_time: 0.0453  lr: 0.0014265  max_mem: 11576M
[12/11 21:59:21 d2.utils.events]:  eta: 0:47:15  iter: 4659  total_loss: 1.99  loss_sem_seg: 0.9705  loss_center: 0.5117  loss_offset: 0.5574  time: 0.5329  data_time: 0.0449  lr: 0.0014217  max_mem: 11576M
[12/11 21:59:32 d2.utils.events]:  eta: 0:47:05  iter: 4679  total_loss: 2.127  loss_sem_seg: 1.016  loss_center: 0.5365  loss_offset: 0.5797  time: 0.5329  data_time: 0.0561  lr: 0.0014169  max_mem: 11576M
[12/11 21:59:43 d2.utils.events]:  eta: 0:46:54  iter: 4699  total_loss: 2.03  loss_sem_seg: 0.8066  loss_center: 0.5515  loss_offset: 0.5833  time: 0.5330  data_time: 0.0532  lr: 0.0014121  max_mem: 11576M
[12/11 21:59:54 d2.utils.events]:  eta: 0:46:43  iter: 4719  total_loss: 2.016  loss_sem_seg: 0.8921  loss_center: 0.5042  loss_offset: 0.5772  time: 0.5330  data_time: 0.0522  lr: 0.0014073  max_mem: 11576M
[12/11 22:00:04 d2.utils.events]:  eta: 0:46:32  iter: 4739  total_loss: 2.155  loss_sem_seg: 0.9318  loss_center: 0.4968  loss_offset: 0.5979  time: 0.5330  data_time: 0.0469  lr: 0.0014025  max_mem: 11576M
[12/11 22:00:15 d2.utils.events]:  eta: 0:46:22  iter: 4759  total_loss: 2.313  loss_sem_seg: 0.9881  loss_center: 0.5204  loss_offset: 0.5807  time: 0.5330  data_time: 0.0515  lr: 0.0013977  max_mem: 11576M
[12/11 22:00:26 d2.utils.events]:  eta: 0:46:11  iter: 4779  total_loss: 2.176  loss_sem_seg: 1.038  loss_center: 0.5147  loss_offset: 0.5779  time: 0.5330  data_time: 0.0474  lr: 0.0013929  max_mem: 11576M
[12/11 22:00:37 d2.utils.events]:  eta: 0:46:00  iter: 4799  total_loss: 2.188  loss_sem_seg: 1.047  loss_center: 0.5862  loss_offset: 0.6657  time: 0.5330  data_time: 0.0495  lr: 0.0013881  max_mem: 11576M
[12/11 22:00:47 d2.utils.events]:  eta: 0:45:50  iter: 4819  total_loss: 2.056  loss_sem_seg: 0.9641  loss_center: 0.4975  loss_offset: 0.5398  time: 0.5330  data_time: 0.0499  lr: 0.0013833  max_mem: 11576M
[12/11 22:00:58 d2.utils.events]:  eta: 0:45:40  iter: 4839  total_loss: 2.076  loss_sem_seg: 0.9038  loss_center: 0.5002  loss_offset: 0.5647  time: 0.5330  data_time: 0.0474  lr: 0.0013785  max_mem: 11576M
[12/11 22:01:09 d2.utils.events]:  eta: 0:45:31  iter: 4859  total_loss: 2.191  loss_sem_seg: 0.9481  loss_center: 0.5335  loss_offset: 0.5654  time: 0.5330  data_time: 0.0499  lr: 0.0013737  max_mem: 11576M
[12/11 22:01:19 d2.utils.events]:  eta: 0:45:21  iter: 4879  total_loss: 2.119  loss_sem_seg: 0.9356  loss_center: 0.5266  loss_offset: 0.6119  time: 0.5330  data_time: 0.0491  lr: 0.0013689  max_mem: 11576M
[12/11 22:01:30 d2.utils.events]:  eta: 0:45:10  iter: 4899  total_loss: 2.095  loss_sem_seg: 0.8728  loss_center: 0.465  loss_offset: 0.5458  time: 0.5330  data_time: 0.0448  lr: 0.001364  max_mem: 11576M
[12/11 22:01:41 d2.utils.events]:  eta: 0:45:00  iter: 4919  total_loss: 2.165  loss_sem_seg: 0.9451  loss_center: 0.5919  loss_offset: 0.6312  time: 0.5330  data_time: 0.0481  lr: 0.0013592  max_mem: 11576M
[12/11 22:01:51 d2.utils.events]:  eta: 0:44:51  iter: 4939  total_loss: 2.062  loss_sem_seg: 0.8939  loss_center: 0.4381  loss_offset: 0.6291  time: 0.5330  data_time: 0.0493  lr: 0.0013544  max_mem: 11576M
[12/11 22:02:02 d2.utils.events]:  eta: 0:44:42  iter: 4959  total_loss: 2.129  loss_sem_seg: 0.983  loss_center: 0.4843  loss_offset: 0.5488  time: 0.5330  data_time: 0.0497  lr: 0.0013496  max_mem: 11576M
[12/11 22:02:13 d2.utils.events]:  eta: 0:44:31  iter: 4979  total_loss: 2.221  loss_sem_seg: 0.9896  loss_center: 0.494  loss_offset: 0.652  time: 0.5330  data_time: 0.0422  lr: 0.0013448  max_mem: 11576M
[12/11 22:02:23 fvcore.common.checkpoint]: Saving checkpoint to ./output/model_0004999.pth
[12/11 22:02:24 d2.utils.events]:  eta: 0:44:20  iter: 4999  total_loss: 1.995  loss_sem_seg: 0.9089  loss_center: 0.5163  loss_offset: 0.5655  time: 0.5330  data_time: 0.0498  lr: 0.00134  max_mem: 11576M
[12/11 22:02:35 d2.utils.events]:  eta: 0:44:09  iter: 5019  total_loss: 1.971  loss_sem_seg: 0.9161  loss_center: 0.5493  loss_offset: 0.5392  time: 0.5330  data_time: 0.0492  lr: 0.0013351  max_mem: 11576M
[12/11 22:02:46 d2.utils.events]:  eta: 0:43:59  iter: 5039  total_loss: 2.122  loss_sem_seg: 0.99  loss_center: 0.5002  loss_offset: 0.5285  time: 0.5330  data_time: 0.0505  lr: 0.0013303  max_mem: 11576M
[12/11 22:02:57 d2.utils.events]:  eta: 0:43:49  iter: 5059  total_loss: 2.076  loss_sem_seg: 0.9763  loss_center: 0.5607  loss_offset: 0.5895  time: 0.5330  data_time: 0.0479  lr: 0.0013255  max_mem: 11576M
[12/11 22:03:08 d2.utils.events]:  eta: 0:43:38  iter: 5079  total_loss: 2.198  loss_sem_seg: 1.015  loss_center: 0.4636  loss_offset: 0.6773  time: 0.5330  data_time: 0.0504  lr: 0.0013207  max_mem: 11576M
[12/11 22:03:18 d2.utils.events]:  eta: 0:43:28  iter: 5099  total_loss: 2.103  loss_sem_seg: 0.9828  loss_center: 0.5498  loss_offset: 0.5629  time: 0.5330  data_time: 0.0480  lr: 0.0013158  max_mem: 11576M
[12/11 22:03:29 d2.utils.events]:  eta: 0:43:18  iter: 5119  total_loss: 2.09  loss_sem_seg: 1.005  loss_center: 0.4941  loss_offset: 0.5719  time: 0.5330  data_time: 0.0495  lr: 0.001311  max_mem: 11576M
[12/11 22:03:40 d2.utils.events]:  eta: 0:43:06  iter: 5139  total_loss: 1.941  loss_sem_seg: 0.7876  loss_center: 0.525  loss_offset: 0.5398  time: 0.5330  data_time: 0.0495  lr: 0.0013062  max_mem: 11576M
[12/11 22:03:50 d2.utils.events]:  eta: 0:42:56  iter: 5159  total_loss: 2.134  loss_sem_seg: 0.9782  loss_center: 0.5425  loss_offset: 0.5943  time: 0.5330  data_time: 0.0484  lr: 0.0013013  max_mem: 11576M
[12/11 22:04:01 d2.utils.events]:  eta: 0:42:45  iter: 5179  total_loss: 2.022  loss_sem_seg: 0.9058  loss_center: 0.5297  loss_offset: 0.5533  time: 0.5330  data_time: 0.0487  lr: 0.0012965  max_mem: 11576M
[12/11 22:04:12 d2.utils.events]:  eta: 0:42:34  iter: 5199  total_loss: 2.177  loss_sem_seg: 0.9774  loss_center: 0.6021  loss_offset: 0.5374  time: 0.5330  data_time: 0.0482  lr: 0.0012916  max_mem: 11576M
[12/11 22:04:22 d2.utils.events]:  eta: 0:42:23  iter: 5219  total_loss: 1.98  loss_sem_seg: 0.9159  loss_center: 0.5533  loss_offset: 0.5693  time: 0.5330  data_time: 0.0491  lr: 0.0012868  max_mem: 11576M
[12/11 22:04:33 d2.utils.events]:  eta: 0:42:12  iter: 5239  total_loss: 2.023  loss_sem_seg: 0.8853  loss_center: 0.4546  loss_offset: 0.5876  time: 0.5330  data_time: 0.0497  lr: 0.0012819  max_mem: 11576M
[12/11 22:04:44 d2.utils.events]:  eta: 0:42:02  iter: 5259  total_loss: 2.219  loss_sem_seg: 0.9404  loss_center: 0.5059  loss_offset: 0.556  time: 0.5331  data_time: 0.0558  lr: 0.0012771  max_mem: 11576M
[12/11 22:04:55 d2.utils.events]:  eta: 0:41:52  iter: 5279  total_loss: 2.099  loss_sem_seg: 1.005  loss_center: 0.5331  loss_offset: 0.681  time: 0.5331  data_time: 0.0470  lr: 0.0012722  max_mem: 11576M
[12/11 22:05:05 d2.utils.events]:  eta: 0:41:41  iter: 5299  total_loss: 2.036  loss_sem_seg: 0.9341  loss_center: 0.5124  loss_offset: 0.5101  time: 0.5330  data_time: 0.0426  lr: 0.0012674  max_mem: 11576M
[12/11 22:05:16 d2.utils.events]:  eta: 0:41:31  iter: 5319  total_loss: 2.177  loss_sem_seg: 0.8571  loss_center: 0.6443  loss_offset: 0.6232  time: 0.5330  data_time: 0.0506  lr: 0.0012625  max_mem: 11576M
[12/11 22:05:27 d2.utils.events]:  eta: 0:41:22  iter: 5339  total_loss: 2.107  loss_sem_seg: 0.918  loss_center: 0.601  loss_offset: 0.5873  time: 0.5330  data_time: 0.0489  lr: 0.0012577  max_mem: 11576M
[12/11 22:05:37 d2.utils.events]:  eta: 0:41:11  iter: 5359  total_loss: 1.976  loss_sem_seg: 0.8859  loss_center: 0.5778  loss_offset: 0.5745  time: 0.5330  data_time: 0.0462  lr: 0.0012528  max_mem: 11576M
[12/11 22:05:48 d2.utils.events]:  eta: 0:41:00  iter: 5379  total_loss: 2.042  loss_sem_seg: 0.8863  loss_center: 0.568  loss_offset: 0.5583  time: 0.5331  data_time: 0.0508  lr: 0.001248  max_mem: 11576M
[12/11 22:05:59 d2.utils.events]:  eta: 0:40:50  iter: 5399  total_loss: 2.156  loss_sem_seg: 0.8733  loss_center: 0.4908  loss_offset: 0.6754  time: 0.5331  data_time: 0.0468  lr: 0.0012431  max_mem: 11576M
[12/11 22:06:09 d2.utils.events]:  eta: 0:40:39  iter: 5419  total_loss: 2.079  loss_sem_seg: 0.9981  loss_center: 0.5878  loss_offset: 0.5003  time: 0.5331  data_time: 0.0495  lr: 0.0012382  max_mem: 11576M
[12/11 22:06:20 d2.utils.events]:  eta: 0:40:28  iter: 5439  total_loss: 1.945  loss_sem_seg: 0.8515  loss_center: 0.5155  loss_offset: 0.4875  time: 0.5331  data_time: 0.0436  lr: 0.0012334  max_mem: 11576M
[12/11 22:06:31 d2.utils.events]:  eta: 0:40:17  iter: 5459  total_loss: 2.037  loss_sem_seg: 0.9757  loss_center: 0.525  loss_offset: 0.6286  time: 0.5331  data_time: 0.0551  lr: 0.0012285  max_mem: 11576M
[12/11 22:06:42 d2.utils.events]:  eta: 0:40:06  iter: 5479  total_loss: 2.042  loss_sem_seg: 0.7711  loss_center: 0.5496  loss_offset: 0.5842  time: 0.5331  data_time: 0.0563  lr: 0.0012236  max_mem: 11576M
[12/11 22:06:52 d2.utils.events]:  eta: 0:39:55  iter: 5499  total_loss: 1.894  loss_sem_seg: 0.799  loss_center: 0.5426  loss_offset: 0.6075  time: 0.5331  data_time: 0.0476  lr: 0.0012188  max_mem: 11576M
[12/11 22:07:03 d2.utils.events]:  eta: 0:39:44  iter: 5519  total_loss: 2.146  loss_sem_seg: 1.03  loss_center: 0.4815  loss_offset: 0.6055  time: 0.5331  data_time: 0.0499  lr: 0.0012139  max_mem: 11576M
[12/11 22:07:14 d2.utils.events]:  eta: 0:39:33  iter: 5539  total_loss: 1.95  loss_sem_seg: 0.9464  loss_center: 0.6032  loss_offset: 0.5146  time: 0.5331  data_time: 0.0478  lr: 0.001209  max_mem: 11576M
[12/11 22:07:24 d2.utils.events]:  eta: 0:39:23  iter: 5559  total_loss: 2.05  loss_sem_seg: 0.9235  loss_center: 0.5272  loss_offset: 0.6023  time: 0.5331  data_time: 0.0506  lr: 0.0012041  max_mem: 11576M
[12/11 22:07:35 d2.utils.events]:  eta: 0:39:12  iter: 5579  total_loss: 1.997  loss_sem_seg: 0.9204  loss_center: 0.5921  loss_offset: 0.5256  time: 0.5331  data_time: 0.0472  lr: 0.0011992  max_mem: 11576M
[12/11 22:07:46 d2.utils.events]:  eta: 0:39:01  iter: 5599  total_loss: 2.272  loss_sem_seg: 1.046  loss_center: 0.5069  loss_offset: 0.5614  time: 0.5331  data_time: 0.0468  lr: 0.0011944  max_mem: 11576M
[12/11 22:07:56 d2.utils.events]:  eta: 0:38:51  iter: 5619  total_loss: 1.962  loss_sem_seg: 0.8989  loss_center: 0.5094  loss_offset: 0.5447  time: 0.5331  data_time: 0.0483  lr: 0.0011895  max_mem: 11576M
[12/11 22:08:07 d2.utils.events]:  eta: 0:38:40  iter: 5639  total_loss: 2.022  loss_sem_seg: 0.8479  loss_center: 0.5666  loss_offset: 0.6087  time: 0.5331  data_time: 0.0500  lr: 0.0011846  max_mem: 11576M
[12/11 22:08:18 d2.utils.events]:  eta: 0:38:30  iter: 5659  total_loss: 2.195  loss_sem_seg: 0.9829  loss_center: 0.4718  loss_offset: 0.6702  time: 0.5331  data_time: 0.0457  lr: 0.0011797  max_mem: 11576M
[12/11 22:08:29 d2.utils.events]:  eta: 0:38:19  iter: 5679  total_loss: 2.164  loss_sem_seg: 0.9635  loss_center: 0.5022  loss_offset: 0.5487  time: 0.5331  data_time: 0.0509  lr: 0.0011748  max_mem: 11576M
[12/11 22:08:39 d2.utils.events]:  eta: 0:38:09  iter: 5699  total_loss: 2.053  loss_sem_seg: 0.8374  loss_center: 0.5445  loss_offset: 0.5133  time: 0.5332  data_time: 0.0566  lr: 0.0011699  max_mem: 11576M
[12/11 22:08:50 d2.utils.events]:  eta: 0:37:59  iter: 5719  total_loss: 2.209  loss_sem_seg: 1.022  loss_center: 0.5164  loss_offset: 0.5729  time: 0.5332  data_time: 0.0517  lr: 0.001165  max_mem: 11576M
[12/11 22:09:01 d2.utils.events]:  eta: 0:37:49  iter: 5739  total_loss: 1.981  loss_sem_seg: 0.9223  loss_center: 0.4988  loss_offset: 0.5752  time: 0.5332  data_time: 0.0507  lr: 0.0011601  max_mem: 11576M
[12/11 22:09:12 d2.utils.events]:  eta: 0:37:38  iter: 5759  total_loss: 2.018  loss_sem_seg: 0.9498  loss_center: 0.4174  loss_offset: 0.4822  time: 0.5332  data_time: 0.0490  lr: 0.0011552  max_mem: 11576M
[12/11 22:09:22 d2.utils.events]:  eta: 0:37:27  iter: 5779  total_loss: 1.91  loss_sem_seg: 0.9855  loss_center: 0.3979  loss_offset: 0.5538  time: 0.5332  data_time: 0.0535  lr: 0.0011503  max_mem: 11576M
[12/11 22:09:33 d2.utils.events]:  eta: 0:37:16  iter: 5799  total_loss: 2.16  loss_sem_seg: 0.9966  loss_center: 0.5735  loss_offset: 0.4869  time: 0.5332  data_time: 0.0531  lr: 0.0011454  max_mem: 11576M
[12/11 22:09:44 d2.utils.events]:  eta: 0:37:06  iter: 5819  total_loss: 2.017  loss_sem_seg: 0.9408  loss_center: 0.4718  loss_offset: 0.519  time: 0.5332  data_time: 0.0512  lr: 0.0011405  max_mem: 11576M
[12/11 22:09:55 d2.utils.events]:  eta: 0:36:55  iter: 5839  total_loss: 2.052  loss_sem_seg: 0.8754  loss_center: 0.632  loss_offset: 0.4865  time: 0.5332  data_time: 0.0483  lr: 0.0011356  max_mem: 11576M
[12/11 22:10:05 d2.utils.events]:  eta: 0:36:44  iter: 5859  total_loss: 2.1  loss_sem_seg: 0.8223  loss_center: 0.5093  loss_offset: 0.5913  time: 0.5332  data_time: 0.0526  lr: 0.0011307  max_mem: 11576M
[12/11 22:10:16 d2.utils.events]:  eta: 0:36:33  iter: 5879  total_loss: 2.131  loss_sem_seg: 0.9373  loss_center: 0.5287  loss_offset: 0.6329  time: 0.5333  data_time: 0.0510  lr: 0.0011258  max_mem: 11576M
[12/11 22:10:27 d2.utils.events]:  eta: 0:36:23  iter: 5899  total_loss: 1.818  loss_sem_seg: 0.8713  loss_center: 0.5404  loss_offset: 0.5082  time: 0.5333  data_time: 0.0517  lr: 0.0011208  max_mem: 11576M
[12/11 22:10:38 d2.utils.events]:  eta: 0:36:12  iter: 5919  total_loss: 2.034  loss_sem_seg: 0.8787  loss_center: 0.5201  loss_offset: 0.5921  time: 0.5333  data_time: 0.0506  lr: 0.0011159  max_mem: 11576M
[12/11 22:10:48 d2.utils.events]:  eta: 0:36:02  iter: 5939  total_loss: 1.965  loss_sem_seg: 0.9184  loss_center: 0.5456  loss_offset: 0.5612  time: 0.5333  data_time: 0.0542  lr: 0.001111  max_mem: 11576M
[12/11 22:10:59 d2.utils.events]:  eta: 0:35:51  iter: 5959  total_loss: 2.088  loss_sem_seg: 0.9416  loss_center: 0.6043  loss_offset: 0.5695  time: 0.5333  data_time: 0.0480  lr: 0.0011061  max_mem: 11576M
[12/11 22:11:10 d2.utils.events]:  eta: 0:35:40  iter: 5979  total_loss: 2.034  loss_sem_seg: 0.9232  loss_center: 0.6084  loss_offset: 0.5567  time: 0.5333  data_time: 0.0496  lr: 0.0011011  max_mem: 11576M
[12/11 22:11:20 d2.utils.events]:  eta: 0:35:30  iter: 5999  total_loss: 1.924  loss_sem_seg: 0.9461  loss_center: 0.4015  loss_offset: 0.5002  time: 0.5333  data_time: 0.0487  lr: 0.0010962  max_mem: 11576M
[12/11 22:11:31 d2.utils.events]:  eta: 0:35:19  iter: 6019  total_loss: 1.978  loss_sem_seg: 0.9473  loss_center: 0.545  loss_offset: 0.5634  time: 0.5333  data_time: 0.0490  lr: 0.0010913  max_mem: 11576M
[12/11 22:11:42 d2.utils.events]:  eta: 0:35:09  iter: 6039  total_loss: 2.08  loss_sem_seg: 0.9633  loss_center: 0.5719  loss_offset: 0.5445  time: 0.5333  data_time: 0.0540  lr: 0.0010863  max_mem: 11576M
[12/11 22:11:53 d2.utils.events]:  eta: 0:34:58  iter: 6059  total_loss: 2.008  loss_sem_seg: 0.8841  loss_center: 0.548  loss_offset: 0.5458  time: 0.5333  data_time: 0.0456  lr: 0.0010814  max_mem: 11576M
[12/11 22:12:03 d2.utils.events]:  eta: 0:34:47  iter: 6079  total_loss: 2.107  loss_sem_seg: 1.038  loss_center: 0.5367  loss_offset: 0.6215  time: 0.5333  data_time: 0.0487  lr: 0.0010765  max_mem: 11576M
[12/11 22:12:14 d2.utils.events]:  eta: 0:34:36  iter: 6099  total_loss: 1.918  loss_sem_seg: 0.9555  loss_center: 0.5452  loss_offset: 0.5201  time: 0.5333  data_time: 0.0528  lr: 0.0010715  max_mem: 11576M
[12/11 22:12:25 d2.utils.events]:  eta: 0:34:26  iter: 6119  total_loss: 2.159  loss_sem_seg: 0.8948  loss_center: 0.6109  loss_offset: 0.5655  time: 0.5333  data_time: 0.0523  lr: 0.0010666  max_mem: 11576M
[12/11 22:12:35 d2.utils.events]:  eta: 0:34:16  iter: 6139  total_loss: 1.802  loss_sem_seg: 0.7918  loss_center: 0.4473  loss_offset: 0.5681  time: 0.5334  data_time: 0.0525  lr: 0.0010616  max_mem: 11576M
[12/11 22:12:46 d2.utils.events]:  eta: 0:34:06  iter: 6159  total_loss: 1.905  loss_sem_seg: 0.8658  loss_center: 0.4369  loss_offset: 0.6469  time: 0.5334  data_time: 0.0513  lr: 0.0010567  max_mem: 11576M
[12/11 22:12:57 d2.utils.events]:  eta: 0:33:55  iter: 6179  total_loss: 1.991  loss_sem_seg: 0.8316  loss_center: 0.5325  loss_offset: 0.5362  time: 0.5334  data_time: 0.0467  lr: 0.0010517  max_mem: 11576M
[12/11 22:13:08 d2.utils.events]:  eta: 0:33:46  iter: 6199  total_loss: 1.976  loss_sem_seg: 0.8777  loss_center: 0.4866  loss_offset: 0.585  time: 0.5334  data_time: 0.0499  lr: 0.0010468  max_mem: 11576M
[12/11 22:13:19 d2.utils.events]:  eta: 0:33:36  iter: 6219  total_loss: 2.192  loss_sem_seg: 1.027  loss_center: 0.5605  loss_offset: 0.6158  time: 0.5334  data_time: 0.0531  lr: 0.0010418  max_mem: 11576M
[12/11 22:13:29 d2.utils.events]:  eta: 0:33:25  iter: 6239  total_loss: 2.073  loss_sem_seg: 0.8355  loss_center: 0.5557  loss_offset: 0.5821  time: 0.5334  data_time: 0.0518  lr: 0.0010368  max_mem: 11576M
[12/11 22:13:40 d2.utils.events]:  eta: 0:33:14  iter: 6259  total_loss: 1.95  loss_sem_seg: 0.8727  loss_center: 0.4819  loss_offset: 0.5346  time: 0.5334  data_time: 0.0523  lr: 0.0010319  max_mem: 11576M
[12/11 22:13:51 d2.utils.events]:  eta: 0:33:03  iter: 6279  total_loss: 1.863  loss_sem_seg: 0.8505  loss_center: 0.4391  loss_offset: 0.6054  time: 0.5334  data_time: 0.0512  lr: 0.0010269  max_mem: 11576M
[12/11 22:14:01 d2.utils.events]:  eta: 0:32:53  iter: 6299  total_loss: 2.22  loss_sem_seg: 0.9644  loss_center: 0.6293  loss_offset: 0.6042  time: 0.5334  data_time: 0.0510  lr: 0.0010219  max_mem: 11576M
[12/11 22:14:12 d2.utils.events]:  eta: 0:32:42  iter: 6319  total_loss: 2.034  loss_sem_seg: 0.8844  loss_center: 0.5204  loss_offset: 0.5715  time: 0.5334  data_time: 0.0462  lr: 0.001017  max_mem: 11576M
[12/11 22:14:23 d2.utils.events]:  eta: 0:32:32  iter: 6339  total_loss: 1.776  loss_sem_seg: 0.8312  loss_center: 0.462  loss_offset: 0.4605  time: 0.5334  data_time: 0.0472  lr: 0.001012  max_mem: 11576M
[12/11 22:14:33 d2.utils.events]:  eta: 0:32:21  iter: 6359  total_loss: 1.886  loss_sem_seg: 0.8068  loss_center: 0.6107  loss_offset: 0.5266  time: 0.5334  data_time: 0.0457  lr: 0.001007  max_mem: 11576M
[12/11 22:14:44 d2.utils.events]:  eta: 0:32:10  iter: 6379  total_loss: 1.877  loss_sem_seg: 0.8518  loss_center: 0.4746  loss_offset: 0.4717  time: 0.5334  data_time: 0.0487  lr: 0.001002  max_mem: 11576M
[12/11 22:14:55 d2.utils.events]:  eta: 0:32:00  iter: 6399  total_loss: 1.846  loss_sem_seg: 0.8793  loss_center: 0.4422  loss_offset: 0.5531  time: 0.5334  data_time: 0.0526  lr: 0.00099706  max_mem: 11576M
[12/11 22:15:05 d2.utils.events]:  eta: 0:31:49  iter: 6419  total_loss: 1.934  loss_sem_seg: 0.8701  loss_center: 0.5271  loss_offset: 0.6143  time: 0.5334  data_time: 0.0477  lr: 0.00099207  max_mem: 11576M
[12/11 22:15:16 d2.utils.events]:  eta: 0:31:39  iter: 6439  total_loss: 1.965  loss_sem_seg: 0.8958  loss_center: 0.5128  loss_offset: 0.5695  time: 0.5335  data_time: 0.0509  lr: 0.00098709  max_mem: 11576M
[12/11 22:15:27 d2.utils.events]:  eta: 0:31:29  iter: 6459  total_loss: 2.036  loss_sem_seg: 0.893  loss_center: 0.505  loss_offset: 0.5296  time: 0.5335  data_time: 0.0501  lr: 0.00098209  max_mem: 11576M
[12/11 22:15:38 d2.utils.events]:  eta: 0:31:18  iter: 6479  total_loss: 1.678  loss_sem_seg: 0.8153  loss_center: 0.5462  loss_offset: 0.418  time: 0.5335  data_time: 0.0483  lr: 0.0009771  max_mem: 11576M
[12/11 22:15:49 d2.utils.events]:  eta: 0:31:08  iter: 6499  total_loss: 2.057  loss_sem_seg: 0.9386  loss_center: 0.5118  loss_offset: 0.6312  time: 0.5335  data_time: 0.0502  lr: 0.0009721  max_mem: 11576M
[12/11 22:15:59 d2.utils.events]:  eta: 0:30:57  iter: 6519  total_loss: 2.225  loss_sem_seg: 1.009  loss_center: 0.6133  loss_offset: 0.5884  time: 0.5335  data_time: 0.0463  lr: 0.00096711  max_mem: 11576M
[12/11 22:16:10 d2.utils.events]:  eta: 0:30:46  iter: 6539  total_loss: 1.919  loss_sem_seg: 0.8712  loss_center: 0.4403  loss_offset: 0.5811  time: 0.5334  data_time: 0.0445  lr: 0.0009621  max_mem: 11576M
[12/11 22:16:20 d2.utils.events]:  eta: 0:30:36  iter: 6559  total_loss: 1.98  loss_sem_seg: 0.9441  loss_center: 0.4977  loss_offset: 0.517  time: 0.5334  data_time: 0.0467  lr: 0.0009571  max_mem: 11576M
[12/11 22:16:31 d2.utils.events]:  eta: 0:30:25  iter: 6579  total_loss: 1.951  loss_sem_seg: 0.851  loss_center: 0.474  loss_offset: 0.5171  time: 0.5334  data_time: 0.0526  lr: 0.00095209  max_mem: 11576M
[12/11 22:16:42 d2.utils.events]:  eta: 0:30:16  iter: 6599  total_loss: 2.04  loss_sem_seg: 0.9024  loss_center: 0.5027  loss_offset: 0.5704  time: 0.5335  data_time: 0.0508  lr: 0.00094708  max_mem: 11576M
[12/11 22:16:53 d2.utils.events]:  eta: 0:30:05  iter: 6619  total_loss: 2.132  loss_sem_seg: 1.102  loss_center: 0.3891  loss_offset: 0.5853  time: 0.5335  data_time: 0.0458  lr: 0.00094206  max_mem: 11576M
[12/11 22:17:03 d2.utils.events]:  eta: 0:29:54  iter: 6639  total_loss: 1.866  loss_sem_seg: 0.7577  loss_center: 0.5407  loss_offset: 0.4167  time: 0.5335  data_time: 0.0498  lr: 0.00093705  max_mem: 11576M
[12/11 22:17:14 d2.utils.events]:  eta: 0:29:43  iter: 6659  total_loss: 1.985  loss_sem_seg: 0.8204  loss_center: 0.525  loss_offset: 0.5918  time: 0.5335  data_time: 0.0472  lr: 0.00093203  max_mem: 11576M
[12/11 22:17:25 d2.utils.events]:  eta: 0:29:32  iter: 6679  total_loss: 1.918  loss_sem_seg: 0.7946  loss_center: 0.562  loss_offset: 0.4774  time: 0.5335  data_time: 0.0491  lr: 0.000927  max_mem: 11576M
[12/11 22:17:35 d2.utils.events]:  eta: 0:29:21  iter: 6699  total_loss: 2.107  loss_sem_seg: 0.8421  loss_center: 0.5155  loss_offset: 0.5811  time: 0.5335  data_time: 0.0476  lr: 0.00092198  max_mem: 11576M
[12/11 22:17:46 d2.utils.events]:  eta: 0:29:10  iter: 6719  total_loss: 1.992  loss_sem_seg: 0.8576  loss_center: 0.5405  loss_offset: 0.5302  time: 0.5335  data_time: 0.0496  lr: 0.00091695  max_mem: 11576M
[12/11 22:17:57 d2.utils.events]:  eta: 0:28:59  iter: 6739  total_loss: 1.964  loss_sem_seg: 0.7794  loss_center: 0.5851  loss_offset: 0.4703  time: 0.5335  data_time: 0.0493  lr: 0.00091192  max_mem: 11576M
[12/11 22:18:07 d2.utils.events]:  eta: 0:28:50  iter: 6759  total_loss: 1.981  loss_sem_seg: 0.8692  loss_center: 0.5651  loss_offset: 0.5901  time: 0.5335  data_time: 0.0457  lr: 0.00090688  max_mem: 11576M
[12/11 22:18:18 d2.utils.events]:  eta: 0:28:39  iter: 6779  total_loss: 1.97  loss_sem_seg: 0.8366  loss_center: 0.487  loss_offset: 0.4839  time: 0.5335  data_time: 0.0547  lr: 0.00090184  max_mem: 11576M
[12/11 22:18:29 d2.utils.events]:  eta: 0:28:29  iter: 6799  total_loss: 1.97  loss_sem_seg: 0.8961  loss_center: 0.4949  loss_offset: 0.5927  time: 0.5335  data_time: 0.0501  lr: 0.0008968  max_mem: 11576M
[12/11 22:18:40 d2.utils.events]:  eta: 0:28:17  iter: 6819  total_loss: 1.902  loss_sem_seg: 0.8174  loss_center: 0.4667  loss_offset: 0.4599  time: 0.5335  data_time: 0.0532  lr: 0.00089176  max_mem: 11576M
[12/11 22:18:50 d2.utils.events]:  eta: 0:28:06  iter: 6839  total_loss: 1.821  loss_sem_seg: 0.8645  loss_center: 0.4756  loss_offset: 0.4893  time: 0.5335  data_time: 0.0535  lr: 0.00088671  max_mem: 11576M
[12/11 22:19:01 d2.utils.events]:  eta: 0:27:55  iter: 6859  total_loss: 1.998  loss_sem_seg: 0.9025  loss_center: 0.4663  loss_offset: 0.6018  time: 0.5335  data_time: 0.0510  lr: 0.00088166  max_mem: 11576M
[12/11 22:19:12 d2.utils.events]:  eta: 0:27:44  iter: 6879  total_loss: 1.908  loss_sem_seg: 0.846  loss_center: 0.5442  loss_offset: 0.6236  time: 0.5335  data_time: 0.0552  lr: 0.00087661  max_mem: 11576M
[12/11 22:19:23 d2.utils.events]:  eta: 0:27:34  iter: 6899  total_loss: 2.008  loss_sem_seg: 0.8654  loss_center: 0.544  loss_offset: 0.4954  time: 0.5335  data_time: 0.0549  lr: 0.00087155  max_mem: 11576M
[12/11 22:19:33 d2.utils.events]:  eta: 0:27:23  iter: 6919  total_loss: 2.023  loss_sem_seg: 0.8641  loss_center: 0.5003  loss_offset: 0.5437  time: 0.5335  data_time: 0.0432  lr: 0.00086649  max_mem: 11576M
[12/11 22:19:44 d2.utils.events]:  eta: 0:27:12  iter: 6939  total_loss: 1.985  loss_sem_seg: 0.9174  loss_center: 0.4995  loss_offset: 0.5388  time: 0.5335  data_time: 0.0518  lr: 0.00086142  max_mem: 11576M
[12/11 22:19:55 d2.utils.events]:  eta: 0:27:01  iter: 6959  total_loss: 2.036  loss_sem_seg: 0.8568  loss_center: 0.6156  loss_offset: 0.5304  time: 0.5335  data_time: 0.0511  lr: 0.00085636  max_mem: 11576M
[12/11 22:20:05 d2.utils.events]:  eta: 0:26:50  iter: 6979  total_loss: 1.849  loss_sem_seg: 0.7679  loss_center: 0.5583  loss_offset: 0.5748  time: 0.5335  data_time: 0.0506  lr: 0.00085129  max_mem: 11576M
[12/11 22:20:16 d2.utils.events]:  eta: 0:26:39  iter: 6999  total_loss: 1.745  loss_sem_seg: 0.7643  loss_center: 0.4492  loss_offset: 0.5291  time: 0.5335  data_time: 0.0446  lr: 0.00084621  max_mem: 11576M
[12/11 22:20:27 d2.utils.events]:  eta: 0:26:29  iter: 7019  total_loss: 2.066  loss_sem_seg: 0.9951  loss_center: 0.5293  loss_offset: 0.5122  time: 0.5335  data_time: 0.0498  lr: 0.00084114  max_mem: 11576M
[12/11 22:20:38 d2.utils.events]:  eta: 0:26:18  iter: 7039  total_loss: 1.827  loss_sem_seg: 0.8561  loss_center: 0.5574  loss_offset: 0.517  time: 0.5335  data_time: 0.0466  lr: 0.00083605  max_mem: 11576M
[12/11 22:20:48 d2.utils.events]:  eta: 0:26:07  iter: 7059  total_loss: 2.111  loss_sem_seg: 0.9225  loss_center: 0.4961  loss_offset: 0.6045  time: 0.5336  data_time: 0.0554  lr: 0.00083097  max_mem: 11576M
[12/11 22:20:59 d2.utils.events]:  eta: 0:25:57  iter: 7079  total_loss: 1.918  loss_sem_seg: 0.9069  loss_center: 0.4101  loss_offset: 0.5309  time: 0.5336  data_time: 0.0561  lr: 0.00082588  max_mem: 11576M
[12/11 22:21:10 d2.utils.events]:  eta: 0:25:46  iter: 7099  total_loss: 1.835  loss_sem_seg: 0.7708  loss_center: 0.5614  loss_offset: 0.4629  time: 0.5336  data_time: 0.0524  lr: 0.00082079  max_mem: 11576M
[12/11 22:21:21 d2.utils.events]:  eta: 0:25:36  iter: 7119  total_loss: 1.895  loss_sem_seg: 0.8239  loss_center: 0.5152  loss_offset: 0.5425  time: 0.5336  data_time: 0.0490  lr: 0.0008157  max_mem: 11576M
[12/11 22:21:31 d2.utils.events]:  eta: 0:25:25  iter: 7139  total_loss: 1.941  loss_sem_seg: 0.8058  loss_center: 0.4789  loss_offset: 0.5485  time: 0.5336  data_time: 0.0480  lr: 0.0008106  max_mem: 11576M
[12/11 22:21:42 d2.utils.events]:  eta: 0:25:14  iter: 7159  total_loss: 2.021  loss_sem_seg: 0.8431  loss_center: 0.4742  loss_offset: 0.5643  time: 0.5336  data_time: 0.0500  lr: 0.0008055  max_mem: 11576M
[12/11 22:21:53 d2.utils.events]:  eta: 0:25:03  iter: 7179  total_loss: 2.008  loss_sem_seg: 0.8775  loss_center: 0.4385  loss_offset: 0.6019  time: 0.5336  data_time: 0.0476  lr: 0.00080039  max_mem: 11576M
[12/11 22:22:04 d2.utils.events]:  eta: 0:24:53  iter: 7199  total_loss: 1.905  loss_sem_seg: 0.8991  loss_center: 0.4714  loss_offset: 0.451  time: 0.5336  data_time: 0.0509  lr: 0.00079528  max_mem: 11576M
[12/11 22:22:14 d2.utils.events]:  eta: 0:24:42  iter: 7219  total_loss: 1.877  loss_sem_seg: 0.8276  loss_center: 0.5348  loss_offset: 0.5489  time: 0.5336  data_time: 0.0478  lr: 0.00079017  max_mem: 11576M
[12/11 22:22:25 d2.utils.events]:  eta: 0:24:31  iter: 7239  total_loss: 1.892  loss_sem_seg: 0.9039  loss_center: 0.5068  loss_offset: 0.4748  time: 0.5336  data_time: 0.0498  lr: 0.00078505  max_mem: 11576M
[12/11 22:22:36 d2.utils.events]:  eta: 0:24:21  iter: 7259  total_loss: 2.084  loss_sem_seg: 0.8962  loss_center: 0.4665  loss_offset: 0.5824  time: 0.5336  data_time: 0.0512  lr: 0.00077993  max_mem: 11576M
[12/11 22:22:46 d2.utils.events]:  eta: 0:24:10  iter: 7279  total_loss: 2.024  loss_sem_seg: 0.9535  loss_center: 0.5463  loss_offset: 0.5568  time: 0.5336  data_time: 0.0501  lr: 0.00077481  max_mem: 11576M
[12/11 22:22:57 d2.utils.events]:  eta: 0:23:59  iter: 7299  total_loss: 2.063  loss_sem_seg: 0.8258  loss_center: 0.5513  loss_offset: 0.4212  time: 0.5336  data_time: 0.0549  lr: 0.00076968  max_mem: 11576M
[12/11 22:23:08 d2.utils.events]:  eta: 0:23:49  iter: 7319  total_loss: 2.038  loss_sem_seg: 0.8297  loss_center: 0.5424  loss_offset: 0.57  time: 0.5336  data_time: 0.0493  lr: 0.00076455  max_mem: 11576M
[12/11 22:23:19 d2.utils.events]:  eta: 0:23:38  iter: 7339  total_loss: 1.915  loss_sem_seg: 0.9158  loss_center: 0.5231  loss_offset: 0.4678  time: 0.5337  data_time: 0.0554  lr: 0.00075942  max_mem: 11576M
[12/11 22:23:30 d2.utils.events]:  eta: 0:23:28  iter: 7359  total_loss: 1.668  loss_sem_seg: 0.8609  loss_center: 0.3757  loss_offset: 0.4834  time: 0.5337  data_time: 0.0465  lr: 0.00075428  max_mem: 11576M
[12/11 22:23:40 d2.utils.events]:  eta: 0:23:17  iter: 7379  total_loss: 2.064  loss_sem_seg: 0.8517  loss_center: 0.5675  loss_offset: 0.5573  time: 0.5337  data_time: 0.0487  lr: 0.00074914  max_mem: 11576M
[12/11 22:23:51 d2.utils.events]:  eta: 0:23:06  iter: 7399  total_loss: 1.86  loss_sem_seg: 0.8253  loss_center: 0.5338  loss_offset: 0.5003  time: 0.5337  data_time: 0.0504  lr: 0.00074399  max_mem: 11576M
[12/11 22:24:02 d2.utils.events]:  eta: 0:22:55  iter: 7419  total_loss: 2.213  loss_sem_seg: 1.025  loss_center: 0.5543  loss_offset: 0.5591  time: 0.5337  data_time: 0.0496  lr: 0.00073884  max_mem: 11576M
[12/11 22:24:12 d2.utils.events]:  eta: 0:22:45  iter: 7439  total_loss: 1.936  loss_sem_seg: 0.8032  loss_center: 0.5018  loss_offset: 0.5362  time: 0.5337  data_time: 0.0518  lr: 0.00073368  max_mem: 11576M
[12/11 22:24:23 d2.utils.events]:  eta: 0:22:34  iter: 7459  total_loss: 1.969  loss_sem_seg: 0.845  loss_center: 0.5418  loss_offset: 0.5018  time: 0.5337  data_time: 0.0502  lr: 0.00072852  max_mem: 11576M
[12/11 22:24:34 d2.utils.events]:  eta: 0:22:23  iter: 7479  total_loss: 2.004  loss_sem_seg: 0.8265  loss_center: 0.5049  loss_offset: 0.5431  time: 0.5337  data_time: 0.0516  lr: 0.00072336  max_mem: 11576M
[12/11 22:24:45 d2.utils.events]:  eta: 0:22:13  iter: 7499  total_loss: 1.902  loss_sem_seg: 0.8246  loss_center: 0.503  loss_offset: 0.5017  time: 0.5337  data_time: 0.0473  lr: 0.00071819  max_mem: 11576M
[12/11 22:24:55 d2.utils.events]:  eta: 0:22:02  iter: 7519  total_loss: 2.029  loss_sem_seg: 0.9191  loss_center: 0.4973  loss_offset: 0.55  time: 0.5337  data_time: 0.0497  lr: 0.00071302  max_mem: 11576M
[12/11 22:25:06 d2.utils.events]:  eta: 0:21:51  iter: 7539  total_loss: 1.894  loss_sem_seg: 0.8545  loss_center: 0.4785  loss_offset: 0.5064  time: 0.5337  data_time: 0.0504  lr: 0.00070785  max_mem: 11576M
[12/11 22:25:17 d2.utils.events]:  eta: 0:21:41  iter: 7559  total_loss: 1.836  loss_sem_seg: 0.8161  loss_center: 0.5285  loss_offset: 0.5006  time: 0.5337  data_time: 0.0486  lr: 0.00070267  max_mem: 11576M
[12/11 22:25:27 d2.utils.events]:  eta: 0:21:30  iter: 7579  total_loss: 1.94  loss_sem_seg: 0.8766  loss_center: 0.5226  loss_offset: 0.5278  time: 0.5337  data_time: 0.0453  lr: 0.00069749  max_mem: 11576M
[12/11 22:25:38 d2.utils.events]:  eta: 0:21:19  iter: 7599  total_loss: 1.961  loss_sem_seg: 0.9381  loss_center: 0.5028  loss_offset: 0.4616  time: 0.5337  data_time: 0.0524  lr: 0.0006923  max_mem: 11576M
[12/11 22:25:49 d2.utils.events]:  eta: 0:21:09  iter: 7619  total_loss: 1.948  loss_sem_seg: 0.7831  loss_center: 0.4823  loss_offset: 0.4829  time: 0.5337  data_time: 0.0549  lr: 0.00068711  max_mem: 11576M
[12/11 22:26:00 d2.utils.events]:  eta: 0:20:58  iter: 7639  total_loss: 1.821  loss_sem_seg: 0.8583  loss_center: 0.4891  loss_offset: 0.5282  time: 0.5337  data_time: 0.0483  lr: 0.00068191  max_mem: 11576M
[12/11 22:26:10 d2.utils.events]:  eta: 0:20:48  iter: 7659  total_loss: 1.857  loss_sem_seg: 0.7802  loss_center: 0.568  loss_offset: 0.5109  time: 0.5337  data_time: 0.0474  lr: 0.00067671  max_mem: 11576M
[12/11 22:26:21 d2.utils.events]:  eta: 0:20:37  iter: 7679  total_loss: 1.836  loss_sem_seg: 0.7923  loss_center: 0.4468  loss_offset: 0.5117  time: 0.5337  data_time: 0.0483  lr: 0.0006715  max_mem: 11576M
[12/11 22:26:32 d2.utils.events]:  eta: 0:20:26  iter: 7699  total_loss: 2.081  loss_sem_seg: 0.8499  loss_center: 0.4657  loss_offset: 0.5722  time: 0.5337  data_time: 0.0521  lr: 0.00066629  max_mem: 11576M
[12/11 22:26:43 d2.utils.events]:  eta: 0:20:16  iter: 7719  total_loss: 2.081  loss_sem_seg: 0.8866  loss_center: 0.5739  loss_offset: 0.5616  time: 0.5337  data_time: 0.0496  lr: 0.00066108  max_mem: 11576M
[12/11 22:26:53 d2.utils.events]:  eta: 0:20:05  iter: 7739  total_loss: 2.04  loss_sem_seg: 0.858  loss_center: 0.4433  loss_offset: 0.5328  time: 0.5337  data_time: 0.0490  lr: 0.00065586  max_mem: 11576M
[12/11 22:27:04 d2.utils.events]:  eta: 0:19:54  iter: 7759  total_loss: 1.98  loss_sem_seg: 0.8478  loss_center: 0.597  loss_offset: 0.4915  time: 0.5337  data_time: 0.0474  lr: 0.00065064  max_mem: 11576M
[12/11 22:27:15 d2.utils.events]:  eta: 0:19:43  iter: 7779  total_loss: 1.756  loss_sem_seg: 0.818  loss_center: 0.5126  loss_offset: 0.4318  time: 0.5338  data_time: 0.0509  lr: 0.00064541  max_mem: 11576M
[12/11 22:27:25 d2.utils.events]:  eta: 0:19:33  iter: 7799  total_loss: 2.059  loss_sem_seg: 0.9677  loss_center: 0.4806  loss_offset: 0.6427  time: 0.5338  data_time: 0.0500  lr: 0.00064017  max_mem: 11576M
[12/11 22:27:36 d2.utils.events]:  eta: 0:19:22  iter: 7819  total_loss: 2.053  loss_sem_seg: 0.8294  loss_center: 0.5303  loss_offset: 0.4939  time: 0.5338  data_time: 0.0478  lr: 0.00063494  max_mem: 11576M
[12/11 22:27:47 d2.utils.events]:  eta: 0:19:12  iter: 7839  total_loss: 1.805  loss_sem_seg: 0.7539  loss_center: 0.4888  loss_offset: 0.5201  time: 0.5338  data_time: 0.0446  lr: 0.00062969  max_mem: 11576M
[12/11 22:27:57 d2.utils.events]:  eta: 0:19:01  iter: 7859  total_loss: 1.881  loss_sem_seg: 0.8355  loss_center: 0.5405  loss_offset: 0.5494  time: 0.5338  data_time: 0.0488  lr: 0.00062445  max_mem: 11576M
[12/11 22:28:08 d2.utils.events]:  eta: 0:18:50  iter: 7879  total_loss: 1.751  loss_sem_seg: 0.8506  loss_center: 0.514  loss_offset: 0.4196  time: 0.5337  data_time: 0.0484  lr: 0.00061919  max_mem: 11576M
[12/11 22:28:19 d2.utils.events]:  eta: 0:18:40  iter: 7899  total_loss: 1.929  loss_sem_seg: 0.8588  loss_center: 0.4649  loss_offset: 0.5639  time: 0.5337  data_time: 0.0490  lr: 0.00061394  max_mem: 11576M
[12/11 22:28:30 d2.utils.events]:  eta: 0:18:29  iter: 7919  total_loss: 1.926  loss_sem_seg: 0.9319  loss_center: 0.509  loss_offset: 0.4661  time: 0.5338  data_time: 0.0488  lr: 0.00060867  max_mem: 11576M
[12/11 22:28:40 d2.utils.events]:  eta: 0:18:19  iter: 7939  total_loss: 1.906  loss_sem_seg: 0.7363  loss_center: 0.4293  loss_offset: 0.5329  time: 0.5338  data_time: 0.0495  lr: 0.00060341  max_mem: 11576M
[12/11 22:28:51 d2.utils.events]:  eta: 0:18:09  iter: 7959  total_loss: 2.066  loss_sem_seg: 0.9837  loss_center: 0.5921  loss_offset: 0.5784  time: 0.5338  data_time: 0.0566  lr: 0.00059813  max_mem: 11576M
[12/11 22:29:02 d2.utils.events]:  eta: 0:17:58  iter: 7979  total_loss: 1.985  loss_sem_seg: 0.9167  loss_center: 0.5096  loss_offset: 0.5161  time: 0.5338  data_time: 0.0561  lr: 0.00059286  max_mem: 11576M
[12/11 22:29:13 d2.utils.events]:  eta: 0:17:48  iter: 7999  total_loss: 1.849  loss_sem_seg: 0.7875  loss_center: 0.5192  loss_offset: 0.5237  time: 0.5338  data_time: 0.0510  lr: 0.00058757  max_mem: 11576M
[12/11 22:29:24 d2.utils.events]:  eta: 0:17:37  iter: 8019  total_loss: 1.999  loss_sem_seg: 0.9184  loss_center: 0.5476  loss_offset: 0.47  time: 0.5338  data_time: 0.0499  lr: 0.00058229  max_mem: 11576M
[12/11 22:29:34 d2.utils.events]:  eta: 0:17:26  iter: 8039  total_loss: 1.942  loss_sem_seg: 0.8698  loss_center: 0.4347  loss_offset: 0.562  time: 0.5338  data_time: 0.0472  lr: 0.00057699  max_mem: 11576M
[12/11 22:29:45 d2.utils.events]:  eta: 0:17:15  iter: 8059  total_loss: 1.946  loss_sem_seg: 0.8132  loss_center: 0.4964  loss_offset: 0.5319  time: 0.5338  data_time: 0.0503  lr: 0.00057169  max_mem: 11576M
[12/11 22:29:56 d2.utils.events]:  eta: 0:17:04  iter: 8079  total_loss: 1.981  loss_sem_seg: 0.8989  loss_center: 0.5213  loss_offset: 0.5209  time: 0.5338  data_time: 0.0506  lr: 0.00056639  max_mem: 11576M
[12/11 22:30:06 d2.utils.events]:  eta: 0:16:54  iter: 8099  total_loss: 1.906  loss_sem_seg: 0.9341  loss_center: 0.4162  loss_offset: 0.5629  time: 0.5338  data_time: 0.0441  lr: 0.00056108  max_mem: 11576M
[12/11 22:30:17 d2.utils.events]:  eta: 0:16:43  iter: 8119  total_loss: 1.966  loss_sem_seg: 0.9287  loss_center: 0.5177  loss_offset: 0.5424  time: 0.5338  data_time: 0.0532  lr: 0.00055576  max_mem: 11576M
[12/11 22:30:28 d2.utils.events]:  eta: 0:16:32  iter: 8139  total_loss: 1.905  loss_sem_seg: 0.8426  loss_center: 0.4737  loss_offset: 0.5475  time: 0.5338  data_time: 0.0461  lr: 0.00055044  max_mem: 11576M
[12/11 22:30:39 d2.utils.events]:  eta: 0:16:21  iter: 8159  total_loss: 1.855  loss_sem_seg: 0.8242  loss_center: 0.4909  loss_offset: 0.4084  time: 0.5338  data_time: 0.0516  lr: 0.00054512  max_mem: 11576M
[12/11 22:30:49 d2.utils.events]:  eta: 0:16:11  iter: 8179  total_loss: 1.956  loss_sem_seg: 0.8849  loss_center: 0.5067  loss_offset: 0.5466  time: 0.5339  data_time: 0.0509  lr: 0.00053978  max_mem: 11576M
[12/11 22:31:00 d2.utils.events]:  eta: 0:16:00  iter: 8199  total_loss: 1.887  loss_sem_seg: 0.8594  loss_center: 0.4972  loss_offset: 0.5157  time: 0.5339  data_time: 0.0518  lr: 0.00053444  max_mem: 11576M
[12/11 22:31:11 d2.utils.events]:  eta: 0:15:49  iter: 8219  total_loss: 2.04  loss_sem_seg: 0.8848  loss_center: 0.4846  loss_offset: 0.5602  time: 0.5339  data_time: 0.0476  lr: 0.0005291  max_mem: 11576M
[12/11 22:31:22 d2.utils.events]:  eta: 0:15:39  iter: 8239  total_loss: 1.777  loss_sem_seg: 0.8026  loss_center: 0.52  loss_offset: 0.4909  time: 0.5339  data_time: 0.0468  lr: 0.00052375  max_mem: 11576M
[12/11 22:31:32 d2.utils.events]:  eta: 0:15:29  iter: 8259  total_loss: 1.926  loss_sem_seg: 0.8594  loss_center: 0.5352  loss_offset: 0.6029  time: 0.5339  data_time: 0.0530  lr: 0.00051839  max_mem: 11576M
[12/11 22:31:43 d2.utils.events]:  eta: 0:15:18  iter: 8279  total_loss: 1.899  loss_sem_seg: 0.7861  loss_center: 0.4685  loss_offset: 0.5578  time: 0.5339  data_time: 0.0472  lr: 0.00051303  max_mem: 11576M
[12/11 22:31:54 d2.utils.events]:  eta: 0:15:07  iter: 8299  total_loss: 1.879  loss_sem_seg: 0.8222  loss_center: 0.4661  loss_offset: 0.459  time: 0.5339  data_time: 0.0502  lr: 0.00050766  max_mem: 11576M
[12/11 22:32:04 d2.utils.events]:  eta: 0:14:56  iter: 8319  total_loss: 1.873  loss_sem_seg: 0.7687  loss_center: 0.5269  loss_offset: 0.5804  time: 0.5339  data_time: 0.0491  lr: 0.00050229  max_mem: 11576M
[12/11 22:32:15 d2.utils.events]:  eta: 0:14:46  iter: 8339  total_loss: 1.818  loss_sem_seg: 0.8199  loss_center: 0.52  loss_offset: 0.4546  time: 0.5339  data_time: 0.0484  lr: 0.0004969  max_mem: 11576M
[12/11 22:32:26 d2.utils.events]:  eta: 0:14:35  iter: 8359  total_loss: 1.953  loss_sem_seg: 0.8298  loss_center: 0.4845  loss_offset: 0.5702  time: 0.5339  data_time: 0.0465  lr: 0.00049152  max_mem: 11576M
[12/11 22:32:36 d2.utils.events]:  eta: 0:14:24  iter: 8379  total_loss: 1.852  loss_sem_seg: 0.8062  loss_center: 0.5655  loss_offset: 0.5388  time: 0.5339  data_time: 0.0454  lr: 0.00048612  max_mem: 11576M
[12/11 22:32:47 d2.utils.events]:  eta: 0:14:14  iter: 8399  total_loss: 1.865  loss_sem_seg: 0.7862  loss_center: 0.5222  loss_offset: 0.4768  time: 0.5339  data_time: 0.0494  lr: 0.00048072  max_mem: 11576M
[12/11 22:32:58 d2.utils.events]:  eta: 0:14:03  iter: 8419  total_loss: 1.6  loss_sem_seg: 0.6963  loss_center: 0.3629  loss_offset: 0.4849  time: 0.5339  data_time: 0.0476  lr: 0.00047531  max_mem: 11576M
[12/11 22:33:09 d2.utils.events]:  eta: 0:13:52  iter: 8439  total_loss: 1.868  loss_sem_seg: 0.848  loss_center: 0.53  loss_offset: 0.5039  time: 0.5339  data_time: 0.0542  lr: 0.0004699  max_mem: 11576M
[12/11 22:33:19 d2.utils.events]:  eta: 0:13:42  iter: 8459  total_loss: 1.819  loss_sem_seg: 0.8821  loss_center: 0.5361  loss_offset: 0.5199  time: 0.5339  data_time: 0.0507  lr: 0.00046448  max_mem: 11576M
[12/11 22:33:30 d2.utils.events]:  eta: 0:13:31  iter: 8479  total_loss: 1.809  loss_sem_seg: 0.8517  loss_center: 0.4849  loss_offset: 0.5354  time: 0.5339  data_time: 0.0454  lr: 0.00045905  max_mem: 11576M
[12/11 22:33:41 d2.utils.events]:  eta: 0:13:20  iter: 8499  total_loss: 1.993  loss_sem_seg: 0.86  loss_center: 0.5153  loss_offset: 0.6014  time: 0.5339  data_time: 0.0459  lr: 0.00045361  max_mem: 11576M
[12/11 22:33:51 d2.utils.events]:  eta: 0:13:09  iter: 8519  total_loss: 1.796  loss_sem_seg: 0.808  loss_center: 0.4032  loss_offset: 0.5155  time: 0.5339  data_time: 0.0457  lr: 0.00044817  max_mem: 11576M
[12/11 22:34:02 d2.utils.events]:  eta: 0:12:59  iter: 8539  total_loss: 2.032  loss_sem_seg: 0.8963  loss_center: 0.5316  loss_offset: 0.5313  time: 0.5339  data_time: 0.0513  lr: 0.00044272  max_mem: 11576M
[12/11 22:34:13 d2.utils.events]:  eta: 0:12:48  iter: 8559  total_loss: 1.806  loss_sem_seg: 0.772  loss_center: 0.4628  loss_offset: 0.5078  time: 0.5339  data_time: 0.0521  lr: 0.00043726  max_mem: 11576M
[12/11 22:34:24 d2.utils.events]:  eta: 0:12:37  iter: 8579  total_loss: 1.995  loss_sem_seg: 0.948  loss_center: 0.5016  loss_offset: 0.5173  time: 0.5339  data_time: 0.0543  lr: 0.00043179  max_mem: 11576M
[12/11 22:34:34 d2.utils.events]:  eta: 0:12:27  iter: 8599  total_loss: 1.891  loss_sem_seg: 0.802  loss_center: 0.5331  loss_offset: 0.423  time: 0.5339  data_time: 0.0522  lr: 0.00042632  max_mem: 11576M
[12/11 22:34:45 d2.utils.events]:  eta: 0:12:16  iter: 8619  total_loss: 1.636  loss_sem_seg: 0.7743  loss_center: 0.4805  loss_offset: 0.3748  time: 0.5339  data_time: 0.0526  lr: 0.00042084  max_mem: 11576M
[12/11 22:34:56 d2.utils.events]:  eta: 0:12:05  iter: 8639  total_loss: 1.981  loss_sem_seg: 0.7738  loss_center: 0.603  loss_offset: 0.4909  time: 0.5339  data_time: 0.0476  lr: 0.00041535  max_mem: 11576M
[12/11 22:35:06 d2.utils.events]:  eta: 0:11:54  iter: 8659  total_loss: 1.879  loss_sem_seg: 0.8246  loss_center: 0.5547  loss_offset: 0.513  time: 0.5339  data_time: 0.0440  lr: 0.00040985  max_mem: 11576M
[12/11 22:35:17 d2.utils.events]:  eta: 0:11:44  iter: 8679  total_loss: 1.957  loss_sem_seg: 0.8839  loss_center: 0.5246  loss_offset: 0.4846  time: 0.5339  data_time: 0.0485  lr: 0.00040435  max_mem: 11576M
[12/11 22:35:28 d2.utils.events]:  eta: 0:11:33  iter: 8699  total_loss: 1.811  loss_sem_seg: 0.7964  loss_center: 0.5295  loss_offset: 0.4568  time: 0.5339  data_time: 0.0513  lr: 0.00039883  max_mem: 11576M
[12/11 22:35:38 d2.utils.events]:  eta: 0:11:22  iter: 8719  total_loss: 2.114  loss_sem_seg: 0.8515  loss_center: 0.5547  loss_offset: 0.5218  time: 0.5339  data_time: 0.0469  lr: 0.00039331  max_mem: 11576M
[12/11 22:35:49 d2.utils.events]:  eta: 0:11:12  iter: 8739  total_loss: 1.874  loss_sem_seg: 0.7927  loss_center: 0.456  loss_offset: 0.5995  time: 0.5339  data_time: 0.0600  lr: 0.00038778  max_mem: 11576M
[12/11 22:36:00 d2.utils.events]:  eta: 0:11:01  iter: 8759  total_loss: 1.843  loss_sem_seg: 0.8071  loss_center: 0.4991  loss_offset: 0.5308  time: 0.5339  data_time: 0.0545  lr: 0.00038224  max_mem: 11576M
[12/11 22:36:11 d2.utils.events]:  eta: 0:10:50  iter: 8779  total_loss: 1.873  loss_sem_seg: 0.736  loss_center: 0.4885  loss_offset: 0.5131  time: 0.5339  data_time: 0.0512  lr: 0.00037669  max_mem: 11576M
[12/11 22:36:22 d2.utils.events]:  eta: 0:10:39  iter: 8799  total_loss: 1.993  loss_sem_seg: 0.847  loss_center: 0.5818  loss_offset: 0.4823  time: 0.5339  data_time: 0.0549  lr: 0.00037113  max_mem: 11576M
[12/11 22:36:32 d2.utils.events]:  eta: 0:10:29  iter: 8819  total_loss: 1.943  loss_sem_seg: 0.8388  loss_center: 0.4837  loss_offset: 0.5005  time: 0.5339  data_time: 0.0505  lr: 0.00036557  max_mem: 11576M
[12/11 22:36:43 d2.utils.events]:  eta: 0:10:18  iter: 8839  total_loss: 1.852  loss_sem_seg: 0.8047  loss_center: 0.4972  loss_offset: 0.5488  time: 0.5339  data_time: 0.0478  lr: 0.00035999  max_mem: 11576M
[12/11 22:36:54 d2.utils.events]:  eta: 0:10:07  iter: 8859  total_loss: 1.973  loss_sem_seg: 0.8581  loss_center: 0.4975  loss_offset: 0.58  time: 0.5339  data_time: 0.0493  lr: 0.0003544  max_mem: 11576M
[12/11 22:37:05 d2.utils.events]:  eta: 0:09:57  iter: 8879  total_loss: 1.97  loss_sem_seg: 0.794  loss_center: 0.5659  loss_offset: 0.5447  time: 0.5339  data_time: 0.0497  lr: 0.00034881  max_mem: 11576M
[12/11 22:37:15 d2.utils.events]:  eta: 0:09:46  iter: 8899  total_loss: 1.691  loss_sem_seg: 0.7574  loss_center: 0.4688  loss_offset: 0.4806  time: 0.5339  data_time: 0.0472  lr: 0.0003432  max_mem: 11576M
[12/11 22:37:26 d2.utils.events]:  eta: 0:09:35  iter: 8919  total_loss: 1.902  loss_sem_seg: 0.781  loss_center: 0.5305  loss_offset: 0.5053  time: 0.5339  data_time: 0.0517  lr: 0.00033758  max_mem: 11576M
[12/11 22:37:37 d2.utils.events]:  eta: 0:09:24  iter: 8939  total_loss: 1.791  loss_sem_seg: 0.8654  loss_center: 0.4873  loss_offset: 0.485  time: 0.5340  data_time: 0.0538  lr: 0.00033196  max_mem: 11576M
[12/11 22:37:47 d2.utils.events]:  eta: 0:09:14  iter: 8959  total_loss: 1.83  loss_sem_seg: 0.7197  loss_center: 0.4751  loss_offset: 0.483  time: 0.5340  data_time: 0.0506  lr: 0.00032632  max_mem: 11576M
[12/11 22:37:58 d2.utils.events]:  eta: 0:09:03  iter: 8979  total_loss: 1.896  loss_sem_seg: 0.8242  loss_center: 0.5401  loss_offset: 0.5036  time: 0.5340  data_time: 0.0510  lr: 0.00032067  max_mem: 11576M
[12/11 22:38:09 d2.utils.events]:  eta: 0:08:52  iter: 8999  total_loss: 1.962  loss_sem_seg: 0.9439  loss_center: 0.5071  loss_offset: 0.4806  time: 0.5340  data_time: 0.0515  lr: 0.00031501  max_mem: 11576M
[12/11 22:38:20 d2.utils.events]:  eta: 0:08:42  iter: 9019  total_loss: 1.844  loss_sem_seg: 0.6922  loss_center: 0.5775  loss_offset: 0.4685  time: 0.5340  data_time: 0.0502  lr: 0.00030934  max_mem: 11576M
[12/11 22:38:30 d2.utils.events]:  eta: 0:08:31  iter: 9039  total_loss: 1.719  loss_sem_seg: 0.7174  loss_center: 0.4762  loss_offset: 0.4461  time: 0.5340  data_time: 0.0510  lr: 0.00030366  max_mem: 11576M
[12/11 22:38:41 d2.utils.events]:  eta: 0:08:21  iter: 9059  total_loss: 1.92  loss_sem_seg: 0.8372  loss_center: 0.4813  loss_offset: 0.5639  time: 0.5340  data_time: 0.0520  lr: 0.00029797  max_mem: 11576M
[12/11 22:38:52 d2.utils.events]:  eta: 0:08:10  iter: 9079  total_loss: 1.65  loss_sem_seg: 0.737  loss_center: 0.4847  loss_offset: 0.4685  time: 0.5340  data_time: 0.0513  lr: 0.00029226  max_mem: 11576M
[12/11 22:39:03 d2.utils.events]:  eta: 0:07:59  iter: 9099  total_loss: 1.902  loss_sem_seg: 0.9017  loss_center: 0.5744  loss_offset: 0.4898  time: 0.5340  data_time: 0.0532  lr: 0.00028654  max_mem: 11576M
[12/11 22:39:13 d2.utils.events]:  eta: 0:07:48  iter: 9119  total_loss: 2.064  loss_sem_seg: 0.807  loss_center: 0.6372  loss_offset: 0.5294  time: 0.5340  data_time: 0.0503  lr: 0.00028081  max_mem: 11576M
[12/11 22:39:24 d2.utils.events]:  eta: 0:07:38  iter: 9139  total_loss: 1.841  loss_sem_seg: 0.8054  loss_center: 0.4886  loss_offset: 0.4639  time: 0.5340  data_time: 0.0462  lr: 0.00027507  max_mem: 11576M
[12/11 22:39:35 d2.utils.events]:  eta: 0:07:27  iter: 9159  total_loss: 1.795  loss_sem_seg: 0.7895  loss_center: 0.5318  loss_offset: 0.5194  time: 0.5340  data_time: 0.0481  lr: 0.00026931  max_mem: 11576M
[12/11 22:39:45 d2.utils.events]:  eta: 0:07:16  iter: 9179  total_loss: 1.847  loss_sem_seg: 0.8198  loss_center: 0.5584  loss_offset: 0.4831  time: 0.5340  data_time: 0.0511  lr: 0.00026354  max_mem: 11576M
[12/11 22:39:56 d2.utils.events]:  eta: 0:07:06  iter: 9199  total_loss: 1.761  loss_sem_seg: 0.7763  loss_center: 0.5331  loss_offset: 0.4848  time: 0.5340  data_time: 0.0496  lr: 0.00025776  max_mem: 11576M
[12/11 22:40:07 d2.utils.events]:  eta: 0:06:55  iter: 9219  total_loss: 1.927  loss_sem_seg: 0.8295  loss_center: 0.5103  loss_offset: 0.5469  time: 0.5340  data_time: 0.0509  lr: 0.00025196  max_mem: 11576M
[12/11 22:40:18 d2.utils.events]:  eta: 0:06:44  iter: 9239  total_loss: 1.848  loss_sem_seg: 0.8549  loss_center: 0.4716  loss_offset: 0.5314  time: 0.5340  data_time: 0.0451  lr: 0.00024614  max_mem: 11576M
[12/11 22:40:28 d2.utils.events]:  eta: 0:06:34  iter: 9259  total_loss: 1.86  loss_sem_seg: 0.7933  loss_center: 0.4733  loss_offset: 0.5162  time: 0.5340  data_time: 0.0439  lr: 0.00024031  max_mem: 11576M
[12/11 22:40:39 d2.utils.events]:  eta: 0:06:23  iter: 9279  total_loss: 2.006  loss_sem_seg: 0.7301  loss_center: 0.5583  loss_offset: 0.4565  time: 0.5340  data_time: 0.0504  lr: 0.00023447  max_mem: 11576M
[12/11 22:40:50 d2.utils.events]:  eta: 0:06:12  iter: 9299  total_loss: 1.987  loss_sem_seg: 0.8353  loss_center: 0.618  loss_offset: 0.5792  time: 0.5340  data_time: 0.0526  lr: 0.00022861  max_mem: 11576M
[12/11 22:41:00 d2.utils.events]:  eta: 0:06:02  iter: 9319  total_loss: 1.63  loss_sem_seg: 0.7202  loss_center: 0.4234  loss_offset: 0.5093  time: 0.5340  data_time: 0.0505  lr: 0.00022273  max_mem: 11576M
[12/11 22:41:11 d2.utils.events]:  eta: 0:05:51  iter: 9339  total_loss: 1.723  loss_sem_seg: 0.7295  loss_center: 0.4599  loss_offset: 0.414  time: 0.5340  data_time: 0.0558  lr: 0.00021683  max_mem: 11576M
[12/11 22:41:22 d2.utils.events]:  eta: 0:05:40  iter: 9359  total_loss: 1.831  loss_sem_seg: 0.8142  loss_center: 0.5285  loss_offset: 0.5668  time: 0.5340  data_time: 0.0459  lr: 0.00021092  max_mem: 11576M
[12/11 22:41:33 d2.utils.events]:  eta: 0:05:30  iter: 9379  total_loss: 1.867  loss_sem_seg: 0.8636  loss_center: 0.504  loss_offset: 0.5133  time: 0.5340  data_time: 0.0481  lr: 0.00020499  max_mem: 11576M
[12/11 22:41:43 d2.utils.events]:  eta: 0:05:19  iter: 9399  total_loss: 1.934  loss_sem_seg: 0.8767  loss_center: 0.4414  loss_offset: 0.4777  time: 0.5340  data_time: 0.0525  lr: 0.00019903  max_mem: 11576M
[12/11 22:41:54 d2.utils.events]:  eta: 0:05:08  iter: 9419  total_loss: 1.904  loss_sem_seg: 0.797  loss_center: 0.4226  loss_offset: 0.5889  time: 0.5340  data_time: 0.0529  lr: 0.00019306  max_mem: 11576M
[12/11 22:42:05 d2.utils.events]:  eta: 0:04:58  iter: 9439  total_loss: 1.933  loss_sem_seg: 0.8337  loss_center: 0.4533  loss_offset: 0.6087  time: 0.5341  data_time: 0.0557  lr: 0.00018707  max_mem: 11576M
[12/11 22:42:16 d2.utils.events]:  eta: 0:04:47  iter: 9459  total_loss: 1.806  loss_sem_seg: 0.6667  loss_center: 0.5585  loss_offset: 0.4629  time: 0.5340  data_time: 0.0470  lr: 0.00018106  max_mem: 11576M
[12/11 22:42:26 d2.utils.events]:  eta: 0:04:36  iter: 9479  total_loss: 1.876  loss_sem_seg: 0.8271  loss_center: 0.4585  loss_offset: 0.5233  time: 0.5341  data_time: 0.0486  lr: 0.00017502  max_mem: 11576M
[12/11 22:42:37 d2.utils.events]:  eta: 0:04:26  iter: 9499  total_loss: 1.906  loss_sem_seg: 0.8147  loss_center: 0.592  loss_offset: 0.4685  time: 0.5341  data_time: 0.0520  lr: 0.00016896  max_mem: 11576M
[12/11 22:42:48 d2.utils.events]:  eta: 0:04:15  iter: 9519  total_loss: 1.839  loss_sem_seg: 0.7517  loss_center: 0.5276  loss_offset: 0.5055  time: 0.5341  data_time: 0.0586  lr: 0.00016288  max_mem: 11576M
[12/11 22:42:59 d2.utils.events]:  eta: 0:04:05  iter: 9539  total_loss: 1.67  loss_sem_seg: 0.7349  loss_center: 0.5212  loss_offset: 0.4886  time: 0.5341  data_time: 0.0507  lr: 0.00015677  max_mem: 11576M
[12/11 22:43:10 d2.utils.events]:  eta: 0:03:54  iter: 9559  total_loss: 1.742  loss_sem_seg: 0.8016  loss_center: 0.4827  loss_offset: 0.4867  time: 0.5341  data_time: 0.0524  lr: 0.00015064  max_mem: 11576M
[12/11 22:43:20 d2.utils.events]:  eta: 0:03:43  iter: 9579  total_loss: 1.933  loss_sem_seg: 0.8341  loss_center: 0.5002  loss_offset: 0.5872  time: 0.5341  data_time: 0.0536  lr: 0.00014448  max_mem: 11576M
[12/11 22:43:31 d2.utils.events]:  eta: 0:03:33  iter: 9599  total_loss: 1.938  loss_sem_seg: 0.8537  loss_center: 0.4945  loss_offset: 0.532  time: 0.5341  data_time: 0.0474  lr: 0.00013828  max_mem: 11576M
[12/11 22:43:42 d2.utils.events]:  eta: 0:03:22  iter: 9619  total_loss: 1.948  loss_sem_seg: 0.8455  loss_center: 0.4812  loss_offset: 0.5928  time: 0.5341  data_time: 0.0512  lr: 0.00013206  max_mem: 11576M
[12/11 22:43:53 d2.utils.events]:  eta: 0:03:11  iter: 9639  total_loss: 1.846  loss_sem_seg: 0.8095  loss_center: 0.4307  loss_offset: 0.55  time: 0.5341  data_time: 0.0524  lr: 0.0001258  max_mem: 11576M
[12/11 22:44:03 d2.utils.events]:  eta: 0:03:01  iter: 9659  total_loss: 1.802  loss_sem_seg: 0.7592  loss_center: 0.5064  loss_offset: 0.4448  time: 0.5341  data_time: 0.0489  lr: 0.00011951  max_mem: 11576M
[12/11 22:44:14 d2.utils.events]:  eta: 0:02:50  iter: 9679  total_loss: 1.73  loss_sem_seg: 0.7415  loss_center: 0.4237  loss_offset: 0.4876  time: 0.5341  data_time: 0.0459  lr: 0.00011319  max_mem: 11576M
[12/11 22:44:25 d2.utils.events]:  eta: 0:02:39  iter: 9699  total_loss: 1.611  loss_sem_seg: 0.7493  loss_center: 0.4444  loss_offset: 0.3773  time: 0.5341  data_time: 0.0484  lr: 0.00010682  max_mem: 11576M
[12/11 22:44:35 d2.utils.events]:  eta: 0:02:29  iter: 9719  total_loss: 1.793  loss_sem_seg: 0.8152  loss_center: 0.5121  loss_offset: 0.5202  time: 0.5341  data_time: 0.0482  lr: 0.00010041  max_mem: 11576M
[12/11 22:44:46 d2.utils.events]:  eta: 0:02:18  iter: 9739  total_loss: 1.668  loss_sem_seg: 0.7816  loss_center: 0.4454  loss_offset: 0.4574  time: 0.5341  data_time: 0.0495  lr: 9.3954e-05  max_mem: 11576M
[12/11 22:44:57 d2.utils.events]:  eta: 0:02:07  iter: 9759  total_loss: 1.939  loss_sem_seg: 0.9685  loss_center: 0.4283  loss_offset: 0.536  time: 0.5341  data_time: 0.0487  lr: 8.7449e-05  max_mem: 11576M
[12/11 22:45:07 d2.utils.events]:  eta: 0:01:57  iter: 9779  total_loss: 1.779  loss_sem_seg: 0.767  loss_center: 0.4685  loss_offset: 0.45  time: 0.5341  data_time: 0.0495  lr: 8.089e-05  max_mem: 11576M
[12/11 22:45:18 d2.utils.events]:  eta: 0:01:46  iter: 9799  total_loss: 1.822  loss_sem_seg: 0.8504  loss_center: 0.4094  loss_offset: 0.482  time: 0.5341  data_time: 0.0516  lr: 7.4271e-05  max_mem: 11576M
[12/11 22:45:29 d2.utils.events]:  eta: 0:01:35  iter: 9819  total_loss: 1.838  loss_sem_seg: 0.757  loss_center: 0.5207  loss_offset: 0.5682  time: 0.5341  data_time: 0.0492  lr: 6.7585e-05  max_mem: 11576M
[12/11 22:45:40 d2.utils.events]:  eta: 0:01:25  iter: 9839  total_loss: 1.655  loss_sem_seg: 0.71  loss_center: 0.4793  loss_offset: 0.4477  time: 0.5341  data_time: 0.0549  lr: 6.0825e-05  max_mem: 11576M
[12/11 22:45:50 d2.utils.events]:  eta: 0:01:14  iter: 9859  total_loss: 1.8  loss_sem_seg: 0.7599  loss_center: 0.5371  loss_offset: 0.484  time: 0.5341  data_time: 0.0465  lr: 5.3981e-05  max_mem: 11576M
[12/11 22:46:01 d2.utils.events]:  eta: 0:01:03  iter: 9879  total_loss: 1.871  loss_sem_seg: 0.6689  loss_center: 0.508  loss_offset: 0.5076  time: 0.5341  data_time: 0.0484  lr: 4.7038e-05  max_mem: 11576M
[12/11 22:46:12 d2.utils.events]:  eta: 0:00:53  iter: 9899  total_loss: 1.885  loss_sem_seg: 0.7693  loss_center: 0.5338  loss_offset: 0.4916  time: 0.5341  data_time: 0.0518  lr: 3.9979e-05  max_mem: 11576M
[12/11 22:46:23 d2.utils.events]:  eta: 0:00:42  iter: 9919  total_loss: 1.938  loss_sem_seg: 0.8597  loss_center: 0.524  loss_offset: 0.5164  time: 0.5341  data_time: 0.0516  lr: 3.2778e-05  max_mem: 11576M
[12/11 22:46:33 d2.utils.events]:  eta: 0:00:31  iter: 9939  total_loss: 1.772  loss_sem_seg: 0.8089  loss_center: 0.4708  loss_offset: 0.4743  time: 0.5341  data_time: 0.0479  lr: 2.5394e-05  max_mem: 11576M
[12/11 22:46:44 d2.utils.events]:  eta: 0:00:21  iter: 9959  total_loss: 1.942  loss_sem_seg: 0.805  loss_center: 0.4977  loss_offset: 0.5222  time: 0.5341  data_time: 0.0466  lr: 1.776e-05  max_mem: 11576M
[12/11 22:46:55 d2.utils.events]:  eta: 0:00:10  iter: 9979  total_loss: 1.986  loss_sem_seg: 0.8604  loss_center: 0.5512  loss_offset: 0.5315  time: 0.5341  data_time: 0.0488  lr: 9.7261e-06  max_mem: 11576M
[12/11 22:47:05 fvcore.common.checkpoint]: Saving checkpoint to ./output/model_0009999.pth
[12/11 22:47:06 fvcore.common.checkpoint]: Saving checkpoint to ./output/model_final.pth
[12/11 22:47:07 d2.utils.events]:  eta: 0:00:00  iter: 9999  total_loss: 1.889  loss_sem_seg: 0.8194  loss_center: 0.507  loss_offset: 0.5326  time: 0.5341  data_time: 0.0489  lr: 6.2797e-07  max_mem: 11576M
[12/11 22:47:08 d2.engine.hooks]: Overall training speed: 9998 iterations in 1:29:00 (0.5342 s / it)
[12/11 22:47:08 d2.engine.hooks]: Total training time: 1:29:12 (0:00:12 on hooks)
[12/11 22:47:08 d2.data.dataset_mapper]: [DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(640, 640), max_size=640, sample_style='choice')]
[12/11 22:47:08 d2.data.common]: Serializing the dataset using: <class 'detectron2.data.common.NumpySerializedList'>
[12/11 22:47:08 d2.data.common]: Serializing 5000 elements to byte tensors and concatenating them all ...
[12/11 22:47:08 d2.data.common]: Serialized dataset takes 3.40 MiB
/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:481: UserWarning: This DataLoader will create 10 worker processes in total. Our suggested max number of worker in current system is 8, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.
  cpuset_checked))
[12/11 22:47:09 d2.evaluation.evaluator]: Start inference on 5000 batches
/usr/local/lib/python3.7/dist-packages/torch/functional.py:445: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at  ../aten/src/ATen/native/TensorShape.cpp:2157.)
  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]
[12/11 22:47:11 d2.evaluation.evaluator]: Inference done 11/5000. Dataloading: 0.0007 s/iter. Inference: 0.0652 s/iter. Eval: 0.0369 s/iter. Total: 0.1028 s/iter. ETA=0:08:32
[12/11 22:47:16 d2.evaluation.evaluator]: Inference done 66/5000. Dataloading: 0.0009 s/iter. Inference: 0.0606 s/iter. Eval: 0.0307 s/iter. Total: 0.0923 s/iter. ETA=0:07:35
[12/11 22:47:21 d2.evaluation.evaluator]: Inference done 117/5000. Dataloading: 0.0010 s/iter. Inference: 0.0614 s/iter. Eval: 0.0325 s/iter. Total: 0.0950 s/iter. ETA=0:07:43
[12/11 22:47:26 d2.evaluation.evaluator]: Inference done 166/5000. Dataloading: 0.0010 s/iter. Inference: 0.0630 s/iter. Eval: 0.0332 s/iter. Total: 0.0973 s/iter. ETA=0:07:50
[12/11 22:47:31 d2.evaluation.evaluator]: Inference done 218/5000. Dataloading: 0.0011 s/iter. Inference: 0.0630 s/iter. Eval: 0.0331 s/iter. Total: 0.0971 s/iter. ETA=0:07:44
[12/11 22:47:36 d2.evaluation.evaluator]: Inference done 271/5000. Dataloading: 0.0011 s/iter. Inference: 0.0629 s/iter. Eval: 0.0329 s/iter. Total: 0.0969 s/iter. ETA=0:07:38
[12/11 22:47:41 d2.evaluation.evaluator]: Inference done 323/5000. Dataloading: 0.0011 s/iter. Inference: 0.0628 s/iter. Eval: 0.0329 s/iter. Total: 0.0968 s/iter. ETA=0:07:32
[12/11 22:47:46 d2.evaluation.evaluator]: Inference done 374/5000. Dataloading: 0.0011 s/iter. Inference: 0.0630 s/iter. Eval: 0.0329 s/iter. Total: 0.0971 s/iter. ETA=0:07:29
[12/11 22:47:51 d2.evaluation.evaluator]: Inference done 428/5000. Dataloading: 0.0011 s/iter. Inference: 0.0628 s/iter. Eval: 0.0326 s/iter. Total: 0.0966 s/iter. ETA=0:07:21
[12/11 22:47:56 d2.evaluation.evaluator]: Inference done 484/5000. Dataloading: 0.0011 s/iter. Inference: 0.0624 s/iter. Eval: 0.0324 s/iter. Total: 0.0959 s/iter. ETA=0:07:13
[12/11 22:48:01 d2.evaluation.evaluator]: Inference done 536/5000. Dataloading: 0.0011 s/iter. Inference: 0.0625 s/iter. Eval: 0.0325 s/iter. Total: 0.0960 s/iter. ETA=0:07:08
[12/11 22:48:06 d2.evaluation.evaluator]: Inference done 583/5000. Dataloading: 0.0011 s/iter. Inference: 0.0634 s/iter. Eval: 0.0325 s/iter. Total: 0.0970 s/iter. ETA=0:07:08
[12/11 22:48:11 d2.evaluation.evaluator]: Inference done 634/5000. Dataloading: 0.0011 s/iter. Inference: 0.0635 s/iter. Eval: 0.0326 s/iter. Total: 0.0972 s/iter. ETA=0:07:04
[12/11 22:48:16 d2.evaluation.evaluator]: Inference done 684/5000. Dataloading: 0.0011 s/iter. Inference: 0.0636 s/iter. Eval: 0.0327 s/iter. Total: 0.0975 s/iter. ETA=0:07:00
[12/11 22:48:21 d2.evaluation.evaluator]: Inference done 736/5000. Dataloading: 0.0011 s/iter. Inference: 0.0635 s/iter. Eval: 0.0327 s/iter. Total: 0.0974 s/iter. ETA=0:06:55
[12/11 22:48:26 d2.evaluation.evaluator]: Inference done 789/5000. Dataloading: 0.0011 s/iter. Inference: 0.0634 s/iter. Eval: 0.0327 s/iter. Total: 0.0973 s/iter. ETA=0:06:49
[12/11 22:48:31 d2.evaluation.evaluator]: Inference done 844/5000. Dataloading: 0.0011 s/iter. Inference: 0.0633 s/iter. Eval: 0.0326 s/iter. Total: 0.0970 s/iter. ETA=0:06:43
[12/11 22:48:36 d2.evaluation.evaluator]: Inference done 900/5000. Dataloading: 0.0011 s/iter. Inference: 0.0630 s/iter. Eval: 0.0325 s/iter. Total: 0.0966 s/iter. ETA=0:06:36
[12/11 22:48:41 d2.evaluation.evaluator]: Inference done 955/5000. Dataloading: 0.0011 s/iter. Inference: 0.0628 s/iter. Eval: 0.0324 s/iter. Total: 0.0963 s/iter. ETA=0:06:29
[12/11 22:48:46 d2.evaluation.evaluator]: Inference done 1008/5000. Dataloading: 0.0011 s/iter. Inference: 0.0628 s/iter. Eval: 0.0324 s/iter. Total: 0.0963 s/iter. ETA=0:06:24
[12/11 22:48:52 d2.evaluation.evaluator]: Inference done 1060/5000. Dataloading: 0.0011 s/iter. Inference: 0.0627 s/iter. Eval: 0.0324 s/iter. Total: 0.0963 s/iter. ETA=0:06:19
[12/11 22:48:57 d2.evaluation.evaluator]: Inference done 1113/5000. Dataloading: 0.0011 s/iter. Inference: 0.0627 s/iter. Eval: 0.0324 s/iter. Total: 0.0962 s/iter. ETA=0:06:13
[12/11 22:49:02 d2.evaluation.evaluator]: Inference done 1167/5000. Dataloading: 0.0011 s/iter. Inference: 0.0626 s/iter. Eval: 0.0324 s/iter. Total: 0.0961 s/iter. ETA=0:06:08
[12/11 22:49:07 d2.evaluation.evaluator]: Inference done 1217/5000. Dataloading: 0.0011 s/iter. Inference: 0.0627 s/iter. Eval: 0.0325 s/iter. Total: 0.0963 s/iter. ETA=0:06:04
[12/11 22:49:12 d2.evaluation.evaluator]: Inference done 1267/5000. Dataloading: 0.0011 s/iter. Inference: 0.0627 s/iter. Eval: 0.0326 s/iter. Total: 0.0965 s/iter. ETA=0:06:00
[12/11 22:49:17 d2.evaluation.evaluator]: Inference done 1320/5000. Dataloading: 0.0011 s/iter. Inference: 0.0627 s/iter. Eval: 0.0326 s/iter. Total: 0.0964 s/iter. ETA=0:05:54
[12/11 22:49:22 d2.evaluation.evaluator]: Inference done 1371/5000. Dataloading: 0.0011 s/iter. Inference: 0.0628 s/iter. Eval: 0.0326 s/iter. Total: 0.0965 s/iter. ETA=0:05:50
[12/11 22:49:27 d2.evaluation.evaluator]: Inference done 1424/5000. Dataloading: 0.0011 s/iter. Inference: 0.0627 s/iter. Eval: 0.0327 s/iter. Total: 0.0965 s/iter. ETA=0:05:45
[12/11 22:49:32 d2.evaluation.evaluator]: Inference done 1475/5000. Dataloading: 0.0011 s/iter. Inference: 0.0627 s/iter. Eval: 0.0327 s/iter. Total: 0.0966 s/iter. ETA=0:05:40
[12/11 22:49:37 d2.evaluation.evaluator]: Inference done 1527/5000. Dataloading: 0.0011 s/iter. Inference: 0.0626 s/iter. Eval: 0.0328 s/iter. Total: 0.0966 s/iter. ETA=0:05:35
[12/11 22:49:42 d2.evaluation.evaluator]: Inference done 1578/5000. Dataloading: 0.0011 s/iter. Inference: 0.0627 s/iter. Eval: 0.0328 s/iter. Total: 0.0966 s/iter. ETA=0:05:30
[12/11 22:49:47 d2.evaluation.evaluator]: Inference done 1629/5000. Dataloading: 0.0011 s/iter. Inference: 0.0627 s/iter. Eval: 0.0329 s/iter. Total: 0.0967 s/iter. ETA=0:05:26
[12/11 22:49:52 d2.evaluation.evaluator]: Inference done 1680/5000. Dataloading: 0.0011 s/iter. Inference: 0.0628 s/iter. Eval: 0.0329 s/iter. Total: 0.0968 s/iter. ETA=0:05:21
[12/11 22:49:57 d2.evaluation.evaluator]: Inference done 1732/5000. Dataloading: 0.0011 s/iter. Inference: 0.0627 s/iter. Eval: 0.0329 s/iter. Total: 0.0968 s/iter. ETA=0:05:16
[12/11 22:50:02 d2.evaluation.evaluator]: Inference done 1785/5000. Dataloading: 0.0011 s/iter. Inference: 0.0627 s/iter. Eval: 0.0329 s/iter. Total: 0.0968 s/iter. ETA=0:05:11
[12/11 22:50:07 d2.evaluation.evaluator]: Inference done 1838/5000. Dataloading: 0.0011 s/iter. Inference: 0.0627 s/iter. Eval: 0.0329 s/iter. Total: 0.0967 s/iter. ETA=0:05:05
[12/11 22:50:12 d2.evaluation.evaluator]: Inference done 1890/5000. Dataloading: 0.0011 s/iter. Inference: 0.0627 s/iter. Eval: 0.0329 s/iter. Total: 0.0968 s/iter. ETA=0:05:00
[12/11 22:50:17 d2.evaluation.evaluator]: Inference done 1945/5000. Dataloading: 0.0011 s/iter. Inference: 0.0626 s/iter. Eval: 0.0329 s/iter. Total: 0.0966 s/iter. ETA=0:04:55
[12/11 22:50:22 d2.evaluation.evaluator]: Inference done 1997/5000. Dataloading: 0.0011 s/iter. Inference: 0.0626 s/iter. Eval: 0.0329 s/iter. Total: 0.0966 s/iter. ETA=0:04:50
[12/11 22:50:27 d2.evaluation.evaluator]: Inference done 2048/5000. Dataloading: 0.0011 s/iter. Inference: 0.0626 s/iter. Eval: 0.0329 s/iter. Total: 0.0967 s/iter. ETA=0:04:45
[12/11 22:50:33 d2.evaluation.evaluator]: Inference done 2103/5000. Dataloading: 0.0011 s/iter. Inference: 0.0625 s/iter. Eval: 0.0329 s/iter. Total: 0.0966 s/iter. ETA=0:04:39
[12/11 22:50:38 d2.evaluation.evaluator]: Inference done 2156/5000. Dataloading: 0.0011 s/iter. Inference: 0.0625 s/iter. Eval: 0.0329 s/iter. Total: 0.0966 s/iter. ETA=0:04:34
[12/11 22:50:43 d2.evaluation.evaluator]: Inference done 2208/5000. Dataloading: 0.0011 s/iter. Inference: 0.0625 s/iter. Eval: 0.0329 s/iter. Total: 0.0966 s/iter. ETA=0:04:29
[12/11 22:50:48 d2.evaluation.evaluator]: Inference done 2261/5000. Dataloading: 0.0011 s/iter. Inference: 0.0625 s/iter. Eval: 0.0328 s/iter. Total: 0.0965 s/iter. ETA=0:04:24
[12/11 22:50:53 d2.evaluation.evaluator]: Inference done 2314/5000. Dataloading: 0.0011 s/iter. Inference: 0.0625 s/iter. Eval: 0.0328 s/iter. Total: 0.0965 s/iter. ETA=0:04:19
[12/11 22:50:58 d2.evaluation.evaluator]: Inference done 2371/5000. Dataloading: 0.0011 s/iter. Inference: 0.0624 s/iter. Eval: 0.0327 s/iter. Total: 0.0963 s/iter. ETA=0:04:13
[12/11 22:51:03 d2.evaluation.evaluator]: Inference done 2421/5000. Dataloading: 0.0011 s/iter. Inference: 0.0624 s/iter. Eval: 0.0328 s/iter. Total: 0.0964 s/iter. ETA=0:04:08
[12/11 22:51:08 d2.evaluation.evaluator]: Inference done 2474/5000. Dataloading: 0.0011 s/iter. Inference: 0.0624 s/iter. Eval: 0.0328 s/iter. Total: 0.0964 s/iter. ETA=0:04:03
[12/11 22:51:13 d2.evaluation.evaluator]: Inference done 2527/5000. Dataloading: 0.0011 s/iter. Inference: 0.0624 s/iter. Eval: 0.0328 s/iter. Total: 0.0963 s/iter. ETA=0:03:58
[12/11 22:51:18 d2.evaluation.evaluator]: Inference done 2580/5000. Dataloading: 0.0011 s/iter. Inference: 0.0624 s/iter. Eval: 0.0328 s/iter. Total: 0.0963 s/iter. ETA=0:03:53
[12/11 22:51:23 d2.evaluation.evaluator]: Inference done 2631/5000. Dataloading: 0.0011 s/iter. Inference: 0.0624 s/iter. Eval: 0.0328 s/iter. Total: 0.0964 s/iter. ETA=0:03:48
[12/11 22:51:28 d2.evaluation.evaluator]: Inference done 2686/5000. Dataloading: 0.0011 s/iter. Inference: 0.0624 s/iter. Eval: 0.0327 s/iter. Total: 0.0963 s/iter. ETA=0:03:42
[12/11 22:51:33 d2.evaluation.evaluator]: Inference done 2740/5000. Dataloading: 0.0011 s/iter. Inference: 0.0623 s/iter. Eval: 0.0327 s/iter. Total: 0.0962 s/iter. ETA=0:03:37
[12/11 22:51:38 d2.evaluation.evaluator]: Inference done 2793/5000. Dataloading: 0.0011 s/iter. Inference: 0.0623 s/iter. Eval: 0.0327 s/iter. Total: 0.0962 s/iter. ETA=0:03:32
[12/11 22:51:43 d2.evaluation.evaluator]: Inference done 2847/5000. Dataloading: 0.0011 s/iter. Inference: 0.0623 s/iter. Eval: 0.0327 s/iter. Total: 0.0961 s/iter. ETA=0:03:27
[12/11 22:51:48 d2.evaluation.evaluator]: Inference done 2897/5000. Dataloading: 0.0011 s/iter. Inference: 0.0623 s/iter. Eval: 0.0327 s/iter. Total: 0.0962 s/iter. ETA=0:03:22
[12/11 22:51:53 d2.evaluation.evaluator]: Inference done 2948/5000. Dataloading: 0.0011 s/iter. Inference: 0.0623 s/iter. Eval: 0.0328 s/iter. Total: 0.0962 s/iter. ETA=0:03:17
[12/11 22:51:58 d2.evaluation.evaluator]: Inference done 3003/5000. Dataloading: 0.0011 s/iter. Inference: 0.0623 s/iter. Eval: 0.0327 s/iter. Total: 0.0962 s/iter. ETA=0:03:12
[12/11 22:52:03 d2.evaluation.evaluator]: Inference done 3057/5000. Dataloading: 0.0011 s/iter. Inference: 0.0622 s/iter. Eval: 0.0327 s/iter. Total: 0.0961 s/iter. ETA=0:03:06
[12/11 22:52:08 d2.evaluation.evaluator]: Inference done 3111/5000. Dataloading: 0.0011 s/iter. Inference: 0.0622 s/iter. Eval: 0.0327 s/iter. Total: 0.0961 s/iter. ETA=0:03:01
[12/11 22:52:13 d2.evaluation.evaluator]: Inference done 3162/5000. Dataloading: 0.0011 s/iter. Inference: 0.0622 s/iter. Eval: 0.0327 s/iter. Total: 0.0961 s/iter. ETA=0:02:56
[12/11 22:52:18 d2.evaluation.evaluator]: Inference done 3214/5000. Dataloading: 0.0011 s/iter. Inference: 0.0622 s/iter. Eval: 0.0327 s/iter. Total: 0.0961 s/iter. ETA=0:02:51
[12/11 22:52:23 d2.evaluation.evaluator]: Inference done 3267/5000. Dataloading: 0.0011 s/iter. Inference: 0.0622 s/iter. Eval: 0.0327 s/iter. Total: 0.0961 s/iter. ETA=0:02:46
[12/11 22:52:29 d2.evaluation.evaluator]: Inference done 3318/5000. Dataloading: 0.0011 s/iter. Inference: 0.0622 s/iter. Eval: 0.0328 s/iter. Total: 0.0962 s/iter. ETA=0:02:41
[12/11 22:52:34 d2.evaluation.evaluator]: Inference done 3369/5000. Dataloading: 0.0011 s/iter. Inference: 0.0623 s/iter. Eval: 0.0328 s/iter. Total: 0.0962 s/iter. ETA=0:02:36
[12/11 22:52:39 d2.evaluation.evaluator]: Inference done 3422/5000. Dataloading: 0.0011 s/iter. Inference: 0.0622 s/iter. Eval: 0.0328 s/iter. Total: 0.0962 s/iter. ETA=0:02:31
[12/11 22:52:44 d2.evaluation.evaluator]: Inference done 3474/5000. Dataloading: 0.0011 s/iter. Inference: 0.0622 s/iter. Eval: 0.0328 s/iter. Total: 0.0962 s/iter. ETA=0:02:26
[12/11 22:52:49 d2.evaluation.evaluator]: Inference done 3527/5000. Dataloading: 0.0011 s/iter. Inference: 0.0622 s/iter. Eval: 0.0328 s/iter. Total: 0.0962 s/iter. ETA=0:02:21
[12/11 22:52:54 d2.evaluation.evaluator]: Inference done 3579/5000. Dataloading: 0.0011 s/iter. Inference: 0.0622 s/iter. Eval: 0.0328 s/iter. Total: 0.0962 s/iter. ETA=0:02:16
[12/11 22:52:59 d2.evaluation.evaluator]: Inference done 3630/5000. Dataloading: 0.0011 s/iter. Inference: 0.0623 s/iter. Eval: 0.0328 s/iter. Total: 0.0962 s/iter. ETA=0:02:11
[12/11 22:53:04 d2.evaluation.evaluator]: Inference done 3684/5000. Dataloading: 0.0011 s/iter. Inference: 0.0622 s/iter. Eval: 0.0328 s/iter. Total: 0.0962 s/iter. ETA=0:02:06
[12/11 22:53:09 d2.evaluation.evaluator]: Inference done 3738/5000. Dataloading: 0.0011 s/iter. Inference: 0.0622 s/iter. Eval: 0.0328 s/iter. Total: 0.0961 s/iter. ETA=0:02:01
[12/11 22:53:14 d2.evaluation.evaluator]: Inference done 3790/5000. Dataloading: 0.0011 s/iter. Inference: 0.0622 s/iter. Eval: 0.0328 s/iter. Total: 0.0962 s/iter. ETA=0:01:56
[12/11 22:53:19 d2.evaluation.evaluator]: Inference done 3845/5000. Dataloading: 0.0011 s/iter. Inference: 0.0622 s/iter. Eval: 0.0327 s/iter. Total: 0.0961 s/iter. ETA=0:01:50
[12/11 22:53:24 d2.evaluation.evaluator]: Inference done 3901/5000. Dataloading: 0.0011 s/iter. Inference: 0.0621 s/iter. Eval: 0.0327 s/iter. Total: 0.0960 s/iter. ETA=0:01:45
[12/11 22:53:29 d2.evaluation.evaluator]: Inference done 3954/5000. Dataloading: 0.0011 s/iter. Inference: 0.0621 s/iter. Eval: 0.0327 s/iter. Total: 0.0960 s/iter. ETA=0:01:40
[12/11 22:53:34 d2.evaluation.evaluator]: Inference done 4008/5000. Dataloading: 0.0011 s/iter. Inference: 0.0621 s/iter. Eval: 0.0327 s/iter. Total: 0.0960 s/iter. ETA=0:01:35
[12/11 22:53:39 d2.evaluation.evaluator]: Inference done 4061/5000. Dataloading: 0.0011 s/iter. Inference: 0.0621 s/iter. Eval: 0.0327 s/iter. Total: 0.0959 s/iter. ETA=0:01:30
[12/11 22:53:44 d2.evaluation.evaluator]: Inference done 4115/5000. Dataloading: 0.0011 s/iter. Inference: 0.0621 s/iter. Eval: 0.0327 s/iter. Total: 0.0959 s/iter. ETA=0:01:24
[12/11 22:53:49 d2.evaluation.evaluator]: Inference done 4166/5000. Dataloading: 0.0011 s/iter. Inference: 0.0621 s/iter. Eval: 0.0327 s/iter. Total: 0.0960 s/iter. ETA=0:01:20
[12/11 22:53:54 d2.evaluation.evaluator]: Inference done 4218/5000. Dataloading: 0.0011 s/iter. Inference: 0.0621 s/iter. Eval: 0.0327 s/iter. Total: 0.0960 s/iter. ETA=0:01:15
[12/11 22:53:59 d2.evaluation.evaluator]: Inference done 4271/5000. Dataloading: 0.0011 s/iter. Inference: 0.0621 s/iter. Eval: 0.0327 s/iter. Total: 0.0960 s/iter. ETA=0:01:09
[12/11 22:54:04 d2.evaluation.evaluator]: Inference done 4325/5000. Dataloading: 0.0011 s/iter. Inference: 0.0620 s/iter. Eval: 0.0327 s/iter. Total: 0.0959 s/iter. ETA=0:01:04
[12/11 22:54:09 d2.evaluation.evaluator]: Inference done 4380/5000. Dataloading: 0.0011 s/iter. Inference: 0.0620 s/iter. Eval: 0.0327 s/iter. Total: 0.0959 s/iter. ETA=0:00:59
[12/11 22:54:14 d2.evaluation.evaluator]: Inference done 4431/5000. Dataloading: 0.0011 s/iter. Inference: 0.0621 s/iter. Eval: 0.0327 s/iter. Total: 0.0959 s/iter. ETA=0:00:54
[12/11 22:54:20 d2.evaluation.evaluator]: Inference done 4485/5000. Dataloading: 0.0011 s/iter. Inference: 0.0621 s/iter. Eval: 0.0327 s/iter. Total: 0.0959 s/iter. ETA=0:00:49
[12/11 22:54:25 d2.evaluation.evaluator]: Inference done 4537/5000. Dataloading: 0.0011 s/iter. Inference: 0.0621 s/iter. Eval: 0.0327 s/iter. Total: 0.0959 s/iter. ETA=0:00:44
[12/11 22:54:30 d2.evaluation.evaluator]: Inference done 4590/5000. Dataloading: 0.0011 s/iter. Inference: 0.0621 s/iter. Eval: 0.0327 s/iter. Total: 0.0959 s/iter. ETA=0:00:39
[12/11 22:54:35 d2.evaluation.evaluator]: Inference done 4644/5000. Dataloading: 0.0011 s/iter. Inference: 0.0620 s/iter. Eval: 0.0326 s/iter. Total: 0.0959 s/iter. ETA=0:00:34
[12/11 22:54:40 d2.evaluation.evaluator]: Inference done 4697/5000. Dataloading: 0.0011 s/iter. Inference: 0.0620 s/iter. Eval: 0.0326 s/iter. Total: 0.0958 s/iter. ETA=0:00:29
[12/11 22:54:45 d2.evaluation.evaluator]: Inference done 4751/5000. Dataloading: 0.0011 s/iter. Inference: 0.0620 s/iter. Eval: 0.0326 s/iter. Total: 0.0958 s/iter. ETA=0:00:23
[12/11 22:54:50 d2.evaluation.evaluator]: Inference done 4803/5000. Dataloading: 0.0011 s/iter. Inference: 0.0620 s/iter. Eval: 0.0326 s/iter. Total: 0.0958 s/iter. ETA=0:00:18
[12/11 22:54:55 d2.evaluation.evaluator]: Inference done 4856/5000. Dataloading: 0.0011 s/iter. Inference: 0.0620 s/iter. Eval: 0.0326 s/iter. Total: 0.0958 s/iter. ETA=0:00:13
[12/11 22:55:00 d2.evaluation.evaluator]: Inference done 4910/5000. Dataloading: 0.0011 s/iter. Inference: 0.0620 s/iter. Eval: 0.0326 s/iter. Total: 0.0958 s/iter. ETA=0:00:08
[12/11 22:55:05 d2.evaluation.evaluator]: Inference done 4963/5000. Dataloading: 0.0011 s/iter. Inference: 0.0620 s/iter. Eval: 0.0326 s/iter. Total: 0.0958 s/iter. ETA=0:00:03
[12/11 22:55:09 d2.evaluation.evaluator]: Total inference time: 0:07:58.930010 (0.095882 s / iter per device, on 1 devices)
[12/11 22:55:09 d2.evaluation.evaluator]: Total inference pure compute time: 0:05:10 (0.062070 s / iter per device, on 1 devices)
[12/11 22:55:09 d2.evaluation.panoptic_evaluation]: Writing all panoptic predictions to /tmp/panoptic_eval4uggpa_p ...
[12/11 22:55:31 d2.evaluation.panoptic_evaluation]: Panoptic Evaluation Results:
|        |   PQ   |   SQ   |   RQ   |  #categories  |
|:------:|:------:|:------:|:------:|:-------------:|
|  All   | 22.502 | 68.998 | 29.112 |      133      |
| Things | 23.011 | 71.151 | 29.809 |      80       |
| Stuff  | 21.734 | 65.749 | 28.060 |      53       |
[12/11 22:55:32 d2.evaluation.coco_evaluation]: Preparing results for COCO format ...
[12/11 22:55:32 d2.evaluation.coco_evaluation]: Saving results to ./output/inference/coco_instances_results.json
[12/11 22:55:32 d2.evaluation.coco_evaluation]: Evaluating predictions with unofficial COCO API...
Loading and preparing results...
DONE (t=0.04s)
creating index...
index created!
[12/11 22:55:32 d2.evaluation.fast_eval_api]: Evaluate annotation type *bbox*
[12/11 22:55:40 d2.evaluation.fast_eval_api]: COCOeval_opt.evaluate() finished in 7.68 seconds.
[12/11 22:55:40 d2.evaluation.fast_eval_api]: Accumulating evaluation results...
[12/11 22:55:40 d2.evaluation.fast_eval_api]: COCOeval_opt.accumulate() finished in 0.62 seconds.
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.097
 Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.182
 Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.089
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.016
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.086
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.168
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.111
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.152
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.153
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.019
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.129
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.275
[12/11 22:55:40 d2.evaluation.coco_evaluation]: Evaluation results for bbox: 
|  AP   |  AP50  |  AP75  |  APs  |  APm  |  APl   |
|:-----:|:------:|:------:|:-----:|:-----:|:------:|
| 9.700 | 18.237 | 8.945  | 1.575 | 8.622 | 16.832 |
[12/11 22:55:40 d2.evaluation.coco_evaluation]: Per-category bbox AP: 
| category      | AP     | category     | AP     | category       | AP     |
|:--------------|:-------|:-------------|:-------|:---------------|:-------|
| person        | 17.194 | bicycle      | 5.830  | car            | 9.732  |
| motorcycle    | 9.688  | airplane     | 27.219 | bus            | 36.162 |
| train         | 33.804 | truck        | 7.744  | boat           | 3.273  |
| traffic light | 2.968  | fire hydrant | 31.173 | stop sign      | 28.282 |
| parking meter | 9.276  | bench        | 3.918  | bird           | 8.870  |
| cat           | 16.628 | dog          | 22.050 | horse          | 18.679 |
| sheep         | 15.784 | cow          | 18.693 | elephant       | 32.612 |
| bear          | 43.174 | zebra        | 36.966 | giraffe        | 36.139 |
| backpack      | 0.552  | umbrella     | 10.460 | handbag        | 0.000  |
| tie           | 0.414  | suitcase     | 5.009  | frisbee        | 15.235 |
| skis          | 1.742  | snowboard    | 1.073  | sports ball    | 4.164  |
| kite          | 12.131 | baseball bat | 0.373  | baseball glove | 5.398  |
| skateboard    | 8.585  | surfboard    | 5.256  | tennis racket  | 10.145 |
| bottle        | 1.178  | wine glass   | 0.759  | cup            | 2.472  |
| fork          | 0.183  | knife        | 0.036  | spoon          | 0.000  |
| bowl          | 3.013  | banana       | 2.408  | apple          | 1.469  |
| sandwich      | 1.388  | orange       | 3.813  | broccoli       | 1.153  |
| carrot        | 0.386  | hot dog      | 0.836  | pizza          | 5.168  |
| donut         | 4.359  | cake         | 1.435  | chair          | 3.184  |
| couch         | 15.418 | potted plant | 1.838  | bed            | 19.436 |
| dining table  | 3.341  | toilet       | 23.780 | tv             | 21.400 |
| laptop        | 18.268 | mouse        | 11.281 | remote         | 1.093  |
| keyboard      | 8.091  | cell phone   | 3.518  | microwave      | 8.659  |
| oven          | 4.077  | toaster      | 0.000  | sink           | 6.762  |
| refrigerator  | 15.863 | book         | 0.472  | clock          | 13.332 |
| vase          | 2.411  | scissors     | 0.297  | teddy bear     | 7.067  |
| hair drier    | 0.000  | toothbrush   | 0.000  |                |        |
Loading and preparing results...
DONE (t=0.43s)
creating index...
index created!
[12/11 22:55:41 d2.evaluation.fast_eval_api]: Evaluate annotation type *segm*
[12/11 22:55:50 d2.evaluation.fast_eval_api]: COCOeval_opt.evaluate() finished in 8.69 seconds.
[12/11 22:55:50 d2.evaluation.fast_eval_api]: Accumulating evaluation results...
[12/11 22:55:51 d2.evaluation.fast_eval_api]: COCOeval_opt.accumulate() finished in 0.69 seconds.
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.101
 Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.194
 Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.094
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.009
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.088
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.217
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.112
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.147
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.148
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.013
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.131
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.274
[12/11 22:55:53 d2.evaluation.coco_evaluation]: Evaluation results for segm: 
|   AP   |  AP50  |  AP75  |  APs  |  APm  |  APl   |
|:------:|:------:|:------:|:-----:|:-----:|:------:|
| 10.059 | 19.382 | 9.429  | 0.917 | 8.791 | 21.659 |
[12/11 22:55:53 d2.evaluation.coco_evaluation]: Per-category segm AP: 
| category      | AP     | category     | AP     | category       | AP     |
|:--------------|:-------|:-------------|:-------|:---------------|:-------|
| person        | 12.936 | bicycle      | 3.508  | car            | 9.286  |
| motorcycle    | 6.640  | airplane     | 22.844 | bus            | 36.541 |
| train         | 38.311 | truck        | 7.859  | boat           | 2.736  |
| traffic light | 3.733  | fire hydrant | 35.489 | stop sign      | 35.577 |
| parking meter | 13.172 | bench        | 3.245  | bird           | 6.092  |
| cat           | 23.953 | dog          | 23.039 | horse          | 13.004 |
| sheep         | 13.906 | cow          | 14.127 | elephant       | 29.626 |
| bear          | 45.433 | zebra        | 28.425 | giraffe        | 25.863 |
| backpack      | 0.629  | umbrella     | 15.501 | handbag        | 0.198  |
| tie           | 0.511  | suitcase     | 6.694  | frisbee        | 14.378 |
| skis          | 0.035  | snowboard    | 0.887  | sports ball    | 4.639  |
| kite          | 7.335  | baseball bat | 0.940  | baseball glove | 6.227  |
| skateboard    | 3.736  | surfboard    | 4.787  | tennis racket  | 19.507 |
| bottle        | 2.500  | wine glass   | 0.839  | cup            | 5.468  |
| fork          | 0.000  | knife        | 0.000  | spoon          | 0.079  |
| bowl          | 4.831  | banana       | 1.812  | apple          | 1.876  |
| sandwich      | 2.232  | orange       | 5.344  | broccoli       | 2.083  |
| carrot        | 0.611  | hot dog      | 1.343  | pizza          | 6.674  |
| donut         | 6.988  | cake         | 1.830  | chair          | 2.628  |
| couch         | 14.074 | potted plant | 2.585  | bed            | 14.852 |
| dining table  | 0.388  | toilet       | 33.962 | tv             | 28.052 |
| laptop        | 22.329 | mouse        | 13.761 | remote         | 1.193  |
| keyboard      | 12.902 | cell phone   | 4.649  | microwave      | 11.046 |
| oven          | 4.069  | toaster      | 0.000  | sink           | 7.832  |
| refrigerator  | 14.313 | book         | 0.231  | clock          | 13.843 |
| vase          | 5.063  | scissors     | 0.639  | teddy bear     | 10.442 |
| hair drier    | 0.000  | toothbrush   | 0.033  |                |        |
[12/11 22:55:55 d2.engine.defaults]: Evaluation results for coco_2017_val_panoptic in csv format:
[12/11 22:55:55 d2.evaluation.testing]: copypaste: Task: panoptic_seg
[12/11 22:55:55 d2.evaluation.testing]: copypaste: PQ,SQ,RQ,PQ_th,SQ_th,RQ_th,PQ_st,SQ_st,RQ_st
[12/11 22:55:55 d2.evaluation.testing]: copypaste: 22.5018,68.9983,29.1119,23.0106,71.1511,29.8090,21.7338,65.7487,28.0597
[12/11 22:55:55 d2.evaluation.testing]: copypaste: Task: bbox
[12/11 22:55:55 d2.evaluation.testing]: copypaste: AP,AP50,AP75,APs,APm,APl
[12/11 22:55:55 d2.evaluation.testing]: copypaste: 9.7005,18.2369,8.9451,1.5751,8.6221,16.8321
[12/11 22:55:55 d2.evaluation.testing]: copypaste: Task: segm
[12/11 22:55:55 d2.evaluation.testing]: copypaste: AP,AP50,AP75,APs,APm,APl
[12/11 22:55:55 d2.evaluation.testing]: copypaste: 10.0593,19.3823,9.4292,0.9174,8.7912,21.6587