Command Line Args: Namespace(config_file='./detectron2/projects/Panoptic-DeepLab/configs/COCO-PanopticSegmentation/panoptic_deeplab_R_52_os16_mg124_poly_200k_bs64_crop_640_640_coco_dsconv.yaml', dist_url='tcp://127.0.0.1:49152', eval_only=False, machine_rank=0, num_gpus=1, num_machines=1, opts=['MODEL.RESNETS.NORM', 'BN', 'MODEL.INS_EMBED_HEAD.NORM', 'BN', 'MODEL.SEM_SEG_HEAD.NORM', 'BN', 'SOLVER.MAX_ITER', '10000', 'SOLVER.IMS_PER_BATCH', '5', 'SOLVER.BASE_LR', '0.0025', 'MODEL.BACKBONE.FREEZE_AT', '5'], resume=False)
Loading config ./detectron2/projects/Panoptic-DeepLab/configs/COCO-PanopticSegmentation/panoptic_deeplab_R_52_os16_mg124_poly_200k_bs64_crop_640_640_coco_dsconv.yaml with yaml.unsafe_load. Your machine may be at risk if the file contains malicious content.
[12/10 21:52:46 detectron2]: Rank of current process: 0. World size: 1
[12/10 21:52:46 detectron2]: Environment info:
----------------------  ----------------------------------------------------------------
sys.platform            linux
Python                  3.7.12 (default, Jan 15 2022, 18:48:18) [GCC 7.5.0]
numpy                   1.21.5
detectron2              0.6 @/content/detectron2/detectron2
Compiler                GCC 7.5
CUDA compiler           CUDA 11.1
detectron2 arch flags   7.0
DETECTRON2_ENV_MODULE   <not set>
PyTorch                 1.10.0+cu111 @/usr/local/lib/python3.7/dist-packages/torch
PyTorch debug build     False
GPU available           Yes
GPU 0                   Tesla V100-SXM2-16GB (arch=7.0)
Driver version          460.32.03
CUDA_HOME               /usr/local/cuda
Pillow                  7.1.2
torchvision             0.11.1+cu111 @/usr/local/lib/python3.7/dist-packages/torchvision
torchvision arch flags  3.5, 5.0, 6.0, 7.0, 7.5, 8.0, 8.6
fvcore                  0.1.5.post20221122
iopath                  0.1.9
cv2                     4.1.2
----------------------  ----------------------------------------------------------------
PyTorch built with:
  - GCC 7.3
  - C++ Version: 201402
  - Intel(R) Math Kernel Library Version 2020.0.0 Product Build 20191122 for Intel(R) 64 architecture applications
  - Intel(R) MKL-DNN v2.2.3 (Git Hash 7336ca9f055cf1bfa13efb658fe15dc9b41f0740)
  - OpenMP 201511 (a.k.a. OpenMP 4.5)
  - LAPACK is enabled (usually provided by MKL)
  - NNPACK is enabled
  - CPU capability usage: AVX512
  - CUDA Runtime 11.1
  - NVCC architecture flags: -gencode;arch=compute_37,code=sm_37;-gencode;arch=compute_50,code=sm_50;-gencode;arch=compute_60,code=sm_60;-gencode;arch=compute_70,code=sm_70;-gencode;arch=compute_75,code=sm_75;-gencode;arch=compute_80,code=sm_80;-gencode;arch=compute_86,code=sm_86
  - CuDNN 8.0.5
  - Magma 2.5.2
  - Build settings: BLAS_INFO=mkl, BUILD_TYPE=Release, CUDA_VERSION=11.1, CUDNN_VERSION=8.0.5, CXX_COMPILER=/opt/rh/devtoolset-7/root/usr/bin/c++, CXX_FLAGS= -Wno-deprecated -fvisibility-inlines-hidden -DUSE_PTHREADPOOL -fopenmp -DNDEBUG -DUSE_KINETO -DUSE_FBGEMM -DUSE_QNNPACK -DUSE_PYTORCH_QNNPACK -DUSE_XNNPACK -DSYMBOLICATE_MOBILE_DEBUG_HANDLE -DEDGE_PROFILER_USE_KINETO -O2 -fPIC -Wno-narrowing -Wall -Wextra -Werror=return-type -Wno-missing-field-initializers -Wno-type-limits -Wno-array-bounds -Wno-unknown-pragmas -Wno-sign-compare -Wno-unused-parameter -Wno-unused-variable -Wno-unused-function -Wno-unused-result -Wno-unused-local-typedefs -Wno-strict-overflow -Wno-strict-aliasing -Wno-error=deprecated-declarations -Wno-stringop-overflow -Wno-psabi -Wno-error=pedantic -Wno-error=redundant-decls -Wno-error=old-style-cast -fdiagnostics-color=always -faligned-new -Wno-unused-but-set-variable -Wno-maybe-uninitialized -fno-math-errno -fno-trapping-math -Werror=format -Wno-stringop-overflow, LAPACK_INFO=mkl, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, TORCH_VERSION=1.10.0, USE_CUDA=ON, USE_CUDNN=ON, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_MKL=ON, USE_MKLDNN=ON, USE_MPI=OFF, USE_NCCL=ON, USE_NNPACK=ON, USE_OPENMP=ON, 

[12/10 21:52:46 detectron2]: Command line arguments: Namespace(config_file='./detectron2/projects/Panoptic-DeepLab/configs/COCO-PanopticSegmentation/panoptic_deeplab_R_52_os16_mg124_poly_200k_bs64_crop_640_640_coco_dsconv.yaml', dist_url='tcp://127.0.0.1:49152', eval_only=False, machine_rank=0, num_gpus=1, num_machines=1, opts=['MODEL.RESNETS.NORM', 'BN', 'MODEL.INS_EMBED_HEAD.NORM', 'BN', 'MODEL.SEM_SEG_HEAD.NORM', 'BN', 'SOLVER.MAX_ITER', '10000', 'SOLVER.IMS_PER_BATCH', '5', 'SOLVER.BASE_LR', '0.0025', 'MODEL.BACKBONE.FREEZE_AT', '5'], resume=False)
[12/10 21:52:46 detectron2]: Contents of args.config_file=./detectron2/projects/Panoptic-DeepLab/configs/COCO-PanopticSegmentation/panoptic_deeplab_R_52_os16_mg124_poly_200k_bs64_crop_640_640_coco_dsconv.yaml:
_BASE_: ../Cityscapes-PanopticSegmentation/Base-PanopticDeepLab-OS16.yaml
MODEL:
  WEIGHTS: "detectron2://DeepLab/R-52.pkl"
  PIXEL_MEAN: [123.675, 116.280, 103.530]
  PIXEL_STD: [58.395, 57.120, 57.375]
  BACKBONE:
    NAME: "build_resnet_deeplab_backbone"
  RESNETS:
    DEPTH: 50
    NORM: "SyncBN"
    RES5_MULTI_GRID: [1, 2, 4]
    STEM_TYPE: "deeplab"
    STEM_OUT_CHANNELS: 128
    STRIDE_IN_1X1: False
  SEM_SEG_HEAD:
    NUM_CLASSES: 133
    LOSS_TOP_K: 1.0
    USE_DEPTHWISE_SEPARABLE_CONV: True
  PANOPTIC_DEEPLAB:
    STUFF_AREA: 4096
    NMS_KERNEL: 41
    SIZE_DIVISIBILITY: 640
    USE_DEPTHWISE_SEPARABLE_CONV: True
DATASETS:
  TRAIN: ("coco_2017_train_panoptic",)
  TEST: ("coco_2017_val_panoptic",)
SOLVER:
  BASE_LR: 0.0005
  MAX_ITER: 200000
  IMS_PER_BATCH: 64
INPUT:
  FORMAT: "RGB"
  GAUSSIAN_SIGMA: 8
  MIN_SIZE_TRAIN: !!python/object/apply:eval ["[int(x * 0.1 * 640) for x in range(5, 16)]"]
  MIN_SIZE_TRAIN_SAMPLING: "choice"
  MIN_SIZE_TEST: 640
  MAX_SIZE_TRAIN: 960
  MAX_SIZE_TEST: 640
  CROP:
    ENABLED: True
    TYPE: "absolute"
    SIZE: (640, 640)

[12/10 21:52:46 detectron2]: Running with full config:
CUDNN_BENCHMARK: false
DATALOADER:
  ASPECT_RATIO_GROUPING: true
  FILTER_EMPTY_ANNOTATIONS: true
  NUM_WORKERS: 10
  REPEAT_THRESHOLD: 0.0
  SAMPLER_TRAIN: TrainingSampler
DATASETS:
  PRECOMPUTED_PROPOSAL_TOPK_TEST: 1000
  PRECOMPUTED_PROPOSAL_TOPK_TRAIN: 2000
  PROPOSAL_FILES_TEST: []
  PROPOSAL_FILES_TRAIN: []
  TEST:
  - coco_2017_val_panoptic
  TRAIN:
  - coco_2017_train_panoptic
GLOBAL:
  HACK: 1.0
INPUT:
  CROP:
    ENABLED: true
    SINGLE_CATEGORY_MAX_AREA: 1.0
    SIZE:
    - 640
    - 640
    TYPE: absolute
  FORMAT: RGB
  GAUSSIAN_SIGMA: 8
  IGNORE_CROWD_IN_SEMANTIC: false
  IGNORE_STUFF_IN_OFFSET: true
  MASK_FORMAT: polygon
  MAX_SIZE_TEST: 640
  MAX_SIZE_TRAIN: 960
  MIN_SIZE_TEST: 640
  MIN_SIZE_TRAIN:
  - 320
  - 384
  - 448
  - 512
  - 576
  - 640
  - 704
  - 768
  - 832
  - 896
  - 960
  MIN_SIZE_TRAIN_SAMPLING: choice
  RANDOM_FLIP: horizontal
  SMALL_INSTANCE_AREA: 4096
  SMALL_INSTANCE_WEIGHT: 3
MODEL:
  ANCHOR_GENERATOR:
    ANGLES:
    - - -90
      - 0
      - 90
    ASPECT_RATIOS:
    - - 0.5
      - 1.0
      - 2.0
    NAME: DefaultAnchorGenerator
    OFFSET: 0.0
    SIZES:
    - - 32
      - 64
      - 128
      - 256
      - 512
  BACKBONE:
    FREEZE_AT: 5
    NAME: build_resnet_deeplab_backbone
  DEVICE: cuda
  FPN:
    FUSE_TYPE: sum
    IN_FEATURES: []
    NORM: ''
    OUT_CHANNELS: 256
  INS_EMBED_HEAD:
    ASPP_CHANNELS: 256
    ASPP_DILATIONS:
    - 6
    - 12
    - 18
    ASPP_DROPOUT: 0.1
    CENTER_LOSS_WEIGHT: 200.0
    COMMON_STRIDE: 4
    CONVS_DIM: 128
    HEAD_CHANNELS: 32
    IN_FEATURES:
    - res2
    - res3
    - res5
    NAME: PanopticDeepLabInsEmbedHead
    NORM: BN
    OFFSET_LOSS_WEIGHT: 0.01
    PROJECT_CHANNELS:
    - 32
    - 64
    PROJECT_FEATURES:
    - res2
    - res3
  KEYPOINT_ON: false
  LOAD_PROPOSALS: false
  MASK_ON: false
  META_ARCHITECTURE: PanopticDeepLab
  PANOPTIC_DEEPLAB:
    BENCHMARK_NETWORK_SPEED: false
    CENTER_THRESHOLD: 0.1
    NMS_KERNEL: 41
    PREDICT_INSTANCES: true
    SIZE_DIVISIBILITY: 640
    STUFF_AREA: 4096
    TOP_K_INSTANCE: 200
    USE_DEPTHWISE_SEPARABLE_CONV: true
  PANOPTIC_FPN:
    COMBINE:
      ENABLED: true
      INSTANCES_CONFIDENCE_THRESH: 0.5
      OVERLAP_THRESH: 0.5
      STUFF_AREA_LIMIT: 4096
    INSTANCE_LOSS_WEIGHT: 1.0
  PIXEL_MEAN:
  - 123.675
  - 116.28
  - 103.53
  PIXEL_STD:
  - 58.395
  - 57.12
  - 57.375
  PROPOSAL_GENERATOR:
    MIN_SIZE: 0
    NAME: RPN
  RESNETS:
    DEFORM_MODULATED: false
    DEFORM_NUM_GROUPS: 1
    DEFORM_ON_PER_STAGE:
    - false
    - false
    - false
    - false
    DEPTH: 50
    NORM: BN
    NUM_GROUPS: 1
    OUT_FEATURES:
    - res2
    - res3
    - res5
    RES2_OUT_CHANNELS: 256
    RES4_DILATION: 1
    RES5_DILATION: 2
    RES5_MULTI_GRID:
    - 1
    - 2
    - 4
    STEM_OUT_CHANNELS: 128
    STEM_TYPE: deeplab
    STRIDE_IN_1X1: false
    WIDTH_PER_GROUP: 64
  RETINANET:
    BBOX_REG_LOSS_TYPE: smooth_l1
    BBOX_REG_WEIGHTS: &id001
    - 1.0
    - 1.0
    - 1.0
    - 1.0
    FOCAL_LOSS_ALPHA: 0.25
    FOCAL_LOSS_GAMMA: 2.0
    IN_FEATURES:
    - p3
    - p4
    - p5
    - p6
    - p7
    IOU_LABELS:
    - 0
    - -1
    - 1
    IOU_THRESHOLDS:
    - 0.4
    - 0.5
    NMS_THRESH_TEST: 0.5
    NORM: ''
    NUM_CLASSES: 80
    NUM_CONVS: 4
    PRIOR_PROB: 0.01
    SCORE_THRESH_TEST: 0.05
    SMOOTH_L1_LOSS_BETA: 0.1
    TOPK_CANDIDATES_TEST: 1000
  ROI_BOX_CASCADE_HEAD:
    BBOX_REG_WEIGHTS:
    - - 10.0
      - 10.0
      - 5.0
      - 5.0
    - - 20.0
      - 20.0
      - 10.0
      - 10.0
    - - 30.0
      - 30.0
      - 15.0
      - 15.0
    IOUS:
    - 0.5
    - 0.6
    - 0.7
  ROI_BOX_HEAD:
    BBOX_REG_LOSS_TYPE: smooth_l1
    BBOX_REG_LOSS_WEIGHT: 1.0
    BBOX_REG_WEIGHTS:
    - 10.0
    - 10.0
    - 5.0
    - 5.0
    CLS_AGNOSTIC_BBOX_REG: false
    CONV_DIM: 256
    FC_DIM: 1024
    FED_LOSS_FREQ_WEIGHT_POWER: 0.5
    FED_LOSS_NUM_CLASSES: 50
    NAME: ''
    NORM: ''
    NUM_CONV: 0
    NUM_FC: 0
    POOLER_RESOLUTION: 14
    POOLER_SAMPLING_RATIO: 0
    POOLER_TYPE: ROIAlignV2
    SMOOTH_L1_BETA: 0.0
    TRAIN_ON_PRED_BOXES: false
    USE_FED_LOSS: false
    USE_SIGMOID_CE: false
  ROI_HEADS:
    BATCH_SIZE_PER_IMAGE: 512
    IN_FEATURES:
    - res4
    IOU_LABELS:
    - 0
    - 1
    IOU_THRESHOLDS:
    - 0.5
    NAME: Res5ROIHeads
    NMS_THRESH_TEST: 0.5
    NUM_CLASSES: 80
    POSITIVE_FRACTION: 0.25
    PROPOSAL_APPEND_GT: true
    SCORE_THRESH_TEST: 0.05
  ROI_KEYPOINT_HEAD:
    CONV_DIMS:
    - 512
    - 512
    - 512
    - 512
    - 512
    - 512
    - 512
    - 512
    LOSS_WEIGHT: 1.0
    MIN_KEYPOINTS_PER_IMAGE: 1
    NAME: KRCNNConvDeconvUpsampleHead
    NORMALIZE_LOSS_BY_VISIBLE_KEYPOINTS: true
    NUM_KEYPOINTS: 17
    POOLER_RESOLUTION: 14
    POOLER_SAMPLING_RATIO: 0
    POOLER_TYPE: ROIAlignV2
  ROI_MASK_HEAD:
    CLS_AGNOSTIC_MASK: false
    CONV_DIM: 256
    NAME: MaskRCNNConvUpsampleHead
    NORM: ''
    NUM_CONV: 0
    POOLER_RESOLUTION: 14
    POOLER_SAMPLING_RATIO: 0
    POOLER_TYPE: ROIAlignV2
  RPN:
    BATCH_SIZE_PER_IMAGE: 256
    BBOX_REG_LOSS_TYPE: smooth_l1
    BBOX_REG_LOSS_WEIGHT: 1.0
    BBOX_REG_WEIGHTS: *id001
    BOUNDARY_THRESH: -1
    CONV_DIMS:
    - -1
    HEAD_NAME: StandardRPNHead
    IN_FEATURES:
    - res4
    IOU_LABELS:
    - 0
    - -1
    - 1
    IOU_THRESHOLDS:
    - 0.3
    - 0.7
    LOSS_WEIGHT: 1.0
    NMS_THRESH: 0.7
    POSITIVE_FRACTION: 0.5
    POST_NMS_TOPK_TEST: 1000
    POST_NMS_TOPK_TRAIN: 2000
    PRE_NMS_TOPK_TEST: 6000
    PRE_NMS_TOPK_TRAIN: 12000
    SMOOTH_L1_BETA: 0.0
  SEM_SEG_HEAD:
    ASPP_CHANNELS: 256
    ASPP_DILATIONS:
    - 6
    - 12
    - 18
    ASPP_DROPOUT: 0.1
    COMMON_STRIDE: 4
    CONVS_DIM: 256
    HEAD_CHANNELS: 256
    IGNORE_VALUE: 255
    IN_FEATURES:
    - res2
    - res3
    - res5
    LOSS_TOP_K: 1.0
    LOSS_TYPE: hard_pixel_mining
    LOSS_WEIGHT: 1.0
    NAME: PanopticDeepLabSemSegHead
    NORM: BN
    NUM_CLASSES: 133
    PROJECT_CHANNELS:
    - 32
    - 64
    PROJECT_FEATURES:
    - res2
    - res3
    USE_DEPTHWISE_SEPARABLE_CONV: true
  WEIGHTS: detectron2://DeepLab/R-52.pkl
OUTPUT_DIR: ./output
SEED: -1
SOLVER:
  AMP:
    ENABLED: false
  BASE_LR: 0.0025
  BASE_LR_END: 0.0
  BIAS_LR_FACTOR: 1.0
  CHECKPOINT_PERIOD: 5000
  CLIP_GRADIENTS:
    CLIP_TYPE: value
    CLIP_VALUE: 1.0
    ENABLED: false
    NORM_TYPE: 2.0
  GAMMA: 0.1
  IMS_PER_BATCH: 5
  LR_SCHEDULER_NAME: WarmupPolyLR
  MAX_ITER: 10000
  MOMENTUM: 0.9
  NESTEROV: false
  NUM_DECAYS: 3
  OPTIMIZER: ADAM
  POLY_LR_CONSTANT_ENDING: 0.0
  POLY_LR_POWER: 0.9
  REFERENCE_WORLD_SIZE: 0
  RESCALE_INTERVAL: false
  STEPS:
  - 30000
  WARMUP_FACTOR: 0.001
  WARMUP_ITERS: 1000
  WARMUP_METHOD: linear
  WEIGHT_DECAY: 0.0
  WEIGHT_DECAY_BIAS: 0.0
  WEIGHT_DECAY_NORM: 0.0
TEST:
  AUG:
    ENABLED: false
    FLIP: true
    MAX_SIZE: 4000
    MIN_SIZES:
    - 400
    - 500
    - 600
    - 700
    - 800
    - 900
    - 1000
    - 1100
    - 1200
  DETECTIONS_PER_IMAGE: 100
  EVAL_PERIOD: 0
  EXPECTED_RESULTS: []
  KEYPOINT_OKS_SIGMAS: []
  PRECISE_BN:
    ENABLED: false
    NUM_ITER: 200
VERSION: 2
VIS_PERIOD: 0

[12/10 21:52:46 detectron2]: Full config saved to ./output/config.yaml
[12/10 21:52:47 d2.utils.env]: Using a generated random seed 47066630
=== ResNet Feeze ===
Resnet stage idx: 2
Resnet stage idx: 3
Resnet stage idx: 4
Resnet stage idx: 5
=== ResNet Feeze ===
Resnet stage idx: 2
Resnet stage idx: 3
Resnet stage idx: 4
Resnet stage idx: 5
[12/10 21:52:51 d2.engine.defaults]: Model:
PanopticDeepLab(
  (backbone): ResNet(
    (stem): DeepLabStem(
      (conv1): Conv2d(
        3, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False
        (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
      )
      (conv2): Conv2d(
        64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
        (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
      )
      (conv3): Conv2d(
        64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
        (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
      )
    )
    (res2): Sequential(
      (0): BottleneckBlock(
        (shortcut): Conv2d(
          128, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv1): Conv2d(
          128, 64, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
        )
        (conv2): Conv2d(
          64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
        )
        (conv3): Conv2d(
          64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
      )
      (1): BottleneckBlock(
        (conv1): Conv2d(
          256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
        )
        (conv2): Conv2d(
          64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
        )
        (conv3): Conv2d(
          64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
      )
      (2): BottleneckBlock(
        (conv1): Conv2d(
          256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
        )
        (conv2): Conv2d(
          64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
        )
        (conv3): Conv2d(
          64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
      )
    )
    (res3): Sequential(
      (0): BottleneckBlock(
        (shortcut): Conv2d(
          256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False
          (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
        )
        (conv1): Conv2d(
          256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
        )
        (conv2): Conv2d(
          128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
        )
        (conv3): Conv2d(
          128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
        )
      )
      (1): BottleneckBlock(
        (conv1): Conv2d(
          512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
        )
        (conv2): Conv2d(
          128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
        )
        (conv3): Conv2d(
          128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
        )
      )
      (2): BottleneckBlock(
        (conv1): Conv2d(
          512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
        )
        (conv2): Conv2d(
          128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
        )
        (conv3): Conv2d(
          128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
        )
      )
      (3): BottleneckBlock(
        (conv1): Conv2d(
          512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
        )
        (conv2): Conv2d(
          128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
        )
        (conv3): Conv2d(
          128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
        )
      )
    )
    (res4): Sequential(
      (0): BottleneckBlock(
        (shortcut): Conv2d(
          512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False
          (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
        )
        (conv1): Conv2d(
          512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv2): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv3): Conv2d(
          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
        )
      )
      (1): BottleneckBlock(
        (conv1): Conv2d(
          1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv2): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv3): Conv2d(
          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
        )
      )
      (2): BottleneckBlock(
        (conv1): Conv2d(
          1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv2): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv3): Conv2d(
          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
        )
      )
      (3): BottleneckBlock(
        (conv1): Conv2d(
          1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv2): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv3): Conv2d(
          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
        )
      )
      (4): BottleneckBlock(
        (conv1): Conv2d(
          1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv2): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv3): Conv2d(
          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
        )
      )
      (5): BottleneckBlock(
        (conv1): Conv2d(
          1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv2): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv3): Conv2d(
          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
        )
      )
    )
    (res5): Sequential(
      (0): BottleneckBlock(
        (shortcut): Conv2d(
          1024, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)
        )
        (conv1): Conv2d(
          1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
        )
        (conv2): Conv2d(
          512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2), dilation=(2, 2), bias=False
          (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
        )
        (conv3): Conv2d(
          512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)
        )
      )
      (1): BottleneckBlock(
        (conv1): Conv2d(
          2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
        )
        (conv2): Conv2d(
          512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(4, 4), dilation=(4, 4), bias=False
          (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
        )
        (conv3): Conv2d(
          512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)
        )
      )
      (2): BottleneckBlock(
        (conv1): Conv2d(
          2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
        )
        (conv2): Conv2d(
          512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(8, 8), dilation=(8, 8), bias=False
          (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
        )
        (conv3): Conv2d(
          512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)
        )
      )
    )
  )
  (sem_seg_head): PanopticDeepLabSemSegHead(
    (decoder): ModuleDict(
      (res2): ModuleDict(
        (project_conv): Conv2d(
          256, 32, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (fuse_conv): DepthwiseSeparableConv2d(
          (depthwise): Conv2d(
            288, 288, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=288, bias=False
            (norm): BatchNorm2d(288, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          )
          (pointwise): Conv2d(
            288, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
      )
      (res3): ModuleDict(
        (project_conv): Conv2d(
          512, 64, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (fuse_conv): DepthwiseSeparableConv2d(
          (depthwise): Conv2d(
            320, 320, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=320, bias=False
            (norm): BatchNorm2d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          )
          (pointwise): Conv2d(
            320, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
      )
      (res5): ModuleDict(
        (project_conv): ASPP(
          (convs): ModuleList(
            (0): Conv2d(
              2048, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
              (norm): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            )
            (1): DepthwiseSeparableConv2d(
              (depthwise): Conv2d(
                2048, 2048, kernel_size=(3, 3), stride=(1, 1), padding=(6, 6), dilation=(6, 6), groups=2048, bias=False
                (norm): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
              (pointwise): Conv2d(
                2048, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
            )
            (2): DepthwiseSeparableConv2d(
              (depthwise): Conv2d(
                2048, 2048, kernel_size=(3, 3), stride=(1, 1), padding=(12, 12), dilation=(12, 12), groups=2048, bias=False
                (norm): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
              (pointwise): Conv2d(
                2048, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
            )
            (3): DepthwiseSeparableConv2d(
              (depthwise): Conv2d(
                2048, 2048, kernel_size=(3, 3), stride=(1, 1), padding=(18, 18), dilation=(18, 18), groups=2048, bias=False
                (norm): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
              (pointwise): Conv2d(
                2048, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
            )
            (4): Sequential(
              (0): AvgPool2d(kernel_size=(40, 40), stride=1, padding=0)
              (1): Conv2d(2048, 256, kernel_size=(1, 1), stride=(1, 1))
            )
          )
          (project): Conv2d(
            1280, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (fuse_conv): None
      )
    )
    (head): DepthwiseSeparableConv2d(
      (depthwise): Conv2d(
        256, 256, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=256, bias=False
        (norm): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (pointwise): Conv2d(
        256, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
        (norm): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (predictor): Conv2d(256, 133, kernel_size=(1, 1), stride=(1, 1))
    (loss): DeepLabCE(
      (criterion): CrossEntropyLoss()
    )
  )
  (ins_embed_head): PanopticDeepLabInsEmbedHead(
    (decoder): ModuleDict(
      (res2): ModuleDict(
        (project_conv): Conv2d(
          256, 32, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (fuse_conv): DepthwiseSeparableConv2d(
          (depthwise): Conv2d(
            160, 160, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=160, bias=False
            (norm): BatchNorm2d(160, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          )
          (pointwise): Conv2d(
            160, 128, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
      )
      (res3): ModuleDict(
        (project_conv): Conv2d(
          512, 64, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (fuse_conv): DepthwiseSeparableConv2d(
          (depthwise): Conv2d(
            320, 320, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=320, bias=False
            (norm): BatchNorm2d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          )
          (pointwise): Conv2d(
            320, 128, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
      )
      (res5): ModuleDict(
        (project_conv): ASPP(
          (convs): ModuleList(
            (0): Conv2d(
              2048, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
              (norm): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            )
            (1): DepthwiseSeparableConv2d(
              (depthwise): Conv2d(
                2048, 2048, kernel_size=(3, 3), stride=(1, 1), padding=(6, 6), dilation=(6, 6), groups=2048, bias=False
                (norm): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
              (pointwise): Conv2d(
                2048, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
            )
            (2): DepthwiseSeparableConv2d(
              (depthwise): Conv2d(
                2048, 2048, kernel_size=(3, 3), stride=(1, 1), padding=(12, 12), dilation=(12, 12), groups=2048, bias=False
                (norm): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
              (pointwise): Conv2d(
                2048, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
            )
            (3): DepthwiseSeparableConv2d(
              (depthwise): Conv2d(
                2048, 2048, kernel_size=(3, 3), stride=(1, 1), padding=(18, 18), dilation=(18, 18), groups=2048, bias=False
                (norm): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
              (pointwise): Conv2d(
                2048, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
            )
            (4): Sequential(
              (0): AvgPool2d(kernel_size=(40, 40), stride=1, padding=0)
              (1): Conv2d(2048, 256, kernel_size=(1, 1), stride=(1, 1))
            )
          )
          (project): Conv2d(
            1280, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (fuse_conv): None
      )
    )
    (center_head): Sequential(
      (0): Conv2d(
        128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
        (norm): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (1): Conv2d(
        128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
        (norm): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (center_predictor): Conv2d(32, 1, kernel_size=(1, 1), stride=(1, 1))
    (offset_head): DepthwiseSeparableConv2d(
      (depthwise): Conv2d(
        128, 128, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=128, bias=False
        (norm): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (pointwise): Conv2d(
        128, 32, kernel_size=(1, 1), stride=(1, 1), bias=False
        (norm): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (offset_predictor): Conv2d(32, 2, kernel_size=(1, 1), stride=(1, 1))
    (center_loss): MSELoss()
    (offset_loss): L1Loss()
  )
)
[12/10 21:52:51 d2.projects.panoptic_deeplab.dataset_mapper]: Augmentations used in training: [ResizeShortestEdge(short_edge_length=(320, 384, 448, 512, 576, 640, 704, 768, 832, 896, 960), max_size=960, sample_style='choice'), RandomCrop(crop_type='absolute', crop_size=[640, 640]), RandomFlip()]
[12/10 21:52:58 d2.data.build]: Using training sampler TrainingSampler
[12/10 21:52:58 d2.data.common]: Serializing the dataset using: <class 'detectron2.data.common.NumpySerializedList'>
[12/10 21:52:58 d2.data.common]: Serializing 118287 elements to byte tensors and concatenating them all ...
[12/10 21:52:59 d2.data.common]: Serialized dataset takes 78.29 MiB
/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:481: UserWarning: This DataLoader will create 10 worker processes in total. Our suggested max number of worker in current system is 8, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.
  cpuset_checked))
[12/10 21:53:01 fvcore.common.checkpoint]: [Checkpointer] Loading from detectron2://DeepLab/R-52.pkl ...
R-52.pkl: 103MB [00:06, 15.4MB/s]                
[12/10 21:53:08 fvcore.common.checkpoint]: Reading a file from 'torchvision'
[12/10 21:53:08 d2.checkpoint.c2_model_loading]: Following weights matched with submodule backbone:
| Names in Model    | Names in Checkpoint                                                               | Shapes                                          |
|:------------------|:----------------------------------------------------------------------------------|:------------------------------------------------|
| res2.0.conv1.*    | res2.0.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (64,) (64,) (64,) (64,) (64,128,1,1)            |
| res2.0.conv2.*    | res2.0.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (64,) (64,) (64,) (64,) (64,64,3,3)             |
| res2.0.conv3.*    | res2.0.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) (256,) (256,) (256,) (256,64,1,1)        |
| res2.0.shortcut.* | res2.0.shortcut.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight} | (256,) (256,) (256,) (256,) (256,128,1,1)       |
| res2.1.conv1.*    | res2.1.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (64,) (64,) (64,) (64,) (64,256,1,1)            |
| res2.1.conv2.*    | res2.1.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (64,) (64,) (64,) (64,) (64,64,3,3)             |
| res2.1.conv3.*    | res2.1.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) (256,) (256,) (256,) (256,64,1,1)        |
| res2.2.conv1.*    | res2.2.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (64,) (64,) (64,) (64,) (64,256,1,1)            |
| res2.2.conv2.*    | res2.2.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (64,) (64,) (64,) (64,) (64,64,3,3)             |
| res2.2.conv3.*    | res2.2.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) (256,) (256,) (256,) (256,64,1,1)        |
| res3.0.conv1.*    | res3.0.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (128,) (128,) (128,) (128,) (128,256,1,1)       |
| res3.0.conv2.*    | res3.0.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (128,) (128,) (128,) (128,) (128,128,3,3)       |
| res3.0.conv3.*    | res3.0.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (512,) (512,) (512,) (512,) (512,128,1,1)       |
| res3.0.shortcut.* | res3.0.shortcut.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight} | (512,) (512,) (512,) (512,) (512,256,1,1)       |
| res3.1.conv1.*    | res3.1.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (128,) (128,) (128,) (128,) (128,512,1,1)       |
| res3.1.conv2.*    | res3.1.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (128,) (128,) (128,) (128,) (128,128,3,3)       |
| res3.1.conv3.*    | res3.1.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (512,) (512,) (512,) (512,) (512,128,1,1)       |
| res3.2.conv1.*    | res3.2.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (128,) (128,) (128,) (128,) (128,512,1,1)       |
| res3.2.conv2.*    | res3.2.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (128,) (128,) (128,) (128,) (128,128,3,3)       |
| res3.2.conv3.*    | res3.2.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (512,) (512,) (512,) (512,) (512,128,1,1)       |
| res3.3.conv1.*    | res3.3.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (128,) (128,) (128,) (128,) (128,512,1,1)       |
| res3.3.conv2.*    | res3.3.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (128,) (128,) (128,) (128,) (128,128,3,3)       |
| res3.3.conv3.*    | res3.3.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (512,) (512,) (512,) (512,) (512,128,1,1)       |
| res4.0.conv1.*    | res4.0.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) (256,) (256,) (256,) (256,512,1,1)       |
| res4.0.conv2.*    | res4.0.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) (256,) (256,) (256,) (256,256,3,3)       |
| res4.0.conv3.*    | res4.0.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (1024,) (1024,) (1024,) (1024,) (1024,256,1,1)  |
| res4.0.shortcut.* | res4.0.shortcut.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight} | (1024,) (1024,) (1024,) (1024,) (1024,512,1,1)  |
| res4.1.conv1.*    | res4.1.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) (256,) (256,) (256,) (256,1024,1,1)      |
| res4.1.conv2.*    | res4.1.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) (256,) (256,) (256,) (256,256,3,3)       |
| res4.1.conv3.*    | res4.1.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (1024,) (1024,) (1024,) (1024,) (1024,256,1,1)  |
| res4.2.conv1.*    | res4.2.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) (256,) (256,) (256,) (256,1024,1,1)      |
| res4.2.conv2.*    | res4.2.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) (256,) (256,) (256,) (256,256,3,3)       |
| res4.2.conv3.*    | res4.2.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (1024,) (1024,) (1024,) (1024,) (1024,256,1,1)  |
| res4.3.conv1.*    | res4.3.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) (256,) (256,) (256,) (256,1024,1,1)      |
| res4.3.conv2.*    | res4.3.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) (256,) (256,) (256,) (256,256,3,3)       |
| res4.3.conv3.*    | res4.3.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (1024,) (1024,) (1024,) (1024,) (1024,256,1,1)  |
| res4.4.conv1.*    | res4.4.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) (256,) (256,) (256,) (256,1024,1,1)      |
| res4.4.conv2.*    | res4.4.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) (256,) (256,) (256,) (256,256,3,3)       |
| res4.4.conv3.*    | res4.4.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (1024,) (1024,) (1024,) (1024,) (1024,256,1,1)  |
| res4.5.conv1.*    | res4.5.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) (256,) (256,) (256,) (256,1024,1,1)      |
| res4.5.conv2.*    | res4.5.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) (256,) (256,) (256,) (256,256,3,3)       |
| res4.5.conv3.*    | res4.5.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (1024,) (1024,) (1024,) (1024,) (1024,256,1,1)  |
| res5.0.conv1.*    | res5.0.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (512,) (512,) (512,) (512,) (512,1024,1,1)      |
| res5.0.conv2.*    | res5.0.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (512,) (512,) (512,) (512,) (512,512,3,3)       |
| res5.0.conv3.*    | res5.0.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (2048,) (2048,) (2048,) (2048,) (2048,512,1,1)  |
| res5.0.shortcut.* | res5.0.shortcut.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight} | (2048,) (2048,) (2048,) (2048,) (2048,1024,1,1) |
| res5.1.conv1.*    | res5.1.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (512,) (512,) (512,) (512,) (512,2048,1,1)      |
| res5.1.conv2.*    | res5.1.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (512,) (512,) (512,) (512,) (512,512,3,3)       |
| res5.1.conv3.*    | res5.1.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (2048,) (2048,) (2048,) (2048,) (2048,512,1,1)  |
| res5.2.conv1.*    | res5.2.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (512,) (512,) (512,) (512,) (512,2048,1,1)      |
| res5.2.conv2.*    | res5.2.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (512,) (512,) (512,) (512,) (512,512,3,3)       |
| res5.2.conv3.*    | res5.2.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (2048,) (2048,) (2048,) (2048,) (2048,512,1,1)  |
| stem.conv1.*      | stem.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}      | (64,) (64,) (64,) (64,) (64,3,3,3)              |
| stem.conv2.*      | stem.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}      | (64,) (64,) (64,) (64,) (64,64,3,3)             |
| stem.conv3.*      | stem.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}      | (128,) (128,) (128,) (128,) (128,64,3,3)        |
WARNING [12/10 21:53:10 fvcore.common.checkpoint]: Some model parameters or buffers are not found in the checkpoint:
ins_embed_head.center_head.0.norm.{bias, running_mean, running_var, weight}
ins_embed_head.center_head.0.weight
ins_embed_head.center_head.1.norm.{bias, running_mean, running_var, weight}
ins_embed_head.center_head.1.weight
ins_embed_head.center_predictor.{bias, weight}
ins_embed_head.decoder.res2.fuse_conv.depthwise.norm.{bias, running_mean, running_var, weight}
ins_embed_head.decoder.res2.fuse_conv.depthwise.weight
ins_embed_head.decoder.res2.fuse_conv.pointwise.norm.{bias, running_mean, running_var, weight}
ins_embed_head.decoder.res2.fuse_conv.pointwise.weight
ins_embed_head.decoder.res2.project_conv.norm.{bias, running_mean, running_var, weight}
ins_embed_head.decoder.res2.project_conv.weight
ins_embed_head.decoder.res3.fuse_conv.depthwise.norm.{bias, running_mean, running_var, weight}
ins_embed_head.decoder.res3.fuse_conv.depthwise.weight
ins_embed_head.decoder.res3.fuse_conv.pointwise.norm.{bias, running_mean, running_var, weight}
ins_embed_head.decoder.res3.fuse_conv.pointwise.weight
ins_embed_head.decoder.res3.project_conv.norm.{bias, running_mean, running_var, weight}
ins_embed_head.decoder.res3.project_conv.weight
ins_embed_head.decoder.res5.project_conv.convs.0.norm.{bias, running_mean, running_var, weight}
ins_embed_head.decoder.res5.project_conv.convs.0.weight
ins_embed_head.decoder.res5.project_conv.convs.1.depthwise.norm.{bias, running_mean, running_var, weight}
ins_embed_head.decoder.res5.project_conv.convs.1.depthwise.weight
ins_embed_head.decoder.res5.project_conv.convs.1.pointwise.norm.{bias, running_mean, running_var, weight}
ins_embed_head.decoder.res5.project_conv.convs.1.pointwise.weight
ins_embed_head.decoder.res5.project_conv.convs.2.depthwise.norm.{bias, running_mean, running_var, weight}
ins_embed_head.decoder.res5.project_conv.convs.2.depthwise.weight
ins_embed_head.decoder.res5.project_conv.convs.2.pointwise.norm.{bias, running_mean, running_var, weight}
ins_embed_head.decoder.res5.project_conv.convs.2.pointwise.weight
ins_embed_head.decoder.res5.project_conv.convs.3.depthwise.norm.{bias, running_mean, running_var, weight}
ins_embed_head.decoder.res5.project_conv.convs.3.depthwise.weight
ins_embed_head.decoder.res5.project_conv.convs.3.pointwise.norm.{bias, running_mean, running_var, weight}
ins_embed_head.decoder.res5.project_conv.convs.3.pointwise.weight
ins_embed_head.decoder.res5.project_conv.convs.4.1.{bias, weight}
ins_embed_head.decoder.res5.project_conv.project.norm.{bias, running_mean, running_var, weight}
ins_embed_head.decoder.res5.project_conv.project.weight
ins_embed_head.offset_head.depthwise.norm.{bias, running_mean, running_var, weight}
ins_embed_head.offset_head.depthwise.weight
ins_embed_head.offset_head.pointwise.norm.{bias, running_mean, running_var, weight}
ins_embed_head.offset_head.pointwise.weight
ins_embed_head.offset_predictor.{bias, weight}
sem_seg_head.decoder.res2.fuse_conv.depthwise.norm.{bias, running_mean, running_var, weight}
sem_seg_head.decoder.res2.fuse_conv.depthwise.weight
sem_seg_head.decoder.res2.fuse_conv.pointwise.norm.{bias, running_mean, running_var, weight}
sem_seg_head.decoder.res2.fuse_conv.pointwise.weight
sem_seg_head.decoder.res2.project_conv.norm.{bias, running_mean, running_var, weight}
sem_seg_head.decoder.res2.project_conv.weight
sem_seg_head.decoder.res3.fuse_conv.depthwise.norm.{bias, running_mean, running_var, weight}
sem_seg_head.decoder.res3.fuse_conv.depthwise.weight
sem_seg_head.decoder.res3.fuse_conv.pointwise.norm.{bias, running_mean, running_var, weight}
sem_seg_head.decoder.res3.fuse_conv.pointwise.weight
sem_seg_head.decoder.res3.project_conv.norm.{bias, running_mean, running_var, weight}
sem_seg_head.decoder.res3.project_conv.weight
sem_seg_head.decoder.res5.project_conv.convs.0.norm.{bias, running_mean, running_var, weight}
sem_seg_head.decoder.res5.project_conv.convs.0.weight
sem_seg_head.decoder.res5.project_conv.convs.1.depthwise.norm.{bias, running_mean, running_var, weight}
sem_seg_head.decoder.res5.project_conv.convs.1.depthwise.weight
sem_seg_head.decoder.res5.project_conv.convs.1.pointwise.norm.{bias, running_mean, running_var, weight}
sem_seg_head.decoder.res5.project_conv.convs.1.pointwise.weight
sem_seg_head.decoder.res5.project_conv.convs.2.depthwise.norm.{bias, running_mean, running_var, weight}
sem_seg_head.decoder.res5.project_conv.convs.2.depthwise.weight
sem_seg_head.decoder.res5.project_conv.convs.2.pointwise.norm.{bias, running_mean, running_var, weight}
sem_seg_head.decoder.res5.project_conv.convs.2.pointwise.weight
sem_seg_head.decoder.res5.project_conv.convs.3.depthwise.norm.{bias, running_mean, running_var, weight}
sem_seg_head.decoder.res5.project_conv.convs.3.depthwise.weight
sem_seg_head.decoder.res5.project_conv.convs.3.pointwise.norm.{bias, running_mean, running_var, weight}
sem_seg_head.decoder.res5.project_conv.convs.3.pointwise.weight
sem_seg_head.decoder.res5.project_conv.convs.4.1.{bias, weight}
sem_seg_head.decoder.res5.project_conv.project.norm.{bias, running_mean, running_var, weight}
sem_seg_head.decoder.res5.project_conv.project.weight
sem_seg_head.head.depthwise.norm.{bias, running_mean, running_var, weight}
sem_seg_head.head.depthwise.weight
sem_seg_head.head.pointwise.norm.{bias, running_mean, running_var, weight}
sem_seg_head.head.pointwise.weight
sem_seg_head.predictor.{bias, weight}
WARNING [12/10 21:53:10 fvcore.common.checkpoint]: The checkpoint state_dict contains keys that are not used by the model:
  res2.0.conv1.norm.num_batches_tracked
  res2.0.conv2.norm.num_batches_tracked
  res2.0.conv3.norm.num_batches_tracked
  res2.0.shortcut.norm.num_batches_tracked
  res2.1.conv1.norm.num_batches_tracked
  res2.1.conv2.norm.num_batches_tracked
  res2.1.conv3.norm.num_batches_tracked
  res2.2.conv1.norm.num_batches_tracked
  res2.2.conv2.norm.num_batches_tracked
  res2.2.conv3.norm.num_batches_tracked
  res3.0.conv1.norm.num_batches_tracked
  res3.0.conv2.norm.num_batches_tracked
  res3.0.conv3.norm.num_batches_tracked
  res3.0.shortcut.norm.num_batches_tracked
  res3.1.conv1.norm.num_batches_tracked
  res3.1.conv2.norm.num_batches_tracked
  res3.1.conv3.norm.num_batches_tracked
  res3.2.conv1.norm.num_batches_tracked
  res3.2.conv2.norm.num_batches_tracked
  res3.2.conv3.norm.num_batches_tracked
  res3.3.conv1.norm.num_batches_tracked
  res3.3.conv2.norm.num_batches_tracked
  res3.3.conv3.norm.num_batches_tracked
  res4.0.conv1.norm.num_batches_tracked
  res4.0.conv2.norm.num_batches_tracked
  res4.0.conv3.norm.num_batches_tracked
  res4.0.shortcut.norm.num_batches_tracked
  res4.1.conv1.norm.num_batches_tracked
  res4.1.conv2.norm.num_batches_tracked
  res4.1.conv3.norm.num_batches_tracked
  res4.2.conv1.norm.num_batches_tracked
  res4.2.conv2.norm.num_batches_tracked
  res4.2.conv3.norm.num_batches_tracked
  res4.3.conv1.norm.num_batches_tracked
  res4.3.conv2.norm.num_batches_tracked
  res4.3.conv3.norm.num_batches_tracked
  res4.4.conv1.norm.num_batches_tracked
  res4.4.conv2.norm.num_batches_tracked
  res4.4.conv3.norm.num_batches_tracked
  res4.5.conv1.norm.num_batches_tracked
  res4.5.conv2.norm.num_batches_tracked
  res4.5.conv3.norm.num_batches_tracked
  res5.0.conv1.norm.num_batches_tracked
  res5.0.conv2.norm.num_batches_tracked
  res5.0.conv3.norm.num_batches_tracked
  res5.0.shortcut.norm.num_batches_tracked
  res5.1.conv1.norm.num_batches_tracked
  res5.1.conv2.norm.num_batches_tracked
  res5.1.conv3.norm.num_batches_tracked
  res5.2.conv1.norm.num_batches_tracked
  res5.2.conv2.norm.num_batches_tracked
  res5.2.conv3.norm.num_batches_tracked
  stem.conv1.norm.num_batches_tracked
  stem.conv2.norm.num_batches_tracked
  stem.conv3.norm.num_batches_tracked
  stem.fc.{bias, weight}
[12/10 21:53:10 d2.engine.train_loop]: Starting training from iteration 0
/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:481: UserWarning: This DataLoader will create 10 worker processes in total. Our suggested max number of worker in current system is 8, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.
  cpuset_checked))
[12/10 21:53:17 d2.utils.events]:  eta: 0:43:53  iter: 19  total_loss: 5.904  loss_sem_seg: 3.58  loss_center: 0.7001  loss_offset: 1.494  time: 0.2638  data_time: 0.0548  lr: 4.9867e-05  max_mem: 6513M
[12/10 21:53:22 d2.utils.events]:  eta: 0:43:38  iter: 39  total_loss: 5.915  loss_sem_seg: 3.429  loss_center: 0.7715  loss_offset: 1.597  time: 0.2636  data_time: 0.0220  lr: 9.9552e-05  max_mem: 6513M
[12/10 21:53:27 d2.utils.events]:  eta: 0:43:33  iter: 59  total_loss: 5.59  loss_sem_seg: 3.304  loss_center: 0.6512  loss_offset: 1.53  time: 0.2642  data_time: 0.0231  lr: 0.00014906  max_mem: 6513M
[12/10 21:53:33 d2.utils.events]:  eta: 0:43:33  iter: 79  total_loss: 5.805  loss_sem_seg: 3.258  loss_center: 0.7799  loss_offset: 1.597  time: 0.2642  data_time: 0.0226  lr: 0.00019838  max_mem: 6513M
[12/10 21:53:38 d2.utils.events]:  eta: 0:43:30  iter: 99  total_loss: 5.366  loss_sem_seg: 3.033  loss_center: 0.6544  loss_offset: 1.442  time: 0.2640  data_time: 0.0218  lr: 0.00024753  max_mem: 6513M
[12/10 21:53:43 d2.utils.events]:  eta: 0:43:22  iter: 119  total_loss: 5.332  loss_sem_seg: 2.937  loss_center: 0.6256  loss_offset: 1.732  time: 0.2635  data_time: 0.0221  lr: 0.00029649  max_mem: 6513M
[12/10 21:53:49 d2.utils.events]:  eta: 0:43:20  iter: 139  total_loss: 4.906  loss_sem_seg: 2.835  loss_center: 0.6561  loss_offset: 1.441  time: 0.2641  data_time: 0.0245  lr: 0.00034528  max_mem: 6513M
[12/10 21:53:54 d2.utils.events]:  eta: 0:43:15  iter: 159  total_loss: 5.179  loss_sem_seg: 2.713  loss_center: 0.6819  loss_offset: 1.564  time: 0.2641  data_time: 0.0226  lr: 0.00039388  max_mem: 6513M
[12/10 21:53:59 d2.utils.events]:  eta: 0:43:12  iter: 179  total_loss: 5.045  loss_sem_seg: 2.708  loss_center: 0.5395  loss_offset: 1.662  time: 0.2643  data_time: 0.0238  lr: 0.0004423  max_mem: 6513M
[12/10 21:54:04 d2.utils.events]:  eta: 0:43:10  iter: 199  total_loss: 4.621  loss_sem_seg: 2.336  loss_center: 0.7308  loss_offset: 1.515  time: 0.2645  data_time: 0.0236  lr: 0.00049055  max_mem: 6513M
[12/10 21:54:10 d2.utils.events]:  eta: 0:43:06  iter: 219  total_loss: 5.005  loss_sem_seg: 2.553  loss_center: 0.6129  loss_offset: 1.634  time: 0.2649  data_time: 0.0234  lr: 0.00053861  max_mem: 6513M
[12/10 21:54:15 d2.utils.events]:  eta: 0:43:03  iter: 239  total_loss: 4.675  loss_sem_seg: 2.489  loss_center: 0.7147  loss_offset: 1.494  time: 0.2651  data_time: 0.0239  lr: 0.00058649  max_mem: 6513M
[12/10 21:54:21 d2.utils.events]:  eta: 0:42:59  iter: 259  total_loss: 4.666  loss_sem_seg: 2.35  loss_center: 0.6944  loss_offset: 1.485  time: 0.2654  data_time: 0.0234  lr: 0.0006342  max_mem: 6513M
[12/10 21:54:26 d2.utils.events]:  eta: 0:42:54  iter: 279  total_loss: 4.27  loss_sem_seg: 2.133  loss_center: 0.7447  loss_offset: 1.365  time: 0.2653  data_time: 0.0234  lr: 0.00068172  max_mem: 6513M
[12/10 21:54:31 d2.utils.events]:  eta: 0:42:49  iter: 299  total_loss: 4.377  loss_sem_seg: 2.259  loss_center: 0.8206  loss_offset: 1.258  time: 0.2655  data_time: 0.0254  lr: 0.00072906  max_mem: 6513M
[12/10 21:54:37 d2.utils.events]:  eta: 0:42:43  iter: 319  total_loss: 4.527  loss_sem_seg: 2.135  loss_center: 0.7003  loss_offset: 1.564  time: 0.2656  data_time: 0.0233  lr: 0.00077622  max_mem: 6513M
[12/10 21:54:42 d2.utils.events]:  eta: 0:42:40  iter: 339  total_loss: 4.096  loss_sem_seg: 2.012  loss_center: 0.6738  loss_offset: 1.28  time: 0.2658  data_time: 0.0242  lr: 0.0008232  max_mem: 6513M
[12/10 21:54:47 d2.utils.events]:  eta: 0:42:39  iter: 359  total_loss: 4.39  loss_sem_seg: 2.477  loss_center: 0.6377  loss_offset: 1.322  time: 0.2660  data_time: 0.0245  lr: 0.00087  max_mem: 6513M
[12/10 21:54:53 d2.utils.events]:  eta: 0:42:34  iter: 379  total_loss: 4.389  loss_sem_seg: 2.308  loss_center: 0.8005  loss_offset: 1.221  time: 0.2661  data_time: 0.0236  lr: 0.00091662  max_mem: 6513M
[12/10 21:54:58 d2.utils.events]:  eta: 0:42:32  iter: 399  total_loss: 4.176  loss_sem_seg: 2.115  loss_center: 0.646  loss_offset: 1.323  time: 0.2661  data_time: 0.0246  lr: 0.00096306  max_mem: 6513M
[12/10 21:55:03 d2.utils.events]:  eta: 0:42:20  iter: 419  total_loss: 3.929  loss_sem_seg: 1.922  loss_center: 0.5468  loss_offset: 1.253  time: 0.2662  data_time: 0.0242  lr: 0.0010093  max_mem: 6513M
[12/10 21:55:09 d2.utils.events]:  eta: 0:42:17  iter: 439  total_loss: 4.302  loss_sem_seg: 2.277  loss_center: 0.6417  loss_offset: 1.364  time: 0.2664  data_time: 0.0252  lr: 0.0010554  max_mem: 6513M
[12/10 21:55:14 d2.utils.events]:  eta: 0:42:09  iter: 459  total_loss: 4.065  loss_sem_seg: 2.06  loss_center: 0.6518  loss_offset: 1.271  time: 0.2663  data_time: 0.0231  lr: 0.0011013  max_mem: 6513M
[12/10 21:55:20 d2.utils.events]:  eta: 0:42:09  iter: 479  total_loss: 3.775  loss_sem_seg: 1.971  loss_center: 0.5735  loss_offset: 1.271  time: 0.2664  data_time: 0.0238  lr: 0.001147  max_mem: 6513M
[12/10 21:55:25 d2.utils.events]:  eta: 0:41:59  iter: 499  total_loss: 3.573  loss_sem_seg: 1.753  loss_center: 0.579  loss_offset: 1.14  time: 0.2664  data_time: 0.0230  lr: 0.0011925  max_mem: 6513M
[12/10 21:55:30 d2.utils.events]:  eta: 0:41:52  iter: 519  total_loss: 3.498  loss_sem_seg: 1.623  loss_center: 0.7146  loss_offset: 1.087  time: 0.2666  data_time: 0.0244  lr: 0.0012379  max_mem: 6513M
[12/10 21:55:36 d2.utils.events]:  eta: 0:41:48  iter: 539  total_loss: 3.689  loss_sem_seg: 1.817  loss_center: 0.7164  loss_offset: 1.172  time: 0.2666  data_time: 0.0243  lr: 0.001283  max_mem: 6513M
[12/10 21:55:41 d2.utils.events]:  eta: 0:41:42  iter: 559  total_loss: 3.684  loss_sem_seg: 1.601  loss_center: 0.638  loss_offset: 1.142  time: 0.2667  data_time: 0.0234  lr: 0.001328  max_mem: 6513M
[12/10 21:55:46 d2.utils.events]:  eta: 0:41:38  iter: 579  total_loss: 3.498  loss_sem_seg: 1.732  loss_center: 0.7185  loss_offset: 1.03  time: 0.2667  data_time: 0.0227  lr: 0.0013728  max_mem: 6513M
[12/10 21:55:52 d2.utils.events]:  eta: 0:41:33  iter: 599  total_loss: 3.598  loss_sem_seg: 1.579  loss_center: 0.5816  loss_offset: 1.126  time: 0.2667  data_time: 0.0242  lr: 0.0014175  max_mem: 6513M
[12/10 21:55:57 d2.utils.events]:  eta: 0:41:29  iter: 619  total_loss: 3.812  loss_sem_seg: 2.148  loss_center: 0.776  loss_offset: 1.067  time: 0.2667  data_time: 0.0240  lr: 0.0014619  max_mem: 6513M
[12/10 21:56:02 d2.utils.events]:  eta: 0:41:24  iter: 639  total_loss: 3.448  loss_sem_seg: 1.743  loss_center: 0.7076  loss_offset: 1.05  time: 0.2667  data_time: 0.0239  lr: 0.0015062  max_mem: 6513M
[12/10 21:56:08 d2.utils.events]:  eta: 0:41:23  iter: 659  total_loss: 3.756  loss_sem_seg: 2.046  loss_center: 0.6061  loss_offset: 1.068  time: 0.2669  data_time: 0.0264  lr: 0.0015503  max_mem: 6513M
[12/10 21:56:13 d2.utils.events]:  eta: 0:41:18  iter: 679  total_loss: 3.409  loss_sem_seg: 1.573  loss_center: 0.7373  loss_offset: 1.018  time: 0.2669  data_time: 0.0234  lr: 0.0015942  max_mem: 6513M
[12/10 21:56:19 d2.utils.events]:  eta: 0:41:11  iter: 699  total_loss: 3.714  loss_sem_seg: 1.891  loss_center: 0.6361  loss_offset: 1.113  time: 0.2668  data_time: 0.0228  lr: 0.0016379  max_mem: 6513M
[12/10 21:56:24 d2.utils.events]:  eta: 0:41:07  iter: 719  total_loss: 3.387  loss_sem_seg: 1.685  loss_center: 0.5157  loss_offset: 1.094  time: 0.2668  data_time: 0.0240  lr: 0.0016814  max_mem: 6513M
[12/10 21:56:29 d2.utils.events]:  eta: 0:41:00  iter: 739  total_loss: 3.317  loss_sem_seg: 1.657  loss_center: 0.6123  loss_offset: 1.107  time: 0.2668  data_time: 0.0232  lr: 0.0017248  max_mem: 6513M
[12/10 21:56:35 d2.utils.events]:  eta: 0:40:56  iter: 759  total_loss: 3.438  loss_sem_seg: 1.655  loss_center: 0.7551  loss_offset: 1.01  time: 0.2667  data_time: 0.0238  lr: 0.0017679  max_mem: 6513M
[12/10 21:56:40 d2.utils.events]:  eta: 0:40:51  iter: 779  total_loss: 3.356  loss_sem_seg: 1.713  loss_center: 0.7114  loss_offset: 1.009  time: 0.2668  data_time: 0.0236  lr: 0.0018109  max_mem: 6513M
[12/10 21:56:45 d2.utils.events]:  eta: 0:40:46  iter: 799  total_loss: 3.147  loss_sem_seg: 1.682  loss_center: 0.5657  loss_offset: 0.8188  time: 0.2668  data_time: 0.0235  lr: 0.0018537  max_mem: 6513M
[12/10 21:56:51 d2.utils.events]:  eta: 0:40:41  iter: 819  total_loss: 3.587  loss_sem_seg: 1.84  loss_center: 0.6799  loss_offset: 1.081  time: 0.2669  data_time: 0.0231  lr: 0.0018964  max_mem: 6513M
[12/10 21:56:56 d2.utils.events]:  eta: 0:40:36  iter: 839  total_loss: 3.382  loss_sem_seg: 1.565  loss_center: 0.6282  loss_offset: 1.035  time: 0.2670  data_time: 0.0243  lr: 0.0019388  max_mem: 6513M
[12/10 21:57:01 d2.utils.events]:  eta: 0:40:31  iter: 859  total_loss: 3.406  loss_sem_seg: 1.658  loss_center: 0.7291  loss_offset: 0.8766  time: 0.2670  data_time: 0.0233  lr: 0.0019811  max_mem: 6513M
[12/10 21:57:07 d2.utils.events]:  eta: 0:40:26  iter: 879  total_loss: 3.152  loss_sem_seg: 1.436  loss_center: 0.73  loss_offset: 0.8092  time: 0.2669  data_time: 0.0246  lr: 0.0020231  max_mem: 6513M
[12/10 21:57:12 d2.utils.events]:  eta: 0:40:19  iter: 899  total_loss: 3.393  loss_sem_seg: 1.558  loss_center: 0.7581  loss_offset: 0.9817  time: 0.2669  data_time: 0.0216  lr: 0.002065  max_mem: 6513M
[12/10 21:57:17 d2.utils.events]:  eta: 0:40:14  iter: 919  total_loss: 3.301  loss_sem_seg: 1.487  loss_center: 0.8049  loss_offset: 0.9883  time: 0.2669  data_time: 0.0231  lr: 0.0021068  max_mem: 6513M
[12/10 21:57:23 d2.utils.events]:  eta: 0:40:09  iter: 939  total_loss: 3.659  loss_sem_seg: 1.879  loss_center: 0.7642  loss_offset: 1.113  time: 0.2669  data_time: 0.0240  lr: 0.0021483  max_mem: 6513M
[12/10 21:57:28 d2.utils.events]:  eta: 0:40:05  iter: 959  total_loss: 3.281  loss_sem_seg: 1.671  loss_center: 0.5879  loss_offset: 0.9099  time: 0.2669  data_time: 0.0250  lr: 0.0021896  max_mem: 6513M
[12/10 21:57:33 d2.utils.events]:  eta: 0:40:00  iter: 979  total_loss: 3.085  loss_sem_seg: 1.581  loss_center: 0.5213  loss_offset: 0.8452  time: 0.2669  data_time: 0.0235  lr: 0.0022308  max_mem: 6513M
[12/10 21:57:39 d2.utils.events]:  eta: 0:39:54  iter: 999  total_loss: 3.347  loss_sem_seg: 1.578  loss_center: 0.5558  loss_offset: 0.9591  time: 0.2669  data_time: 0.0223  lr: 0.0022718  max_mem: 6513M
[12/10 21:57:44 d2.utils.events]:  eta: 0:39:49  iter: 1019  total_loss: 3.492  loss_sem_seg: 1.603  loss_center: 0.5352  loss_offset: 0.9128  time: 0.2669  data_time: 0.0256  lr: 0.0022695  max_mem: 6513M
[12/10 21:57:49 d2.utils.events]:  eta: 0:39:45  iter: 1039  total_loss: 3.031  loss_sem_seg: 1.456  loss_center: 0.6684  loss_offset: 0.9019  time: 0.2669  data_time: 0.0234  lr: 0.002265  max_mem: 6513M
[12/10 21:57:55 d2.utils.events]:  eta: 0:39:40  iter: 1059  total_loss: 3.356  loss_sem_seg: 1.776  loss_center: 0.4793  loss_offset: 1.006  time: 0.2669  data_time: 0.0255  lr: 0.0022604  max_mem: 6513M
[12/10 21:58:00 d2.utils.events]:  eta: 0:39:34  iter: 1079  total_loss: 3.33  loss_sem_seg: 1.515  loss_center: 0.7123  loss_offset: 0.9337  time: 0.2669  data_time: 0.0232  lr: 0.0022559  max_mem: 6513M
[12/10 21:58:06 d2.utils.events]:  eta: 0:39:31  iter: 1099  total_loss: 3.11  loss_sem_seg: 1.454  loss_center: 0.5982  loss_offset: 0.9084  time: 0.2670  data_time: 0.0250  lr: 0.0022513  max_mem: 6513M
[12/10 21:58:11 d2.utils.events]:  eta: 0:39:27  iter: 1119  total_loss: 3.143  loss_sem_seg: 1.416  loss_center: 0.6613  loss_offset: 0.9153  time: 0.2670  data_time: 0.0234  lr: 0.0022468  max_mem: 6513M
[12/10 21:58:16 d2.utils.events]:  eta: 0:39:22  iter: 1139  total_loss: 3.012  loss_sem_seg: 1.395  loss_center: 0.6451  loss_offset: 0.8643  time: 0.2670  data_time: 0.0240  lr: 0.0022422  max_mem: 6513M
[12/10 21:58:22 d2.utils.events]:  eta: 0:39:18  iter: 1159  total_loss: 3.233  loss_sem_seg: 1.579  loss_center: 0.5635  loss_offset: 1.059  time: 0.2670  data_time: 0.0231  lr: 0.0022376  max_mem: 6513M
[12/10 21:58:27 d2.utils.events]:  eta: 0:39:11  iter: 1179  total_loss: 3.273  loss_sem_seg: 1.538  loss_center: 0.5835  loss_offset: 0.9641  time: 0.2670  data_time: 0.0239  lr: 0.0022331  max_mem: 6513M
[12/10 21:58:32 d2.utils.events]:  eta: 0:39:05  iter: 1199  total_loss: 3.106  loss_sem_seg: 1.59  loss_center: 0.5466  loss_offset: 1  time: 0.2671  data_time: 0.0250  lr: 0.0022285  max_mem: 6513M
[12/10 21:58:38 d2.utils.events]:  eta: 0:38:59  iter: 1219  total_loss: 2.887  loss_sem_seg: 1.291  loss_center: 0.6808  loss_offset: 0.8282  time: 0.2670  data_time: 0.0250  lr: 0.002224  max_mem: 6513M
[12/10 21:58:43 d2.utils.events]:  eta: 0:38:54  iter: 1239  total_loss: 3.011  loss_sem_seg: 1.576  loss_center: 0.4807  loss_offset: 0.9211  time: 0.2670  data_time: 0.0241  lr: 0.0022194  max_mem: 6513M
[12/10 21:58:48 d2.utils.events]:  eta: 0:38:47  iter: 1259  total_loss: 3.031  loss_sem_seg: 1.306  loss_center: 0.7748  loss_offset: 0.834  time: 0.2670  data_time: 0.0234  lr: 0.0022149  max_mem: 6513M
[12/10 21:58:54 d2.utils.events]:  eta: 0:38:41  iter: 1279  total_loss: 2.954  loss_sem_seg: 1.46  loss_center: 0.8111  loss_offset: 0.9246  time: 0.2670  data_time: 0.0235  lr: 0.0022103  max_mem: 6513M
[12/10 21:58:59 d2.utils.events]:  eta: 0:38:37  iter: 1299  total_loss: 2.887  loss_sem_seg: 1.436  loss_center: 0.5267  loss_offset: 0.902  time: 0.2671  data_time: 0.0268  lr: 0.0022057  max_mem: 6513M
[12/10 21:59:05 d2.utils.events]:  eta: 0:38:32  iter: 1319  total_loss: 3.072  loss_sem_seg: 1.405  loss_center: 0.6318  loss_offset: 0.93  time: 0.2671  data_time: 0.0230  lr: 0.0022012  max_mem: 6513M
[12/10 21:59:10 d2.utils.events]:  eta: 0:38:27  iter: 1339  total_loss: 3.151  loss_sem_seg: 1.674  loss_center: 0.6499  loss_offset: 0.8316  time: 0.2671  data_time: 0.0245  lr: 0.0021966  max_mem: 6513M
[12/10 21:59:15 d2.utils.events]:  eta: 0:38:20  iter: 1359  total_loss: 3.095  loss_sem_seg: 1.506  loss_center: 0.5156  loss_offset: 0.9111  time: 0.2671  data_time: 0.0241  lr: 0.002192  max_mem: 6513M
[12/10 21:59:21 d2.utils.events]:  eta: 0:38:15  iter: 1379  total_loss: 3.072  loss_sem_seg: 1.535  loss_center: 0.6331  loss_offset: 0.8935  time: 0.2671  data_time: 0.0243  lr: 0.0021875  max_mem: 6513M
[12/10 21:59:26 d2.utils.events]:  eta: 0:38:09  iter: 1399  total_loss: 3.129  loss_sem_seg: 1.471  loss_center: 0.726  loss_offset: 0.8985  time: 0.2671  data_time: 0.0247  lr: 0.0021829  max_mem: 6513M
[12/10 21:59:31 d2.utils.events]:  eta: 0:38:05  iter: 1419  total_loss: 2.992  loss_sem_seg: 1.363  loss_center: 0.5647  loss_offset: 0.9208  time: 0.2671  data_time: 0.0234  lr: 0.0021783  max_mem: 6513M
[12/10 21:59:37 d2.utils.events]:  eta: 0:37:59  iter: 1439  total_loss: 3.348  loss_sem_seg: 1.437  loss_center: 0.6977  loss_offset: 1.001  time: 0.2671  data_time: 0.0240  lr: 0.0021738  max_mem: 6513M
[12/10 21:59:42 d2.utils.events]:  eta: 0:37:53  iter: 1459  total_loss: 3.101  loss_sem_seg: 1.388  loss_center: 0.6332  loss_offset: 0.931  time: 0.2670  data_time: 0.0218  lr: 0.0021692  max_mem: 6513M
[12/10 21:59:47 d2.utils.events]:  eta: 0:37:47  iter: 1479  total_loss: 2.701  loss_sem_seg: 1.221  loss_center: 0.6211  loss_offset: 0.7825  time: 0.2670  data_time: 0.0243  lr: 0.0021646  max_mem: 6513M
[12/10 21:59:53 d2.utils.events]:  eta: 0:37:42  iter: 1499  total_loss: 3.082  loss_sem_seg: 1.334  loss_center: 0.6196  loss_offset: 0.9283  time: 0.2671  data_time: 0.0240  lr: 0.00216  max_mem: 6513M
[12/10 21:59:58 d2.utils.events]:  eta: 0:37:37  iter: 1519  total_loss: 3.103  loss_sem_seg: 1.342  loss_center: 0.7874  loss_offset: 0.8464  time: 0.2670  data_time: 0.0242  lr: 0.0021555  max_mem: 6513M
[12/10 22:00:03 d2.utils.events]:  eta: 0:37:32  iter: 1539  total_loss: 3.06  loss_sem_seg: 1.348  loss_center: 0.5923  loss_offset: 0.9278  time: 0.2670  data_time: 0.0243  lr: 0.0021509  max_mem: 6513M
[12/10 22:00:09 d2.utils.events]:  eta: 0:37:27  iter: 1559  total_loss: 2.813  loss_sem_seg: 1.275  loss_center: 0.7436  loss_offset: 0.8412  time: 0.2670  data_time: 0.0245  lr: 0.0021463  max_mem: 6513M
[12/10 22:00:14 d2.utils.events]:  eta: 0:37:23  iter: 1579  total_loss: 2.989  loss_sem_seg: 1.372  loss_center: 0.6072  loss_offset: 0.9009  time: 0.2670  data_time: 0.0251  lr: 0.0021417  max_mem: 6513M
[12/10 22:00:19 d2.utils.events]:  eta: 0:37:18  iter: 1599  total_loss: 2.853  loss_sem_seg: 1.354  loss_center: 0.5506  loss_offset: 0.981  time: 0.2670  data_time: 0.0232  lr: 0.0021372  max_mem: 6513M
[12/10 22:00:25 d2.utils.events]:  eta: 0:37:13  iter: 1619  total_loss: 2.978  loss_sem_seg: 1.533  loss_center: 0.6042  loss_offset: 0.8231  time: 0.2670  data_time: 0.0246  lr: 0.0021326  max_mem: 6513M
[12/10 22:00:30 d2.utils.events]:  eta: 0:37:06  iter: 1639  total_loss: 2.898  loss_sem_seg: 1.366  loss_center: 0.5409  loss_offset: 0.7732  time: 0.2670  data_time: 0.0234  lr: 0.002128  max_mem: 6513M
[12/10 22:00:35 d2.utils.events]:  eta: 0:36:59  iter: 1659  total_loss: 2.841  loss_sem_seg: 1.249  loss_center: 0.5982  loss_offset: 0.8919  time: 0.2670  data_time: 0.0240  lr: 0.0021234  max_mem: 6513M
[12/10 22:00:41 d2.utils.events]:  eta: 0:36:53  iter: 1679  total_loss: 2.856  loss_sem_seg: 1.266  loss_center: 0.5961  loss_offset: 0.8533  time: 0.2670  data_time: 0.0234  lr: 0.0021188  max_mem: 6513M
[12/10 22:00:46 d2.utils.events]:  eta: 0:36:48  iter: 1699  total_loss: 2.909  loss_sem_seg: 1.506  loss_center: 0.6538  loss_offset: 0.8502  time: 0.2670  data_time: 0.0245  lr: 0.0021143  max_mem: 6513M
[12/10 22:00:52 d2.utils.events]:  eta: 0:36:42  iter: 1719  total_loss: 2.815  loss_sem_seg: 1.315  loss_center: 0.6945  loss_offset: 0.837  time: 0.2670  data_time: 0.0252  lr: 0.0021097  max_mem: 6513M
[12/10 22:00:57 d2.utils.events]:  eta: 0:36:38  iter: 1739  total_loss: 2.76  loss_sem_seg: 1.337  loss_center: 0.6754  loss_offset: 0.8398  time: 0.2670  data_time: 0.0242  lr: 0.0021051  max_mem: 6513M
[12/10 22:01:02 d2.utils.events]:  eta: 0:36:33  iter: 1759  total_loss: 2.858  loss_sem_seg: 1.396  loss_center: 0.589  loss_offset: 0.8431  time: 0.2671  data_time: 0.0240  lr: 0.0021005  max_mem: 6513M
[12/10 22:01:08 d2.utils.events]:  eta: 0:36:28  iter: 1779  total_loss: 2.617  loss_sem_seg: 1.258  loss_center: 0.6449  loss_offset: 0.7939  time: 0.2671  data_time: 0.0247  lr: 0.0020959  max_mem: 6513M
[12/10 22:01:13 d2.utils.events]:  eta: 0:36:22  iter: 1799  total_loss: 2.775  loss_sem_seg: 1.365  loss_center: 0.6107  loss_offset: 0.8138  time: 0.2671  data_time: 0.0241  lr: 0.0020913  max_mem: 6513M
[12/10 22:01:18 d2.utils.events]:  eta: 0:36:17  iter: 1819  total_loss: 2.913  loss_sem_seg: 1.477  loss_center: 0.6498  loss_offset: 0.9  time: 0.2671  data_time: 0.0257  lr: 0.0020867  max_mem: 6513M
[12/10 22:01:24 d2.utils.events]:  eta: 0:36:12  iter: 1839  total_loss: 2.747  loss_sem_seg: 1.336  loss_center: 0.6075  loss_offset: 0.9466  time: 0.2671  data_time: 0.0237  lr: 0.0020821  max_mem: 6513M
[12/10 22:01:29 d2.utils.events]:  eta: 0:36:07  iter: 1859  total_loss: 2.891  loss_sem_seg: 1.475  loss_center: 0.6894  loss_offset: 0.8489  time: 0.2671  data_time: 0.0259  lr: 0.0020775  max_mem: 6513M
[12/10 22:01:34 d2.utils.events]:  eta: 0:36:01  iter: 1879  total_loss: 2.783  loss_sem_seg: 1.35  loss_center: 0.6151  loss_offset: 0.8487  time: 0.2671  data_time: 0.0238  lr: 0.0020729  max_mem: 6513M
[12/10 22:01:40 d2.utils.events]:  eta: 0:35:56  iter: 1899  total_loss: 2.809  loss_sem_seg: 1.42  loss_center: 0.5643  loss_offset: 0.8597  time: 0.2671  data_time: 0.0245  lr: 0.0020684  max_mem: 6513M
[12/10 22:01:45 d2.utils.events]:  eta: 0:35:50  iter: 1919  total_loss: 2.906  loss_sem_seg: 1.318  loss_center: 0.4912  loss_offset: 0.9194  time: 0.2671  data_time: 0.0243  lr: 0.0020638  max_mem: 6513M
[12/10 22:01:51 d2.utils.events]:  eta: 0:35:45  iter: 1939  total_loss: 2.84  loss_sem_seg: 1.378  loss_center: 0.7096  loss_offset: 0.8449  time: 0.2671  data_time: 0.0242  lr: 0.0020592  max_mem: 6513M
[12/10 22:01:56 d2.utils.events]:  eta: 0:35:39  iter: 1959  total_loss: 2.982  loss_sem_seg: 1.252  loss_center: 0.5753  loss_offset: 0.7887  time: 0.2672  data_time: 0.0258  lr: 0.0020546  max_mem: 6513M
[12/10 22:02:01 d2.utils.events]:  eta: 0:35:34  iter: 1979  total_loss: 3.019  loss_sem_seg: 1.419  loss_center: 0.6873  loss_offset: 0.809  time: 0.2672  data_time: 0.0232  lr: 0.00205  max_mem: 6513M
[12/10 22:02:07 d2.utils.events]:  eta: 0:35:29  iter: 1999  total_loss: 3.056  loss_sem_seg: 1.333  loss_center: 0.671  loss_offset: 0.8625  time: 0.2672  data_time: 0.0246  lr: 0.0020454  max_mem: 6513M
[12/10 22:02:12 d2.utils.events]:  eta: 0:35:24  iter: 2019  total_loss: 2.95  loss_sem_seg: 1.268  loss_center: 0.5473  loss_offset: 0.9332  time: 0.2672  data_time: 0.0259  lr: 0.0020408  max_mem: 6513M
[12/10 22:02:18 d2.utils.events]:  eta: 0:35:19  iter: 2039  total_loss: 2.7  loss_sem_seg: 1.146  loss_center: 0.6077  loss_offset: 0.8842  time: 0.2672  data_time: 0.0249  lr: 0.0020362  max_mem: 6513M
[12/10 22:02:23 d2.utils.events]:  eta: 0:35:14  iter: 2059  total_loss: 3.012  loss_sem_seg: 1.476  loss_center: 0.5674  loss_offset: 0.9126  time: 0.2673  data_time: 0.0250  lr: 0.0020316  max_mem: 6513M
[12/10 22:02:28 d2.utils.events]:  eta: 0:35:08  iter: 2079  total_loss: 3.025  loss_sem_seg: 1.39  loss_center: 0.6084  loss_offset: 0.9126  time: 0.2673  data_time: 0.0232  lr: 0.0020269  max_mem: 6513M
[12/10 22:02:34 d2.utils.events]:  eta: 0:35:03  iter: 2099  total_loss: 2.658  loss_sem_seg: 1.238  loss_center: 0.5639  loss_offset: 0.8027  time: 0.2673  data_time: 0.0249  lr: 0.0020223  max_mem: 6513M
[12/10 22:02:39 d2.utils.events]:  eta: 0:34:57  iter: 2119  total_loss: 2.863  loss_sem_seg: 1.44  loss_center: 0.6255  loss_offset: 0.8338  time: 0.2672  data_time: 0.0235  lr: 0.0020177  max_mem: 6513M
[12/10 22:02:44 d2.utils.events]:  eta: 0:34:52  iter: 2139  total_loss: 3.046  loss_sem_seg: 1.257  loss_center: 0.7972  loss_offset: 0.9217  time: 0.2673  data_time: 0.0248  lr: 0.0020131  max_mem: 6513M
[12/10 22:02:50 d2.utils.events]:  eta: 0:34:46  iter: 2159  total_loss: 2.891  loss_sem_seg: 1.218  loss_center: 0.6563  loss_offset: 0.7904  time: 0.2672  data_time: 0.0230  lr: 0.0020085  max_mem: 6513M
[12/10 22:02:55 d2.utils.events]:  eta: 0:34:41  iter: 2179  total_loss: 2.837  loss_sem_seg: 1.27  loss_center: 0.6111  loss_offset: 0.7635  time: 0.2672  data_time: 0.0244  lr: 0.0020039  max_mem: 6513M
[12/10 22:03:00 d2.utils.events]:  eta: 0:34:35  iter: 2199  total_loss: 2.734  loss_sem_seg: 1.224  loss_center: 0.6693  loss_offset: 0.7899  time: 0.2672  data_time: 0.0241  lr: 0.0019993  max_mem: 6513M
[12/10 22:03:06 d2.utils.events]:  eta: 0:34:31  iter: 2219  total_loss: 2.809  loss_sem_seg: 1.247  loss_center: 0.7508  loss_offset: 0.9047  time: 0.2672  data_time: 0.0243  lr: 0.0019947  max_mem: 6513M
[12/10 22:03:11 d2.utils.events]:  eta: 0:34:25  iter: 2239  total_loss: 2.625  loss_sem_seg: 1.038  loss_center: 0.6722  loss_offset: 0.7912  time: 0.2672  data_time: 0.0229  lr: 0.0019901  max_mem: 6513M
[12/10 22:03:16 d2.utils.events]:  eta: 0:34:20  iter: 2259  total_loss: 2.899  loss_sem_seg: 1.219  loss_center: 0.8212  loss_offset: 0.7682  time: 0.2672  data_time: 0.0242  lr: 0.0019854  max_mem: 6513M
[12/10 22:03:22 d2.utils.events]:  eta: 0:34:15  iter: 2279  total_loss: 2.862  loss_sem_seg: 1.244  loss_center: 0.7815  loss_offset: 0.7886  time: 0.2672  data_time: 0.0246  lr: 0.0019808  max_mem: 6513M
[12/10 22:03:27 d2.utils.events]:  eta: 0:34:09  iter: 2299  total_loss: 2.618  loss_sem_seg: 1.046  loss_center: 0.7256  loss_offset: 0.809  time: 0.2672  data_time: 0.0238  lr: 0.0019762  max_mem: 6513M
[12/10 22:03:32 d2.utils.events]:  eta: 0:34:04  iter: 2319  total_loss: 2.772  loss_sem_seg: 1.381  loss_center: 0.5708  loss_offset: 0.7876  time: 0.2672  data_time: 0.0251  lr: 0.0019716  max_mem: 6513M
[12/10 22:03:38 d2.utils.events]:  eta: 0:33:59  iter: 2339  total_loss: 2.748  loss_sem_seg: 1.351  loss_center: 0.5332  loss_offset: 0.8404  time: 0.2672  data_time: 0.0254  lr: 0.001967  max_mem: 6513M
[12/10 22:03:43 d2.utils.events]:  eta: 0:33:53  iter: 2359  total_loss: 2.805  loss_sem_seg: 1.211  loss_center: 0.6802  loss_offset: 0.7797  time: 0.2672  data_time: 0.0224  lr: 0.0019623  max_mem: 6513M
[12/10 22:03:48 d2.utils.events]:  eta: 0:33:48  iter: 2379  total_loss: 2.964  loss_sem_seg: 1.228  loss_center: 0.6749  loss_offset: 0.8267  time: 0.2672  data_time: 0.0244  lr: 0.0019577  max_mem: 6513M
[12/10 22:03:54 d2.utils.events]:  eta: 0:33:42  iter: 2399  total_loss: 2.874  loss_sem_seg: 1.364  loss_center: 0.6432  loss_offset: 0.7912  time: 0.2672  data_time: 0.0230  lr: 0.0019531  max_mem: 6513M
[12/10 22:03:59 d2.utils.events]:  eta: 0:33:37  iter: 2419  total_loss: 2.795  loss_sem_seg: 1.321  loss_center: 0.5678  loss_offset: 0.8431  time: 0.2672  data_time: 0.0259  lr: 0.0019485  max_mem: 6513M
[12/10 22:04:05 d2.utils.events]:  eta: 0:33:32  iter: 2439  total_loss: 2.459  loss_sem_seg: 1.213  loss_center: 0.5076  loss_offset: 0.7674  time: 0.2672  data_time: 0.0255  lr: 0.0019438  max_mem: 6513M
[12/10 22:04:10 d2.utils.events]:  eta: 0:33:27  iter: 2459  total_loss: 2.621  loss_sem_seg: 1.031  loss_center: 0.5764  loss_offset: 0.8166  time: 0.2672  data_time: 0.0227  lr: 0.0019392  max_mem: 6513M
[12/10 22:04:15 d2.utils.events]:  eta: 0:33:21  iter: 2479  total_loss: 2.765  loss_sem_seg: 1.277  loss_center: 0.5744  loss_offset: 0.8166  time: 0.2673  data_time: 0.0243  lr: 0.0019346  max_mem: 6513M
[12/10 22:04:21 d2.utils.events]:  eta: 0:33:16  iter: 2499  total_loss: 2.864  loss_sem_seg: 1.257  loss_center: 0.6211  loss_offset: 0.8844  time: 0.2673  data_time: 0.0234  lr: 0.00193  max_mem: 6513M
[12/10 22:04:26 d2.utils.events]:  eta: 0:33:12  iter: 2519  total_loss: 2.617  loss_sem_seg: 1.13  loss_center: 0.5551  loss_offset: 0.83  time: 0.2673  data_time: 0.0241  lr: 0.0019253  max_mem: 6513M
[12/10 22:04:31 d2.utils.events]:  eta: 0:33:06  iter: 2539  total_loss: 2.731  loss_sem_seg: 1.118  loss_center: 0.595  loss_offset: 0.7844  time: 0.2673  data_time: 0.0235  lr: 0.0019207  max_mem: 6513M
[12/10 22:04:37 d2.utils.events]:  eta: 0:33:03  iter: 2559  total_loss: 2.799  loss_sem_seg: 1.219  loss_center: 0.6978  loss_offset: 0.8975  time: 0.2673  data_time: 0.0240  lr: 0.0019161  max_mem: 6513M
[12/10 22:04:42 d2.utils.events]:  eta: 0:32:57  iter: 2579  total_loss: 2.676  loss_sem_seg: 1.193  loss_center: 0.7161  loss_offset: 0.8108  time: 0.2673  data_time: 0.0242  lr: 0.0019114  max_mem: 6513M
[12/10 22:04:47 d2.utils.events]:  eta: 0:32:51  iter: 2599  total_loss: 2.712  loss_sem_seg: 1.206  loss_center: 0.6226  loss_offset: 0.7792  time: 0.2673  data_time: 0.0241  lr: 0.0019068  max_mem: 6513M
[12/10 22:04:53 d2.utils.events]:  eta: 0:32:46  iter: 2619  total_loss: 2.452  loss_sem_seg: 1.127  loss_center: 0.5662  loss_offset: 0.7221  time: 0.2673  data_time: 0.0241  lr: 0.0019021  max_mem: 6513M
[12/10 22:04:58 d2.utils.events]:  eta: 0:32:42  iter: 2639  total_loss: 2.844  loss_sem_seg: 1.294  loss_center: 0.6047  loss_offset: 0.8692  time: 0.2673  data_time: 0.0256  lr: 0.0018975  max_mem: 6513M
[12/10 22:05:04 d2.utils.events]:  eta: 0:32:37  iter: 2659  total_loss: 2.747  loss_sem_seg: 1.112  loss_center: 0.6439  loss_offset: 0.8043  time: 0.2673  data_time: 0.0247  lr: 0.0018929  max_mem: 6513M
[12/10 22:05:09 d2.utils.events]:  eta: 0:32:32  iter: 2679  total_loss: 2.795  loss_sem_seg: 1.249  loss_center: 0.7047  loss_offset: 0.7825  time: 0.2673  data_time: 0.0238  lr: 0.0018882  max_mem: 6513M
[12/10 22:05:14 d2.utils.events]:  eta: 0:32:26  iter: 2699  total_loss: 2.954  loss_sem_seg: 1.276  loss_center: 0.6319  loss_offset: 0.9609  time: 0.2673  data_time: 0.0244  lr: 0.0018836  max_mem: 6513M
[12/10 22:05:20 d2.utils.events]:  eta: 0:32:21  iter: 2719  total_loss: 2.583  loss_sem_seg: 1.206  loss_center: 0.566  loss_offset: 0.7835  time: 0.2673  data_time: 0.0243  lr: 0.0018789  max_mem: 6513M
[12/10 22:05:25 d2.utils.events]:  eta: 0:32:16  iter: 2739  total_loss: 2.868  loss_sem_seg: 1.386  loss_center: 0.5891  loss_offset: 0.8327  time: 0.2673  data_time: 0.0237  lr: 0.0018743  max_mem: 6513M
[12/10 22:05:30 d2.utils.events]:  eta: 0:32:09  iter: 2759  total_loss: 2.644  loss_sem_seg: 1.131  loss_center: 0.5879  loss_offset: 0.8092  time: 0.2673  data_time: 0.0251  lr: 0.0018696  max_mem: 6513M
[12/10 22:05:36 d2.utils.events]:  eta: 0:32:04  iter: 2779  total_loss: 2.825  loss_sem_seg: 1.148  loss_center: 0.6003  loss_offset: 0.9402  time: 0.2673  data_time: 0.0236  lr: 0.001865  max_mem: 6513M
[12/10 22:05:41 d2.utils.events]:  eta: 0:31:59  iter: 2799  total_loss: 2.705  loss_sem_seg: 1.176  loss_center: 0.694  loss_offset: 0.8551  time: 0.2673  data_time: 0.0256  lr: 0.0018603  max_mem: 6513M
[12/10 22:05:46 d2.utils.events]:  eta: 0:31:52  iter: 2819  total_loss: 2.92  loss_sem_seg: 1.285  loss_center: 0.6097  loss_offset: 0.8449  time: 0.2673  data_time: 0.0220  lr: 0.0018557  max_mem: 6513M
[12/10 22:05:52 d2.utils.events]:  eta: 0:31:46  iter: 2839  total_loss: 2.784  loss_sem_seg: 1.233  loss_center: 0.5301  loss_offset: 0.8765  time: 0.2673  data_time: 0.0238  lr: 0.001851  max_mem: 6513M
[12/10 22:05:57 d2.utils.events]:  eta: 0:31:40  iter: 2859  total_loss: 2.69  loss_sem_seg: 1.141  loss_center: 0.6754  loss_offset: 0.8956  time: 0.2673  data_time: 0.0242  lr: 0.0018464  max_mem: 6513M
[12/10 22:06:02 d2.utils.events]:  eta: 0:31:37  iter: 2879  total_loss: 2.721  loss_sem_seg: 1.219  loss_center: 0.7572  loss_offset: 0.8171  time: 0.2673  data_time: 0.0252  lr: 0.0018417  max_mem: 6513M
[12/10 22:06:08 d2.utils.events]:  eta: 0:31:30  iter: 2899  total_loss: 2.413  loss_sem_seg: 1.004  loss_center: 0.5308  loss_offset: 0.735  time: 0.2673  data_time: 0.0236  lr: 0.0018371  max_mem: 6513M
[12/10 22:06:13 d2.utils.events]:  eta: 0:31:27  iter: 2919  total_loss: 2.826  loss_sem_seg: 1.085  loss_center: 0.5378  loss_offset: 0.9096  time: 0.2673  data_time: 0.0245  lr: 0.0018324  max_mem: 6513M
[12/10 22:06:19 d2.utils.events]:  eta: 0:31:21  iter: 2939  total_loss: 2.568  loss_sem_seg: 1.035  loss_center: 0.633  loss_offset: 0.7975  time: 0.2673  data_time: 0.0242  lr: 0.0018278  max_mem: 6513M
[12/10 22:06:24 d2.utils.events]:  eta: 0:31:15  iter: 2959  total_loss: 2.763  loss_sem_seg: 1.222  loss_center: 0.6806  loss_offset: 0.7061  time: 0.2673  data_time: 0.0241  lr: 0.0018231  max_mem: 6513M
[12/10 22:06:29 d2.utils.events]:  eta: 0:31:09  iter: 2979  total_loss: 2.654  loss_sem_seg: 1.232  loss_center: 0.6724  loss_offset: 0.7631  time: 0.2673  data_time: 0.0227  lr: 0.0018184  max_mem: 6513M
[12/10 22:06:35 d2.utils.events]:  eta: 0:31:03  iter: 2999  total_loss: 2.657  loss_sem_seg: 1.32  loss_center: 0.6533  loss_offset: 0.7709  time: 0.2673  data_time: 0.0241  lr: 0.0018138  max_mem: 6513M
[12/10 22:06:40 d2.utils.events]:  eta: 0:30:59  iter: 3019  total_loss: 2.894  loss_sem_seg: 1.278  loss_center: 0.734  loss_offset: 0.8442  time: 0.2673  data_time: 0.0257  lr: 0.0018091  max_mem: 6513M
[12/10 22:06:45 d2.utils.events]:  eta: 0:30:53  iter: 3039  total_loss: 2.692  loss_sem_seg: 1.062  loss_center: 0.611  loss_offset: 0.7874  time: 0.2673  data_time: 0.0249  lr: 0.0018044  max_mem: 6513M
[12/10 22:06:51 d2.utils.events]:  eta: 0:30:47  iter: 3059  total_loss: 2.585  loss_sem_seg: 1.218  loss_center: 0.6058  loss_offset: 0.8159  time: 0.2673  data_time: 0.0240  lr: 0.0017998  max_mem: 6513M
[12/10 22:06:56 d2.utils.events]:  eta: 0:30:42  iter: 3079  total_loss: 2.595  loss_sem_seg: 1.139  loss_center: 0.5172  loss_offset: 0.8522  time: 0.2673  data_time: 0.0250  lr: 0.0017951  max_mem: 6513M
[12/10 22:07:01 d2.utils.events]:  eta: 0:30:38  iter: 3099  total_loss: 3.055  loss_sem_seg: 1.433  loss_center: 0.7627  loss_offset: 0.8674  time: 0.2673  data_time: 0.0244  lr: 0.0017904  max_mem: 6513M
[12/10 22:07:07 d2.utils.events]:  eta: 0:30:34  iter: 3119  total_loss: 2.558  loss_sem_seg: 1.213  loss_center: 0.5631  loss_offset: 0.7546  time: 0.2673  data_time: 0.0249  lr: 0.0017858  max_mem: 6513M
[12/10 22:07:12 d2.utils.events]:  eta: 0:30:28  iter: 3139  total_loss: 2.694  loss_sem_seg: 1.08  loss_center: 0.6064  loss_offset: 0.7871  time: 0.2673  data_time: 0.0243  lr: 0.0017811  max_mem: 6513M
[12/10 22:07:18 d2.utils.events]:  eta: 0:30:23  iter: 3159  total_loss: 2.485  loss_sem_seg: 0.9744  loss_center: 0.6171  loss_offset: 0.8229  time: 0.2673  data_time: 0.0226  lr: 0.0017764  max_mem: 6513M
[12/10 22:07:23 d2.utils.events]:  eta: 0:30:18  iter: 3179  total_loss: 2.597  loss_sem_seg: 1.232  loss_center: 0.5731  loss_offset: 0.8693  time: 0.2674  data_time: 0.0258  lr: 0.0017718  max_mem: 6513M
[12/10 22:07:28 d2.utils.events]:  eta: 0:30:13  iter: 3199  total_loss: 2.398  loss_sem_seg: 1.04  loss_center: 0.5936  loss_offset: 0.8091  time: 0.2674  data_time: 0.0239  lr: 0.0017671  max_mem: 6513M
[12/10 22:07:34 d2.utils.events]:  eta: 0:30:07  iter: 3219  total_loss: 2.727  loss_sem_seg: 1.253  loss_center: 0.5011  loss_offset: 0.7933  time: 0.2674  data_time: 0.0235  lr: 0.0017624  max_mem: 6513M
[12/10 22:07:39 d2.utils.events]:  eta: 0:30:02  iter: 3239  total_loss: 2.65  loss_sem_seg: 1.068  loss_center: 0.5854  loss_offset: 0.9038  time: 0.2674  data_time: 0.0237  lr: 0.0017577  max_mem: 6513M
[12/10 22:07:44 d2.utils.events]:  eta: 0:29:56  iter: 3259  total_loss: 2.6  loss_sem_seg: 1.061  loss_center: 0.6319  loss_offset: 0.7588  time: 0.2674  data_time: 0.0230  lr: 0.001753  max_mem: 6513M
[12/10 22:07:50 d2.utils.events]:  eta: 0:29:50  iter: 3279  total_loss: 2.458  loss_sem_seg: 1.018  loss_center: 0.6317  loss_offset: 0.8027  time: 0.2673  data_time: 0.0231  lr: 0.0017484  max_mem: 6513M
[12/10 22:07:55 d2.utils.events]:  eta: 0:29:45  iter: 3299  total_loss: 2.765  loss_sem_seg: 1.222  loss_center: 0.6687  loss_offset: 0.8006  time: 0.2674  data_time: 0.0241  lr: 0.0017437  max_mem: 6513M
[12/10 22:08:00 d2.utils.events]:  eta: 0:29:39  iter: 3319  total_loss: 2.725  loss_sem_seg: 1.054  loss_center: 0.6747  loss_offset: 0.7942  time: 0.2674  data_time: 0.0235  lr: 0.001739  max_mem: 6513M
[12/10 22:08:06 d2.utils.events]:  eta: 0:29:34  iter: 3339  total_loss: 2.639  loss_sem_seg: 1.169  loss_center: 0.5498  loss_offset: 0.8083  time: 0.2674  data_time: 0.0245  lr: 0.0017343  max_mem: 6513M
[12/10 22:08:11 d2.utils.events]:  eta: 0:29:30  iter: 3359  total_loss: 2.543  loss_sem_seg: 1.123  loss_center: 0.5747  loss_offset: 0.844  time: 0.2674  data_time: 0.0248  lr: 0.0017296  max_mem: 6513M
[12/10 22:08:17 d2.utils.events]:  eta: 0:29:26  iter: 3379  total_loss: 2.875  loss_sem_seg: 1.138  loss_center: 0.5725  loss_offset: 0.8367  time: 0.2674  data_time: 0.0234  lr: 0.0017249  max_mem: 6513M
[12/10 22:08:22 d2.utils.events]:  eta: 0:29:20  iter: 3399  total_loss: 2.837  loss_sem_seg: 1.291  loss_center: 0.6254  loss_offset: 0.8391  time: 0.2674  data_time: 0.0246  lr: 0.0017202  max_mem: 6513M
[12/10 22:08:27 d2.utils.events]:  eta: 0:29:15  iter: 3419  total_loss: 2.653  loss_sem_seg: 1.216  loss_center: 0.5044  loss_offset: 0.9241  time: 0.2674  data_time: 0.0249  lr: 0.0017155  max_mem: 6513M
[12/10 22:08:33 d2.utils.events]:  eta: 0:29:08  iter: 3439  total_loss: 2.572  loss_sem_seg: 1.032  loss_center: 0.6283  loss_offset: 0.7776  time: 0.2674  data_time: 0.0223  lr: 0.0017109  max_mem: 6513M
[12/10 22:08:38 d2.utils.events]:  eta: 0:29:03  iter: 3459  total_loss: 2.438  loss_sem_seg: 1.055  loss_center: 0.4534  loss_offset: 0.7272  time: 0.2674  data_time: 0.0234  lr: 0.0017062  max_mem: 6513M
[12/10 22:08:43 d2.utils.events]:  eta: 0:28:57  iter: 3479  total_loss: 2.566  loss_sem_seg: 1.06  loss_center: 0.707  loss_offset: 0.7419  time: 0.2673  data_time: 0.0239  lr: 0.0017015  max_mem: 6513M
[12/10 22:08:49 d2.utils.events]:  eta: 0:28:51  iter: 3499  total_loss: 2.768  loss_sem_seg: 1.151  loss_center: 0.7646  loss_offset: 0.8947  time: 0.2673  data_time: 0.0259  lr: 0.0016968  max_mem: 6513M
[12/10 22:08:54 d2.utils.events]:  eta: 0:28:46  iter: 3519  total_loss: 2.557  loss_sem_seg: 1.145  loss_center: 0.5602  loss_offset: 0.8552  time: 0.2673  data_time: 0.0245  lr: 0.0016921  max_mem: 6513M
[12/10 22:08:59 d2.utils.events]:  eta: 0:28:41  iter: 3539  total_loss: 2.557  loss_sem_seg: 1.225  loss_center: 0.6907  loss_offset: 0.7431  time: 0.2673  data_time: 0.0226  lr: 0.0016874  max_mem: 6513M
[12/10 22:09:05 d2.utils.events]:  eta: 0:28:36  iter: 3559  total_loss: 2.889  loss_sem_seg: 1.312  loss_center: 0.5572  loss_offset: 0.7973  time: 0.2673  data_time: 0.0243  lr: 0.0016827  max_mem: 6513M
[12/10 22:09:10 d2.utils.events]:  eta: 0:28:30  iter: 3579  total_loss: 2.422  loss_sem_seg: 1.109  loss_center: 0.5618  loss_offset: 0.7528  time: 0.2674  data_time: 0.0250  lr: 0.001678  max_mem: 6513M
[12/10 22:09:15 d2.utils.events]:  eta: 0:28:25  iter: 3599  total_loss: 2.951  loss_sem_seg: 1.304  loss_center: 0.7003  loss_offset: 0.7735  time: 0.2674  data_time: 0.0232  lr: 0.0016733  max_mem: 6513M
[12/10 22:09:21 d2.utils.events]:  eta: 0:28:19  iter: 3619  total_loss: 2.258  loss_sem_seg: 1.033  loss_center: 0.4309  loss_offset: 0.7219  time: 0.2674  data_time: 0.0235  lr: 0.0016686  max_mem: 6513M
[12/10 22:09:26 d2.utils.events]:  eta: 0:28:14  iter: 3639  total_loss: 2.558  loss_sem_seg: 1.112  loss_center: 0.5632  loss_offset: 0.8336  time: 0.2674  data_time: 0.0249  lr: 0.0016638  max_mem: 6513M
[12/10 22:09:32 d2.utils.events]:  eta: 0:28:09  iter: 3659  total_loss: 2.507  loss_sem_seg: 1.189  loss_center: 0.4474  loss_offset: 0.7534  time: 0.2674  data_time: 0.0247  lr: 0.0016591  max_mem: 6513M
[12/10 22:09:37 d2.utils.events]:  eta: 0:28:04  iter: 3679  total_loss: 2.826  loss_sem_seg: 1.26  loss_center: 0.6726  loss_offset: 0.7877  time: 0.2674  data_time: 0.0258  lr: 0.0016544  max_mem: 6513M
[12/10 22:09:42 d2.utils.events]:  eta: 0:27:59  iter: 3699  total_loss: 2.692  loss_sem_seg: 1.134  loss_center: 0.6363  loss_offset: 0.7948  time: 0.2674  data_time: 0.0243  lr: 0.0016497  max_mem: 6513M
[12/10 22:09:48 d2.utils.events]:  eta: 0:27:54  iter: 3719  total_loss: 2.605  loss_sem_seg: 1.031  loss_center: 0.6182  loss_offset: 0.8084  time: 0.2674  data_time: 0.0250  lr: 0.001645  max_mem: 6513M
[12/10 22:09:53 d2.utils.events]:  eta: 0:27:48  iter: 3739  total_loss: 2.542  loss_sem_seg: 1.147  loss_center: 0.5787  loss_offset: 0.8016  time: 0.2674  data_time: 0.0224  lr: 0.0016403  max_mem: 6513M
[12/10 22:09:58 d2.utils.events]:  eta: 0:27:44  iter: 3759  total_loss: 2.663  loss_sem_seg: 1.176  loss_center: 0.6183  loss_offset: 0.7733  time: 0.2674  data_time: 0.0240  lr: 0.0016356  max_mem: 6513M
[12/10 22:10:04 d2.utils.events]:  eta: 0:27:39  iter: 3779  total_loss: 2.564  loss_sem_seg: 1.104  loss_center: 0.5929  loss_offset: 0.7628  time: 0.2674  data_time: 0.0249  lr: 0.0016309  max_mem: 6513M
[12/10 22:10:09 d2.utils.events]:  eta: 0:27:32  iter: 3799  total_loss: 2.627  loss_sem_seg: 1.214  loss_center: 0.6988  loss_offset: 0.8208  time: 0.2674  data_time: 0.0224  lr: 0.0016261  max_mem: 6513M
[12/10 22:10:14 d2.utils.events]:  eta: 0:27:28  iter: 3819  total_loss: 2.643  loss_sem_seg: 1.244  loss_center: 0.6484  loss_offset: 0.7388  time: 0.2674  data_time: 0.0234  lr: 0.0016214  max_mem: 6513M
[12/10 22:10:20 d2.utils.events]:  eta: 0:27:23  iter: 3839  total_loss: 2.523  loss_sem_seg: 1.146  loss_center: 0.4641  loss_offset: 0.8243  time: 0.2674  data_time: 0.0245  lr: 0.0016167  max_mem: 6513M
[12/10 22:10:25 d2.utils.events]:  eta: 0:27:18  iter: 3859  total_loss: 3.07  loss_sem_seg: 1.272  loss_center: 0.749  loss_offset: 0.9021  time: 0.2674  data_time: 0.0238  lr: 0.001612  max_mem: 6513M
[12/10 22:10:30 d2.utils.events]:  eta: 0:27:13  iter: 3879  total_loss: 2.693  loss_sem_seg: 1.236  loss_center: 0.6371  loss_offset: 0.7404  time: 0.2674  data_time: 0.0238  lr: 0.0016072  max_mem: 6513M
[12/10 22:10:36 d2.utils.events]:  eta: 0:27:08  iter: 3899  total_loss: 2.702  loss_sem_seg: 1.181  loss_center: 0.668  loss_offset: 0.8602  time: 0.2674  data_time: 0.0233  lr: 0.0016025  max_mem: 6513M
[12/10 22:10:41 d2.utils.events]:  eta: 0:27:02  iter: 3919  total_loss: 2.698  loss_sem_seg: 1.21  loss_center: 0.4755  loss_offset: 0.7809  time: 0.2674  data_time: 0.0239  lr: 0.0015978  max_mem: 6513M
[12/10 22:10:46 d2.utils.events]:  eta: 0:26:57  iter: 3939  total_loss: 2.573  loss_sem_seg: 0.9684  loss_center: 0.6354  loss_offset: 0.8459  time: 0.2674  data_time: 0.0242  lr: 0.0015931  max_mem: 6513M
[12/10 22:10:52 d2.utils.events]:  eta: 0:26:52  iter: 3959  total_loss: 2.739  loss_sem_seg: 1.175  loss_center: 0.6477  loss_offset: 0.8971  time: 0.2673  data_time: 0.0235  lr: 0.0015883  max_mem: 6513M
[12/10 22:10:57 d2.utils.events]:  eta: 0:26:47  iter: 3979  total_loss: 2.715  loss_sem_seg: 1.156  loss_center: 0.6045  loss_offset: 0.8112  time: 0.2674  data_time: 0.0252  lr: 0.0015836  max_mem: 6513M
[12/10 22:11:03 d2.utils.events]:  eta: 0:26:42  iter: 3999  total_loss: 2.303  loss_sem_seg: 0.9672  loss_center: 0.5322  loss_offset: 0.6962  time: 0.2674  data_time: 0.0241  lr: 0.0015789  max_mem: 6513M
[12/10 22:11:08 d2.utils.events]:  eta: 0:26:36  iter: 4019  total_loss: 2.545  loss_sem_seg: 1.138  loss_center: 0.5183  loss_offset: 0.7405  time: 0.2674  data_time: 0.0232  lr: 0.0015741  max_mem: 6513M
[12/10 22:11:13 d2.utils.events]:  eta: 0:26:31  iter: 4039  total_loss: 2.673  loss_sem_seg: 1.09  loss_center: 0.5239  loss_offset: 0.8094  time: 0.2673  data_time: 0.0239  lr: 0.0015694  max_mem: 6513M
[12/10 22:11:19 d2.utils.events]:  eta: 0:26:26  iter: 4059  total_loss: 2.528  loss_sem_seg: 0.9774  loss_center: 0.4982  loss_offset: 0.7922  time: 0.2673  data_time: 0.0238  lr: 0.0015646  max_mem: 6513M
[12/10 22:11:24 d2.utils.events]:  eta: 0:26:19  iter: 4079  total_loss: 2.566  loss_sem_seg: 1.066  loss_center: 0.7004  loss_offset: 0.7601  time: 0.2673  data_time: 0.0224  lr: 0.0015599  max_mem: 6513M
[12/10 22:11:29 d2.utils.events]:  eta: 0:26:13  iter: 4099  total_loss: 2.602  loss_sem_seg: 1.114  loss_center: 0.6655  loss_offset: 0.754  time: 0.2673  data_time: 0.0238  lr: 0.0015552  max_mem: 6513M
[12/10 22:11:35 d2.utils.events]:  eta: 0:26:07  iter: 4119  total_loss: 2.583  loss_sem_seg: 1.148  loss_center: 0.5211  loss_offset: 0.7705  time: 0.2673  data_time: 0.0238  lr: 0.0015504  max_mem: 6513M
[12/10 22:11:40 d2.utils.events]:  eta: 0:26:02  iter: 4139  total_loss: 2.707  loss_sem_seg: 1.205  loss_center: 0.7005  loss_offset: 0.6986  time: 0.2673  data_time: 0.0240  lr: 0.0015457  max_mem: 6513M
[12/10 22:11:45 d2.utils.events]:  eta: 0:25:57  iter: 4159  total_loss: 2.565  loss_sem_seg: 1.165  loss_center: 0.467  loss_offset: 0.875  time: 0.2673  data_time: 0.0240  lr: 0.0015409  max_mem: 6513M
[12/10 22:11:51 d2.utils.events]:  eta: 0:25:52  iter: 4179  total_loss: 2.36  loss_sem_seg: 1.1  loss_center: 0.475  loss_offset: 0.9206  time: 0.2673  data_time: 0.0244  lr: 0.0015362  max_mem: 6513M
[12/10 22:11:56 d2.utils.events]:  eta: 0:25:47  iter: 4199  total_loss: 2.52  loss_sem_seg: 1.074  loss_center: 0.6016  loss_offset: 0.8272  time: 0.2673  data_time: 0.0239  lr: 0.0015314  max_mem: 6513M
[12/10 22:12:01 d2.utils.events]:  eta: 0:25:41  iter: 4219  total_loss: 2.494  loss_sem_seg: 1.15  loss_center: 0.5654  loss_offset: 0.8436  time: 0.2673  data_time: 0.0224  lr: 0.0015267  max_mem: 6513M
[12/10 22:12:07 d2.utils.events]:  eta: 0:25:37  iter: 4239  total_loss: 2.313  loss_sem_seg: 1.016  loss_center: 0.612  loss_offset: 0.7244  time: 0.2673  data_time: 0.0230  lr: 0.0015219  max_mem: 6513M
[12/10 22:12:12 d2.utils.events]:  eta: 0:25:31  iter: 4259  total_loss: 2.725  loss_sem_seg: 1.056  loss_center: 0.5963  loss_offset: 0.8592  time: 0.2673  data_time: 0.0228  lr: 0.0015172  max_mem: 6513M
[12/10 22:12:17 d2.utils.events]:  eta: 0:25:26  iter: 4279  total_loss: 2.741  loss_sem_seg: 1.112  loss_center: 0.7017  loss_offset: 0.8207  time: 0.2673  data_time: 0.0232  lr: 0.0015124  max_mem: 6513M
[12/10 22:12:23 d2.utils.events]:  eta: 0:25:21  iter: 4299  total_loss: 2.605  loss_sem_seg: 1.181  loss_center: 0.6513  loss_offset: 0.7066  time: 0.2673  data_time: 0.0243  lr: 0.0015076  max_mem: 6513M
[12/10 22:12:28 d2.utils.events]:  eta: 0:25:15  iter: 4319  total_loss: 2.49  loss_sem_seg: 1.088  loss_center: 0.593  loss_offset: 0.6104  time: 0.2673  data_time: 0.0233  lr: 0.0015029  max_mem: 6513M
[12/10 22:12:33 d2.utils.events]:  eta: 0:25:10  iter: 4339  total_loss: 2.561  loss_sem_seg: 1.103  loss_center: 0.563  loss_offset: 0.7766  time: 0.2673  data_time: 0.0253  lr: 0.0014981  max_mem: 6513M
[12/10 22:12:39 d2.utils.events]:  eta: 0:25:04  iter: 4359  total_loss: 2.353  loss_sem_seg: 1.006  loss_center: 0.5934  loss_offset: 0.6647  time: 0.2673  data_time: 0.0230  lr: 0.0014933  max_mem: 6513M
[12/10 22:12:44 d2.utils.events]:  eta: 0:24:59  iter: 4379  total_loss: 2.282  loss_sem_seg: 0.9963  loss_center: 0.617  loss_offset: 0.609  time: 0.2673  data_time: 0.0244  lr: 0.0014886  max_mem: 6513M
[12/10 22:12:50 d2.utils.events]:  eta: 0:24:54  iter: 4399  total_loss: 2.431  loss_sem_seg: 1.064  loss_center: 0.4945  loss_offset: 0.8749  time: 0.2673  data_time: 0.0238  lr: 0.0014838  max_mem: 6513M
[12/10 22:12:55 d2.utils.events]:  eta: 0:24:49  iter: 4419  total_loss: 2.426  loss_sem_seg: 1.031  loss_center: 0.4525  loss_offset: 0.775  time: 0.2673  data_time: 0.0242  lr: 0.001479  max_mem: 6513M
[12/10 22:13:00 d2.utils.events]:  eta: 0:24:44  iter: 4439  total_loss: 2.59  loss_sem_seg: 1.076  loss_center: 0.6103  loss_offset: 0.7416  time: 0.2673  data_time: 0.0237  lr: 0.0014743  max_mem: 6513M
[12/10 22:13:06 d2.utils.events]:  eta: 0:24:39  iter: 4459  total_loss: 2.774  loss_sem_seg: 1.164  loss_center: 0.8136  loss_offset: 0.8726  time: 0.2673  data_time: 0.0228  lr: 0.0014695  max_mem: 6513M
[12/10 22:13:11 d2.utils.events]:  eta: 0:24:34  iter: 4479  total_loss: 2.377  loss_sem_seg: 1.035  loss_center: 0.6432  loss_offset: 0.7478  time: 0.2673  data_time: 0.0233  lr: 0.0014647  max_mem: 6513M
[12/10 22:13:16 d2.utils.events]:  eta: 0:24:28  iter: 4499  total_loss: 2.388  loss_sem_seg: 0.9997  loss_center: 0.5473  loss_offset: 0.7639  time: 0.2673  data_time: 0.0236  lr: 0.0014599  max_mem: 6513M
[12/10 22:13:22 d2.utils.events]:  eta: 0:24:23  iter: 4519  total_loss: 2.322  loss_sem_seg: 1.013  loss_center: 0.5724  loss_offset: 0.7601  time: 0.2673  data_time: 0.0243  lr: 0.0014552  max_mem: 6513M
[12/10 22:13:27 d2.utils.events]:  eta: 0:24:17  iter: 4539  total_loss: 2.316  loss_sem_seg: 0.9944  loss_center: 0.5599  loss_offset: 0.7256  time: 0.2673  data_time: 0.0229  lr: 0.0014504  max_mem: 6513M
[12/10 22:13:32 d2.utils.events]:  eta: 0:24:12  iter: 4559  total_loss: 2.662  loss_sem_seg: 1.097  loss_center: 0.614  loss_offset: 0.7787  time: 0.2673  data_time: 0.0241  lr: 0.0014456  max_mem: 6513M
[12/10 22:13:38 d2.utils.events]:  eta: 0:24:07  iter: 4579  total_loss: 2.513  loss_sem_seg: 0.9995  loss_center: 0.6984  loss_offset: 0.6979  time: 0.2673  data_time: 0.0254  lr: 0.0014408  max_mem: 6513M
[12/10 22:13:43 d2.utils.events]:  eta: 0:24:02  iter: 4599  total_loss: 2.5  loss_sem_seg: 1.125  loss_center: 0.5312  loss_offset: 0.7086  time: 0.2674  data_time: 0.0244  lr: 0.001436  max_mem: 6513M
[12/10 22:13:49 d2.utils.events]:  eta: 0:23:57  iter: 4619  total_loss: 2.94  loss_sem_seg: 1.14  loss_center: 0.7376  loss_offset: 0.7887  time: 0.2674  data_time: 0.0259  lr: 0.0014313  max_mem: 6513M
[12/10 22:13:54 d2.utils.events]:  eta: 0:23:51  iter: 4639  total_loss: 2.115  loss_sem_seg: 0.8548  loss_center: 0.5687  loss_offset: 0.7111  time: 0.2673  data_time: 0.0225  lr: 0.0014265  max_mem: 6513M
[12/10 22:13:59 d2.utils.events]:  eta: 0:23:45  iter: 4659  total_loss: 2.266  loss_sem_seg: 0.8832  loss_center: 0.6799  loss_offset: 0.5986  time: 0.2673  data_time: 0.0235  lr: 0.0014217  max_mem: 6513M
[12/10 22:14:05 d2.utils.events]:  eta: 0:23:40  iter: 4679  total_loss: 2.374  loss_sem_seg: 1.05  loss_center: 0.6355  loss_offset: 0.8101  time: 0.2673  data_time: 0.0250  lr: 0.0014169  max_mem: 6513M
[12/10 22:14:10 d2.utils.events]:  eta: 0:23:35  iter: 4699  total_loss: 2.634  loss_sem_seg: 1.002  loss_center: 0.5614  loss_offset: 0.8176  time: 0.2673  data_time: 0.0230  lr: 0.0014121  max_mem: 6513M
[12/10 22:14:15 d2.utils.events]:  eta: 0:23:29  iter: 4719  total_loss: 2.44  loss_sem_seg: 1.145  loss_center: 0.5998  loss_offset: 0.6553  time: 0.2673  data_time: 0.0238  lr: 0.0014073  max_mem: 6513M
[12/10 22:14:21 d2.utils.events]:  eta: 0:23:25  iter: 4739  total_loss: 2.534  loss_sem_seg: 1.052  loss_center: 0.8047  loss_offset: 0.7975  time: 0.2674  data_time: 0.0254  lr: 0.0014025  max_mem: 6513M
[12/10 22:14:26 d2.utils.events]:  eta: 0:23:20  iter: 4759  total_loss: 2.422  loss_sem_seg: 0.8847  loss_center: 0.639  loss_offset: 0.6777  time: 0.2674  data_time: 0.0241  lr: 0.0013977  max_mem: 6513M
[12/10 22:14:31 d2.utils.events]:  eta: 0:23:15  iter: 4779  total_loss: 2.524  loss_sem_seg: 1.098  loss_center: 0.5504  loss_offset: 0.8763  time: 0.2674  data_time: 0.0242  lr: 0.0013929  max_mem: 6513M
[12/10 22:14:37 d2.utils.events]:  eta: 0:23:10  iter: 4799  total_loss: 2.59  loss_sem_seg: 1.027  loss_center: 0.587  loss_offset: 0.7649  time: 0.2674  data_time: 0.0241  lr: 0.0013881  max_mem: 6513M
[12/10 22:14:42 d2.utils.events]:  eta: 0:23:05  iter: 4819  total_loss: 2.655  loss_sem_seg: 1.01  loss_center: 0.6597  loss_offset: 0.7824  time: 0.2674  data_time: 0.0229  lr: 0.0013833  max_mem: 6513M
[12/10 22:14:47 d2.utils.events]:  eta: 0:22:59  iter: 4839  total_loss: 2.393  loss_sem_seg: 1.049  loss_center: 0.6147  loss_offset: 0.7232  time: 0.2674  data_time: 0.0232  lr: 0.0013785  max_mem: 6513M
[12/10 22:14:53 d2.utils.events]:  eta: 0:22:54  iter: 4859  total_loss: 2.401  loss_sem_seg: 0.9354  loss_center: 0.6538  loss_offset: 0.7387  time: 0.2674  data_time: 0.0244  lr: 0.0013737  max_mem: 6513M
[12/10 22:14:58 d2.utils.events]:  eta: 0:22:48  iter: 4879  total_loss: 2.405  loss_sem_seg: 1.124  loss_center: 0.6075  loss_offset: 0.653  time: 0.2674  data_time: 0.0255  lr: 0.0013689  max_mem: 6513M
[12/10 22:15:03 d2.utils.events]:  eta: 0:22:42  iter: 4899  total_loss: 2.47  loss_sem_seg: 1.142  loss_center: 0.5831  loss_offset: 0.7915  time: 0.2674  data_time: 0.0239  lr: 0.001364  max_mem: 6513M
[12/10 22:15:09 d2.utils.events]:  eta: 0:22:37  iter: 4919  total_loss: 2.88  loss_sem_seg: 1.215  loss_center: 0.5557  loss_offset: 0.8947  time: 0.2674  data_time: 0.0243  lr: 0.0013592  max_mem: 6513M
[12/10 22:15:14 d2.utils.events]:  eta: 0:22:32  iter: 4939  total_loss: 2.51  loss_sem_seg: 1.086  loss_center: 0.6892  loss_offset: 0.6726  time: 0.2674  data_time: 0.0246  lr: 0.0013544  max_mem: 6513M
[12/10 22:15:20 d2.utils.events]:  eta: 0:22:26  iter: 4959  total_loss: 2.472  loss_sem_seg: 1.103  loss_center: 0.5414  loss_offset: 0.7556  time: 0.2674  data_time: 0.0238  lr: 0.0013496  max_mem: 6513M
[12/10 22:15:25 d2.utils.events]:  eta: 0:22:20  iter: 4979  total_loss: 2.491  loss_sem_seg: 1.127  loss_center: 0.6824  loss_offset: 0.7195  time: 0.2674  data_time: 0.0241  lr: 0.0013448  max_mem: 6513M
[12/10 22:15:30 fvcore.common.checkpoint]: Saving checkpoint to ./output/model_0004999.pth
[12/10 22:15:31 d2.utils.events]:  eta: 0:22:15  iter: 4999  total_loss: 2.416  loss_sem_seg: 1.103  loss_center: 0.5825  loss_offset: 0.7641  time: 0.2674  data_time: 0.0243  lr: 0.00134  max_mem: 6513M
[12/10 22:15:36 d2.utils.events]:  eta: 0:22:10  iter: 5019  total_loss: 2.444  loss_sem_seg: 1.172  loss_center: 0.5656  loss_offset: 0.7271  time: 0.2674  data_time: 0.0252  lr: 0.0013351  max_mem: 6513M
[12/10 22:15:41 d2.utils.events]:  eta: 0:22:05  iter: 5039  total_loss: 2.545  loss_sem_seg: 1.052  loss_center: 0.5829  loss_offset: 0.8968  time: 0.2674  data_time: 0.0246  lr: 0.0013303  max_mem: 6513M
[12/10 22:15:47 d2.utils.events]:  eta: 0:21:59  iter: 5059  total_loss: 2.704  loss_sem_seg: 0.9777  loss_center: 0.7669  loss_offset: 0.7938  time: 0.2674  data_time: 0.0249  lr: 0.0013255  max_mem: 6513M
[12/10 22:15:52 d2.utils.events]:  eta: 0:21:56  iter: 5079  total_loss: 2.597  loss_sem_seg: 1.167  loss_center: 0.4834  loss_offset: 0.7635  time: 0.2674  data_time: 0.0247  lr: 0.0013207  max_mem: 6513M
[12/10 22:15:57 d2.utils.events]:  eta: 0:21:50  iter: 5099  total_loss: 2.377  loss_sem_seg: 1.01  loss_center: 0.7159  loss_offset: 0.7093  time: 0.2674  data_time: 0.0238  lr: 0.0013158  max_mem: 6513M
[12/10 22:16:03 d2.utils.events]:  eta: 0:21:45  iter: 5119  total_loss: 2.381  loss_sem_seg: 1.068  loss_center: 0.5019  loss_offset: 0.8446  time: 0.2674  data_time: 0.0258  lr: 0.001311  max_mem: 6513M
[12/10 22:16:08 d2.utils.events]:  eta: 0:21:40  iter: 5139  total_loss: 2.445  loss_sem_seg: 0.9226  loss_center: 0.7623  loss_offset: 0.7676  time: 0.2674  data_time: 0.0244  lr: 0.0013062  max_mem: 6513M
[12/10 22:16:14 d2.utils.events]:  eta: 0:21:35  iter: 5159  total_loss: 2.388  loss_sem_seg: 0.8816  loss_center: 0.6442  loss_offset: 0.719  time: 0.2674  data_time: 0.0229  lr: 0.0013013  max_mem: 6513M
[12/10 22:16:19 d2.utils.events]:  eta: 0:21:29  iter: 5179  total_loss: 2.229  loss_sem_seg: 0.9119  loss_center: 0.5016  loss_offset: 0.7508  time: 0.2674  data_time: 0.0241  lr: 0.0012965  max_mem: 6513M
[12/10 22:16:24 d2.utils.events]:  eta: 0:21:24  iter: 5199  total_loss: 2.333  loss_sem_seg: 1.02  loss_center: 0.6412  loss_offset: 0.7363  time: 0.2674  data_time: 0.0243  lr: 0.0012916  max_mem: 6513M
[12/10 22:16:30 d2.utils.events]:  eta: 0:21:19  iter: 5219  total_loss: 2.402  loss_sem_seg: 0.9968  loss_center: 0.5294  loss_offset: 0.7372  time: 0.2674  data_time: 0.0255  lr: 0.0012868  max_mem: 6513M
[12/10 22:16:35 d2.utils.events]:  eta: 0:21:14  iter: 5239  total_loss: 2.446  loss_sem_seg: 1.118  loss_center: 0.6373  loss_offset: 0.7948  time: 0.2674  data_time: 0.0233  lr: 0.0012819  max_mem: 6513M
[12/10 22:16:41 d2.utils.events]:  eta: 0:21:08  iter: 5259  total_loss: 2.499  loss_sem_seg: 1.111  loss_center: 0.5755  loss_offset: 0.7807  time: 0.2674  data_time: 0.0240  lr: 0.0012771  max_mem: 6513M
[12/10 22:16:46 d2.utils.events]:  eta: 0:21:03  iter: 5279  total_loss: 2.559  loss_sem_seg: 0.896  loss_center: 0.8082  loss_offset: 0.7672  time: 0.2674  data_time: 0.0259  lr: 0.0012722  max_mem: 6513M
[12/10 22:16:51 d2.utils.events]:  eta: 0:20:57  iter: 5299  total_loss: 2.35  loss_sem_seg: 1.001  loss_center: 0.5912  loss_offset: 0.7101  time: 0.2674  data_time: 0.0235  lr: 0.0012674  max_mem: 6513M
[12/10 22:16:57 d2.utils.events]:  eta: 0:20:52  iter: 5319  total_loss: 2.56  loss_sem_seg: 1.039  loss_center: 0.5612  loss_offset: 0.7332  time: 0.2674  data_time: 0.0253  lr: 0.0012625  max_mem: 6513M
[12/10 22:17:02 d2.utils.events]:  eta: 0:20:45  iter: 5339  total_loss: 2.406  loss_sem_seg: 1.033  loss_center: 0.5516  loss_offset: 0.7269  time: 0.2674  data_time: 0.0251  lr: 0.0012577  max_mem: 6513M
[12/10 22:17:07 d2.utils.events]:  eta: 0:20:41  iter: 5359  total_loss: 2.351  loss_sem_seg: 0.8987  loss_center: 0.5025  loss_offset: 0.7692  time: 0.2674  data_time: 0.0248  lr: 0.0012528  max_mem: 6513M
[12/10 22:17:13 d2.utils.events]:  eta: 0:20:34  iter: 5379  total_loss: 2.309  loss_sem_seg: 1.015  loss_center: 0.6053  loss_offset: 0.6925  time: 0.2675  data_time: 0.0250  lr: 0.001248  max_mem: 6513M
[12/10 22:17:18 d2.utils.events]:  eta: 0:20:29  iter: 5399  total_loss: 2.467  loss_sem_seg: 1.117  loss_center: 0.6374  loss_offset: 0.699  time: 0.2675  data_time: 0.0231  lr: 0.0012431  max_mem: 6513M
[12/10 22:17:24 d2.utils.events]:  eta: 0:20:23  iter: 5419  total_loss: 2.444  loss_sem_seg: 1.015  loss_center: 0.6037  loss_offset: 0.7752  time: 0.2674  data_time: 0.0228  lr: 0.0012382  max_mem: 6513M
[12/10 22:17:29 d2.utils.events]:  eta: 0:20:17  iter: 5439  total_loss: 2.271  loss_sem_seg: 0.9755  loss_center: 0.5762  loss_offset: 0.7392  time: 0.2675  data_time: 0.0233  lr: 0.0012334  max_mem: 6513M
[12/10 22:17:34 d2.utils.events]:  eta: 0:20:12  iter: 5459  total_loss: 2.538  loss_sem_seg: 1.066  loss_center: 0.6186  loss_offset: 0.8652  time: 0.2675  data_time: 0.0237  lr: 0.0012285  max_mem: 6513M
[12/10 22:17:40 d2.utils.events]:  eta: 0:20:08  iter: 5479  total_loss: 2.415  loss_sem_seg: 0.9594  loss_center: 0.5604  loss_offset: 0.6805  time: 0.2675  data_time: 0.0244  lr: 0.0012236  max_mem: 6513M
[12/10 22:17:45 d2.utils.events]:  eta: 0:20:02  iter: 5499  total_loss: 2.293  loss_sem_seg: 1.01  loss_center: 0.657  loss_offset: 0.6787  time: 0.2675  data_time: 0.0241  lr: 0.0012188  max_mem: 6513M
[12/10 22:17:50 d2.utils.events]:  eta: 0:19:58  iter: 5519  total_loss: 2.265  loss_sem_seg: 0.962  loss_center: 0.54  loss_offset: 0.7919  time: 0.2675  data_time: 0.0266  lr: 0.0012139  max_mem: 6513M
[12/10 22:17:56 d2.utils.events]:  eta: 0:19:53  iter: 5539  total_loss: 2.526  loss_sem_seg: 1.029  loss_center: 0.6356  loss_offset: 0.8712  time: 0.2675  data_time: 0.0240  lr: 0.001209  max_mem: 6513M
[12/10 22:18:01 d2.utils.events]:  eta: 0:19:46  iter: 5559  total_loss: 2.615  loss_sem_seg: 1.091  loss_center: 0.6343  loss_offset: 0.7099  time: 0.2675  data_time: 0.0237  lr: 0.0012041  max_mem: 6513M
[12/10 22:18:07 d2.utils.events]:  eta: 0:19:40  iter: 5579  total_loss: 2.364  loss_sem_seg: 1.044  loss_center: 0.6951  loss_offset: 0.6363  time: 0.2675  data_time: 0.0239  lr: 0.0011992  max_mem: 6513M
[12/10 22:18:12 d2.utils.events]:  eta: 0:19:34  iter: 5599  total_loss: 2.464  loss_sem_seg: 0.9816  loss_center: 0.6205  loss_offset: 0.7832  time: 0.2675  data_time: 0.0230  lr: 0.0011944  max_mem: 6513M
[12/10 22:18:17 d2.utils.events]:  eta: 0:19:29  iter: 5619  total_loss: 2.463  loss_sem_seg: 1.126  loss_center: 0.4797  loss_offset: 0.7066  time: 0.2675  data_time: 0.0249  lr: 0.0011895  max_mem: 6513M
[12/10 22:18:23 d2.utils.events]:  eta: 0:19:24  iter: 5639  total_loss: 2.645  loss_sem_seg: 1.004  loss_center: 0.6138  loss_offset: 0.7476  time: 0.2675  data_time: 0.0266  lr: 0.0011846  max_mem: 6513M
[12/10 22:18:28 d2.utils.events]:  eta: 0:19:19  iter: 5659  total_loss: 2.105  loss_sem_seg: 0.9786  loss_center: 0.439  loss_offset: 0.7589  time: 0.2675  data_time: 0.0253  lr: 0.0011797  max_mem: 6513M
[12/10 22:18:33 d2.utils.events]:  eta: 0:19:14  iter: 5679  total_loss: 2.586  loss_sem_seg: 1.251  loss_center: 0.5418  loss_offset: 0.8023  time: 0.2675  data_time: 0.0236  lr: 0.0011748  max_mem: 6513M
[12/10 22:18:39 d2.utils.events]:  eta: 0:19:08  iter: 5699  total_loss: 2.522  loss_sem_seg: 1.144  loss_center: 0.542  loss_offset: 0.8135  time: 0.2675  data_time: 0.0239  lr: 0.0011699  max_mem: 6513M
[12/10 22:18:44 d2.utils.events]:  eta: 0:19:03  iter: 5719  total_loss: 2.391  loss_sem_seg: 0.9999  loss_center: 0.5899  loss_offset: 0.6744  time: 0.2675  data_time: 0.0237  lr: 0.001165  max_mem: 6513M
[12/10 22:18:49 d2.utils.events]:  eta: 0:18:57  iter: 5739  total_loss: 2.26  loss_sem_seg: 0.9449  loss_center: 0.5436  loss_offset: 0.7343  time: 0.2675  data_time: 0.0243  lr: 0.0011601  max_mem: 6513M
[12/10 22:18:55 d2.utils.events]:  eta: 0:18:52  iter: 5759  total_loss: 2.254  loss_sem_seg: 0.9879  loss_center: 0.5527  loss_offset: 0.6906  time: 0.2675  data_time: 0.0239  lr: 0.0011552  max_mem: 6513M
[12/10 22:19:00 d2.utils.events]:  eta: 0:18:46  iter: 5779  total_loss: 2.607  loss_sem_seg: 1.107  loss_center: 0.5679  loss_offset: 0.7859  time: 0.2675  data_time: 0.0243  lr: 0.0011503  max_mem: 6513M
[12/10 22:19:06 d2.utils.events]:  eta: 0:18:41  iter: 5799  total_loss: 2.585  loss_sem_seg: 1.096  loss_center: 0.6682  loss_offset: 0.7284  time: 0.2675  data_time: 0.0269  lr: 0.0011454  max_mem: 6513M
[12/10 22:19:11 d2.utils.events]:  eta: 0:18:35  iter: 5819  total_loss: 2.56  loss_sem_seg: 1.174  loss_center: 0.5356  loss_offset: 0.8681  time: 0.2675  data_time: 0.0257  lr: 0.0011405  max_mem: 6513M
[12/10 22:19:16 d2.utils.events]:  eta: 0:18:30  iter: 5839  total_loss: 2.351  loss_sem_seg: 1.05  loss_center: 0.5157  loss_offset: 0.7177  time: 0.2675  data_time: 0.0237  lr: 0.0011356  max_mem: 6513M
[12/10 22:19:22 d2.utils.events]:  eta: 0:18:24  iter: 5859  total_loss: 2.386  loss_sem_seg: 0.937  loss_center: 0.6807  loss_offset: 0.7095  time: 0.2675  data_time: 0.0257  lr: 0.0011307  max_mem: 6513M
[12/10 22:19:27 d2.utils.events]:  eta: 0:18:19  iter: 5879  total_loss: 2.41  loss_sem_seg: 0.8691  loss_center: 0.617  loss_offset: 0.7022  time: 0.2675  data_time: 0.0251  lr: 0.0011258  max_mem: 6513M
[12/10 22:19:33 d2.utils.events]:  eta: 0:18:14  iter: 5899  total_loss: 2.33  loss_sem_seg: 0.8301  loss_center: 0.578  loss_offset: 0.78  time: 0.2675  data_time: 0.0239  lr: 0.0011208  max_mem: 6513M
[12/10 22:19:38 d2.utils.events]:  eta: 0:18:08  iter: 5919  total_loss: 2.551  loss_sem_seg: 1.017  loss_center: 0.6483  loss_offset: 0.8047  time: 0.2675  data_time: 0.0244  lr: 0.0011159  max_mem: 6513M
[12/10 22:19:43 d2.utils.events]:  eta: 0:18:02  iter: 5939  total_loss: 2.683  loss_sem_seg: 1.169  loss_center: 0.6137  loss_offset: 0.7909  time: 0.2675  data_time: 0.0235  lr: 0.001111  max_mem: 6513M
[12/10 22:19:49 d2.utils.events]:  eta: 0:17:57  iter: 5959  total_loss: 2.49  loss_sem_seg: 0.9286  loss_center: 0.6545  loss_offset: 0.7696  time: 0.2675  data_time: 0.0234  lr: 0.0011061  max_mem: 6513M
[12/10 22:19:54 d2.utils.events]:  eta: 0:17:52  iter: 5979  total_loss: 2.371  loss_sem_seg: 0.9373  loss_center: 0.58  loss_offset: 0.7842  time: 0.2675  data_time: 0.0246  lr: 0.0011011  max_mem: 6513M
[12/10 22:19:59 d2.utils.events]:  eta: 0:17:46  iter: 5999  total_loss: 2.594  loss_sem_seg: 1.096  loss_center: 0.6461  loss_offset: 0.7694  time: 0.2675  data_time: 0.0242  lr: 0.0010962  max_mem: 6513M
[12/10 22:20:05 d2.utils.events]:  eta: 0:17:41  iter: 6019  total_loss: 2.376  loss_sem_seg: 0.9873  loss_center: 0.6528  loss_offset: 0.7061  time: 0.2675  data_time: 0.0248  lr: 0.0010913  max_mem: 6513M
[12/10 22:20:10 d2.utils.events]:  eta: 0:17:36  iter: 6039  total_loss: 2.282  loss_sem_seg: 0.9333  loss_center: 0.5922  loss_offset: 0.6503  time: 0.2675  data_time: 0.0234  lr: 0.0010863  max_mem: 6513M
[12/10 22:20:15 d2.utils.events]:  eta: 0:17:31  iter: 6059  total_loss: 2.6  loss_sem_seg: 1.019  loss_center: 0.7466  loss_offset: 0.7332  time: 0.2675  data_time: 0.0260  lr: 0.0010814  max_mem: 6513M
[12/10 22:20:21 d2.utils.events]:  eta: 0:17:25  iter: 6079  total_loss: 2.15  loss_sem_seg: 0.9149  loss_center: 0.5477  loss_offset: 0.6145  time: 0.2675  data_time: 0.0250  lr: 0.0010765  max_mem: 6513M
[12/10 22:20:26 d2.utils.events]:  eta: 0:17:19  iter: 6099  total_loss: 2.687  loss_sem_seg: 1.074  loss_center: 0.6887  loss_offset: 0.7926  time: 0.2675  data_time: 0.0219  lr: 0.0010715  max_mem: 6513M
[12/10 22:20:31 d2.utils.events]:  eta: 0:17:13  iter: 6119  total_loss: 2.332  loss_sem_seg: 0.8635  loss_center: 0.5599  loss_offset: 0.7357  time: 0.2675  data_time: 0.0240  lr: 0.0010666  max_mem: 6513M
[12/10 22:20:37 d2.utils.events]:  eta: 0:17:07  iter: 6139  total_loss: 2.461  loss_sem_seg: 0.941  loss_center: 0.5576  loss_offset: 0.8124  time: 0.2675  data_time: 0.0245  lr: 0.0010616  max_mem: 6513M
[12/10 22:20:42 d2.utils.events]:  eta: 0:17:02  iter: 6159  total_loss: 2.314  loss_sem_seg: 0.926  loss_center: 0.5916  loss_offset: 0.7281  time: 0.2675  data_time: 0.0246  lr: 0.0010567  max_mem: 6513M
[12/10 22:20:48 d2.utils.events]:  eta: 0:16:57  iter: 6179  total_loss: 2.327  loss_sem_seg: 0.8973  loss_center: 0.5739  loss_offset: 0.7095  time: 0.2675  data_time: 0.0241  lr: 0.0010517  max_mem: 6513M
[12/10 22:20:53 d2.utils.events]:  eta: 0:16:51  iter: 6199  total_loss: 2.394  loss_sem_seg: 0.9965  loss_center: 0.569  loss_offset: 0.7717  time: 0.2675  data_time: 0.0238  lr: 0.0010468  max_mem: 6513M
[12/10 22:20:58 d2.utils.events]:  eta: 0:16:46  iter: 6219  total_loss: 2.41  loss_sem_seg: 0.9321  loss_center: 0.6594  loss_offset: 0.7682  time: 0.2675  data_time: 0.0261  lr: 0.0010418  max_mem: 6513M
[12/10 22:21:04 d2.utils.events]:  eta: 0:16:41  iter: 6239  total_loss: 2.494  loss_sem_seg: 1.044  loss_center: 0.6089  loss_offset: 0.8195  time: 0.2675  data_time: 0.0238  lr: 0.0010368  max_mem: 6513M
[12/10 22:21:09 d2.utils.events]:  eta: 0:16:36  iter: 6259  total_loss: 2.495  loss_sem_seg: 1.037  loss_center: 0.5487  loss_offset: 0.8466  time: 0.2675  data_time: 0.0260  lr: 0.0010319  max_mem: 6513M
[12/10 22:21:14 d2.utils.events]:  eta: 0:16:32  iter: 6279  total_loss: 2.498  loss_sem_seg: 1.008  loss_center: 0.6435  loss_offset: 0.8047  time: 0.2675  data_time: 0.0241  lr: 0.0010269  max_mem: 6513M
[12/10 22:21:20 d2.utils.events]:  eta: 0:16:27  iter: 6299  total_loss: 2.347  loss_sem_seg: 0.8702  loss_center: 0.4775  loss_offset: 0.7227  time: 0.2675  data_time: 0.0244  lr: 0.0010219  max_mem: 6513M
[12/10 22:21:25 d2.utils.events]:  eta: 0:16:20  iter: 6319  total_loss: 2.488  loss_sem_seg: 0.9254  loss_center: 0.6223  loss_offset: 0.7253  time: 0.2675  data_time: 0.0237  lr: 0.001017  max_mem: 6513M
[12/10 22:21:31 d2.utils.events]:  eta: 0:16:16  iter: 6339  total_loss: 2.291  loss_sem_seg: 0.9433  loss_center: 0.5765  loss_offset: 0.7523  time: 0.2675  data_time: 0.0245  lr: 0.001012  max_mem: 6513M
[12/10 22:21:36 d2.utils.events]:  eta: 0:16:09  iter: 6359  total_loss: 2.332  loss_sem_seg: 0.9474  loss_center: 0.5991  loss_offset: 0.6866  time: 0.2675  data_time: 0.0245  lr: 0.001007  max_mem: 6513M
[12/10 22:21:41 d2.utils.events]:  eta: 0:16:04  iter: 6379  total_loss: 2.483  loss_sem_seg: 0.9798  loss_center: 0.5687  loss_offset: 0.7636  time: 0.2675  data_time: 0.0228  lr: 0.001002  max_mem: 6513M
[12/10 22:21:47 d2.utils.events]:  eta: 0:15:58  iter: 6399  total_loss: 2.341  loss_sem_seg: 0.8963  loss_center: 0.6868  loss_offset: 0.7143  time: 0.2675  data_time: 0.0233  lr: 0.00099706  max_mem: 6513M
[12/10 22:21:52 d2.utils.events]:  eta: 0:15:53  iter: 6419  total_loss: 2.394  loss_sem_seg: 1.006  loss_center: 0.6918  loss_offset: 0.7949  time: 0.2675  data_time: 0.0242  lr: 0.00099207  max_mem: 6513M
[12/10 22:21:57 d2.utils.events]:  eta: 0:15:48  iter: 6439  total_loss: 2.504  loss_sem_seg: 1.023  loss_center: 0.6756  loss_offset: 0.7827  time: 0.2675  data_time: 0.0258  lr: 0.00098709  max_mem: 6513M
[12/10 22:22:03 d2.utils.events]:  eta: 0:15:43  iter: 6459  total_loss: 2.601  loss_sem_seg: 1.094  loss_center: 0.6952  loss_offset: 0.7167  time: 0.2675  data_time: 0.0257  lr: 0.00098209  max_mem: 6513M
[12/10 22:22:08 d2.utils.events]:  eta: 0:15:37  iter: 6479  total_loss: 2.709  loss_sem_seg: 1.108  loss_center: 0.698  loss_offset: 0.8465  time: 0.2675  data_time: 0.0237  lr: 0.0009771  max_mem: 6513M
[12/10 22:22:13 d2.utils.events]:  eta: 0:15:33  iter: 6499  total_loss: 2.503  loss_sem_seg: 1.218  loss_center: 0.5588  loss_offset: 0.7111  time: 0.2676  data_time: 0.0262  lr: 0.0009721  max_mem: 6513M
[12/10 22:22:19 d2.utils.events]:  eta: 0:15:27  iter: 6519  total_loss: 2.54  loss_sem_seg: 1.05  loss_center: 0.6265  loss_offset: 0.785  time: 0.2676  data_time: 0.0241  lr: 0.00096711  max_mem: 6513M
[12/10 22:22:24 d2.utils.events]:  eta: 0:15:23  iter: 6539  total_loss: 2.364  loss_sem_seg: 1.02  loss_center: 0.5138  loss_offset: 0.743  time: 0.2676  data_time: 0.0243  lr: 0.0009621  max_mem: 6513M
[12/10 22:22:30 d2.utils.events]:  eta: 0:15:17  iter: 6559  total_loss: 2.201  loss_sem_seg: 0.9738  loss_center: 0.6205  loss_offset: 0.7084  time: 0.2676  data_time: 0.0245  lr: 0.0009571  max_mem: 6513M
[12/10 22:22:35 d2.utils.events]:  eta: 0:15:12  iter: 6579  total_loss: 2.452  loss_sem_seg: 0.9431  loss_center: 0.6449  loss_offset: 0.7212  time: 0.2676  data_time: 0.0244  lr: 0.00095209  max_mem: 6513M
[12/10 22:22:40 d2.utils.events]:  eta: 0:15:08  iter: 6599  total_loss: 2.689  loss_sem_seg: 1.091  loss_center: 0.5586  loss_offset: 0.8074  time: 0.2676  data_time: 0.0247  lr: 0.00094708  max_mem: 6513M
[12/10 22:22:46 d2.utils.events]:  eta: 0:15:02  iter: 6619  total_loss: 2.277  loss_sem_seg: 1.017  loss_center: 0.5051  loss_offset: 0.8065  time: 0.2676  data_time: 0.0254  lr: 0.00094206  max_mem: 6513M
[12/10 22:22:51 d2.utils.events]:  eta: 0:14:57  iter: 6639  total_loss: 2.557  loss_sem_seg: 1.173  loss_center: 0.6368  loss_offset: 0.8041  time: 0.2676  data_time: 0.0267  lr: 0.00093705  max_mem: 6513M
[12/10 22:22:56 d2.utils.events]:  eta: 0:14:51  iter: 6659  total_loss: 2.431  loss_sem_seg: 0.9242  loss_center: 0.5937  loss_offset: 0.6928  time: 0.2676  data_time: 0.0238  lr: 0.00093203  max_mem: 6513M
[12/10 22:23:02 d2.utils.events]:  eta: 0:14:46  iter: 6679  total_loss: 2.526  loss_sem_seg: 1.06  loss_center: 0.8334  loss_offset: 0.6243  time: 0.2676  data_time: 0.0250  lr: 0.000927  max_mem: 6513M
[12/10 22:23:07 d2.utils.events]:  eta: 0:14:41  iter: 6699  total_loss: 2.4  loss_sem_seg: 0.9864  loss_center: 0.6246  loss_offset: 0.7209  time: 0.2676  data_time: 0.0227  lr: 0.00092198  max_mem: 6513M
[12/10 22:23:13 d2.utils.events]:  eta: 0:14:35  iter: 6719  total_loss: 2.353  loss_sem_seg: 0.9566  loss_center: 0.618  loss_offset: 0.722  time: 0.2676  data_time: 0.0242  lr: 0.00091695  max_mem: 6513M
[12/10 22:23:18 d2.utils.events]:  eta: 0:14:30  iter: 6739  total_loss: 2.185  loss_sem_seg: 0.9276  loss_center: 0.5972  loss_offset: 0.7273  time: 0.2676  data_time: 0.0280  lr: 0.00091192  max_mem: 6513M
[12/10 22:23:23 d2.utils.events]:  eta: 0:14:25  iter: 6759  total_loss: 2.736  loss_sem_seg: 1.133  loss_center: 0.6624  loss_offset: 0.7801  time: 0.2676  data_time: 0.0220  lr: 0.00090688  max_mem: 6513M
[12/10 22:23:29 d2.utils.events]:  eta: 0:14:20  iter: 6779  total_loss: 2.504  loss_sem_seg: 1.092  loss_center: 0.6704  loss_offset: 0.7024  time: 0.2676  data_time: 0.0237  lr: 0.00090184  max_mem: 6513M
[12/10 22:23:34 d2.utils.events]:  eta: 0:14:14  iter: 6799  total_loss: 2.221  loss_sem_seg: 1.013  loss_center: 0.5429  loss_offset: 0.6095  time: 0.2676  data_time: 0.0247  lr: 0.0008968  max_mem: 6513M
[12/10 22:23:39 d2.utils.events]:  eta: 0:14:09  iter: 6819  total_loss: 2.699  loss_sem_seg: 0.9861  loss_center: 0.6038  loss_offset: 0.7696  time: 0.2676  data_time: 0.0245  lr: 0.00089176  max_mem: 6513M
[12/10 22:23:45 d2.utils.events]:  eta: 0:14:04  iter: 6839  total_loss: 2.496  loss_sem_seg: 1.101  loss_center: 0.6536  loss_offset: 0.6934  time: 0.2676  data_time: 0.0242  lr: 0.00088671  max_mem: 6513M
[12/10 22:23:50 d2.utils.events]:  eta: 0:13:58  iter: 6859  total_loss: 2.345  loss_sem_seg: 0.9411  loss_center: 0.595  loss_offset: 0.8031  time: 0.2676  data_time: 0.0254  lr: 0.00088166  max_mem: 6513M
[12/10 22:23:56 d2.utils.events]:  eta: 0:13:53  iter: 6879  total_loss: 2.499  loss_sem_seg: 0.9948  loss_center: 0.6131  loss_offset: 0.6858  time: 0.2676  data_time: 0.0247  lr: 0.00087661  max_mem: 6513M
[12/10 22:24:01 d2.utils.events]:  eta: 0:13:48  iter: 6899  total_loss: 2.199  loss_sem_seg: 0.9089  loss_center: 0.4462  loss_offset: 0.6787  time: 0.2676  data_time: 0.0222  lr: 0.00087155  max_mem: 6513M
[12/10 22:24:06 d2.utils.events]:  eta: 0:13:43  iter: 6919  total_loss: 2.106  loss_sem_seg: 0.8477  loss_center: 0.4464  loss_offset: 0.6515  time: 0.2676  data_time: 0.0236  lr: 0.00086649  max_mem: 6513M
[12/10 22:24:12 d2.utils.events]:  eta: 0:13:38  iter: 6939  total_loss: 2.551  loss_sem_seg: 1.056  loss_center: 0.7106  loss_offset: 0.8007  time: 0.2676  data_time: 0.0239  lr: 0.00086142  max_mem: 6513M
[12/10 22:24:17 d2.utils.events]:  eta: 0:13:33  iter: 6959  total_loss: 2.551  loss_sem_seg: 1.154  loss_center: 0.5371  loss_offset: 0.8094  time: 0.2676  data_time: 0.0249  lr: 0.00085636  max_mem: 6513M
[12/10 22:24:22 d2.utils.events]:  eta: 0:13:27  iter: 6979  total_loss: 2.346  loss_sem_seg: 0.9151  loss_center: 0.6942  loss_offset: 0.7208  time: 0.2676  data_time: 0.0262  lr: 0.00085129  max_mem: 6513M
[12/10 22:24:28 d2.utils.events]:  eta: 0:13:22  iter: 6999  total_loss: 2.329  loss_sem_seg: 0.8936  loss_center: 0.5797  loss_offset: 0.6453  time: 0.2676  data_time: 0.0235  lr: 0.00084621  max_mem: 6513M
[12/10 22:24:33 d2.utils.events]:  eta: 0:13:17  iter: 7019  total_loss: 2.517  loss_sem_seg: 1.014  loss_center: 0.648  loss_offset: 0.7109  time: 0.2676  data_time: 0.0263  lr: 0.00084114  max_mem: 6513M
[12/10 22:24:39 d2.utils.events]:  eta: 0:13:12  iter: 7039  total_loss: 2.405  loss_sem_seg: 1.084  loss_center: 0.5654  loss_offset: 0.7666  time: 0.2676  data_time: 0.0240  lr: 0.00083605  max_mem: 6513M
[12/10 22:24:44 d2.utils.events]:  eta: 0:13:07  iter: 7059  total_loss: 2.245  loss_sem_seg: 1.054  loss_center: 0.4949  loss_offset: 0.6924  time: 0.2676  data_time: 0.0243  lr: 0.00083097  max_mem: 6513M
[12/10 22:24:49 d2.utils.events]:  eta: 0:13:02  iter: 7079  total_loss: 2.546  loss_sem_seg: 1.065  loss_center: 0.8214  loss_offset: 0.7211  time: 0.2676  data_time: 0.0240  lr: 0.00082588  max_mem: 6513M
[12/10 22:24:55 d2.utils.events]:  eta: 0:12:57  iter: 7099  total_loss: 2.698  loss_sem_seg: 0.969  loss_center: 0.8298  loss_offset: 0.7344  time: 0.2676  data_time: 0.0254  lr: 0.00082079  max_mem: 6513M
[12/10 22:25:00 d2.utils.events]:  eta: 0:12:51  iter: 7119  total_loss: 2.203  loss_sem_seg: 1.016  loss_center: 0.4857  loss_offset: 0.7593  time: 0.2676  data_time: 0.0246  lr: 0.0008157  max_mem: 6513M
[12/10 22:25:05 d2.utils.events]:  eta: 0:12:46  iter: 7139  total_loss: 2.415  loss_sem_seg: 0.9299  loss_center: 0.52  loss_offset: 0.7191  time: 0.2676  data_time: 0.0239  lr: 0.0008106  max_mem: 6513M
[12/10 22:25:11 d2.utils.events]:  eta: 0:12:41  iter: 7159  total_loss: 2.23  loss_sem_seg: 0.9255  loss_center: 0.5115  loss_offset: 0.7118  time: 0.2676  data_time: 0.0260  lr: 0.0008055  max_mem: 6513M
[12/10 22:25:16 d2.utils.events]:  eta: 0:12:35  iter: 7179  total_loss: 2.151  loss_sem_seg: 0.8902  loss_center: 0.5048  loss_offset: 0.6733  time: 0.2676  data_time: 0.0234  lr: 0.00080039  max_mem: 6513M
[12/10 22:25:21 d2.utils.events]:  eta: 0:12:30  iter: 7199  total_loss: 2.15  loss_sem_seg: 0.7133  loss_center: 0.6322  loss_offset: 0.6055  time: 0.2676  data_time: 0.0236  lr: 0.00079528  max_mem: 6513M
[12/10 22:25:27 d2.utils.events]:  eta: 0:12:25  iter: 7219  total_loss: 2.431  loss_sem_seg: 1.04  loss_center: 0.6028  loss_offset: 0.8024  time: 0.2676  data_time: 0.0244  lr: 0.00079017  max_mem: 6513M
[12/10 22:25:32 d2.utils.events]:  eta: 0:12:19  iter: 7239  total_loss: 2.154  loss_sem_seg: 0.873  loss_center: 0.5277  loss_offset: 0.7308  time: 0.2676  data_time: 0.0235  lr: 0.00078505  max_mem: 6513M
[12/10 22:25:38 d2.utils.events]:  eta: 0:12:13  iter: 7259  total_loss: 2.333  loss_sem_seg: 0.8854  loss_center: 0.4881  loss_offset: 0.7242  time: 0.2676  data_time: 0.0254  lr: 0.00077993  max_mem: 6513M
[12/10 22:25:43 d2.utils.events]:  eta: 0:12:08  iter: 7279  total_loss: 2.361  loss_sem_seg: 1.018  loss_center: 0.6199  loss_offset: 0.6517  time: 0.2676  data_time: 0.0239  lr: 0.00077481  max_mem: 6513M
[12/10 22:25:48 d2.utils.events]:  eta: 0:12:03  iter: 7299  total_loss: 2.245  loss_sem_seg: 0.9693  loss_center: 0.5868  loss_offset: 0.6804  time: 0.2676  data_time: 0.0243  lr: 0.00076968  max_mem: 6513M
[12/10 22:25:54 d2.utils.events]:  eta: 0:11:58  iter: 7319  total_loss: 2.475  loss_sem_seg: 1.052  loss_center: 0.6308  loss_offset: 0.7254  time: 0.2676  data_time: 0.0228  lr: 0.00076455  max_mem: 6513M
[12/10 22:25:59 d2.utils.events]:  eta: 0:11:52  iter: 7339  total_loss: 2.617  loss_sem_seg: 1.075  loss_center: 0.5688  loss_offset: 0.678  time: 0.2676  data_time: 0.0250  lr: 0.00075942  max_mem: 6513M
[12/10 22:26:04 d2.utils.events]:  eta: 0:11:47  iter: 7359  total_loss: 2.419  loss_sem_seg: 1.067  loss_center: 0.5489  loss_offset: 0.8147  time: 0.2676  data_time: 0.0237  lr: 0.00075428  max_mem: 6513M
[12/10 22:26:10 d2.utils.events]:  eta: 0:11:42  iter: 7379  total_loss: 2.523  loss_sem_seg: 0.9731  loss_center: 0.6384  loss_offset: 0.7435  time: 0.2676  data_time: 0.0254  lr: 0.00074914  max_mem: 6513M
[12/10 22:26:15 d2.utils.events]:  eta: 0:11:36  iter: 7399  total_loss: 2.326  loss_sem_seg: 1.027  loss_center: 0.6744  loss_offset: 0.6989  time: 0.2676  data_time: 0.0242  lr: 0.00074399  max_mem: 6513M
[12/10 22:26:21 d2.utils.events]:  eta: 0:11:31  iter: 7419  total_loss: 2.357  loss_sem_seg: 1.011  loss_center: 0.4397  loss_offset: 0.7427  time: 0.2676  data_time: 0.0231  lr: 0.00073884  max_mem: 6513M
[12/10 22:26:26 d2.utils.events]:  eta: 0:11:26  iter: 7439  total_loss: 2.34  loss_sem_seg: 0.7233  loss_center: 0.548  loss_offset: 0.8149  time: 0.2676  data_time: 0.0235  lr: 0.00073368  max_mem: 6513M
[12/10 22:26:31 d2.utils.events]:  eta: 0:11:20  iter: 7459  total_loss: 2.256  loss_sem_seg: 0.9291  loss_center: 0.5155  loss_offset: 0.7677  time: 0.2676  data_time: 0.0245  lr: 0.00072852  max_mem: 6513M
[12/10 22:26:37 d2.utils.events]:  eta: 0:11:15  iter: 7479  total_loss: 2.573  loss_sem_seg: 0.9546  loss_center: 0.7333  loss_offset: 0.7294  time: 0.2676  data_time: 0.0244  lr: 0.00072336  max_mem: 6513M
[12/10 22:26:42 d2.utils.events]:  eta: 0:11:09  iter: 7499  total_loss: 2.277  loss_sem_seg: 0.9205  loss_center: 0.7184  loss_offset: 0.6263  time: 0.2676  data_time: 0.0238  lr: 0.00071819  max_mem: 6513M
[12/10 22:26:47 d2.utils.events]:  eta: 0:11:04  iter: 7519  total_loss: 2.298  loss_sem_seg: 0.9176  loss_center: 0.6  loss_offset: 0.6901  time: 0.2676  data_time: 0.0235  lr: 0.00071302  max_mem: 6513M
[12/10 22:26:53 d2.utils.events]:  eta: 0:10:59  iter: 7539  total_loss: 2.396  loss_sem_seg: 1.017  loss_center: 0.525  loss_offset: 0.7046  time: 0.2676  data_time: 0.0270  lr: 0.00070785  max_mem: 6513M
[12/10 22:26:58 d2.utils.events]:  eta: 0:10:53  iter: 7559  total_loss: 2.43  loss_sem_seg: 0.944  loss_center: 0.6912  loss_offset: 0.7091  time: 0.2676  data_time: 0.0234  lr: 0.00070267  max_mem: 6513M
[12/10 22:27:03 d2.utils.events]:  eta: 0:10:48  iter: 7579  total_loss: 2.351  loss_sem_seg: 0.9144  loss_center: 0.5574  loss_offset: 0.7501  time: 0.2676  data_time: 0.0247  lr: 0.00069749  max_mem: 6513M
[12/10 22:27:09 d2.utils.events]:  eta: 0:10:42  iter: 7599  total_loss: 2.411  loss_sem_seg: 0.98  loss_center: 0.5809  loss_offset: 0.7126  time: 0.2676  data_time: 0.0252  lr: 0.0006923  max_mem: 6513M
[12/10 22:27:14 d2.utils.events]:  eta: 0:10:37  iter: 7619  total_loss: 2.237  loss_sem_seg: 0.8962  loss_center: 0.5231  loss_offset: 0.7843  time: 0.2676  data_time: 0.0251  lr: 0.00068711  max_mem: 6513M
[12/10 22:27:20 d2.utils.events]:  eta: 0:10:31  iter: 7639  total_loss: 2.478  loss_sem_seg: 0.9784  loss_center: 0.594  loss_offset: 0.7066  time: 0.2676  data_time: 0.0238  lr: 0.00068191  max_mem: 6513M
[12/10 22:27:25 d2.utils.events]:  eta: 0:10:26  iter: 7659  total_loss: 2.354  loss_sem_seg: 0.8625  loss_center: 0.6239  loss_offset: 0.8176  time: 0.2676  data_time: 0.0230  lr: 0.00067671  max_mem: 6513M
[12/10 22:27:30 d2.utils.events]:  eta: 0:10:20  iter: 7679  total_loss: 2.446  loss_sem_seg: 0.92  loss_center: 0.658  loss_offset: 0.6805  time: 0.2676  data_time: 0.0240  lr: 0.0006715  max_mem: 6513M
[12/10 22:27:36 d2.utils.events]:  eta: 0:10:15  iter: 7699  total_loss: 2.194  loss_sem_seg: 0.8828  loss_center: 0.4802  loss_offset: 0.6831  time: 0.2676  data_time: 0.0238  lr: 0.00066629  max_mem: 6513M
[12/10 22:27:41 d2.utils.events]:  eta: 0:10:10  iter: 7719  total_loss: 2.278  loss_sem_seg: 1.018  loss_center: 0.5592  loss_offset: 0.6887  time: 0.2676  data_time: 0.0241  lr: 0.00066108  max_mem: 6513M
[12/10 22:27:46 d2.utils.events]:  eta: 0:10:04  iter: 7739  total_loss: 2.12  loss_sem_seg: 0.8865  loss_center: 0.5102  loss_offset: 0.6305  time: 0.2676  data_time: 0.0244  lr: 0.00065586  max_mem: 6513M
[12/10 22:27:52 d2.utils.events]:  eta: 0:09:59  iter: 7759  total_loss: 2.367  loss_sem_seg: 0.9357  loss_center: 0.6527  loss_offset: 0.6826  time: 0.2676  data_time: 0.0248  lr: 0.00065064  max_mem: 6513M
[12/10 22:27:57 d2.utils.events]:  eta: 0:09:53  iter: 7779  total_loss: 2.443  loss_sem_seg: 1.114  loss_center: 0.6048  loss_offset: 0.726  time: 0.2676  data_time: 0.0243  lr: 0.00064541  max_mem: 6513M
[12/10 22:28:02 d2.utils.events]:  eta: 0:09:48  iter: 7799  total_loss: 2.345  loss_sem_seg: 0.9637  loss_center: 0.6863  loss_offset: 0.6566  time: 0.2676  data_time: 0.0234  lr: 0.00064017  max_mem: 6513M
[12/10 22:28:08 d2.utils.events]:  eta: 0:09:43  iter: 7819  total_loss: 2.233  loss_sem_seg: 0.9615  loss_center: 0.549  loss_offset: 0.6476  time: 0.2676  data_time: 0.0247  lr: 0.00063494  max_mem: 6513M
[12/10 22:28:13 d2.utils.events]:  eta: 0:09:37  iter: 7839  total_loss: 2.516  loss_sem_seg: 0.9611  loss_center: 0.6214  loss_offset: 0.7396  time: 0.2676  data_time: 0.0254  lr: 0.00062969  max_mem: 6513M
[12/10 22:28:19 d2.utils.events]:  eta: 0:09:32  iter: 7859  total_loss: 2.262  loss_sem_seg: 0.8085  loss_center: 0.598  loss_offset: 0.672  time: 0.2676  data_time: 0.0244  lr: 0.00062445  max_mem: 6513M
[12/10 22:28:24 d2.utils.events]:  eta: 0:09:26  iter: 7879  total_loss: 2.601  loss_sem_seg: 1.12  loss_center: 0.6309  loss_offset: 0.7513  time: 0.2676  data_time: 0.0234  lr: 0.00061919  max_mem: 6513M
[12/10 22:28:29 d2.utils.events]:  eta: 0:09:21  iter: 7899  total_loss: 2.614  loss_sem_seg: 1.014  loss_center: 0.6136  loss_offset: 0.809  time: 0.2676  data_time: 0.0245  lr: 0.00061394  max_mem: 6513M
[12/10 22:28:35 d2.utils.events]:  eta: 0:09:16  iter: 7919  total_loss: 2.373  loss_sem_seg: 0.9971  loss_center: 0.5278  loss_offset: 0.6606  time: 0.2676  data_time: 0.0236  lr: 0.00060867  max_mem: 6513M
[12/10 22:28:40 d2.utils.events]:  eta: 0:09:10  iter: 7939  total_loss: 2.307  loss_sem_seg: 0.8154  loss_center: 0.6415  loss_offset: 0.7403  time: 0.2676  data_time: 0.0245  lr: 0.00060341  max_mem: 6513M
[12/10 22:28:45 d2.utils.events]:  eta: 0:09:05  iter: 7959  total_loss: 2.336  loss_sem_seg: 0.8732  loss_center: 0.5631  loss_offset: 0.7825  time: 0.2676  data_time: 0.0255  lr: 0.00059813  max_mem: 6513M
[12/10 22:28:51 d2.utils.events]:  eta: 0:09:00  iter: 7979  total_loss: 2.224  loss_sem_seg: 0.9594  loss_center: 0.4648  loss_offset: 0.7078  time: 0.2676  data_time: 0.0252  lr: 0.00059286  max_mem: 6513M
[12/10 22:28:56 d2.utils.events]:  eta: 0:08:54  iter: 7999  total_loss: 2.188  loss_sem_seg: 0.8915  loss_center: 0.5702  loss_offset: 0.6954  time: 0.2676  data_time: 0.0239  lr: 0.00058757  max_mem: 6513M
[12/10 22:29:01 d2.utils.events]:  eta: 0:08:49  iter: 8019  total_loss: 2.339  loss_sem_seg: 0.9419  loss_center: 0.6583  loss_offset: 0.7493  time: 0.2676  data_time: 0.0239  lr: 0.00058229  max_mem: 6513M
[12/10 22:29:07 d2.utils.events]:  eta: 0:08:44  iter: 8039  total_loss: 2.342  loss_sem_seg: 0.9872  loss_center: 0.6057  loss_offset: 0.7307  time: 0.2676  data_time: 0.0253  lr: 0.00057699  max_mem: 6513M
[12/10 22:29:12 d2.utils.events]:  eta: 0:08:38  iter: 8059  total_loss: 2.468  loss_sem_seg: 1.068  loss_center: 0.5566  loss_offset: 0.7799  time: 0.2676  data_time: 0.0257  lr: 0.00057169  max_mem: 6513M
[12/10 22:29:18 d2.utils.events]:  eta: 0:08:33  iter: 8079  total_loss: 2.224  loss_sem_seg: 0.9642  loss_center: 0.5457  loss_offset: 0.7362  time: 0.2676  data_time: 0.0253  lr: 0.00056639  max_mem: 6513M
[12/10 22:29:23 d2.utils.events]:  eta: 0:08:27  iter: 8099  total_loss: 2.215  loss_sem_seg: 0.847  loss_center: 0.5638  loss_offset: 0.6749  time: 0.2676  data_time: 0.0243  lr: 0.00056108  max_mem: 6513M
[12/10 22:29:28 d2.utils.events]:  eta: 0:08:22  iter: 8119  total_loss: 2.205  loss_sem_seg: 0.8134  loss_center: 0.5296  loss_offset: 0.691  time: 0.2676  data_time: 0.0252  lr: 0.00055576  max_mem: 6513M
[12/10 22:29:34 d2.utils.events]:  eta: 0:08:17  iter: 8139  total_loss: 2.308  loss_sem_seg: 1.061  loss_center: 0.5341  loss_offset: 0.7487  time: 0.2676  data_time: 0.0236  lr: 0.00055044  max_mem: 6513M
[12/10 22:29:39 d2.utils.events]:  eta: 0:08:11  iter: 8159  total_loss: 2.721  loss_sem_seg: 1.101  loss_center: 0.6368  loss_offset: 0.8111  time: 0.2676  data_time: 0.0243  lr: 0.00054512  max_mem: 6513M
[12/10 22:29:44 d2.utils.events]:  eta: 0:08:06  iter: 8179  total_loss: 2.401  loss_sem_seg: 0.9719  loss_center: 0.5711  loss_offset: 0.6955  time: 0.2676  data_time: 0.0228  lr: 0.00053978  max_mem: 6513M
[12/10 22:29:50 d2.utils.events]:  eta: 0:08:01  iter: 8199  total_loss: 2.267  loss_sem_seg: 0.9154  loss_center: 0.5846  loss_offset: 0.6887  time: 0.2676  data_time: 0.0231  lr: 0.00053444  max_mem: 6513M
[12/10 22:29:55 d2.utils.events]:  eta: 0:07:55  iter: 8219  total_loss: 2.283  loss_sem_seg: 0.8761  loss_center: 0.4737  loss_offset: 0.7253  time: 0.2676  data_time: 0.0239  lr: 0.0005291  max_mem: 6513M
[12/10 22:30:00 d2.utils.events]:  eta: 0:07:50  iter: 8239  total_loss: 2.417  loss_sem_seg: 1.024  loss_center: 0.5949  loss_offset: 0.7187  time: 0.2676  data_time: 0.0250  lr: 0.00052375  max_mem: 6513M
[12/10 22:30:06 d2.utils.events]:  eta: 0:07:44  iter: 8259  total_loss: 2.335  loss_sem_seg: 0.981  loss_center: 0.6122  loss_offset: 0.7389  time: 0.2676  data_time: 0.0227  lr: 0.00051839  max_mem: 6513M
[12/10 22:30:11 d2.utils.events]:  eta: 0:07:39  iter: 8279  total_loss: 2.297  loss_sem_seg: 0.9798  loss_center: 0.6524  loss_offset: 0.7313  time: 0.2676  data_time: 0.0236  lr: 0.00051303  max_mem: 6513M
[12/10 22:30:16 d2.utils.events]:  eta: 0:07:34  iter: 8299  total_loss: 2.503  loss_sem_seg: 0.9889  loss_center: 0.6354  loss_offset: 0.7363  time: 0.2676  data_time: 0.0247  lr: 0.00050766  max_mem: 6513M
[12/10 22:30:22 d2.utils.events]:  eta: 0:07:28  iter: 8319  total_loss: 2.241  loss_sem_seg: 0.9025  loss_center: 0.5438  loss_offset: 0.6646  time: 0.2676  data_time: 0.0246  lr: 0.00050229  max_mem: 6513M
[12/10 22:30:27 d2.utils.events]:  eta: 0:07:23  iter: 8339  total_loss: 2.268  loss_sem_seg: 1.015  loss_center: 0.5535  loss_offset: 0.6811  time: 0.2676  data_time: 0.0253  lr: 0.0004969  max_mem: 6513M
[12/10 22:30:33 d2.utils.events]:  eta: 0:07:18  iter: 8359  total_loss: 2.437  loss_sem_seg: 1.098  loss_center: 0.6094  loss_offset: 0.6815  time: 0.2676  data_time: 0.0243  lr: 0.00049152  max_mem: 6513M
[12/10 22:30:38 d2.utils.events]:  eta: 0:07:12  iter: 8379  total_loss: 2.251  loss_sem_seg: 0.8912  loss_center: 0.4343  loss_offset: 0.7301  time: 0.2676  data_time: 0.0250  lr: 0.00048612  max_mem: 6513M
[12/10 22:30:43 d2.utils.events]:  eta: 0:07:07  iter: 8399  total_loss: 2.25  loss_sem_seg: 0.9169  loss_center: 0.4865  loss_offset: 0.7395  time: 0.2676  data_time: 0.0269  lr: 0.00048072  max_mem: 6513M
[12/10 22:30:49 d2.utils.events]:  eta: 0:07:02  iter: 8419  total_loss: 2.223  loss_sem_seg: 0.9447  loss_center: 0.5979  loss_offset: 0.6273  time: 0.2676  data_time: 0.0227  lr: 0.00047531  max_mem: 6513M
[12/10 22:30:54 d2.utils.events]:  eta: 0:06:56  iter: 8439  total_loss: 2.303  loss_sem_seg: 0.8775  loss_center: 0.5306  loss_offset: 0.582  time: 0.2676  data_time: 0.0243  lr: 0.0004699  max_mem: 6513M
[12/10 22:30:59 d2.utils.events]:  eta: 0:06:51  iter: 8459  total_loss: 2.382  loss_sem_seg: 0.9759  loss_center: 0.6434  loss_offset: 0.7608  time: 0.2676  data_time: 0.0243  lr: 0.00046448  max_mem: 6513M
[12/10 22:31:05 d2.utils.events]:  eta: 0:06:45  iter: 8479  total_loss: 2.163  loss_sem_seg: 0.9253  loss_center: 0.6193  loss_offset: 0.6308  time: 0.2676  data_time: 0.0232  lr: 0.00045905  max_mem: 6513M
[12/10 22:31:10 d2.utils.events]:  eta: 0:06:40  iter: 8499  total_loss: 2.477  loss_sem_seg: 1.117  loss_center: 0.6828  loss_offset: 0.7848  time: 0.2676  data_time: 0.0248  lr: 0.00045361  max_mem: 6513M
[12/10 22:31:16 d2.utils.events]:  eta: 0:06:35  iter: 8519  total_loss: 2.155  loss_sem_seg: 0.8878  loss_center: 0.5383  loss_offset: 0.7585  time: 0.2676  data_time: 0.0239  lr: 0.00044817  max_mem: 6513M
[12/10 22:31:21 d2.utils.events]:  eta: 0:06:29  iter: 8539  total_loss: 2.121  loss_sem_seg: 0.8306  loss_center: 0.5965  loss_offset: 0.694  time: 0.2677  data_time: 0.0252  lr: 0.00044272  max_mem: 6513M
[12/10 22:31:26 d2.utils.events]:  eta: 0:06:24  iter: 8559  total_loss: 2.322  loss_sem_seg: 0.9979  loss_center: 0.4955  loss_offset: 0.7314  time: 0.2677  data_time: 0.0242  lr: 0.00043726  max_mem: 6513M
[12/10 22:31:32 d2.utils.events]:  eta: 0:06:19  iter: 8579  total_loss: 2.168  loss_sem_seg: 0.8361  loss_center: 0.6217  loss_offset: 0.6702  time: 0.2676  data_time: 0.0238  lr: 0.00043179  max_mem: 6513M
[12/10 22:31:37 d2.utils.events]:  eta: 0:06:13  iter: 8599  total_loss: 2.448  loss_sem_seg: 0.8496  loss_center: 0.6551  loss_offset: 0.7051  time: 0.2676  data_time: 0.0250  lr: 0.00042632  max_mem: 6513M
[12/10 22:31:42 d2.utils.events]:  eta: 0:06:08  iter: 8619  total_loss: 2.124  loss_sem_seg: 0.7518  loss_center: 0.5977  loss_offset: 0.6624  time: 0.2676  data_time: 0.0242  lr: 0.00042084  max_mem: 6513M
[12/10 22:31:48 d2.utils.events]:  eta: 0:06:03  iter: 8639  total_loss: 2.43  loss_sem_seg: 0.898  loss_center: 0.7296  loss_offset: 0.7726  time: 0.2676  data_time: 0.0240  lr: 0.00041535  max_mem: 6513M
[12/10 22:31:53 d2.utils.events]:  eta: 0:05:58  iter: 8659  total_loss: 2.348  loss_sem_seg: 0.8871  loss_center: 0.6047  loss_offset: 0.7189  time: 0.2677  data_time: 0.0244  lr: 0.00040985  max_mem: 6513M
[12/10 22:31:59 d2.utils.events]:  eta: 0:05:52  iter: 8679  total_loss: 2.3  loss_sem_seg: 0.9993  loss_center: 0.5247  loss_offset: 0.7484  time: 0.2677  data_time: 0.0249  lr: 0.00040435  max_mem: 6513M
[12/10 22:32:04 d2.utils.events]:  eta: 0:05:47  iter: 8699  total_loss: 2.414  loss_sem_seg: 0.9208  loss_center: 0.5877  loss_offset: 0.8605  time: 0.2677  data_time: 0.0233  lr: 0.00039883  max_mem: 6513M
[12/10 22:32:09 d2.utils.events]:  eta: 0:05:42  iter: 8719  total_loss: 2.429  loss_sem_seg: 0.9575  loss_center: 0.6147  loss_offset: 0.6473  time: 0.2677  data_time: 0.0242  lr: 0.00039331  max_mem: 6513M
[12/10 22:32:15 d2.utils.events]:  eta: 0:05:36  iter: 8739  total_loss: 2.033  loss_sem_seg: 0.7816  loss_center: 0.6496  loss_offset: 0.6047  time: 0.2677  data_time: 0.0244  lr: 0.00038778  max_mem: 6513M
[12/10 22:32:20 d2.utils.events]:  eta: 0:05:31  iter: 8759  total_loss: 2.213  loss_sem_seg: 0.9548  loss_center: 0.5825  loss_offset: 0.6436  time: 0.2677  data_time: 0.0248  lr: 0.00038224  max_mem: 6513M
[12/10 22:32:26 d2.utils.events]:  eta: 0:05:26  iter: 8779  total_loss: 2.358  loss_sem_seg: 0.8265  loss_center: 0.6581  loss_offset: 0.723  time: 0.2677  data_time: 0.0253  lr: 0.00037669  max_mem: 6513M
[12/10 22:32:31 d2.utils.events]:  eta: 0:05:20  iter: 8799  total_loss: 2.14  loss_sem_seg: 0.9304  loss_center: 0.5641  loss_offset: 0.6641  time: 0.2677  data_time: 0.0238  lr: 0.00037113  max_mem: 6513M
[12/10 22:32:36 d2.utils.events]:  eta: 0:05:15  iter: 8819  total_loss: 2.01  loss_sem_seg: 0.9342  loss_center: 0.4993  loss_offset: 0.7507  time: 0.2677  data_time: 0.0252  lr: 0.00036557  max_mem: 6513M
[12/10 22:32:42 d2.utils.events]:  eta: 0:05:10  iter: 8839  total_loss: 2.267  loss_sem_seg: 0.9859  loss_center: 0.438  loss_offset: 0.6626  time: 0.2677  data_time: 0.0250  lr: 0.00035999  max_mem: 6513M
[12/10 22:32:47 d2.utils.events]:  eta: 0:05:04  iter: 8859  total_loss: 1.963  loss_sem_seg: 0.7681  loss_center: 0.6079  loss_offset: 0.7033  time: 0.2677  data_time: 0.0248  lr: 0.0003544  max_mem: 6513M
[12/10 22:32:52 d2.utils.events]:  eta: 0:04:59  iter: 8879  total_loss: 1.955  loss_sem_seg: 0.8034  loss_center: 0.4473  loss_offset: 0.5953  time: 0.2677  data_time: 0.0251  lr: 0.00034881  max_mem: 6513M
[12/10 22:32:58 d2.utils.events]:  eta: 0:04:54  iter: 8899  total_loss: 2.137  loss_sem_seg: 0.8165  loss_center: 0.6072  loss_offset: 0.702  time: 0.2677  data_time: 0.0247  lr: 0.0003432  max_mem: 6513M
[12/10 22:33:03 d2.utils.events]:  eta: 0:04:48  iter: 8919  total_loss: 2.427  loss_sem_seg: 0.8996  loss_center: 0.5619  loss_offset: 0.6908  time: 0.2677  data_time: 0.0245  lr: 0.00033758  max_mem: 6513M
[12/10 22:33:09 d2.utils.events]:  eta: 0:04:43  iter: 8939  total_loss: 2.194  loss_sem_seg: 0.8436  loss_center: 0.5631  loss_offset: 0.6889  time: 0.2677  data_time: 0.0243  lr: 0.00033196  max_mem: 6513M
[12/10 22:33:14 d2.utils.events]:  eta: 0:04:38  iter: 8959  total_loss: 2.288  loss_sem_seg: 0.93  loss_center: 0.4407  loss_offset: 0.8044  time: 0.2677  data_time: 0.0249  lr: 0.00032632  max_mem: 6513M
[12/10 22:33:19 d2.utils.events]:  eta: 0:04:32  iter: 8979  total_loss: 2.347  loss_sem_seg: 0.9722  loss_center: 0.5994  loss_offset: 0.706  time: 0.2677  data_time: 0.0259  lr: 0.00032067  max_mem: 6513M
[12/10 22:33:25 d2.utils.events]:  eta: 0:04:27  iter: 8999  total_loss: 2.278  loss_sem_seg: 0.9771  loss_center: 0.7219  loss_offset: 0.6993  time: 0.2677  data_time: 0.0256  lr: 0.00031501  max_mem: 6513M
[12/10 22:33:30 d2.utils.events]:  eta: 0:04:22  iter: 9019  total_loss: 2.082  loss_sem_seg: 0.835  loss_center: 0.5246  loss_offset: 0.6612  time: 0.2677  data_time: 0.0238  lr: 0.00030934  max_mem: 6513M
[12/10 22:33:36 d2.utils.events]:  eta: 0:04:16  iter: 9039  total_loss: 2.5  loss_sem_seg: 0.9521  loss_center: 0.6123  loss_offset: 0.688  time: 0.2677  data_time: 0.0234  lr: 0.00030366  max_mem: 6513M
[12/10 22:33:41 d2.utils.events]:  eta: 0:04:11  iter: 9059  total_loss: 2.321  loss_sem_seg: 0.9769  loss_center: 0.5337  loss_offset: 0.7152  time: 0.2677  data_time: 0.0257  lr: 0.00029797  max_mem: 6513M
[12/10 22:33:46 d2.utils.events]:  eta: 0:04:06  iter: 9079  total_loss: 2.132  loss_sem_seg: 0.8426  loss_center: 0.5655  loss_offset: 0.6743  time: 0.2677  data_time: 0.0237  lr: 0.00029226  max_mem: 6513M
[12/10 22:33:52 d2.utils.events]:  eta: 0:04:00  iter: 9099  total_loss: 2.039  loss_sem_seg: 0.7236  loss_center: 0.5238  loss_offset: 0.6294  time: 0.2677  data_time: 0.0259  lr: 0.00028654  max_mem: 6513M
[12/10 22:33:57 d2.utils.events]:  eta: 0:03:55  iter: 9119  total_loss: 2.211  loss_sem_seg: 0.8499  loss_center: 0.594  loss_offset: 0.6655  time: 0.2677  data_time: 0.0272  lr: 0.00028081  max_mem: 6513M
[12/10 22:34:03 d2.utils.events]:  eta: 0:03:50  iter: 9139  total_loss: 2.045  loss_sem_seg: 0.7443  loss_center: 0.5848  loss_offset: 0.6517  time: 0.2677  data_time: 0.0247  lr: 0.00027507  max_mem: 6513M
[12/10 22:34:08 d2.utils.events]:  eta: 0:03:44  iter: 9159  total_loss: 1.906  loss_sem_seg: 0.8332  loss_center: 0.4864  loss_offset: 0.6697  time: 0.2677  data_time: 0.0254  lr: 0.00026931  max_mem: 6513M
[12/10 22:34:13 d2.utils.events]:  eta: 0:03:39  iter: 9179  total_loss: 2.243  loss_sem_seg: 0.8513  loss_center: 0.6121  loss_offset: 0.6155  time: 0.2677  data_time: 0.0256  lr: 0.00026354  max_mem: 6513M
[12/10 22:34:19 d2.utils.events]:  eta: 0:03:34  iter: 9199  total_loss: 2.222  loss_sem_seg: 0.8713  loss_center: 0.6413  loss_offset: 0.6704  time: 0.2677  data_time: 0.0264  lr: 0.00025776  max_mem: 6513M
[12/10 22:34:24 d2.utils.events]:  eta: 0:03:28  iter: 9219  total_loss: 1.952  loss_sem_seg: 0.7906  loss_center: 0.5463  loss_offset: 0.6859  time: 0.2677  data_time: 0.0248  lr: 0.00025196  max_mem: 6513M
[12/10 22:34:30 d2.utils.events]:  eta: 0:03:23  iter: 9239  total_loss: 2.15  loss_sem_seg: 0.8554  loss_center: 0.6361  loss_offset: 0.626  time: 0.2677  data_time: 0.0233  lr: 0.00024614  max_mem: 6513M
[12/10 22:34:35 d2.utils.events]:  eta: 0:03:18  iter: 9259  total_loss: 2.335  loss_sem_seg: 0.9708  loss_center: 0.5702  loss_offset: 0.7479  time: 0.2678  data_time: 0.0275  lr: 0.00024031  max_mem: 6513M
[12/10 22:34:40 d2.utils.events]:  eta: 0:03:12  iter: 9279  total_loss: 2.052  loss_sem_seg: 0.7674  loss_center: 0.5513  loss_offset: 0.6982  time: 0.2678  data_time: 0.0235  lr: 0.00023447  max_mem: 6513M
[12/10 22:34:46 d2.utils.events]:  eta: 0:03:07  iter: 9299  total_loss: 2.319  loss_sem_seg: 0.9824  loss_center: 0.5076  loss_offset: 0.6906  time: 0.2678  data_time: 0.0258  lr: 0.00022861  max_mem: 6513M
[12/10 22:34:51 d2.utils.events]:  eta: 0:03:02  iter: 9319  total_loss: 2.141  loss_sem_seg: 0.9588  loss_center: 0.5371  loss_offset: 0.6266  time: 0.2678  data_time: 0.0232  lr: 0.00022273  max_mem: 6513M
[12/10 22:34:57 d2.utils.events]:  eta: 0:02:56  iter: 9339  total_loss: 2.18  loss_sem_seg: 0.8061  loss_center: 0.575  loss_offset: 0.7641  time: 0.2678  data_time: 0.0251  lr: 0.00021683  max_mem: 6513M
[12/10 22:35:02 d2.utils.events]:  eta: 0:02:51  iter: 9359  total_loss: 2.227  loss_sem_seg: 0.8811  loss_center: 0.5736  loss_offset: 0.7227  time: 0.2678  data_time: 0.0244  lr: 0.00021092  max_mem: 6513M
[12/10 22:35:07 d2.utils.events]:  eta: 0:02:46  iter: 9379  total_loss: 2.153  loss_sem_seg: 0.9514  loss_center: 0.5347  loss_offset: 0.6688  time: 0.2678  data_time: 0.0246  lr: 0.00020499  max_mem: 6513M
[12/10 22:35:13 d2.utils.events]:  eta: 0:02:40  iter: 9399  total_loss: 2.236  loss_sem_seg: 0.8949  loss_center: 0.5978  loss_offset: 0.6938  time: 0.2678  data_time: 0.0238  lr: 0.00019903  max_mem: 6513M
[12/10 22:35:18 d2.utils.events]:  eta: 0:02:35  iter: 9419  total_loss: 2.231  loss_sem_seg: 0.8869  loss_center: 0.6006  loss_offset: 0.7041  time: 0.2678  data_time: 0.0249  lr: 0.00019306  max_mem: 6513M
[12/10 22:35:23 d2.utils.events]:  eta: 0:02:29  iter: 9439  total_loss: 2.246  loss_sem_seg: 0.8215  loss_center: 0.643  loss_offset: 0.7055  time: 0.2678  data_time: 0.0248  lr: 0.00018707  max_mem: 6513M
[12/10 22:35:29 d2.utils.events]:  eta: 0:02:24  iter: 9459  total_loss: 2.258  loss_sem_seg: 0.8332  loss_center: 0.6246  loss_offset: 0.667  time: 0.2678  data_time: 0.0247  lr: 0.00018106  max_mem: 6513M
[12/10 22:35:34 d2.utils.events]:  eta: 0:02:19  iter: 9479  total_loss: 2.425  loss_sem_seg: 0.9681  loss_center: 0.6377  loss_offset: 0.7675  time: 0.2678  data_time: 0.0256  lr: 0.00017502  max_mem: 6513M
[12/10 22:35:40 d2.utils.events]:  eta: 0:02:14  iter: 9499  total_loss: 2.059  loss_sem_seg: 0.9409  loss_center: 0.6004  loss_offset: 0.6634  time: 0.2678  data_time: 0.0236  lr: 0.00016896  max_mem: 6513M
[12/10 22:35:45 d2.utils.events]:  eta: 0:02:08  iter: 9519  total_loss: 2.351  loss_sem_seg: 0.9752  loss_center: 0.6598  loss_offset: 0.628  time: 0.2678  data_time: 0.0234  lr: 0.00016288  max_mem: 6513M
[12/10 22:35:50 d2.utils.events]:  eta: 0:02:03  iter: 9539  total_loss: 2.364  loss_sem_seg: 0.7901  loss_center: 0.6265  loss_offset: 0.7328  time: 0.2678  data_time: 0.0250  lr: 0.00015677  max_mem: 6513M
[12/10 22:35:56 d2.utils.events]:  eta: 0:01:57  iter: 9559  total_loss: 2.249  loss_sem_seg: 0.9286  loss_center: 0.6213  loss_offset: 0.7315  time: 0.2678  data_time: 0.0263  lr: 0.00015064  max_mem: 6513M
[12/10 22:36:01 d2.utils.events]:  eta: 0:01:52  iter: 9579  total_loss: 2.184  loss_sem_seg: 0.9947  loss_center: 0.4601  loss_offset: 0.7264  time: 0.2678  data_time: 0.0245  lr: 0.00014448  max_mem: 6513M
[12/10 22:36:06 d2.utils.events]:  eta: 0:01:47  iter: 9599  total_loss: 2.146  loss_sem_seg: 0.79  loss_center: 0.5337  loss_offset: 0.7061  time: 0.2678  data_time: 0.0256  lr: 0.00013828  max_mem: 6513M
[12/10 22:36:12 d2.utils.events]:  eta: 0:01:41  iter: 9619  total_loss: 1.863  loss_sem_seg: 0.7667  loss_center: 0.5212  loss_offset: 0.5964  time: 0.2678  data_time: 0.0246  lr: 0.00013206  max_mem: 6513M
[12/10 22:36:17 d2.utils.events]:  eta: 0:01:36  iter: 9639  total_loss: 2.278  loss_sem_seg: 1.087  loss_center: 0.5263  loss_offset: 0.7191  time: 0.2678  data_time: 0.0250  lr: 0.0001258  max_mem: 6513M
[12/10 22:36:23 d2.utils.events]:  eta: 0:01:31  iter: 9659  total_loss: 2.257  loss_sem_seg: 0.82  loss_center: 0.5988  loss_offset: 0.7349  time: 0.2678  data_time: 0.0247  lr: 0.00011951  max_mem: 6513M
[12/10 22:36:28 d2.utils.events]:  eta: 0:01:25  iter: 9679  total_loss: 2.185  loss_sem_seg: 0.8431  loss_center: 0.6475  loss_offset: 0.6284  time: 0.2678  data_time: 0.0249  lr: 0.00011319  max_mem: 6513M
[12/10 22:36:33 d2.utils.events]:  eta: 0:01:20  iter: 9699  total_loss: 2.182  loss_sem_seg: 0.8888  loss_center: 0.6718  loss_offset: 0.6102  time: 0.2678  data_time: 0.0234  lr: 0.00010682  max_mem: 6513M
[12/10 22:36:39 d2.utils.events]:  eta: 0:01:15  iter: 9719  total_loss: 2.336  loss_sem_seg: 1.011  loss_center: 0.6053  loss_offset: 0.582  time: 0.2678  data_time: 0.0247  lr: 0.00010041  max_mem: 6513M
[12/10 22:36:44 d2.utils.events]:  eta: 0:01:09  iter: 9739  total_loss: 2.276  loss_sem_seg: 0.9668  loss_center: 0.5406  loss_offset: 0.7316  time: 0.2678  data_time: 0.0258  lr: 9.3954e-05  max_mem: 6513M
[12/10 22:36:50 d2.utils.events]:  eta: 0:01:04  iter: 9759  total_loss: 2.481  loss_sem_seg: 1.148  loss_center: 0.6218  loss_offset: 0.6747  time: 0.2678  data_time: 0.0260  lr: 8.7449e-05  max_mem: 6513M
[12/10 22:36:55 d2.utils.events]:  eta: 0:00:58  iter: 9779  total_loss: 2.207  loss_sem_seg: 0.9038  loss_center: 0.5764  loss_offset: 0.5685  time: 0.2678  data_time: 0.0256  lr: 8.089e-05  max_mem: 6513M
[12/10 22:37:00 d2.utils.events]:  eta: 0:00:53  iter: 9799  total_loss: 2.188  loss_sem_seg: 0.9206  loss_center: 0.6091  loss_offset: 0.7044  time: 0.2678  data_time: 0.0246  lr: 7.4271e-05  max_mem: 6513M
[12/10 22:37:06 d2.utils.events]:  eta: 0:00:48  iter: 9819  total_loss: 2.029  loss_sem_seg: 0.8057  loss_center: 0.4984  loss_offset: 0.5943  time: 0.2678  data_time: 0.0244  lr: 6.7585e-05  max_mem: 6513M
[12/10 22:37:11 d2.utils.events]:  eta: 0:00:42  iter: 9839  total_loss: 2.335  loss_sem_seg: 0.8606  loss_center: 0.6708  loss_offset: 0.6803  time: 0.2678  data_time: 0.0253  lr: 6.0825e-05  max_mem: 6513M
[12/10 22:37:17 d2.utils.events]:  eta: 0:00:37  iter: 9859  total_loss: 2.16  loss_sem_seg: 0.796  loss_center: 0.6261  loss_offset: 0.6177  time: 0.2678  data_time: 0.0257  lr: 5.3981e-05  max_mem: 6513M
[12/10 22:37:22 d2.utils.events]:  eta: 0:00:32  iter: 9879  total_loss: 2.069  loss_sem_seg: 0.8316  loss_center: 0.6007  loss_offset: 0.5929  time: 0.2678  data_time: 0.0254  lr: 4.7038e-05  max_mem: 6513M
[12/10 22:37:27 d2.utils.events]:  eta: 0:00:26  iter: 9899  total_loss: 2.219  loss_sem_seg: 0.9738  loss_center: 0.5295  loss_offset: 0.7223  time: 0.2678  data_time: 0.0255  lr: 3.9979e-05  max_mem: 6513M
[12/10 22:37:33 d2.utils.events]:  eta: 0:00:21  iter: 9919  total_loss: 2.586  loss_sem_seg: 1.119  loss_center: 0.5525  loss_offset: 0.739  time: 0.2678  data_time: 0.0262  lr: 3.2778e-05  max_mem: 6513M
[12/10 22:37:38 d2.utils.events]:  eta: 0:00:16  iter: 9939  total_loss: 2.088  loss_sem_seg: 0.8836  loss_center: 0.4492  loss_offset: 0.6572  time: 0.2679  data_time: 0.0250  lr: 2.5394e-05  max_mem: 6513M
[12/10 22:37:44 d2.utils.events]:  eta: 0:00:10  iter: 9959  total_loss: 2.327  loss_sem_seg: 1.037  loss_center: 0.59  loss_offset: 0.6619  time: 0.2679  data_time: 0.0244  lr: 1.776e-05  max_mem: 6513M
[12/10 22:37:49 d2.utils.events]:  eta: 0:00:05  iter: 9979  total_loss: 2.079  loss_sem_seg: 0.8885  loss_center: 0.5369  loss_offset: 0.6576  time: 0.2679  data_time: 0.0244  lr: 9.7261e-06  max_mem: 6513M
[12/10 22:37:54 fvcore.common.checkpoint]: Saving checkpoint to ./output/model_0009999.pth
[12/10 22:37:55 fvcore.common.checkpoint]: Saving checkpoint to ./output/model_final.pth
[12/10 22:37:55 d2.utils.events]:  eta: 0:00:00  iter: 9999  total_loss: 2.555  loss_sem_seg: 1.129  loss_center: 0.5864  loss_offset: 0.799  time: 0.2679  data_time: 0.0249  lr: 6.2797e-07  max_mem: 6513M
[12/10 22:37:56 d2.engine.hooks]: Overall training speed: 9998 iterations in 0:44:38 (0.2679 s / it)
[12/10 22:37:56 d2.engine.hooks]: Total training time: 0:44:43 (0:00:05 on hooks)
[12/10 22:37:56 d2.data.dataset_mapper]: [DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(640, 640), max_size=640, sample_style='choice')]
[12/10 22:37:56 d2.data.common]: Serializing the dataset using: <class 'detectron2.data.common.NumpySerializedList'>
[12/10 22:37:56 d2.data.common]: Serializing 5000 elements to byte tensors and concatenating them all ...
[12/10 22:37:56 d2.data.common]: Serialized dataset takes 3.31 MiB
/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:481: UserWarning: This DataLoader will create 10 worker processes in total. Our suggested max number of worker in current system is 8, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.
  cpuset_checked))
[12/10 22:37:57 d2.evaluation.evaluator]: Start inference on 5000 batches
/usr/local/lib/python3.7/dist-packages/torch/functional.py:445: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at  ../aten/src/ATen/native/TensorShape.cpp:2157.)
  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]
[12/10 22:37:59 d2.evaluation.evaluator]: Inference done 11/5000. Dataloading: 0.0004 s/iter. Inference: 0.0505 s/iter. Eval: 0.0337 s/iter. Total: 0.0846 s/iter. ETA=0:07:02
[12/10 22:38:04 d2.evaluation.evaluator]: Inference done 76/5000. Dataloading: 0.0010 s/iter. Inference: 0.0482 s/iter. Eval: 0.0299 s/iter. Total: 0.0791 s/iter. ETA=0:06:29
[12/10 22:38:09 d2.evaluation.evaluator]: Inference done 134/5000. Dataloading: 0.0010 s/iter. Inference: 0.0497 s/iter. Eval: 0.0317 s/iter. Total: 0.0824 s/iter. ETA=0:06:40
[12/10 22:38:14 d2.evaluation.evaluator]: Inference done 193/5000. Dataloading: 0.0010 s/iter. Inference: 0.0502 s/iter. Eval: 0.0322 s/iter. Total: 0.0834 s/iter. ETA=0:06:41
[12/10 22:38:19 d2.evaluation.evaluator]: Inference done 254/5000. Dataloading: 0.0010 s/iter. Inference: 0.0505 s/iter. Eval: 0.0319 s/iter. Total: 0.0834 s/iter. ETA=0:06:36
[12/10 22:38:24 d2.evaluation.evaluator]: Inference done 315/5000. Dataloading: 0.0010 s/iter. Inference: 0.0504 s/iter. Eval: 0.0318 s/iter. Total: 0.0833 s/iter. ETA=0:06:30
[12/10 22:38:29 d2.evaluation.evaluator]: Inference done 375/5000. Dataloading: 0.0010 s/iter. Inference: 0.0505 s/iter. Eval: 0.0318 s/iter. Total: 0.0834 s/iter. ETA=0:06:25
[12/10 22:38:34 d2.evaluation.evaluator]: Inference done 437/5000. Dataloading: 0.0010 s/iter. Inference: 0.0504 s/iter. Eval: 0.0317 s/iter. Total: 0.0831 s/iter. ETA=0:06:19
[12/10 22:38:39 d2.evaluation.evaluator]: Inference done 497/5000. Dataloading: 0.0010 s/iter. Inference: 0.0504 s/iter. Eval: 0.0316 s/iter. Total: 0.0831 s/iter. ETA=0:06:14
[12/10 22:38:44 d2.evaluation.evaluator]: Inference done 557/5000. Dataloading: 0.0010 s/iter. Inference: 0.0505 s/iter. Eval: 0.0317 s/iter. Total: 0.0833 s/iter. ETA=0:06:10
[12/10 22:38:49 d2.evaluation.evaluator]: Inference done 617/5000. Dataloading: 0.0010 s/iter. Inference: 0.0506 s/iter. Eval: 0.0317 s/iter. Total: 0.0834 s/iter. ETA=0:06:05
[12/10 22:38:54 d2.evaluation.evaluator]: Inference done 674/5000. Dataloading: 0.0010 s/iter. Inference: 0.0508 s/iter. Eval: 0.0319 s/iter. Total: 0.0838 s/iter. ETA=0:06:02
[12/10 22:38:59 d2.evaluation.evaluator]: Inference done 733/5000. Dataloading: 0.0010 s/iter. Inference: 0.0509 s/iter. Eval: 0.0319 s/iter. Total: 0.0839 s/iter. ETA=0:05:58
[12/10 22:39:04 d2.evaluation.evaluator]: Inference done 789/5000. Dataloading: 0.0010 s/iter. Inference: 0.0513 s/iter. Eval: 0.0319 s/iter. Total: 0.0843 s/iter. ETA=0:05:55
[12/10 22:39:09 d2.evaluation.evaluator]: Inference done 850/5000. Dataloading: 0.0010 s/iter. Inference: 0.0513 s/iter. Eval: 0.0318 s/iter. Total: 0.0842 s/iter. ETA=0:05:49
[12/10 22:39:14 d2.evaluation.evaluator]: Inference done 911/5000. Dataloading: 0.0010 s/iter. Inference: 0.0513 s/iter. Eval: 0.0317 s/iter. Total: 0.0841 s/iter. ETA=0:05:43
[12/10 22:39:19 d2.evaluation.evaluator]: Inference done 972/5000. Dataloading: 0.0010 s/iter. Inference: 0.0512 s/iter. Eval: 0.0317 s/iter. Total: 0.0840 s/iter. ETA=0:05:38
[12/10 22:39:24 d2.evaluation.evaluator]: Inference done 1033/5000. Dataloading: 0.0010 s/iter. Inference: 0.0512 s/iter. Eval: 0.0316 s/iter. Total: 0.0839 s/iter. ETA=0:05:32
[12/10 22:39:29 d2.evaluation.evaluator]: Inference done 1095/5000. Dataloading: 0.0010 s/iter. Inference: 0.0511 s/iter. Eval: 0.0316 s/iter. Total: 0.0837 s/iter. ETA=0:05:26
[12/10 22:39:34 d2.evaluation.evaluator]: Inference done 1157/5000. Dataloading: 0.0010 s/iter. Inference: 0.0509 s/iter. Eval: 0.0315 s/iter. Total: 0.0836 s/iter. ETA=0:05:21
[12/10 22:39:39 d2.evaluation.evaluator]: Inference done 1216/5000. Dataloading: 0.0010 s/iter. Inference: 0.0510 s/iter. Eval: 0.0316 s/iter. Total: 0.0837 s/iter. ETA=0:05:16
[12/10 22:39:44 d2.evaluation.evaluator]: Inference done 1274/5000. Dataloading: 0.0010 s/iter. Inference: 0.0511 s/iter. Eval: 0.0317 s/iter. Total: 0.0839 s/iter. ETA=0:05:12
[12/10 22:39:50 d2.evaluation.evaluator]: Inference done 1334/5000. Dataloading: 0.0010 s/iter. Inference: 0.0511 s/iter. Eval: 0.0317 s/iter. Total: 0.0839 s/iter. ETA=0:05:07
[12/10 22:39:55 d2.evaluation.evaluator]: Inference done 1395/5000. Dataloading: 0.0010 s/iter. Inference: 0.0510 s/iter. Eval: 0.0317 s/iter. Total: 0.0838 s/iter. ETA=0:05:02
[12/10 22:40:00 d2.evaluation.evaluator]: Inference done 1456/5000. Dataloading: 0.0010 s/iter. Inference: 0.0510 s/iter. Eval: 0.0317 s/iter. Total: 0.0838 s/iter. ETA=0:04:56
[12/10 22:40:05 d2.evaluation.evaluator]: Inference done 1516/5000. Dataloading: 0.0010 s/iter. Inference: 0.0509 s/iter. Eval: 0.0318 s/iter. Total: 0.0838 s/iter. ETA=0:04:51
[12/10 22:40:10 d2.evaluation.evaluator]: Inference done 1575/5000. Dataloading: 0.0010 s/iter. Inference: 0.0509 s/iter. Eval: 0.0318 s/iter. Total: 0.0838 s/iter. ETA=0:04:47
[12/10 22:40:15 d2.evaluation.evaluator]: Inference done 1634/5000. Dataloading: 0.0010 s/iter. Inference: 0.0510 s/iter. Eval: 0.0319 s/iter. Total: 0.0839 s/iter. ETA=0:04:42
[12/10 22:40:20 d2.evaluation.evaluator]: Inference done 1693/5000. Dataloading: 0.0010 s/iter. Inference: 0.0510 s/iter. Eval: 0.0319 s/iter. Total: 0.0840 s/iter. ETA=0:04:37
[12/10 22:40:25 d2.evaluation.evaluator]: Inference done 1756/5000. Dataloading: 0.0010 s/iter. Inference: 0.0509 s/iter. Eval: 0.0318 s/iter. Total: 0.0839 s/iter. ETA=0:04:32
[12/10 22:40:30 d2.evaluation.evaluator]: Inference done 1818/5000. Dataloading: 0.0010 s/iter. Inference: 0.0509 s/iter. Eval: 0.0318 s/iter. Total: 0.0838 s/iter. ETA=0:04:26
[12/10 22:40:35 d2.evaluation.evaluator]: Inference done 1877/5000. Dataloading: 0.0010 s/iter. Inference: 0.0509 s/iter. Eval: 0.0318 s/iter. Total: 0.0838 s/iter. ETA=0:04:21
[12/10 22:40:40 d2.evaluation.evaluator]: Inference done 1938/5000. Dataloading: 0.0010 s/iter. Inference: 0.0509 s/iter. Eval: 0.0318 s/iter. Total: 0.0838 s/iter. ETA=0:04:16
[12/10 22:40:45 d2.evaluation.evaluator]: Inference done 1999/5000. Dataloading: 0.0010 s/iter. Inference: 0.0508 s/iter. Eval: 0.0318 s/iter. Total: 0.0837 s/iter. ETA=0:04:11
[12/10 22:40:50 d2.evaluation.evaluator]: Inference done 2057/5000. Dataloading: 0.0010 s/iter. Inference: 0.0509 s/iter. Eval: 0.0319 s/iter. Total: 0.0838 s/iter. ETA=0:04:06
[12/10 22:40:55 d2.evaluation.evaluator]: Inference done 2118/5000. Dataloading: 0.0010 s/iter. Inference: 0.0509 s/iter. Eval: 0.0318 s/iter. Total: 0.0838 s/iter. ETA=0:04:01
[12/10 22:41:00 d2.evaluation.evaluator]: Inference done 2179/5000. Dataloading: 0.0010 s/iter. Inference: 0.0508 s/iter. Eval: 0.0318 s/iter. Total: 0.0838 s/iter. ETA=0:03:56
[12/10 22:41:05 d2.evaluation.evaluator]: Inference done 2240/5000. Dataloading: 0.0010 s/iter. Inference: 0.0508 s/iter. Eval: 0.0318 s/iter. Total: 0.0837 s/iter. ETA=0:03:51
[12/10 22:41:10 d2.evaluation.evaluator]: Inference done 2302/5000. Dataloading: 0.0010 s/iter. Inference: 0.0508 s/iter. Eval: 0.0318 s/iter. Total: 0.0837 s/iter. ETA=0:03:45
[12/10 22:41:15 d2.evaluation.evaluator]: Inference done 2365/5000. Dataloading: 0.0010 s/iter. Inference: 0.0508 s/iter. Eval: 0.0317 s/iter. Total: 0.0836 s/iter. ETA=0:03:40
[12/10 22:41:20 d2.evaluation.evaluator]: Inference done 2420/5000. Dataloading: 0.0010 s/iter. Inference: 0.0509 s/iter. Eval: 0.0318 s/iter. Total: 0.0838 s/iter. ETA=0:03:36
[12/10 22:41:25 d2.evaluation.evaluator]: Inference done 2480/5000. Dataloading: 0.0010 s/iter. Inference: 0.0509 s/iter. Eval: 0.0318 s/iter. Total: 0.0838 s/iter. ETA=0:03:31
[12/10 22:41:30 d2.evaluation.evaluator]: Inference done 2541/5000. Dataloading: 0.0010 s/iter. Inference: 0.0508 s/iter. Eval: 0.0318 s/iter. Total: 0.0837 s/iter. ETA=0:03:25
[12/10 22:41:35 d2.evaluation.evaluator]: Inference done 2601/5000. Dataloading: 0.0010 s/iter. Inference: 0.0508 s/iter. Eval: 0.0318 s/iter. Total: 0.0837 s/iter. ETA=0:03:20
[12/10 22:41:41 d2.evaluation.evaluator]: Inference done 2660/5000. Dataloading: 0.0010 s/iter. Inference: 0.0509 s/iter. Eval: 0.0318 s/iter. Total: 0.0838 s/iter. ETA=0:03:16
[12/10 22:41:46 d2.evaluation.evaluator]: Inference done 2725/5000. Dataloading: 0.0010 s/iter. Inference: 0.0508 s/iter. Eval: 0.0318 s/iter. Total: 0.0837 s/iter. ETA=0:03:10
[12/10 22:41:51 d2.evaluation.evaluator]: Inference done 2787/5000. Dataloading: 0.0010 s/iter. Inference: 0.0508 s/iter. Eval: 0.0318 s/iter. Total: 0.0836 s/iter. ETA=0:03:05
[12/10 22:41:56 d2.evaluation.evaluator]: Inference done 2849/5000. Dataloading: 0.0010 s/iter. Inference: 0.0507 s/iter. Eval: 0.0318 s/iter. Total: 0.0835 s/iter. ETA=0:02:59
[12/10 22:42:01 d2.evaluation.evaluator]: Inference done 2909/5000. Dataloading: 0.0010 s/iter. Inference: 0.0507 s/iter. Eval: 0.0317 s/iter. Total: 0.0835 s/iter. ETA=0:02:54
[12/10 22:42:06 d2.evaluation.evaluator]: Inference done 2970/5000. Dataloading: 0.0010 s/iter. Inference: 0.0507 s/iter. Eval: 0.0317 s/iter. Total: 0.0835 s/iter. ETA=0:02:49
[12/10 22:42:11 d2.evaluation.evaluator]: Inference done 3032/5000. Dataloading: 0.0010 s/iter. Inference: 0.0507 s/iter. Eval: 0.0317 s/iter. Total: 0.0835 s/iter. ETA=0:02:44
[12/10 22:42:16 d2.evaluation.evaluator]: Inference done 3096/5000. Dataloading: 0.0010 s/iter. Inference: 0.0506 s/iter. Eval: 0.0317 s/iter. Total: 0.0834 s/iter. ETA=0:02:38
[12/10 22:42:21 d2.evaluation.evaluator]: Inference done 3154/5000. Dataloading: 0.0010 s/iter. Inference: 0.0507 s/iter. Eval: 0.0317 s/iter. Total: 0.0834 s/iter. ETA=0:02:34
[12/10 22:42:26 d2.evaluation.evaluator]: Inference done 3213/5000. Dataloading: 0.0010 s/iter. Inference: 0.0507 s/iter. Eval: 0.0317 s/iter. Total: 0.0835 s/iter. ETA=0:02:29
[12/10 22:42:31 d2.evaluation.evaluator]: Inference done 3272/5000. Dataloading: 0.0010 s/iter. Inference: 0.0507 s/iter. Eval: 0.0317 s/iter. Total: 0.0835 s/iter. ETA=0:02:24
[12/10 22:42:36 d2.evaluation.evaluator]: Inference done 3330/5000. Dataloading: 0.0010 s/iter. Inference: 0.0507 s/iter. Eval: 0.0318 s/iter. Total: 0.0836 s/iter. ETA=0:02:19
[12/10 22:42:41 d2.evaluation.evaluator]: Inference done 3387/5000. Dataloading: 0.0010 s/iter. Inference: 0.0508 s/iter. Eval: 0.0318 s/iter. Total: 0.0837 s/iter. ETA=0:02:14
[12/10 22:42:46 d2.evaluation.evaluator]: Inference done 3447/5000. Dataloading: 0.0010 s/iter. Inference: 0.0508 s/iter. Eval: 0.0318 s/iter. Total: 0.0837 s/iter. ETA=0:02:09
[12/10 22:42:51 d2.evaluation.evaluator]: Inference done 3510/5000. Dataloading: 0.0010 s/iter. Inference: 0.0507 s/iter. Eval: 0.0318 s/iter. Total: 0.0836 s/iter. ETA=0:02:04
[12/10 22:42:56 d2.evaluation.evaluator]: Inference done 3570/5000. Dataloading: 0.0010 s/iter. Inference: 0.0507 s/iter. Eval: 0.0318 s/iter. Total: 0.0836 s/iter. ETA=0:01:59
[12/10 22:43:01 d2.evaluation.evaluator]: Inference done 3629/5000. Dataloading: 0.0010 s/iter. Inference: 0.0508 s/iter. Eval: 0.0318 s/iter. Total: 0.0836 s/iter. ETA=0:01:54
[12/10 22:43:06 d2.evaluation.evaluator]: Inference done 3691/5000. Dataloading: 0.0010 s/iter. Inference: 0.0507 s/iter. Eval: 0.0318 s/iter. Total: 0.0836 s/iter. ETA=0:01:49
[12/10 22:43:11 d2.evaluation.evaluator]: Inference done 3752/5000. Dataloading: 0.0010 s/iter. Inference: 0.0507 s/iter. Eval: 0.0318 s/iter. Total: 0.0836 s/iter. ETA=0:01:44
[12/10 22:43:16 d2.evaluation.evaluator]: Inference done 3810/5000. Dataloading: 0.0010 s/iter. Inference: 0.0508 s/iter. Eval: 0.0318 s/iter. Total: 0.0836 s/iter. ETA=0:01:39
[12/10 22:43:21 d2.evaluation.evaluator]: Inference done 3874/5000. Dataloading: 0.0010 s/iter. Inference: 0.0507 s/iter. Eval: 0.0317 s/iter. Total: 0.0836 s/iter. ETA=0:01:34
[12/10 22:43:26 d2.evaluation.evaluator]: Inference done 3936/5000. Dataloading: 0.0010 s/iter. Inference: 0.0507 s/iter. Eval: 0.0317 s/iter. Total: 0.0835 s/iter. ETA=0:01:28
[12/10 22:43:31 d2.evaluation.evaluator]: Inference done 4000/5000. Dataloading: 0.0010 s/iter. Inference: 0.0507 s/iter. Eval: 0.0317 s/iter. Total: 0.0835 s/iter. ETA=0:01:23
[12/10 22:43:37 d2.evaluation.evaluator]: Inference done 4060/5000. Dataloading: 0.0010 s/iter. Inference: 0.0506 s/iter. Eval: 0.0317 s/iter. Total: 0.0835 s/iter. ETA=0:01:18
[12/10 22:43:42 d2.evaluation.evaluator]: Inference done 4120/5000. Dataloading: 0.0010 s/iter. Inference: 0.0506 s/iter. Eval: 0.0317 s/iter. Total: 0.0835 s/iter. ETA=0:01:13
[12/10 22:43:47 d2.evaluation.evaluator]: Inference done 4178/5000. Dataloading: 0.0010 s/iter. Inference: 0.0506 s/iter. Eval: 0.0318 s/iter. Total: 0.0835 s/iter. ETA=0:01:08
[12/10 22:43:52 d2.evaluation.evaluator]: Inference done 4241/5000. Dataloading: 0.0010 s/iter. Inference: 0.0506 s/iter. Eval: 0.0318 s/iter. Total: 0.0835 s/iter. ETA=0:01:03
[12/10 22:43:57 d2.evaluation.evaluator]: Inference done 4301/5000. Dataloading: 0.0010 s/iter. Inference: 0.0506 s/iter. Eval: 0.0318 s/iter. Total: 0.0835 s/iter. ETA=0:00:58
[12/10 22:44:02 d2.evaluation.evaluator]: Inference done 4365/5000. Dataloading: 0.0010 s/iter. Inference: 0.0506 s/iter. Eval: 0.0317 s/iter. Total: 0.0834 s/iter. ETA=0:00:52
[12/10 22:44:07 d2.evaluation.evaluator]: Inference done 4426/5000. Dataloading: 0.0010 s/iter. Inference: 0.0506 s/iter. Eval: 0.0317 s/iter. Total: 0.0834 s/iter. ETA=0:00:47
[12/10 22:44:12 d2.evaluation.evaluator]: Inference done 4488/5000. Dataloading: 0.0010 s/iter. Inference: 0.0505 s/iter. Eval: 0.0317 s/iter. Total: 0.0834 s/iter. ETA=0:00:42
[12/10 22:44:17 d2.evaluation.evaluator]: Inference done 4550/5000. Dataloading: 0.0010 s/iter. Inference: 0.0505 s/iter. Eval: 0.0317 s/iter. Total: 0.0833 s/iter. ETA=0:00:37
[12/10 22:44:22 d2.evaluation.evaluator]: Inference done 4611/5000. Dataloading: 0.0010 s/iter. Inference: 0.0505 s/iter. Eval: 0.0317 s/iter. Total: 0.0833 s/iter. ETA=0:00:32
[12/10 22:44:27 d2.evaluation.evaluator]: Inference done 4670/5000. Dataloading: 0.0010 s/iter. Inference: 0.0505 s/iter. Eval: 0.0318 s/iter. Total: 0.0833 s/iter. ETA=0:00:27
[12/10 22:44:32 d2.evaluation.evaluator]: Inference done 4731/5000. Dataloading: 0.0010 s/iter. Inference: 0.0505 s/iter. Eval: 0.0318 s/iter. Total: 0.0833 s/iter. ETA=0:00:22
[12/10 22:44:37 d2.evaluation.evaluator]: Inference done 4793/5000. Dataloading: 0.0010 s/iter. Inference: 0.0505 s/iter. Eval: 0.0318 s/iter. Total: 0.0833 s/iter. ETA=0:00:17
[12/10 22:44:42 d2.evaluation.evaluator]: Inference done 4851/5000. Dataloading: 0.0010 s/iter. Inference: 0.0505 s/iter. Eval: 0.0318 s/iter. Total: 0.0834 s/iter. ETA=0:00:12
[12/10 22:44:47 d2.evaluation.evaluator]: Inference done 4913/5000. Dataloading: 0.0010 s/iter. Inference: 0.0505 s/iter. Eval: 0.0318 s/iter. Total: 0.0833 s/iter. ETA=0:00:07
[12/10 22:44:52 d2.evaluation.evaluator]: Inference done 4974/5000. Dataloading: 0.0010 s/iter. Inference: 0.0505 s/iter. Eval: 0.0318 s/iter. Total: 0.0833 s/iter. ETA=0:00:02
[12/10 22:44:54 d2.evaluation.evaluator]: Total inference time: 0:06:56.280807 (0.083340 s / iter per device, on 1 devices)
[12/10 22:44:54 d2.evaluation.evaluator]: Total inference pure compute time: 0:04:12 (0.050460 s / iter per device, on 1 devices)
[12/10 22:44:54 d2.evaluation.panoptic_evaluation]: Writing all panoptic predictions to /tmp/panoptic_eval_ynjhv6u ...
[12/10 22:45:17 d2.evaluation.panoptic_evaluation]: Panoptic Evaluation Results:
|        |   PQ   |   SQ   |   RQ   |  #categories  |
|:------:|:------:|:------:|:------:|:-------------:|
|  All   | 14.856 | 60.523 | 20.033 |      133      |
| Things | 13.261 | 61.571 | 18.291 |      80       |
| Stuff  | 17.263 | 58.942 | 22.663 |      53       |
[12/10 22:45:17 d2.evaluation.coco_evaluation]: Preparing results for COCO format ...
[12/10 22:45:17 d2.evaluation.coco_evaluation]: Saving results to ./output/inference/coco_instances_results.json
[12/10 22:45:17 d2.evaluation.coco_evaluation]: Evaluating predictions with unofficial COCO API...
Loading and preparing results...
DONE (t=0.03s)
creating index...
index created!
[12/10 22:45:17 d2.evaluation.fast_eval_api]: Evaluate annotation type *bbox*
[12/10 22:45:25 d2.evaluation.fast_eval_api]: COCOeval_opt.evaluate() finished in 7.53 seconds.
[12/10 22:45:25 d2.evaluation.fast_eval_api]: Accumulating evaluation results...
[12/10 22:45:26 d2.evaluation.fast_eval_api]: COCOeval_opt.accumulate() finished in 0.60 seconds.
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.033
 Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.081
 Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.024
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.007
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.033
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.060
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.052
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.078
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.079
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.009
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.061
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.145
[12/10 22:45:26 d2.evaluation.coco_evaluation]: Evaluation results for bbox: 
|  AP   |  AP50  |  AP75  |  APs  |  APm  |  APl  |
|:-----:|:------:|:------:|:-----:|:-----:|:-----:|
| 3.343 | 8.072  | 2.433  | 0.665 | 3.347 | 5.976 |
[12/10 22:45:26 d2.evaluation.coco_evaluation]: Per-category bbox AP: 
| category      | AP     | category     | AP     | category       | AP     |
|:--------------|:-------|:-------------|:-------|:---------------|:-------|
| person        | 8.798  | bicycle      | 1.479  | car            | 3.659  |
| motorcycle    | 4.168  | airplane     | 12.765 | bus            | 12.316 |
| train         | 7.821  | truck        | 2.252  | boat           | 0.484  |
| traffic light | 2.014  | fire hydrant | 16.209 | stop sign      | 12.561 |
| parking meter | 1.134  | bench        | 0.870  | bird           | 3.401  |
| cat           | 7.247  | dog          | 8.670  | horse          | 9.336  |
| sheep         | 5.741  | cow          | 8.737  | elephant       | 12.101 |
| bear          | 13.653 | zebra        | 12.471 | giraffe        | 14.237 |
| backpack      | 0.000  | umbrella     | 2.150  | handbag        | 0.000  |
| tie           | 0.000  | suitcase     | 0.592  | frisbee        | 5.288  |
| skis          | 0.094  | snowboard    | 0.141  | sports ball    | 4.709  |
| kite          | 5.718  | baseball bat | 0.000  | baseball glove | 1.228  |
| skateboard    | 0.808  | surfboard    | 1.391  | tennis racket  | 4.687  |
| bottle        | 0.207  | wine glass   | 0.106  | cup            | 0.390  |
| fork          | 0.000  | knife        | 0.000  | spoon          | 0.000  |
| bowl          | 1.021  | banana       | 0.811  | apple          | 0.776  |
| sandwich      | 0.708  | orange       | 2.455  | broccoli       | 0.615  |
| carrot        | 0.263  | hot dog      | 0.198  | pizza          | 2.168  |
| donut         | 1.101  | cake         | 0.373  | chair          | 0.569  |
| couch         | 4.161  | potted plant | 0.473  | bed            | 6.719  |
| dining table  | 1.717  | toilet       | 6.011  | tv             | 6.483  |
| laptop        | 2.419  | mouse        | 4.127  | remote         | 0.297  |
| keyboard      | 0.759  | cell phone   | 0.327  | microwave      | 1.462  |
| oven          | 2.226  | toaster      | 0.000  | sink           | 0.913  |
| refrigerator  | 1.264  | book         | 0.451  | clock          | 2.718  |
| vase          | 0.491  | scissors     | 0.990  | teddy bear     | 2.731  |
| hair drier    | 0.000  | toothbrush   | 0.000  |                |        |
Loading and preparing results...
DONE (t=0.44s)
creating index...
index created!
[12/10 22:45:27 d2.evaluation.fast_eval_api]: Evaluate annotation type *segm*
[12/10 22:45:35 d2.evaluation.fast_eval_api]: COCOeval_opt.evaluate() finished in 8.53 seconds.
[12/10 22:45:35 d2.evaluation.fast_eval_api]: Accumulating evaluation results...
[12/10 22:45:36 d2.evaluation.fast_eval_api]: COCOeval_opt.accumulate() finished in 0.65 seconds.
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.035
 Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.085
 Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.025
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.004
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.035
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.089
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.051
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.071
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.072
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.008
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.059
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.134
[12/10 22:45:38 d2.evaluation.coco_evaluation]: Evaluation results for segm: 
|  AP   |  AP50  |  AP75  |  APs  |  APm  |  APl  |
|:-----:|:------:|:------:|:-----:|:-----:|:-----:|
| 3.518 | 8.550  | 2.458  | 0.426 | 3.541 | 8.851 |
[12/10 22:45:38 d2.evaluation.coco_evaluation]: Per-category segm AP: 
| category      | AP     | category     | AP     | category       | AP     |
|:--------------|:-------|:-------------|:-------|:---------------|:-------|
| person        | 5.682  | bicycle      | 0.819  | car            | 3.546  |
| motorcycle    | 2.017  | airplane     | 6.705  | bus            | 10.558 |
| train         | 12.680 | truck        | 1.874  | boat           | 0.271  |
| traffic light | 2.317  | fire hydrant | 19.364 | stop sign      | 20.557 |
| parking meter | 9.601  | bench        | 0.633  | bird           | 2.543  |
| cat           | 9.479  | dog          | 11.266 | horse          | 4.700  |
| sheep         | 5.291  | cow          | 7.620  | elephant       | 10.277 |
| bear          | 20.651 | zebra        | 7.355  | giraffe        | 9.809  |
| backpack      | 0.000  | umbrella     | 3.685  | handbag        | 0.000  |
| tie           | 0.000  | suitcase     | 1.112  | frisbee        | 5.837  |
| skis          | 0.000  | snowboard    | 0.198  | sports ball    | 5.307  |
| kite          | 1.896  | baseball bat | 0.059  | baseball glove | 1.898  |
| skateboard    | 0.089  | surfboard    | 1.317  | tennis racket  | 11.426 |
| bottle        | 0.247  | wine glass   | 0.122  | cup            | 1.030  |
| fork          | 0.000  | knife        | 0.000  | spoon          | 0.000  |
| bowl          | 1.140  | banana       | 0.251  | apple          | 0.115  |
| sandwich      | 0.465  | orange       | 3.694  | broccoli       | 0.813  |
| carrot        | 0.252  | hot dog      | 0.000  | pizza          | 2.090  |
| donut         | 2.945  | cake         | 0.505  | chair          | 0.306  |
| couch         | 2.737  | potted plant | 0.355  | bed            | 4.710  |
| dining table  | 0.125  | toilet       | 9.687  | tv             | 8.297  |
| laptop        | 2.413  | mouse        | 4.613  | remote         | 0.297  |
| keyboard      | 0.646  | cell phone   | 0.388  | microwave      | 2.210  |
| oven          | 1.348  | toaster      | 0.000  | sink           | 1.495  |
| refrigerator  | 0.983  | book         | 0.218  | clock          | 5.090  |
| vase          | 0.722  | scissors     | 0.099  | teddy bear     | 2.576  |
| hair drier    | 0.000  | toothbrush   | 0.000  |                |        |
[12/10 22:45:40 d2.engine.defaults]: Evaluation results for coco_2017_val_panoptic in csv format:
[12/10 22:45:40 d2.evaluation.testing]: copypaste: Task: panoptic_seg
[12/10 22:45:40 d2.evaluation.testing]: copypaste: PQ,SQ,RQ,PQ_th,SQ_th,RQ_th,PQ_st,SQ_st,RQ_st
[12/10 22:45:40 d2.evaluation.testing]: copypaste: 14.8558,60.5232,20.0332,13.2608,61.5709,18.2909,17.2635,58.9419,22.6631
[12/10 22:45:40 d2.evaluation.testing]: copypaste: Task: bbox
[12/10 22:45:40 d2.evaluation.testing]: copypaste: AP,AP50,AP75,APs,APm,APl
[12/10 22:45:40 d2.evaluation.testing]: copypaste: 3.3429,8.0717,2.4331,0.6648,3.3472,5.9761
[12/10 22:45:40 d2.evaluation.testing]: copypaste: Task: segm
[12/10 22:45:40 d2.evaluation.testing]: copypaste: AP,AP50,AP75,APs,APm,APl
[12/10 22:45:40 d2.evaluation.testing]: copypaste: 3.5178,8.5496,2.4584,0.4265,3.5414,8.8508