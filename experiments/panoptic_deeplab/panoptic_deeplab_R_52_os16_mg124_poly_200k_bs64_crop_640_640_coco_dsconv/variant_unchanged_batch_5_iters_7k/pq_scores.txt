env: DETECTRON2_DATASETS=/content/datasets
Command Line Args: Namespace(config_file='./detectron2/projects/Panoptic-DeepLab/configs/COCO-PanopticSegmentation/panoptic_deeplab_R_52_os16_mg124_poly_200k_bs64_crop_640_640_coco_dsconv.yaml', dist_url='tcp://127.0.0.1:49152', eval_only=False, machine_rank=0, num_gpus=1, num_machines=1, opts=['MODEL.RESNETS.NORM', 'BN', 'MODEL.INS_EMBED_HEAD.NORM', 'BN', 'MODEL.SEM_SEG_HEAD.NORM', 'BN', 'SOLVER.MAX_ITER', '7000', 'SOLVER.IMS_PER_BATCH', '5', 'SOLVER.BASE_LR', '0.0025'], resume=False)
Loading config ./detectron2/projects/Panoptic-DeepLab/configs/COCO-PanopticSegmentation/panoptic_deeplab_R_52_os16_mg124_poly_200k_bs64_crop_640_640_coco_dsconv.yaml with yaml.unsafe_load. Your machine may be at risk if the file contains malicious content.
[12/09 09:23:41 detectron2]: Rank of current process: 0. World size: 1
[12/09 09:23:42 detectron2]: Environment info:
----------------------  ----------------------------------------------------------------
sys.platform            linux
Python                  3.7.12 (default, Jan 15 2022, 18:48:18) [GCC 7.5.0]
numpy                   1.21.5
detectron2              0.6 @/content/detectron2/detectron2
Compiler                GCC 7.5
CUDA compiler           CUDA 11.1
detectron2 arch flags   7.0
DETECTRON2_ENV_MODULE   <not set>
PyTorch                 1.10.0+cu111 @/usr/local/lib/python3.7/dist-packages/torch
PyTorch debug build     False
GPU available           Yes
GPU 0                   Tesla V100-SXM2-16GB (arch=7.0)
Driver version          460.32.03
CUDA_HOME               /usr/local/cuda
Pillow                  7.1.2
torchvision             0.11.1+cu111 @/usr/local/lib/python3.7/dist-packages/torchvision
torchvision arch flags  3.5, 5.0, 6.0, 7.0, 7.5, 8.0, 8.6
fvcore                  0.1.5.post20221122
iopath                  0.1.9
cv2                     4.1.2
----------------------  ----------------------------------------------------------------
PyTorch built with:
  - GCC 7.3
  - C++ Version: 201402
  - Intel(R) Math Kernel Library Version 2020.0.0 Product Build 20191122 for Intel(R) 64 architecture applications
  - Intel(R) MKL-DNN v2.2.3 (Git Hash 7336ca9f055cf1bfa13efb658fe15dc9b41f0740)
  - OpenMP 201511 (a.k.a. OpenMP 4.5)
  - LAPACK is enabled (usually provided by MKL)
  - NNPACK is enabled
  - CPU capability usage: AVX2
  - CUDA Runtime 11.1
  - NVCC architecture flags: -gencode;arch=compute_37,code=sm_37;-gencode;arch=compute_50,code=sm_50;-gencode;arch=compute_60,code=sm_60;-gencode;arch=compute_70,code=sm_70;-gencode;arch=compute_75,code=sm_75;-gencode;arch=compute_80,code=sm_80;-gencode;arch=compute_86,code=sm_86
  - CuDNN 8.0.5
  - Magma 2.5.2
  - Build settings: BLAS_INFO=mkl, BUILD_TYPE=Release, CUDA_VERSION=11.1, CUDNN_VERSION=8.0.5, CXX_COMPILER=/opt/rh/devtoolset-7/root/usr/bin/c++, CXX_FLAGS= -Wno-deprecated -fvisibility-inlines-hidden -DUSE_PTHREADPOOL -fopenmp -DNDEBUG -DUSE_KINETO -DUSE_FBGEMM -DUSE_QNNPACK -DUSE_PYTORCH_QNNPACK -DUSE_XNNPACK -DSYMBOLICATE_MOBILE_DEBUG_HANDLE -DEDGE_PROFILER_USE_KINETO -O2 -fPIC -Wno-narrowing -Wall -Wextra -Werror=return-type -Wno-missing-field-initializers -Wno-type-limits -Wno-array-bounds -Wno-unknown-pragmas -Wno-sign-compare -Wno-unused-parameter -Wno-unused-variable -Wno-unused-function -Wno-unused-result -Wno-unused-local-typedefs -Wno-strict-overflow -Wno-strict-aliasing -Wno-error=deprecated-declarations -Wno-stringop-overflow -Wno-psabi -Wno-error=pedantic -Wno-error=redundant-decls -Wno-error=old-style-cast -fdiagnostics-color=always -faligned-new -Wno-unused-but-set-variable -Wno-maybe-uninitialized -fno-math-errno -fno-trapping-math -Werror=format -Wno-stringop-overflow, LAPACK_INFO=mkl, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, TORCH_VERSION=1.10.0, USE_CUDA=ON, USE_CUDNN=ON, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_MKL=ON, USE_MKLDNN=ON, USE_MPI=OFF, USE_NCCL=ON, USE_NNPACK=ON, USE_OPENMP=ON, 

[12/09 09:23:42 detectron2]: Command line arguments: Namespace(config_file='./detectron2/projects/Panoptic-DeepLab/configs/COCO-PanopticSegmentation/panoptic_deeplab_R_52_os16_mg124_poly_200k_bs64_crop_640_640_coco_dsconv.yaml', dist_url='tcp://127.0.0.1:49152', eval_only=False, machine_rank=0, num_gpus=1, num_machines=1, opts=['MODEL.RESNETS.NORM', 'BN', 'MODEL.INS_EMBED_HEAD.NORM', 'BN', 'MODEL.SEM_SEG_HEAD.NORM', 'BN', 'SOLVER.MAX_ITER', '7000', 'SOLVER.IMS_PER_BATCH', '5', 'SOLVER.BASE_LR', '0.0025'], resume=False)
[12/09 09:23:42 detectron2]: Contents of args.config_file=./detectron2/projects/Panoptic-DeepLab/configs/COCO-PanopticSegmentation/panoptic_deeplab_R_52_os16_mg124_poly_200k_bs64_crop_640_640_coco_dsconv.yaml:
_BASE_: ../Cityscapes-PanopticSegmentation/Base-PanopticDeepLab-OS16.yaml
MODEL:
  WEIGHTS: "detectron2://DeepLab/R-52.pkl"
  PIXEL_MEAN: [123.675, 116.280, 103.530]
  PIXEL_STD: [58.395, 57.120, 57.375]
  BACKBONE:
    NAME: "build_resnet_deeplab_backbone"
  RESNETS:
    DEPTH: 50
    NORM: "SyncBN"
    RES5_MULTI_GRID: [1, 2, 4]
    STEM_TYPE: "deeplab"
    STEM_OUT_CHANNELS: 128
    STRIDE_IN_1X1: False
  SEM_SEG_HEAD:
    NUM_CLASSES: 133
    LOSS_TOP_K: 1.0
    USE_DEPTHWISE_SEPARABLE_CONV: True
  PANOPTIC_DEEPLAB:
    STUFF_AREA: 4096
    NMS_KERNEL: 41
    SIZE_DIVISIBILITY: 640
    USE_DEPTHWISE_SEPARABLE_CONV: True
DATASETS:
  TRAIN: ("coco_2017_train_panoptic",)
  TEST: ("coco_2017_val_panoptic",)
SOLVER:
  BASE_LR: 0.0005
  MAX_ITER: 200000
  IMS_PER_BATCH: 64
INPUT:
  FORMAT: "RGB"
  GAUSSIAN_SIGMA: 8
  MIN_SIZE_TRAIN: !!python/object/apply:eval ["[int(x * 0.1 * 640) for x in range(5, 16)]"]
  MIN_SIZE_TRAIN_SAMPLING: "choice"
  MIN_SIZE_TEST: 640
  MAX_SIZE_TRAIN: 960
  MAX_SIZE_TEST: 640
  CROP:
    ENABLED: True
    TYPE: "absolute"
    SIZE: (640, 640)

[12/09 09:23:42 detectron2]: Running with full config:
CUDNN_BENCHMARK: false
DATALOADER:
  ASPECT_RATIO_GROUPING: true
  FILTER_EMPTY_ANNOTATIONS: true
  NUM_WORKERS: 10
  REPEAT_THRESHOLD: 0.0
  SAMPLER_TRAIN: TrainingSampler
DATASETS:
  PRECOMPUTED_PROPOSAL_TOPK_TEST: 1000
  PRECOMPUTED_PROPOSAL_TOPK_TRAIN: 2000
  PROPOSAL_FILES_TEST: []
  PROPOSAL_FILES_TRAIN: []
  TEST:
  - coco_2017_val_panoptic
  TRAIN:
  - coco_2017_train_panoptic
GLOBAL:
  HACK: 1.0
INPUT:
  CROP:
    ENABLED: true
    SINGLE_CATEGORY_MAX_AREA: 1.0
    SIZE:
    - 640
    - 640
    TYPE: absolute
  FORMAT: RGB
  GAUSSIAN_SIGMA: 8
  IGNORE_CROWD_IN_SEMANTIC: false
  IGNORE_STUFF_IN_OFFSET: true
  MASK_FORMAT: polygon
  MAX_SIZE_TEST: 640
  MAX_SIZE_TRAIN: 960
  MIN_SIZE_TEST: 640
  MIN_SIZE_TRAIN:
  - 320
  - 384
  - 448
  - 512
  - 576
  - 640
  - 704
  - 768
  - 832
  - 896
  - 960
  MIN_SIZE_TRAIN_SAMPLING: choice
  RANDOM_FLIP: horizontal
  SMALL_INSTANCE_AREA: 4096
  SMALL_INSTANCE_WEIGHT: 3
MODEL:
  ANCHOR_GENERATOR:
    ANGLES:
    - - -90
      - 0
      - 90
    ASPECT_RATIOS:
    - - 0.5
      - 1.0
      - 2.0
    NAME: DefaultAnchorGenerator
    OFFSET: 0.0
    SIZES:
    - - 32
      - 64
      - 128
      - 256
      - 512
  BACKBONE:
    FREEZE_AT: 0
    NAME: build_resnet_deeplab_backbone
  DEVICE: cuda
  FPN:
    FUSE_TYPE: sum
    IN_FEATURES: []
    NORM: ''
    OUT_CHANNELS: 256
  INS_EMBED_HEAD:
    ASPP_CHANNELS: 256
    ASPP_DILATIONS:
    - 6
    - 12
    - 18
    ASPP_DROPOUT: 0.1
    CENTER_LOSS_WEIGHT: 200.0
    COMMON_STRIDE: 4
    CONVS_DIM: 128
    HEAD_CHANNELS: 32
    IN_FEATURES:
    - res2
    - res3
    - res5
    NAME: PanopticDeepLabInsEmbedHead
    NORM: BN
    OFFSET_LOSS_WEIGHT: 0.01
    PROJECT_CHANNELS:
    - 32
    - 64
    PROJECT_FEATURES:
    - res2
    - res3
  KEYPOINT_ON: false
  LOAD_PROPOSALS: false
  MASK_ON: false
  META_ARCHITECTURE: PanopticDeepLab
  PANOPTIC_DEEPLAB:
    BENCHMARK_NETWORK_SPEED: false
    CENTER_THRESHOLD: 0.1
    NMS_KERNEL: 41
    PREDICT_INSTANCES: true
    SIZE_DIVISIBILITY: 640
    STUFF_AREA: 4096
    TOP_K_INSTANCE: 200
    USE_DEPTHWISE_SEPARABLE_CONV: true
  PANOPTIC_FPN:
    COMBINE:
      ENABLED: true
      INSTANCES_CONFIDENCE_THRESH: 0.5
      OVERLAP_THRESH: 0.5
      STUFF_AREA_LIMIT: 4096
    INSTANCE_LOSS_WEIGHT: 1.0
  PIXEL_MEAN:
  - 123.675
  - 116.28
  - 103.53
  PIXEL_STD:
  - 58.395
  - 57.12
  - 57.375
  PROPOSAL_GENERATOR:
    MIN_SIZE: 0
    NAME: RPN
  RESNETS:
    DEFORM_MODULATED: false
    DEFORM_NUM_GROUPS: 1
    DEFORM_ON_PER_STAGE:
    - false
    - false
    - false
    - false
    DEPTH: 50
    NORM: BN
    NUM_GROUPS: 1
    OUT_FEATURES:
    - res2
    - res3
    - res5
    RES2_OUT_CHANNELS: 256
    RES4_DILATION: 1
    RES5_DILATION: 2
    RES5_MULTI_GRID:
    - 1
    - 2
    - 4
    STEM_OUT_CHANNELS: 128
    STEM_TYPE: deeplab
    STRIDE_IN_1X1: false
    WIDTH_PER_GROUP: 64
  RETINANET:
    BBOX_REG_LOSS_TYPE: smooth_l1
    BBOX_REG_WEIGHTS: &id001
    - 1.0
    - 1.0
    - 1.0
    - 1.0
    FOCAL_LOSS_ALPHA: 0.25
    FOCAL_LOSS_GAMMA: 2.0
    IN_FEATURES:
    - p3
    - p4
    - p5
    - p6
    - p7
    IOU_LABELS:
    - 0
    - -1
    - 1
    IOU_THRESHOLDS:
    - 0.4
    - 0.5
    NMS_THRESH_TEST: 0.5
    NORM: ''
    NUM_CLASSES: 80
    NUM_CONVS: 4
    PRIOR_PROB: 0.01
    SCORE_THRESH_TEST: 0.05
    SMOOTH_L1_LOSS_BETA: 0.1
    TOPK_CANDIDATES_TEST: 1000
  ROI_BOX_CASCADE_HEAD:
    BBOX_REG_WEIGHTS:
    - - 10.0
      - 10.0
      - 5.0
      - 5.0
    - - 20.0
      - 20.0
      - 10.0
      - 10.0
    - - 30.0
      - 30.0
      - 15.0
      - 15.0
    IOUS:
    - 0.5
    - 0.6
    - 0.7
  ROI_BOX_HEAD:
    BBOX_REG_LOSS_TYPE: smooth_l1
    BBOX_REG_LOSS_WEIGHT: 1.0
    BBOX_REG_WEIGHTS:
    - 10.0
    - 10.0
    - 5.0
    - 5.0
    CLS_AGNOSTIC_BBOX_REG: false
    CONV_DIM: 256
    FC_DIM: 1024
    FED_LOSS_FREQ_WEIGHT_POWER: 0.5
    FED_LOSS_NUM_CLASSES: 50
    NAME: ''
    NORM: ''
    NUM_CONV: 0
    NUM_FC: 0
    POOLER_RESOLUTION: 14
    POOLER_SAMPLING_RATIO: 0
    POOLER_TYPE: ROIAlignV2
    SMOOTH_L1_BETA: 0.0
    TRAIN_ON_PRED_BOXES: false
    USE_FED_LOSS: false
    USE_SIGMOID_CE: false
  ROI_HEADS:
    BATCH_SIZE_PER_IMAGE: 512
    IN_FEATURES:
    - res4
    IOU_LABELS:
    - 0
    - 1
    IOU_THRESHOLDS:
    - 0.5
    NAME: Res5ROIHeads
    NMS_THRESH_TEST: 0.5
    NUM_CLASSES: 80
    POSITIVE_FRACTION: 0.25
    PROPOSAL_APPEND_GT: true
    SCORE_THRESH_TEST: 0.05
  ROI_KEYPOINT_HEAD:
    CONV_DIMS:
    - 512
    - 512
    - 512
    - 512
    - 512
    - 512
    - 512
    - 512
    LOSS_WEIGHT: 1.0
    MIN_KEYPOINTS_PER_IMAGE: 1
    NAME: KRCNNConvDeconvUpsampleHead
    NORMALIZE_LOSS_BY_VISIBLE_KEYPOINTS: true
    NUM_KEYPOINTS: 17
    POOLER_RESOLUTION: 14
    POOLER_SAMPLING_RATIO: 0
    POOLER_TYPE: ROIAlignV2
  ROI_MASK_HEAD:
    CLS_AGNOSTIC_MASK: false
    CONV_DIM: 256
    NAME: MaskRCNNConvUpsampleHead
    NORM: ''
    NUM_CONV: 0
    POOLER_RESOLUTION: 14
    POOLER_SAMPLING_RATIO: 0
    POOLER_TYPE: ROIAlignV2
  RPN:
    BATCH_SIZE_PER_IMAGE: 256
    BBOX_REG_LOSS_TYPE: smooth_l1
    BBOX_REG_LOSS_WEIGHT: 1.0
    BBOX_REG_WEIGHTS: *id001
    BOUNDARY_THRESH: -1
    CONV_DIMS:
    - -1
    HEAD_NAME: StandardRPNHead
    IN_FEATURES:
    - res4
    IOU_LABELS:
    - 0
    - -1
    - 1
    IOU_THRESHOLDS:
    - 0.3
    - 0.7
    LOSS_WEIGHT: 1.0
    NMS_THRESH: 0.7
    POSITIVE_FRACTION: 0.5
    POST_NMS_TOPK_TEST: 1000
    POST_NMS_TOPK_TRAIN: 2000
    PRE_NMS_TOPK_TEST: 6000
    PRE_NMS_TOPK_TRAIN: 12000
    SMOOTH_L1_BETA: 0.0
  SEM_SEG_HEAD:
    ASPP_CHANNELS: 256
    ASPP_DILATIONS:
    - 6
    - 12
    - 18
    ASPP_DROPOUT: 0.1
    COMMON_STRIDE: 4
    CONVS_DIM: 256
    HEAD_CHANNELS: 256
    IGNORE_VALUE: 255
    IN_FEATURES:
    - res2
    - res3
    - res5
    LOSS_TOP_K: 1.0
    LOSS_TYPE: hard_pixel_mining
    LOSS_WEIGHT: 1.0
    NAME: PanopticDeepLabSemSegHead
    NORM: BN
    NUM_CLASSES: 133
    PROJECT_CHANNELS:
    - 32
    - 64
    PROJECT_FEATURES:
    - res2
    - res3
    USE_DEPTHWISE_SEPARABLE_CONV: true
  WEIGHTS: detectron2://DeepLab/R-52.pkl
OUTPUT_DIR: ./output
SEED: -1
SOLVER:
  AMP:
    ENABLED: false
  BASE_LR: 0.0025
  BASE_LR_END: 0.0
  BIAS_LR_FACTOR: 1.0
  CHECKPOINT_PERIOD: 5000
  CLIP_GRADIENTS:
    CLIP_TYPE: value
    CLIP_VALUE: 1.0
    ENABLED: false
    NORM_TYPE: 2.0
  GAMMA: 0.1
  IMS_PER_BATCH: 5
  LR_SCHEDULER_NAME: WarmupPolyLR
  MAX_ITER: 7000
  MOMENTUM: 0.9
  NESTEROV: false
  NUM_DECAYS: 3
  OPTIMIZER: ADAM
  POLY_LR_CONSTANT_ENDING: 0.0
  POLY_LR_POWER: 0.9
  REFERENCE_WORLD_SIZE: 0
  RESCALE_INTERVAL: false
  STEPS:
  - 30000
  WARMUP_FACTOR: 0.001
  WARMUP_ITERS: 1000
  WARMUP_METHOD: linear
  WEIGHT_DECAY: 0.0
  WEIGHT_DECAY_BIAS: 0.0
  WEIGHT_DECAY_NORM: 0.0
TEST:
  AUG:
    ENABLED: false
    FLIP: true
    MAX_SIZE: 4000
    MIN_SIZES:
    - 400
    - 500
    - 600
    - 700
    - 800
    - 900
    - 1000
    - 1100
    - 1200
  DETECTIONS_PER_IMAGE: 100
  EVAL_PERIOD: 0
  EXPECTED_RESULTS: []
  KEYPOINT_OKS_SIGMAS: []
  PRECISE_BN:
    ENABLED: false
    NUM_ITER: 200
VERSION: 2
VIS_PERIOD: 0

[12/09 09:23:42 detectron2]: Full config saved to ./output/config.yaml
[12/09 09:23:42 d2.utils.env]: Using a generated random seed 42999814
[12/09 09:23:47 d2.engine.defaults]: Model:
PanopticDeepLab(
  (backbone): ResNet(
    (stem): DeepLabStem(
      (conv1): Conv2d(
        3, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False
        (norm): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (conv2): Conv2d(
        64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
        (norm): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (conv3): Conv2d(
        64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
        (norm): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (res2): Sequential(
      (0): BottleneckBlock(
        (shortcut): Conv2d(
          128, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv1): Conv2d(
          128, 64, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv2): Conv2d(
          64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv3): Conv2d(
          64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (1): BottleneckBlock(
        (conv1): Conv2d(
          256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv2): Conv2d(
          64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv3): Conv2d(
          64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (2): BottleneckBlock(
        (conv1): Conv2d(
          256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv2): Conv2d(
          64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv3): Conv2d(
          64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
    )
    (res3): Sequential(
      (0): BottleneckBlock(
        (shortcut): Conv2d(
          256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False
          (norm): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv1): Conv2d(
          256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv2): Conv2d(
          128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False
          (norm): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv3): Conv2d(
          128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (1): BottleneckBlock(
        (conv1): Conv2d(
          512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv2): Conv2d(
          128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv3): Conv2d(
          128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (2): BottleneckBlock(
        (conv1): Conv2d(
          512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv2): Conv2d(
          128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv3): Conv2d(
          128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (3): BottleneckBlock(
        (conv1): Conv2d(
          512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv2): Conv2d(
          128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv3): Conv2d(
          128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
    )
    (res4): Sequential(
      (0): BottleneckBlock(
        (shortcut): Conv2d(
          512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False
          (norm): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv1): Conv2d(
          512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv2): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False
          (norm): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv3): Conv2d(
          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (1): BottleneckBlock(
        (conv1): Conv2d(
          1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv2): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv3): Conv2d(
          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (2): BottleneckBlock(
        (conv1): Conv2d(
          1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv2): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv3): Conv2d(
          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (3): BottleneckBlock(
        (conv1): Conv2d(
          1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv2): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv3): Conv2d(
          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (4): BottleneckBlock(
        (conv1): Conv2d(
          1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv2): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv3): Conv2d(
          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (5): BottleneckBlock(
        (conv1): Conv2d(
          1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv2): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv3): Conv2d(
          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
    )
    (res5): Sequential(
      (0): BottleneckBlock(
        (shortcut): Conv2d(
          1024, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv1): Conv2d(
          1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv2): Conv2d(
          512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2), dilation=(2, 2), bias=False
          (norm): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv3): Conv2d(
          512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (1): BottleneckBlock(
        (conv1): Conv2d(
          2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv2): Conv2d(
          512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(4, 4), dilation=(4, 4), bias=False
          (norm): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv3): Conv2d(
          512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (2): BottleneckBlock(
        (conv1): Conv2d(
          2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv2): Conv2d(
          512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(8, 8), dilation=(8, 8), bias=False
          (norm): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv3): Conv2d(
          512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
    )
  )
  (sem_seg_head): PanopticDeepLabSemSegHead(
    (decoder): ModuleDict(
      (res2): ModuleDict(
        (project_conv): Conv2d(
          256, 32, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (fuse_conv): DepthwiseSeparableConv2d(
          (depthwise): Conv2d(
            288, 288, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=288, bias=False
            (norm): BatchNorm2d(288, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          )
          (pointwise): Conv2d(
            288, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
      )
      (res3): ModuleDict(
        (project_conv): Conv2d(
          512, 64, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (fuse_conv): DepthwiseSeparableConv2d(
          (depthwise): Conv2d(
            320, 320, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=320, bias=False
            (norm): BatchNorm2d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          )
          (pointwise): Conv2d(
            320, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
      )
      (res5): ModuleDict(
        (project_conv): ASPP(
          (convs): ModuleList(
            (0): Conv2d(
              2048, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
              (norm): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            )
            (1): DepthwiseSeparableConv2d(
              (depthwise): Conv2d(
                2048, 2048, kernel_size=(3, 3), stride=(1, 1), padding=(6, 6), dilation=(6, 6), groups=2048, bias=False
                (norm): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
              (pointwise): Conv2d(
                2048, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
            )
            (2): DepthwiseSeparableConv2d(
              (depthwise): Conv2d(
                2048, 2048, kernel_size=(3, 3), stride=(1, 1), padding=(12, 12), dilation=(12, 12), groups=2048, bias=False
                (norm): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
              (pointwise): Conv2d(
                2048, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
            )
            (3): DepthwiseSeparableConv2d(
              (depthwise): Conv2d(
                2048, 2048, kernel_size=(3, 3), stride=(1, 1), padding=(18, 18), dilation=(18, 18), groups=2048, bias=False
                (norm): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
              (pointwise): Conv2d(
                2048, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
            )
            (4): Sequential(
              (0): AvgPool2d(kernel_size=(40, 40), stride=1, padding=0)
              (1): Conv2d(2048, 256, kernel_size=(1, 1), stride=(1, 1))
            )
          )
          (project): Conv2d(
            1280, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (fuse_conv): None
      )
    )
    (head): DepthwiseSeparableConv2d(
      (depthwise): Conv2d(
        256, 256, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=256, bias=False
        (norm): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (pointwise): Conv2d(
        256, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
        (norm): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (predictor): Conv2d(256, 133, kernel_size=(1, 1), stride=(1, 1))
    (loss): DeepLabCE(
      (criterion): CrossEntropyLoss()
    )
  )
  (ins_embed_head): PanopticDeepLabInsEmbedHead(
    (decoder): ModuleDict(
      (res2): ModuleDict(
        (project_conv): Conv2d(
          256, 32, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (fuse_conv): DepthwiseSeparableConv2d(
          (depthwise): Conv2d(
            160, 160, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=160, bias=False
            (norm): BatchNorm2d(160, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          )
          (pointwise): Conv2d(
            160, 128, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
      )
      (res3): ModuleDict(
        (project_conv): Conv2d(
          512, 64, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (fuse_conv): DepthwiseSeparableConv2d(
          (depthwise): Conv2d(
            320, 320, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=320, bias=False
            (norm): BatchNorm2d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          )
          (pointwise): Conv2d(
            320, 128, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
      )
      (res5): ModuleDict(
        (project_conv): ASPP(
          (convs): ModuleList(
            (0): Conv2d(
              2048, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
              (norm): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            )
            (1): DepthwiseSeparableConv2d(
              (depthwise): Conv2d(
                2048, 2048, kernel_size=(3, 3), stride=(1, 1), padding=(6, 6), dilation=(6, 6), groups=2048, bias=False
                (norm): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
              (pointwise): Conv2d(
                2048, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
            )
            (2): DepthwiseSeparableConv2d(
              (depthwise): Conv2d(
                2048, 2048, kernel_size=(3, 3), stride=(1, 1), padding=(12, 12), dilation=(12, 12), groups=2048, bias=False
                (norm): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
              (pointwise): Conv2d(
                2048, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
            )
            (3): DepthwiseSeparableConv2d(
              (depthwise): Conv2d(
                2048, 2048, kernel_size=(3, 3), stride=(1, 1), padding=(18, 18), dilation=(18, 18), groups=2048, bias=False
                (norm): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
              (pointwise): Conv2d(
                2048, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
            )
            (4): Sequential(
              (0): AvgPool2d(kernel_size=(40, 40), stride=1, padding=0)
              (1): Conv2d(2048, 256, kernel_size=(1, 1), stride=(1, 1))
            )
          )
          (project): Conv2d(
            1280, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (fuse_conv): None
      )
    )
    (center_head): Sequential(
      (0): Conv2d(
        128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
        (norm): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (1): Conv2d(
        128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
        (norm): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (center_predictor): Conv2d(32, 1, kernel_size=(1, 1), stride=(1, 1))
    (offset_head): DepthwiseSeparableConv2d(
      (depthwise): Conv2d(
        128, 128, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=128, bias=False
        (norm): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (pointwise): Conv2d(
        128, 32, kernel_size=(1, 1), stride=(1, 1), bias=False
        (norm): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (offset_predictor): Conv2d(32, 2, kernel_size=(1, 1), stride=(1, 1))
    (center_loss): MSELoss()
    (offset_loss): L1Loss()
  )
)
[12/09 09:23:47 d2.projects.panoptic_deeplab.dataset_mapper]: Augmentations used in training: [ResizeShortestEdge(short_edge_length=(320, 384, 448, 512, 576, 640, 704, 768, 832, 896, 960), max_size=960, sample_style='choice'), RandomCrop(crop_type='absolute', crop_size=[640, 640]), RandomFlip()]
[12/09 09:23:54 d2.data.build]: Using training sampler TrainingSampler
[12/09 09:23:54 d2.data.common]: Serializing the dataset using: <class 'detectron2.data.common.NumpySerializedList'>
[12/09 09:23:54 d2.data.common]: Serializing 118287 elements to byte tensors and concatenating them all ...
[12/09 09:23:55 d2.data.common]: Serialized dataset takes 80.32 MiB
/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:481: UserWarning: This DataLoader will create 10 worker processes in total. Our suggested max number of worker in current system is 8, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.
  cpuset_checked))
[12/09 09:23:58 fvcore.common.checkpoint]: [Checkpointer] Loading from detectron2://DeepLab/R-52.pkl ...
[12/09 09:23:59 fvcore.common.checkpoint]: Reading a file from 'torchvision'
[12/09 09:23:59 d2.checkpoint.c2_model_loading]: Following weights matched with submodule backbone:
| Names in Model    | Names in Checkpoint                                                                                        | Shapes                                             |
|:------------------|:-----------------------------------------------------------------------------------------------------------|:---------------------------------------------------|
| res2.0.conv1.*    | res2.0.conv1.{norm.bias,norm.num_batches_tracked,norm.running_mean,norm.running_var,norm.weight,weight}    | (64,) () (64,) (64,) (64,) (64,128,1,1)            |
| res2.0.conv2.*    | res2.0.conv2.{norm.bias,norm.num_batches_tracked,norm.running_mean,norm.running_var,norm.weight,weight}    | (64,) () (64,) (64,) (64,) (64,64,3,3)             |
| res2.0.conv3.*    | res2.0.conv3.{norm.bias,norm.num_batches_tracked,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) () (256,) (256,) (256,) (256,64,1,1)        |
| res2.0.shortcut.* | res2.0.shortcut.{norm.bias,norm.num_batches_tracked,norm.running_mean,norm.running_var,norm.weight,weight} | (256,) () (256,) (256,) (256,) (256,128,1,1)       |
| res2.1.conv1.*    | res2.1.conv1.{norm.bias,norm.num_batches_tracked,norm.running_mean,norm.running_var,norm.weight,weight}    | (64,) () (64,) (64,) (64,) (64,256,1,1)            |
| res2.1.conv2.*    | res2.1.conv2.{norm.bias,norm.num_batches_tracked,norm.running_mean,norm.running_var,norm.weight,weight}    | (64,) () (64,) (64,) (64,) (64,64,3,3)             |
| res2.1.conv3.*    | res2.1.conv3.{norm.bias,norm.num_batches_tracked,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) () (256,) (256,) (256,) (256,64,1,1)        |
| res2.2.conv1.*    | res2.2.conv1.{norm.bias,norm.num_batches_tracked,norm.running_mean,norm.running_var,norm.weight,weight}    | (64,) () (64,) (64,) (64,) (64,256,1,1)            |
| res2.2.conv2.*    | res2.2.conv2.{norm.bias,norm.num_batches_tracked,norm.running_mean,norm.running_var,norm.weight,weight}    | (64,) () (64,) (64,) (64,) (64,64,3,3)             |
| res2.2.conv3.*    | res2.2.conv3.{norm.bias,norm.num_batches_tracked,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) () (256,) (256,) (256,) (256,64,1,1)        |
| res3.0.conv1.*    | res3.0.conv1.{norm.bias,norm.num_batches_tracked,norm.running_mean,norm.running_var,norm.weight,weight}    | (128,) () (128,) (128,) (128,) (128,256,1,1)       |
| res3.0.conv2.*    | res3.0.conv2.{norm.bias,norm.num_batches_tracked,norm.running_mean,norm.running_var,norm.weight,weight}    | (128,) () (128,) (128,) (128,) (128,128,3,3)       |
| res3.0.conv3.*    | res3.0.conv3.{norm.bias,norm.num_batches_tracked,norm.running_mean,norm.running_var,norm.weight,weight}    | (512,) () (512,) (512,) (512,) (512,128,1,1)       |
| res3.0.shortcut.* | res3.0.shortcut.{norm.bias,norm.num_batches_tracked,norm.running_mean,norm.running_var,norm.weight,weight} | (512,) () (512,) (512,) (512,) (512,256,1,1)       |
| res3.1.conv1.*    | res3.1.conv1.{norm.bias,norm.num_batches_tracked,norm.running_mean,norm.running_var,norm.weight,weight}    | (128,) () (128,) (128,) (128,) (128,512,1,1)       |
| res3.1.conv2.*    | res3.1.conv2.{norm.bias,norm.num_batches_tracked,norm.running_mean,norm.running_var,norm.weight,weight}    | (128,) () (128,) (128,) (128,) (128,128,3,3)       |
| res3.1.conv3.*    | res3.1.conv3.{norm.bias,norm.num_batches_tracked,norm.running_mean,norm.running_var,norm.weight,weight}    | (512,) () (512,) (512,) (512,) (512,128,1,1)       |
| res3.2.conv1.*    | res3.2.conv1.{norm.bias,norm.num_batches_tracked,norm.running_mean,norm.running_var,norm.weight,weight}    | (128,) () (128,) (128,) (128,) (128,512,1,1)       |
| res3.2.conv2.*    | res3.2.conv2.{norm.bias,norm.num_batches_tracked,norm.running_mean,norm.running_var,norm.weight,weight}    | (128,) () (128,) (128,) (128,) (128,128,3,3)       |
| res3.2.conv3.*    | res3.2.conv3.{norm.bias,norm.num_batches_tracked,norm.running_mean,norm.running_var,norm.weight,weight}    | (512,) () (512,) (512,) (512,) (512,128,1,1)       |
| res3.3.conv1.*    | res3.3.conv1.{norm.bias,norm.num_batches_tracked,norm.running_mean,norm.running_var,norm.weight,weight}    | (128,) () (128,) (128,) (128,) (128,512,1,1)       |
| res3.3.conv2.*    | res3.3.conv2.{norm.bias,norm.num_batches_tracked,norm.running_mean,norm.running_var,norm.weight,weight}    | (128,) () (128,) (128,) (128,) (128,128,3,3)       |
| res3.3.conv3.*    | res3.3.conv3.{norm.bias,norm.num_batches_tracked,norm.running_mean,norm.running_var,norm.weight,weight}    | (512,) () (512,) (512,) (512,) (512,128,1,1)       |
| res4.0.conv1.*    | res4.0.conv1.{norm.bias,norm.num_batches_tracked,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) () (256,) (256,) (256,) (256,512,1,1)       |
| res4.0.conv2.*    | res4.0.conv2.{norm.bias,norm.num_batches_tracked,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) () (256,) (256,) (256,) (256,256,3,3)       |
| res4.0.conv3.*    | res4.0.conv3.{norm.bias,norm.num_batches_tracked,norm.running_mean,norm.running_var,norm.weight,weight}    | (1024,) () (1024,) (1024,) (1024,) (1024,256,1,1)  |
| res4.0.shortcut.* | res4.0.shortcut.{norm.bias,norm.num_batches_tracked,norm.running_mean,norm.running_var,norm.weight,weight} | (1024,) () (1024,) (1024,) (1024,) (1024,512,1,1)  |
| res4.1.conv1.*    | res4.1.conv1.{norm.bias,norm.num_batches_tracked,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) () (256,) (256,) (256,) (256,1024,1,1)      |
| res4.1.conv2.*    | res4.1.conv2.{norm.bias,norm.num_batches_tracked,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) () (256,) (256,) (256,) (256,256,3,3)       |
| res4.1.conv3.*    | res4.1.conv3.{norm.bias,norm.num_batches_tracked,norm.running_mean,norm.running_var,norm.weight,weight}    | (1024,) () (1024,) (1024,) (1024,) (1024,256,1,1)  |
| res4.2.conv1.*    | res4.2.conv1.{norm.bias,norm.num_batches_tracked,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) () (256,) (256,) (256,) (256,1024,1,1)      |
| res4.2.conv2.*    | res4.2.conv2.{norm.bias,norm.num_batches_tracked,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) () (256,) (256,) (256,) (256,256,3,3)       |
| res4.2.conv3.*    | res4.2.conv3.{norm.bias,norm.num_batches_tracked,norm.running_mean,norm.running_var,norm.weight,weight}    | (1024,) () (1024,) (1024,) (1024,) (1024,256,1,1)  |
| res4.3.conv1.*    | res4.3.conv1.{norm.bias,norm.num_batches_tracked,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) () (256,) (256,) (256,) (256,1024,1,1)      |
| res4.3.conv2.*    | res4.3.conv2.{norm.bias,norm.num_batches_tracked,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) () (256,) (256,) (256,) (256,256,3,3)       |
| res4.3.conv3.*    | res4.3.conv3.{norm.bias,norm.num_batches_tracked,norm.running_mean,norm.running_var,norm.weight,weight}    | (1024,) () (1024,) (1024,) (1024,) (1024,256,1,1)  |
| res4.4.conv1.*    | res4.4.conv1.{norm.bias,norm.num_batches_tracked,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) () (256,) (256,) (256,) (256,1024,1,1)      |
| res4.4.conv2.*    | res4.4.conv2.{norm.bias,norm.num_batches_tracked,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) () (256,) (256,) (256,) (256,256,3,3)       |
| res4.4.conv3.*    | res4.4.conv3.{norm.bias,norm.num_batches_tracked,norm.running_mean,norm.running_var,norm.weight,weight}    | (1024,) () (1024,) (1024,) (1024,) (1024,256,1,1)  |
| res4.5.conv1.*    | res4.5.conv1.{norm.bias,norm.num_batches_tracked,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) () (256,) (256,) (256,) (256,1024,1,1)      |
| res4.5.conv2.*    | res4.5.conv2.{norm.bias,norm.num_batches_tracked,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) () (256,) (256,) (256,) (256,256,3,3)       |
| res4.5.conv3.*    | res4.5.conv3.{norm.bias,norm.num_batches_tracked,norm.running_mean,norm.running_var,norm.weight,weight}    | (1024,) () (1024,) (1024,) (1024,) (1024,256,1,1)  |
| res5.0.conv1.*    | res5.0.conv1.{norm.bias,norm.num_batches_tracked,norm.running_mean,norm.running_var,norm.weight,weight}    | (512,) () (512,) (512,) (512,) (512,1024,1,1)      |
| res5.0.conv2.*    | res5.0.conv2.{norm.bias,norm.num_batches_tracked,norm.running_mean,norm.running_var,norm.weight,weight}    | (512,) () (512,) (512,) (512,) (512,512,3,3)       |
| res5.0.conv3.*    | res5.0.conv3.{norm.bias,norm.num_batches_tracked,norm.running_mean,norm.running_var,norm.weight,weight}    | (2048,) () (2048,) (2048,) (2048,) (2048,512,1,1)  |
| res5.0.shortcut.* | res5.0.shortcut.{norm.bias,norm.num_batches_tracked,norm.running_mean,norm.running_var,norm.weight,weight} | (2048,) () (2048,) (2048,) (2048,) (2048,1024,1,1) |
| res5.1.conv1.*    | res5.1.conv1.{norm.bias,norm.num_batches_tracked,norm.running_mean,norm.running_var,norm.weight,weight}    | (512,) () (512,) (512,) (512,) (512,2048,1,1)      |
| res5.1.conv2.*    | res5.1.conv2.{norm.bias,norm.num_batches_tracked,norm.running_mean,norm.running_var,norm.weight,weight}    | (512,) () (512,) (512,) (512,) (512,512,3,3)       |
| res5.1.conv3.*    | res5.1.conv3.{norm.bias,norm.num_batches_tracked,norm.running_mean,norm.running_var,norm.weight,weight}    | (2048,) () (2048,) (2048,) (2048,) (2048,512,1,1)  |
| res5.2.conv1.*    | res5.2.conv1.{norm.bias,norm.num_batches_tracked,norm.running_mean,norm.running_var,norm.weight,weight}    | (512,) () (512,) (512,) (512,) (512,2048,1,1)      |
| res5.2.conv2.*    | res5.2.conv2.{norm.bias,norm.num_batches_tracked,norm.running_mean,norm.running_var,norm.weight,weight}    | (512,) () (512,) (512,) (512,) (512,512,3,3)       |
| res5.2.conv3.*    | res5.2.conv3.{norm.bias,norm.num_batches_tracked,norm.running_mean,norm.running_var,norm.weight,weight}    | (2048,) () (2048,) (2048,) (2048,) (2048,512,1,1)  |
| stem.conv1.*      | stem.conv1.{norm.bias,norm.num_batches_tracked,norm.running_mean,norm.running_var,norm.weight,weight}      | (64,) () (64,) (64,) (64,) (64,3,3,3)              |
| stem.conv2.*      | stem.conv2.{norm.bias,norm.num_batches_tracked,norm.running_mean,norm.running_var,norm.weight,weight}      | (64,) () (64,) (64,) (64,) (64,64,3,3)             |
| stem.conv3.*      | stem.conv3.{norm.bias,norm.num_batches_tracked,norm.running_mean,norm.running_var,norm.weight,weight}      | (128,) () (128,) (128,) (128,) (128,64,3,3)        |
WARNING [12/09 09:23:59 fvcore.common.checkpoint]: Some model parameters or buffers are not found in the checkpoint:
ins_embed_head.center_head.0.norm.{bias, running_mean, running_var, weight}
ins_embed_head.center_head.0.weight
ins_embed_head.center_head.1.norm.{bias, running_mean, running_var, weight}
ins_embed_head.center_head.1.weight
ins_embed_head.center_predictor.{bias, weight}
ins_embed_head.decoder.res2.fuse_conv.depthwise.norm.{bias, running_mean, running_var, weight}
ins_embed_head.decoder.res2.fuse_conv.depthwise.weight
ins_embed_head.decoder.res2.fuse_conv.pointwise.norm.{bias, running_mean, running_var, weight}
ins_embed_head.decoder.res2.fuse_conv.pointwise.weight
ins_embed_head.decoder.res2.project_conv.norm.{bias, running_mean, running_var, weight}
ins_embed_head.decoder.res2.project_conv.weight
ins_embed_head.decoder.res3.fuse_conv.depthwise.norm.{bias, running_mean, running_var, weight}
ins_embed_head.decoder.res3.fuse_conv.depthwise.weight
ins_embed_head.decoder.res3.fuse_conv.pointwise.norm.{bias, running_mean, running_var, weight}
ins_embed_head.decoder.res3.fuse_conv.pointwise.weight
ins_embed_head.decoder.res3.project_conv.norm.{bias, running_mean, running_var, weight}
ins_embed_head.decoder.res3.project_conv.weight
ins_embed_head.decoder.res5.project_conv.convs.0.norm.{bias, running_mean, running_var, weight}
ins_embed_head.decoder.res5.project_conv.convs.0.weight
ins_embed_head.decoder.res5.project_conv.convs.1.depthwise.norm.{bias, running_mean, running_var, weight}
ins_embed_head.decoder.res5.project_conv.convs.1.depthwise.weight
ins_embed_head.decoder.res5.project_conv.convs.1.pointwise.norm.{bias, running_mean, running_var, weight}
ins_embed_head.decoder.res5.project_conv.convs.1.pointwise.weight
ins_embed_head.decoder.res5.project_conv.convs.2.depthwise.norm.{bias, running_mean, running_var, weight}
ins_embed_head.decoder.res5.project_conv.convs.2.depthwise.weight
ins_embed_head.decoder.res5.project_conv.convs.2.pointwise.norm.{bias, running_mean, running_var, weight}
ins_embed_head.decoder.res5.project_conv.convs.2.pointwise.weight
ins_embed_head.decoder.res5.project_conv.convs.3.depthwise.norm.{bias, running_mean, running_var, weight}
ins_embed_head.decoder.res5.project_conv.convs.3.depthwise.weight
ins_embed_head.decoder.res5.project_conv.convs.3.pointwise.norm.{bias, running_mean, running_var, weight}
ins_embed_head.decoder.res5.project_conv.convs.3.pointwise.weight
ins_embed_head.decoder.res5.project_conv.convs.4.1.{bias, weight}
ins_embed_head.decoder.res5.project_conv.project.norm.{bias, running_mean, running_var, weight}
ins_embed_head.decoder.res5.project_conv.project.weight
ins_embed_head.offset_head.depthwise.norm.{bias, running_mean, running_var, weight}
ins_embed_head.offset_head.depthwise.weight
ins_embed_head.offset_head.pointwise.norm.{bias, running_mean, running_var, weight}
ins_embed_head.offset_head.pointwise.weight
ins_embed_head.offset_predictor.{bias, weight}
sem_seg_head.decoder.res2.fuse_conv.depthwise.norm.{bias, running_mean, running_var, weight}
sem_seg_head.decoder.res2.fuse_conv.depthwise.weight
sem_seg_head.decoder.res2.fuse_conv.pointwise.norm.{bias, running_mean, running_var, weight}
sem_seg_head.decoder.res2.fuse_conv.pointwise.weight
sem_seg_head.decoder.res2.project_conv.norm.{bias, running_mean, running_var, weight}
sem_seg_head.decoder.res2.project_conv.weight
sem_seg_head.decoder.res3.fuse_conv.depthwise.norm.{bias, running_mean, running_var, weight}
sem_seg_head.decoder.res3.fuse_conv.depthwise.weight
sem_seg_head.decoder.res3.fuse_conv.pointwise.norm.{bias, running_mean, running_var, weight}
sem_seg_head.decoder.res3.fuse_conv.pointwise.weight
sem_seg_head.decoder.res3.project_conv.norm.{bias, running_mean, running_var, weight}
sem_seg_head.decoder.res3.project_conv.weight
sem_seg_head.decoder.res5.project_conv.convs.0.norm.{bias, running_mean, running_var, weight}
sem_seg_head.decoder.res5.project_conv.convs.0.weight
sem_seg_head.decoder.res5.project_conv.convs.1.depthwise.norm.{bias, running_mean, running_var, weight}
sem_seg_head.decoder.res5.project_conv.convs.1.depthwise.weight
sem_seg_head.decoder.res5.project_conv.convs.1.pointwise.norm.{bias, running_mean, running_var, weight}
sem_seg_head.decoder.res5.project_conv.convs.1.pointwise.weight
sem_seg_head.decoder.res5.project_conv.convs.2.depthwise.norm.{bias, running_mean, running_var, weight}
sem_seg_head.decoder.res5.project_conv.convs.2.depthwise.weight
sem_seg_head.decoder.res5.project_conv.convs.2.pointwise.norm.{bias, running_mean, running_var, weight}
sem_seg_head.decoder.res5.project_conv.convs.2.pointwise.weight
sem_seg_head.decoder.res5.project_conv.convs.3.depthwise.norm.{bias, running_mean, running_var, weight}
sem_seg_head.decoder.res5.project_conv.convs.3.depthwise.weight
sem_seg_head.decoder.res5.project_conv.convs.3.pointwise.norm.{bias, running_mean, running_var, weight}
sem_seg_head.decoder.res5.project_conv.convs.3.pointwise.weight
sem_seg_head.decoder.res5.project_conv.convs.4.1.{bias, weight}
sem_seg_head.decoder.res5.project_conv.project.norm.{bias, running_mean, running_var, weight}
sem_seg_head.decoder.res5.project_conv.project.weight
sem_seg_head.head.depthwise.norm.{bias, running_mean, running_var, weight}
sem_seg_head.head.depthwise.weight
sem_seg_head.head.pointwise.norm.{bias, running_mean, running_var, weight}
sem_seg_head.head.pointwise.weight
sem_seg_head.predictor.{bias, weight}
WARNING [12/09 09:23:59 fvcore.common.checkpoint]: The checkpoint state_dict contains keys that are not used by the model:
  stem.fc.{bias, weight}
[12/09 09:23:59 d2.engine.train_loop]: Starting training from iteration 0
/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:481: UserWarning: This DataLoader will create 10 worker processes in total. Our suggested max number of worker in current system is 8, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.
  cpuset_checked))
[12/09 09:24:09 d2.utils.events]:  eta: 0:49:49  iter: 19  total_loss: 6.197  loss_sem_seg: 3.852  loss_center: 0.5916  loss_offset: 1.609  time: 0.4274  data_time: 0.0631  lr: 4.983e-05  max_mem: 11463M
[12/09 09:24:18 d2.utils.events]:  eta: 0:49:44  iter: 39  total_loss: 6.077  loss_sem_seg: 3.699  loss_center: 0.6499  loss_offset: 1.722  time: 0.4287  data_time: 0.0252  lr: 9.9401e-05  max_mem: 11463M
[12/09 09:24:26 d2.utils.events]:  eta: 0:49:34  iter: 59  total_loss: 6.11  loss_sem_seg: 3.645  loss_center: 0.5669  loss_offset: 1.685  time: 0.4289  data_time: 0.0244  lr: 0.00014872  max_mem: 11463M
[12/09 09:24:35 d2.utils.events]:  eta: 0:49:25  iter: 79  total_loss: 5.681  loss_sem_seg: 3.488  loss_center: 0.6826  loss_offset: 1.474  time: 0.4292  data_time: 0.0258  lr: 0.00019777  max_mem: 11463M
[12/09 09:24:43 d2.utils.events]:  eta: 0:49:17  iter: 99  total_loss: 5.457  loss_sem_seg: 3.152  loss_center: 0.6251  loss_offset: 1.726  time: 0.4288  data_time: 0.0247  lr: 0.00024657  max_mem: 11463M
[12/09 09:24:52 d2.utils.events]:  eta: 0:49:07  iter: 119  total_loss: 5.487  loss_sem_seg: 3.061  loss_center: 0.7957  loss_offset: 1.531  time: 0.4285  data_time: 0.0249  lr: 0.00029511  max_mem: 11463M
[12/09 09:25:00 d2.utils.events]:  eta: 0:49:02  iter: 139  total_loss: 5.082  loss_sem_seg: 2.866  loss_center: 0.6  loss_offset: 1.626  time: 0.4285  data_time: 0.0247  lr: 0.0003434  max_mem: 11463M
[12/09 09:25:09 d2.utils.events]:  eta: 0:48:50  iter: 159  total_loss: 5.189  loss_sem_seg: 2.833  loss_center: 0.6554  loss_offset: 1.473  time: 0.4282  data_time: 0.0230  lr: 0.00039142  max_mem: 11463M
[12/09 09:25:18 d2.utils.events]:  eta: 0:48:38  iter: 179  total_loss: 5.158  loss_sem_seg: 2.851  loss_center: 0.6818  loss_offset: 1.614  time: 0.4281  data_time: 0.0241  lr: 0.00043919  max_mem: 11463M
[12/09 09:25:26 d2.utils.events]:  eta: 0:48:31  iter: 199  total_loss: 5.065  loss_sem_seg: 2.789  loss_center: 0.6347  loss_offset: 1.702  time: 0.4284  data_time: 0.0256  lr: 0.0004867  max_mem: 11463M
[12/09 09:25:35 d2.utils.events]:  eta: 0:48:24  iter: 219  total_loss: 4.855  loss_sem_seg: 2.472  loss_center: 0.7132  loss_offset: 1.273  time: 0.4284  data_time: 0.0243  lr: 0.00053396  max_mem: 11463M
[12/09 09:25:43 d2.utils.events]:  eta: 0:48:17  iter: 239  total_loss: 5.196  loss_sem_seg: 2.769  loss_center: 0.8741  loss_offset: 1.62  time: 0.4283  data_time: 0.0246  lr: 0.00058095  max_mem: 11463M
[12/09 09:25:52 d2.utils.events]:  eta: 0:48:09  iter: 259  total_loss: 4.774  loss_sem_seg: 2.79  loss_center: 0.5511  loss_offset: 1.584  time: 0.4284  data_time: 0.0248  lr: 0.00062769  max_mem: 11463M
[12/09 09:26:01 d2.utils.events]:  eta: 0:48:01  iter: 279  total_loss: 5.083  loss_sem_seg: 2.741  loss_center: 0.6093  loss_offset: 1.586  time: 0.4285  data_time: 0.0245  lr: 0.00067417  max_mem: 11463M
[12/09 09:26:09 d2.utils.events]:  eta: 0:47:52  iter: 299  total_loss: 5.037  loss_sem_seg: 2.725  loss_center: 0.6264  loss_offset: 1.617  time: 0.4284  data_time: 0.0245  lr: 0.00072039  max_mem: 11463M
[12/09 09:26:18 d2.utils.events]:  eta: 0:47:44  iter: 319  total_loss: 4.687  loss_sem_seg: 2.548  loss_center: 0.6202  loss_offset: 1.494  time: 0.4284  data_time: 0.0253  lr: 0.00076635  max_mem: 11463M
[12/09 09:26:26 d2.utils.events]:  eta: 0:47:36  iter: 339  total_loss: 4.83  loss_sem_seg: 2.563  loss_center: 0.7968  loss_offset: 1.3  time: 0.4286  data_time: 0.0252  lr: 0.00081205  max_mem: 11463M
[12/09 09:26:35 d2.utils.events]:  eta: 0:47:26  iter: 359  total_loss: 4.781  loss_sem_seg: 2.434  loss_center: 0.6826  loss_offset: 1.286  time: 0.4285  data_time: 0.0244  lr: 0.00085749  max_mem: 11463M
[12/09 09:26:44 d2.utils.events]:  eta: 0:47:18  iter: 379  total_loss: 4.786  loss_sem_seg: 2.663  loss_center: 0.7695  loss_offset: 1.331  time: 0.4286  data_time: 0.0254  lr: 0.00090268  max_mem: 11463M
[12/09 09:26:52 d2.utils.events]:  eta: 0:47:10  iter: 399  total_loss: 4.794  loss_sem_seg: 2.664  loss_center: 0.6708  loss_offset: 1.338  time: 0.4287  data_time: 0.0248  lr: 0.0009476  max_mem: 11463M
[12/09 09:27:01 d2.utils.events]:  eta: 0:47:01  iter: 419  total_loss: 4.192  loss_sem_seg: 2.414  loss_center: 0.7911  loss_offset: 1.259  time: 0.4289  data_time: 0.0270  lr: 0.00099227  max_mem: 11463M
[12/09 09:27:09 d2.utils.events]:  eta: 0:46:52  iter: 439  total_loss: 4.545  loss_sem_seg: 2.633  loss_center: 0.6364  loss_offset: 1.141  time: 0.4289  data_time: 0.0254  lr: 0.0010367  max_mem: 11463M
[12/09 09:27:18 d2.utils.events]:  eta: 0:46:45  iter: 459  total_loss: 4.819  loss_sem_seg: 2.733  loss_center: 0.699  loss_offset: 1.305  time: 0.4289  data_time: 0.0244  lr: 0.0010808  max_mem: 11463M
[12/09 09:27:27 d2.utils.events]:  eta: 0:46:37  iter: 479  total_loss: 4.54  loss_sem_seg: 2.699  loss_center: 0.7455  loss_offset: 1.167  time: 0.4289  data_time: 0.0249  lr: 0.0011247  max_mem: 11463M
[12/09 09:27:35 d2.utils.events]:  eta: 0:46:29  iter: 499  total_loss: 4.87  loss_sem_seg: 2.649  loss_center: 0.5667  loss_offset: 1.42  time: 0.4290  data_time: 0.0263  lr: 0.0011683  max_mem: 11463M
[12/09 09:27:44 d2.utils.events]:  eta: 0:46:20  iter: 519  total_loss: 4.384  loss_sem_seg: 2.329  loss_center: 0.8024  loss_offset: 1.179  time: 0.4290  data_time: 0.0255  lr: 0.0012117  max_mem: 11463M
[12/09 09:27:52 d2.utils.events]:  eta: 0:46:11  iter: 539  total_loss: 4.424  loss_sem_seg: 2.462  loss_center: 0.7665  loss_offset: 1.201  time: 0.4289  data_time: 0.0246  lr: 0.0012548  max_mem: 11463M
[12/09 09:28:01 d2.utils.events]:  eta: 0:46:00  iter: 559  total_loss: 4.117  loss_sem_seg: 2.327  loss_center: 0.6922  loss_offset: 1.107  time: 0.4288  data_time: 0.0238  lr: 0.0012977  max_mem: 11463M
[12/09 09:28:10 d2.utils.events]:  eta: 0:45:52  iter: 579  total_loss: 4.633  loss_sem_seg: 2.571  loss_center: 0.8808  loss_offset: 1.174  time: 0.4288  data_time: 0.0242  lr: 0.0013403  max_mem: 11463M
[12/09 09:28:18 d2.utils.events]:  eta: 0:45:43  iter: 599  total_loss: 4.594  loss_sem_seg: 2.505  loss_center: 0.6575  loss_offset: 1.324  time: 0.4289  data_time: 0.0266  lr: 0.0013826  max_mem: 11463M
[12/09 09:28:27 d2.utils.events]:  eta: 0:45:34  iter: 619  total_loss: 4.801  loss_sem_seg: 2.568  loss_center: 0.8494  loss_offset: 1.294  time: 0.4288  data_time: 0.0246  lr: 0.0014247  max_mem: 11463M
[12/09 09:28:35 d2.utils.events]:  eta: 0:45:25  iter: 639  total_loss: 4.325  loss_sem_seg: 2.554  loss_center: 0.7958  loss_offset: 1.209  time: 0.4288  data_time: 0.0242  lr: 0.0014665  max_mem: 11463M
[12/09 09:28:44 d2.utils.events]:  eta: 0:45:17  iter: 659  total_loss: 4.412  loss_sem_seg: 2.526  loss_center: 0.5984  loss_offset: 1.172  time: 0.4288  data_time: 0.0261  lr: 0.001508  max_mem: 11463M
[12/09 09:28:53 d2.utils.events]:  eta: 0:45:09  iter: 679  total_loss: 4.458  loss_sem_seg: 2.373  loss_center: 0.6853  loss_offset: 1.164  time: 0.4289  data_time: 0.0257  lr: 0.0015493  max_mem: 11463M
[12/09 09:29:01 d2.utils.events]:  eta: 0:45:00  iter: 699  total_loss: 4.508  loss_sem_seg: 2.494  loss_center: 0.7238  loss_offset: 1.225  time: 0.4289  data_time: 0.0250  lr: 0.0015903  max_mem: 11463M
[12/09 09:29:10 d2.utils.events]:  eta: 0:44:52  iter: 719  total_loss: 4.437  loss_sem_seg: 2.48  loss_center: 0.6875  loss_offset: 1.173  time: 0.4289  data_time: 0.0241  lr: 0.0016311  max_mem: 11463M
[12/09 09:29:18 d2.utils.events]:  eta: 0:44:43  iter: 739  total_loss: 4.508  loss_sem_seg: 2.36  loss_center: 0.8257  loss_offset: 1.244  time: 0.4289  data_time: 0.0249  lr: 0.0016716  max_mem: 11463M
[12/09 09:29:27 d2.utils.events]:  eta: 0:44:35  iter: 759  total_loss: 4.212  loss_sem_seg: 2.373  loss_center: 0.7495  loss_offset: 1.069  time: 0.4288  data_time: 0.0230  lr: 0.0017118  max_mem: 11463M
[12/09 09:29:35 d2.utils.events]:  eta: 0:44:26  iter: 779  total_loss: 4.34  loss_sem_seg: 2.327  loss_center: 0.726  loss_offset: 1.156  time: 0.4288  data_time: 0.0251  lr: 0.0017518  max_mem: 11463M
[12/09 09:29:44 d2.utils.events]:  eta: 0:44:18  iter: 799  total_loss: 4.332  loss_sem_seg: 2.52  loss_center: 0.6375  loss_offset: 1.19  time: 0.4289  data_time: 0.0263  lr: 0.0017915  max_mem: 11463M
[12/09 09:29:53 d2.utils.events]:  eta: 0:44:10  iter: 819  total_loss: 4.28  loss_sem_seg: 2.278  loss_center: 0.6646  loss_offset: 1.122  time: 0.4289  data_time: 0.0254  lr: 0.001831  max_mem: 11463M
[12/09 09:30:01 d2.utils.events]:  eta: 0:44:02  iter: 839  total_loss: 4.422  loss_sem_seg: 2.488  loss_center: 0.6788  loss_offset: 1.212  time: 0.4289  data_time: 0.0255  lr: 0.0018702  max_mem: 11463M
[12/09 09:30:10 d2.utils.events]:  eta: 0:43:54  iter: 859  total_loss: 4.252  loss_sem_seg: 2.23  loss_center: 0.6602  loss_offset: 1.14  time: 0.4289  data_time: 0.0252  lr: 0.0019091  max_mem: 11463M
[12/09 09:30:18 d2.utils.events]:  eta: 0:43:44  iter: 879  total_loss: 4.338  loss_sem_seg: 2.495  loss_center: 0.6034  loss_offset: 1.083  time: 0.4289  data_time: 0.0247  lr: 0.0019478  max_mem: 11463M
[12/09 09:30:27 d2.utils.events]:  eta: 0:43:37  iter: 899  total_loss: 4.724  loss_sem_seg: 2.654  loss_center: 0.6708  loss_offset: 1.17  time: 0.4289  data_time: 0.0258  lr: 0.0019862  max_mem: 11463M
[12/09 09:30:36 d2.utils.events]:  eta: 0:43:28  iter: 919  total_loss: 4.337  loss_sem_seg: 2.415  loss_center: 0.7045  loss_offset: 1.113  time: 0.4289  data_time: 0.0238  lr: 0.0020243  max_mem: 11463M
[12/09 09:30:44 d2.utils.events]:  eta: 0:43:19  iter: 939  total_loss: 4.162  loss_sem_seg: 2.467  loss_center: 0.6362  loss_offset: 1.16  time: 0.4289  data_time: 0.0245  lr: 0.0020622  max_mem: 11463M
[12/09 09:30:53 d2.utils.events]:  eta: 0:43:11  iter: 959  total_loss: 4.745  loss_sem_seg: 2.728  loss_center: 0.7175  loss_offset: 1.303  time: 0.4289  data_time: 0.0244  lr: 0.0020998  max_mem: 11463M
[12/09 09:31:01 d2.utils.events]:  eta: 0:43:02  iter: 979  total_loss: 4.51  loss_sem_seg: 2.303  loss_center: 0.7886  loss_offset: 1.166  time: 0.4289  data_time: 0.0256  lr: 0.0021372  max_mem: 11463M
[12/09 09:31:10 d2.utils.events]:  eta: 0:42:53  iter: 999  total_loss: 4.319  loss_sem_seg: 2.342  loss_center: 0.7026  loss_offset: 1.074  time: 0.4288  data_time: 0.0236  lr: 0.0021743  max_mem: 11463M
[12/09 09:31:18 d2.utils.events]:  eta: 0:42:45  iter: 1019  total_loss: 4.179  loss_sem_seg: 2.376  loss_center: 0.6406  loss_offset: 1.189  time: 0.4288  data_time: 0.0244  lr: 0.0021699  max_mem: 11463M
[12/09 09:31:27 d2.utils.events]:  eta: 0:42:37  iter: 1039  total_loss: 4.481  loss_sem_seg: 2.42  loss_center: 0.6704  loss_offset: 1.173  time: 0.4289  data_time: 0.0263  lr: 0.0021634  max_mem: 11463M
[12/09 09:31:36 d2.utils.events]:  eta: 0:42:29  iter: 1059  total_loss: 4.158  loss_sem_seg: 2.407  loss_center: 0.5162  loss_offset: 1.16  time: 0.4289  data_time: 0.0272  lr: 0.0021569  max_mem: 11463M
[12/09 09:31:44 d2.utils.events]:  eta: 0:42:20  iter: 1079  total_loss: 4.101  loss_sem_seg: 2.414  loss_center: 0.6197  loss_offset: 1.086  time: 0.4289  data_time: 0.0254  lr: 0.0021503  max_mem: 11463M
[12/09 09:31:53 d2.utils.events]:  eta: 0:42:11  iter: 1099  total_loss: 4.286  loss_sem_seg: 2.406  loss_center: 0.7284  loss_offset: 1.077  time: 0.4289  data_time: 0.0250  lr: 0.0021438  max_mem: 11463M
[12/09 09:32:01 d2.utils.events]:  eta: 0:42:03  iter: 1119  total_loss: 4.67  loss_sem_seg: 2.662  loss_center: 0.7026  loss_offset: 1.13  time: 0.4289  data_time: 0.0253  lr: 0.0021373  max_mem: 11463M
[12/09 09:32:10 d2.utils.events]:  eta: 0:41:52  iter: 1139  total_loss: 4.159  loss_sem_seg: 2.298  loss_center: 0.772  loss_offset: 1.1  time: 0.4289  data_time: 0.0250  lr: 0.0021307  max_mem: 11463M
[12/09 09:32:19 d2.utils.events]:  eta: 0:41:45  iter: 1159  total_loss: 4.475  loss_sem_seg: 2.409  loss_center: 0.6348  loss_offset: 1.161  time: 0.4289  data_time: 0.0257  lr: 0.0021242  max_mem: 11463M
[12/09 09:32:27 d2.utils.events]:  eta: 0:41:36  iter: 1179  total_loss: 4.337  loss_sem_seg: 2.511  loss_center: 0.5754  loss_offset: 1.195  time: 0.4288  data_time: 0.0237  lr: 0.0021176  max_mem: 11463M
[12/09 09:32:36 d2.utils.events]:  eta: 0:41:28  iter: 1199  total_loss: 4.555  loss_sem_seg: 2.396  loss_center: 0.7987  loss_offset: 1.173  time: 0.4289  data_time: 0.0260  lr: 0.0021111  max_mem: 11463M
[12/09 09:32:44 d2.utils.events]:  eta: 0:41:19  iter: 1219  total_loss: 4.244  loss_sem_seg: 2.419  loss_center: 0.6047  loss_offset: 1.142  time: 0.4289  data_time: 0.0240  lr: 0.0021045  max_mem: 11463M
[12/09 09:32:53 d2.utils.events]:  eta: 0:41:09  iter: 1239  total_loss: 4.061  loss_sem_seg: 2.316  loss_center: 0.5483  loss_offset: 1.12  time: 0.4289  data_time: 0.0248  lr: 0.002098  max_mem: 11463M
[12/09 09:33:02 d2.utils.events]:  eta: 0:41:00  iter: 1259  total_loss: 4.431  loss_sem_seg: 2.703  loss_center: 0.6342  loss_offset: 1.165  time: 0.4289  data_time: 0.0261  lr: 0.0020914  max_mem: 11463M
[12/09 09:33:10 d2.utils.events]:  eta: 0:40:51  iter: 1279  total_loss: 4.405  loss_sem_seg: 2.612  loss_center: 0.6962  loss_offset: 1.123  time: 0.4290  data_time: 0.0262  lr: 0.0020849  max_mem: 11463M
[12/09 09:33:19 d2.utils.events]:  eta: 0:40:43  iter: 1299  total_loss: 4.432  loss_sem_seg: 2.429  loss_center: 0.8541  loss_offset: 1.056  time: 0.4289  data_time: 0.0244  lr: 0.0020783  max_mem: 11463M
[12/09 09:33:27 d2.utils.events]:  eta: 0:40:34  iter: 1319  total_loss: 4.562  loss_sem_seg: 2.453  loss_center: 0.7509  loss_offset: 1.203  time: 0.4289  data_time: 0.0264  lr: 0.0020717  max_mem: 11463M
[12/09 09:33:36 d2.utils.events]:  eta: 0:40:25  iter: 1339  total_loss: 4.099  loss_sem_seg: 2.301  loss_center: 0.6388  loss_offset: 1.151  time: 0.4290  data_time: 0.0267  lr: 0.0020652  max_mem: 11463M
[12/09 09:33:45 d2.utils.events]:  eta: 0:40:17  iter: 1359  total_loss: 4.274  loss_sem_seg: 2.361  loss_center: 0.7121  loss_offset: 1.103  time: 0.4290  data_time: 0.0258  lr: 0.0020586  max_mem: 11463M
[12/09 09:33:53 d2.utils.events]:  eta: 0:40:09  iter: 1379  total_loss: 4.092  loss_sem_seg: 2.249  loss_center: 0.6551  loss_offset: 1.079  time: 0.4290  data_time: 0.0252  lr: 0.002052  max_mem: 11463M
[12/09 09:34:02 d2.utils.events]:  eta: 0:40:00  iter: 1399  total_loss: 4.279  loss_sem_seg: 2.33  loss_center: 0.795  loss_offset: 1.021  time: 0.4290  data_time: 0.0242  lr: 0.0020455  max_mem: 11463M
[12/09 09:34:10 d2.utils.events]:  eta: 0:39:51  iter: 1419  total_loss: 4.493  loss_sem_seg: 2.554  loss_center: 0.7608  loss_offset: 1.095  time: 0.4290  data_time: 0.0262  lr: 0.0020389  max_mem: 11463M
[12/09 09:34:19 d2.utils.events]:  eta: 0:39:43  iter: 1439  total_loss: 4.22  loss_sem_seg: 2.376  loss_center: 0.6747  loss_offset: 1.039  time: 0.4290  data_time: 0.0249  lr: 0.0020323  max_mem: 11463M
[12/09 09:34:28 d2.utils.events]:  eta: 0:39:34  iter: 1459  total_loss: 4.372  loss_sem_seg: 2.454  loss_center: 0.6626  loss_offset: 0.9532  time: 0.4290  data_time: 0.0252  lr: 0.0020257  max_mem: 11463M
[12/09 09:34:36 d2.utils.events]:  eta: 0:39:25  iter: 1479  total_loss: 4.099  loss_sem_seg: 2.378  loss_center: 0.607  loss_offset: 1.167  time: 0.4290  data_time: 0.0260  lr: 0.0020191  max_mem: 11463M
[12/09 09:34:45 d2.utils.events]:  eta: 0:39:16  iter: 1499  total_loss: 4.122  loss_sem_seg: 2.224  loss_center: 0.8145  loss_offset: 1.066  time: 0.4290  data_time: 0.0251  lr: 0.0020126  max_mem: 11463M
[12/09 09:34:53 d2.utils.events]:  eta: 0:39:07  iter: 1519  total_loss: 4.051  loss_sem_seg: 2.251  loss_center: 0.7493  loss_offset: 1.038  time: 0.4290  data_time: 0.0262  lr: 0.002006  max_mem: 11463M
[12/09 09:35:02 d2.utils.events]:  eta: 0:39:00  iter: 1539  total_loss: 4.37  loss_sem_seg: 2.383  loss_center: 0.6757  loss_offset: 1.092  time: 0.4290  data_time: 0.0266  lr: 0.0019994  max_mem: 11463M
[12/09 09:35:11 d2.utils.events]:  eta: 0:38:51  iter: 1559  total_loss: 4.226  loss_sem_seg: 2.32  loss_center: 0.7938  loss_offset: 1.02  time: 0.4290  data_time: 0.0242  lr: 0.0019928  max_mem: 11463M
[12/09 09:35:19 d2.utils.events]:  eta: 0:38:43  iter: 1579  total_loss: 4.458  loss_sem_seg: 2.604  loss_center: 0.6545  loss_offset: 1.189  time: 0.4291  data_time: 0.0274  lr: 0.0019862  max_mem: 11463M
[12/09 09:35:28 d2.utils.events]:  eta: 0:38:35  iter: 1599  total_loss: 3.871  loss_sem_seg: 2.167  loss_center: 0.6953  loss_offset: 0.9696  time: 0.4291  data_time: 0.0258  lr: 0.0019796  max_mem: 11463M
[12/09 09:35:37 d2.utils.events]:  eta: 0:38:27  iter: 1619  total_loss: 4.325  loss_sem_seg: 2.497  loss_center: 0.7325  loss_offset: 1.095  time: 0.4291  data_time: 0.0261  lr: 0.001973  max_mem: 11463M
[12/09 09:35:45 d2.utils.events]:  eta: 0:38:19  iter: 1639  total_loss: 4.094  loss_sem_seg: 2.35  loss_center: 0.7056  loss_offset: 1.137  time: 0.4291  data_time: 0.0243  lr: 0.0019664  max_mem: 11463M
[12/09 09:35:54 d2.utils.events]:  eta: 0:38:10  iter: 1659  total_loss: 3.734  loss_sem_seg: 2.199  loss_center: 0.5011  loss_offset: 1.068  time: 0.4291  data_time: 0.0249  lr: 0.0019598  max_mem: 11463M
[12/09 09:36:02 d2.utils.events]:  eta: 0:38:00  iter: 1679  total_loss: 3.934  loss_sem_seg: 2.058  loss_center: 0.6785  loss_offset: 1.12  time: 0.4291  data_time: 0.0262  lr: 0.0019532  max_mem: 11463M
[12/09 09:36:11 d2.utils.events]:  eta: 0:37:52  iter: 1699  total_loss: 4.076  loss_sem_seg: 2.115  loss_center: 0.7486  loss_offset: 1.036  time: 0.4291  data_time: 0.0243  lr: 0.0019466  max_mem: 11463M
[12/09 09:36:20 d2.utils.events]:  eta: 0:37:43  iter: 1719  total_loss: 4.161  loss_sem_seg: 2.222  loss_center: 0.6144  loss_offset: 1.07  time: 0.4291  data_time: 0.0248  lr: 0.00194  max_mem: 11463M
[12/09 09:36:28 d2.utils.events]:  eta: 0:37:34  iter: 1739  total_loss: 4.091  loss_sem_seg: 2.203  loss_center: 0.7628  loss_offset: 1.045  time: 0.4291  data_time: 0.0243  lr: 0.0019334  max_mem: 11463M
[12/09 09:36:37 d2.utils.events]:  eta: 0:37:25  iter: 1759  total_loss: 3.86  loss_sem_seg: 2.082  loss_center: 0.8076  loss_offset: 1.018  time: 0.4291  data_time: 0.0251  lr: 0.0019267  max_mem: 11463M
[12/09 09:36:45 d2.utils.events]:  eta: 0:37:17  iter: 1779  total_loss: 4.145  loss_sem_seg: 2.309  loss_center: 0.8034  loss_offset: 1.042  time: 0.4291  data_time: 0.0257  lr: 0.0019201  max_mem: 11463M
[12/09 09:36:54 d2.utils.events]:  eta: 0:37:08  iter: 1799  total_loss: 3.958  loss_sem_seg: 2.042  loss_center: 0.78  loss_offset: 1.061  time: 0.4291  data_time: 0.0257  lr: 0.0019135  max_mem: 11463M
[12/09 09:37:02 d2.utils.events]:  eta: 0:36:59  iter: 1819  total_loss: 3.962  loss_sem_seg: 2.209  loss_center: 0.591  loss_offset: 1.075  time: 0.4291  data_time: 0.0264  lr: 0.0019069  max_mem: 11463M
[12/09 09:37:11 d2.utils.events]:  eta: 0:36:50  iter: 1839  total_loss: 3.919  loss_sem_seg: 2.092  loss_center: 0.7175  loss_offset: 0.9743  time: 0.4291  data_time: 0.0259  lr: 0.0019003  max_mem: 11463M
[12/09 09:37:20 d2.utils.events]:  eta: 0:36:41  iter: 1859  total_loss: 4.193  loss_sem_seg: 2.221  loss_center: 0.7561  loss_offset: 1.03  time: 0.4291  data_time: 0.0258  lr: 0.0018936  max_mem: 11463M
[12/09 09:37:28 d2.utils.events]:  eta: 0:36:33  iter: 1879  total_loss: 3.976  loss_sem_seg: 2.253  loss_center: 0.7295  loss_offset: 1.054  time: 0.4291  data_time: 0.0242  lr: 0.001887  max_mem: 11463M
[12/09 09:37:37 d2.utils.events]:  eta: 0:36:25  iter: 1899  total_loss: 4.067  loss_sem_seg: 2.353  loss_center: 0.7838  loss_offset: 1.027  time: 0.4291  data_time: 0.0260  lr: 0.0018804  max_mem: 11463M
[12/09 09:37:46 d2.utils.events]:  eta: 0:36:16  iter: 1919  total_loss: 4.169  loss_sem_seg: 2.233  loss_center: 0.8124  loss_offset: 0.9798  time: 0.4292  data_time: 0.0260  lr: 0.0018737  max_mem: 11463M
[12/09 09:37:54 d2.utils.events]:  eta: 0:36:07  iter: 1939  total_loss: 4.072  loss_sem_seg: 2.181  loss_center: 0.8173  loss_offset: 0.9945  time: 0.4292  data_time: 0.0257  lr: 0.0018671  max_mem: 11463M
[12/09 09:38:03 d2.utils.events]:  eta: 0:35:58  iter: 1959  total_loss: 3.975  loss_sem_seg: 2.317  loss_center: 0.702  loss_offset: 1.07  time: 0.4292  data_time: 0.0257  lr: 0.0018604  max_mem: 11463M
[12/09 09:38:11 d2.utils.events]:  eta: 0:35:50  iter: 1979  total_loss: 3.852  loss_sem_seg: 2.151  loss_center: 0.5609  loss_offset: 1.132  time: 0.4292  data_time: 0.0261  lr: 0.0018538  max_mem: 11463M
[12/09 09:38:20 d2.utils.events]:  eta: 0:35:42  iter: 1999  total_loss: 4.04  loss_sem_seg: 2.237  loss_center: 0.6116  loss_offset: 1.049  time: 0.4292  data_time: 0.0261  lr: 0.0018472  max_mem: 11463M
[12/09 09:38:29 d2.utils.events]:  eta: 0:35:33  iter: 2019  total_loss: 3.802  loss_sem_seg: 2.227  loss_center: 0.7334  loss_offset: 1.031  time: 0.4292  data_time: 0.0258  lr: 0.0018405  max_mem: 11463M
[12/09 09:38:37 d2.utils.events]:  eta: 0:35:24  iter: 2039  total_loss: 3.921  loss_sem_seg: 2.126  loss_center: 0.6659  loss_offset: 1.034  time: 0.4292  data_time: 0.0256  lr: 0.0018339  max_mem: 11463M
[12/09 09:38:46 d2.utils.events]:  eta: 0:35:15  iter: 2059  total_loss: 3.88  loss_sem_seg: 2.25  loss_center: 0.6365  loss_offset: 1.084  time: 0.4292  data_time: 0.0254  lr: 0.0018272  max_mem: 11463M
[12/09 09:38:55 d2.utils.events]:  eta: 0:35:06  iter: 2079  total_loss: 3.969  loss_sem_seg: 2.264  loss_center: 0.5115  loss_offset: 0.9938  time: 0.4292  data_time: 0.0257  lr: 0.0018205  max_mem: 11463M
[12/09 09:39:03 d2.utils.events]:  eta: 0:34:58  iter: 2099  total_loss: 4.117  loss_sem_seg: 2.232  loss_center: 0.7181  loss_offset: 1.096  time: 0.4292  data_time: 0.0245  lr: 0.0018139  max_mem: 11463M
[12/09 09:39:12 d2.utils.events]:  eta: 0:34:51  iter: 2119  total_loss: 4.018  loss_sem_seg: 2.173  loss_center: 0.6156  loss_offset: 1.006  time: 0.4293  data_time: 0.0258  lr: 0.0018072  max_mem: 11463M
[12/09 09:39:20 d2.utils.events]:  eta: 0:34:43  iter: 2139  total_loss: 3.924  loss_sem_seg: 2.032  loss_center: 0.7028  loss_offset: 1.017  time: 0.4293  data_time: 0.0247  lr: 0.0018005  max_mem: 11463M
[12/09 09:39:29 d2.utils.events]:  eta: 0:34:34  iter: 2159  total_loss: 3.906  loss_sem_seg: 2.092  loss_center: 0.7437  loss_offset: 0.9737  time: 0.4293  data_time: 0.0249  lr: 0.0017939  max_mem: 11463M
[12/09 09:39:38 d2.utils.events]:  eta: 0:34:26  iter: 2179  total_loss: 3.744  loss_sem_seg: 2.049  loss_center: 0.7323  loss_offset: 0.9444  time: 0.4292  data_time: 0.0249  lr: 0.0017872  max_mem: 11463M
[12/09 09:39:46 d2.utils.events]:  eta: 0:34:17  iter: 2199  total_loss: 3.522  loss_sem_seg: 1.944  loss_center: 0.6053  loss_offset: 0.8339  time: 0.4293  data_time: 0.0247  lr: 0.0017805  max_mem: 11463M
[12/09 09:39:55 d2.utils.events]:  eta: 0:34:09  iter: 2219  total_loss: 4.056  loss_sem_seg: 2.286  loss_center: 0.7256  loss_offset: 0.9438  time: 0.4293  data_time: 0.0255  lr: 0.0017739  max_mem: 11463M
[12/09 09:40:03 d2.utils.events]:  eta: 0:34:00  iter: 2239  total_loss: 3.886  loss_sem_seg: 2.139  loss_center: 0.7481  loss_offset: 0.9685  time: 0.4293  data_time: 0.0263  lr: 0.0017672  max_mem: 11463M
[12/09 09:40:12 d2.utils.events]:  eta: 0:33:51  iter: 2259  total_loss: 3.852  loss_sem_seg: 2.146  loss_center: 0.5489  loss_offset: 1.038  time: 0.4293  data_time: 0.0258  lr: 0.0017605  max_mem: 11463M
[12/09 09:40:21 d2.utils.events]:  eta: 0:33:43  iter: 2279  total_loss: 3.691  loss_sem_seg: 1.973  loss_center: 0.4923  loss_offset: 1.113  time: 0.4293  data_time: 0.0260  lr: 0.0017538  max_mem: 11463M
[12/09 09:40:29 d2.utils.events]:  eta: 0:33:34  iter: 2299  total_loss: 4.49  loss_sem_seg: 2.52  loss_center: 0.6717  loss_offset: 1.145  time: 0.4293  data_time: 0.0272  lr: 0.0017471  max_mem: 11463M
[12/09 09:40:38 d2.utils.events]:  eta: 0:33:25  iter: 2319  total_loss: 3.795  loss_sem_seg: 2.117  loss_center: 0.7912  loss_offset: 0.9799  time: 0.4293  data_time: 0.0253  lr: 0.0017404  max_mem: 11463M
[12/09 09:40:46 d2.utils.events]:  eta: 0:33:16  iter: 2339  total_loss: 4.084  loss_sem_seg: 2.317  loss_center: 0.5526  loss_offset: 1.073  time: 0.4293  data_time: 0.0256  lr: 0.0017337  max_mem: 11463M
[12/09 09:40:55 d2.utils.events]:  eta: 0:33:08  iter: 2359  total_loss: 3.965  loss_sem_seg: 2.224  loss_center: 0.6631  loss_offset: 1.074  time: 0.4293  data_time: 0.0261  lr: 0.001727  max_mem: 11463M
[12/09 09:41:04 d2.utils.events]:  eta: 0:32:59  iter: 2379  total_loss: 3.419  loss_sem_seg: 1.82  loss_center: 0.6932  loss_offset: 0.9764  time: 0.4293  data_time: 0.0252  lr: 0.0017203  max_mem: 11463M
[12/09 09:41:12 d2.utils.events]:  eta: 0:32:50  iter: 2399  total_loss: 3.974  loss_sem_seg: 2.055  loss_center: 0.6849  loss_offset: 1.034  time: 0.4293  data_time: 0.0251  lr: 0.0017136  max_mem: 11463M
[12/09 09:41:21 d2.utils.events]:  eta: 0:32:41  iter: 2419  total_loss: 4.209  loss_sem_seg: 2.269  loss_center: 0.7178  loss_offset: 1.106  time: 0.4293  data_time: 0.0241  lr: 0.0017069  max_mem: 11463M
[12/09 09:41:29 d2.utils.events]:  eta: 0:32:32  iter: 2439  total_loss: 4.042  loss_sem_seg: 2.266  loss_center: 0.6457  loss_offset: 1.126  time: 0.4293  data_time: 0.0257  lr: 0.0017002  max_mem: 11463M
[12/09 09:41:38 d2.utils.events]:  eta: 0:32:25  iter: 2459  total_loss: 3.586  loss_sem_seg: 1.891  loss_center: 0.5564  loss_offset: 0.9514  time: 0.4293  data_time: 0.0264  lr: 0.0016935  max_mem: 11463M
[12/09 09:41:46 d2.utils.events]:  eta: 0:32:17  iter: 2479  total_loss: 3.92  loss_sem_seg: 2.101  loss_center: 0.7467  loss_offset: 1.001  time: 0.4293  data_time: 0.0258  lr: 0.0016868  max_mem: 11463M
[12/09 09:41:55 d2.utils.events]:  eta: 0:32:09  iter: 2499  total_loss: 3.855  loss_sem_seg: 1.996  loss_center: 0.7546  loss_offset: 0.9449  time: 0.4293  data_time: 0.0264  lr: 0.0016801  max_mem: 11463M
[12/09 09:42:04 d2.utils.events]:  eta: 0:32:01  iter: 2519  total_loss: 3.872  loss_sem_seg: 2.053  loss_center: 0.6618  loss_offset: 1.079  time: 0.4293  data_time: 0.0249  lr: 0.0016734  max_mem: 11463M
[12/09 09:42:12 d2.utils.events]:  eta: 0:31:52  iter: 2539  total_loss: 3.831  loss_sem_seg: 2.066  loss_center: 0.5758  loss_offset: 1.085  time: 0.4293  data_time: 0.0255  lr: 0.0016666  max_mem: 11463M
[12/09 09:42:21 d2.utils.events]:  eta: 0:31:44  iter: 2559  total_loss: 3.982  loss_sem_seg: 2.302  loss_center: 0.6441  loss_offset: 0.9967  time: 0.4293  data_time: 0.0244  lr: 0.0016599  max_mem: 11463M
[12/09 09:42:29 d2.utils.events]:  eta: 0:31:35  iter: 2579  total_loss: 3.858  loss_sem_seg: 2.031  loss_center: 0.6782  loss_offset: 1.01  time: 0.4293  data_time: 0.0241  lr: 0.0016532  max_mem: 11463M
[12/09 09:42:38 d2.utils.events]:  eta: 0:31:26  iter: 2599  total_loss: 4.023  loss_sem_seg: 2.204  loss_center: 0.7816  loss_offset: 0.9847  time: 0.4293  data_time: 0.0257  lr: 0.0016464  max_mem: 11463M
[12/09 09:42:47 d2.utils.events]:  eta: 0:31:18  iter: 2619  total_loss: 4.08  loss_sem_seg: 2.294  loss_center: 0.8121  loss_offset: 0.9683  time: 0.4293  data_time: 0.0263  lr: 0.0016397  max_mem: 11463M
[12/09 09:42:55 d2.utils.events]:  eta: 0:31:10  iter: 2639  total_loss: 3.779  loss_sem_seg: 2.018  loss_center: 0.687  loss_offset: 1.044  time: 0.4293  data_time: 0.0243  lr: 0.001633  max_mem: 11463M
[12/09 09:43:04 d2.utils.events]:  eta: 0:31:01  iter: 2659  total_loss: 3.847  loss_sem_seg: 1.985  loss_center: 0.8051  loss_offset: 0.9793  time: 0.4293  data_time: 0.0272  lr: 0.0016262  max_mem: 11463M
[12/09 09:43:13 d2.utils.events]:  eta: 0:30:53  iter: 2679  total_loss: 3.726  loss_sem_seg: 1.927  loss_center: 0.6105  loss_offset: 1.067  time: 0.4293  data_time: 0.0255  lr: 0.0016195  max_mem: 11463M
[12/09 09:43:21 d2.utils.events]:  eta: 0:30:45  iter: 2699  total_loss: 4.071  loss_sem_seg: 2.36  loss_center: 0.5799  loss_offset: 1.05  time: 0.4293  data_time: 0.0262  lr: 0.0016127  max_mem: 11463M
[12/09 09:43:30 d2.utils.events]:  eta: 0:30:36  iter: 2719  total_loss: 3.692  loss_sem_seg: 1.953  loss_center: 0.7735  loss_offset: 1.043  time: 0.4293  data_time: 0.0246  lr: 0.001606  max_mem: 11463M
[12/09 09:43:38 d2.utils.events]:  eta: 0:30:28  iter: 2739  total_loss: 3.658  loss_sem_seg: 1.971  loss_center: 0.6817  loss_offset: 0.8526  time: 0.4293  data_time: 0.0249  lr: 0.0015992  max_mem: 11463M
[12/09 09:43:47 d2.utils.events]:  eta: 0:30:19  iter: 2759  total_loss: 3.479  loss_sem_seg: 1.922  loss_center: 0.6621  loss_offset: 0.9618  time: 0.4293  data_time: 0.0268  lr: 0.0015925  max_mem: 11463M
[12/09 09:43:56 d2.utils.events]:  eta: 0:30:11  iter: 2779  total_loss: 4.144  loss_sem_seg: 2.14  loss_center: 0.6241  loss_offset: 1.092  time: 0.4293  data_time: 0.0257  lr: 0.0015857  max_mem: 11463M
[12/09 09:44:04 d2.utils.events]:  eta: 0:30:02  iter: 2799  total_loss: 3.989  loss_sem_seg: 2.106  loss_center: 0.6666  loss_offset: 1.111  time: 0.4293  data_time: 0.0265  lr: 0.001579  max_mem: 11463M
[12/09 09:44:13 d2.utils.events]:  eta: 0:29:54  iter: 2819  total_loss: 3.754  loss_sem_seg: 2.148  loss_center: 0.5732  loss_offset: 1.002  time: 0.4293  data_time: 0.0258  lr: 0.0015722  max_mem: 11463M
[12/09 09:44:21 d2.utils.events]:  eta: 0:29:45  iter: 2839  total_loss: 3.816  loss_sem_seg: 2.047  loss_center: 0.6036  loss_offset: 1.095  time: 0.4293  data_time: 0.0238  lr: 0.0015654  max_mem: 11463M
[12/09 09:44:30 d2.utils.events]:  eta: 0:29:36  iter: 2859  total_loss: 3.606  loss_sem_seg: 2.004  loss_center: 0.6239  loss_offset: 1.042  time: 0.4293  data_time: 0.0252  lr: 0.0015586  max_mem: 11463M
[12/09 09:44:39 d2.utils.events]:  eta: 0:29:28  iter: 2879  total_loss: 3.788  loss_sem_seg: 1.859  loss_center: 0.6809  loss_offset: 1.054  time: 0.4293  data_time: 0.0258  lr: 0.0015519  max_mem: 11463M
[12/09 09:44:47 d2.utils.events]:  eta: 0:29:19  iter: 2899  total_loss: 4.132  loss_sem_seg: 2.185  loss_center: 0.8528  loss_offset: 1.069  time: 0.4293  data_time: 0.0253  lr: 0.0015451  max_mem: 11463M
[12/09 09:44:56 d2.utils.events]:  eta: 0:29:11  iter: 2919  total_loss: 3.891  loss_sem_seg: 2.334  loss_center: 0.6028  loss_offset: 1.004  time: 0.4293  data_time: 0.0254  lr: 0.0015383  max_mem: 11463M
[12/09 09:45:04 d2.utils.events]:  eta: 0:29:02  iter: 2939  total_loss: 3.778  loss_sem_seg: 2.091  loss_center: 0.6986  loss_offset: 0.9697  time: 0.4293  data_time: 0.0260  lr: 0.0015315  max_mem: 11463M
[12/09 09:45:13 d2.utils.events]:  eta: 0:28:54  iter: 2959  total_loss: 4.085  loss_sem_seg: 2.414  loss_center: 0.5769  loss_offset: 1.046  time: 0.4294  data_time: 0.0255  lr: 0.0015247  max_mem: 11463M
[12/09 09:45:22 d2.utils.events]:  eta: 0:28:45  iter: 2979  total_loss: 3.757  loss_sem_seg: 1.942  loss_center: 0.6915  loss_offset: 1.015  time: 0.4294  data_time: 0.0254  lr: 0.0015179  max_mem: 11463M
[12/09 09:45:30 d2.utils.events]:  eta: 0:28:37  iter: 2999  total_loss: 3.762  loss_sem_seg: 2.067  loss_center: 0.6208  loss_offset: 1.088  time: 0.4294  data_time: 0.0264  lr: 0.0015111  max_mem: 11463M
[12/09 09:45:39 d2.utils.events]:  eta: 0:28:28  iter: 3019  total_loss: 3.929  loss_sem_seg: 1.912  loss_center: 0.6794  loss_offset: 1.046  time: 0.4294  data_time: 0.0245  lr: 0.0015043  max_mem: 11463M
[12/09 09:45:48 d2.utils.events]:  eta: 0:28:19  iter: 3039  total_loss: 3.818  loss_sem_seg: 2.056  loss_center: 0.6936  loss_offset: 0.946  time: 0.4294  data_time: 0.0258  lr: 0.0014975  max_mem: 11463M
[12/09 09:45:56 d2.utils.events]:  eta: 0:28:11  iter: 3059  total_loss: 3.957  loss_sem_seg: 2.299  loss_center: 0.7644  loss_offset: 0.9811  time: 0.4294  data_time: 0.0250  lr: 0.0014907  max_mem: 11463M
[12/09 09:46:05 d2.utils.events]:  eta: 0:28:02  iter: 3079  total_loss: 3.826  loss_sem_seg: 2.004  loss_center: 0.6843  loss_offset: 0.9432  time: 0.4294  data_time: 0.0255  lr: 0.0014839  max_mem: 11463M
[12/09 09:46:13 d2.utils.events]:  eta: 0:27:54  iter: 3099  total_loss: 3.694  loss_sem_seg: 2.086  loss_center: 0.6521  loss_offset: 0.9553  time: 0.4294  data_time: 0.0266  lr: 0.0014771  max_mem: 11463M
[12/09 09:46:22 d2.utils.events]:  eta: 0:27:45  iter: 3119  total_loss: 3.896  loss_sem_seg: 2.173  loss_center: 0.8085  loss_offset: 0.9513  time: 0.4294  data_time: 0.0256  lr: 0.0014703  max_mem: 11463M
[12/09 09:46:31 d2.utils.events]:  eta: 0:27:36  iter: 3139  total_loss: 3.763  loss_sem_seg: 2.107  loss_center: 0.6966  loss_offset: 0.8899  time: 0.4294  data_time: 0.0252  lr: 0.0014635  max_mem: 11463M
[12/09 09:46:39 d2.utils.events]:  eta: 0:27:28  iter: 3159  total_loss: 3.498  loss_sem_seg: 1.83  loss_center: 0.6356  loss_offset: 0.9617  time: 0.4294  data_time: 0.0249  lr: 0.0014566  max_mem: 11463M
[12/09 09:46:48 d2.utils.events]:  eta: 0:27:19  iter: 3179  total_loss: 3.642  loss_sem_seg: 1.965  loss_center: 0.5539  loss_offset: 0.916  time: 0.4294  data_time: 0.0250  lr: 0.0014498  max_mem: 11463M
[12/09 09:46:57 d2.utils.events]:  eta: 0:27:11  iter: 3199  total_loss: 3.744  loss_sem_seg: 2.045  loss_center: 0.6155  loss_offset: 0.9737  time: 0.4295  data_time: 0.0282  lr: 0.001443  max_mem: 11463M
[12/09 09:47:05 d2.utils.events]:  eta: 0:27:02  iter: 3219  total_loss: 3.536  loss_sem_seg: 2.004  loss_center: 0.6636  loss_offset: 0.8719  time: 0.4295  data_time: 0.0254  lr: 0.0014361  max_mem: 11463M
[12/09 09:47:14 d2.utils.events]:  eta: 0:26:54  iter: 3239  total_loss: 3.501  loss_sem_seg: 1.965  loss_center: 0.7683  loss_offset: 0.9624  time: 0.4295  data_time: 0.0262  lr: 0.0014293  max_mem: 11463M
[12/09 09:47:22 d2.utils.events]:  eta: 0:26:45  iter: 3259  total_loss: 3.876  loss_sem_seg: 2.031  loss_center: 0.7499  loss_offset: 0.9795  time: 0.4295  data_time: 0.0250  lr: 0.0014225  max_mem: 11463M
[12/09 09:47:31 d2.utils.events]:  eta: 0:26:37  iter: 3279  total_loss: 3.681  loss_sem_seg: 1.817  loss_center: 0.7091  loss_offset: 0.9791  time: 0.4295  data_time: 0.0253  lr: 0.0014156  max_mem: 11463M
[12/09 09:47:40 d2.utils.events]:  eta: 0:26:29  iter: 3299  total_loss: 3.421  loss_sem_seg: 1.855  loss_center: 0.6612  loss_offset: 0.9044  time: 0.4295  data_time: 0.0256  lr: 0.0014088  max_mem: 11463M
[12/09 09:47:48 d2.utils.events]:  eta: 0:26:20  iter: 3319  total_loss: 3.745  loss_sem_seg: 1.883  loss_center: 0.7485  loss_offset: 0.9768  time: 0.4295  data_time: 0.0257  lr: 0.0014019  max_mem: 11463M
[12/09 09:47:57 d2.utils.events]:  eta: 0:26:12  iter: 3339  total_loss: 3.979  loss_sem_seg: 2.064  loss_center: 0.7354  loss_offset: 1.049  time: 0.4295  data_time: 0.0251  lr: 0.0013951  max_mem: 11463M
[12/09 09:48:06 d2.utils.events]:  eta: 0:26:03  iter: 3359  total_loss: 3.641  loss_sem_seg: 1.917  loss_center: 0.5544  loss_offset: 0.9426  time: 0.4295  data_time: 0.0251  lr: 0.0013882  max_mem: 11463M
[12/09 09:48:14 d2.utils.events]:  eta: 0:25:55  iter: 3379  total_loss: 3.558  loss_sem_seg: 1.972  loss_center: 0.6558  loss_offset: 1.013  time: 0.4295  data_time: 0.0253  lr: 0.0013813  max_mem: 11463M
[12/09 09:48:23 d2.utils.events]:  eta: 0:25:46  iter: 3399  total_loss: 3.585  loss_sem_seg: 1.901  loss_center: 0.6467  loss_offset: 0.9306  time: 0.4295  data_time: 0.0251  lr: 0.0013745  max_mem: 11463M
[12/09 09:48:31 d2.utils.events]:  eta: 0:25:38  iter: 3419  total_loss: 3.784  loss_sem_seg: 2.261  loss_center: 0.5036  loss_offset: 0.93  time: 0.4295  data_time: 0.0257  lr: 0.0013676  max_mem: 11463M
[12/09 09:48:40 d2.utils.events]:  eta: 0:25:29  iter: 3439  total_loss: 3.673  loss_sem_seg: 2.062  loss_center: 0.6178  loss_offset: 0.9312  time: 0.4295  data_time: 0.0258  lr: 0.0013607  max_mem: 11463M
[12/09 09:48:49 d2.utils.events]:  eta: 0:25:21  iter: 3459  total_loss: 3.695  loss_sem_seg: 2.047  loss_center: 0.6704  loss_offset: 0.9069  time: 0.4295  data_time: 0.0251  lr: 0.0013538  max_mem: 11463M
[12/09 09:48:57 d2.utils.events]:  eta: 0:25:12  iter: 3479  total_loss: 3.757  loss_sem_seg: 1.987  loss_center: 0.6268  loss_offset: 1.133  time: 0.4295  data_time: 0.0259  lr: 0.0013469  max_mem: 11463M
[12/09 09:49:06 d2.utils.events]:  eta: 0:25:03  iter: 3499  total_loss: 3.864  loss_sem_seg: 2.024  loss_center: 0.7829  loss_offset: 0.8493  time: 0.4295  data_time: 0.0254  lr: 0.0013401  max_mem: 11463M
[12/09 09:49:14 d2.utils.events]:  eta: 0:24:54  iter: 3519  total_loss: 3.68  loss_sem_seg: 1.734  loss_center: 0.8507  loss_offset: 0.8546  time: 0.4295  data_time: 0.0240  lr: 0.0013332  max_mem: 11463M
[12/09 09:49:23 d2.utils.events]:  eta: 0:24:45  iter: 3539  total_loss: 3.568  loss_sem_seg: 2.099  loss_center: 0.6672  loss_offset: 0.9405  time: 0.4295  data_time: 0.0245  lr: 0.0013263  max_mem: 11463M
[12/09 09:49:32 d2.utils.events]:  eta: 0:24:37  iter: 3559  total_loss: 3.621  loss_sem_seg: 2.006  loss_center: 0.645  loss_offset: 0.9216  time: 0.4295  data_time: 0.0259  lr: 0.0013194  max_mem: 11463M
[12/09 09:49:40 d2.utils.events]:  eta: 0:24:28  iter: 3579  total_loss: 3.659  loss_sem_seg: 2.194  loss_center: 0.5597  loss_offset: 0.9245  time: 0.4295  data_time: 0.0267  lr: 0.0013125  max_mem: 11463M
[12/09 09:49:49 d2.utils.events]:  eta: 0:24:20  iter: 3599  total_loss: 4.012  loss_sem_seg: 2.163  loss_center: 0.8356  loss_offset: 1.045  time: 0.4295  data_time: 0.0262  lr: 0.0013056  max_mem: 11463M
[12/09 09:49:57 d2.utils.events]:  eta: 0:24:10  iter: 3619  total_loss: 3.561  loss_sem_seg: 1.973  loss_center: 0.6421  loss_offset: 0.923  time: 0.4295  data_time: 0.0245  lr: 0.0012987  max_mem: 11463M
[12/09 09:50:06 d2.utils.events]:  eta: 0:24:01  iter: 3639  total_loss: 3.902  loss_sem_seg: 2.045  loss_center: 0.7964  loss_offset: 0.9613  time: 0.4295  data_time: 0.0242  lr: 0.0012917  max_mem: 11463M
[12/09 09:50:15 d2.utils.events]:  eta: 0:23:52  iter: 3659  total_loss: 3.655  loss_sem_seg: 1.885  loss_center: 0.6501  loss_offset: 1.006  time: 0.4295  data_time: 0.0255  lr: 0.0012848  max_mem: 11463M
[12/09 09:50:23 d2.utils.events]:  eta: 0:23:43  iter: 3679  total_loss: 3.477  loss_sem_seg: 1.731  loss_center: 0.6001  loss_offset: 0.8995  time: 0.4295  data_time: 0.0270  lr: 0.0012779  max_mem: 11463M
[12/09 09:50:32 d2.utils.events]:  eta: 0:23:35  iter: 3699  total_loss: 3.359  loss_sem_seg: 1.984  loss_center: 0.6011  loss_offset: 0.8742  time: 0.4295  data_time: 0.0256  lr: 0.001271  max_mem: 11463M
[12/09 09:50:40 d2.utils.events]:  eta: 0:23:26  iter: 3719  total_loss: 3.74  loss_sem_seg: 2.145  loss_center: 0.5883  loss_offset: 1.036  time: 0.4295  data_time: 0.0254  lr: 0.001264  max_mem: 11463M
[12/09 09:50:49 d2.utils.events]:  eta: 0:23:18  iter: 3739  total_loss: 3.703  loss_sem_seg: 2.003  loss_center: 0.6847  loss_offset: 1.04  time: 0.4295  data_time: 0.0258  lr: 0.0012571  max_mem: 11463M
[12/09 09:50:58 d2.utils.events]:  eta: 0:23:09  iter: 3759  total_loss: 3.643  loss_sem_seg: 1.968  loss_center: 0.5084  loss_offset: 0.9398  time: 0.4295  data_time: 0.0242  lr: 0.0012502  max_mem: 11463M
[12/09 09:51:06 d2.utils.events]:  eta: 0:23:00  iter: 3779  total_loss: 3.805  loss_sem_seg: 2.114  loss_center: 0.5652  loss_offset: 0.9368  time: 0.4295  data_time: 0.0254  lr: 0.0012432  max_mem: 11463M
[12/09 09:51:15 d2.utils.events]:  eta: 0:22:51  iter: 3799  total_loss: 3.697  loss_sem_seg: 2.061  loss_center: 0.6767  loss_offset: 0.9384  time: 0.4295  data_time: 0.0259  lr: 0.0012363  max_mem: 11463M
[12/09 09:51:23 d2.utils.events]:  eta: 0:22:43  iter: 3819  total_loss: 3.985  loss_sem_seg: 2.177  loss_center: 0.6305  loss_offset: 1.012  time: 0.4295  data_time: 0.0254  lr: 0.0012293  max_mem: 11463M
[12/09 09:51:32 d2.utils.events]:  eta: 0:22:34  iter: 3839  total_loss: 3.713  loss_sem_seg: 1.968  loss_center: 0.6489  loss_offset: 0.9725  time: 0.4295  data_time: 0.0246  lr: 0.0012223  max_mem: 11463M
[12/09 09:51:41 d2.utils.events]:  eta: 0:22:25  iter: 3859  total_loss: 3.351  loss_sem_seg: 1.776  loss_center: 0.6522  loss_offset: 0.9246  time: 0.4295  data_time: 0.0244  lr: 0.0012154  max_mem: 11463M
[12/09 09:51:49 d2.utils.events]:  eta: 0:22:17  iter: 3879  total_loss: 3.565  loss_sem_seg: 1.782  loss_center: 0.5851  loss_offset: 0.9941  time: 0.4295  data_time: 0.0255  lr: 0.0012084  max_mem: 11463M
[12/09 09:51:58 d2.utils.events]:  eta: 0:22:08  iter: 3899  total_loss: 3.832  loss_sem_seg: 1.995  loss_center: 0.8274  loss_offset: 0.9675  time: 0.4295  data_time: 0.0267  lr: 0.0012014  max_mem: 11463M
[12/09 09:52:06 d2.utils.events]:  eta: 0:22:00  iter: 3919  total_loss: 3.691  loss_sem_seg: 1.855  loss_center: 0.6799  loss_offset: 0.9484  time: 0.4295  data_time: 0.0250  lr: 0.0011945  max_mem: 11463M
[12/09 09:52:15 d2.utils.events]:  eta: 0:21:51  iter: 3939  total_loss: 3.381  loss_sem_seg: 1.754  loss_center: 0.5959  loss_offset: 0.8905  time: 0.4295  data_time: 0.0262  lr: 0.0011875  max_mem: 11463M
[12/09 09:52:24 d2.utils.events]:  eta: 0:21:43  iter: 3959  total_loss: 3.541  loss_sem_seg: 1.832  loss_center: 0.6874  loss_offset: 0.9844  time: 0.4295  data_time: 0.0259  lr: 0.0011805  max_mem: 11463M
[12/09 09:52:32 d2.utils.events]:  eta: 0:21:34  iter: 3979  total_loss: 3.651  loss_sem_seg: 1.932  loss_center: 0.6012  loss_offset: 0.9848  time: 0.4295  data_time: 0.0247  lr: 0.0011735  max_mem: 11463M
[12/09 09:52:41 d2.utils.events]:  eta: 0:21:26  iter: 3999  total_loss: 3.381  loss_sem_seg: 1.743  loss_center: 0.615  loss_offset: 0.9351  time: 0.4295  data_time: 0.0241  lr: 0.0011665  max_mem: 11463M
[12/09 09:52:49 d2.utils.events]:  eta: 0:21:17  iter: 4019  total_loss: 3.661  loss_sem_seg: 2.077  loss_center: 0.7505  loss_offset: 0.9517  time: 0.4295  data_time: 0.0255  lr: 0.0011595  max_mem: 11463M
[12/09 09:52:58 d2.utils.events]:  eta: 0:21:08  iter: 4039  total_loss: 3.917  loss_sem_seg: 2.243  loss_center: 0.5756  loss_offset: 0.9996  time: 0.4295  data_time: 0.0263  lr: 0.0011525  max_mem: 11463M
[12/09 09:53:07 d2.utils.events]:  eta: 0:21:00  iter: 4059  total_loss: 3.526  loss_sem_seg: 1.995  loss_center: 0.5552  loss_offset: 0.9481  time: 0.4295  data_time: 0.0255  lr: 0.0011455  max_mem: 11463M
[12/09 09:53:15 d2.utils.events]:  eta: 0:20:51  iter: 4079  total_loss: 3.833  loss_sem_seg: 1.876  loss_center: 0.7766  loss_offset: 0.989  time: 0.4295  data_time: 0.0245  lr: 0.0011385  max_mem: 11463M
[12/09 09:53:24 d2.utils.events]:  eta: 0:20:42  iter: 4099  total_loss: 3.551  loss_sem_seg: 1.769  loss_center: 0.7199  loss_offset: 0.8716  time: 0.4295  data_time: 0.0258  lr: 0.0011315  max_mem: 11463M
[12/09 09:53:32 d2.utils.events]:  eta: 0:20:34  iter: 4119  total_loss: 3.346  loss_sem_seg: 1.755  loss_center: 0.5517  loss_offset: 0.8656  time: 0.4295  data_time: 0.0251  lr: 0.0011245  max_mem: 11463M
[12/09 09:53:41 d2.utils.events]:  eta: 0:20:25  iter: 4139  total_loss: 3.234  loss_sem_seg: 1.544  loss_center: 0.778  loss_offset: 1.034  time: 0.4295  data_time: 0.0251  lr: 0.0011174  max_mem: 11463M
[12/09 09:53:50 d2.utils.events]:  eta: 0:20:17  iter: 4159  total_loss: 3.457  loss_sem_seg: 1.701  loss_center: 0.6715  loss_offset: 0.9359  time: 0.4295  data_time: 0.0255  lr: 0.0011104  max_mem: 11463M
[12/09 09:53:58 d2.utils.events]:  eta: 0:20:08  iter: 4179  total_loss: 3.677  loss_sem_seg: 1.8  loss_center: 0.6412  loss_offset: 0.9694  time: 0.4295  data_time: 0.0245  lr: 0.0011034  max_mem: 11463M
[12/09 09:54:07 d2.utils.events]:  eta: 0:19:59  iter: 4199  total_loss: 3.584  loss_sem_seg: 1.851  loss_center: 0.6855  loss_offset: 0.9948  time: 0.4295  data_time: 0.0252  lr: 0.0010963  max_mem: 11463M
[12/09 09:54:15 d2.utils.events]:  eta: 0:19:51  iter: 4219  total_loss: 3.58  loss_sem_seg: 2.09  loss_center: 0.6369  loss_offset: 0.9045  time: 0.4295  data_time: 0.0267  lr: 0.0010893  max_mem: 11463M
[12/09 09:54:24 d2.utils.events]:  eta: 0:19:42  iter: 4239  total_loss: 3.474  loss_sem_seg: 1.889  loss_center: 0.6424  loss_offset: 0.9208  time: 0.4295  data_time: 0.0245  lr: 0.0010822  max_mem: 11463M
[12/09 09:54:33 d2.utils.events]:  eta: 0:19:34  iter: 4259  total_loss: 3.706  loss_sem_seg: 1.969  loss_center: 0.764  loss_offset: 0.9592  time: 0.4295  data_time: 0.0259  lr: 0.0010752  max_mem: 11463M
[12/09 09:54:41 d2.utils.events]:  eta: 0:19:25  iter: 4279  total_loss: 3.298  loss_sem_seg: 1.696  loss_center: 0.5207  loss_offset: 0.9346  time: 0.4295  data_time: 0.0260  lr: 0.0010681  max_mem: 11463M
[12/09 09:54:50 d2.utils.events]:  eta: 0:19:17  iter: 4299  total_loss: 3.197  loss_sem_seg: 1.919  loss_center: 0.4772  loss_offset: 0.8516  time: 0.4295  data_time: 0.0258  lr: 0.001061  max_mem: 11463M
[12/09 09:54:59 d2.utils.events]:  eta: 0:19:08  iter: 4319  total_loss: 3.202  loss_sem_seg: 1.726  loss_center: 0.5879  loss_offset: 0.7534  time: 0.4295  data_time: 0.0243  lr: 0.0010539  max_mem: 11463M
[12/09 09:55:07 d2.utils.events]:  eta: 0:19:00  iter: 4339  total_loss: 3.625  loss_sem_seg: 1.796  loss_center: 0.6367  loss_offset: 0.9162  time: 0.4295  data_time: 0.0260  lr: 0.0010469  max_mem: 11463M
[12/09 09:55:16 d2.utils.events]:  eta: 0:18:51  iter: 4359  total_loss: 3.311  loss_sem_seg: 1.747  loss_center: 0.6324  loss_offset: 0.8832  time: 0.4295  data_time: 0.0258  lr: 0.0010398  max_mem: 11463M
[12/09 09:55:24 d2.utils.events]:  eta: 0:18:43  iter: 4379  total_loss: 3.345  loss_sem_seg: 1.862  loss_center: 0.6185  loss_offset: 0.8801  time: 0.4295  data_time: 0.0233  lr: 0.0010327  max_mem: 11463M
[12/09 09:55:33 d2.utils.events]:  eta: 0:18:34  iter: 4399  total_loss: 3.626  loss_sem_seg: 2.046  loss_center: 0.6854  loss_offset: 0.9931  time: 0.4295  data_time: 0.0262  lr: 0.0010256  max_mem: 11463M
[12/09 09:55:42 d2.utils.events]:  eta: 0:18:25  iter: 4419  total_loss: 3.329  loss_sem_seg: 1.783  loss_center: 0.5686  loss_offset: 0.868  time: 0.4295  data_time: 0.0270  lr: 0.0010185  max_mem: 11463M
[12/09 09:55:50 d2.utils.events]:  eta: 0:18:17  iter: 4439  total_loss: 3.2  loss_sem_seg: 1.712  loss_center: 0.5835  loss_offset: 0.871  time: 0.4295  data_time: 0.0261  lr: 0.0010114  max_mem: 11463M
[12/09 09:55:59 d2.utils.events]:  eta: 0:18:08  iter: 4459  total_loss: 3.095  loss_sem_seg: 1.708  loss_center: 0.6679  loss_offset: 0.8307  time: 0.4295  data_time: 0.0234  lr: 0.0010043  max_mem: 11463M
[12/09 09:56:07 d2.utils.events]:  eta: 0:18:00  iter: 4479  total_loss: 3.644  loss_sem_seg: 1.888  loss_center: 0.6688  loss_offset: 0.8659  time: 0.4295  data_time: 0.0263  lr: 0.00099717  max_mem: 11463M
[12/09 09:56:16 d2.utils.events]:  eta: 0:17:53  iter: 4499  total_loss: 3.578  loss_sem_seg: 1.813  loss_center: 0.5122  loss_offset: 0.9487  time: 0.4295  data_time: 0.0258  lr: 0.00099004  max_mem: 11463M
[12/09 09:56:25 d2.utils.events]:  eta: 0:17:43  iter: 4519  total_loss: 3.297  loss_sem_seg: 1.751  loss_center: 0.5055  loss_offset: 0.9834  time: 0.4295  data_time: 0.0253  lr: 0.00098291  max_mem: 11463M
[12/09 09:56:33 d2.utils.events]:  eta: 0:17:34  iter: 4539  total_loss: 3.301  loss_sem_seg: 1.792  loss_center: 0.7265  loss_offset: 0.9029  time: 0.4295  data_time: 0.0253  lr: 0.00097578  max_mem: 11463M
[12/09 09:56:42 d2.utils.events]:  eta: 0:17:26  iter: 4559  total_loss: 3.53  loss_sem_seg: 1.966  loss_center: 0.5787  loss_offset: 0.9415  time: 0.4295  data_time: 0.0256  lr: 0.00096864  max_mem: 11463M
[12/09 09:56:51 d2.utils.events]:  eta: 0:17:17  iter: 4579  total_loss: 3.469  loss_sem_seg: 1.85  loss_center: 0.6226  loss_offset: 1.009  time: 0.4295  data_time: 0.0260  lr: 0.0009615  max_mem: 11463M
[12/09 09:56:59 d2.utils.events]:  eta: 0:17:09  iter: 4599  total_loss: 3.571  loss_sem_seg: 1.804  loss_center: 0.722  loss_offset: 0.9536  time: 0.4295  data_time: 0.0263  lr: 0.00095434  max_mem: 11463M
[12/09 09:57:08 d2.utils.events]:  eta: 0:17:00  iter: 4619  total_loss: 3.648  loss_sem_seg: 2.037  loss_center: 0.6136  loss_offset: 1.015  time: 0.4295  data_time: 0.0252  lr: 0.00094719  max_mem: 11463M
[12/09 09:57:16 d2.utils.events]:  eta: 0:16:52  iter: 4639  total_loss: 3.734  loss_sem_seg: 1.921  loss_center: 0.7942  loss_offset: 0.9804  time: 0.4295  data_time: 0.0255  lr: 0.00094002  max_mem: 11463M
[12/09 09:57:25 d2.utils.events]:  eta: 0:16:43  iter: 4659  total_loss: 3.557  loss_sem_seg: 1.831  loss_center: 0.731  loss_offset: 0.9002  time: 0.4295  data_time: 0.0255  lr: 0.00093285  max_mem: 11463M
[12/09 09:57:34 d2.utils.events]:  eta: 0:16:35  iter: 4679  total_loss: 3.455  loss_sem_seg: 1.916  loss_center: 0.5984  loss_offset: 0.9794  time: 0.4295  data_time: 0.0262  lr: 0.00092568  max_mem: 11463M
[12/09 09:57:42 d2.utils.events]:  eta: 0:16:27  iter: 4699  total_loss: 3.481  loss_sem_seg: 1.947  loss_center: 0.6571  loss_offset: 0.8979  time: 0.4295  data_time: 0.0256  lr: 0.00091849  max_mem: 11463M
[12/09 09:57:51 d2.utils.events]:  eta: 0:16:18  iter: 4719  total_loss: 3.764  loss_sem_seg: 1.872  loss_center: 0.6624  loss_offset: 0.9842  time: 0.4295  data_time: 0.0252  lr: 0.00091131  max_mem: 11463M
[12/09 09:57:59 d2.utils.events]:  eta: 0:16:10  iter: 4739  total_loss: 3.499  loss_sem_seg: 1.855  loss_center: 0.634  loss_offset: 0.9299  time: 0.4295  data_time: 0.0255  lr: 0.00090411  max_mem: 11463M
[12/09 09:58:08 d2.utils.events]:  eta: 0:16:01  iter: 4759  total_loss: 3.294  loss_sem_seg: 1.536  loss_center: 0.7492  loss_offset: 0.7879  time: 0.4295  data_time: 0.0260  lr: 0.00089691  max_mem: 11463M
[12/09 09:58:17 d2.utils.events]:  eta: 0:15:52  iter: 4779  total_loss: 3.388  loss_sem_seg: 1.798  loss_center: 0.7443  loss_offset: 0.9316  time: 0.4295  data_time: 0.0247  lr: 0.0008897  max_mem: 11463M
[12/09 09:58:25 d2.utils.events]:  eta: 0:15:44  iter: 4799  total_loss: 3.541  loss_sem_seg: 2.128  loss_center: 0.627  loss_offset: 0.794  time: 0.4296  data_time: 0.0269  lr: 0.00088249  max_mem: 11463M
[12/09 09:58:34 d2.utils.events]:  eta: 0:15:35  iter: 4819  total_loss: 3.214  loss_sem_seg: 1.865  loss_center: 0.7326  loss_offset: 0.835  time: 0.4295  data_time: 0.0252  lr: 0.00087527  max_mem: 11463M
[12/09 09:58:42 d2.utils.events]:  eta: 0:15:27  iter: 4839  total_loss: 3.017  loss_sem_seg: 1.732  loss_center: 0.6367  loss_offset: 0.7834  time: 0.4295  data_time: 0.0243  lr: 0.00086804  max_mem: 11463M
[12/09 09:58:51 d2.utils.events]:  eta: 0:15:18  iter: 4859  total_loss: 3.475  loss_sem_seg: 1.768  loss_center: 0.6779  loss_offset: 0.8621  time: 0.4295  data_time: 0.0253  lr: 0.00086081  max_mem: 11463M
[12/09 09:59:00 d2.utils.events]:  eta: 0:15:10  iter: 4879  total_loss: 3.584  loss_sem_seg: 1.738  loss_center: 0.7248  loss_offset: 0.9727  time: 0.4295  data_time: 0.0256  lr: 0.00085357  max_mem: 11463M
[12/09 09:59:08 d2.utils.events]:  eta: 0:15:01  iter: 4899  total_loss: 3.336  loss_sem_seg: 1.64  loss_center: 0.808  loss_offset: 0.9696  time: 0.4295  data_time: 0.0239  lr: 0.00084632  max_mem: 11463M
[12/09 09:59:17 d2.utils.events]:  eta: 0:14:52  iter: 4919  total_loss: 3.289  loss_sem_seg: 1.863  loss_center: 0.5561  loss_offset: 0.8097  time: 0.4295  data_time: 0.0257  lr: 0.00083907  max_mem: 11463M
[12/09 09:59:25 d2.utils.events]:  eta: 0:14:44  iter: 4939  total_loss: 3.384  loss_sem_seg: 1.787  loss_center: 0.7589  loss_offset: 0.8375  time: 0.4295  data_time: 0.0250  lr: 0.00083181  max_mem: 11463M
[12/09 09:59:34 d2.utils.events]:  eta: 0:14:35  iter: 4959  total_loss: 3.276  loss_sem_seg: 1.745  loss_center: 0.5162  loss_offset: 0.8369  time: 0.4295  data_time: 0.0248  lr: 0.00082454  max_mem: 11463M
[12/09 09:59:43 d2.utils.events]:  eta: 0:14:26  iter: 4979  total_loss: 3.423  loss_sem_seg: 2.011  loss_center: 0.5644  loss_offset: 0.918  time: 0.4295  data_time: 0.0258  lr: 0.00081726  max_mem: 11463M
[12/09 09:59:51 fvcore.common.checkpoint]: Saving checkpoint to ./output/model_0004999.pth
[12/09 09:59:52 d2.utils.events]:  eta: 0:14:17  iter: 4999  total_loss: 3.548  loss_sem_seg: 1.899  loss_center: 0.6151  loss_offset: 0.939  time: 0.4295  data_time: 0.0254  lr: 0.00080998  max_mem: 11463M
[12/09 10:00:01 d2.utils.events]:  eta: 0:14:09  iter: 5019  total_loss: 3.28  loss_sem_seg: 1.713  loss_center: 0.7136  loss_offset: 0.8537  time: 0.4295  data_time: 0.0256  lr: 0.00080269  max_mem: 11463M
[12/09 10:00:10 d2.utils.events]:  eta: 0:14:00  iter: 5039  total_loss: 3.421  loss_sem_seg: 1.873  loss_center: 0.7222  loss_offset: 0.8415  time: 0.4295  data_time: 0.0267  lr: 0.00079539  max_mem: 11463M
[12/09 10:00:18 d2.utils.events]:  eta: 0:13:52  iter: 5059  total_loss: 3.485  loss_sem_seg: 1.827  loss_center: 0.6915  loss_offset: 0.807  time: 0.4295  data_time: 0.0262  lr: 0.00078809  max_mem: 11463M
[12/09 10:00:27 d2.utils.events]:  eta: 0:13:43  iter: 5079  total_loss: 3.127  loss_sem_seg: 1.741  loss_center: 0.6956  loss_offset: 0.8847  time: 0.4295  data_time: 0.0252  lr: 0.00078078  max_mem: 11463M
[12/09 10:00:35 d2.utils.events]:  eta: 0:13:35  iter: 5099  total_loss: 3.16  loss_sem_seg: 1.449  loss_center: 0.7307  loss_offset: 0.8606  time: 0.4295  data_time: 0.0259  lr: 0.00077346  max_mem: 11463M
[12/09 10:00:44 d2.utils.events]:  eta: 0:13:26  iter: 5119  total_loss: 3.212  loss_sem_seg: 1.764  loss_center: 0.612  loss_offset: 0.7768  time: 0.4295  data_time: 0.0251  lr: 0.00076613  max_mem: 11463M
[12/09 10:00:53 d2.utils.events]:  eta: 0:13:18  iter: 5139  total_loss: 2.993  loss_sem_seg: 1.611  loss_center: 0.5065  loss_offset: 0.7687  time: 0.4295  data_time: 0.0270  lr: 0.00075879  max_mem: 11463M
[12/09 10:01:01 d2.utils.events]:  eta: 0:13:09  iter: 5159  total_loss: 3.405  loss_sem_seg: 1.793  loss_center: 0.5333  loss_offset: 0.8292  time: 0.4295  data_time: 0.0254  lr: 0.00075145  max_mem: 11463M
[12/09 10:01:10 d2.utils.events]:  eta: 0:13:01  iter: 5179  total_loss: 3.351  loss_sem_seg: 1.858  loss_center: 0.5673  loss_offset: 0.8052  time: 0.4295  data_time: 0.0266  lr: 0.0007441  max_mem: 11463M
[12/09 10:01:19 d2.utils.events]:  eta: 0:12:52  iter: 5199  total_loss: 3.25  loss_sem_seg: 1.534  loss_center: 0.8183  loss_offset: 0.7859  time: 0.4295  data_time: 0.0262  lr: 0.00073674  max_mem: 11463M
[12/09 10:01:27 d2.utils.events]:  eta: 0:12:43  iter: 5219  total_loss: 3.422  loss_sem_seg: 1.695  loss_center: 0.6132  loss_offset: 0.8004  time: 0.4295  data_time: 0.0264  lr: 0.00072937  max_mem: 11463M
[12/09 10:01:36 d2.utils.events]:  eta: 0:12:35  iter: 5239  total_loss: 3.624  loss_sem_seg: 2.137  loss_center: 0.6149  loss_offset: 0.8923  time: 0.4296  data_time: 0.0266  lr: 0.000722  max_mem: 11463M
[12/09 10:01:44 d2.utils.events]:  eta: 0:12:26  iter: 5259  total_loss: 3.657  loss_sem_seg: 1.983  loss_center: 0.6455  loss_offset: 0.9255  time: 0.4296  data_time: 0.0254  lr: 0.00071461  max_mem: 11463M
[12/09 10:01:53 d2.utils.events]:  eta: 0:12:18  iter: 5279  total_loss: 3.032  loss_sem_seg: 1.579  loss_center: 0.656  loss_offset: 0.8295  time: 0.4295  data_time: 0.0252  lr: 0.00070722  max_mem: 11463M
[12/09 10:02:02 d2.utils.events]:  eta: 0:12:09  iter: 5299  total_loss: 3.321  loss_sem_seg: 1.58  loss_center: 0.8634  loss_offset: 0.8317  time: 0.4295  data_time: 0.0254  lr: 0.00069982  max_mem: 11463M
[12/09 10:02:10 d2.utils.events]:  eta: 0:12:00  iter: 5319  total_loss: 2.994  loss_sem_seg: 1.568  loss_center: 0.64  loss_offset: 0.8362  time: 0.4296  data_time: 0.0266  lr: 0.00069241  max_mem: 11463M
[12/09 10:02:19 d2.utils.events]:  eta: 0:11:52  iter: 5339  total_loss: 3.479  loss_sem_seg: 1.863  loss_center: 0.5696  loss_offset: 0.9206  time: 0.4296  data_time: 0.0260  lr: 0.00068499  max_mem: 11463M
[12/09 10:02:28 d2.utils.events]:  eta: 0:11:43  iter: 5359  total_loss: 3.274  loss_sem_seg: 1.793  loss_center: 0.6394  loss_offset: 0.8567  time: 0.4296  data_time: 0.0255  lr: 0.00067756  max_mem: 11463M
[12/09 10:02:36 d2.utils.events]:  eta: 0:11:34  iter: 5379  total_loss: 3.137  loss_sem_seg: 1.614  loss_center: 0.6487  loss_offset: 0.7787  time: 0.4296  data_time: 0.0271  lr: 0.00067013  max_mem: 11463M
[12/09 10:02:45 d2.utils.events]:  eta: 0:11:26  iter: 5399  total_loss: 3.289  loss_sem_seg: 1.763  loss_center: 0.6644  loss_offset: 0.8095  time: 0.4296  data_time: 0.0241  lr: 0.00066268  max_mem: 11463M
[12/09 10:02:53 d2.utils.events]:  eta: 0:11:17  iter: 5419  total_loss: 3.196  loss_sem_seg: 1.575  loss_center: 0.7786  loss_offset: 0.7347  time: 0.4295  data_time: 0.0245  lr: 0.00065522  max_mem: 11463M
[12/09 10:03:02 d2.utils.events]:  eta: 0:11:08  iter: 5439  total_loss: 3.485  loss_sem_seg: 1.961  loss_center: 0.5988  loss_offset: 0.8574  time: 0.4296  data_time: 0.0267  lr: 0.00064776  max_mem: 11463M
[12/09 10:03:11 d2.utils.events]:  eta: 0:11:00  iter: 5459  total_loss: 3.335  loss_sem_seg: 1.836  loss_center: 0.5756  loss_offset: 0.8676  time: 0.4296  data_time: 0.0256  lr: 0.00064029  max_mem: 11463M
[12/09 10:03:19 d2.utils.events]:  eta: 0:10:51  iter: 5479  total_loss: 3.265  loss_sem_seg: 1.615  loss_center: 0.5317  loss_offset: 0.898  time: 0.4296  data_time: 0.0268  lr: 0.0006328  max_mem: 11463M
[12/09 10:03:28 d2.utils.events]:  eta: 0:10:42  iter: 5499  total_loss: 3.492  loss_sem_seg: 1.996  loss_center: 0.5688  loss_offset: 0.8853  time: 0.4296  data_time: 0.0265  lr: 0.00062531  max_mem: 11463M
[12/09 10:03:37 d2.utils.events]:  eta: 0:10:34  iter: 5519  total_loss: 3.479  loss_sem_seg: 1.926  loss_center: 0.7338  loss_offset: 0.8903  time: 0.4296  data_time: 0.0263  lr: 0.0006178  max_mem: 11463M
[12/09 10:03:45 d2.utils.events]:  eta: 0:10:26  iter: 5539  total_loss: 3.225  loss_sem_seg: 1.647  loss_center: 0.6014  loss_offset: 0.9115  time: 0.4296  data_time: 0.0247  lr: 0.00061029  max_mem: 11463M
[12/09 10:03:54 d2.utils.events]:  eta: 0:10:17  iter: 5559  total_loss: 3.352  loss_sem_seg: 1.633  loss_center: 0.7626  loss_offset: 0.8391  time: 0.4296  data_time: 0.0247  lr: 0.00060277  max_mem: 11463M
[12/09 10:04:02 d2.utils.events]:  eta: 0:10:08  iter: 5579  total_loss: 3.504  loss_sem_seg: 1.748  loss_center: 0.6838  loss_offset: 0.8547  time: 0.4296  data_time: 0.0259  lr: 0.00059523  max_mem: 11463M
[12/09 10:04:11 d2.utils.events]:  eta: 0:10:00  iter: 5599  total_loss: 3.358  loss_sem_seg: 1.743  loss_center: 0.7479  loss_offset: 0.7821  time: 0.4296  data_time: 0.0269  lr: 0.00058769  max_mem: 11463M
[12/09 10:04:19 d2.utils.events]:  eta: 0:09:51  iter: 5619  total_loss: 3.506  loss_sem_seg: 1.885  loss_center: 0.5664  loss_offset: 0.9416  time: 0.4296  data_time: 0.0244  lr: 0.00058013  max_mem: 11463M
[12/09 10:04:28 d2.utils.events]:  eta: 0:09:43  iter: 5639  total_loss: 3.582  loss_sem_seg: 1.657  loss_center: 0.7781  loss_offset: 0.8124  time: 0.4296  data_time: 0.0273  lr: 0.00057256  max_mem: 11463M
[12/09 10:04:37 d2.utils.events]:  eta: 0:09:34  iter: 5659  total_loss: 2.998  loss_sem_seg: 1.454  loss_center: 0.736  loss_offset: 0.7675  time: 0.4296  data_time: 0.0257  lr: 0.00056499  max_mem: 11463M
[12/09 10:04:45 d2.utils.events]:  eta: 0:09:25  iter: 5679  total_loss: 3.578  loss_sem_seg: 1.706  loss_center: 0.6444  loss_offset: 0.7744  time: 0.4296  data_time: 0.0258  lr: 0.0005574  max_mem: 11463M
[12/09 10:04:54 d2.utils.events]:  eta: 0:09:17  iter: 5699  total_loss: 2.943  loss_sem_seg: 1.608  loss_center: 0.5037  loss_offset: 0.8397  time: 0.4296  data_time: 0.0264  lr: 0.0005498  max_mem: 11463M
[12/09 10:05:02 d2.utils.events]:  eta: 0:09:08  iter: 5719  total_loss: 3.373  loss_sem_seg: 1.677  loss_center: 0.6914  loss_offset: 0.9452  time: 0.4296  data_time: 0.0260  lr: 0.00054218  max_mem: 11463M
[12/09 10:05:11 d2.utils.events]:  eta: 0:09:00  iter: 5739  total_loss: 3.499  loss_sem_seg: 1.823  loss_center: 0.564  loss_offset: 0.8909  time: 0.4296  data_time: 0.0264  lr: 0.00053456  max_mem: 11463M
[12/09 10:05:20 d2.utils.events]:  eta: 0:08:51  iter: 5759  total_loss: 3.294  loss_sem_seg: 1.837  loss_center: 0.6283  loss_offset: 0.8033  time: 0.4296  data_time: 0.0267  lr: 0.00052692  max_mem: 11463M
[12/09 10:05:28 d2.utils.events]:  eta: 0:08:42  iter: 5779  total_loss: 3.49  loss_sem_seg: 1.928  loss_center: 0.532  loss_offset: 0.8253  time: 0.4296  data_time: 0.0260  lr: 0.00051927  max_mem: 11463M
[12/09 10:05:37 d2.utils.events]:  eta: 0:08:34  iter: 5799  total_loss: 3.228  loss_sem_seg: 1.712  loss_center: 0.5696  loss_offset: 0.788  time: 0.4296  data_time: 0.0253  lr: 0.00051161  max_mem: 11463M
[12/09 10:05:46 d2.utils.events]:  eta: 0:08:25  iter: 5819  total_loss: 3.248  loss_sem_seg: 1.788  loss_center: 0.6174  loss_offset: 0.797  time: 0.4296  data_time: 0.0260  lr: 0.00050394  max_mem: 11463M
[12/09 10:05:54 d2.utils.events]:  eta: 0:08:17  iter: 5839  total_loss: 3.501  loss_sem_seg: 1.707  loss_center: 0.7245  loss_offset: 0.8541  time: 0.4296  data_time: 0.0264  lr: 0.00049625  max_mem: 11463M
[12/09 10:06:03 d2.utils.events]:  eta: 0:08:08  iter: 5859  total_loss: 3.54  loss_sem_seg: 1.712  loss_center: 0.7002  loss_offset: 0.9151  time: 0.4296  data_time: 0.0269  lr: 0.00048855  max_mem: 11463M
[12/09 10:06:12 d2.utils.events]:  eta: 0:08:00  iter: 5879  total_loss: 3.3  loss_sem_seg: 1.776  loss_center: 0.6257  loss_offset: 0.832  time: 0.4296  data_time: 0.0260  lr: 0.00048084  max_mem: 11463M
[12/09 10:06:20 d2.utils.events]:  eta: 0:07:51  iter: 5899  total_loss: 3.003  loss_sem_seg: 1.522  loss_center: 0.6515  loss_offset: 0.8887  time: 0.4296  data_time: 0.0268  lr: 0.00047311  max_mem: 11463M
[12/09 10:06:29 d2.utils.events]:  eta: 0:07:43  iter: 5919  total_loss: 3.22  loss_sem_seg: 1.732  loss_center: 0.6406  loss_offset: 0.8425  time: 0.4297  data_time: 0.0277  lr: 0.00046537  max_mem: 11463M
[12/09 10:06:38 d2.utils.events]:  eta: 0:07:34  iter: 5939  total_loss: 3.302  loss_sem_seg: 1.709  loss_center: 0.6855  loss_offset: 0.8509  time: 0.4297  data_time: 0.0255  lr: 0.00045761  max_mem: 11463M
[12/09 10:06:46 d2.utils.events]:  eta: 0:07:26  iter: 5959  total_loss: 2.929  loss_sem_seg: 1.626  loss_center: 0.5919  loss_offset: 0.8128  time: 0.4297  data_time: 0.0274  lr: 0.00044984  max_mem: 11463M
[12/09 10:06:55 d2.utils.events]:  eta: 0:07:17  iter: 5979  total_loss: 3.466  loss_sem_seg: 1.669  loss_center: 0.7274  loss_offset: 0.9452  time: 0.4297  data_time: 0.0248  lr: 0.00044205  max_mem: 11463M
[12/09 10:07:04 d2.utils.events]:  eta: 0:07:09  iter: 5999  total_loss: 3.243  loss_sem_seg: 1.648  loss_center: 0.7033  loss_offset: 0.8949  time: 0.4297  data_time: 0.0250  lr: 0.00043425  max_mem: 11463M
[12/09 10:07:12 d2.utils.events]:  eta: 0:07:00  iter: 6019  total_loss: 3.349  loss_sem_seg: 1.654  loss_center: 0.5975  loss_offset: 0.8959  time: 0.4297  data_time: 0.0259  lr: 0.00042644  max_mem: 11463M
[12/09 10:07:21 d2.utils.events]:  eta: 0:06:52  iter: 6039  total_loss: 3.337  loss_sem_seg: 1.785  loss_center: 0.6823  loss_offset: 0.8423  time: 0.4297  data_time: 0.0263  lr: 0.0004186  max_mem: 11463M
[12/09 10:07:29 d2.utils.events]:  eta: 0:06:43  iter: 6059  total_loss: 3.383  loss_sem_seg: 1.735  loss_center: 0.7715  loss_offset: 0.7375  time: 0.4297  data_time: 0.0239  lr: 0.00041075  max_mem: 11463M
[12/09 10:07:38 d2.utils.events]:  eta: 0:06:34  iter: 6079  total_loss: 3.168  loss_sem_seg: 1.546  loss_center: 0.6212  loss_offset: 0.7706  time: 0.4297  data_time: 0.0260  lr: 0.00040289  max_mem: 11463M
[12/09 10:07:47 d2.utils.events]:  eta: 0:06:26  iter: 6099  total_loss: 3.16  loss_sem_seg: 1.475  loss_center: 0.6663  loss_offset: 0.7876  time: 0.4297  data_time: 0.0254  lr: 0.00039501  max_mem: 11463M
[12/09 10:07:55 d2.utils.events]:  eta: 0:06:17  iter: 6119  total_loss: 3.298  loss_sem_seg: 1.562  loss_center: 0.7936  loss_offset: 0.8283  time: 0.4297  data_time: 0.0238  lr: 0.00038711  max_mem: 11463M
[12/09 10:08:04 d2.utils.events]:  eta: 0:06:08  iter: 6139  total_loss: 3.24  loss_sem_seg: 1.713  loss_center: 0.6196  loss_offset: 0.8106  time: 0.4297  data_time: 0.0251  lr: 0.00037919  max_mem: 11463M
[12/09 10:08:12 d2.utils.events]:  eta: 0:06:00  iter: 6159  total_loss: 3.421  loss_sem_seg: 1.733  loss_center: 0.7281  loss_offset: 0.9082  time: 0.4297  data_time: 0.0253  lr: 0.00037125  max_mem: 11463M
[12/09 10:08:21 d2.utils.events]:  eta: 0:05:51  iter: 6179  total_loss: 3.13  loss_sem_seg: 1.677  loss_center: 0.6188  loss_offset: 0.8325  time: 0.4297  data_time: 0.0249  lr: 0.0003633  max_mem: 11463M
[12/09 10:08:30 d2.utils.events]:  eta: 0:05:43  iter: 6199  total_loss: 3.119  loss_sem_seg: 1.509  loss_center: 0.7828  loss_offset: 0.8067  time: 0.4297  data_time: 0.0239  lr: 0.00035532  max_mem: 11463M
[12/09 10:08:38 d2.utils.events]:  eta: 0:05:34  iter: 6219  total_loss: 3.237  loss_sem_seg: 1.721  loss_center: 0.6167  loss_offset: 0.8601  time: 0.4297  data_time: 0.0259  lr: 0.00034733  max_mem: 11463M
[12/09 10:08:47 d2.utils.events]:  eta: 0:05:26  iter: 6239  total_loss: 3.374  loss_sem_seg: 1.744  loss_center: 0.5362  loss_offset: 0.6548  time: 0.4297  data_time: 0.0236  lr: 0.00033931  max_mem: 11463M
[12/09 10:08:55 d2.utils.events]:  eta: 0:05:17  iter: 6259  total_loss: 3.55  loss_sem_seg: 1.823  loss_center: 0.602  loss_offset: 0.8462  time: 0.4297  data_time: 0.0248  lr: 0.00033127  max_mem: 11463M
[12/09 10:09:04 d2.utils.events]:  eta: 0:05:08  iter: 6279  total_loss: 3.057  loss_sem_seg: 1.574  loss_center: 0.6213  loss_offset: 0.7876  time: 0.4297  data_time: 0.0252  lr: 0.00032322  max_mem: 11463M
[12/09 10:09:13 d2.utils.events]:  eta: 0:05:00  iter: 6299  total_loss: 3.472  loss_sem_seg: 1.704  loss_center: 0.6405  loss_offset: 0.8883  time: 0.4297  data_time: 0.0254  lr: 0.00031514  max_mem: 11463M
[12/09 10:09:21 d2.utils.events]:  eta: 0:04:51  iter: 6319  total_loss: 3.172  loss_sem_seg: 1.631  loss_center: 0.6453  loss_offset: 0.7699  time: 0.4297  data_time: 0.0249  lr: 0.00030703  max_mem: 11463M
[12/09 10:09:30 d2.utils.events]:  eta: 0:04:43  iter: 6339  total_loss: 2.98  loss_sem_seg: 1.539  loss_center: 0.5975  loss_offset: 0.8345  time: 0.4297  data_time: 0.0254  lr: 0.0002989  max_mem: 11463M
[12/09 10:09:38 d2.utils.events]:  eta: 0:04:34  iter: 6359  total_loss: 2.896  loss_sem_seg: 1.462  loss_center: 0.6461  loss_offset: 0.7365  time: 0.4297  data_time: 0.0252  lr: 0.00029075  max_mem: 11463M
[12/09 10:09:47 d2.utils.events]:  eta: 0:04:26  iter: 6379  total_loss: 3.144  loss_sem_seg: 1.855  loss_center: 0.5656  loss_offset: 0.7124  time: 0.4297  data_time: 0.0261  lr: 0.00028258  max_mem: 11463M
[12/09 10:09:56 d2.utils.events]:  eta: 0:04:17  iter: 6399  total_loss: 3.314  loss_sem_seg: 1.558  loss_center: 0.776  loss_offset: 0.8277  time: 0.4297  data_time: 0.0244  lr: 0.00027437  max_mem: 11463M
[12/09 10:10:04 d2.utils.events]:  eta: 0:04:09  iter: 6419  total_loss: 3.105  loss_sem_seg: 1.495  loss_center: 0.7257  loss_offset: 0.7083  time: 0.4297  data_time: 0.0258  lr: 0.00026614  max_mem: 11463M
[12/09 10:10:13 d2.utils.events]:  eta: 0:04:00  iter: 6439  total_loss: 3.396  loss_sem_seg: 1.707  loss_center: 0.6804  loss_offset: 0.821  time: 0.4297  data_time: 0.0245  lr: 0.00025788  max_mem: 11463M
[12/09 10:10:21 d2.utils.events]:  eta: 0:03:51  iter: 6459  total_loss: 3.064  loss_sem_seg: 1.822  loss_center: 0.5327  loss_offset: 0.8139  time: 0.4297  data_time: 0.0250  lr: 0.00024959  max_mem: 11463M
[12/09 10:10:30 d2.utils.events]:  eta: 0:03:43  iter: 6479  total_loss: 3.488  loss_sem_seg: 1.627  loss_center: 0.9117  loss_offset: 0.7699  time: 0.4297  data_time: 0.0265  lr: 0.00024127  max_mem: 11463M
[12/09 10:10:39 d2.utils.events]:  eta: 0:03:34  iter: 6499  total_loss: 3.077  loss_sem_seg: 1.664  loss_center: 0.5524  loss_offset: 0.7737  time: 0.4297  data_time: 0.0253  lr: 0.00023292  max_mem: 11463M
[12/09 10:10:47 d2.utils.events]:  eta: 0:03:26  iter: 6519  total_loss: 3.344  loss_sem_seg: 1.719  loss_center: 0.6372  loss_offset: 0.7863  time: 0.4297  data_time: 0.0262  lr: 0.00022453  max_mem: 11463M
[12/09 10:10:56 d2.utils.events]:  eta: 0:03:17  iter: 6539  total_loss: 3.044  loss_sem_seg: 1.42  loss_center: 0.6996  loss_offset: 0.7247  time: 0.4297  data_time: 0.0244  lr: 0.00021611  max_mem: 11463M
[12/09 10:11:05 d2.utils.events]:  eta: 0:03:08  iter: 6559  total_loss: 3.23  loss_sem_seg: 1.673  loss_center: 0.6726  loss_offset: 0.8607  time: 0.4297  data_time: 0.0266  lr: 0.00020766  max_mem: 11463M
[12/09 10:11:13 d2.utils.events]:  eta: 0:03:00  iter: 6579  total_loss: 3.436  loss_sem_seg: 1.806  loss_center: 0.5993  loss_offset: 0.8661  time: 0.4297  data_time: 0.0265  lr: 0.00019916  max_mem: 11463M
[12/09 10:11:22 d2.utils.events]:  eta: 0:02:51  iter: 6599  total_loss: 3.025  loss_sem_seg: 1.493  loss_center: 0.5408  loss_offset: 0.7473  time: 0.4297  data_time: 0.0253  lr: 0.00019063  max_mem: 11463M
[12/09 10:11:30 d2.utils.events]:  eta: 0:02:43  iter: 6619  total_loss: 3.391  loss_sem_seg: 1.7  loss_center: 0.7803  loss_offset: 0.9004  time: 0.4297  data_time: 0.0251  lr: 0.00018205  max_mem: 11463M
[12/09 10:11:39 d2.utils.events]:  eta: 0:02:34  iter: 6639  total_loss: 3.049  loss_sem_seg: 1.668  loss_center: 0.7064  loss_offset: 0.6763  time: 0.4297  data_time: 0.0256  lr: 0.00017342  max_mem: 11463M
[12/09 10:11:48 d2.utils.events]:  eta: 0:02:25  iter: 6659  total_loss: 3.319  loss_sem_seg: 1.818  loss_center: 0.5909  loss_offset: 0.8468  time: 0.4297  data_time: 0.0245  lr: 0.00016475  max_mem: 11463M
[12/09 10:11:56 d2.utils.events]:  eta: 0:02:17  iter: 6679  total_loss: 3.089  loss_sem_seg: 1.554  loss_center: 0.665  loss_offset: 0.7729  time: 0.4297  data_time: 0.0259  lr: 0.00015603  max_mem: 11463M
[12/09 10:12:05 d2.utils.events]:  eta: 0:02:08  iter: 6699  total_loss: 2.901  loss_sem_seg: 1.6  loss_center: 0.6272  loss_offset: 0.7611  time: 0.4297  data_time: 0.0241  lr: 0.00014725  max_mem: 11463M
[12/09 10:12:13 d2.utils.events]:  eta: 0:02:00  iter: 6719  total_loss: 3.016  loss_sem_seg: 1.441  loss_center: 0.6345  loss_offset: 0.7661  time: 0.4297  data_time: 0.0261  lr: 0.00013842  max_mem: 11463M
[12/09 10:12:22 d2.utils.events]:  eta: 0:01:51  iter: 6739  total_loss: 3.124  loss_sem_seg: 1.437  loss_center: 0.6117  loss_offset: 0.7316  time: 0.4297  data_time: 0.0244  lr: 0.00012952  max_mem: 11463M
[12/09 10:12:31 d2.utils.events]:  eta: 0:01:43  iter: 6759  total_loss: 2.93  loss_sem_seg: 1.537  loss_center: 0.6972  loss_offset: 0.8405  time: 0.4297  data_time: 0.0240  lr: 0.00012055  max_mem: 11463M
[12/09 10:12:39 d2.utils.events]:  eta: 0:01:34  iter: 6779  total_loss: 3.218  loss_sem_seg: 1.739  loss_center: 0.5971  loss_offset: 0.8794  time: 0.4297  data_time: 0.0252  lr: 0.00011151  max_mem: 11463M
[12/09 10:12:48 d2.utils.events]:  eta: 0:01:25  iter: 6799  total_loss: 3.179  loss_sem_seg: 1.529  loss_center: 0.6518  loss_offset: 0.8135  time: 0.4297  data_time: 0.0263  lr: 0.00010238  max_mem: 11463M
[12/09 10:12:56 d2.utils.events]:  eta: 0:01:17  iter: 6819  total_loss: 2.925  loss_sem_seg: 1.694  loss_center: 0.5479  loss_offset: 0.7854  time: 0.4297  data_time: 0.0243  lr: 9.3167e-05  max_mem: 11463M
[12/09 10:13:05 d2.utils.events]:  eta: 0:01:08  iter: 6839  total_loss: 3.174  loss_sem_seg: 1.634  loss_center: 0.7504  loss_offset: 0.7177  time: 0.4297  data_time: 0.0243  lr: 8.3848e-05  max_mem: 11463M
[12/09 10:13:14 d2.utils.events]:  eta: 0:01:00  iter: 6859  total_loss: 3.557  loss_sem_seg: 1.873  loss_center: 0.5882  loss_offset: 0.8108  time: 0.4297  data_time: 0.0255  lr: 7.4413e-05  max_mem: 11463M
[12/09 10:13:22 d2.utils.events]:  eta: 0:00:51  iter: 6879  total_loss: 2.954  loss_sem_seg: 1.591  loss_center: 0.7101  loss_offset: 0.779  time: 0.4297  data_time: 0.0254  lr: 6.4842e-05  max_mem: 11463M
[12/09 10:13:31 d2.utils.events]:  eta: 0:00:42  iter: 6899  total_loss: 3.174  loss_sem_seg: 1.581  loss_center: 0.7122  loss_offset: 0.8753  time: 0.4297  data_time: 0.0250  lr: 5.5111e-05  max_mem: 11463M
[12/09 10:13:40 d2.utils.events]:  eta: 0:00:34  iter: 6919  total_loss: 3.208  loss_sem_seg: 1.779  loss_center: 0.6579  loss_offset: 0.7092  time: 0.4297  data_time: 0.0262  lr: 4.5184e-05  max_mem: 11463M
[12/09 10:13:48 d2.utils.events]:  eta: 0:00:25  iter: 6939  total_loss: 3.071  loss_sem_seg: 1.615  loss_center: 0.4952  loss_offset: 0.8429  time: 0.4297  data_time: 0.0253  lr: 3.5006e-05  max_mem: 11463M
[12/09 10:13:57 d2.utils.events]:  eta: 0:00:17  iter: 6959  total_loss: 3.158  loss_sem_seg: 1.483  loss_center: 0.6211  loss_offset: 0.8205  time: 0.4297  data_time: 0.0259  lr: 2.4483e-05  max_mem: 11463M
[12/09 10:14:06 d2.utils.events]:  eta: 0:00:08  iter: 6979  total_loss: 2.938  loss_sem_seg: 1.547  loss_center: 0.4627  loss_offset: 0.7929  time: 0.4297  data_time: 0.0267  lr: 1.3408e-05  max_mem: 11463M
[12/09 10:14:14 fvcore.common.checkpoint]: Saving checkpoint to ./output/model_final.pth
[12/09 10:14:15 d2.utils.events]:  eta: 0:00:00  iter: 6999  total_loss: 2.916  loss_sem_seg: 1.618  loss_center: 0.5472  loss_offset: 0.831  time: 0.4297  data_time: 0.0255  lr: 8.6567e-07  max_mem: 11463M
[12/09 10:14:16 d2.engine.hooks]: Overall training speed: 6998 iterations in 0:50:07 (0.4297 s / it)
[12/09 10:14:16 d2.engine.hooks]: Total training time: 0:50:14 (0:00:06 on hooks)
[12/09 10:14:16 d2.data.dataset_mapper]: [DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(640, 640), max_size=640, sample_style='choice')]
[12/09 10:14:16 d2.data.common]: Serializing the dataset using: <class 'detectron2.data.common.NumpySerializedList'>
[12/09 10:14:16 d2.data.common]: Serializing 5000 elements to byte tensors and concatenating them all ...
[12/09 10:14:16 d2.data.common]: Serialized dataset takes 3.40 MiB
/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:481: UserWarning: This DataLoader will create 10 worker processes in total. Our suggested max number of worker in current system is 8, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.
  cpuset_checked))
[12/09 10:14:17 d2.evaluation.evaluator]: Start inference on 5000 batches
/usr/local/lib/python3.7/dist-packages/torch/functional.py:445: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at  ../aten/src/ATen/native/TensorShape.cpp:2157.)
  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]
[12/09 10:14:19 d2.evaluation.evaluator]: Inference done 11/5000. Dataloading: 0.0011 s/iter. Inference: 0.0982 s/iter. Eval: 0.0354 s/iter. Total: 0.1346 s/iter. ETA=0:11:11
[12/09 10:14:24 d2.evaluation.evaluator]: Inference done 73/5000. Dataloading: 0.0011 s/iter. Inference: 0.0532 s/iter. Eval: 0.0312 s/iter. Total: 0.0856 s/iter. ETA=0:07:01
[12/09 10:14:29 d2.evaluation.evaluator]: Inference done 128/5000. Dataloading: 0.0012 s/iter. Inference: 0.0532 s/iter. Eval: 0.0335 s/iter. Total: 0.0880 s/iter. ETA=0:07:08
[12/09 10:14:34 d2.evaluation.evaluator]: Inference done 184/5000. Dataloading: 0.0012 s/iter. Inference: 0.0532 s/iter. Eval: 0.0343 s/iter. Total: 0.0888 s/iter. ETA=0:07:07
[12/09 10:14:39 d2.evaluation.evaluator]: Inference done 247/5000. Dataloading: 0.0012 s/iter. Inference: 0.0519 s/iter. Eval: 0.0336 s/iter. Total: 0.0867 s/iter. ETA=0:06:51
[12/09 10:14:44 d2.evaluation.evaluator]: Inference done 306/5000. Dataloading: 0.0012 s/iter. Inference: 0.0516 s/iter. Eval: 0.0336 s/iter. Total: 0.0865 s/iter. ETA=0:06:46
[12/09 10:14:49 d2.evaluation.evaluator]: Inference done 363/5000. Dataloading: 0.0012 s/iter. Inference: 0.0518 s/iter. Eval: 0.0338 s/iter. Total: 0.0869 s/iter. ETA=0:06:42
[12/09 10:14:54 d2.evaluation.evaluator]: Inference done 424/5000. Dataloading: 0.0012 s/iter. Inference: 0.0514 s/iter. Eval: 0.0336 s/iter. Total: 0.0863 s/iter. ETA=0:06:34
[12/09 10:14:59 d2.evaluation.evaluator]: Inference done 486/5000. Dataloading: 0.0012 s/iter. Inference: 0.0510 s/iter. Eval: 0.0334 s/iter. Total: 0.0856 s/iter. ETA=0:06:26
[12/09 10:15:04 d2.evaluation.evaluator]: Inference done 545/5000. Dataloading: 0.0012 s/iter. Inference: 0.0509 s/iter. Eval: 0.0334 s/iter. Total: 0.0856 s/iter. ETA=0:06:21
[12/09 10:15:09 d2.evaluation.evaluator]: Inference done 605/5000. Dataloading: 0.0012 s/iter. Inference: 0.0507 s/iter. Eval: 0.0334 s/iter. Total: 0.0854 s/iter. ETA=0:06:15
[12/09 10:15:14 d2.evaluation.evaluator]: Inference done 662/5000. Dataloading: 0.0012 s/iter. Inference: 0.0507 s/iter. Eval: 0.0336 s/iter. Total: 0.0856 s/iter. ETA=0:06:11
[12/09 10:15:19 d2.evaluation.evaluator]: Inference done 720/5000. Dataloading: 0.0012 s/iter. Inference: 0.0508 s/iter. Eval: 0.0337 s/iter. Total: 0.0857 s/iter. ETA=0:06:06
[12/09 10:15:24 d2.evaluation.evaluator]: Inference done 781/5000. Dataloading: 0.0012 s/iter. Inference: 0.0506 s/iter. Eval: 0.0336 s/iter. Total: 0.0855 s/iter. ETA=0:06:00
[12/09 10:15:29 d2.evaluation.evaluator]: Inference done 843/5000. Dataloading: 0.0012 s/iter. Inference: 0.0504 s/iter. Eval: 0.0335 s/iter. Total: 0.0852 s/iter. ETA=0:05:54
[12/09 10:15:34 d2.evaluation.evaluator]: Inference done 905/5000. Dataloading: 0.0012 s/iter. Inference: 0.0503 s/iter. Eval: 0.0334 s/iter. Total: 0.0850 s/iter. ETA=0:05:47
[12/09 10:15:39 d2.evaluation.evaluator]: Inference done 967/5000. Dataloading: 0.0012 s/iter. Inference: 0.0502 s/iter. Eval: 0.0333 s/iter. Total: 0.0848 s/iter. ETA=0:05:42
[12/09 10:15:45 d2.evaluation.evaluator]: Inference done 1028/5000. Dataloading: 0.0012 s/iter. Inference: 0.0501 s/iter. Eval: 0.0333 s/iter. Total: 0.0847 s/iter. ETA=0:05:36
[12/09 10:15:50 d2.evaluation.evaluator]: Inference done 1089/5000. Dataloading: 0.0012 s/iter. Inference: 0.0501 s/iter. Eval: 0.0332 s/iter. Total: 0.0846 s/iter. ETA=0:05:30
[12/09 10:15:55 d2.evaluation.evaluator]: Inference done 1149/5000. Dataloading: 0.0012 s/iter. Inference: 0.0501 s/iter. Eval: 0.0332 s/iter. Total: 0.0845 s/iter. ETA=0:05:25
[12/09 10:16:00 d2.evaluation.evaluator]: Inference done 1208/5000. Dataloading: 0.0012 s/iter. Inference: 0.0501 s/iter. Eval: 0.0332 s/iter. Total: 0.0846 s/iter. ETA=0:05:20
[12/09 10:16:05 d2.evaluation.evaluator]: Inference done 1265/5000. Dataloading: 0.0012 s/iter. Inference: 0.0503 s/iter. Eval: 0.0333 s/iter. Total: 0.0848 s/iter. ETA=0:05:16
[12/09 10:16:10 d2.evaluation.evaluator]: Inference done 1325/5000. Dataloading: 0.0012 s/iter. Inference: 0.0503 s/iter. Eval: 0.0332 s/iter. Total: 0.0848 s/iter. ETA=0:05:11
[12/09 10:16:15 d2.evaluation.evaluator]: Inference done 1385/5000. Dataloading: 0.0012 s/iter. Inference: 0.0502 s/iter. Eval: 0.0332 s/iter. Total: 0.0847 s/iter. ETA=0:05:06
[12/09 10:16:20 d2.evaluation.evaluator]: Inference done 1446/5000. Dataloading: 0.0012 s/iter. Inference: 0.0502 s/iter. Eval: 0.0332 s/iter. Total: 0.0847 s/iter. ETA=0:05:00
[12/09 10:16:25 d2.evaluation.evaluator]: Inference done 1505/5000. Dataloading: 0.0012 s/iter. Inference: 0.0502 s/iter. Eval: 0.0333 s/iter. Total: 0.0847 s/iter. ETA=0:04:56
[12/09 10:16:30 d2.evaluation.evaluator]: Inference done 1565/5000. Dataloading: 0.0012 s/iter. Inference: 0.0502 s/iter. Eval: 0.0333 s/iter. Total: 0.0847 s/iter. ETA=0:04:51
[12/09 10:16:35 d2.evaluation.evaluator]: Inference done 1624/5000. Dataloading: 0.0012 s/iter. Inference: 0.0502 s/iter. Eval: 0.0333 s/iter. Total: 0.0848 s/iter. ETA=0:04:46
[12/09 10:16:40 d2.evaluation.evaluator]: Inference done 1683/5000. Dataloading: 0.0012 s/iter. Inference: 0.0502 s/iter. Eval: 0.0333 s/iter. Total: 0.0848 s/iter. ETA=0:04:41
[12/09 10:16:45 d2.evaluation.evaluator]: Inference done 1742/5000. Dataloading: 0.0012 s/iter. Inference: 0.0502 s/iter. Eval: 0.0334 s/iter. Total: 0.0848 s/iter. ETA=0:04:36
[12/09 10:16:50 d2.evaluation.evaluator]: Inference done 1803/5000. Dataloading: 0.0012 s/iter. Inference: 0.0502 s/iter. Eval: 0.0333 s/iter. Total: 0.0848 s/iter. ETA=0:04:30
[12/09 10:16:55 d2.evaluation.evaluator]: Inference done 1862/5000. Dataloading: 0.0012 s/iter. Inference: 0.0502 s/iter. Eval: 0.0333 s/iter. Total: 0.0848 s/iter. ETA=0:04:26
[12/09 10:17:00 d2.evaluation.evaluator]: Inference done 1923/5000. Dataloading: 0.0012 s/iter. Inference: 0.0502 s/iter. Eval: 0.0333 s/iter. Total: 0.0847 s/iter. ETA=0:04:20
[12/09 10:17:05 d2.evaluation.evaluator]: Inference done 1984/5000. Dataloading: 0.0012 s/iter. Inference: 0.0501 s/iter. Eval: 0.0333 s/iter. Total: 0.0847 s/iter. ETA=0:04:15
[12/09 10:17:10 d2.evaluation.evaluator]: Inference done 2043/5000. Dataloading: 0.0012 s/iter. Inference: 0.0501 s/iter. Eval: 0.0333 s/iter. Total: 0.0847 s/iter. ETA=0:04:10
[12/09 10:17:15 d2.evaluation.evaluator]: Inference done 2103/5000. Dataloading: 0.0012 s/iter. Inference: 0.0501 s/iter. Eval: 0.0333 s/iter. Total: 0.0847 s/iter. ETA=0:04:05
[12/09 10:17:20 d2.evaluation.evaluator]: Inference done 2164/5000. Dataloading: 0.0012 s/iter. Inference: 0.0501 s/iter. Eval: 0.0333 s/iter. Total: 0.0846 s/iter. ETA=0:03:59
[12/09 10:17:26 d2.evaluation.evaluator]: Inference done 2223/5000. Dataloading: 0.0012 s/iter. Inference: 0.0501 s/iter. Eval: 0.0333 s/iter. Total: 0.0846 s/iter. ETA=0:03:54
[12/09 10:17:31 d2.evaluation.evaluator]: Inference done 2285/5000. Dataloading: 0.0012 s/iter. Inference: 0.0501 s/iter. Eval: 0.0332 s/iter. Total: 0.0845 s/iter. ETA=0:03:49
[12/09 10:17:36 d2.evaluation.evaluator]: Inference done 2347/5000. Dataloading: 0.0012 s/iter. Inference: 0.0500 s/iter. Eval: 0.0332 s/iter. Total: 0.0845 s/iter. ETA=0:03:44
[12/09 10:17:41 d2.evaluation.evaluator]: Inference done 2405/5000. Dataloading: 0.0012 s/iter. Inference: 0.0500 s/iter. Eval: 0.0332 s/iter. Total: 0.0845 s/iter. ETA=0:03:39
[12/09 10:17:46 d2.evaluation.evaluator]: Inference done 2465/5000. Dataloading: 0.0012 s/iter. Inference: 0.0501 s/iter. Eval: 0.0332 s/iter. Total: 0.0845 s/iter. ETA=0:03:34
[12/09 10:17:51 d2.evaluation.evaluator]: Inference done 2523/5000. Dataloading: 0.0012 s/iter. Inference: 0.0501 s/iter. Eval: 0.0332 s/iter. Total: 0.0845 s/iter. ETA=0:03:29
[12/09 10:17:56 d2.evaluation.evaluator]: Inference done 2582/5000. Dataloading: 0.0012 s/iter. Inference: 0.0501 s/iter. Eval: 0.0332 s/iter. Total: 0.0846 s/iter. ETA=0:03:24
[12/09 10:18:01 d2.evaluation.evaluator]: Inference done 2641/5000. Dataloading: 0.0012 s/iter. Inference: 0.0501 s/iter. Eval: 0.0332 s/iter. Total: 0.0846 s/iter. ETA=0:03:19
[12/09 10:18:06 d2.evaluation.evaluator]: Inference done 2704/5000. Dataloading: 0.0012 s/iter. Inference: 0.0500 s/iter. Eval: 0.0332 s/iter. Total: 0.0845 s/iter. ETA=0:03:13
[12/09 10:18:11 d2.evaluation.evaluator]: Inference done 2766/5000. Dataloading: 0.0012 s/iter. Inference: 0.0500 s/iter. Eval: 0.0332 s/iter. Total: 0.0844 s/iter. ETA=0:03:08
[12/09 10:18:16 d2.evaluation.evaluator]: Inference done 2824/5000. Dataloading: 0.0012 s/iter. Inference: 0.0500 s/iter. Eval: 0.0332 s/iter. Total: 0.0844 s/iter. ETA=0:03:03
[12/09 10:18:21 d2.evaluation.evaluator]: Inference done 2885/5000. Dataloading: 0.0012 s/iter. Inference: 0.0500 s/iter. Eval: 0.0332 s/iter. Total: 0.0844 s/iter. ETA=0:02:58
[12/09 10:18:26 d2.evaluation.evaluator]: Inference done 2944/5000. Dataloading: 0.0012 s/iter. Inference: 0.0500 s/iter. Eval: 0.0332 s/iter. Total: 0.0844 s/iter. ETA=0:02:53
[12/09 10:18:31 d2.evaluation.evaluator]: Inference done 3006/5000. Dataloading: 0.0012 s/iter. Inference: 0.0500 s/iter. Eval: 0.0331 s/iter. Total: 0.0844 s/iter. ETA=0:02:48
[12/09 10:18:36 d2.evaluation.evaluator]: Inference done 3069/5000. Dataloading: 0.0012 s/iter. Inference: 0.0499 s/iter. Eval: 0.0331 s/iter. Total: 0.0843 s/iter. ETA=0:02:42
[12/09 10:18:41 d2.evaluation.evaluator]: Inference done 3129/5000. Dataloading: 0.0012 s/iter. Inference: 0.0499 s/iter. Eval: 0.0331 s/iter. Total: 0.0843 s/iter. ETA=0:02:37
[12/09 10:18:46 d2.evaluation.evaluator]: Inference done 3187/5000. Dataloading: 0.0012 s/iter. Inference: 0.0500 s/iter. Eval: 0.0331 s/iter. Total: 0.0843 s/iter. ETA=0:02:32
[12/09 10:18:51 d2.evaluation.evaluator]: Inference done 3245/5000. Dataloading: 0.0012 s/iter. Inference: 0.0500 s/iter. Eval: 0.0331 s/iter. Total: 0.0844 s/iter. ETA=0:02:28
[12/09 10:18:56 d2.evaluation.evaluator]: Inference done 3305/5000. Dataloading: 0.0012 s/iter. Inference: 0.0500 s/iter. Eval: 0.0331 s/iter. Total: 0.0844 s/iter. ETA=0:02:23
[12/09 10:19:01 d2.evaluation.evaluator]: Inference done 3362/5000. Dataloading: 0.0012 s/iter. Inference: 0.0500 s/iter. Eval: 0.0332 s/iter. Total: 0.0844 s/iter. ETA=0:02:18
[12/09 10:19:06 d2.evaluation.evaluator]: Inference done 3421/5000. Dataloading: 0.0012 s/iter. Inference: 0.0500 s/iter. Eval: 0.0332 s/iter. Total: 0.0845 s/iter. ETA=0:02:13
[12/09 10:19:11 d2.evaluation.evaluator]: Inference done 3481/5000. Dataloading: 0.0012 s/iter. Inference: 0.0500 s/iter. Eval: 0.0332 s/iter. Total: 0.0845 s/iter. ETA=0:02:08
[12/09 10:19:17 d2.evaluation.evaluator]: Inference done 3542/5000. Dataloading: 0.0012 s/iter. Inference: 0.0500 s/iter. Eval: 0.0332 s/iter. Total: 0.0844 s/iter. ETA=0:02:03
[12/09 10:19:22 d2.evaluation.evaluator]: Inference done 3599/5000. Dataloading: 0.0012 s/iter. Inference: 0.0501 s/iter. Eval: 0.0332 s/iter. Total: 0.0845 s/iter. ETA=0:01:58
[12/09 10:19:27 d2.evaluation.evaluator]: Inference done 3662/5000. Dataloading: 0.0012 s/iter. Inference: 0.0500 s/iter. Eval: 0.0332 s/iter. Total: 0.0844 s/iter. ETA=0:01:52
[12/09 10:19:32 d2.evaluation.evaluator]: Inference done 3722/5000. Dataloading: 0.0012 s/iter. Inference: 0.0500 s/iter. Eval: 0.0332 s/iter. Total: 0.0844 s/iter. ETA=0:01:47
[12/09 10:19:37 d2.evaluation.evaluator]: Inference done 3780/5000. Dataloading: 0.0012 s/iter. Inference: 0.0501 s/iter. Eval: 0.0332 s/iter. Total: 0.0845 s/iter. ETA=0:01:43
[12/09 10:19:42 d2.evaluation.evaluator]: Inference done 3839/5000. Dataloading: 0.0012 s/iter. Inference: 0.0501 s/iter. Eval: 0.0332 s/iter. Total: 0.0845 s/iter. ETA=0:01:38
[12/09 10:19:47 d2.evaluation.evaluator]: Inference done 3901/5000. Dataloading: 0.0012 s/iter. Inference: 0.0500 s/iter. Eval: 0.0331 s/iter. Total: 0.0844 s/iter. ETA=0:01:32
[12/09 10:19:52 d2.evaluation.evaluator]: Inference done 3960/5000. Dataloading: 0.0012 s/iter. Inference: 0.0500 s/iter. Eval: 0.0331 s/iter. Total: 0.0844 s/iter. ETA=0:01:27
[12/09 10:19:57 d2.evaluation.evaluator]: Inference done 4019/5000. Dataloading: 0.0012 s/iter. Inference: 0.0500 s/iter. Eval: 0.0331 s/iter. Total: 0.0844 s/iter. ETA=0:01:22
[12/09 10:20:02 d2.evaluation.evaluator]: Inference done 4078/5000. Dataloading: 0.0012 s/iter. Inference: 0.0500 s/iter. Eval: 0.0332 s/iter. Total: 0.0844 s/iter. ETA=0:01:17
[12/09 10:20:07 d2.evaluation.evaluator]: Inference done 4137/5000. Dataloading: 0.0012 s/iter. Inference: 0.0501 s/iter. Eval: 0.0332 s/iter. Total: 0.0845 s/iter. ETA=0:01:12
[12/09 10:20:12 d2.evaluation.evaluator]: Inference done 4194/5000. Dataloading: 0.0012 s/iter. Inference: 0.0501 s/iter. Eval: 0.0332 s/iter. Total: 0.0845 s/iter. ETA=0:01:08
[12/09 10:20:17 d2.evaluation.evaluator]: Inference done 4255/5000. Dataloading: 0.0012 s/iter. Inference: 0.0501 s/iter. Eval: 0.0332 s/iter. Total: 0.0845 s/iter. ETA=0:01:02
[12/09 10:20:22 d2.evaluation.evaluator]: Inference done 4313/5000. Dataloading: 0.0012 s/iter. Inference: 0.0501 s/iter. Eval: 0.0332 s/iter. Total: 0.0845 s/iter. ETA=0:00:58
[12/09 10:20:27 d2.evaluation.evaluator]: Inference done 4376/5000. Dataloading: 0.0012 s/iter. Inference: 0.0501 s/iter. Eval: 0.0332 s/iter. Total: 0.0845 s/iter. ETA=0:00:52
[12/09 10:20:32 d2.evaluation.evaluator]: Inference done 4435/5000. Dataloading: 0.0012 s/iter. Inference: 0.0501 s/iter. Eval: 0.0332 s/iter. Total: 0.0845 s/iter. ETA=0:00:47
[12/09 10:20:37 d2.evaluation.evaluator]: Inference done 4495/5000. Dataloading: 0.0012 s/iter. Inference: 0.0500 s/iter. Eval: 0.0332 s/iter. Total: 0.0845 s/iter. ETA=0:00:42
[12/09 10:20:42 d2.evaluation.evaluator]: Inference done 4554/5000. Dataloading: 0.0012 s/iter. Inference: 0.0500 s/iter. Eval: 0.0332 s/iter. Total: 0.0845 s/iter. ETA=0:00:37
[12/09 10:20:47 d2.evaluation.evaluator]: Inference done 4615/5000. Dataloading: 0.0012 s/iter. Inference: 0.0500 s/iter. Eval: 0.0332 s/iter. Total: 0.0845 s/iter. ETA=0:00:32
[12/09 10:20:52 d2.evaluation.evaluator]: Inference done 4672/5000. Dataloading: 0.0012 s/iter. Inference: 0.0501 s/iter. Eval: 0.0332 s/iter. Total: 0.0845 s/iter. ETA=0:00:27
[12/09 10:20:57 d2.evaluation.evaluator]: Inference done 4733/5000. Dataloading: 0.0012 s/iter. Inference: 0.0500 s/iter. Eval: 0.0332 s/iter. Total: 0.0845 s/iter. ETA=0:00:22
[12/09 10:21:02 d2.evaluation.evaluator]: Inference done 4794/5000. Dataloading: 0.0012 s/iter. Inference: 0.0500 s/iter. Eval: 0.0332 s/iter. Total: 0.0845 s/iter. ETA=0:00:17
[12/09 10:21:07 d2.evaluation.evaluator]: Inference done 4852/5000. Dataloading: 0.0012 s/iter. Inference: 0.0500 s/iter. Eval: 0.0332 s/iter. Total: 0.0845 s/iter. ETA=0:00:12
[12/09 10:21:12 d2.evaluation.evaluator]: Inference done 4912/5000. Dataloading: 0.0012 s/iter. Inference: 0.0500 s/iter. Eval: 0.0332 s/iter. Total: 0.0845 s/iter. ETA=0:00:07
[12/09 10:21:17 d2.evaluation.evaluator]: Inference done 4971/5000. Dataloading: 0.0012 s/iter. Inference: 0.0500 s/iter. Eval: 0.0332 s/iter. Total: 0.0845 s/iter. ETA=0:00:02
[12/09 10:21:20 d2.evaluation.evaluator]: Total inference time: 0:07:02.425696 (0.084570 s / iter per device, on 1 devices)
[12/09 10:21:20 d2.evaluation.evaluator]: Total inference pure compute time: 0:04:10 (0.050085 s / iter per device, on 1 devices)
[12/09 10:21:20 d2.evaluation.panoptic_evaluation]: Writing all panoptic predictions to /tmp/panoptic_evalnjmszzn8 ...
[12/09 10:21:43 d2.evaluation.panoptic_evaluation]: Panoptic Evaluation Results:
|        |  PQ   |   SQ   |   RQ   |  #categories  |
|:------:|:-----:|:------:|:------:|:-------------:|
|  All   | 4.956 | 33.083 | 6.700  |      133      |
| Things | 2.898 | 30.860 | 3.994  |      80       |
| Stuff  | 8.063 | 36.439 | 10.785 |      53       |
[12/09 10:21:44 d2.evaluation.coco_evaluation]: Preparing results for COCO format ...
[12/09 10:21:44 d2.evaluation.coco_evaluation]: Saving results to ./output/inference/coco_instances_results.json
[12/09 10:21:44 d2.evaluation.coco_evaluation]: Evaluating predictions with unofficial COCO API...
Loading and preparing results...
DONE (t=0.03s)
creating index...
index created!
[12/09 10:21:44 d2.evaluation.fast_eval_api]: Evaluate annotation type *bbox*
[12/09 10:21:51 d2.evaluation.fast_eval_api]: COCOeval_opt.evaluate() finished in 7.40 seconds.
[12/09 10:21:52 d2.evaluation.fast_eval_api]: Accumulating evaluation results...
[12/09 10:21:52 d2.evaluation.fast_eval_api]: COCOeval_opt.accumulate() finished in 0.61 seconds.
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.007
 Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.017
 Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.005
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.001
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.005
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.014
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.014
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.021
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.021
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.001
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.011
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.040
[12/09 10:21:52 d2.evaluation.coco_evaluation]: Evaluation results for bbox: 
|  AP   |  AP50  |  AP75  |  APs  |  APm  |  APl  |
|:-----:|:------:|:------:|:-----:|:-----:|:-----:|
| 0.723 | 1.729  | 0.517  | 0.053 | 0.546 | 1.445 |
[12/09 10:21:52 d2.evaluation.coco_evaluation]: Per-category bbox AP: 
| category      | AP    | category     | AP    | category       | AP    |
|:--------------|:------|:-------------|:------|:---------------|:------|
| person        | 5.027 | bicycle      | 0.000 | car            | 2.020 |
| motorcycle    | 0.616 | airplane     | 0.140 | bus            | 5.046 |
| train         | 0.224 | truck        | 0.013 | boat           | 0.012 |
| traffic light | 0.174 | fire hydrant | 0.000 | stop sign      | 8.343 |
| parking meter | 0.000 | bench        | 0.025 | bird           | 0.000 |
| cat           | 1.720 | dog          | 0.000 | horse          | 0.000 |
| sheep         | 0.770 | cow          | 0.371 | elephant       | 3.472 |
| bear          | 3.317 | zebra        | 8.762 | giraffe        | 2.685 |
| backpack      | 0.000 | umbrella     | 0.035 | handbag        | 0.000 |
| tie           | 0.000 | suitcase     | 0.000 | frisbee        | 0.248 |
| skis          | 0.000 | snowboard    | 0.000 | sports ball    | 0.000 |
| kite          | 1.715 | baseball bat | 0.000 | baseball glove | 0.000 |
| skateboard    | 0.000 | surfboard    | 0.198 | tennis racket  | 0.000 |
| bottle        | 0.004 | wine glass   | 0.000 | cup            | 0.000 |
| fork          | 0.000 | knife        | 0.000 | spoon          | 0.000 |
| bowl          | 0.135 | banana       | 0.010 | apple          | 0.000 |
| sandwich      | 0.000 | orange       | 0.714 | broccoli       | 0.000 |
| carrot        | 0.000 | hot dog      | 0.000 | pizza          | 0.720 |
| donut         | 0.000 | cake         | 0.000 | chair          | 0.133 |
| couch         | 0.000 | potted plant | 0.043 | bed            | 0.371 |
| dining table  | 1.384 | toilet       | 4.849 | tv             | 2.546 |
| laptop        | 0.000 | mouse        | 0.000 | remote         | 0.000 |
| keyboard      | 0.198 | cell phone   | 0.000 | microwave      | 0.000 |
| oven          | 0.173 | toaster      | 0.000 | sink           | 0.709 |
| refrigerator  | 0.000 | book         | 0.013 | clock          | 0.917 |
| vase          | 0.000 | scissors     | 0.000 | teddy bear     | 0.000 |
| hair drier    | 0.000 | toothbrush   | 0.000 |                |       |
Loading and preparing results...
DONE (t=0.42s)
creating index...
index created!
[12/09 10:21:53 d2.evaluation.fast_eval_api]: Evaluate annotation type *segm*
[12/09 10:22:02 d2.evaluation.fast_eval_api]: COCOeval_opt.evaluate() finished in 8.35 seconds.
[12/09 10:22:02 d2.evaluation.fast_eval_api]: Accumulating evaluation results...
[12/09 10:22:02 d2.evaluation.fast_eval_api]: COCOeval_opt.accumulate() finished in 0.66 seconds.
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.008
 Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.017
 Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.007
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.000
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.005
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.020
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.014
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.018
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.018
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.000
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.009
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.035
[12/09 10:22:04 d2.evaluation.coco_evaluation]: Evaluation results for segm: 
|  AP   |  AP50  |  AP75  |  APs  |  APm  |  APl  |
|:-----:|:------:|:------:|:-----:|:-----:|:-----:|
| 0.789 | 1.655  | 0.708  | 0.028 | 0.479 | 2.025 |
[12/09 10:22:04 d2.evaluation.coco_evaluation]: Per-category segm AP: 
| category      | AP    | category     | AP    | category       | AP     |
|:--------------|:------|:-------------|:------|:---------------|:-------|
| person        | 3.289 | bicycle      | 0.000 | car            | 1.908  |
| motorcycle    | 0.294 | airplane     | 0.165 | bus            | 5.286  |
| train         | 0.356 | truck        | 0.027 | boat           | 0.003  |
| traffic light | 0.594 | fire hydrant | 0.000 | stop sign      | 14.905 |
| parking meter | 0.000 | bench        | 0.000 | bird           | 0.000  |
| cat           | 1.210 | dog          | 0.000 | horse          | 0.000  |
| sheep         | 0.651 | cow          | 0.178 | elephant       | 2.860  |
| bear          | 5.687 | zebra        | 8.404 | giraffe        | 1.931  |
| backpack      | 0.000 | umbrella     | 0.000 | handbag        | 0.000  |
| tie           | 0.000 | suitcase     | 0.000 | frisbee        | 0.149  |
| skis          | 0.000 | snowboard    | 0.000 | sports ball    | 0.000  |
| kite          | 1.476 | baseball bat | 0.000 | baseball glove | 0.000  |
| skateboard    | 0.000 | surfboard    | 0.184 | tennis racket  | 0.000  |
| bottle        | 0.007 | wine glass   | 0.000 | cup            | 0.004  |
| fork          | 0.000 | knife        | 0.000 | spoon          | 0.000  |
| bowl          | 0.260 | banana       | 0.000 | apple          | 0.000  |
| sandwich      | 0.000 | orange       | 1.502 | broccoli       | 0.000  |
| carrot        | 0.000 | hot dog      | 0.000 | pizza          | 0.396  |
| donut         | 0.000 | cake         | 0.000 | chair          | 0.099  |
| couch         | 0.000 | potted plant | 0.066 | bed            | 0.348  |
| dining table  | 0.323 | toilet       | 4.744 | tv             | 2.748  |
| laptop        | 0.000 | mouse        | 0.000 | remote         | 0.000  |
| keyboard      | 0.198 | cell phone   | 0.000 | microwave      | 0.000  |
| oven          | 0.110 | toaster      | 0.000 | sink           | 0.756  |
| refrigerator  | 0.000 | book         | 0.000 | clock          | 1.979  |
| vase          | 0.000 | scissors     | 0.000 | teddy bear     | 0.000  |
| hair drier    | 0.000 | toothbrush   | 0.000 |                |        |
[12/09 10:22:06 d2.engine.defaults]: Evaluation results for coco_2017_val_panoptic in csv format:
[12/09 10:22:06 d2.evaluation.testing]: copypaste: Task: panoptic_seg
[12/09 10:22:06 d2.evaluation.testing]: copypaste: PQ,SQ,RQ,PQ_th,SQ_th,RQ_th,PQ_st,SQ_st,RQ_st
[12/09 10:22:06 d2.evaluation.testing]: copypaste: 4.9562,33.0829,6.7000,2.8980,30.8598,3.9936,8.0629,36.4385,10.7850
[12/09 10:22:06 d2.evaluation.testing]: copypaste: Task: bbox
[12/09 10:22:06 d2.evaluation.testing]: copypaste: AP,AP50,AP75,APs,APm,APl
[12/09 10:22:06 d2.evaluation.testing]: copypaste: 0.7231,1.7286,0.5169,0.0526,0.5457,1.4450
[12/09 10:22:06 d2.evaluation.testing]: copypaste: Task: segm
[12/09 10:22:06 d2.evaluation.testing]: copypaste: AP,AP50,AP75,APs,APm,APl
[12/09 10:22:06 d2.evaluation.testing]: copypaste: 0.7887,1.6545,0.7078,0.0276,0.4786,2.0251