env: DETECTRON2_DATASETS=/content/datasets
Command Line Args: Namespace(config_file='./detectron2/projects/Panoptic-DeepLab/configs/COCO-PanopticSegmentation/panoptic_deeplab_R_52_os16_mg124_poly_200k_bs64_crop_640_640_coco_dsconv.yaml', dist_url='tcp://127.0.0.1:49152', eval_only=False, machine_rank=0, num_gpus=1, num_machines=1, opts=['MODEL.RESNETS.NORM', 'BN', 'MODEL.INS_EMBED_HEAD.NORM', 'BN', 'MODEL.SEM_SEG_HEAD.NORM', 'BN', 'SOLVER.MAX_ITER', '10000', 'SOLVER.IMS_PER_BATCH', '5', 'SOLVER.BASE_LR', '0.0025', 'MODEL.BACKBONE.FREEZE_AT', '2', 'MODEL.SEM_SEG_HEAD.NAME', 'PanopticDeepLabASPPHead'], resume=False)
Loading config ./detectron2/projects/Panoptic-DeepLab/configs/COCO-PanopticSegmentation/panoptic_deeplab_R_52_os16_mg124_poly_200k_bs64_crop_640_640_coco_dsconv.yaml with yaml.unsafe_load. Your machine may be at risk if the file contains malicious content.
[12/10 02:21:31 detectron2]: Rank of current process: 0. World size: 1
[12/10 02:21:32 detectron2]: Environment info:
----------------------  ----------------------------------------------------------------
sys.platform            linux
Python                  3.7.12 (default, Jan 15 2022, 18:48:18) [GCC 7.5.0]
numpy                   1.21.5
detectron2              0.6 @/content/detectron2/detectron2
Compiler                GCC 7.5
CUDA compiler           CUDA 11.1
detectron2 arch flags   7.0
DETECTRON2_ENV_MODULE   <not set>
PyTorch                 1.10.0+cu111 @/usr/local/lib/python3.7/dist-packages/torch
PyTorch debug build     False
GPU available           Yes
GPU 0                   Tesla V100-SXM2-16GB (arch=7.0)
Driver version          460.32.03
CUDA_HOME               /usr/local/cuda
Pillow                  7.1.2
torchvision             0.11.1+cu111 @/usr/local/lib/python3.7/dist-packages/torchvision
torchvision arch flags  3.5, 5.0, 6.0, 7.0, 7.5, 8.0, 8.6
fvcore                  0.1.5.post20221122
iopath                  0.1.9
cv2                     4.1.2
----------------------  ----------------------------------------------------------------
PyTorch built with:
  - GCC 7.3
  - C++ Version: 201402
  - Intel(R) Math Kernel Library Version 2020.0.0 Product Build 20191122 for Intel(R) 64 architecture applications
  - Intel(R) MKL-DNN v2.2.3 (Git Hash 7336ca9f055cf1bfa13efb658fe15dc9b41f0740)
  - OpenMP 201511 (a.k.a. OpenMP 4.5)
  - LAPACK is enabled (usually provided by MKL)
  - NNPACK is enabled
  - CPU capability usage: AVX512
  - CUDA Runtime 11.1
  - NVCC architecture flags: -gencode;arch=compute_37,code=sm_37;-gencode;arch=compute_50,code=sm_50;-gencode;arch=compute_60,code=sm_60;-gencode;arch=compute_70,code=sm_70;-gencode;arch=compute_75,code=sm_75;-gencode;arch=compute_80,code=sm_80;-gencode;arch=compute_86,code=sm_86
  - CuDNN 8.0.5
  - Magma 2.5.2
  - Build settings: BLAS_INFO=mkl, BUILD_TYPE=Release, CUDA_VERSION=11.1, CUDNN_VERSION=8.0.5, CXX_COMPILER=/opt/rh/devtoolset-7/root/usr/bin/c++, CXX_FLAGS= -Wno-deprecated -fvisibility-inlines-hidden -DUSE_PTHREADPOOL -fopenmp -DNDEBUG -DUSE_KINETO -DUSE_FBGEMM -DUSE_QNNPACK -DUSE_PYTORCH_QNNPACK -DUSE_XNNPACK -DSYMBOLICATE_MOBILE_DEBUG_HANDLE -DEDGE_PROFILER_USE_KINETO -O2 -fPIC -Wno-narrowing -Wall -Wextra -Werror=return-type -Wno-missing-field-initializers -Wno-type-limits -Wno-array-bounds -Wno-unknown-pragmas -Wno-sign-compare -Wno-unused-parameter -Wno-unused-variable -Wno-unused-function -Wno-unused-result -Wno-unused-local-typedefs -Wno-strict-overflow -Wno-strict-aliasing -Wno-error=deprecated-declarations -Wno-stringop-overflow -Wno-psabi -Wno-error=pedantic -Wno-error=redundant-decls -Wno-error=old-style-cast -fdiagnostics-color=always -faligned-new -Wno-unused-but-set-variable -Wno-maybe-uninitialized -fno-math-errno -fno-trapping-math -Werror=format -Wno-stringop-overflow, LAPACK_INFO=mkl, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, TORCH_VERSION=1.10.0, USE_CUDA=ON, USE_CUDNN=ON, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_MKL=ON, USE_MKLDNN=ON, USE_MPI=OFF, USE_NCCL=ON, USE_NNPACK=ON, USE_OPENMP=ON, 

[12/10 02:21:32 detectron2]: Command line arguments: Namespace(config_file='./detectron2/projects/Panoptic-DeepLab/configs/COCO-PanopticSegmentation/panoptic_deeplab_R_52_os16_mg124_poly_200k_bs64_crop_640_640_coco_dsconv.yaml', dist_url='tcp://127.0.0.1:49152', eval_only=False, machine_rank=0, num_gpus=1, num_machines=1, opts=['MODEL.RESNETS.NORM', 'BN', 'MODEL.INS_EMBED_HEAD.NORM', 'BN', 'MODEL.SEM_SEG_HEAD.NORM', 'BN', 'SOLVER.MAX_ITER', '10000', 'SOLVER.IMS_PER_BATCH', '5', 'SOLVER.BASE_LR', '0.0025', 'MODEL.BACKBONE.FREEZE_AT', '2', 'MODEL.SEM_SEG_HEAD.NAME', 'PanopticDeepLabASPPHead'], resume=False)
[12/10 02:21:32 detectron2]: Contents of args.config_file=./detectron2/projects/Panoptic-DeepLab/configs/COCO-PanopticSegmentation/panoptic_deeplab_R_52_os16_mg124_poly_200k_bs64_crop_640_640_coco_dsconv.yaml:
_BASE_: ../Cityscapes-PanopticSegmentation/Base-PanopticDeepLab-OS16.yaml
MODEL:
  WEIGHTS: "detectron2://DeepLab/R-52.pkl"
  PIXEL_MEAN: [123.675, 116.280, 103.530]
  PIXEL_STD: [58.395, 57.120, 57.375]
  BACKBONE:
    NAME: "build_resnet_deeplab_backbone"
  RESNETS:
    DEPTH: 50
    NORM: "SyncBN"
    RES5_MULTI_GRID: [1, 2, 4]
    STEM_TYPE: "deeplab"
    STEM_OUT_CHANNELS: 128
    STRIDE_IN_1X1: False
  SEM_SEG_HEAD:
    NUM_CLASSES: 133
    LOSS_TOP_K: 1.0
    USE_DEPTHWISE_SEPARABLE_CONV: True
  PANOPTIC_DEEPLAB:
    STUFF_AREA: 4096
    NMS_KERNEL: 41
    SIZE_DIVISIBILITY: 640
    USE_DEPTHWISE_SEPARABLE_CONV: True
DATASETS:
  TRAIN: ("coco_2017_train_panoptic",)
  TEST: ("coco_2017_val_panoptic",)
SOLVER:
  BASE_LR: 0.0005
  MAX_ITER: 200000
  IMS_PER_BATCH: 64
INPUT:
  FORMAT: "RGB"
  GAUSSIAN_SIGMA: 8
  MIN_SIZE_TRAIN: !!python/object/apply:eval ["[int(x * 0.1 * 640) for x in range(5, 16)]"]
  MIN_SIZE_TRAIN_SAMPLING: "choice"
  MIN_SIZE_TEST: 640
  MAX_SIZE_TRAIN: 960
  MAX_SIZE_TEST: 640
  CROP:
    ENABLED: True
    TYPE: "absolute"
    SIZE: (640, 640)

[12/10 02:21:32 detectron2]: Running with full config:
CUDNN_BENCHMARK: false
DATALOADER:
  ASPECT_RATIO_GROUPING: true
  FILTER_EMPTY_ANNOTATIONS: true
  NUM_WORKERS: 10
  REPEAT_THRESHOLD: 0.0
  SAMPLER_TRAIN: TrainingSampler
DATASETS:
  PRECOMPUTED_PROPOSAL_TOPK_TEST: 1000
  PRECOMPUTED_PROPOSAL_TOPK_TRAIN: 2000
  PROPOSAL_FILES_TEST: []
  PROPOSAL_FILES_TRAIN: []
  TEST:
  - coco_2017_val_panoptic
  TRAIN:
  - coco_2017_train_panoptic
GLOBAL:
  HACK: 1.0
INPUT:
  CROP:
    ENABLED: true
    SINGLE_CATEGORY_MAX_AREA: 1.0
    SIZE:
    - 640
    - 640
    TYPE: absolute
  FORMAT: RGB
  GAUSSIAN_SIGMA: 8
  IGNORE_CROWD_IN_SEMANTIC: false
  IGNORE_STUFF_IN_OFFSET: true
  MASK_FORMAT: polygon
  MAX_SIZE_TEST: 640
  MAX_SIZE_TRAIN: 960
  MIN_SIZE_TEST: 640
  MIN_SIZE_TRAIN:
  - 320
  - 384
  - 448
  - 512
  - 576
  - 640
  - 704
  - 768
  - 832
  - 896
  - 960
  MIN_SIZE_TRAIN_SAMPLING: choice
  RANDOM_FLIP: horizontal
  SMALL_INSTANCE_AREA: 4096
  SMALL_INSTANCE_WEIGHT: 3
MODEL:
  ANCHOR_GENERATOR:
    ANGLES:
    - - -90
      - 0
      - 90
    ASPECT_RATIOS:
    - - 0.5
      - 1.0
      - 2.0
    NAME: DefaultAnchorGenerator
    OFFSET: 0.0
    SIZES:
    - - 32
      - 64
      - 128
      - 256
      - 512
  BACKBONE:
    FREEZE_AT: 2
    NAME: build_resnet_deeplab_backbone
  DEVICE: cuda
  FPN:
    FUSE_TYPE: sum
    IN_FEATURES: []
    NORM: ''
    OUT_CHANNELS: 256
  INS_EMBED_HEAD:
    ASPP_CHANNELS: 256
    ASPP_DILATIONS:
    - 6
    - 12
    - 18
    ASPP_DROPOUT: 0.1
    CENTER_LOSS_WEIGHT: 200.0
    COMMON_STRIDE: 4
    CONVS_DIM: 128
    HEAD_CHANNELS: 32
    IN_FEATURES:
    - res2
    - res3
    - res5
    NAME: PanopticDeepLabInsEmbedHead
    NORM: BN
    OFFSET_LOSS_WEIGHT: 0.01
    PROJECT_CHANNELS:
    - 32
    - 64
    PROJECT_FEATURES:
    - res2
    - res3
  KEYPOINT_ON: false
  LOAD_PROPOSALS: false
  MASK_ON: false
  META_ARCHITECTURE: PanopticDeepLab
  PANOPTIC_DEEPLAB:
    BENCHMARK_NETWORK_SPEED: false
    CENTER_THRESHOLD: 0.1
    NMS_KERNEL: 41
    PREDICT_INSTANCES: true
    SIZE_DIVISIBILITY: 640
    STUFF_AREA: 4096
    TOP_K_INSTANCE: 200
    USE_DEPTHWISE_SEPARABLE_CONV: true
  PANOPTIC_FPN:
    COMBINE:
      ENABLED: true
      INSTANCES_CONFIDENCE_THRESH: 0.5
      OVERLAP_THRESH: 0.5
      STUFF_AREA_LIMIT: 4096
    INSTANCE_LOSS_WEIGHT: 1.0
  PIXEL_MEAN:
  - 123.675
  - 116.28
  - 103.53
  PIXEL_STD:
  - 58.395
  - 57.12
  - 57.375
  PROPOSAL_GENERATOR:
    MIN_SIZE: 0
    NAME: RPN
  RESNETS:
    DEFORM_MODULATED: false
    DEFORM_NUM_GROUPS: 1
    DEFORM_ON_PER_STAGE:
    - false
    - false
    - false
    - false
    DEPTH: 50
    NORM: BN
    NUM_GROUPS: 1
    OUT_FEATURES:
    - res2
    - res3
    - res5
    RES2_OUT_CHANNELS: 256
    RES4_DILATION: 1
    RES5_DILATION: 2
    RES5_MULTI_GRID:
    - 1
    - 2
    - 4
    STEM_OUT_CHANNELS: 128
    STEM_TYPE: deeplab
    STRIDE_IN_1X1: false
    WIDTH_PER_GROUP: 64
  RETINANET:
    BBOX_REG_LOSS_TYPE: smooth_l1
    BBOX_REG_WEIGHTS: &id001
    - 1.0
    - 1.0
    - 1.0
    - 1.0
    FOCAL_LOSS_ALPHA: 0.25
    FOCAL_LOSS_GAMMA: 2.0
    IN_FEATURES:
    - p3
    - p4
    - p5
    - p6
    - p7
    IOU_LABELS:
    - 0
    - -1
    - 1
    IOU_THRESHOLDS:
    - 0.4
    - 0.5
    NMS_THRESH_TEST: 0.5
    NORM: ''
    NUM_CLASSES: 80
    NUM_CONVS: 4
    PRIOR_PROB: 0.01
    SCORE_THRESH_TEST: 0.05
    SMOOTH_L1_LOSS_BETA: 0.1
    TOPK_CANDIDATES_TEST: 1000
  ROI_BOX_CASCADE_HEAD:
    BBOX_REG_WEIGHTS:
    - - 10.0
      - 10.0
      - 5.0
      - 5.0
    - - 20.0
      - 20.0
      - 10.0
      - 10.0
    - - 30.0
      - 30.0
      - 15.0
      - 15.0
    IOUS:
    - 0.5
    - 0.6
    - 0.7
  ROI_BOX_HEAD:
    BBOX_REG_LOSS_TYPE: smooth_l1
    BBOX_REG_LOSS_WEIGHT: 1.0
    BBOX_REG_WEIGHTS:
    - 10.0
    - 10.0
    - 5.0
    - 5.0
    CLS_AGNOSTIC_BBOX_REG: false
    CONV_DIM: 256
    FC_DIM: 1024
    FED_LOSS_FREQ_WEIGHT_POWER: 0.5
    FED_LOSS_NUM_CLASSES: 50
    NAME: ''
    NORM: ''
    NUM_CONV: 0
    NUM_FC: 0
    POOLER_RESOLUTION: 14
    POOLER_SAMPLING_RATIO: 0
    POOLER_TYPE: ROIAlignV2
    SMOOTH_L1_BETA: 0.0
    TRAIN_ON_PRED_BOXES: false
    USE_FED_LOSS: false
    USE_SIGMOID_CE: false
  ROI_HEADS:
    BATCH_SIZE_PER_IMAGE: 512
    IN_FEATURES:
    - res4
    IOU_LABELS:
    - 0
    - 1
    IOU_THRESHOLDS:
    - 0.5
    NAME: Res5ROIHeads
    NMS_THRESH_TEST: 0.5
    NUM_CLASSES: 80
    POSITIVE_FRACTION: 0.25
    PROPOSAL_APPEND_GT: true
    SCORE_THRESH_TEST: 0.05
  ROI_KEYPOINT_HEAD:
    CONV_DIMS:
    - 512
    - 512
    - 512
    - 512
    - 512
    - 512
    - 512
    - 512
    LOSS_WEIGHT: 1.0
    MIN_KEYPOINTS_PER_IMAGE: 1
    NAME: KRCNNConvDeconvUpsampleHead
    NORMALIZE_LOSS_BY_VISIBLE_KEYPOINTS: true
    NUM_KEYPOINTS: 17
    POOLER_RESOLUTION: 14
    POOLER_SAMPLING_RATIO: 0
    POOLER_TYPE: ROIAlignV2
  ROI_MASK_HEAD:
    CLS_AGNOSTIC_MASK: false
    CONV_DIM: 256
    NAME: MaskRCNNConvUpsampleHead
    NORM: ''
    NUM_CONV: 0
    POOLER_RESOLUTION: 14
    POOLER_SAMPLING_RATIO: 0
    POOLER_TYPE: ROIAlignV2
  RPN:
    BATCH_SIZE_PER_IMAGE: 256
    BBOX_REG_LOSS_TYPE: smooth_l1
    BBOX_REG_LOSS_WEIGHT: 1.0
    BBOX_REG_WEIGHTS: *id001
    BOUNDARY_THRESH: -1
    CONV_DIMS:
    - -1
    HEAD_NAME: StandardRPNHead
    IN_FEATURES:
    - res4
    IOU_LABELS:
    - 0
    - -1
    - 1
    IOU_THRESHOLDS:
    - 0.3
    - 0.7
    LOSS_WEIGHT: 1.0
    NMS_THRESH: 0.7
    POSITIVE_FRACTION: 0.5
    POST_NMS_TOPK_TEST: 1000
    POST_NMS_TOPK_TRAIN: 2000
    PRE_NMS_TOPK_TEST: 6000
    PRE_NMS_TOPK_TRAIN: 12000
    SMOOTH_L1_BETA: 0.0
  SEM_SEG_HEAD:
    ASPP_CHANNELS: 256
    ASPP_DILATIONS:
    - 6
    - 12
    - 18
    ASPP_DROPOUT: 0.1
    COMMON_STRIDE: 4
    CONVS_DIM: 256
    HEAD_CHANNELS: 256
    IGNORE_VALUE: 255
    IN_FEATURES:
    - res2
    - res3
    - res5
    LOSS_TOP_K: 1.0
    LOSS_TYPE: hard_pixel_mining
    LOSS_WEIGHT: 1.0
    NAME: PanopticDeepLabASPPHead
    NORM: BN
    NUM_CLASSES: 133
    PROJECT_CHANNELS:
    - 32
    - 64
    PROJECT_FEATURES:
    - res2
    - res3
    USE_DEPTHWISE_SEPARABLE_CONV: true
  WEIGHTS: detectron2://DeepLab/R-52.pkl
OUTPUT_DIR: ./output
SEED: -1
SOLVER:
  AMP:
    ENABLED: false
  BASE_LR: 0.0025
  BASE_LR_END: 0.0
  BIAS_LR_FACTOR: 1.0
  CHECKPOINT_PERIOD: 5000
  CLIP_GRADIENTS:
    CLIP_TYPE: value
    CLIP_VALUE: 1.0
    ENABLED: false
    NORM_TYPE: 2.0
  GAMMA: 0.1
  IMS_PER_BATCH: 5
  LR_SCHEDULER_NAME: WarmupPolyLR
  MAX_ITER: 10000
  MOMENTUM: 0.9
  NESTEROV: false
  NUM_DECAYS: 3
  OPTIMIZER: ADAM
  POLY_LR_CONSTANT_ENDING: 0.0
  POLY_LR_POWER: 0.9
  REFERENCE_WORLD_SIZE: 0
  RESCALE_INTERVAL: false
  STEPS:
  - 30000
  WARMUP_FACTOR: 0.001
  WARMUP_ITERS: 1000
  WARMUP_METHOD: linear
  WEIGHT_DECAY: 0.0
  WEIGHT_DECAY_BIAS: 0.0
  WEIGHT_DECAY_NORM: 0.0
TEST:
  AUG:
    ENABLED: false
    FLIP: true
    MAX_SIZE: 4000
    MIN_SIZES:
    - 400
    - 500
    - 600
    - 700
    - 800
    - 900
    - 1000
    - 1100
    - 1200
  DETECTIONS_PER_IMAGE: 100
  EVAL_PERIOD: 0
  EXPECTED_RESULTS: []
  KEYPOINT_OKS_SIGMAS: []
  PRECISE_BN:
    ENABLED: false
    NUM_ITER: 200
VERSION: 2
VIS_PERIOD: 0

[12/10 02:21:32 detectron2]: Full config saved to ./output/config.yaml
[12/10 02:21:32 d2.utils.env]: Using a generated random seed 32950172
[12/10 02:21:37 d2.engine.defaults]: Model:
PanopticDeepLab(
  (backbone): ResNet(
    (stem): DeepLabStem(
      (conv1): Conv2d(
        3, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False
        (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
      )
      (conv2): Conv2d(
        64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
        (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
      )
      (conv3): Conv2d(
        64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
        (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
      )
    )
    (res2): Sequential(
      (0): BottleneckBlock(
        (shortcut): Conv2d(
          128, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv1): Conv2d(
          128, 64, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
        )
        (conv2): Conv2d(
          64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
        )
        (conv3): Conv2d(
          64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
      )
      (1): BottleneckBlock(
        (conv1): Conv2d(
          256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
        )
        (conv2): Conv2d(
          64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
        )
        (conv3): Conv2d(
          64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
      )
      (2): BottleneckBlock(
        (conv1): Conv2d(
          256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
        )
        (conv2): Conv2d(
          64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
        )
        (conv3): Conv2d(
          64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
      )
    )
    (res3): Sequential(
      (0): BottleneckBlock(
        (shortcut): Conv2d(
          256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False
          (norm): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv1): Conv2d(
          256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv2): Conv2d(
          128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False
          (norm): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv3): Conv2d(
          128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (1): BottleneckBlock(
        (conv1): Conv2d(
          512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv2): Conv2d(
          128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv3): Conv2d(
          128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (2): BottleneckBlock(
        (conv1): Conv2d(
          512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv2): Conv2d(
          128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv3): Conv2d(
          128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (3): BottleneckBlock(
        (conv1): Conv2d(
          512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv2): Conv2d(
          128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv3): Conv2d(
          128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
    )
    (res4): Sequential(
      (0): BottleneckBlock(
        (shortcut): Conv2d(
          512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False
          (norm): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv1): Conv2d(
          512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv2): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False
          (norm): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv3): Conv2d(
          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (1): BottleneckBlock(
        (conv1): Conv2d(
          1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv2): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv3): Conv2d(
          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (2): BottleneckBlock(
        (conv1): Conv2d(
          1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv2): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv3): Conv2d(
          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (3): BottleneckBlock(
        (conv1): Conv2d(
          1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv2): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv3): Conv2d(
          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (4): BottleneckBlock(
        (conv1): Conv2d(
          1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv2): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv3): Conv2d(
          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (5): BottleneckBlock(
        (conv1): Conv2d(
          1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv2): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv3): Conv2d(
          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
    )
    (res5): Sequential(
      (0): BottleneckBlock(
        (shortcut): Conv2d(
          1024, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv1): Conv2d(
          1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv2): Conv2d(
          512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2), dilation=(2, 2), bias=False
          (norm): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv3): Conv2d(
          512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (1): BottleneckBlock(
        (conv1): Conv2d(
          2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv2): Conv2d(
          512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(4, 4), dilation=(4, 4), bias=False
          (norm): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv3): Conv2d(
          512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (2): BottleneckBlock(
        (conv1): Conv2d(
          2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv2): Conv2d(
          512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(8, 8), dilation=(8, 8), bias=False
          (norm): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv3): Conv2d(
          512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
    )
  )
  (aspp_head): PanopticDeepLabASPPHead(
    (decoder): ModuleDict(
      (res2): ModuleDict(
        (project_conv): Conv2d(
          256, 32, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (fuse_conv): DepthwiseSeparableConv2d(
          (depthwise): Conv2d(
            288, 288, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=288, bias=False
            (norm): BatchNorm2d(288, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          )
          (pointwise): Conv2d(
            288, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
      )
      (res3): ModuleDict(
        (project_conv): Conv2d(
          512, 64, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (fuse_conv): DepthwiseSeparableConv2d(
          (depthwise): Conv2d(
            320, 320, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=320, bias=False
            (norm): BatchNorm2d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          )
          (pointwise): Conv2d(
            320, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
      )
      (res5): ModuleDict(
        (project_conv): ASPP(
          (convs): ModuleList(
            (0): Conv2d(
              2048, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
              (norm): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            )
            (1): DepthwiseSeparableConv2d(
              (depthwise): Conv2d(
                2048, 2048, kernel_size=(3, 3), stride=(1, 1), padding=(6, 6), dilation=(6, 6), groups=2048, bias=False
                (norm): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
              (pointwise): Conv2d(
                2048, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
            )
            (2): DepthwiseSeparableConv2d(
              (depthwise): Conv2d(
                2048, 2048, kernel_size=(3, 3), stride=(1, 1), padding=(12, 12), dilation=(12, 12), groups=2048, bias=False
                (norm): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
              (pointwise): Conv2d(
                2048, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
            )
            (3): DepthwiseSeparableConv2d(
              (depthwise): Conv2d(
                2048, 2048, kernel_size=(3, 3), stride=(1, 1), padding=(18, 18), dilation=(18, 18), groups=2048, bias=False
                (norm): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
              (pointwise): Conv2d(
                2048, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
            )
            (4): Sequential(
              (0): AvgPool2d(kernel_size=(40, 40), stride=1, padding=0)
              (1): Conv2d(2048, 256, kernel_size=(1, 1), stride=(1, 1))
            )
          )
          (project): Conv2d(
            1280, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (fuse_conv): None
      )
    )
    (loss): DeepLabCE(
      (criterion): CrossEntropyLoss()
    )
  )
  (sem_seg_head): PanopticDeepLabSemSegHead(
    (aspp_head): PanopticDeepLabASPPHead(
      (decoder): ModuleDict(
        (res2): ModuleDict(
          (project_conv): Conv2d(
            256, 32, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          )
          (fuse_conv): DepthwiseSeparableConv2d(
            (depthwise): Conv2d(
              288, 288, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=288, bias=False
              (norm): BatchNorm2d(288, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            )
            (pointwise): Conv2d(
              288, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
              (norm): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            )
          )
        )
        (res3): ModuleDict(
          (project_conv): Conv2d(
            512, 64, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          )
          (fuse_conv): DepthwiseSeparableConv2d(
            (depthwise): Conv2d(
              320, 320, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=320, bias=False
              (norm): BatchNorm2d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            )
            (pointwise): Conv2d(
              320, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
              (norm): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            )
          )
        )
        (res5): ModuleDict(
          (project_conv): ASPP(
            (convs): ModuleList(
              (0): Conv2d(
                2048, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
              (1): DepthwiseSeparableConv2d(
                (depthwise): Conv2d(
                  2048, 2048, kernel_size=(3, 3), stride=(1, 1), padding=(6, 6), dilation=(6, 6), groups=2048, bias=False
                  (norm): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                )
                (pointwise): Conv2d(
                  2048, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
                  (norm): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                )
              )
              (2): DepthwiseSeparableConv2d(
                (depthwise): Conv2d(
                  2048, 2048, kernel_size=(3, 3), stride=(1, 1), padding=(12, 12), dilation=(12, 12), groups=2048, bias=False
                  (norm): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                )
                (pointwise): Conv2d(
                  2048, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
                  (norm): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                )
              )
              (3): DepthwiseSeparableConv2d(
                (depthwise): Conv2d(
                  2048, 2048, kernel_size=(3, 3), stride=(1, 1), padding=(18, 18), dilation=(18, 18), groups=2048, bias=False
                  (norm): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                )
                (pointwise): Conv2d(
                  2048, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
                  (norm): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                )
              )
              (4): Sequential(
                (0): AvgPool2d(kernel_size=(40, 40), stride=1, padding=0)
                (1): Conv2d(2048, 256, kernel_size=(1, 1), stride=(1, 1))
              )
            )
            (project): Conv2d(
              1280, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
              (norm): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            )
          )
          (fuse_conv): None
        )
      )
      (loss): DeepLabCE(
        (criterion): CrossEntropyLoss()
      )
    )
    (head): DepthwiseSeparableConv2d(
      (depthwise): Conv2d(
        256, 256, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=256, bias=False
        (norm): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (pointwise): Conv2d(
        256, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
        (norm): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (predictor): Conv2d(256, 133, kernel_size=(1, 1), stride=(1, 1))
    (loss): DeepLabCE(
      (criterion): CrossEntropyLoss()
    )
  )
  (ins_embed_head): PanopticDeepLabInsEmbedHead(
    (aspp_head): PanopticDeepLabASPPHead(
      (decoder): ModuleDict(
        (res2): ModuleDict(
          (project_conv): Conv2d(
            256, 32, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          )
          (fuse_conv): DepthwiseSeparableConv2d(
            (depthwise): Conv2d(
              288, 288, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=288, bias=False
              (norm): BatchNorm2d(288, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            )
            (pointwise): Conv2d(
              288, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
              (norm): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            )
          )
        )
        (res3): ModuleDict(
          (project_conv): Conv2d(
            512, 64, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          )
          (fuse_conv): DepthwiseSeparableConv2d(
            (depthwise): Conv2d(
              320, 320, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=320, bias=False
              (norm): BatchNorm2d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            )
            (pointwise): Conv2d(
              320, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
              (norm): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            )
          )
        )
        (res5): ModuleDict(
          (project_conv): ASPP(
            (convs): ModuleList(
              (0): Conv2d(
                2048, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
              (1): DepthwiseSeparableConv2d(
                (depthwise): Conv2d(
                  2048, 2048, kernel_size=(3, 3), stride=(1, 1), padding=(6, 6), dilation=(6, 6), groups=2048, bias=False
                  (norm): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                )
                (pointwise): Conv2d(
                  2048, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
                  (norm): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                )
              )
              (2): DepthwiseSeparableConv2d(
                (depthwise): Conv2d(
                  2048, 2048, kernel_size=(3, 3), stride=(1, 1), padding=(12, 12), dilation=(12, 12), groups=2048, bias=False
                  (norm): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                )
                (pointwise): Conv2d(
                  2048, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
                  (norm): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                )
              )
              (3): DepthwiseSeparableConv2d(
                (depthwise): Conv2d(
                  2048, 2048, kernel_size=(3, 3), stride=(1, 1), padding=(18, 18), dilation=(18, 18), groups=2048, bias=False
                  (norm): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                )
                (pointwise): Conv2d(
                  2048, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
                  (norm): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                )
              )
              (4): Sequential(
                (0): AvgPool2d(kernel_size=(40, 40), stride=1, padding=0)
                (1): Conv2d(2048, 256, kernel_size=(1, 1), stride=(1, 1))
              )
            )
            (project): Conv2d(
              1280, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
              (norm): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            )
          )
          (fuse_conv): None
        )
      )
      (loss): DeepLabCE(
        (criterion): CrossEntropyLoss()
      )
    )
    (center_head): Sequential(
      (0): Conv2d(
        256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
        (norm): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (1): Conv2d(
        256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
        (norm): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (center_predictor): Conv2d(256, 1, kernel_size=(1, 1), stride=(1, 1))
    (offset_head): DepthwiseSeparableConv2d(
      (depthwise): Conv2d(
        256, 256, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=256, bias=False
        (norm): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (pointwise): Conv2d(
        256, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
        (norm): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (offset_predictor): Conv2d(256, 2, kernel_size=(1, 1), stride=(1, 1))
    (center_loss): MSELoss()
    (offset_loss): L1Loss()
  )
)
[12/10 02:21:37 d2.projects.panoptic_deeplab.dataset_mapper]: Augmentations used in training: [ResizeShortestEdge(short_edge_length=(320, 384, 448, 512, 576, 640, 704, 768, 832, 896, 960), max_size=960, sample_style='choice'), RandomCrop(crop_type='absolute', crop_size=[640, 640]), RandomFlip()]
[12/10 02:21:44 d2.data.build]: Using training sampler TrainingSampler
[12/10 02:21:44 d2.data.common]: Serializing the dataset using: <class 'detectron2.data.common.NumpySerializedList'>
[12/10 02:21:44 d2.data.common]: Serializing 118287 elements to byte tensors and concatenating them all ...
[12/10 02:21:45 d2.data.common]: Serialized dataset takes 80.32 MiB
/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:481: UserWarning: This DataLoader will create 10 worker processes in total. Our suggested max number of worker in current system is 8, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.
  cpuset_checked))
[12/10 02:21:47 fvcore.common.checkpoint]: [Checkpointer] Loading from detectron2://DeepLab/R-52.pkl ...
[12/10 02:21:48 fvcore.common.checkpoint]: Reading a file from 'torchvision'
[12/10 02:21:48 d2.checkpoint.c2_model_loading]: Following weights matched with submodule backbone:
| Names in Model    | Names in Checkpoint                                                                                        | Shapes                                             |
|:------------------|:-----------------------------------------------------------------------------------------------------------|:---------------------------------------------------|
| res2.0.conv1.*    | res2.0.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}                             | (64,) (64,) (64,) (64,) (64,128,1,1)               |
| res2.0.conv2.*    | res2.0.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}                             | (64,) (64,) (64,) (64,) (64,64,3,3)                |
| res2.0.conv3.*    | res2.0.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}                             | (256,) (256,) (256,) (256,) (256,64,1,1)           |
| res2.0.shortcut.* | res2.0.shortcut.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}                          | (256,) (256,) (256,) (256,) (256,128,1,1)          |
| res2.1.conv1.*    | res2.1.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}                             | (64,) (64,) (64,) (64,) (64,256,1,1)               |
| res2.1.conv2.*    | res2.1.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}                             | (64,) (64,) (64,) (64,) (64,64,3,3)                |
| res2.1.conv3.*    | res2.1.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}                             | (256,) (256,) (256,) (256,) (256,64,1,1)           |
| res2.2.conv1.*    | res2.2.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}                             | (64,) (64,) (64,) (64,) (64,256,1,1)               |
| res2.2.conv2.*    | res2.2.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}                             | (64,) (64,) (64,) (64,) (64,64,3,3)                |
| res2.2.conv3.*    | res2.2.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}                             | (256,) (256,) (256,) (256,) (256,64,1,1)           |
| res3.0.conv1.*    | res3.0.conv1.{norm.bias,norm.num_batches_tracked,norm.running_mean,norm.running_var,norm.weight,weight}    | (128,) () (128,) (128,) (128,) (128,256,1,1)       |
| res3.0.conv2.*    | res3.0.conv2.{norm.bias,norm.num_batches_tracked,norm.running_mean,norm.running_var,norm.weight,weight}    | (128,) () (128,) (128,) (128,) (128,128,3,3)       |
| res3.0.conv3.*    | res3.0.conv3.{norm.bias,norm.num_batches_tracked,norm.running_mean,norm.running_var,norm.weight,weight}    | (512,) () (512,) (512,) (512,) (512,128,1,1)       |
| res3.0.shortcut.* | res3.0.shortcut.{norm.bias,norm.num_batches_tracked,norm.running_mean,norm.running_var,norm.weight,weight} | (512,) () (512,) (512,) (512,) (512,256,1,1)       |
| res3.1.conv1.*    | res3.1.conv1.{norm.bias,norm.num_batches_tracked,norm.running_mean,norm.running_var,norm.weight,weight}    | (128,) () (128,) (128,) (128,) (128,512,1,1)       |
| res3.1.conv2.*    | res3.1.conv2.{norm.bias,norm.num_batches_tracked,norm.running_mean,norm.running_var,norm.weight,weight}    | (128,) () (128,) (128,) (128,) (128,128,3,3)       |
| res3.1.conv3.*    | res3.1.conv3.{norm.bias,norm.num_batches_tracked,norm.running_mean,norm.running_var,norm.weight,weight}    | (512,) () (512,) (512,) (512,) (512,128,1,1)       |
| res3.2.conv1.*    | res3.2.conv1.{norm.bias,norm.num_batches_tracked,norm.running_mean,norm.running_var,norm.weight,weight}    | (128,) () (128,) (128,) (128,) (128,512,1,1)       |
| res3.2.conv2.*    | res3.2.conv2.{norm.bias,norm.num_batches_tracked,norm.running_mean,norm.running_var,norm.weight,weight}    | (128,) () (128,) (128,) (128,) (128,128,3,3)       |
| res3.2.conv3.*    | res3.2.conv3.{norm.bias,norm.num_batches_tracked,norm.running_mean,norm.running_var,norm.weight,weight}    | (512,) () (512,) (512,) (512,) (512,128,1,1)       |
| res3.3.conv1.*    | res3.3.conv1.{norm.bias,norm.num_batches_tracked,norm.running_mean,norm.running_var,norm.weight,weight}    | (128,) () (128,) (128,) (128,) (128,512,1,1)       |
| res3.3.conv2.*    | res3.3.conv2.{norm.bias,norm.num_batches_tracked,norm.running_mean,norm.running_var,norm.weight,weight}    | (128,) () (128,) (128,) (128,) (128,128,3,3)       |
| res3.3.conv3.*    | res3.3.conv3.{norm.bias,norm.num_batches_tracked,norm.running_mean,norm.running_var,norm.weight,weight}    | (512,) () (512,) (512,) (512,) (512,128,1,1)       |
| res4.0.conv1.*    | res4.0.conv1.{norm.bias,norm.num_batches_tracked,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) () (256,) (256,) (256,) (256,512,1,1)       |
| res4.0.conv2.*    | res4.0.conv2.{norm.bias,norm.num_batches_tracked,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) () (256,) (256,) (256,) (256,256,3,3)       |
| res4.0.conv3.*    | res4.0.conv3.{norm.bias,norm.num_batches_tracked,norm.running_mean,norm.running_var,norm.weight,weight}    | (1024,) () (1024,) (1024,) (1024,) (1024,256,1,1)  |
| res4.0.shortcut.* | res4.0.shortcut.{norm.bias,norm.num_batches_tracked,norm.running_mean,norm.running_var,norm.weight,weight} | (1024,) () (1024,) (1024,) (1024,) (1024,512,1,1)  |
| res4.1.conv1.*    | res4.1.conv1.{norm.bias,norm.num_batches_tracked,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) () (256,) (256,) (256,) (256,1024,1,1)      |
| res4.1.conv2.*    | res4.1.conv2.{norm.bias,norm.num_batches_tracked,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) () (256,) (256,) (256,) (256,256,3,3)       |
| res4.1.conv3.*    | res4.1.conv3.{norm.bias,norm.num_batches_tracked,norm.running_mean,norm.running_var,norm.weight,weight}    | (1024,) () (1024,) (1024,) (1024,) (1024,256,1,1)  |
| res4.2.conv1.*    | res4.2.conv1.{norm.bias,norm.num_batches_tracked,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) () (256,) (256,) (256,) (256,1024,1,1)      |
| res4.2.conv2.*    | res4.2.conv2.{norm.bias,norm.num_batches_tracked,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) () (256,) (256,) (256,) (256,256,3,3)       |
| res4.2.conv3.*    | res4.2.conv3.{norm.bias,norm.num_batches_tracked,norm.running_mean,norm.running_var,norm.weight,weight}    | (1024,) () (1024,) (1024,) (1024,) (1024,256,1,1)  |
| res4.3.conv1.*    | res4.3.conv1.{norm.bias,norm.num_batches_tracked,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) () (256,) (256,) (256,) (256,1024,1,1)      |
| res4.3.conv2.*    | res4.3.conv2.{norm.bias,norm.num_batches_tracked,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) () (256,) (256,) (256,) (256,256,3,3)       |
| res4.3.conv3.*    | res4.3.conv3.{norm.bias,norm.num_batches_tracked,norm.running_mean,norm.running_var,norm.weight,weight}    | (1024,) () (1024,) (1024,) (1024,) (1024,256,1,1)  |
| res4.4.conv1.*    | res4.4.conv1.{norm.bias,norm.num_batches_tracked,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) () (256,) (256,) (256,) (256,1024,1,1)      |
| res4.4.conv2.*    | res4.4.conv2.{norm.bias,norm.num_batches_tracked,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) () (256,) (256,) (256,) (256,256,3,3)       |
| res4.4.conv3.*    | res4.4.conv3.{norm.bias,norm.num_batches_tracked,norm.running_mean,norm.running_var,norm.weight,weight}    | (1024,) () (1024,) (1024,) (1024,) (1024,256,1,1)  |
| res4.5.conv1.*    | res4.5.conv1.{norm.bias,norm.num_batches_tracked,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) () (256,) (256,) (256,) (256,1024,1,1)      |
| res4.5.conv2.*    | res4.5.conv2.{norm.bias,norm.num_batches_tracked,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) () (256,) (256,) (256,) (256,256,3,3)       |
| res4.5.conv3.*    | res4.5.conv3.{norm.bias,norm.num_batches_tracked,norm.running_mean,norm.running_var,norm.weight,weight}    | (1024,) () (1024,) (1024,) (1024,) (1024,256,1,1)  |
| res5.0.conv1.*    | res5.0.conv1.{norm.bias,norm.num_batches_tracked,norm.running_mean,norm.running_var,norm.weight,weight}    | (512,) () (512,) (512,) (512,) (512,1024,1,1)      |
| res5.0.conv2.*    | res5.0.conv2.{norm.bias,norm.num_batches_tracked,norm.running_mean,norm.running_var,norm.weight,weight}    | (512,) () (512,) (512,) (512,) (512,512,3,3)       |
| res5.0.conv3.*    | res5.0.conv3.{norm.bias,norm.num_batches_tracked,norm.running_mean,norm.running_var,norm.weight,weight}    | (2048,) () (2048,) (2048,) (2048,) (2048,512,1,1)  |
| res5.0.shortcut.* | res5.0.shortcut.{norm.bias,norm.num_batches_tracked,norm.running_mean,norm.running_var,norm.weight,weight} | (2048,) () (2048,) (2048,) (2048,) (2048,1024,1,1) |
| res5.1.conv1.*    | res5.1.conv1.{norm.bias,norm.num_batches_tracked,norm.running_mean,norm.running_var,norm.weight,weight}    | (512,) () (512,) (512,) (512,) (512,2048,1,1)      |
| res5.1.conv2.*    | res5.1.conv2.{norm.bias,norm.num_batches_tracked,norm.running_mean,norm.running_var,norm.weight,weight}    | (512,) () (512,) (512,) (512,) (512,512,3,3)       |
| res5.1.conv3.*    | res5.1.conv3.{norm.bias,norm.num_batches_tracked,norm.running_mean,norm.running_var,norm.weight,weight}    | (2048,) () (2048,) (2048,) (2048,) (2048,512,1,1)  |
| res5.2.conv1.*    | res5.2.conv1.{norm.bias,norm.num_batches_tracked,norm.running_mean,norm.running_var,norm.weight,weight}    | (512,) () (512,) (512,) (512,) (512,2048,1,1)      |
| res5.2.conv2.*    | res5.2.conv2.{norm.bias,norm.num_batches_tracked,norm.running_mean,norm.running_var,norm.weight,weight}    | (512,) () (512,) (512,) (512,) (512,512,3,3)       |
| res5.2.conv3.*    | res5.2.conv3.{norm.bias,norm.num_batches_tracked,norm.running_mean,norm.running_var,norm.weight,weight}    | (2048,) () (2048,) (2048,) (2048,) (2048,512,1,1)  |
| stem.conv1.*      | stem.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}                               | (64,) (64,) (64,) (64,) (64,3,3,3)                 |
| stem.conv2.*      | stem.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}                               | (64,) (64,) (64,) (64,) (64,64,3,3)                |
| stem.conv3.*      | stem.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}                               | (128,) (128,) (128,) (128,) (128,64,3,3)           |
WARNING [12/10 02:21:48 fvcore.common.checkpoint]: Some model parameters or buffers are not found in the checkpoint:
aspp_head.decoder.res2.fuse_conv.depthwise.norm.{bias, running_mean, running_var, weight}
aspp_head.decoder.res2.fuse_conv.depthwise.weight
aspp_head.decoder.res2.fuse_conv.pointwise.norm.{bias, running_mean, running_var, weight}
aspp_head.decoder.res2.fuse_conv.pointwise.weight
aspp_head.decoder.res2.project_conv.norm.{bias, running_mean, running_var, weight}
aspp_head.decoder.res2.project_conv.weight
aspp_head.decoder.res3.fuse_conv.depthwise.norm.{bias, running_mean, running_var, weight}
aspp_head.decoder.res3.fuse_conv.depthwise.weight
aspp_head.decoder.res3.fuse_conv.pointwise.norm.{bias, running_mean, running_var, weight}
aspp_head.decoder.res3.fuse_conv.pointwise.weight
aspp_head.decoder.res3.project_conv.norm.{bias, running_mean, running_var, weight}
aspp_head.decoder.res3.project_conv.weight
aspp_head.decoder.res5.project_conv.convs.0.norm.{bias, running_mean, running_var, weight}
aspp_head.decoder.res5.project_conv.convs.0.weight
aspp_head.decoder.res5.project_conv.convs.1.depthwise.norm.{bias, running_mean, running_var, weight}
aspp_head.decoder.res5.project_conv.convs.1.depthwise.weight
aspp_head.decoder.res5.project_conv.convs.1.pointwise.norm.{bias, running_mean, running_var, weight}
aspp_head.decoder.res5.project_conv.convs.1.pointwise.weight
aspp_head.decoder.res5.project_conv.convs.2.depthwise.norm.{bias, running_mean, running_var, weight}
aspp_head.decoder.res5.project_conv.convs.2.depthwise.weight
aspp_head.decoder.res5.project_conv.convs.2.pointwise.norm.{bias, running_mean, running_var, weight}
aspp_head.decoder.res5.project_conv.convs.2.pointwise.weight
aspp_head.decoder.res5.project_conv.convs.3.depthwise.norm.{bias, running_mean, running_var, weight}
aspp_head.decoder.res5.project_conv.convs.3.depthwise.weight
aspp_head.decoder.res5.project_conv.convs.3.pointwise.norm.{bias, running_mean, running_var, weight}
aspp_head.decoder.res5.project_conv.convs.3.pointwise.weight
aspp_head.decoder.res5.project_conv.convs.4.1.{bias, weight}
aspp_head.decoder.res5.project_conv.project.norm.{bias, running_mean, running_var, weight}
aspp_head.decoder.res5.project_conv.project.weight
ins_embed_head.aspp_head.decoder.res2.fuse_conv.depthwise.norm.{bias, running_mean, running_var, weight}
ins_embed_head.aspp_head.decoder.res2.fuse_conv.depthwise.weight
ins_embed_head.aspp_head.decoder.res2.fuse_conv.pointwise.norm.{bias, running_mean, running_var, weight}
ins_embed_head.aspp_head.decoder.res2.fuse_conv.pointwise.weight
ins_embed_head.aspp_head.decoder.res2.project_conv.norm.{bias, running_mean, running_var, weight}
ins_embed_head.aspp_head.decoder.res2.project_conv.weight
ins_embed_head.aspp_head.decoder.res3.fuse_conv.depthwise.norm.{bias, running_mean, running_var, weight}
ins_embed_head.aspp_head.decoder.res3.fuse_conv.depthwise.weight
ins_embed_head.aspp_head.decoder.res3.fuse_conv.pointwise.norm.{bias, running_mean, running_var, weight}
ins_embed_head.aspp_head.decoder.res3.fuse_conv.pointwise.weight
ins_embed_head.aspp_head.decoder.res3.project_conv.norm.{bias, running_mean, running_var, weight}
ins_embed_head.aspp_head.decoder.res3.project_conv.weight
ins_embed_head.aspp_head.decoder.res5.project_conv.convs.0.norm.{bias, running_mean, running_var, weight}
ins_embed_head.aspp_head.decoder.res5.project_conv.convs.0.weight
ins_embed_head.aspp_head.decoder.res5.project_conv.convs.1.depthwise.norm.{bias, running_mean, running_var, weight}
ins_embed_head.aspp_head.decoder.res5.project_conv.convs.1.depthwise.weight
ins_embed_head.aspp_head.decoder.res5.project_conv.convs.1.pointwise.norm.{bias, running_mean, running_var, weight}
ins_embed_head.aspp_head.decoder.res5.project_conv.convs.1.pointwise.weight
ins_embed_head.aspp_head.decoder.res5.project_conv.convs.2.depthwise.norm.{bias, running_mean, running_var, weight}
ins_embed_head.aspp_head.decoder.res5.project_conv.convs.2.depthwise.weight
ins_embed_head.aspp_head.decoder.res5.project_conv.convs.2.pointwise.norm.{bias, running_mean, running_var, weight}
ins_embed_head.aspp_head.decoder.res5.project_conv.convs.2.pointwise.weight
ins_embed_head.aspp_head.decoder.res5.project_conv.convs.3.depthwise.norm.{bias, running_mean, running_var, weight}
ins_embed_head.aspp_head.decoder.res5.project_conv.convs.3.depthwise.weight
ins_embed_head.aspp_head.decoder.res5.project_conv.convs.3.pointwise.norm.{bias, running_mean, running_var, weight}
ins_embed_head.aspp_head.decoder.res5.project_conv.convs.3.pointwise.weight
ins_embed_head.aspp_head.decoder.res5.project_conv.convs.4.1.{bias, weight}
ins_embed_head.aspp_head.decoder.res5.project_conv.project.norm.{bias, running_mean, running_var, weight}
ins_embed_head.aspp_head.decoder.res5.project_conv.project.weight
ins_embed_head.center_head.0.norm.{bias, running_mean, running_var, weight}
ins_embed_head.center_head.0.weight
ins_embed_head.center_head.1.norm.{bias, running_mean, running_var, weight}
ins_embed_head.center_head.1.weight
ins_embed_head.center_predictor.{bias, weight}
ins_embed_head.offset_head.depthwise.norm.{bias, running_mean, running_var, weight}
ins_embed_head.offset_head.depthwise.weight
ins_embed_head.offset_head.pointwise.norm.{bias, running_mean, running_var, weight}
ins_embed_head.offset_head.pointwise.weight
ins_embed_head.offset_predictor.{bias, weight}
sem_seg_head.aspp_head.decoder.res2.fuse_conv.depthwise.norm.{bias, running_mean, running_var, weight}
sem_seg_head.aspp_head.decoder.res2.fuse_conv.depthwise.weight
sem_seg_head.aspp_head.decoder.res2.fuse_conv.pointwise.norm.{bias, running_mean, running_var, weight}
sem_seg_head.aspp_head.decoder.res2.fuse_conv.pointwise.weight
sem_seg_head.aspp_head.decoder.res2.project_conv.norm.{bias, running_mean, running_var, weight}
sem_seg_head.aspp_head.decoder.res2.project_conv.weight
sem_seg_head.aspp_head.decoder.res3.fuse_conv.depthwise.norm.{bias, running_mean, running_var, weight}
sem_seg_head.aspp_head.decoder.res3.fuse_conv.depthwise.weight
sem_seg_head.aspp_head.decoder.res3.fuse_conv.pointwise.norm.{bias, running_mean, running_var, weight}
sem_seg_head.aspp_head.decoder.res3.fuse_conv.pointwise.weight
sem_seg_head.aspp_head.decoder.res3.project_conv.norm.{bias, running_mean, running_var, weight}
sem_seg_head.aspp_head.decoder.res3.project_conv.weight
sem_seg_head.aspp_head.decoder.res5.project_conv.convs.0.norm.{bias, running_mean, running_var, weight}
sem_seg_head.aspp_head.decoder.res5.project_conv.convs.0.weight
sem_seg_head.aspp_head.decoder.res5.project_conv.convs.1.depthwise.norm.{bias, running_mean, running_var, weight}
sem_seg_head.aspp_head.decoder.res5.project_conv.convs.1.depthwise.weight
sem_seg_head.aspp_head.decoder.res5.project_conv.convs.1.pointwise.norm.{bias, running_mean, running_var, weight}
sem_seg_head.aspp_head.decoder.res5.project_conv.convs.1.pointwise.weight
sem_seg_head.aspp_head.decoder.res5.project_conv.convs.2.depthwise.norm.{bias, running_mean, running_var, weight}
sem_seg_head.aspp_head.decoder.res5.project_conv.convs.2.depthwise.weight
sem_seg_head.aspp_head.decoder.res5.project_conv.convs.2.pointwise.norm.{bias, running_mean, running_var, weight}
sem_seg_head.aspp_head.decoder.res5.project_conv.convs.2.pointwise.weight
sem_seg_head.aspp_head.decoder.res5.project_conv.convs.3.depthwise.norm.{bias, running_mean, running_var, weight}
sem_seg_head.aspp_head.decoder.res5.project_conv.convs.3.depthwise.weight
sem_seg_head.aspp_head.decoder.res5.project_conv.convs.3.pointwise.norm.{bias, running_mean, running_var, weight}
sem_seg_head.aspp_head.decoder.res5.project_conv.convs.3.pointwise.weight
sem_seg_head.aspp_head.decoder.res5.project_conv.convs.4.1.{bias, weight}
sem_seg_head.aspp_head.decoder.res5.project_conv.project.norm.{bias, running_mean, running_var, weight}
sem_seg_head.aspp_head.decoder.res5.project_conv.project.weight
sem_seg_head.head.depthwise.norm.{bias, running_mean, running_var, weight}
sem_seg_head.head.depthwise.weight
sem_seg_head.head.pointwise.norm.{bias, running_mean, running_var, weight}
sem_seg_head.head.pointwise.weight
sem_seg_head.predictor.{bias, weight}
WARNING [12/10 02:21:48 fvcore.common.checkpoint]: The checkpoint state_dict contains keys that are not used by the model:
  res2.0.conv1.norm.num_batches_tracked
  res2.0.conv2.norm.num_batches_tracked
  res2.0.conv3.norm.num_batches_tracked
  res2.0.shortcut.norm.num_batches_tracked
  res2.1.conv1.norm.num_batches_tracked
  res2.1.conv2.norm.num_batches_tracked
  res2.1.conv3.norm.num_batches_tracked
  res2.2.conv1.norm.num_batches_tracked
  res2.2.conv2.norm.num_batches_tracked
  res2.2.conv3.norm.num_batches_tracked
  stem.conv1.norm.num_batches_tracked
  stem.conv2.norm.num_batches_tracked
  stem.conv3.norm.num_batches_tracked
  stem.fc.{bias, weight}
[12/10 02:21:48 d2.engine.train_loop]: Starting training from iteration 0
/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:481: UserWarning: This DataLoader will create 10 worker processes in total. Our suggested max number of worker in current system is 8, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.
  cpuset_checked))
[12/10 02:21:58 d2.utils.events]:  eta: 1:09:03  iter: 19  total_loss: 5.858  loss_sem_seg: 3.684  loss_center: 0.6505  loss_offset: 1.47  time: 0.4164  data_time: 0.0627  lr: 4.9867e-05  max_mem: 9415M
[12/10 02:22:06 d2.utils.events]:  eta: 1:09:34  iter: 39  total_loss: 6.438  loss_sem_seg: 3.901  loss_center: 0.8329  loss_offset: 1.623  time: 0.4206  data_time: 0.0267  lr: 9.9552e-05  max_mem: 9415M
[12/10 02:22:15 d2.utils.events]:  eta: 1:09:20  iter: 59  total_loss: 5.899  loss_sem_seg: 3.546  loss_center: 0.7824  loss_offset: 1.434  time: 0.4211  data_time: 0.0250  lr: 0.00014906  max_mem: 9415M
[12/10 02:22:23 d2.utils.events]:  eta: 1:09:16  iter: 79  total_loss: 5.907  loss_sem_seg: 3.628  loss_center: 0.7345  loss_offset: 1.558  time: 0.4207  data_time: 0.0266  lr: 0.00019838  max_mem: 9415M
[12/10 02:22:31 d2.utils.events]:  eta: 1:09:12  iter: 99  total_loss: 5.556  loss_sem_seg: 3.394  loss_center: 0.6124  loss_offset: 1.589  time: 0.4206  data_time: 0.0259  lr: 0.00024753  max_mem: 9415M
[12/10 02:22:40 d2.utils.events]:  eta: 1:09:03  iter: 119  total_loss: 5.663  loss_sem_seg: 3.478  loss_center: 0.6594  loss_offset: 1.508  time: 0.4204  data_time: 0.0253  lr: 0.00029649  max_mem: 9415M
[12/10 02:22:48 d2.utils.events]:  eta: 1:08:57  iter: 139  total_loss: 5.49  loss_sem_seg: 3.333  loss_center: 0.8129  loss_offset: 1.338  time: 0.4206  data_time: 0.0283  lr: 0.00034528  max_mem: 9415M
[12/10 02:22:57 d2.utils.events]:  eta: 1:08:46  iter: 159  total_loss: 5.522  loss_sem_seg: 2.96  loss_center: 0.6928  loss_offset: 1.699  time: 0.4200  data_time: 0.0257  lr: 0.00039388  max_mem: 9415M
[12/10 02:23:05 d2.utils.events]:  eta: 1:08:40  iter: 179  total_loss: 5.099  loss_sem_seg: 2.871  loss_center: 0.6942  loss_offset: 1.486  time: 0.4203  data_time: 0.0263  lr: 0.0004423  max_mem: 9415M
[12/10 02:23:13 d2.utils.events]:  eta: 1:08:38  iter: 199  total_loss: 5.173  loss_sem_seg: 3.005  loss_center: 0.6062  loss_offset: 1.34  time: 0.4208  data_time: 0.0284  lr: 0.00049055  max_mem: 9415M
[12/10 02:23:22 d2.utils.events]:  eta: 1:08:28  iter: 219  total_loss: 4.852  loss_sem_seg: 2.741  loss_center: 0.655  loss_offset: 1.466  time: 0.4206  data_time: 0.0272  lr: 0.00053861  max_mem: 9415M
[12/10 02:23:30 d2.utils.events]:  eta: 1:08:18  iter: 239  total_loss: 4.661  loss_sem_seg: 2.56  loss_center: 0.9188  loss_offset: 1.201  time: 0.4204  data_time: 0.0249  lr: 0.00058649  max_mem: 9415M
[12/10 02:23:39 d2.utils.events]:  eta: 1:08:10  iter: 259  total_loss: 4.715  loss_sem_seg: 2.526  loss_center: 0.7472  loss_offset: 1.248  time: 0.4202  data_time: 0.0262  lr: 0.0006342  max_mem: 9415M
[12/10 02:23:47 d2.utils.events]:  eta: 1:07:59  iter: 279  total_loss: 4.991  loss_sem_seg: 2.721  loss_center: 0.8175  loss_offset: 1.296  time: 0.4200  data_time: 0.0260  lr: 0.00068172  max_mem: 9415M
[12/10 02:23:55 d2.utils.events]:  eta: 1:07:50  iter: 299  total_loss: 4.893  loss_sem_seg: 2.789  loss_center: 0.5063  loss_offset: 1.391  time: 0.4200  data_time: 0.0265  lr: 0.00072906  max_mem: 9415M
[12/10 02:24:04 d2.utils.events]:  eta: 1:07:42  iter: 319  total_loss: 4.812  loss_sem_seg: 2.843  loss_center: 0.8453  loss_offset: 1.181  time: 0.4201  data_time: 0.0271  lr: 0.00077622  max_mem: 9415M
[12/10 02:24:12 d2.utils.events]:  eta: 1:07:33  iter: 339  total_loss: 4.619  loss_sem_seg: 2.729  loss_center: 0.6027  loss_offset: 1.208  time: 0.4204  data_time: 0.0276  lr: 0.0008232  max_mem: 9415M
[12/10 02:24:21 d2.utils.events]:  eta: 1:07:25  iter: 359  total_loss: 4.532  loss_sem_seg: 2.507  loss_center: 0.767  loss_offset: 1.099  time: 0.4205  data_time: 0.0277  lr: 0.00087  max_mem: 9415M
[12/10 02:24:29 d2.utils.events]:  eta: 1:07:17  iter: 379  total_loss: 4.682  loss_sem_seg: 2.645  loss_center: 0.7526  loss_offset: 1.256  time: 0.4207  data_time: 0.0278  lr: 0.00091662  max_mem: 9415M
[12/10 02:24:38 d2.utils.events]:  eta: 1:07:09  iter: 399  total_loss: 4.96  loss_sem_seg: 2.674  loss_center: 0.846  loss_offset: 1.274  time: 0.4207  data_time: 0.0265  lr: 0.00096306  max_mem: 9415M
[12/10 02:24:46 d2.utils.events]:  eta: 1:07:02  iter: 419  total_loss: 4.962  loss_sem_seg: 2.709  loss_center: 0.9323  loss_offset: 1.266  time: 0.4208  data_time: 0.0270  lr: 0.0010093  max_mem: 9415M
[12/10 02:24:55 d2.utils.events]:  eta: 1:06:52  iter: 439  total_loss: 5.648  loss_sem_seg: 2.931  loss_center: 1.124  loss_offset: 1.509  time: 0.4206  data_time: 0.0260  lr: 0.0010554  max_mem: 9415M
[12/10 02:25:03 d2.utils.events]:  eta: 1:06:43  iter: 459  total_loss: 6.005  loss_sem_seg: 2.697  loss_center: 1.506  loss_offset: 1.35  time: 0.4205  data_time: 0.0258  lr: 0.0011013  max_mem: 9415M
[12/10 02:25:11 d2.utils.events]:  eta: 1:06:35  iter: 479  total_loss: 4.955  loss_sem_seg: 2.496  loss_center: 0.9222  loss_offset: 1.3  time: 0.4205  data_time: 0.0276  lr: 0.001147  max_mem: 9415M
[12/10 02:25:20 d2.utils.events]:  eta: 1:06:27  iter: 499  total_loss: 4.433  loss_sem_seg: 2.375  loss_center: 0.7581  loss_offset: 1.306  time: 0.4204  data_time: 0.0263  lr: 0.0011925  max_mem: 9415M
[12/10 02:25:28 d2.utils.events]:  eta: 1:06:18  iter: 519  total_loss: 4.76  loss_sem_seg: 2.726  loss_center: 0.8124  loss_offset: 1.372  time: 0.4203  data_time: 0.0257  lr: 0.0012379  max_mem: 9415M
[12/10 02:25:37 d2.utils.events]:  eta: 1:06:10  iter: 539  total_loss: 4.99  loss_sem_seg: 2.791  loss_center: 0.7703  loss_offset: 1.292  time: 0.4203  data_time: 0.0256  lr: 0.001283  max_mem: 9415M
[12/10 02:25:45 d2.utils.events]:  eta: 1:06:02  iter: 559  total_loss: 4.896  loss_sem_seg: 2.871  loss_center: 0.665  loss_offset: 1.378  time: 0.4205  data_time: 0.0271  lr: 0.001328  max_mem: 9415M
[12/10 02:25:53 d2.utils.events]:  eta: 1:05:53  iter: 579  total_loss: 4.547  loss_sem_seg: 2.628  loss_center: 0.5671  loss_offset: 1.37  time: 0.4205  data_time: 0.0263  lr: 0.0013728  max_mem: 9415M
[12/10 02:26:02 d2.utils.events]:  eta: 1:05:45  iter: 599  total_loss: 5.06  loss_sem_seg: 2.718  loss_center: 0.9038  loss_offset: 1.315  time: 0.4205  data_time: 0.0261  lr: 0.0014175  max_mem: 9415M
[12/10 02:26:10 d2.utils.events]:  eta: 1:05:36  iter: 619  total_loss: 4.643  loss_sem_seg: 2.601  loss_center: 0.7068  loss_offset: 1.306  time: 0.4204  data_time: 0.0262  lr: 0.0014619  max_mem: 9415M
[12/10 02:26:19 d2.utils.events]:  eta: 1:05:27  iter: 639  total_loss: 4.737  loss_sem_seg: 2.58  loss_center: 0.789  loss_offset: 1.23  time: 0.4203  data_time: 0.0266  lr: 0.0015062  max_mem: 9415M
[12/10 02:26:27 d2.utils.events]:  eta: 1:05:18  iter: 659  total_loss: 4.637  loss_sem_seg: 2.277  loss_center: 0.9659  loss_offset: 1.169  time: 0.4203  data_time: 0.0257  lr: 0.0015503  max_mem: 9415M
[12/10 02:26:35 d2.utils.events]:  eta: 1:05:09  iter: 679  total_loss: 4.578  loss_sem_seg: 2.58  loss_center: 0.6708  loss_offset: 1.163  time: 0.4202  data_time: 0.0258  lr: 0.0015942  max_mem: 9415M
[12/10 02:26:44 d2.utils.events]:  eta: 1:04:59  iter: 699  total_loss: 4.611  loss_sem_seg: 2.509  loss_center: 0.7228  loss_offset: 1.183  time: 0.4201  data_time: 0.0248  lr: 0.0016379  max_mem: 9415M
[12/10 02:26:52 d2.utils.events]:  eta: 1:04:51  iter: 719  total_loss: 4.507  loss_sem_seg: 2.484  loss_center: 0.6886  loss_offset: 1.197  time: 0.4201  data_time: 0.0273  lr: 0.0016814  max_mem: 9415M
[12/10 02:27:00 d2.utils.events]:  eta: 1:04:42  iter: 739  total_loss: 4.548  loss_sem_seg: 2.494  loss_center: 0.6109  loss_offset: 1.243  time: 0.4200  data_time: 0.0256  lr: 0.0017248  max_mem: 9415M
[12/10 02:27:09 d2.utils.events]:  eta: 1:04:32  iter: 759  total_loss: 4.465  loss_sem_seg: 2.5  loss_center: 0.6562  loss_offset: 1.252  time: 0.4200  data_time: 0.0263  lr: 0.0017679  max_mem: 9415M
[12/10 02:27:17 d2.utils.events]:  eta: 1:04:23  iter: 779  total_loss: 4.384  loss_sem_seg: 2.354  loss_center: 0.7572  loss_offset: 1.075  time: 0.4199  data_time: 0.0267  lr: 0.0018109  max_mem: 9415M
[12/10 02:27:26 d2.utils.events]:  eta: 1:04:13  iter: 799  total_loss: 4.312  loss_sem_seg: 2.187  loss_center: 0.8911  loss_offset: 1.192  time: 0.4198  data_time: 0.0248  lr: 0.0018537  max_mem: 9415M
[12/10 02:27:34 d2.utils.events]:  eta: 1:04:03  iter: 819  total_loss: 4.654  loss_sem_seg: 2.465  loss_center: 0.7065  loss_offset: 1.298  time: 0.4197  data_time: 0.0239  lr: 0.0018964  max_mem: 9415M
[12/10 02:27:42 d2.utils.events]:  eta: 1:03:55  iter: 839  total_loss: 4.453  loss_sem_seg: 2.58  loss_center: 0.6236  loss_offset: 1.258  time: 0.4197  data_time: 0.0247  lr: 0.0019388  max_mem: 9415M
[12/10 02:27:51 d2.utils.events]:  eta: 1:03:48  iter: 859  total_loss: 4.7  loss_sem_seg: 2.654  loss_center: 0.6993  loss_offset: 1.284  time: 0.4197  data_time: 0.0271  lr: 0.0019811  max_mem: 9415M
[12/10 02:27:59 d2.utils.events]:  eta: 1:03:39  iter: 879  total_loss: 4.56  loss_sem_seg: 2.613  loss_center: 0.8471  loss_offset: 1.164  time: 0.4197  data_time: 0.0249  lr: 0.0020231  max_mem: 9415M
[12/10 02:28:07 d2.utils.events]:  eta: 1:03:30  iter: 899  total_loss: 4.509  loss_sem_seg: 2.296  loss_center: 0.7815  loss_offset: 1.219  time: 0.4196  data_time: 0.0252  lr: 0.002065  max_mem: 9415M
[12/10 02:28:16 d2.utils.events]:  eta: 1:03:19  iter: 919  total_loss: 4.379  loss_sem_seg: 2.529  loss_center: 0.6023  loss_offset: 1.256  time: 0.4196  data_time: 0.0258  lr: 0.0021068  max_mem: 9415M
[12/10 02:28:24 d2.utils.events]:  eta: 1:03:11  iter: 939  total_loss: 4.321  loss_sem_seg: 2.455  loss_center: 0.7091  loss_offset: 1.215  time: 0.4196  data_time: 0.0269  lr: 0.0021483  max_mem: 9415M
[12/10 02:28:33 d2.utils.events]:  eta: 1:03:02  iter: 959  total_loss: 4.684  loss_sem_seg: 2.486  loss_center: 0.8633  loss_offset: 1.238  time: 0.4196  data_time: 0.0264  lr: 0.0021896  max_mem: 9415M
[12/10 02:28:41 d2.utils.events]:  eta: 1:02:54  iter: 979  total_loss: 4.422  loss_sem_seg: 2.494  loss_center: 0.6409  loss_offset: 1.235  time: 0.4196  data_time: 0.0256  lr: 0.0022308  max_mem: 9415M
[12/10 02:28:49 d2.utils.events]:  eta: 1:02:44  iter: 999  total_loss: 4.137  loss_sem_seg: 2.193  loss_center: 0.6617  loss_offset: 1.225  time: 0.4195  data_time: 0.0258  lr: 0.0022718  max_mem: 9415M
[12/10 02:28:58 d2.utils.events]:  eta: 1:02:35  iter: 1019  total_loss: 4.369  loss_sem_seg: 2.499  loss_center: 0.6694  loss_offset: 1.31  time: 0.4195  data_time: 0.0240  lr: 0.0022695  max_mem: 9415M
[12/10 02:29:06 d2.utils.events]:  eta: 1:02:26  iter: 1039  total_loss: 4.261  loss_sem_seg: 2.393  loss_center: 0.7476  loss_offset: 1.174  time: 0.4195  data_time: 0.0255  lr: 0.002265  max_mem: 9415M
[12/10 02:29:14 d2.utils.events]:  eta: 1:02:18  iter: 1059  total_loss: 4.517  loss_sem_seg: 2.477  loss_center: 0.6658  loss_offset: 1.263  time: 0.4195  data_time: 0.0258  lr: 0.0022604  max_mem: 9415M
[12/10 02:29:23 d2.utils.events]:  eta: 1:02:08  iter: 1079  total_loss: 4.099  loss_sem_seg: 2.346  loss_center: 0.6917  loss_offset: 1.279  time: 0.4194  data_time: 0.0254  lr: 0.0022559  max_mem: 9415M
[12/10 02:29:31 d2.utils.events]:  eta: 1:01:58  iter: 1099  total_loss: 4.416  loss_sem_seg: 2.293  loss_center: 0.8101  loss_offset: 1.249  time: 0.4193  data_time: 0.0240  lr: 0.0022513  max_mem: 9415M
[12/10 02:29:40 d2.utils.events]:  eta: 1:01:50  iter: 1119  total_loss: 4.377  loss_sem_seg: 2.412  loss_center: 0.6516  loss_offset: 1.294  time: 0.4193  data_time: 0.0247  lr: 0.0022468  max_mem: 9415M
[12/10 02:29:48 d2.utils.events]:  eta: 1:01:41  iter: 1139  total_loss: 4.344  loss_sem_seg: 2.556  loss_center: 0.5736  loss_offset: 1.28  time: 0.4193  data_time: 0.0257  lr: 0.0022422  max_mem: 9415M
[12/10 02:29:56 d2.utils.events]:  eta: 1:01:32  iter: 1159  total_loss: 4.287  loss_sem_seg: 2.348  loss_center: 0.7342  loss_offset: 1.132  time: 0.4193  data_time: 0.0255  lr: 0.0022376  max_mem: 9415M
[12/10 02:30:05 d2.utils.events]:  eta: 1:01:24  iter: 1179  total_loss: 4.332  loss_sem_seg: 2.245  loss_center: 0.7576  loss_offset: 1.232  time: 0.4193  data_time: 0.0254  lr: 0.0022331  max_mem: 9415M
[12/10 02:30:13 d2.utils.events]:  eta: 1:01:14  iter: 1199  total_loss: 3.934  loss_sem_seg: 2.259  loss_center: 0.5949  loss_offset: 1.147  time: 0.4192  data_time: 0.0260  lr: 0.0022285  max_mem: 9415M
[12/10 02:30:21 d2.utils.events]:  eta: 1:01:06  iter: 1219  total_loss: 4.451  loss_sem_seg: 2.489  loss_center: 0.7767  loss_offset: 1.22  time: 0.4192  data_time: 0.0257  lr: 0.002224  max_mem: 9415M
[12/10 02:30:30 d2.utils.events]:  eta: 1:00:58  iter: 1239  total_loss: 4.479  loss_sem_seg: 2.364  loss_center: 0.7614  loss_offset: 1.188  time: 0.4192  data_time: 0.0260  lr: 0.0022194  max_mem: 9415M
[12/10 02:30:38 d2.utils.events]:  eta: 1:00:50  iter: 1259  total_loss: 4.274  loss_sem_seg: 2.276  loss_center: 0.7787  loss_offset: 1.12  time: 0.4193  data_time: 0.0269  lr: 0.0022149  max_mem: 9415M
[12/10 02:30:47 d2.utils.events]:  eta: 1:00:41  iter: 1279  total_loss: 4.006  loss_sem_seg: 2.159  loss_center: 0.6056  loss_offset: 1.136  time: 0.4192  data_time: 0.0243  lr: 0.0022103  max_mem: 9415M
[12/10 02:30:55 d2.utils.events]:  eta: 1:00:32  iter: 1299  total_loss: 4.43  loss_sem_seg: 2.529  loss_center: 0.7551  loss_offset: 1.147  time: 0.4192  data_time: 0.0260  lr: 0.0022057  max_mem: 9415M
[12/10 02:31:03 d2.utils.events]:  eta: 1:00:23  iter: 1319  total_loss: 4.445  loss_sem_seg: 2.39  loss_center: 0.8369  loss_offset: 1.236  time: 0.4191  data_time: 0.0254  lr: 0.0022012  max_mem: 9415M
[12/10 02:31:12 d2.utils.events]:  eta: 1:00:15  iter: 1339  total_loss: 4.076  loss_sem_seg: 2.316  loss_center: 0.8117  loss_offset: 1.104  time: 0.4191  data_time: 0.0272  lr: 0.0021966  max_mem: 9415M
[12/10 02:31:20 d2.utils.events]:  eta: 1:00:06  iter: 1359  total_loss: 4.271  loss_sem_seg: 2.302  loss_center: 0.7286  loss_offset: 1.218  time: 0.4191  data_time: 0.0264  lr: 0.002192  max_mem: 9415M
[12/10 02:31:28 d2.utils.events]:  eta: 0:59:57  iter: 1379  total_loss: 4.105  loss_sem_seg: 2.251  loss_center: 0.7201  loss_offset: 1.259  time: 0.4191  data_time: 0.0253  lr: 0.0021875  max_mem: 9415M
[12/10 02:31:37 d2.utils.events]:  eta: 0:59:48  iter: 1399  total_loss: 4.265  loss_sem_seg: 2.223  loss_center: 0.9034  loss_offset: 1.159  time: 0.4191  data_time: 0.0256  lr: 0.0021829  max_mem: 9415M
[12/10 02:31:45 d2.utils.events]:  eta: 0:59:39  iter: 1419  total_loss: 4.246  loss_sem_seg: 2.282  loss_center: 0.7476  loss_offset: 1.136  time: 0.4190  data_time: 0.0258  lr: 0.0021783  max_mem: 9415M
[12/10 02:31:53 d2.utils.events]:  eta: 0:59:30  iter: 1439  total_loss: 3.967  loss_sem_seg: 2.257  loss_center: 0.7069  loss_offset: 1.103  time: 0.4190  data_time: 0.0260  lr: 0.0021738  max_mem: 9415M
[12/10 02:32:02 d2.utils.events]:  eta: 0:59:22  iter: 1459  total_loss: 4.208  loss_sem_seg: 2.134  loss_center: 0.631  loss_offset: 1.093  time: 0.4190  data_time: 0.0241  lr: 0.0021692  max_mem: 9415M
[12/10 02:32:10 d2.utils.events]:  eta: 0:59:13  iter: 1479  total_loss: 3.842  loss_sem_seg: 2.002  loss_center: 0.8631  loss_offset: 1.089  time: 0.4189  data_time: 0.0254  lr: 0.0021646  max_mem: 9415M
[12/10 02:32:18 d2.utils.events]:  eta: 0:59:04  iter: 1499  total_loss: 3.922  loss_sem_seg: 2.094  loss_center: 0.6542  loss_offset: 1.091  time: 0.4189  data_time: 0.0244  lr: 0.00216  max_mem: 9415M
[12/10 02:32:27 d2.utils.events]:  eta: 0:58:54  iter: 1519  total_loss: 3.886  loss_sem_seg: 2.075  loss_center: 0.5157  loss_offset: 1.162  time: 0.4189  data_time: 0.0251  lr: 0.0021555  max_mem: 9415M
[12/10 02:32:35 d2.utils.events]:  eta: 0:58:45  iter: 1539  total_loss: 3.958  loss_sem_seg: 2.157  loss_center: 0.6805  loss_offset: 1.164  time: 0.4189  data_time: 0.0246  lr: 0.0021509  max_mem: 9415M
[12/10 02:32:44 d2.utils.events]:  eta: 0:58:36  iter: 1559  total_loss: 3.976  loss_sem_seg: 2.149  loss_center: 0.6504  loss_offset: 1.103  time: 0.4188  data_time: 0.0260  lr: 0.0021463  max_mem: 9415M
[12/10 02:32:52 d2.utils.events]:  eta: 0:58:26  iter: 1579  total_loss: 4.194  loss_sem_seg: 2.196  loss_center: 0.8113  loss_offset: 1.151  time: 0.4188  data_time: 0.0247  lr: 0.0021417  max_mem: 9415M
[12/10 02:33:00 d2.utils.events]:  eta: 0:58:17  iter: 1599  total_loss: 4.574  loss_sem_seg: 2.351  loss_center: 0.8201  loss_offset: 1.144  time: 0.4188  data_time: 0.0262  lr: 0.0021372  max_mem: 9415M
[12/10 02:33:09 d2.utils.events]:  eta: 0:58:09  iter: 1619  total_loss: 4.08  loss_sem_seg: 2.145  loss_center: 0.6498  loss_offset: 1.158  time: 0.4188  data_time: 0.0246  lr: 0.0021326  max_mem: 9415M
[12/10 02:33:17 d2.utils.events]:  eta: 0:58:02  iter: 1639  total_loss: 3.774  loss_sem_seg: 2.169  loss_center: 0.5614  loss_offset: 1.064  time: 0.4188  data_time: 0.0261  lr: 0.002128  max_mem: 9415M
[12/10 02:33:25 d2.utils.events]:  eta: 0:57:54  iter: 1659  total_loss: 3.955  loss_sem_seg: 1.976  loss_center: 0.7167  loss_offset: 1.099  time: 0.4188  data_time: 0.0261  lr: 0.0021234  max_mem: 9415M
[12/10 02:33:34 d2.utils.events]:  eta: 0:57:46  iter: 1679  total_loss: 4.144  loss_sem_seg: 2.388  loss_center: 0.6719  loss_offset: 1.083  time: 0.4188  data_time: 0.0252  lr: 0.0021188  max_mem: 9415M
[12/10 02:33:42 d2.utils.events]:  eta: 0:57:38  iter: 1699  total_loss: 4.087  loss_sem_seg: 1.961  loss_center: 0.7475  loss_offset: 1.087  time: 0.4187  data_time: 0.0250  lr: 0.0021143  max_mem: 9415M
[12/10 02:33:50 d2.utils.events]:  eta: 0:57:30  iter: 1719  total_loss: 3.914  loss_sem_seg: 2.003  loss_center: 0.6719  loss_offset: 1.119  time: 0.4187  data_time: 0.0252  lr: 0.0021097  max_mem: 9415M
[12/10 02:33:59 d2.utils.events]:  eta: 0:57:22  iter: 1739  total_loss: 3.973  loss_sem_seg: 2.212  loss_center: 0.6901  loss_offset: 1.145  time: 0.4187  data_time: 0.0253  lr: 0.0021051  max_mem: 9415M
[12/10 02:34:07 d2.utils.events]:  eta: 0:57:13  iter: 1759  total_loss: 4.153  loss_sem_seg: 2.079  loss_center: 0.7464  loss_offset: 1.169  time: 0.4187  data_time: 0.0253  lr: 0.0021005  max_mem: 9415M
[12/10 02:34:16 d2.utils.events]:  eta: 0:57:05  iter: 1779  total_loss: 4.151  loss_sem_seg: 2.268  loss_center: 0.6329  loss_offset: 0.9932  time: 0.4187  data_time: 0.0262  lr: 0.0020959  max_mem: 9415M
[12/10 02:34:24 d2.utils.events]:  eta: 0:56:58  iter: 1799  total_loss: 4.183  loss_sem_seg: 2.274  loss_center: 0.5687  loss_offset: 1.15  time: 0.4187  data_time: 0.0255  lr: 0.0020913  max_mem: 9415M
[12/10 02:34:32 d2.utils.events]:  eta: 0:56:52  iter: 1819  total_loss: 4.205  loss_sem_seg: 2.338  loss_center: 0.711  loss_offset: 1.153  time: 0.4187  data_time: 0.0265  lr: 0.0020867  max_mem: 9415M
[12/10 02:34:41 d2.utils.events]:  eta: 0:56:42  iter: 1839  total_loss: 4.326  loss_sem_seg: 2.286  loss_center: 0.812  loss_offset: 1.072  time: 0.4187  data_time: 0.0257  lr: 0.0020821  max_mem: 9415M
[12/10 02:34:49 d2.utils.events]:  eta: 0:56:32  iter: 1859  total_loss: 3.82  loss_sem_seg: 2.009  loss_center: 0.6756  loss_offset: 1.098  time: 0.4187  data_time: 0.0259  lr: 0.0020775  max_mem: 9415M
[12/10 02:34:57 d2.utils.events]:  eta: 0:56:23  iter: 1879  total_loss: 3.985  loss_sem_seg: 2.069  loss_center: 0.7238  loss_offset: 1.109  time: 0.4186  data_time: 0.0250  lr: 0.0020729  max_mem: 9415M
[12/10 02:35:06 d2.utils.events]:  eta: 0:56:14  iter: 1899  total_loss: 4.279  loss_sem_seg: 2.007  loss_center: 0.8159  loss_offset: 1.114  time: 0.4186  data_time: 0.0248  lr: 0.0020684  max_mem: 9415M
[12/10 02:35:14 d2.utils.events]:  eta: 0:56:05  iter: 1919  total_loss: 4.239  loss_sem_seg: 2.28  loss_center: 0.761  loss_offset: 1.179  time: 0.4186  data_time: 0.0261  lr: 0.0020638  max_mem: 9415M
[12/10 02:35:22 d2.utils.events]:  eta: 0:55:58  iter: 1939  total_loss: 3.977  loss_sem_seg: 2.169  loss_center: 0.7082  loss_offset: 1.106  time: 0.4186  data_time: 0.0242  lr: 0.0020592  max_mem: 9415M
[12/10 02:35:31 d2.utils.events]:  eta: 0:55:50  iter: 1959  total_loss: 4.061  loss_sem_seg: 2.126  loss_center: 0.7609  loss_offset: 1.12  time: 0.4186  data_time: 0.0277  lr: 0.0020546  max_mem: 9415M
[12/10 02:35:39 d2.utils.events]:  eta: 0:55:42  iter: 1979  total_loss: 3.865  loss_sem_seg: 2.017  loss_center: 0.7772  loss_offset: 1.06  time: 0.4186  data_time: 0.0260  lr: 0.00205  max_mem: 9415M
[12/10 02:35:48 d2.utils.events]:  eta: 0:55:34  iter: 1999  total_loss: 4.051  loss_sem_seg: 2.03  loss_center: 0.7026  loss_offset: 1.167  time: 0.4186  data_time: 0.0238  lr: 0.0020454  max_mem: 9415M
[12/10 02:35:56 d2.utils.events]:  eta: 0:55:26  iter: 2019  total_loss: 4.011  loss_sem_seg: 2.057  loss_center: 0.8667  loss_offset: 1.095  time: 0.4185  data_time: 0.0259  lr: 0.0020408  max_mem: 9415M
[12/10 02:36:04 d2.utils.events]:  eta: 0:55:17  iter: 2039  total_loss: 4.077  loss_sem_seg: 2.234  loss_center: 0.8924  loss_offset: 1.125  time: 0.4185  data_time: 0.0254  lr: 0.0020362  max_mem: 9415M
[12/10 02:36:13 d2.utils.events]:  eta: 0:55:09  iter: 2059  total_loss: 3.886  loss_sem_seg: 2.185  loss_center: 0.7038  loss_offset: 1.053  time: 0.4185  data_time: 0.0266  lr: 0.0020316  max_mem: 9415M
[12/10 02:36:21 d2.utils.events]:  eta: 0:55:01  iter: 2079  total_loss: 3.92  loss_sem_seg: 2.06  loss_center: 0.7528  loss_offset: 1.112  time: 0.4185  data_time: 0.0250  lr: 0.0020269  max_mem: 9415M
[12/10 02:36:29 d2.utils.events]:  eta: 0:54:53  iter: 2099  total_loss: 4.131  loss_sem_seg: 2.198  loss_center: 0.6755  loss_offset: 1.062  time: 0.4185  data_time: 0.0267  lr: 0.0020223  max_mem: 9415M
[12/10 02:36:38 d2.utils.events]:  eta: 0:54:44  iter: 2119  total_loss: 4.151  loss_sem_seg: 2.225  loss_center: 0.661  loss_offset: 1.093  time: 0.4185  data_time: 0.0257  lr: 0.0020177  max_mem: 9415M
[12/10 02:36:46 d2.utils.events]:  eta: 0:54:38  iter: 2139  total_loss: 4.302  loss_sem_seg: 2.335  loss_center: 0.6053  loss_offset: 1.117  time: 0.4186  data_time: 0.0286  lr: 0.0020131  max_mem: 9415M
[12/10 02:36:55 d2.utils.events]:  eta: 0:54:29  iter: 2159  total_loss: 4.039  loss_sem_seg: 2.037  loss_center: 0.8959  loss_offset: 1.096  time: 0.4186  data_time: 0.0252  lr: 0.0020085  max_mem: 9415M
[12/10 02:37:03 d2.utils.events]:  eta: 0:54:20  iter: 2179  total_loss: 3.957  loss_sem_seg: 2.027  loss_center: 0.8558  loss_offset: 0.9852  time: 0.4185  data_time: 0.0245  lr: 0.0020039  max_mem: 9415M
[12/10 02:37:11 d2.utils.events]:  eta: 0:54:11  iter: 2199  total_loss: 3.99  loss_sem_seg: 2.108  loss_center: 0.8388  loss_offset: 1.152  time: 0.4185  data_time: 0.0245  lr: 0.0019993  max_mem: 9415M
[12/10 02:37:20 d2.utils.events]:  eta: 0:54:02  iter: 2219  total_loss: 4.002  loss_sem_seg: 2.163  loss_center: 0.7447  loss_offset: 1.018  time: 0.4185  data_time: 0.0270  lr: 0.0019947  max_mem: 9415M
[12/10 02:37:28 d2.utils.events]:  eta: 0:53:54  iter: 2239  total_loss: 4.036  loss_sem_seg: 2.07  loss_center: 0.6945  loss_offset: 1.139  time: 0.4186  data_time: 0.0273  lr: 0.0019901  max_mem: 9415M
[12/10 02:37:37 d2.utils.events]:  eta: 0:53:45  iter: 2259  total_loss: 3.82  loss_sem_seg: 2.06  loss_center: 0.5545  loss_offset: 1.092  time: 0.4186  data_time: 0.0256  lr: 0.0019854  max_mem: 9415M
[12/10 02:37:45 d2.utils.events]:  eta: 0:53:37  iter: 2279  total_loss: 3.768  loss_sem_seg: 1.973  loss_center: 0.7077  loss_offset: 1.085  time: 0.4185  data_time: 0.0246  lr: 0.0019808  max_mem: 9415M
[12/10 02:37:53 d2.utils.events]:  eta: 0:53:28  iter: 2299  total_loss: 3.704  loss_sem_seg: 1.825  loss_center: 0.6945  loss_offset: 1.075  time: 0.4185  data_time: 0.0264  lr: 0.0019762  max_mem: 9415M
[12/10 02:38:02 d2.utils.events]:  eta: 0:53:20  iter: 2319  total_loss: 3.864  loss_sem_seg: 2.132  loss_center: 0.6431  loss_offset: 1.031  time: 0.4186  data_time: 0.0257  lr: 0.0019716  max_mem: 9415M
[12/10 02:38:10 d2.utils.events]:  eta: 0:53:12  iter: 2339  total_loss: 4.325  loss_sem_seg: 2.515  loss_center: 0.7003  loss_offset: 1.153  time: 0.4186  data_time: 0.0249  lr: 0.001967  max_mem: 9415M
[12/10 02:38:18 d2.utils.events]:  eta: 0:53:04  iter: 2359  total_loss: 3.678  loss_sem_seg: 2.105  loss_center: 0.6996  loss_offset: 1.08  time: 0.4186  data_time: 0.0252  lr: 0.0019623  max_mem: 9415M
[12/10 02:38:27 d2.utils.events]:  eta: 0:52:57  iter: 2379  total_loss: 4.092  loss_sem_seg: 2.163  loss_center: 0.6476  loss_offset: 1.195  time: 0.4186  data_time: 0.0253  lr: 0.0019577  max_mem: 9415M
[12/10 02:38:35 d2.utils.events]:  eta: 0:52:48  iter: 2399  total_loss: 3.908  loss_sem_seg: 2.039  loss_center: 0.8243  loss_offset: 1.047  time: 0.4186  data_time: 0.0258  lr: 0.0019531  max_mem: 9415M
[12/10 02:38:44 d2.utils.events]:  eta: 0:52:41  iter: 2419  total_loss: 3.831  loss_sem_seg: 2.163  loss_center: 0.6175  loss_offset: 1.042  time: 0.4186  data_time: 0.0267  lr: 0.0019485  max_mem: 9415M
[12/10 02:38:52 d2.utils.events]:  eta: 0:52:34  iter: 2439  total_loss: 3.756  loss_sem_seg: 1.951  loss_center: 0.7197  loss_offset: 1.034  time: 0.4186  data_time: 0.0260  lr: 0.0019438  max_mem: 9415M
[12/10 02:39:00 d2.utils.events]:  eta: 0:52:24  iter: 2459  total_loss: 3.877  loss_sem_seg: 1.915  loss_center: 0.7145  loss_offset: 1.115  time: 0.4186  data_time: 0.0253  lr: 0.0019392  max_mem: 9415M
[12/10 02:39:09 d2.utils.events]:  eta: 0:52:16  iter: 2479  total_loss: 3.814  loss_sem_seg: 2.21  loss_center: 0.7419  loss_offset: 1.012  time: 0.4186  data_time: 0.0274  lr: 0.0019346  max_mem: 9415M
[12/10 02:39:17 d2.utils.events]:  eta: 0:52:08  iter: 2499  total_loss: 3.85  loss_sem_seg: 1.965  loss_center: 0.6049  loss_offset: 1.054  time: 0.4186  data_time: 0.0258  lr: 0.00193  max_mem: 9415M
[12/10 02:39:26 d2.utils.events]:  eta: 0:52:00  iter: 2519  total_loss: 3.884  loss_sem_seg: 2.139  loss_center: 0.6258  loss_offset: 1.068  time: 0.4186  data_time: 0.0259  lr: 0.0019253  max_mem: 9415M
[12/10 02:39:34 d2.utils.events]:  eta: 0:51:52  iter: 2539  total_loss: 3.887  loss_sem_seg: 2.159  loss_center: 0.6094  loss_offset: 1.085  time: 0.4186  data_time: 0.0243  lr: 0.0019207  max_mem: 9415M
[12/10 02:39:42 d2.utils.events]:  eta: 0:51:43  iter: 2559  total_loss: 3.84  loss_sem_seg: 2.142  loss_center: 0.5788  loss_offset: 1.093  time: 0.4186  data_time: 0.0258  lr: 0.0019161  max_mem: 9415M
[12/10 02:39:51 d2.utils.events]:  eta: 0:51:35  iter: 2579  total_loss: 3.784  loss_sem_seg: 1.947  loss_center: 0.6747  loss_offset: 1.109  time: 0.4186  data_time: 0.0268  lr: 0.0019114  max_mem: 9415M
[12/10 02:39:59 d2.utils.events]:  eta: 0:51:28  iter: 2599  total_loss: 4.108  loss_sem_seg: 2.271  loss_center: 0.6872  loss_offset: 1.131  time: 0.4186  data_time: 0.0256  lr: 0.0019068  max_mem: 9415M
[12/10 02:40:07 d2.utils.events]:  eta: 0:51:20  iter: 2619  total_loss: 3.932  loss_sem_seg: 2.164  loss_center: 0.6491  loss_offset: 1.132  time: 0.4186  data_time: 0.0259  lr: 0.0019021  max_mem: 9415M
[12/10 02:40:16 d2.utils.events]:  eta: 0:51:12  iter: 2639  total_loss: 3.792  loss_sem_seg: 1.872  loss_center: 0.7054  loss_offset: 1.083  time: 0.4186  data_time: 0.0268  lr: 0.0018975  max_mem: 9415M
[12/10 02:40:24 d2.utils.events]:  eta: 0:51:04  iter: 2659  total_loss: 3.907  loss_sem_seg: 2.105  loss_center: 0.6722  loss_offset: 1.096  time: 0.4186  data_time: 0.0257  lr: 0.0018929  max_mem: 9415M
[12/10 02:40:32 d2.utils.events]:  eta: 0:50:55  iter: 2679  total_loss: 3.839  loss_sem_seg: 2.15  loss_center: 0.6657  loss_offset: 1.031  time: 0.4186  data_time: 0.0240  lr: 0.0018882  max_mem: 9415M
[12/10 02:40:41 d2.utils.events]:  eta: 0:50:45  iter: 2699  total_loss: 3.733  loss_sem_seg: 1.94  loss_center: 0.7508  loss_offset: 1.006  time: 0.4186  data_time: 0.0263  lr: 0.0018836  max_mem: 9415M
[12/10 02:40:49 d2.utils.events]:  eta: 0:50:36  iter: 2719  total_loss: 3.632  loss_sem_seg: 1.843  loss_center: 0.7453  loss_offset: 1.049  time: 0.4185  data_time: 0.0253  lr: 0.0018789  max_mem: 9415M
[12/10 02:40:58 d2.utils.events]:  eta: 0:50:27  iter: 2739  total_loss: 3.633  loss_sem_seg: 1.775  loss_center: 0.777  loss_offset: 1.016  time: 0.4185  data_time: 0.0254  lr: 0.0018743  max_mem: 9415M
[12/10 02:41:06 d2.utils.events]:  eta: 0:50:20  iter: 2759  total_loss: 3.921  loss_sem_seg: 2.047  loss_center: 0.5857  loss_offset: 1.158  time: 0.4185  data_time: 0.0266  lr: 0.0018696  max_mem: 9415M
[12/10 02:41:14 d2.utils.events]:  eta: 0:50:11  iter: 2779  total_loss: 3.915  loss_sem_seg: 2.178  loss_center: 0.542  loss_offset: 1.184  time: 0.4185  data_time: 0.0269  lr: 0.001865  max_mem: 9415M
[12/10 02:41:23 d2.utils.events]:  eta: 0:50:02  iter: 2799  total_loss: 3.866  loss_sem_seg: 2.015  loss_center: 0.6154  loss_offset: 1.146  time: 0.4186  data_time: 0.0254  lr: 0.0018603  max_mem: 9415M
[12/10 02:41:31 d2.utils.events]:  eta: 0:49:54  iter: 2819  total_loss: 4.071  loss_sem_seg: 2.103  loss_center: 0.7196  loss_offset: 1.079  time: 0.4185  data_time: 0.0260  lr: 0.0018557  max_mem: 9415M
[12/10 02:41:39 d2.utils.events]:  eta: 0:49:45  iter: 2839  total_loss: 3.815  loss_sem_seg: 2.018  loss_center: 0.6534  loss_offset: 1.024  time: 0.4185  data_time: 0.0237  lr: 0.001851  max_mem: 9415M
[12/10 02:41:48 d2.utils.events]:  eta: 0:49:37  iter: 2859  total_loss: 3.714  loss_sem_seg: 1.874  loss_center: 0.7723  loss_offset: 0.997  time: 0.4185  data_time: 0.0245  lr: 0.0018464  max_mem: 9415M
[12/10 02:41:56 d2.utils.events]:  eta: 0:49:29  iter: 2879  total_loss: 4.172  loss_sem_seg: 2.27  loss_center: 0.6551  loss_offset: 1.085  time: 0.4185  data_time: 0.0265  lr: 0.0018417  max_mem: 9415M
[12/10 02:42:05 d2.utils.events]:  eta: 0:49:23  iter: 2899  total_loss: 3.885  loss_sem_seg: 1.926  loss_center: 0.7546  loss_offset: 1.065  time: 0.4185  data_time: 0.0268  lr: 0.0018371  max_mem: 9415M
[12/10 02:42:13 d2.utils.events]:  eta: 0:49:15  iter: 2919  total_loss: 3.707  loss_sem_seg: 2.12  loss_center: 0.6271  loss_offset: 1.137  time: 0.4185  data_time: 0.0249  lr: 0.0018324  max_mem: 9415M
[12/10 02:42:21 d2.utils.events]:  eta: 0:49:07  iter: 2939  total_loss: 3.854  loss_sem_seg: 1.971  loss_center: 0.6963  loss_offset: 1.05  time: 0.4185  data_time: 0.0246  lr: 0.0018278  max_mem: 9415M
[12/10 02:42:30 d2.utils.events]:  eta: 0:48:57  iter: 2959  total_loss: 4.014  loss_sem_seg: 2.097  loss_center: 0.8084  loss_offset: 1.063  time: 0.4185  data_time: 0.0266  lr: 0.0018231  max_mem: 9415M
[12/10 02:42:38 d2.utils.events]:  eta: 0:48:50  iter: 2979  total_loss: 3.808  loss_sem_seg: 2.107  loss_center: 0.7811  loss_offset: 0.9891  time: 0.4185  data_time: 0.0260  lr: 0.0018184  max_mem: 9415M
[12/10 02:42:46 d2.utils.events]:  eta: 0:48:42  iter: 2999  total_loss: 3.907  loss_sem_seg: 2.057  loss_center: 0.7567  loss_offset: 1.017  time: 0.4185  data_time: 0.0253  lr: 0.0018138  max_mem: 9415M
[12/10 02:42:55 d2.utils.events]:  eta: 0:48:33  iter: 3019  total_loss: 3.995  loss_sem_seg: 2.235  loss_center: 0.6399  loss_offset: 0.948  time: 0.4185  data_time: 0.0260  lr: 0.0018091  max_mem: 9415M
[12/10 02:43:03 d2.utils.events]:  eta: 0:48:26  iter: 3039  total_loss: 3.389  loss_sem_seg: 1.789  loss_center: 0.5656  loss_offset: 0.9588  time: 0.4185  data_time: 0.0272  lr: 0.0018044  max_mem: 9415M
[12/10 02:43:12 d2.utils.events]:  eta: 0:48:17  iter: 3059  total_loss: 3.787  loss_sem_seg: 2.081  loss_center: 0.6451  loss_offset: 0.9276  time: 0.4185  data_time: 0.0236  lr: 0.0017998  max_mem: 9415M
[12/10 02:43:20 d2.utils.events]:  eta: 0:48:09  iter: 3079  total_loss: 4.035  loss_sem_seg: 2.405  loss_center: 0.6338  loss_offset: 1.117  time: 0.4185  data_time: 0.0281  lr: 0.0017951  max_mem: 9415M
[12/10 02:43:28 d2.utils.events]:  eta: 0:48:01  iter: 3099  total_loss: 3.738  loss_sem_seg: 1.839  loss_center: 0.7161  loss_offset: 1.075  time: 0.4185  data_time: 0.0258  lr: 0.0017904  max_mem: 9415M
[12/10 02:43:37 d2.utils.events]:  eta: 0:47:52  iter: 3119  total_loss: 3.881  loss_sem_seg: 2.113  loss_center: 0.7987  loss_offset: 1.014  time: 0.4185  data_time: 0.0248  lr: 0.0017858  max_mem: 9415M
[12/10 02:43:45 d2.utils.events]:  eta: 0:47:43  iter: 3139  total_loss: 3.567  loss_sem_seg: 1.936  loss_center: 0.7019  loss_offset: 1.006  time: 0.4185  data_time: 0.0265  lr: 0.0017811  max_mem: 9415M
[12/10 02:43:53 d2.utils.events]:  eta: 0:47:35  iter: 3159  total_loss: 4.037  loss_sem_seg: 2.113  loss_center: 0.8474  loss_offset: 0.945  time: 0.4185  data_time: 0.0253  lr: 0.0017764  max_mem: 9415M
[12/10 02:44:02 d2.utils.events]:  eta: 0:47:27  iter: 3179  total_loss: 3.731  loss_sem_seg: 1.958  loss_center: 0.72  loss_offset: 1.003  time: 0.4185  data_time: 0.0255  lr: 0.0017718  max_mem: 9415M
[12/10 02:44:10 d2.utils.events]:  eta: 0:47:19  iter: 3199  total_loss: 3.462  loss_sem_seg: 1.797  loss_center: 0.5823  loss_offset: 0.9942  time: 0.4185  data_time: 0.0253  lr: 0.0017671  max_mem: 9415M
[12/10 02:44:18 d2.utils.events]:  eta: 0:47:10  iter: 3219  total_loss: 3.644  loss_sem_seg: 1.996  loss_center: 0.7427  loss_offset: 1.033  time: 0.4184  data_time: 0.0243  lr: 0.0017624  max_mem: 9415M
[12/10 02:44:27 d2.utils.events]:  eta: 0:47:02  iter: 3239  total_loss: 3.919  loss_sem_seg: 2.021  loss_center: 0.7522  loss_offset: 1.02  time: 0.4185  data_time: 0.0266  lr: 0.0017577  max_mem: 9415M
[12/10 02:44:35 d2.utils.events]:  eta: 0:46:54  iter: 3259  total_loss: 3.698  loss_sem_seg: 2.059  loss_center: 0.7736  loss_offset: 1.075  time: 0.4185  data_time: 0.0250  lr: 0.001753  max_mem: 9415M
[12/10 02:44:44 d2.utils.events]:  eta: 0:46:47  iter: 3279  total_loss: 4.103  loss_sem_seg: 2.129  loss_center: 0.7704  loss_offset: 1.05  time: 0.4185  data_time: 0.0252  lr: 0.0017484  max_mem: 9415M
[12/10 02:44:52 d2.utils.events]:  eta: 0:46:39  iter: 3299  total_loss: 3.865  loss_sem_seg: 2.304  loss_center: 0.7299  loss_offset: 0.9601  time: 0.4185  data_time: 0.0258  lr: 0.0017437  max_mem: 9415M
[12/10 02:45:00 d2.utils.events]:  eta: 0:46:30  iter: 3319  total_loss: 3.412  loss_sem_seg: 1.78  loss_center: 0.5115  loss_offset: 0.985  time: 0.4184  data_time: 0.0257  lr: 0.001739  max_mem: 9415M
[12/10 02:45:09 d2.utils.events]:  eta: 0:46:22  iter: 3339  total_loss: 3.599  loss_sem_seg: 1.881  loss_center: 0.5683  loss_offset: 1.044  time: 0.4184  data_time: 0.0270  lr: 0.0017343  max_mem: 9415M
[12/10 02:45:17 d2.utils.events]:  eta: 0:46:14  iter: 3359  total_loss: 3.965  loss_sem_seg: 2.263  loss_center: 0.6452  loss_offset: 1.073  time: 0.4184  data_time: 0.0253  lr: 0.0017296  max_mem: 9415M
[12/10 02:45:25 d2.utils.events]:  eta: 0:46:05  iter: 3379  total_loss: 3.468  loss_sem_seg: 1.793  loss_center: 0.6607  loss_offset: 0.957  time: 0.4184  data_time: 0.0247  lr: 0.0017249  max_mem: 9415M
[12/10 02:45:34 d2.utils.events]:  eta: 0:45:55  iter: 3399  total_loss: 3.856  loss_sem_seg: 1.957  loss_center: 0.9249  loss_offset: 0.9293  time: 0.4184  data_time: 0.0243  lr: 0.0017202  max_mem: 9415M
[12/10 02:45:42 d2.utils.events]:  eta: 0:45:47  iter: 3419  total_loss: 3.985  loss_sem_seg: 2.143  loss_center: 0.6363  loss_offset: 0.9735  time: 0.4184  data_time: 0.0260  lr: 0.0017155  max_mem: 9415M
[12/10 02:45:51 d2.utils.events]:  eta: 0:45:38  iter: 3439  total_loss: 3.544  loss_sem_seg: 1.866  loss_center: 0.6732  loss_offset: 1.032  time: 0.4184  data_time: 0.0253  lr: 0.0017109  max_mem: 9415M
[12/10 02:45:59 d2.utils.events]:  eta: 0:45:30  iter: 3459  total_loss: 3.761  loss_sem_seg: 1.94  loss_center: 0.6146  loss_offset: 1.033  time: 0.4184  data_time: 0.0249  lr: 0.0017062  max_mem: 9415M
[12/10 02:46:07 d2.utils.events]:  eta: 0:45:21  iter: 3479  total_loss: 3.821  loss_sem_seg: 1.993  loss_center: 0.7016  loss_offset: 0.9924  time: 0.4184  data_time: 0.0260  lr: 0.0017015  max_mem: 9415M
[12/10 02:46:16 d2.utils.events]:  eta: 0:45:14  iter: 3499  total_loss: 3.917  loss_sem_seg: 2.079  loss_center: 0.7206  loss_offset: 1.02  time: 0.4184  data_time: 0.0273  lr: 0.0016968  max_mem: 9415M
[12/10 02:46:24 d2.utils.events]:  eta: 0:45:05  iter: 3519  total_loss: 3.713  loss_sem_seg: 1.982  loss_center: 0.5894  loss_offset: 1.023  time: 0.4184  data_time: 0.0267  lr: 0.0016921  max_mem: 9415M
[12/10 02:46:33 d2.utils.events]:  eta: 0:44:57  iter: 3539  total_loss: 3.584  loss_sem_seg: 1.938  loss_center: 0.646  loss_offset: 1.032  time: 0.4184  data_time: 0.0248  lr: 0.0016874  max_mem: 9415M
[12/10 02:46:41 d2.utils.events]:  eta: 0:44:48  iter: 3559  total_loss: 4.06  loss_sem_seg: 1.864  loss_center: 0.6357  loss_offset: 1.06  time: 0.4184  data_time: 0.0245  lr: 0.0016827  max_mem: 9415M
[12/10 02:46:49 d2.utils.events]:  eta: 0:44:40  iter: 3579  total_loss: 3.535  loss_sem_seg: 1.879  loss_center: 0.7671  loss_offset: 0.9862  time: 0.4184  data_time: 0.0254  lr: 0.001678  max_mem: 9415M
[12/10 02:46:58 d2.utils.events]:  eta: 0:44:31  iter: 3599  total_loss: 3.83  loss_sem_seg: 1.923  loss_center: 0.9416  loss_offset: 0.9735  time: 0.4184  data_time: 0.0269  lr: 0.0016733  max_mem: 9415M
[12/10 02:47:06 d2.utils.events]:  eta: 0:44:22  iter: 3619  total_loss: 3.742  loss_sem_seg: 1.984  loss_center: 0.7443  loss_offset: 0.9795  time: 0.4184  data_time: 0.0252  lr: 0.0016686  max_mem: 9415M
[12/10 02:47:15 d2.utils.events]:  eta: 0:44:14  iter: 3639  total_loss: 3.894  loss_sem_seg: 2.143  loss_center: 0.6349  loss_offset: 0.9998  time: 0.4185  data_time: 0.0276  lr: 0.0016638  max_mem: 9415M
[12/10 02:47:23 d2.utils.events]:  eta: 0:44:05  iter: 3659  total_loss: 3.761  loss_sem_seg: 1.916  loss_center: 0.6726  loss_offset: 0.9661  time: 0.4185  data_time: 0.0250  lr: 0.0016591  max_mem: 9415M
[12/10 02:47:31 d2.utils.events]:  eta: 0:43:56  iter: 3679  total_loss: 3.926  loss_sem_seg: 2.06  loss_center: 0.6261  loss_offset: 1.041  time: 0.4184  data_time: 0.0253  lr: 0.0016544  max_mem: 9415M
[12/10 02:47:40 d2.utils.events]:  eta: 0:43:49  iter: 3699  total_loss: 3.357  loss_sem_seg: 1.826  loss_center: 0.5402  loss_offset: 0.9824  time: 0.4184  data_time: 0.0241  lr: 0.0016497  max_mem: 9415M
[12/10 02:47:48 d2.utils.events]:  eta: 0:43:40  iter: 3719  total_loss: 3.646  loss_sem_seg: 1.838  loss_center: 0.7052  loss_offset: 0.9225  time: 0.4184  data_time: 0.0253  lr: 0.001645  max_mem: 9415M
[12/10 02:47:56 d2.utils.events]:  eta: 0:43:32  iter: 3739  total_loss: 3.581  loss_sem_seg: 2.033  loss_center: 0.5786  loss_offset: 0.9034  time: 0.4184  data_time: 0.0264  lr: 0.0016403  max_mem: 9415M
[12/10 02:48:05 d2.utils.events]:  eta: 0:43:23  iter: 3759  total_loss: 3.794  loss_sem_seg: 1.838  loss_center: 0.7059  loss_offset: 0.9853  time: 0.4184  data_time: 0.0246  lr: 0.0016356  max_mem: 9415M
[12/10 02:48:13 d2.utils.events]:  eta: 0:43:15  iter: 3779  total_loss: 3.498  loss_sem_seg: 1.848  loss_center: 0.6712  loss_offset: 0.9178  time: 0.4184  data_time: 0.0274  lr: 0.0016309  max_mem: 9415M
[12/10 02:48:21 d2.utils.events]:  eta: 0:43:07  iter: 3799  total_loss: 3.558  loss_sem_seg: 1.782  loss_center: 0.6617  loss_offset: 0.8826  time: 0.4184  data_time: 0.0267  lr: 0.0016261  max_mem: 9415M
[12/10 02:48:30 d2.utils.events]:  eta: 0:42:59  iter: 3819  total_loss: 3.856  loss_sem_seg: 1.903  loss_center: 0.77  loss_offset: 0.9783  time: 0.4184  data_time: 0.0260  lr: 0.0016214  max_mem: 9415M
[12/10 02:48:38 d2.utils.events]:  eta: 0:42:51  iter: 3839  total_loss: 3.707  loss_sem_seg: 2.01  loss_center: 0.6995  loss_offset: 1.002  time: 0.4184  data_time: 0.0259  lr: 0.0016167  max_mem: 9415M
[12/10 02:48:47 d2.utils.events]:  eta: 0:42:42  iter: 3859  total_loss: 3.268  loss_sem_seg: 1.74  loss_center: 0.7939  loss_offset: 0.9279  time: 0.4184  data_time: 0.0248  lr: 0.001612  max_mem: 9415M
[12/10 02:48:55 d2.utils.events]:  eta: 0:42:33  iter: 3879  total_loss: 3.484  loss_sem_seg: 1.747  loss_center: 0.6973  loss_offset: 0.96  time: 0.4184  data_time: 0.0259  lr: 0.0016072  max_mem: 9415M
[12/10 02:49:03 d2.utils.events]:  eta: 0:42:24  iter: 3899  total_loss: 3.725  loss_sem_seg: 2.145  loss_center: 0.6841  loss_offset: 0.8834  time: 0.4184  data_time: 0.0252  lr: 0.0016025  max_mem: 9415M
[12/10 02:49:12 d2.utils.events]:  eta: 0:42:15  iter: 3919  total_loss: 3.587  loss_sem_seg: 1.881  loss_center: 0.645  loss_offset: 1.002  time: 0.4184  data_time: 0.0241  lr: 0.0015978  max_mem: 9415M
[12/10 02:49:20 d2.utils.events]:  eta: 0:42:06  iter: 3939  total_loss: 3.865  loss_sem_seg: 1.958  loss_center: 0.6968  loss_offset: 1.033  time: 0.4184  data_time: 0.0258  lr: 0.0015931  max_mem: 9415M
[12/10 02:49:28 d2.utils.events]:  eta: 0:41:59  iter: 3959  total_loss: 3.777  loss_sem_seg: 2.064  loss_center: 0.7183  loss_offset: 1.023  time: 0.4184  data_time: 0.0269  lr: 0.0015883  max_mem: 9415M
[12/10 02:49:37 d2.utils.events]:  eta: 0:41:49  iter: 3979  total_loss: 3.256  loss_sem_seg: 1.701  loss_center: 0.7185  loss_offset: 0.962  time: 0.4184  data_time: 0.0270  lr: 0.0015836  max_mem: 9415M
[12/10 02:49:45 d2.utils.events]:  eta: 0:41:41  iter: 3999  total_loss: 3.615  loss_sem_seg: 1.758  loss_center: 0.6114  loss_offset: 0.9254  time: 0.4184  data_time: 0.0258  lr: 0.0015789  max_mem: 9415M
[12/10 02:49:54 d2.utils.events]:  eta: 0:41:33  iter: 4019  total_loss: 3.549  loss_sem_seg: 1.851  loss_center: 0.712  loss_offset: 0.9366  time: 0.4184  data_time: 0.0261  lr: 0.0015741  max_mem: 9415M
[12/10 02:50:02 d2.utils.events]:  eta: 0:41:24  iter: 4039  total_loss: 3.535  loss_sem_seg: 1.957  loss_center: 0.5961  loss_offset: 0.9646  time: 0.4184  data_time: 0.0261  lr: 0.0015694  max_mem: 9415M
[12/10 02:50:10 d2.utils.events]:  eta: 0:41:16  iter: 4059  total_loss: 3.439  loss_sem_seg: 1.885  loss_center: 0.7412  loss_offset: 0.9487  time: 0.4184  data_time: 0.0261  lr: 0.0015646  max_mem: 9415M
[12/10 02:50:19 d2.utils.events]:  eta: 0:41:06  iter: 4079  total_loss: 3.362  loss_sem_seg: 1.663  loss_center: 0.6345  loss_offset: 0.934  time: 0.4184  data_time: 0.0255  lr: 0.0015599  max_mem: 9415M
[12/10 02:50:27 d2.utils.events]:  eta: 0:40:59  iter: 4099  total_loss: 3.775  loss_sem_seg: 2.062  loss_center: 0.6807  loss_offset: 1.043  time: 0.4184  data_time: 0.0254  lr: 0.0015552  max_mem: 9415M
[12/10 02:50:35 d2.utils.events]:  eta: 0:40:51  iter: 4119  total_loss: 3.523  loss_sem_seg: 1.715  loss_center: 0.6385  loss_offset: 0.97  time: 0.4184  data_time: 0.0243  lr: 0.0015504  max_mem: 9415M
[12/10 02:50:44 d2.utils.events]:  eta: 0:40:41  iter: 4139  total_loss: 3.703  loss_sem_seg: 2.051  loss_center: 0.5609  loss_offset: 1.068  time: 0.4184  data_time: 0.0261  lr: 0.0015457  max_mem: 9415M
[12/10 02:50:52 d2.utils.events]:  eta: 0:40:34  iter: 4159  total_loss: 3.41  loss_sem_seg: 1.696  loss_center: 0.6126  loss_offset: 0.9775  time: 0.4184  data_time: 0.0266  lr: 0.0015409  max_mem: 9415M
[12/10 02:51:01 d2.utils.events]:  eta: 0:40:25  iter: 4179  total_loss: 3.405  loss_sem_seg: 1.756  loss_center: 0.5335  loss_offset: 0.8766  time: 0.4184  data_time: 0.0257  lr: 0.0015362  max_mem: 9415M
[12/10 02:51:09 d2.utils.events]:  eta: 0:40:17  iter: 4199  total_loss: 3.705  loss_sem_seg: 2.089  loss_center: 0.723  loss_offset: 0.9703  time: 0.4184  data_time: 0.0265  lr: 0.0015314  max_mem: 9415M
[12/10 02:51:17 d2.utils.events]:  eta: 0:40:09  iter: 4219  total_loss: 3.911  loss_sem_seg: 1.772  loss_center: 0.8584  loss_offset: 0.9556  time: 0.4184  data_time: 0.0253  lr: 0.0015267  max_mem: 9415M
[12/10 02:51:26 d2.utils.events]:  eta: 0:40:01  iter: 4239  total_loss: 3.612  loss_sem_seg: 1.872  loss_center: 0.5387  loss_offset: 0.8894  time: 0.4184  data_time: 0.0258  lr: 0.0015219  max_mem: 9415M
[12/10 02:51:34 d2.utils.events]:  eta: 0:39:51  iter: 4259  total_loss: 3.326  loss_sem_seg: 1.893  loss_center: 0.6065  loss_offset: 0.9193  time: 0.4184  data_time: 0.0261  lr: 0.0015172  max_mem: 9415M
[12/10 02:51:43 d2.utils.events]:  eta: 0:39:43  iter: 4279  total_loss: 3.702  loss_sem_seg: 1.784  loss_center: 0.616  loss_offset: 0.9219  time: 0.4184  data_time: 0.0259  lr: 0.0015124  max_mem: 9415M
[12/10 02:51:51 d2.utils.events]:  eta: 0:39:36  iter: 4299  total_loss: 3.676  loss_sem_seg: 1.797  loss_center: 0.705  loss_offset: 0.9646  time: 0.4184  data_time: 0.0273  lr: 0.0015076  max_mem: 9415M
[12/10 02:51:59 d2.utils.events]:  eta: 0:39:28  iter: 4319  total_loss: 3.475  loss_sem_seg: 1.871  loss_center: 0.7079  loss_offset: 0.8918  time: 0.4184  data_time: 0.0253  lr: 0.0015029  max_mem: 9415M
[12/10 02:52:08 d2.utils.events]:  eta: 0:39:20  iter: 4339  total_loss: 3.63  loss_sem_seg: 1.986  loss_center: 0.6307  loss_offset: 0.955  time: 0.4184  data_time: 0.0263  lr: 0.0014981  max_mem: 9415M
[12/10 02:52:16 d2.utils.events]:  eta: 0:39:12  iter: 4359  total_loss: 3.576  loss_sem_seg: 1.881  loss_center: 0.7541  loss_offset: 1.019  time: 0.4184  data_time: 0.0268  lr: 0.0014933  max_mem: 9415M
[12/10 02:52:25 d2.utils.events]:  eta: 0:39:03  iter: 4379  total_loss: 3.541  loss_sem_seg: 1.945  loss_center: 0.75  loss_offset: 0.9227  time: 0.4184  data_time: 0.0262  lr: 0.0014886  max_mem: 9415M
[12/10 02:52:33 d2.utils.events]:  eta: 0:38:56  iter: 4399  total_loss: 3.533  loss_sem_seg: 1.891  loss_center: 0.5899  loss_offset: 0.9647  time: 0.4184  data_time: 0.0262  lr: 0.0014838  max_mem: 9415M
[12/10 02:52:41 d2.utils.events]:  eta: 0:38:47  iter: 4419  total_loss: 3.7  loss_sem_seg: 1.829  loss_center: 0.5598  loss_offset: 1.089  time: 0.4184  data_time: 0.0254  lr: 0.001479  max_mem: 9415M
[12/10 02:52:50 d2.utils.events]:  eta: 0:38:38  iter: 4439  total_loss: 3.489  loss_sem_seg: 1.784  loss_center: 0.8003  loss_offset: 0.9605  time: 0.4184  data_time: 0.0267  lr: 0.0014743  max_mem: 9415M
[12/10 02:52:58 d2.utils.events]:  eta: 0:38:32  iter: 4459  total_loss: 3.366  loss_sem_seg: 1.982  loss_center: 0.6515  loss_offset: 0.9096  time: 0.4184  data_time: 0.0264  lr: 0.0014695  max_mem: 9415M
[12/10 02:53:07 d2.utils.events]:  eta: 0:38:23  iter: 4479  total_loss: 3.577  loss_sem_seg: 1.794  loss_center: 0.7496  loss_offset: 0.9583  time: 0.4185  data_time: 0.0261  lr: 0.0014647  max_mem: 9415M
[12/10 02:53:15 d2.utils.events]:  eta: 0:38:15  iter: 4499  total_loss: 3.643  loss_sem_seg: 1.916  loss_center: 0.6468  loss_offset: 1.053  time: 0.4185  data_time: 0.0265  lr: 0.0014599  max_mem: 9415M
[12/10 02:53:23 d2.utils.events]:  eta: 0:38:08  iter: 4519  total_loss: 3.615  loss_sem_seg: 1.808  loss_center: 0.7783  loss_offset: 1.001  time: 0.4185  data_time: 0.0260  lr: 0.0014552  max_mem: 9415M
[12/10 02:53:32 d2.utils.events]:  eta: 0:37:59  iter: 4539  total_loss: 3.476  loss_sem_seg: 1.775  loss_center: 0.6777  loss_offset: 0.9336  time: 0.4185  data_time: 0.0252  lr: 0.0014504  max_mem: 9415M
[12/10 02:53:40 d2.utils.events]:  eta: 0:37:51  iter: 4559  total_loss: 3.454  loss_sem_seg: 1.745  loss_center: 0.6224  loss_offset: 0.9889  time: 0.4185  data_time: 0.0261  lr: 0.0014456  max_mem: 9415M
[12/10 02:53:49 d2.utils.events]:  eta: 0:37:43  iter: 4579  total_loss: 4.211  loss_sem_seg: 2.263  loss_center: 0.6484  loss_offset: 1.078  time: 0.4185  data_time: 0.0265  lr: 0.0014408  max_mem: 9415M
[12/10 02:53:57 d2.utils.events]:  eta: 0:37:36  iter: 4599  total_loss: 3.665  loss_sem_seg: 1.902  loss_center: 0.7474  loss_offset: 1.04  time: 0.4185  data_time: 0.0244  lr: 0.001436  max_mem: 9415M
[12/10 02:54:05 d2.utils.events]:  eta: 0:37:27  iter: 4619  total_loss: 3.938  loss_sem_seg: 2  loss_center: 0.702  loss_offset: 0.8723  time: 0.4185  data_time: 0.0265  lr: 0.0014313  max_mem: 9415M
[12/10 02:54:14 d2.utils.events]:  eta: 0:37:18  iter: 4639  total_loss: 3.676  loss_sem_seg: 2.047  loss_center: 0.7077  loss_offset: 0.8737  time: 0.4185  data_time: 0.0252  lr: 0.0014265  max_mem: 9415M
[12/10 02:54:22 d2.utils.events]:  eta: 0:37:10  iter: 4659  total_loss: 3.319  loss_sem_seg: 1.584  loss_center: 0.6921  loss_offset: 0.8643  time: 0.4185  data_time: 0.0265  lr: 0.0014217  max_mem: 9415M
[12/10 02:54:30 d2.utils.events]:  eta: 0:37:03  iter: 4679  total_loss: 3.805  loss_sem_seg: 1.958  loss_center: 0.541  loss_offset: 0.9539  time: 0.4185  data_time: 0.0265  lr: 0.0014169  max_mem: 9415M
[12/10 02:54:39 d2.utils.events]:  eta: 0:36:55  iter: 4699  total_loss: 3.59  loss_sem_seg: 1.89  loss_center: 0.703  loss_offset: 0.8856  time: 0.4185  data_time: 0.0248  lr: 0.0014121  max_mem: 9415M
[12/10 02:54:47 d2.utils.events]:  eta: 0:36:47  iter: 4719  total_loss: 3.472  loss_sem_seg: 1.873  loss_center: 0.6312  loss_offset: 0.9006  time: 0.4185  data_time: 0.0261  lr: 0.0014073  max_mem: 9415M
[12/10 02:54:56 d2.utils.events]:  eta: 0:36:39  iter: 4739  total_loss: 3.361  loss_sem_seg: 1.775  loss_center: 0.7519  loss_offset: 0.9217  time: 0.4185  data_time: 0.0261  lr: 0.0014025  max_mem: 9415M
[12/10 02:55:04 d2.utils.events]:  eta: 0:36:32  iter: 4759  total_loss: 3.532  loss_sem_seg: 1.812  loss_center: 0.532  loss_offset: 0.8924  time: 0.4185  data_time: 0.0258  lr: 0.0013977  max_mem: 9415M
[12/10 02:55:12 d2.utils.events]:  eta: 0:36:23  iter: 4779  total_loss: 4.083  loss_sem_seg: 2.021  loss_center: 0.6265  loss_offset: 1.052  time: 0.4185  data_time: 0.0269  lr: 0.0013929  max_mem: 9415M
[12/10 02:55:21 d2.utils.events]:  eta: 0:36:15  iter: 4799  total_loss: 3.315  loss_sem_seg: 1.708  loss_center: 0.5717  loss_offset: 0.945  time: 0.4185  data_time: 0.0248  lr: 0.0013881  max_mem: 9415M
[12/10 02:55:29 d2.utils.events]:  eta: 0:36:07  iter: 4819  total_loss: 3.598  loss_sem_seg: 2.043  loss_center: 0.5981  loss_offset: 0.994  time: 0.4185  data_time: 0.0264  lr: 0.0013833  max_mem: 9415M
[12/10 02:55:38 d2.utils.events]:  eta: 0:35:58  iter: 4839  total_loss: 3.757  loss_sem_seg: 1.976  loss_center: 0.8358  loss_offset: 0.916  time: 0.4185  data_time: 0.0245  lr: 0.0013785  max_mem: 9415M
[12/10 02:55:46 d2.utils.events]:  eta: 0:35:50  iter: 4859  total_loss: 3.201  loss_sem_seg: 1.844  loss_center: 0.5632  loss_offset: 0.8955  time: 0.4185  data_time: 0.0260  lr: 0.0013737  max_mem: 9415M
[12/10 02:55:54 d2.utils.events]:  eta: 0:35:42  iter: 4879  total_loss: 3.406  loss_sem_seg: 1.776  loss_center: 0.5946  loss_offset: 0.9608  time: 0.4185  data_time: 0.0259  lr: 0.0013689  max_mem: 9415M
[12/10 02:56:03 d2.utils.events]:  eta: 0:35:34  iter: 4899  total_loss: 3.782  loss_sem_seg: 2.099  loss_center: 0.772  loss_offset: 0.9652  time: 0.4185  data_time: 0.0283  lr: 0.001364  max_mem: 9415M
[12/10 02:56:11 d2.utils.events]:  eta: 0:35:26  iter: 4919  total_loss: 3.499  loss_sem_seg: 1.838  loss_center: 0.7005  loss_offset: 0.9553  time: 0.4185  data_time: 0.0259  lr: 0.0013592  max_mem: 9415M
[12/10 02:56:20 d2.utils.events]:  eta: 0:35:18  iter: 4939  total_loss: 3.435  loss_sem_seg: 1.834  loss_center: 0.5734  loss_offset: 1.056  time: 0.4185  data_time: 0.0254  lr: 0.0013544  max_mem: 9415M
[12/10 02:56:28 d2.utils.events]:  eta: 0:35:09  iter: 4959  total_loss: 3.472  loss_sem_seg: 1.946  loss_center: 0.6036  loss_offset: 0.8487  time: 0.4185  data_time: 0.0238  lr: 0.0013496  max_mem: 9415M
[12/10 02:56:36 d2.utils.events]:  eta: 0:35:01  iter: 4979  total_loss: 3.492  loss_sem_seg: 1.859  loss_center: 0.6988  loss_offset: 0.8532  time: 0.4185  data_time: 0.0270  lr: 0.0013448  max_mem: 9415M
[12/10 02:56:45 fvcore.common.checkpoint]: Saving checkpoint to ./output/model_0004999.pth
[12/10 02:56:45 d2.utils.events]:  eta: 0:34:53  iter: 4999  total_loss: 3.399  loss_sem_seg: 1.651  loss_center: 0.6416  loss_offset: 0.9531  time: 0.4185  data_time: 0.0257  lr: 0.00134  max_mem: 9415M
[12/10 02:56:54 d2.utils.events]:  eta: 0:34:44  iter: 5019  total_loss: 3.313  loss_sem_seg: 1.704  loss_center: 0.7316  loss_offset: 0.8866  time: 0.4185  data_time: 0.0268  lr: 0.0013351  max_mem: 9415M
[12/10 02:57:03 d2.utils.events]:  eta: 0:34:36  iter: 5039  total_loss: 3.473  loss_sem_seg: 1.832  loss_center: 0.6821  loss_offset: 0.9123  time: 0.4185  data_time: 0.0276  lr: 0.0013303  max_mem: 9415M
[12/10 02:57:11 d2.utils.events]:  eta: 0:34:27  iter: 5059  total_loss: 3.287  loss_sem_seg: 1.733  loss_center: 0.7321  loss_offset: 0.836  time: 0.4185  data_time: 0.0258  lr: 0.0013255  max_mem: 9415M
[12/10 02:57:20 d2.utils.events]:  eta: 0:34:19  iter: 5079  total_loss: 3.459  loss_sem_seg: 1.656  loss_center: 0.7208  loss_offset: 0.9558  time: 0.4185  data_time: 0.0251  lr: 0.0013207  max_mem: 9415M
[12/10 02:57:28 d2.utils.events]:  eta: 0:34:11  iter: 5099  total_loss: 3.592  loss_sem_seg: 1.969  loss_center: 0.6177  loss_offset: 0.9569  time: 0.4185  data_time: 0.0269  lr: 0.0013158  max_mem: 9415M
[12/10 02:57:36 d2.utils.events]:  eta: 0:34:03  iter: 5119  total_loss: 3.428  loss_sem_seg: 1.673  loss_center: 0.6768  loss_offset: 0.9983  time: 0.4185  data_time: 0.0246  lr: 0.001311  max_mem: 9415M
[12/10 02:57:45 d2.utils.events]:  eta: 0:33:54  iter: 5139  total_loss: 3.389  loss_sem_seg: 1.642  loss_center: 0.6371  loss_offset: 1.031  time: 0.4185  data_time: 0.0260  lr: 0.0013062  max_mem: 9415M
[12/10 02:57:53 d2.utils.events]:  eta: 0:33:46  iter: 5159  total_loss: 3.369  loss_sem_seg: 1.78  loss_center: 0.6437  loss_offset: 0.9502  time: 0.4185  data_time: 0.0257  lr: 0.0013013  max_mem: 9415M
[12/10 02:58:02 d2.utils.events]:  eta: 0:33:38  iter: 5179  total_loss: 3.636  loss_sem_seg: 1.868  loss_center: 0.6744  loss_offset: 0.9184  time: 0.4185  data_time: 0.0263  lr: 0.0012965  max_mem: 9415M
[12/10 02:58:10 d2.utils.events]:  eta: 0:33:30  iter: 5199  total_loss: 3.539  loss_sem_seg: 1.931  loss_center: 0.6591  loss_offset: 0.9966  time: 0.4185  data_time: 0.0265  lr: 0.0012916  max_mem: 9415M
[12/10 02:58:18 d2.utils.events]:  eta: 0:33:21  iter: 5219  total_loss: 3.389  loss_sem_seg: 1.748  loss_center: 0.6471  loss_offset: 1.015  time: 0.4185  data_time: 0.0259  lr: 0.0012868  max_mem: 9415M
[12/10 02:58:27 d2.utils.events]:  eta: 0:33:13  iter: 5239  total_loss: 3.606  loss_sem_seg: 1.797  loss_center: 0.7169  loss_offset: 0.9641  time: 0.4185  data_time: 0.0251  lr: 0.0012819  max_mem: 9415M
[12/10 02:58:35 d2.utils.events]:  eta: 0:33:05  iter: 5259  total_loss: 3.741  loss_sem_seg: 1.988  loss_center: 0.634  loss_offset: 0.8921  time: 0.4185  data_time: 0.0260  lr: 0.0012771  max_mem: 9415M
[12/10 02:58:44 d2.utils.events]:  eta: 0:32:56  iter: 5279  total_loss: 3.318  loss_sem_seg: 1.698  loss_center: 0.5628  loss_offset: 0.9795  time: 0.4185  data_time: 0.0270  lr: 0.0012722  max_mem: 9415M
[12/10 02:58:52 d2.utils.events]:  eta: 0:32:48  iter: 5299  total_loss: 3.613  loss_sem_seg: 1.838  loss_center: 0.6665  loss_offset: 0.9229  time: 0.4185  data_time: 0.0256  lr: 0.0012674  max_mem: 9415M
[12/10 02:59:00 d2.utils.events]:  eta: 0:32:39  iter: 5319  total_loss: 3.122  loss_sem_seg: 1.6  loss_center: 0.7238  loss_offset: 0.7773  time: 0.4185  data_time: 0.0238  lr: 0.0012625  max_mem: 9415M
[12/10 02:59:09 d2.utils.events]:  eta: 0:32:31  iter: 5339  total_loss: 3.27  loss_sem_seg: 1.627  loss_center: 0.8093  loss_offset: 0.8211  time: 0.4185  data_time: 0.0256  lr: 0.0012577  max_mem: 9415M
[12/10 02:59:17 d2.utils.events]:  eta: 0:32:22  iter: 5359  total_loss: 3.561  loss_sem_seg: 2.016  loss_center: 0.8254  loss_offset: 0.9303  time: 0.4185  data_time: 0.0247  lr: 0.0012528  max_mem: 9415M
[12/10 02:59:25 d2.utils.events]:  eta: 0:32:14  iter: 5379  total_loss: 3.434  loss_sem_seg: 1.829  loss_center: 0.6031  loss_offset: 0.8856  time: 0.4185  data_time: 0.0261  lr: 0.001248  max_mem: 9415M
[12/10 02:59:34 d2.utils.events]:  eta: 0:32:05  iter: 5399  total_loss: 3.267  loss_sem_seg: 1.758  loss_center: 0.6194  loss_offset: 0.972  time: 0.4185  data_time: 0.0263  lr: 0.0012431  max_mem: 9415M
[12/10 02:59:42 d2.utils.events]:  eta: 0:31:57  iter: 5419  total_loss: 3.547  loss_sem_seg: 1.747  loss_center: 0.7358  loss_offset: 0.951  time: 0.4185  data_time: 0.0263  lr: 0.0012382  max_mem: 9415M
[12/10 02:59:51 d2.utils.events]:  eta: 0:31:49  iter: 5439  total_loss: 3.47  loss_sem_seg: 1.813  loss_center: 0.5708  loss_offset: 0.8947  time: 0.4185  data_time: 0.0254  lr: 0.0012334  max_mem: 9415M
[12/10 02:59:59 d2.utils.events]:  eta: 0:31:40  iter: 5459  total_loss: 3.348  loss_sem_seg: 1.664  loss_center: 0.5795  loss_offset: 1.017  time: 0.4185  data_time: 0.0260  lr: 0.0012285  max_mem: 9415M
[12/10 03:00:07 d2.utils.events]:  eta: 0:31:32  iter: 5479  total_loss: 3.385  loss_sem_seg: 1.766  loss_center: 0.6467  loss_offset: 0.8904  time: 0.4185  data_time: 0.0260  lr: 0.0012236  max_mem: 9415M
[12/10 03:00:16 d2.utils.events]:  eta: 0:31:23  iter: 5499  total_loss: 3.494  loss_sem_seg: 1.78  loss_center: 0.8093  loss_offset: 0.9114  time: 0.4185  data_time: 0.0256  lr: 0.0012188  max_mem: 9415M
[12/10 03:00:24 d2.utils.events]:  eta: 0:31:15  iter: 5519  total_loss: 3.241  loss_sem_seg: 1.661  loss_center: 0.6084  loss_offset: 0.9399  time: 0.4185  data_time: 0.0260  lr: 0.0012139  max_mem: 9415M
[12/10 03:00:33 d2.utils.events]:  eta: 0:31:07  iter: 5539  total_loss: 3.197  loss_sem_seg: 1.606  loss_center: 0.6613  loss_offset: 0.8718  time: 0.4185  data_time: 0.0261  lr: 0.001209  max_mem: 9415M
[12/10 03:00:41 d2.utils.events]:  eta: 0:30:58  iter: 5559  total_loss: 3.399  loss_sem_seg: 1.849  loss_center: 0.5936  loss_offset: 0.8484  time: 0.4185  data_time: 0.0257  lr: 0.0012041  max_mem: 9415M
[12/10 03:00:49 d2.utils.events]:  eta: 0:30:50  iter: 5579  total_loss: 3.792  loss_sem_seg: 1.804  loss_center: 0.6423  loss_offset: 0.9694  time: 0.4185  data_time: 0.0269  lr: 0.0011992  max_mem: 9415M
[12/10 03:00:58 d2.utils.events]:  eta: 0:30:42  iter: 5599  total_loss: 3.714  loss_sem_seg: 2.029  loss_center: 0.5166  loss_offset: 1.033  time: 0.4185  data_time: 0.0255  lr: 0.0011944  max_mem: 9415M
[12/10 03:01:06 d2.utils.events]:  eta: 0:30:34  iter: 5619  total_loss: 3.202  loss_sem_seg: 1.646  loss_center: 0.653  loss_offset: 0.8847  time: 0.4185  data_time: 0.0270  lr: 0.0011895  max_mem: 9415M
[12/10 03:01:15 d2.utils.events]:  eta: 0:30:25  iter: 5639  total_loss: 3.326  loss_sem_seg: 1.676  loss_center: 0.8019  loss_offset: 0.9264  time: 0.4185  data_time: 0.0273  lr: 0.0011846  max_mem: 9415M
[12/10 03:01:23 d2.utils.events]:  eta: 0:30:18  iter: 5659  total_loss: 3.256  loss_sem_seg: 1.75  loss_center: 0.5933  loss_offset: 0.8417  time: 0.4186  data_time: 0.0272  lr: 0.0011797  max_mem: 9415M
[12/10 03:01:31 d2.utils.events]:  eta: 0:30:08  iter: 5679  total_loss: 3.421  loss_sem_seg: 1.731  loss_center: 0.5717  loss_offset: 0.9728  time: 0.4185  data_time: 0.0252  lr: 0.0011748  max_mem: 9415M
[12/10 03:01:40 d2.utils.events]:  eta: 0:30:00  iter: 5699  total_loss: 3.093  loss_sem_seg: 1.645  loss_center: 0.6215  loss_offset: 0.875  time: 0.4185  data_time: 0.0249  lr: 0.0011699  max_mem: 9415M
[12/10 03:01:48 d2.utils.events]:  eta: 0:29:52  iter: 5719  total_loss: 3.237  loss_sem_seg: 1.527  loss_center: 0.6173  loss_offset: 0.8154  time: 0.4185  data_time: 0.0248  lr: 0.001165  max_mem: 9415M
[12/10 03:01:56 d2.utils.events]:  eta: 0:29:43  iter: 5739  total_loss: 3.302  loss_sem_seg: 1.825  loss_center: 0.5644  loss_offset: 0.895  time: 0.4185  data_time: 0.0263  lr: 0.0011601  max_mem: 9415M
[12/10 03:02:05 d2.utils.events]:  eta: 0:29:35  iter: 5759  total_loss: 3.657  loss_sem_seg: 1.88  loss_center: 0.7067  loss_offset: 1.023  time: 0.4185  data_time: 0.0259  lr: 0.0011552  max_mem: 9415M
[12/10 03:02:13 d2.utils.events]:  eta: 0:29:26  iter: 5779  total_loss: 3.309  loss_sem_seg: 1.701  loss_center: 0.5846  loss_offset: 0.8228  time: 0.4185  data_time: 0.0249  lr: 0.0011503  max_mem: 9415M
[12/10 03:02:21 d2.utils.events]:  eta: 0:29:18  iter: 5799  total_loss: 3.604  loss_sem_seg: 1.981  loss_center: 0.6922  loss_offset: 0.9364  time: 0.4185  data_time: 0.0271  lr: 0.0011454  max_mem: 9415M
[12/10 03:02:30 d2.utils.events]:  eta: 0:29:09  iter: 5819  total_loss: 3.288  loss_sem_seg: 1.766  loss_center: 0.5436  loss_offset: 0.8652  time: 0.4185  data_time: 0.0272  lr: 0.0011405  max_mem: 9415M
[12/10 03:02:38 d2.utils.events]:  eta: 0:29:01  iter: 5839  total_loss: 3.432  loss_sem_seg: 1.62  loss_center: 0.7155  loss_offset: 0.9113  time: 0.4185  data_time: 0.0250  lr: 0.0011356  max_mem: 9415M
[12/10 03:02:47 d2.utils.events]:  eta: 0:28:53  iter: 5859  total_loss: 3.566  loss_sem_seg: 1.919  loss_center: 0.6162  loss_offset: 0.9871  time: 0.4185  data_time: 0.0263  lr: 0.0011307  max_mem: 9415M
[12/10 03:02:55 d2.utils.events]:  eta: 0:28:44  iter: 5879  total_loss: 3.608  loss_sem_seg: 1.947  loss_center: 0.6564  loss_offset: 1.001  time: 0.4185  data_time: 0.0263  lr: 0.0011258  max_mem: 9415M
[12/10 03:03:03 d2.utils.events]:  eta: 0:28:35  iter: 5899  total_loss: 3.293  loss_sem_seg: 1.71  loss_center: 0.6451  loss_offset: 0.899  time: 0.4185  data_time: 0.0257  lr: 0.0011208  max_mem: 9415M
[12/10 03:03:12 d2.utils.events]:  eta: 0:28:27  iter: 5919  total_loss: 3.496  loss_sem_seg: 1.825  loss_center: 0.6678  loss_offset: 0.8779  time: 0.4185  data_time: 0.0266  lr: 0.0011159  max_mem: 9415M
[12/10 03:03:20 d2.utils.events]:  eta: 0:28:18  iter: 5939  total_loss: 3.374  loss_sem_seg: 1.74  loss_center: 0.7691  loss_offset: 0.8852  time: 0.4185  data_time: 0.0250  lr: 0.001111  max_mem: 9415M
[12/10 03:03:29 d2.utils.events]:  eta: 0:28:10  iter: 5959  total_loss: 3.764  loss_sem_seg: 1.983  loss_center: 0.6903  loss_offset: 0.9536  time: 0.4185  data_time: 0.0253  lr: 0.0011061  max_mem: 9415M
[12/10 03:03:37 d2.utils.events]:  eta: 0:28:01  iter: 5979  total_loss: 3.168  loss_sem_seg: 1.739  loss_center: 0.5994  loss_offset: 0.8025  time: 0.4185  data_time: 0.0263  lr: 0.0011011  max_mem: 9415M
[12/10 03:03:45 d2.utils.events]:  eta: 0:27:53  iter: 5999  total_loss: 3.2  loss_sem_seg: 1.815  loss_center: 0.502  loss_offset: 0.8075  time: 0.4185  data_time: 0.0266  lr: 0.0010962  max_mem: 9415M
[12/10 03:03:54 d2.utils.events]:  eta: 0:27:45  iter: 6019  total_loss: 3.622  loss_sem_seg: 1.912  loss_center: 0.5149  loss_offset: 0.8446  time: 0.4185  data_time: 0.0248  lr: 0.0010913  max_mem: 9415M
[12/10 03:04:02 d2.utils.events]:  eta: 0:27:36  iter: 6039  total_loss: 3.245  loss_sem_seg: 1.661  loss_center: 0.6024  loss_offset: 0.9054  time: 0.4185  data_time: 0.0266  lr: 0.0010863  max_mem: 9415M
[12/10 03:04:11 d2.utils.events]:  eta: 0:27:27  iter: 6059  total_loss: 3.187  loss_sem_seg: 1.634  loss_center: 0.7008  loss_offset: 0.8607  time: 0.4185  data_time: 0.0245  lr: 0.0010814  max_mem: 9415M
[12/10 03:04:19 d2.utils.events]:  eta: 0:27:19  iter: 6079  total_loss: 3.481  loss_sem_seg: 1.913  loss_center: 0.6048  loss_offset: 0.9535  time: 0.4185  data_time: 0.0272  lr: 0.0010765  max_mem: 9415M
[12/10 03:04:27 d2.utils.events]:  eta: 0:27:11  iter: 6099  total_loss: 2.992  loss_sem_seg: 1.67  loss_center: 0.5861  loss_offset: 0.8817  time: 0.4185  data_time: 0.0252  lr: 0.0010715  max_mem: 9415M
[12/10 03:04:36 d2.utils.events]:  eta: 0:27:02  iter: 6119  total_loss: 3.285  loss_sem_seg: 1.915  loss_center: 0.6917  loss_offset: 0.8546  time: 0.4185  data_time: 0.0260  lr: 0.0010666  max_mem: 9415M
[12/10 03:04:44 d2.utils.events]:  eta: 0:26:54  iter: 6139  total_loss: 3.583  loss_sem_seg: 1.798  loss_center: 0.67  loss_offset: 0.8838  time: 0.4185  data_time: 0.0267  lr: 0.0010616  max_mem: 9415M
[12/10 03:04:53 d2.utils.events]:  eta: 0:26:45  iter: 6159  total_loss: 3.12  loss_sem_seg: 1.488  loss_center: 0.674  loss_offset: 0.7124  time: 0.4185  data_time: 0.0265  lr: 0.0010567  max_mem: 9415M
[12/10 03:05:01 d2.utils.events]:  eta: 0:26:37  iter: 6179  total_loss: 3.325  loss_sem_seg: 1.708  loss_center: 0.7093  loss_offset: 0.8699  time: 0.4185  data_time: 0.0257  lr: 0.0010517  max_mem: 9415M
[12/10 03:05:09 d2.utils.events]:  eta: 0:26:28  iter: 6199  total_loss: 3.266  loss_sem_seg: 1.752  loss_center: 0.7724  loss_offset: 0.8089  time: 0.4185  data_time: 0.0257  lr: 0.0010468  max_mem: 9415M
[12/10 03:05:18 d2.utils.events]:  eta: 0:26:19  iter: 6219  total_loss: 3  loss_sem_seg: 1.698  loss_center: 0.6326  loss_offset: 0.8017  time: 0.4185  data_time: 0.0260  lr: 0.0010418  max_mem: 9415M
[12/10 03:05:26 d2.utils.events]:  eta: 0:26:11  iter: 6239  total_loss: 3.272  loss_sem_seg: 1.785  loss_center: 0.6038  loss_offset: 0.8599  time: 0.4185  data_time: 0.0268  lr: 0.0010368  max_mem: 9415M
[12/10 03:05:34 d2.utils.events]:  eta: 0:26:02  iter: 6259  total_loss: 3.529  loss_sem_seg: 1.902  loss_center: 0.6777  loss_offset: 0.8779  time: 0.4185  data_time: 0.0264  lr: 0.0010319  max_mem: 9415M
[12/10 03:05:43 d2.utils.events]:  eta: 0:25:54  iter: 6279  total_loss: 3.193  loss_sem_seg: 1.686  loss_center: 0.6241  loss_offset: 0.8203  time: 0.4185  data_time: 0.0249  lr: 0.0010269  max_mem: 9415M
[12/10 03:05:51 d2.utils.events]:  eta: 0:25:45  iter: 6299  total_loss: 3.366  loss_sem_seg: 1.8  loss_center: 0.6637  loss_offset: 0.8914  time: 0.4185  data_time: 0.0270  lr: 0.0010219  max_mem: 9415M
[12/10 03:05:59 d2.utils.events]:  eta: 0:25:37  iter: 6319  total_loss: 3.275  loss_sem_seg: 1.649  loss_center: 0.6954  loss_offset: 0.975  time: 0.4185  data_time: 0.0244  lr: 0.001017  max_mem: 9415M
[12/10 03:06:08 d2.utils.events]:  eta: 0:25:29  iter: 6339  total_loss: 3.757  loss_sem_seg: 1.983  loss_center: 0.7153  loss_offset: 0.9589  time: 0.4185  data_time: 0.0251  lr: 0.001012  max_mem: 9415M
[12/10 03:06:16 d2.utils.events]:  eta: 0:25:21  iter: 6359  total_loss: 3.382  loss_sem_seg: 1.806  loss_center: 0.6216  loss_offset: 0.9371  time: 0.4185  data_time: 0.0279  lr: 0.001007  max_mem: 9415M
[12/10 03:06:25 d2.utils.events]:  eta: 0:25:12  iter: 6379  total_loss: 3.206  loss_sem_seg: 1.602  loss_center: 0.6418  loss_offset: 0.8545  time: 0.4185  data_time: 0.0261  lr: 0.001002  max_mem: 9415M
[12/10 03:06:33 d2.utils.events]:  eta: 0:25:04  iter: 6399  total_loss: 3.151  loss_sem_seg: 1.68  loss_center: 0.5936  loss_offset: 0.8929  time: 0.4185  data_time: 0.0255  lr: 0.00099706  max_mem: 9415M
[12/10 03:06:41 d2.utils.events]:  eta: 0:24:55  iter: 6419  total_loss: 3.249  loss_sem_seg: 1.77  loss_center: 0.6256  loss_offset: 0.8194  time: 0.4185  data_time: 0.0260  lr: 0.00099207  max_mem: 9415M
[12/10 03:06:50 d2.utils.events]:  eta: 0:24:47  iter: 6439  total_loss: 3.197  loss_sem_seg: 1.718  loss_center: 0.6079  loss_offset: 0.8168  time: 0.4185  data_time: 0.0266  lr: 0.00098709  max_mem: 9415M
[12/10 03:06:58 d2.utils.events]:  eta: 0:24:39  iter: 6459  total_loss: 3.28  loss_sem_seg: 1.954  loss_center: 0.6352  loss_offset: 0.8963  time: 0.4185  data_time: 0.0262  lr: 0.00098209  max_mem: 9415M
[12/10 03:07:07 d2.utils.events]:  eta: 0:24:30  iter: 6479  total_loss: 3.145  loss_sem_seg: 1.817  loss_center: 0.5427  loss_offset: 0.8484  time: 0.4185  data_time: 0.0263  lr: 0.0009771  max_mem: 9415M
[12/10 03:07:15 d2.utils.events]:  eta: 0:24:22  iter: 6499  total_loss: 3.2  loss_sem_seg: 1.576  loss_center: 0.779  loss_offset: 0.8308  time: 0.4185  data_time: 0.0255  lr: 0.0009721  max_mem: 9415M
[12/10 03:07:23 d2.utils.events]:  eta: 0:24:14  iter: 6519  total_loss: 3.272  loss_sem_seg: 1.644  loss_center: 0.5601  loss_offset: 0.8696  time: 0.4185  data_time: 0.0265  lr: 0.00096711  max_mem: 9415M
[12/10 03:07:32 d2.utils.events]:  eta: 0:24:05  iter: 6539  total_loss: 3.131  loss_sem_seg: 1.734  loss_center: 0.7228  loss_offset: 0.775  time: 0.4185  data_time: 0.0259  lr: 0.0009621  max_mem: 9415M
[12/10 03:07:40 d2.utils.events]:  eta: 0:23:57  iter: 6559  total_loss: 3.126  loss_sem_seg: 1.659  loss_center: 0.5309  loss_offset: 0.8718  time: 0.4185  data_time: 0.0267  lr: 0.0009571  max_mem: 9415M
[12/10 03:07:49 d2.utils.events]:  eta: 0:23:48  iter: 6579  total_loss: 3.295  loss_sem_seg: 1.795  loss_center: 0.6754  loss_offset: 0.8961  time: 0.4185  data_time: 0.0259  lr: 0.00095209  max_mem: 9415M
[12/10 03:07:57 d2.utils.events]:  eta: 0:23:40  iter: 6599  total_loss: 3.012  loss_sem_seg: 1.663  loss_center: 0.5125  loss_offset: 0.8052  time: 0.4185  data_time: 0.0250  lr: 0.00094708  max_mem: 9415M
[12/10 03:08:05 d2.utils.events]:  eta: 0:23:31  iter: 6619  total_loss: 3.368  loss_sem_seg: 1.739  loss_center: 0.6065  loss_offset: 0.8369  time: 0.4185  data_time: 0.0264  lr: 0.00094206  max_mem: 9415M
[12/10 03:08:14 d2.utils.events]:  eta: 0:23:23  iter: 6639  total_loss: 3.005  loss_sem_seg: 1.544  loss_center: 0.5742  loss_offset: 0.8687  time: 0.4185  data_time: 0.0264  lr: 0.00093705  max_mem: 9415M
[12/10 03:08:22 d2.utils.events]:  eta: 0:23:15  iter: 6659  total_loss: 3.275  loss_sem_seg: 1.67  loss_center: 0.6761  loss_offset: 0.9091  time: 0.4185  data_time: 0.0245  lr: 0.00093203  max_mem: 9415M
[12/10 03:08:30 d2.utils.events]:  eta: 0:23:07  iter: 6679  total_loss: 3.577  loss_sem_seg: 1.688  loss_center: 0.7341  loss_offset: 0.9643  time: 0.4185  data_time: 0.0251  lr: 0.000927  max_mem: 9415M
[12/10 03:08:39 d2.utils.events]:  eta: 0:22:58  iter: 6699  total_loss: 3.402  loss_sem_seg: 1.77  loss_center: 0.6815  loss_offset: 0.9686  time: 0.4185  data_time: 0.0254  lr: 0.00092198  max_mem: 9415M
[12/10 03:08:47 d2.utils.events]:  eta: 0:22:50  iter: 6719  total_loss: 3.153  loss_sem_seg: 1.65  loss_center: 0.6133  loss_offset: 0.8108  time: 0.4185  data_time: 0.0255  lr: 0.00091695  max_mem: 9415M
[12/10 03:08:56 d2.utils.events]:  eta: 0:22:41  iter: 6739  total_loss: 3.075  loss_sem_seg: 1.508  loss_center: 0.7188  loss_offset: 0.7618  time: 0.4185  data_time: 0.0273  lr: 0.00091192  max_mem: 9415M
[12/10 03:09:04 d2.utils.events]:  eta: 0:22:33  iter: 6759  total_loss: 3.339  loss_sem_seg: 1.805  loss_center: 0.509  loss_offset: 0.9487  time: 0.4185  data_time: 0.0239  lr: 0.00090688  max_mem: 9415M
[12/10 03:09:12 d2.utils.events]:  eta: 0:22:25  iter: 6779  total_loss: 3.32  loss_sem_seg: 1.65  loss_center: 0.679  loss_offset: 0.8062  time: 0.4185  data_time: 0.0289  lr: 0.00090184  max_mem: 9415M
[12/10 03:09:21 d2.utils.events]:  eta: 0:22:17  iter: 6799  total_loss: 3.112  loss_sem_seg: 1.734  loss_center: 0.6075  loss_offset: 0.8846  time: 0.4186  data_time: 0.0291  lr: 0.0008968  max_mem: 9415M
[12/10 03:09:29 d2.utils.events]:  eta: 0:22:08  iter: 6819  total_loss: 3.001  loss_sem_seg: 1.61  loss_center: 0.5265  loss_offset: 0.7509  time: 0.4186  data_time: 0.0278  lr: 0.00089176  max_mem: 9415M
[12/10 03:09:38 d2.utils.events]:  eta: 0:22:00  iter: 6839  total_loss: 3.357  loss_sem_seg: 1.669  loss_center: 0.6536  loss_offset: 0.8404  time: 0.4186  data_time: 0.0259  lr: 0.00088671  max_mem: 9415M
[12/10 03:09:46 d2.utils.events]:  eta: 0:21:52  iter: 6859  total_loss: 3.277  loss_sem_seg: 1.549  loss_center: 0.6847  loss_offset: 0.8045  time: 0.4186  data_time: 0.0253  lr: 0.00088166  max_mem: 9415M
[12/10 03:09:54 d2.utils.events]:  eta: 0:21:43  iter: 6879  total_loss: 3.436  loss_sem_seg: 1.738  loss_center: 0.6  loss_offset: 0.9253  time: 0.4186  data_time: 0.0273  lr: 0.00087661  max_mem: 9415M
[12/10 03:10:03 d2.utils.events]:  eta: 0:21:35  iter: 6899  total_loss: 3.483  loss_sem_seg: 1.8  loss_center: 0.6558  loss_offset: 0.8766  time: 0.4186  data_time: 0.0271  lr: 0.00087155  max_mem: 9415M
[12/10 03:10:11 d2.utils.events]:  eta: 0:21:26  iter: 6919  total_loss: 3.168  loss_sem_seg: 1.54  loss_center: 0.65  loss_offset: 0.8426  time: 0.4186  data_time: 0.0248  lr: 0.00086649  max_mem: 9415M
[12/10 03:10:19 d2.utils.events]:  eta: 0:21:18  iter: 6939  total_loss: 3.254  loss_sem_seg: 1.738  loss_center: 0.5591  loss_offset: 0.8309  time: 0.4185  data_time: 0.0263  lr: 0.00086142  max_mem: 9415M
[12/10 03:10:28 d2.utils.events]:  eta: 0:21:10  iter: 6959  total_loss: 3.458  loss_sem_seg: 1.817  loss_center: 0.8005  loss_offset: 0.787  time: 0.4186  data_time: 0.0268  lr: 0.00085636  max_mem: 9415M
[12/10 03:10:36 d2.utils.events]:  eta: 0:21:02  iter: 6979  total_loss: 3.064  loss_sem_seg: 1.617  loss_center: 0.5923  loss_offset: 0.8314  time: 0.4186  data_time: 0.0259  lr: 0.00085129  max_mem: 9415M
[12/10 03:10:45 d2.utils.events]:  eta: 0:20:53  iter: 6999  total_loss: 3.357  loss_sem_seg: 1.732  loss_center: 0.5903  loss_offset: 0.9384  time: 0.4185  data_time: 0.0274  lr: 0.00084621  max_mem: 9415M
[12/10 03:10:53 d2.utils.events]:  eta: 0:20:45  iter: 7019  total_loss: 3.438  loss_sem_seg: 1.572  loss_center: 0.6076  loss_offset: 0.8457  time: 0.4185  data_time: 0.0251  lr: 0.00084114  max_mem: 9415M
[12/10 03:11:01 d2.utils.events]:  eta: 0:20:37  iter: 7039  total_loss: 3.341  loss_sem_seg: 1.962  loss_center: 0.5584  loss_offset: 0.8474  time: 0.4185  data_time: 0.0253  lr: 0.00083605  max_mem: 9415M
[12/10 03:11:10 d2.utils.events]:  eta: 0:20:29  iter: 7059  total_loss: 3.099  loss_sem_seg: 1.631  loss_center: 0.5579  loss_offset: 0.8576  time: 0.4185  data_time: 0.0273  lr: 0.00083097  max_mem: 9415M
[12/10 03:11:18 d2.utils.events]:  eta: 0:20:20  iter: 7079  total_loss: 3.247  loss_sem_seg: 1.645  loss_center: 0.6957  loss_offset: 0.8385  time: 0.4186  data_time: 0.0260  lr: 0.00082588  max_mem: 9415M
[12/10 03:11:27 d2.utils.events]:  eta: 0:20:12  iter: 7099  total_loss: 3.334  loss_sem_seg: 1.599  loss_center: 0.6524  loss_offset: 0.896  time: 0.4186  data_time: 0.0250  lr: 0.00082079  max_mem: 9415M
[12/10 03:11:35 d2.utils.events]:  eta: 0:20:04  iter: 7119  total_loss: 2.93  loss_sem_seg: 1.448  loss_center: 0.7331  loss_offset: 0.8065  time: 0.4186  data_time: 0.0258  lr: 0.0008157  max_mem: 9415M
[12/10 03:11:43 d2.utils.events]:  eta: 0:19:55  iter: 7139  total_loss: 3.137  loss_sem_seg: 1.656  loss_center: 0.5638  loss_offset: 0.885  time: 0.4186  data_time: 0.0256  lr: 0.0008106  max_mem: 9415M
[12/10 03:11:52 d2.utils.events]:  eta: 0:19:47  iter: 7159  total_loss: 3.251  loss_sem_seg: 1.628  loss_center: 0.6781  loss_offset: 0.7447  time: 0.4185  data_time: 0.0261  lr: 0.0008055  max_mem: 9415M
[12/10 03:12:00 d2.utils.events]:  eta: 0:19:39  iter: 7179  total_loss: 3.027  loss_sem_seg: 1.383  loss_center: 0.5688  loss_offset: 0.8748  time: 0.4186  data_time: 0.0274  lr: 0.00080039  max_mem: 9415M
[12/10 03:12:08 d2.utils.events]:  eta: 0:19:31  iter: 7199  total_loss: 3.229  loss_sem_seg: 1.716  loss_center: 0.5278  loss_offset: 0.8676  time: 0.4185  data_time: 0.0253  lr: 0.00079528  max_mem: 9415M
[12/10 03:12:17 d2.utils.events]:  eta: 0:19:22  iter: 7219  total_loss: 3.183  loss_sem_seg: 1.713  loss_center: 0.608  loss_offset: 0.9383  time: 0.4185  data_time: 0.0262  lr: 0.00079017  max_mem: 9415M
[12/10 03:12:25 d2.utils.events]:  eta: 0:19:14  iter: 7239  total_loss: 3.394  loss_sem_seg: 1.852  loss_center: 0.5679  loss_offset: 0.9179  time: 0.4186  data_time: 0.0279  lr: 0.00078505  max_mem: 9415M
[12/10 03:12:34 d2.utils.events]:  eta: 0:19:06  iter: 7259  total_loss: 3.273  loss_sem_seg: 1.747  loss_center: 0.5838  loss_offset: 0.8767  time: 0.4186  data_time: 0.0259  lr: 0.00077993  max_mem: 9415M
[12/10 03:12:42 d2.utils.events]:  eta: 0:18:58  iter: 7279  total_loss: 2.978  loss_sem_seg: 1.602  loss_center: 0.5177  loss_offset: 0.8522  time: 0.4186  data_time: 0.0271  lr: 0.00077481  max_mem: 9415M
[12/10 03:12:51 d2.utils.events]:  eta: 0:18:49  iter: 7299  total_loss: 3.36  loss_sem_seg: 1.809  loss_center: 0.6272  loss_offset: 0.8629  time: 0.4186  data_time: 0.0270  lr: 0.00076968  max_mem: 9415M
[12/10 03:12:59 d2.utils.events]:  eta: 0:18:41  iter: 7319  total_loss: 3.198  loss_sem_seg: 1.67  loss_center: 0.6617  loss_offset: 0.8545  time: 0.4186  data_time: 0.0268  lr: 0.00076455  max_mem: 9415M
[12/10 03:13:07 d2.utils.events]:  eta: 0:18:33  iter: 7339  total_loss: 2.99  loss_sem_seg: 1.594  loss_center: 0.5471  loss_offset: 0.7541  time: 0.4186  data_time: 0.0262  lr: 0.00075942  max_mem: 9415M
[12/10 03:13:16 d2.utils.events]:  eta: 0:18:24  iter: 7359  total_loss: 3.149  loss_sem_seg: 1.565  loss_center: 0.6366  loss_offset: 0.8587  time: 0.4186  data_time: 0.0281  lr: 0.00075428  max_mem: 9415M
[12/10 03:13:24 d2.utils.events]:  eta: 0:18:16  iter: 7379  total_loss: 3.172  loss_sem_seg: 1.574  loss_center: 0.6008  loss_offset: 0.7914  time: 0.4186  data_time: 0.0262  lr: 0.00074914  max_mem: 9415M
[12/10 03:13:33 d2.utils.events]:  eta: 0:18:08  iter: 7399  total_loss: 3.227  loss_sem_seg: 1.481  loss_center: 0.5175  loss_offset: 0.8526  time: 0.4186  data_time: 0.0266  lr: 0.00074399  max_mem: 9415M
[12/10 03:13:41 d2.utils.events]:  eta: 0:17:59  iter: 7419  total_loss: 3.028  loss_sem_seg: 1.689  loss_center: 0.5629  loss_offset: 0.7604  time: 0.4186  data_time: 0.0256  lr: 0.00073884  max_mem: 9415M
[12/10 03:13:49 d2.utils.events]:  eta: 0:17:51  iter: 7439  total_loss: 3.323  loss_sem_seg: 1.687  loss_center: 0.6272  loss_offset: 0.8441  time: 0.4186  data_time: 0.0228  lr: 0.00073368  max_mem: 9415M
[12/10 03:13:58 d2.utils.events]:  eta: 0:17:43  iter: 7459  total_loss: 3.302  loss_sem_seg: 1.635  loss_center: 0.6692  loss_offset: 0.8562  time: 0.4186  data_time: 0.0258  lr: 0.00072852  max_mem: 9415M
[12/10 03:14:06 d2.utils.events]:  eta: 0:17:34  iter: 7479  total_loss: 3.088  loss_sem_seg: 1.675  loss_center: 0.6122  loss_offset: 0.8166  time: 0.4186  data_time: 0.0260  lr: 0.00072336  max_mem: 9415M
[12/10 03:14:14 d2.utils.events]:  eta: 0:17:26  iter: 7499  total_loss: 3.115  loss_sem_seg: 1.596  loss_center: 0.8368  loss_offset: 0.8275  time: 0.4186  data_time: 0.0275  lr: 0.00071819  max_mem: 9415M
[12/10 03:14:23 d2.utils.events]:  eta: 0:17:18  iter: 7519  total_loss: 3.603  loss_sem_seg: 1.761  loss_center: 0.7516  loss_offset: 1.029  time: 0.4186  data_time: 0.0271  lr: 0.00071302  max_mem: 9415M
[12/10 03:14:31 d2.utils.events]:  eta: 0:17:09  iter: 7539  total_loss: 3.319  loss_sem_seg: 1.675  loss_center: 0.696  loss_offset: 0.8755  time: 0.4186  data_time: 0.0263  lr: 0.00070785  max_mem: 9415M
[12/10 03:14:40 d2.utils.events]:  eta: 0:17:01  iter: 7559  total_loss: 3.106  loss_sem_seg: 1.675  loss_center: 0.5311  loss_offset: 0.7715  time: 0.4186  data_time: 0.0266  lr: 0.00070267  max_mem: 9415M
[12/10 03:14:48 d2.utils.events]:  eta: 0:16:52  iter: 7579  total_loss: 2.916  loss_sem_seg: 1.491  loss_center: 0.6156  loss_offset: 0.9237  time: 0.4186  data_time: 0.0261  lr: 0.00069749  max_mem: 9415M
[12/10 03:14:57 d2.utils.events]:  eta: 0:16:44  iter: 7599  total_loss: 3.418  loss_sem_seg: 1.735  loss_center: 0.688  loss_offset: 0.8634  time: 0.4186  data_time: 0.0275  lr: 0.0006923  max_mem: 9415M
[12/10 03:15:05 d2.utils.events]:  eta: 0:16:36  iter: 7619  total_loss: 2.949  loss_sem_seg: 1.535  loss_center: 0.5604  loss_offset: 0.7671  time: 0.4186  data_time: 0.0269  lr: 0.00068711  max_mem: 9415M
[12/10 03:15:13 d2.utils.events]:  eta: 0:16:28  iter: 7639  total_loss: 3.189  loss_sem_seg: 1.596  loss_center: 0.6357  loss_offset: 0.8452  time: 0.4186  data_time: 0.0262  lr: 0.00068191  max_mem: 9415M
[12/10 03:15:22 d2.utils.events]:  eta: 0:16:20  iter: 7659  total_loss: 3.362  loss_sem_seg: 1.707  loss_center: 0.6789  loss_offset: 0.9925  time: 0.4186  data_time: 0.0246  lr: 0.00067671  max_mem: 9415M
[12/10 03:15:30 d2.utils.events]:  eta: 0:16:11  iter: 7679  total_loss: 3.233  loss_sem_seg: 1.867  loss_center: 0.7006  loss_offset: 0.8271  time: 0.4186  data_time: 0.0255  lr: 0.0006715  max_mem: 9415M
[12/10 03:15:38 d2.utils.events]:  eta: 0:16:03  iter: 7699  total_loss: 3.183  loss_sem_seg: 1.576  loss_center: 0.6912  loss_offset: 0.7913  time: 0.4186  data_time: 0.0256  lr: 0.00066629  max_mem: 9415M
[12/10 03:15:47 d2.utils.events]:  eta: 0:15:54  iter: 7719  total_loss: 3.082  loss_sem_seg: 1.51  loss_center: 0.6788  loss_offset: 0.7942  time: 0.4186  data_time: 0.0256  lr: 0.00066108  max_mem: 9415M
[12/10 03:15:55 d2.utils.events]:  eta: 0:15:46  iter: 7739  total_loss: 3.12  loss_sem_seg: 1.692  loss_center: 0.6055  loss_offset: 0.7706  time: 0.4186  data_time: 0.0259  lr: 0.00065586  max_mem: 9415M
[12/10 03:16:04 d2.utils.events]:  eta: 0:15:38  iter: 7759  total_loss: 3.397  loss_sem_seg: 1.7  loss_center: 0.6145  loss_offset: 0.8885  time: 0.4186  data_time: 0.0264  lr: 0.00065064  max_mem: 9415M
[12/10 03:16:12 d2.utils.events]:  eta: 0:15:29  iter: 7779  total_loss: 3.21  loss_sem_seg: 1.659  loss_center: 0.681  loss_offset: 0.8848  time: 0.4186  data_time: 0.0268  lr: 0.00064541  max_mem: 9415M
[12/10 03:16:20 d2.utils.events]:  eta: 0:15:21  iter: 7799  total_loss: 3.409  loss_sem_seg: 1.836  loss_center: 0.6375  loss_offset: 0.9349  time: 0.4186  data_time: 0.0261  lr: 0.00064017  max_mem: 9415M
[12/10 03:16:29 d2.utils.events]:  eta: 0:15:12  iter: 7819  total_loss: 3.027  loss_sem_seg: 1.626  loss_center: 0.5188  loss_offset: 0.802  time: 0.4186  data_time: 0.0251  lr: 0.00063494  max_mem: 9415M
[12/10 03:16:37 d2.utils.events]:  eta: 0:15:04  iter: 7839  total_loss: 3.308  loss_sem_seg: 1.754  loss_center: 0.6955  loss_offset: 0.8679  time: 0.4186  data_time: 0.0268  lr: 0.00062969  max_mem: 9415M
[12/10 03:16:45 d2.utils.events]:  eta: 0:14:56  iter: 7859  total_loss: 3.201  loss_sem_seg: 1.672  loss_center: 0.6197  loss_offset: 0.9438  time: 0.4186  data_time: 0.0257  lr: 0.00062445  max_mem: 9415M
[12/10 03:16:54 d2.utils.events]:  eta: 0:14:47  iter: 7879  total_loss: 3.328  loss_sem_seg: 1.848  loss_center: 0.6552  loss_offset: 0.9195  time: 0.4186  data_time: 0.0269  lr: 0.00061919  max_mem: 9415M
[12/10 03:17:02 d2.utils.events]:  eta: 0:14:39  iter: 7899  total_loss: 3.204  loss_sem_seg: 1.723  loss_center: 0.6055  loss_offset: 0.8447  time: 0.4186  data_time: 0.0263  lr: 0.00061394  max_mem: 9415M
[12/10 03:17:11 d2.utils.events]:  eta: 0:14:30  iter: 7919  total_loss: 3.127  loss_sem_seg: 1.565  loss_center: 0.65  loss_offset: 0.8196  time: 0.4186  data_time: 0.0260  lr: 0.00060867  max_mem: 9415M
[12/10 03:17:19 d2.utils.events]:  eta: 0:14:22  iter: 7939  total_loss: 2.962  loss_sem_seg: 1.503  loss_center: 0.5906  loss_offset: 0.8487  time: 0.4186  data_time: 0.0263  lr: 0.00060341  max_mem: 9415M
[12/10 03:17:27 d2.utils.events]:  eta: 0:14:13  iter: 7959  total_loss: 3.27  loss_sem_seg: 1.674  loss_center: 0.7366  loss_offset: 0.8159  time: 0.4186  data_time: 0.0262  lr: 0.00059813  max_mem: 9415M
[12/10 03:17:36 d2.utils.events]:  eta: 0:14:05  iter: 7979  total_loss: 3.028  loss_sem_seg: 1.608  loss_center: 0.6387  loss_offset: 0.8227  time: 0.4186  data_time: 0.0276  lr: 0.00059286  max_mem: 9415M
[12/10 03:17:44 d2.utils.events]:  eta: 0:13:57  iter: 7999  total_loss: 3.163  loss_sem_seg: 1.696  loss_center: 0.6066  loss_offset: 0.8612  time: 0.4186  data_time: 0.0270  lr: 0.00058757  max_mem: 9415M
[12/10 03:17:53 d2.utils.events]:  eta: 0:13:49  iter: 8019  total_loss: 3.038  loss_sem_seg: 1.444  loss_center: 0.739  loss_offset: 0.7354  time: 0.4186  data_time: 0.0284  lr: 0.00058229  max_mem: 9415M
[12/10 03:18:01 d2.utils.events]:  eta: 0:13:40  iter: 8039  total_loss: 3.163  loss_sem_seg: 1.598  loss_center: 0.6833  loss_offset: 0.7994  time: 0.4186  data_time: 0.0271  lr: 0.00057699  max_mem: 9415M
[12/10 03:18:10 d2.utils.events]:  eta: 0:13:32  iter: 8059  total_loss: 3.457  loss_sem_seg: 1.798  loss_center: 0.7068  loss_offset: 0.7716  time: 0.4186  data_time: 0.0264  lr: 0.00057169  max_mem: 9415M
[12/10 03:18:18 d2.utils.events]:  eta: 0:13:24  iter: 8079  total_loss: 2.923  loss_sem_seg: 1.407  loss_center: 0.7523  loss_offset: 0.7887  time: 0.4187  data_time: 0.0282  lr: 0.00056639  max_mem: 9415M
[12/10 03:18:27 d2.utils.events]:  eta: 0:13:15  iter: 8099  total_loss: 2.985  loss_sem_seg: 1.52  loss_center: 0.5473  loss_offset: 0.8344  time: 0.4187  data_time: 0.0281  lr: 0.00056108  max_mem: 9415M
[12/10 03:18:35 d2.utils.events]:  eta: 0:13:07  iter: 8119  total_loss: 2.851  loss_sem_seg: 1.408  loss_center: 0.6092  loss_offset: 0.7806  time: 0.4187  data_time: 0.0279  lr: 0.00055576  max_mem: 9415M
[12/10 03:18:43 d2.utils.events]:  eta: 0:12:59  iter: 8139  total_loss: 3.2  loss_sem_seg: 1.833  loss_center: 0.6001  loss_offset: 0.8533  time: 0.4187  data_time: 0.0290  lr: 0.00055044  max_mem: 9415M
[12/10 03:18:52 d2.utils.events]:  eta: 0:12:51  iter: 8159  total_loss: 3.014  loss_sem_seg: 1.733  loss_center: 0.5818  loss_offset: 0.8181  time: 0.4187  data_time: 0.0269  lr: 0.00054512  max_mem: 9415M
[12/10 03:19:00 d2.utils.events]:  eta: 0:12:43  iter: 8179  total_loss: 3.147  loss_sem_seg: 1.51  loss_center: 0.5976  loss_offset: 0.9455  time: 0.4187  data_time: 0.0269  lr: 0.00053978  max_mem: 9415M
[12/10 03:19:09 d2.utils.events]:  eta: 0:12:34  iter: 8199  total_loss: 3.371  loss_sem_seg: 1.715  loss_center: 0.6675  loss_offset: 0.8728  time: 0.4187  data_time: 0.0272  lr: 0.00053444  max_mem: 9415M
[12/10 03:19:17 d2.utils.events]:  eta: 0:12:26  iter: 8219  total_loss: 3.219  loss_sem_seg: 1.51  loss_center: 0.7291  loss_offset: 0.808  time: 0.4187  data_time: 0.0255  lr: 0.0005291  max_mem: 9415M
[12/10 03:19:26 d2.utils.events]:  eta: 0:12:18  iter: 8239  total_loss: 3.17  loss_sem_seg: 1.67  loss_center: 0.7418  loss_offset: 0.7674  time: 0.4187  data_time: 0.0270  lr: 0.00052375  max_mem: 9415M
[12/10 03:19:34 d2.utils.events]:  eta: 0:12:09  iter: 8259  total_loss: 3.21  loss_sem_seg: 1.641  loss_center: 0.6725  loss_offset: 0.8681  time: 0.4187  data_time: 0.0282  lr: 0.00051839  max_mem: 9415M
[12/10 03:19:42 d2.utils.events]:  eta: 0:12:01  iter: 8279  total_loss: 3.228  loss_sem_seg: 1.572  loss_center: 0.5578  loss_offset: 0.8039  time: 0.4187  data_time: 0.0267  lr: 0.00051303  max_mem: 9415M
[12/10 03:19:51 d2.utils.events]:  eta: 0:11:53  iter: 8299  total_loss: 3.312  loss_sem_seg: 1.592  loss_center: 0.6786  loss_offset: 0.8302  time: 0.4187  data_time: 0.0276  lr: 0.00050766  max_mem: 9415M
[12/10 03:19:59 d2.utils.events]:  eta: 0:11:45  iter: 8319  total_loss: 3.394  loss_sem_seg: 1.87  loss_center: 0.6261  loss_offset: 0.8466  time: 0.4187  data_time: 0.0269  lr: 0.00050229  max_mem: 9415M
[12/10 03:20:08 d2.utils.events]:  eta: 0:11:36  iter: 8339  total_loss: 3.276  loss_sem_seg: 1.545  loss_center: 0.6157  loss_offset: 0.786  time: 0.4187  data_time: 0.0276  lr: 0.0004969  max_mem: 9415M
[12/10 03:20:16 d2.utils.events]:  eta: 0:11:28  iter: 8359  total_loss: 3.143  loss_sem_seg: 1.487  loss_center: 0.8223  loss_offset: 0.7409  time: 0.4188  data_time: 0.0280  lr: 0.00049152  max_mem: 9415M
[12/10 03:20:25 d2.utils.events]:  eta: 0:11:20  iter: 8379  total_loss: 3.123  loss_sem_seg: 1.776  loss_center: 0.64  loss_offset: 0.8782  time: 0.4188  data_time: 0.0288  lr: 0.00048612  max_mem: 9415M
[12/10 03:20:33 d2.utils.events]:  eta: 0:11:11  iter: 8399  total_loss: 3.227  loss_sem_seg: 1.619  loss_center: 0.591  loss_offset: 0.7932  time: 0.4188  data_time: 0.0270  lr: 0.00048072  max_mem: 9415M
[12/10 03:20:42 d2.utils.events]:  eta: 0:11:03  iter: 8419  total_loss: 2.884  loss_sem_seg: 1.403  loss_center: 0.6601  loss_offset: 0.6889  time: 0.4188  data_time: 0.0257  lr: 0.00047531  max_mem: 9415M
[12/10 03:20:50 d2.utils.events]:  eta: 0:10:55  iter: 8439  total_loss: 3.056  loss_sem_seg: 1.494  loss_center: 0.6633  loss_offset: 0.8278  time: 0.4188  data_time: 0.0270  lr: 0.0004699  max_mem: 9415M
[12/10 03:20:59 d2.utils.events]:  eta: 0:10:46  iter: 8459  total_loss: 2.753  loss_sem_seg: 1.447  loss_center: 0.7007  loss_offset: 0.839  time: 0.4188  data_time: 0.0280  lr: 0.00046448  max_mem: 9415M
[12/10 03:21:07 d2.utils.events]:  eta: 0:10:38  iter: 8479  total_loss: 3.012  loss_sem_seg: 1.516  loss_center: 0.782  loss_offset: 0.8591  time: 0.4188  data_time: 0.0269  lr: 0.00045905  max_mem: 9415M
[12/10 03:21:16 d2.utils.events]:  eta: 0:10:30  iter: 8499  total_loss: 2.976  loss_sem_seg: 1.568  loss_center: 0.569  loss_offset: 0.8052  time: 0.4188  data_time: 0.0288  lr: 0.00045361  max_mem: 9415M
[12/10 03:21:24 d2.utils.events]:  eta: 0:10:22  iter: 8519  total_loss: 3.103  loss_sem_seg: 1.619  loss_center: 0.7773  loss_offset: 0.7503  time: 0.4188  data_time: 0.0275  lr: 0.00044817  max_mem: 9415M
[12/10 03:21:32 d2.utils.events]:  eta: 0:10:13  iter: 8539  total_loss: 2.979  loss_sem_seg: 1.495  loss_center: 0.6527  loss_offset: 0.7444  time: 0.4188  data_time: 0.0277  lr: 0.00044272  max_mem: 9415M
[12/10 03:21:41 d2.utils.events]:  eta: 0:10:05  iter: 8559  total_loss: 3.24  loss_sem_seg: 1.668  loss_center: 0.5584  loss_offset: 0.8281  time: 0.4188  data_time: 0.0260  lr: 0.00043726  max_mem: 9415M
[12/10 03:21:49 d2.utils.events]:  eta: 0:09:56  iter: 8579  total_loss: 3.056  loss_sem_seg: 1.587  loss_center: 0.5549  loss_offset: 0.8188  time: 0.4188  data_time: 0.0278  lr: 0.00043179  max_mem: 9415M
[12/10 03:21:58 d2.utils.events]:  eta: 0:09:48  iter: 8599  total_loss: 3.314  loss_sem_seg: 1.68  loss_center: 0.6828  loss_offset: 0.7927  time: 0.4188  data_time: 0.0302  lr: 0.00042632  max_mem: 9415M
[12/10 03:22:06 d2.utils.events]:  eta: 0:09:40  iter: 8619  total_loss: 3.12  loss_sem_seg: 1.589  loss_center: 0.615  loss_offset: 0.8489  time: 0.4189  data_time: 0.0265  lr: 0.00042084  max_mem: 9415M
[12/10 03:22:15 d2.utils.events]:  eta: 0:09:32  iter: 8639  total_loss: 3.106  loss_sem_seg: 1.592  loss_center: 0.4854  loss_offset: 0.8286  time: 0.4189  data_time: 0.0280  lr: 0.00041535  max_mem: 9415M
[12/10 03:22:23 d2.utils.events]:  eta: 0:09:23  iter: 8659  total_loss: 2.936  loss_sem_seg: 1.538  loss_center: 0.4981  loss_offset: 0.8305  time: 0.4189  data_time: 0.0275  lr: 0.00040985  max_mem: 9415M
[12/10 03:22:32 d2.utils.events]:  eta: 0:09:15  iter: 8679  total_loss: 3.208  loss_sem_seg: 1.576  loss_center: 0.6769  loss_offset: 0.8373  time: 0.4189  data_time: 0.0288  lr: 0.00040435  max_mem: 9415M
[12/10 03:22:40 d2.utils.events]:  eta: 0:09:07  iter: 8699  total_loss: 3.227  loss_sem_seg: 1.619  loss_center: 0.6267  loss_offset: 0.8945  time: 0.4189  data_time: 0.0289  lr: 0.00039883  max_mem: 9415M
[12/10 03:22:49 d2.utils.events]:  eta: 0:08:58  iter: 8719  total_loss: 3.16  loss_sem_seg: 1.826  loss_center: 0.5572  loss_offset: 0.7665  time: 0.4189  data_time: 0.0265  lr: 0.00039331  max_mem: 9415M
[12/10 03:22:57 d2.utils.events]:  eta: 0:08:50  iter: 8739  total_loss: 3.153  loss_sem_seg: 1.575  loss_center: 0.6768  loss_offset: 0.8367  time: 0.4189  data_time: 0.0288  lr: 0.00038778  max_mem: 9415M
[12/10 03:23:06 d2.utils.events]:  eta: 0:08:42  iter: 8759  total_loss: 3.036  loss_sem_seg: 1.602  loss_center: 0.6296  loss_offset: 0.7521  time: 0.4189  data_time: 0.0281  lr: 0.00038224  max_mem: 9415M
[12/10 03:23:14 d2.utils.events]:  eta: 0:08:33  iter: 8779  total_loss: 3.251  loss_sem_seg: 1.674  loss_center: 0.6472  loss_offset: 0.8315  time: 0.4190  data_time: 0.0300  lr: 0.00037669  max_mem: 9415M
[12/10 03:23:23 d2.utils.events]:  eta: 0:08:25  iter: 8799  total_loss: 3.044  loss_sem_seg: 1.59  loss_center: 0.4941  loss_offset: 0.8538  time: 0.4190  data_time: 0.0319  lr: 0.00037113  max_mem: 9415M
[12/10 03:23:31 d2.utils.events]:  eta: 0:08:17  iter: 8819  total_loss: 3.272  loss_sem_seg: 1.737  loss_center: 0.5984  loss_offset: 0.7968  time: 0.4190  data_time: 0.0280  lr: 0.00036557  max_mem: 9415M
[12/10 03:23:40 d2.utils.events]:  eta: 0:08:09  iter: 8839  total_loss: 3.03  loss_sem_seg: 1.571  loss_center: 0.6239  loss_offset: 0.8181  time: 0.4190  data_time: 0.0270  lr: 0.00035999  max_mem: 9415M
[12/10 03:23:48 d2.utils.events]:  eta: 0:08:00  iter: 8859  total_loss: 3.178  loss_sem_seg: 1.641  loss_center: 0.6863  loss_offset: 0.78  time: 0.4190  data_time: 0.0278  lr: 0.0003544  max_mem: 9415M
[12/10 03:23:57 d2.utils.events]:  eta: 0:07:52  iter: 8879  total_loss: 2.841  loss_sem_seg: 1.51  loss_center: 0.6307  loss_offset: 0.6521  time: 0.4190  data_time: 0.0280  lr: 0.00034881  max_mem: 9415M
[12/10 03:24:05 d2.utils.events]:  eta: 0:07:44  iter: 8899  total_loss: 2.942  loss_sem_seg: 1.588  loss_center: 0.544  loss_offset: 0.7858  time: 0.4190  data_time: 0.0289  lr: 0.0003432  max_mem: 9415M
[12/10 03:24:14 d2.utils.events]:  eta: 0:07:35  iter: 8919  total_loss: 3.026  loss_sem_seg: 1.529  loss_center: 0.7002  loss_offset: 0.8061  time: 0.4190  data_time: 0.0281  lr: 0.00033758  max_mem: 9415M
[12/10 03:24:22 d2.utils.events]:  eta: 0:07:27  iter: 8939  total_loss: 3.321  loss_sem_seg: 1.723  loss_center: 0.6408  loss_offset: 0.9376  time: 0.4190  data_time: 0.0284  lr: 0.00033196  max_mem: 9415M
[12/10 03:24:31 d2.utils.events]:  eta: 0:07:18  iter: 8959  total_loss: 3.113  loss_sem_seg: 1.605  loss_center: 0.6443  loss_offset: 0.838  time: 0.4191  data_time: 0.0290  lr: 0.00032632  max_mem: 9415M
[12/10 03:24:39 d2.utils.events]:  eta: 0:07:10  iter: 8979  total_loss: 3.273  loss_sem_seg: 1.542  loss_center: 0.7259  loss_offset: 0.7702  time: 0.4191  data_time: 0.0266  lr: 0.00032067  max_mem: 9415M
[12/10 03:24:48 d2.utils.events]:  eta: 0:07:02  iter: 8999  total_loss: 2.712  loss_sem_seg: 1.338  loss_center: 0.5422  loss_offset: 0.6996  time: 0.4191  data_time: 0.0287  lr: 0.00031501  max_mem: 9415M
[12/10 03:24:56 d2.utils.events]:  eta: 0:06:53  iter: 9019  total_loss: 3.162  loss_sem_seg: 1.482  loss_center: 0.749  loss_offset: 0.8501  time: 0.4191  data_time: 0.0266  lr: 0.00030934  max_mem: 9415M
[12/10 03:25:05 d2.utils.events]:  eta: 0:06:45  iter: 9039  total_loss: 3.01  loss_sem_seg: 1.543  loss_center: 0.6887  loss_offset: 0.8658  time: 0.4191  data_time: 0.0282  lr: 0.00030366  max_mem: 9415M
[12/10 03:25:13 d2.utils.events]:  eta: 0:06:36  iter: 9059  total_loss: 2.989  loss_sem_seg: 1.559  loss_center: 0.6636  loss_offset: 0.7327  time: 0.4191  data_time: 0.0290  lr: 0.00029797  max_mem: 9415M
[12/10 03:25:22 d2.utils.events]:  eta: 0:06:28  iter: 9079  total_loss: 3.093  loss_sem_seg: 1.429  loss_center: 0.7099  loss_offset: 0.8502  time: 0.4191  data_time: 0.0286  lr: 0.00029226  max_mem: 9415M
[12/10 03:25:30 d2.utils.events]:  eta: 0:06:20  iter: 9099  total_loss: 3.196  loss_sem_seg: 1.503  loss_center: 0.629  loss_offset: 0.786  time: 0.4191  data_time: 0.0275  lr: 0.00028654  max_mem: 9415M
[12/10 03:25:39 d2.utils.events]:  eta: 0:06:11  iter: 9119  total_loss: 2.866  loss_sem_seg: 1.581  loss_center: 0.5959  loss_offset: 0.8658  time: 0.4191  data_time: 0.0284  lr: 0.00028081  max_mem: 9415M
[12/10 03:25:47 d2.utils.events]:  eta: 0:06:03  iter: 9139  total_loss: 3.266  loss_sem_seg: 1.642  loss_center: 0.6735  loss_offset: 0.8074  time: 0.4191  data_time: 0.0285  lr: 0.00027507  max_mem: 9415M
[12/10 03:25:56 d2.utils.events]:  eta: 0:05:54  iter: 9159  total_loss: 2.95  loss_sem_seg: 1.562  loss_center: 0.5738  loss_offset: 0.7375  time: 0.4191  data_time: 0.0267  lr: 0.00026931  max_mem: 9415M
[12/10 03:26:04 d2.utils.events]:  eta: 0:05:46  iter: 9179  total_loss: 3.281  loss_sem_seg: 1.657  loss_center: 0.8154  loss_offset: 0.8134  time: 0.4192  data_time: 0.0280  lr: 0.00026354  max_mem: 9415M
[12/10 03:26:13 d2.utils.events]:  eta: 0:05:38  iter: 9199  total_loss: 3.113  loss_sem_seg: 1.631  loss_center: 0.7063  loss_offset: 0.8748  time: 0.4192  data_time: 0.0271  lr: 0.00025776  max_mem: 9415M
[12/10 03:26:21 d2.utils.events]:  eta: 0:05:29  iter: 9219  total_loss: 3.206  loss_sem_seg: 1.59  loss_center: 0.7298  loss_offset: 0.8186  time: 0.4192  data_time: 0.0269  lr: 0.00025196  max_mem: 9415M
[12/10 03:26:29 d2.utils.events]:  eta: 0:05:21  iter: 9239  total_loss: 2.859  loss_sem_seg: 1.458  loss_center: 0.658  loss_offset: 0.8296  time: 0.4192  data_time: 0.0266  lr: 0.00024614  max_mem: 9415M
[12/10 03:26:38 d2.utils.events]:  eta: 0:05:12  iter: 9259  total_loss: 3.074  loss_sem_seg: 1.73  loss_center: 0.6632  loss_offset: 0.7646  time: 0.4192  data_time: 0.0294  lr: 0.00024031  max_mem: 9415M
[12/10 03:26:46 d2.utils.events]:  eta: 0:05:04  iter: 9279  total_loss: 3.195  loss_sem_seg: 1.529  loss_center: 0.6756  loss_offset: 0.8881  time: 0.4192  data_time: 0.0278  lr: 0.00023447  max_mem: 9415M
[12/10 03:26:55 d2.utils.events]:  eta: 0:04:55  iter: 9299  total_loss: 3.022  loss_sem_seg: 1.566  loss_center: 0.6001  loss_offset: 0.7349  time: 0.4192  data_time: 0.0274  lr: 0.00022861  max_mem: 9415M
[12/10 03:27:03 d2.utils.events]:  eta: 0:04:47  iter: 9319  total_loss: 2.839  loss_sem_seg: 1.377  loss_center: 0.6855  loss_offset: 0.6682  time: 0.4192  data_time: 0.0263  lr: 0.00022273  max_mem: 9415M
[12/10 03:27:12 d2.utils.events]:  eta: 0:04:39  iter: 9339  total_loss: 3.229  loss_sem_seg: 1.715  loss_center: 0.5875  loss_offset: 0.8759  time: 0.4192  data_time: 0.0272  lr: 0.00021683  max_mem: 9415M
[12/10 03:27:20 d2.utils.events]:  eta: 0:04:30  iter: 9359  total_loss: 3.008  loss_sem_seg: 1.467  loss_center: 0.6876  loss_offset: 0.8297  time: 0.4192  data_time: 0.0269  lr: 0.00021092  max_mem: 9415M
[12/10 03:27:28 d2.utils.events]:  eta: 0:04:21  iter: 9379  total_loss: 3.063  loss_sem_seg: 1.364  loss_center: 0.6307  loss_offset: 0.9111  time: 0.4192  data_time: 0.0272  lr: 0.00020499  max_mem: 9415M
[12/10 03:27:37 d2.utils.events]:  eta: 0:04:13  iter: 9399  total_loss: 3.009  loss_sem_seg: 1.44  loss_center: 0.7289  loss_offset: 0.7395  time: 0.4192  data_time: 0.0261  lr: 0.00019903  max_mem: 9415M
[12/10 03:27:45 d2.utils.events]:  eta: 0:04:04  iter: 9419  total_loss: 3.078  loss_sem_seg: 1.561  loss_center: 0.7898  loss_offset: 0.8188  time: 0.4192  data_time: 0.0272  lr: 0.00019306  max_mem: 9415M
[12/10 03:27:54 d2.utils.events]:  eta: 0:03:56  iter: 9439  total_loss: 3.061  loss_sem_seg: 1.425  loss_center: 0.7212  loss_offset: 0.8722  time: 0.4192  data_time: 0.0253  lr: 0.00018707  max_mem: 9415M
[12/10 03:28:02 d2.utils.events]:  eta: 0:03:48  iter: 9459  total_loss: 2.958  loss_sem_seg: 1.502  loss_center: 0.5785  loss_offset: 0.7475  time: 0.4192  data_time: 0.0272  lr: 0.00018106  max_mem: 9415M
[12/10 03:28:11 d2.utils.events]:  eta: 0:03:39  iter: 9479  total_loss: 3.135  loss_sem_seg: 1.666  loss_center: 0.5391  loss_offset: 0.8792  time: 0.4192  data_time: 0.0299  lr: 0.00017502  max_mem: 9415M
[12/10 03:28:19 d2.utils.events]:  eta: 0:03:31  iter: 9499  total_loss: 2.986  loss_sem_seg: 1.47  loss_center: 0.5996  loss_offset: 0.7616  time: 0.4192  data_time: 0.0269  lr: 0.00016896  max_mem: 9415M
[12/10 03:28:28 d2.utils.events]:  eta: 0:03:22  iter: 9519  total_loss: 2.491  loss_sem_seg: 1.253  loss_center: 0.5427  loss_offset: 0.657  time: 0.4192  data_time: 0.0280  lr: 0.00016288  max_mem: 9415M
[12/10 03:28:36 d2.utils.events]:  eta: 0:03:13  iter: 9539  total_loss: 3.056  loss_sem_seg: 1.511  loss_center: 0.6303  loss_offset: 0.7763  time: 0.4192  data_time: 0.0254  lr: 0.00015677  max_mem: 9415M
[12/10 03:28:44 d2.utils.events]:  eta: 0:03:05  iter: 9559  total_loss: 2.892  loss_sem_seg: 1.464  loss_center: 0.6109  loss_offset: 0.8083  time: 0.4192  data_time: 0.0276  lr: 0.00015064  max_mem: 9415M
[12/10 03:28:53 d2.utils.events]:  eta: 0:02:57  iter: 9579  total_loss: 3.157  loss_sem_seg: 1.655  loss_center: 0.672  loss_offset: 0.8184  time: 0.4193  data_time: 0.0272  lr: 0.00014448  max_mem: 9415M
[12/10 03:29:01 d2.utils.events]:  eta: 0:02:48  iter: 9599  total_loss: 3.174  loss_sem_seg: 1.569  loss_center: 0.6144  loss_offset: 0.7976  time: 0.4193  data_time: 0.0263  lr: 0.00013828  max_mem: 9415M
[12/10 03:29:10 d2.utils.events]:  eta: 0:02:40  iter: 9619  total_loss: 2.841  loss_sem_seg: 1.507  loss_center: 0.4914  loss_offset: 0.6334  time: 0.4193  data_time: 0.0254  lr: 0.00013206  max_mem: 9415M
[12/10 03:29:18 d2.utils.events]:  eta: 0:02:31  iter: 9639  total_loss: 3.001  loss_sem_seg: 1.67  loss_center: 0.6755  loss_offset: 0.7643  time: 0.4193  data_time: 0.0276  lr: 0.0001258  max_mem: 9415M
[12/10 03:29:27 d2.utils.events]:  eta: 0:02:23  iter: 9659  total_loss: 2.941  loss_sem_seg: 1.479  loss_center: 0.6956  loss_offset: 0.7676  time: 0.4193  data_time: 0.0268  lr: 0.00011951  max_mem: 9415M
[12/10 03:29:35 d2.utils.events]:  eta: 0:02:14  iter: 9679  total_loss: 2.861  loss_sem_seg: 1.607  loss_center: 0.5169  loss_offset: 0.7361  time: 0.4193  data_time: 0.0285  lr: 0.00011319  max_mem: 9415M
[12/10 03:29:43 d2.utils.events]:  eta: 0:02:06  iter: 9699  total_loss: 3.004  loss_sem_seg: 1.637  loss_center: 0.6327  loss_offset: 0.7963  time: 0.4193  data_time: 0.0264  lr: 0.00010682  max_mem: 9415M
[12/10 03:29:52 d2.utils.events]:  eta: 0:01:58  iter: 9719  total_loss: 3.012  loss_sem_seg: 1.67  loss_center: 0.4888  loss_offset: 0.7948  time: 0.4193  data_time: 0.0273  lr: 0.00010041  max_mem: 9415M
[12/10 03:30:00 d2.utils.events]:  eta: 0:01:49  iter: 9739  total_loss: 2.992  loss_sem_seg: 1.541  loss_center: 0.6049  loss_offset: 0.8146  time: 0.4193  data_time: 0.0260  lr: 9.3954e-05  max_mem: 9415M
[12/10 03:30:09 d2.utils.events]:  eta: 0:01:41  iter: 9759  total_loss: 2.848  loss_sem_seg: 1.354  loss_center: 0.7264  loss_offset: 0.7433  time: 0.4193  data_time: 0.0277  lr: 8.7449e-05  max_mem: 9415M
[12/10 03:30:17 d2.utils.events]:  eta: 0:01:32  iter: 9779  total_loss: 3.112  loss_sem_seg: 1.459  loss_center: 0.6291  loss_offset: 0.7341  time: 0.4193  data_time: 0.0251  lr: 8.089e-05  max_mem: 9415M
[12/10 03:30:26 d2.utils.events]:  eta: 0:01:24  iter: 9799  total_loss: 3.099  loss_sem_seg: 1.424  loss_center: 0.7213  loss_offset: 0.7584  time: 0.4193  data_time: 0.0259  lr: 7.4271e-05  max_mem: 9415M
[12/10 03:30:34 d2.utils.events]:  eta: 0:01:15  iter: 9819  total_loss: 3.12  loss_sem_seg: 1.555  loss_center: 0.6871  loss_offset: 0.7822  time: 0.4193  data_time: 0.0252  lr: 6.7585e-05  max_mem: 9415M
[12/10 03:30:42 d2.utils.events]:  eta: 0:01:07  iter: 9839  total_loss: 3.086  loss_sem_seg: 1.426  loss_center: 0.6819  loss_offset: 0.7326  time: 0.4193  data_time: 0.0264  lr: 6.0825e-05  max_mem: 9415M
[12/10 03:30:51 d2.utils.events]:  eta: 0:00:58  iter: 9859  total_loss: 2.876  loss_sem_seg: 1.529  loss_center: 0.6201  loss_offset: 0.7637  time: 0.4193  data_time: 0.0260  lr: 5.3981e-05  max_mem: 9415M
[12/10 03:30:59 d2.utils.events]:  eta: 0:00:50  iter: 9879  total_loss: 2.783  loss_sem_seg: 1.408  loss_center: 0.4824  loss_offset: 0.6074  time: 0.4193  data_time: 0.0253  lr: 4.7038e-05  max_mem: 9415M
[12/10 03:31:08 d2.utils.events]:  eta: 0:00:42  iter: 9899  total_loss: 3.104  loss_sem_seg: 1.514  loss_center: 0.702  loss_offset: 0.7991  time: 0.4193  data_time: 0.0288  lr: 3.9979e-05  max_mem: 9415M
[12/10 03:31:16 d2.utils.events]:  eta: 0:00:33  iter: 9919  total_loss: 3.377  loss_sem_seg: 1.595  loss_center: 0.6949  loss_offset: 0.8191  time: 0.4193  data_time: 0.0262  lr: 3.2778e-05  max_mem: 9415M
[12/10 03:31:25 d2.utils.events]:  eta: 0:00:25  iter: 9939  total_loss: 3.036  loss_sem_seg: 1.626  loss_center: 0.6742  loss_offset: 0.7026  time: 0.4193  data_time: 0.0275  lr: 2.5394e-05  max_mem: 9415M
[12/10 03:31:33 d2.utils.events]:  eta: 0:00:16  iter: 9959  total_loss: 2.907  loss_sem_seg: 1.529  loss_center: 0.6393  loss_offset: 0.7098  time: 0.4193  data_time: 0.0259  lr: 1.776e-05  max_mem: 9415M
[12/10 03:31:41 d2.utils.events]:  eta: 0:00:08  iter: 9979  total_loss: 3.239  loss_sem_seg: 1.643  loss_center: 0.6889  loss_offset: 0.701  time: 0.4193  data_time: 0.0257  lr: 9.7261e-06  max_mem: 9415M
[12/10 03:31:50 fvcore.common.checkpoint]: Saving checkpoint to ./output/model_0009999.pth
[12/10 03:31:50 fvcore.common.checkpoint]: Saving checkpoint to ./output/model_final.pth
[12/10 03:31:51 d2.utils.events]:  eta: 0:00:00  iter: 9999  total_loss: 2.962  loss_sem_seg: 1.443  loss_center: 0.6146  loss_offset: 0.6913  time: 0.4193  data_time: 0.0295  lr: 6.2797e-07  max_mem: 9415M
[12/10 03:31:52 d2.engine.hooks]: Overall training speed: 9998 iterations in 1:09:52 (0.4193 s / it)
[12/10 03:31:52 d2.engine.hooks]: Total training time: 1:10:01 (0:00:09 on hooks)
[12/10 03:31:52 d2.data.dataset_mapper]: [DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(640, 640), max_size=640, sample_style='choice')]
[12/10 03:31:52 d2.data.common]: Serializing the dataset using: <class 'detectron2.data.common.NumpySerializedList'>
[12/10 03:31:52 d2.data.common]: Serializing 5000 elements to byte tensors and concatenating them all ...
[12/10 03:31:52 d2.data.common]: Serialized dataset takes 3.40 MiB
/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:481: UserWarning: This DataLoader will create 10 worker processes in total. Our suggested max number of worker in current system is 8, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.
  cpuset_checked))
[12/10 03:31:53 d2.evaluation.evaluator]: Start inference on 5000 batches
/usr/local/lib/python3.7/dist-packages/torch/functional.py:445: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at  ../aten/src/ATen/native/TensorShape.cpp:2157.)
  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]
[12/10 03:31:55 d2.evaluation.evaluator]: Inference done 11/5000. Dataloading: 0.0006 s/iter. Inference: 0.0563 s/iter. Eval: 0.0379 s/iter. Total: 0.0948 s/iter. ETA=0:07:52
[12/10 03:32:00 d2.evaluation.evaluator]: Inference done 69/5000. Dataloading: 0.0011 s/iter. Inference: 0.0538 s/iter. Eval: 0.0329 s/iter. Total: 0.0878 s/iter. ETA=0:07:12
[12/10 03:32:05 d2.evaluation.evaluator]: Inference done 123/5000. Dataloading: 0.0012 s/iter. Inference: 0.0544 s/iter. Eval: 0.0350 s/iter. Total: 0.0906 s/iter. ETA=0:07:21
[12/10 03:32:10 d2.evaluation.evaluator]: Inference done 176/5000. Dataloading: 0.0012 s/iter. Inference: 0.0552 s/iter. Eval: 0.0355 s/iter. Total: 0.0919 s/iter. ETA=0:07:23
[12/10 03:32:15 d2.evaluation.evaluator]: Inference done 233/5000. Dataloading: 0.0012 s/iter. Inference: 0.0548 s/iter. Eval: 0.0351 s/iter. Total: 0.0911 s/iter. ETA=0:07:14
[12/10 03:32:20 d2.evaluation.evaluator]: Inference done 287/5000. Dataloading: 0.0012 s/iter. Inference: 0.0550 s/iter. Eval: 0.0352 s/iter. Total: 0.0915 s/iter. ETA=0:07:11
[12/10 03:32:25 d2.evaluation.evaluator]: Inference done 342/5000. Dataloading: 0.0012 s/iter. Inference: 0.0551 s/iter. Eval: 0.0353 s/iter. Total: 0.0916 s/iter. ETA=0:07:06
[12/10 03:32:30 d2.evaluation.evaluator]: Inference done 398/5000. Dataloading: 0.0012 s/iter. Inference: 0.0550 s/iter. Eval: 0.0352 s/iter. Total: 0.0914 s/iter. ETA=0:07:00
[12/10 03:32:35 d2.evaluation.evaluator]: Inference done 456/5000. Dataloading: 0.0012 s/iter. Inference: 0.0547 s/iter. Eval: 0.0350 s/iter. Total: 0.0909 s/iter. ETA=0:06:53
[12/10 03:32:40 d2.evaluation.evaluator]: Inference done 512/5000. Dataloading: 0.0012 s/iter. Inference: 0.0546 s/iter. Eval: 0.0349 s/iter. Total: 0.0908 s/iter. ETA=0:06:47
[12/10 03:32:45 d2.evaluation.evaluator]: Inference done 567/5000. Dataloading: 0.0012 s/iter. Inference: 0.0547 s/iter. Eval: 0.0349 s/iter. Total: 0.0908 s/iter. ETA=0:06:42
[12/10 03:32:50 d2.evaluation.evaluator]: Inference done 622/5000. Dataloading: 0.0012 s/iter. Inference: 0.0547 s/iter. Eval: 0.0350 s/iter. Total: 0.0910 s/iter. ETA=0:06:38
[12/10 03:32:55 d2.evaluation.evaluator]: Inference done 672/5000. Dataloading: 0.0012 s/iter. Inference: 0.0553 s/iter. Eval: 0.0352 s/iter. Total: 0.0918 s/iter. ETA=0:06:37
[12/10 03:33:01 d2.evaluation.evaluator]: Inference done 727/5000. Dataloading: 0.0012 s/iter. Inference: 0.0552 s/iter. Eval: 0.0353 s/iter. Total: 0.0918 s/iter. ETA=0:06:32
[12/10 03:33:06 d2.evaluation.evaluator]: Inference done 783/5000. Dataloading: 0.0012 s/iter. Inference: 0.0551 s/iter. Eval: 0.0353 s/iter. Total: 0.0917 s/iter. ETA=0:06:26
[12/10 03:33:11 d2.evaluation.evaluator]: Inference done 839/5000. Dataloading: 0.0012 s/iter. Inference: 0.0550 s/iter. Eval: 0.0353 s/iter. Total: 0.0915 s/iter. ETA=0:06:20
[12/10 03:33:16 d2.evaluation.evaluator]: Inference done 896/5000. Dataloading: 0.0012 s/iter. Inference: 0.0549 s/iter. Eval: 0.0351 s/iter. Total: 0.0913 s/iter. ETA=0:06:14
[12/10 03:33:21 d2.evaluation.evaluator]: Inference done 953/5000. Dataloading: 0.0012 s/iter. Inference: 0.0547 s/iter. Eval: 0.0351 s/iter. Total: 0.0911 s/iter. ETA=0:06:08
[12/10 03:33:26 d2.evaluation.evaluator]: Inference done 1009/5000. Dataloading: 0.0012 s/iter. Inference: 0.0547 s/iter. Eval: 0.0351 s/iter. Total: 0.0911 s/iter. ETA=0:06:03
[12/10 03:33:31 d2.evaluation.evaluator]: Inference done 1065/5000. Dataloading: 0.0012 s/iter. Inference: 0.0547 s/iter. Eval: 0.0351 s/iter. Total: 0.0911 s/iter. ETA=0:05:58
[12/10 03:33:36 d2.evaluation.evaluator]: Inference done 1122/5000. Dataloading: 0.0012 s/iter. Inference: 0.0546 s/iter. Eval: 0.0350 s/iter. Total: 0.0909 s/iter. ETA=0:05:52
[12/10 03:33:41 d2.evaluation.evaluator]: Inference done 1178/5000. Dataloading: 0.0012 s/iter. Inference: 0.0546 s/iter. Eval: 0.0350 s/iter. Total: 0.0909 s/iter. ETA=0:05:47
[12/10 03:33:46 d2.evaluation.evaluator]: Inference done 1232/5000. Dataloading: 0.0012 s/iter. Inference: 0.0547 s/iter. Eval: 0.0350 s/iter. Total: 0.0910 s/iter. ETA=0:05:42
[12/10 03:33:51 d2.evaluation.evaluator]: Inference done 1286/5000. Dataloading: 0.0012 s/iter. Inference: 0.0548 s/iter. Eval: 0.0351 s/iter. Total: 0.0911 s/iter. ETA=0:05:38
[12/10 03:33:56 d2.evaluation.evaluator]: Inference done 1340/5000. Dataloading: 0.0012 s/iter. Inference: 0.0548 s/iter. Eval: 0.0351 s/iter. Total: 0.0912 s/iter. ETA=0:05:33
[12/10 03:34:01 d2.evaluation.evaluator]: Inference done 1395/5000. Dataloading: 0.0012 s/iter. Inference: 0.0549 s/iter. Eval: 0.0351 s/iter. Total: 0.0913 s/iter. ETA=0:05:28
[12/10 03:34:06 d2.evaluation.evaluator]: Inference done 1451/5000. Dataloading: 0.0012 s/iter. Inference: 0.0549 s/iter. Eval: 0.0351 s/iter. Total: 0.0912 s/iter. ETA=0:05:23
[12/10 03:34:11 d2.evaluation.evaluator]: Inference done 1505/5000. Dataloading: 0.0012 s/iter. Inference: 0.0549 s/iter. Eval: 0.0352 s/iter. Total: 0.0914 s/iter. ETA=0:05:19
[12/10 03:34:16 d2.evaluation.evaluator]: Inference done 1560/5000. Dataloading: 0.0012 s/iter. Inference: 0.0549 s/iter. Eval: 0.0352 s/iter. Total: 0.0914 s/iter. ETA=0:05:14
[12/10 03:34:21 d2.evaluation.evaluator]: Inference done 1614/5000. Dataloading: 0.0012 s/iter. Inference: 0.0550 s/iter. Eval: 0.0352 s/iter. Total: 0.0915 s/iter. ETA=0:05:09
[12/10 03:34:27 d2.evaluation.evaluator]: Inference done 1668/5000. Dataloading: 0.0012 s/iter. Inference: 0.0550 s/iter. Eval: 0.0353 s/iter. Total: 0.0916 s/iter. ETA=0:05:05
[12/10 03:34:32 d2.evaluation.evaluator]: Inference done 1722/5000. Dataloading: 0.0012 s/iter. Inference: 0.0551 s/iter. Eval: 0.0353 s/iter. Total: 0.0916 s/iter. ETA=0:05:00
[12/10 03:34:37 d2.evaluation.evaluator]: Inference done 1779/5000. Dataloading: 0.0012 s/iter. Inference: 0.0550 s/iter. Eval: 0.0353 s/iter. Total: 0.0915 s/iter. ETA=0:04:54
[12/10 03:34:42 d2.evaluation.evaluator]: Inference done 1833/5000. Dataloading: 0.0012 s/iter. Inference: 0.0550 s/iter. Eval: 0.0353 s/iter. Total: 0.0916 s/iter. ETA=0:04:49
[12/10 03:34:47 d2.evaluation.evaluator]: Inference done 1889/5000. Dataloading: 0.0012 s/iter. Inference: 0.0550 s/iter. Eval: 0.0353 s/iter. Total: 0.0915 s/iter. ETA=0:04:44
[12/10 03:34:52 d2.evaluation.evaluator]: Inference done 1946/5000. Dataloading: 0.0012 s/iter. Inference: 0.0549 s/iter. Eval: 0.0352 s/iter. Total: 0.0914 s/iter. ETA=0:04:39
[12/10 03:34:57 d2.evaluation.evaluator]: Inference done 2001/5000. Dataloading: 0.0012 s/iter. Inference: 0.0549 s/iter. Eval: 0.0352 s/iter. Total: 0.0914 s/iter. ETA=0:04:34
[12/10 03:35:02 d2.evaluation.evaluator]: Inference done 2055/5000. Dataloading: 0.0012 s/iter. Inference: 0.0549 s/iter. Eval: 0.0353 s/iter. Total: 0.0915 s/iter. ETA=0:04:29
[12/10 03:35:07 d2.evaluation.evaluator]: Inference done 2111/5000. Dataloading: 0.0012 s/iter. Inference: 0.0549 s/iter. Eval: 0.0353 s/iter. Total: 0.0914 s/iter. ETA=0:04:24
[12/10 03:35:12 d2.evaluation.evaluator]: Inference done 2169/5000. Dataloading: 0.0012 s/iter. Inference: 0.0548 s/iter. Eval: 0.0352 s/iter. Total: 0.0913 s/iter. ETA=0:04:18
[12/10 03:35:17 d2.evaluation.evaluator]: Inference done 2225/5000. Dataloading: 0.0012 s/iter. Inference: 0.0548 s/iter. Eval: 0.0352 s/iter. Total: 0.0913 s/iter. ETA=0:04:13
[12/10 03:35:22 d2.evaluation.evaluator]: Inference done 2283/5000. Dataloading: 0.0012 s/iter. Inference: 0.0548 s/iter. Eval: 0.0352 s/iter. Total: 0.0912 s/iter. ETA=0:04:07
[12/10 03:35:27 d2.evaluation.evaluator]: Inference done 2342/5000. Dataloading: 0.0012 s/iter. Inference: 0.0547 s/iter. Eval: 0.0351 s/iter. Total: 0.0911 s/iter. ETA=0:04:02
[12/10 03:35:32 d2.evaluation.evaluator]: Inference done 2398/5000. Dataloading: 0.0012 s/iter. Inference: 0.0547 s/iter. Eval: 0.0351 s/iter. Total: 0.0910 s/iter. ETA=0:03:56
[12/10 03:35:37 d2.evaluation.evaluator]: Inference done 2453/5000. Dataloading: 0.0012 s/iter. Inference: 0.0547 s/iter. Eval: 0.0351 s/iter. Total: 0.0911 s/iter. ETA=0:03:51
[12/10 03:35:42 d2.evaluation.evaluator]: Inference done 2510/5000. Dataloading: 0.0012 s/iter. Inference: 0.0547 s/iter. Eval: 0.0351 s/iter. Total: 0.0910 s/iter. ETA=0:03:46
[12/10 03:35:47 d2.evaluation.evaluator]: Inference done 2566/5000. Dataloading: 0.0012 s/iter. Inference: 0.0546 s/iter. Eval: 0.0351 s/iter. Total: 0.0910 s/iter. ETA=0:03:41
[12/10 03:35:52 d2.evaluation.evaluator]: Inference done 2622/5000. Dataloading: 0.0012 s/iter. Inference: 0.0546 s/iter. Eval: 0.0351 s/iter. Total: 0.0910 s/iter. ETA=0:03:36
[12/10 03:35:57 d2.evaluation.evaluator]: Inference done 2679/5000. Dataloading: 0.0012 s/iter. Inference: 0.0546 s/iter. Eval: 0.0350 s/iter. Total: 0.0909 s/iter. ETA=0:03:31
[12/10 03:36:02 d2.evaluation.evaluator]: Inference done 2738/5000. Dataloading: 0.0012 s/iter. Inference: 0.0546 s/iter. Eval: 0.0350 s/iter. Total: 0.0908 s/iter. ETA=0:03:25
[12/10 03:36:07 d2.evaluation.evaluator]: Inference done 2795/5000. Dataloading: 0.0012 s/iter. Inference: 0.0545 s/iter. Eval: 0.0350 s/iter. Total: 0.0908 s/iter. ETA=0:03:20
[12/10 03:36:12 d2.evaluation.evaluator]: Inference done 2850/5000. Dataloading: 0.0012 s/iter. Inference: 0.0545 s/iter. Eval: 0.0350 s/iter. Total: 0.0908 s/iter. ETA=0:03:15
[12/10 03:36:18 d2.evaluation.evaluator]: Inference done 2907/5000. Dataloading: 0.0012 s/iter. Inference: 0.0546 s/iter. Eval: 0.0349 s/iter. Total: 0.0907 s/iter. ETA=0:03:09
[12/10 03:36:23 d2.evaluation.evaluator]: Inference done 2962/5000. Dataloading: 0.0012 s/iter. Inference: 0.0546 s/iter. Eval: 0.0349 s/iter. Total: 0.0907 s/iter. ETA=0:03:04
[12/10 03:36:28 d2.evaluation.evaluator]: Inference done 3021/5000. Dataloading: 0.0012 s/iter. Inference: 0.0545 s/iter. Eval: 0.0349 s/iter. Total: 0.0906 s/iter. ETA=0:02:59
[12/10 03:36:33 d2.evaluation.evaluator]: Inference done 3078/5000. Dataloading: 0.0012 s/iter. Inference: 0.0545 s/iter. Eval: 0.0349 s/iter. Total: 0.0906 s/iter. ETA=0:02:54
[12/10 03:36:38 d2.evaluation.evaluator]: Inference done 3134/5000. Dataloading: 0.0012 s/iter. Inference: 0.0545 s/iter. Eval: 0.0348 s/iter. Total: 0.0906 s/iter. ETA=0:02:49
[12/10 03:36:43 d2.evaluation.evaluator]: Inference done 3189/5000. Dataloading: 0.0012 s/iter. Inference: 0.0545 s/iter. Eval: 0.0349 s/iter. Total: 0.0906 s/iter. ETA=0:02:44
[12/10 03:36:48 d2.evaluation.evaluator]: Inference done 3243/5000. Dataloading: 0.0012 s/iter. Inference: 0.0545 s/iter. Eval: 0.0349 s/iter. Total: 0.0906 s/iter. ETA=0:02:39
[12/10 03:36:53 d2.evaluation.evaluator]: Inference done 3299/5000. Dataloading: 0.0012 s/iter. Inference: 0.0545 s/iter. Eval: 0.0349 s/iter. Total: 0.0906 s/iter. ETA=0:02:34
[12/10 03:36:58 d2.evaluation.evaluator]: Inference done 3354/5000. Dataloading: 0.0012 s/iter. Inference: 0.0545 s/iter. Eval: 0.0349 s/iter. Total: 0.0906 s/iter. ETA=0:02:29
[12/10 03:37:03 d2.evaluation.evaluator]: Inference done 3409/5000. Dataloading: 0.0012 s/iter. Inference: 0.0545 s/iter. Eval: 0.0349 s/iter. Total: 0.0906 s/iter. ETA=0:02:24
[12/10 03:37:08 d2.evaluation.evaluator]: Inference done 3464/5000. Dataloading: 0.0012 s/iter. Inference: 0.0546 s/iter. Eval: 0.0349 s/iter. Total: 0.0907 s/iter. ETA=0:02:19
[12/10 03:37:13 d2.evaluation.evaluator]: Inference done 3522/5000. Dataloading: 0.0012 s/iter. Inference: 0.0545 s/iter. Eval: 0.0348 s/iter. Total: 0.0906 s/iter. ETA=0:02:13
[12/10 03:37:18 d2.evaluation.evaluator]: Inference done 3577/5000. Dataloading: 0.0012 s/iter. Inference: 0.0546 s/iter. Eval: 0.0349 s/iter. Total: 0.0906 s/iter. ETA=0:02:08
[12/10 03:37:23 d2.evaluation.evaluator]: Inference done 3632/5000. Dataloading: 0.0012 s/iter. Inference: 0.0546 s/iter. Eval: 0.0349 s/iter. Total: 0.0906 s/iter. ETA=0:02:04
[12/10 03:37:28 d2.evaluation.evaluator]: Inference done 3688/5000. Dataloading: 0.0012 s/iter. Inference: 0.0545 s/iter. Eval: 0.0348 s/iter. Total: 0.0906 s/iter. ETA=0:01:58
[12/10 03:37:33 d2.evaluation.evaluator]: Inference done 3744/5000. Dataloading: 0.0012 s/iter. Inference: 0.0546 s/iter. Eval: 0.0348 s/iter. Total: 0.0906 s/iter. ETA=0:01:53
[12/10 03:37:38 d2.evaluation.evaluator]: Inference done 3798/5000. Dataloading: 0.0012 s/iter. Inference: 0.0546 s/iter. Eval: 0.0348 s/iter. Total: 0.0907 s/iter. ETA=0:01:48
[12/10 03:37:43 d2.evaluation.evaluator]: Inference done 3855/5000. Dataloading: 0.0012 s/iter. Inference: 0.0546 s/iter. Eval: 0.0348 s/iter. Total: 0.0906 s/iter. ETA=0:01:43
[12/10 03:37:48 d2.evaluation.evaluator]: Inference done 3913/5000. Dataloading: 0.0012 s/iter. Inference: 0.0546 s/iter. Eval: 0.0348 s/iter. Total: 0.0906 s/iter. ETA=0:01:38
[12/10 03:37:53 d2.evaluation.evaluator]: Inference done 3968/5000. Dataloading: 0.0012 s/iter. Inference: 0.0546 s/iter. Eval: 0.0348 s/iter. Total: 0.0906 s/iter. ETA=0:01:33
[12/10 03:37:58 d2.evaluation.evaluator]: Inference done 4024/5000. Dataloading: 0.0012 s/iter. Inference: 0.0546 s/iter. Eval: 0.0348 s/iter. Total: 0.0906 s/iter. ETA=0:01:28
[12/10 03:38:03 d2.evaluation.evaluator]: Inference done 4079/5000. Dataloading: 0.0012 s/iter. Inference: 0.0546 s/iter. Eval: 0.0348 s/iter. Total: 0.0906 s/iter. ETA=0:01:23
[12/10 03:38:08 d2.evaluation.evaluator]: Inference done 4136/5000. Dataloading: 0.0012 s/iter. Inference: 0.0545 s/iter. Eval: 0.0348 s/iter. Total: 0.0906 s/iter. ETA=0:01:18
[12/10 03:38:13 d2.evaluation.evaluator]: Inference done 4191/5000. Dataloading: 0.0012 s/iter. Inference: 0.0545 s/iter. Eval: 0.0348 s/iter. Total: 0.0906 s/iter. ETA=0:01:13
[12/10 03:38:18 d2.evaluation.evaluator]: Inference done 4248/5000. Dataloading: 0.0012 s/iter. Inference: 0.0545 s/iter. Eval: 0.0348 s/iter. Total: 0.0905 s/iter. ETA=0:01:08
[12/10 03:38:24 d2.evaluation.evaluator]: Inference done 4305/5000. Dataloading: 0.0012 s/iter. Inference: 0.0545 s/iter. Eval: 0.0348 s/iter. Total: 0.0905 s/iter. ETA=0:01:02
[12/10 03:38:29 d2.evaluation.evaluator]: Inference done 4366/5000. Dataloading: 0.0012 s/iter. Inference: 0.0545 s/iter. Eval: 0.0347 s/iter. Total: 0.0904 s/iter. ETA=0:00:57
[12/10 03:38:34 d2.evaluation.evaluator]: Inference done 4423/5000. Dataloading: 0.0012 s/iter. Inference: 0.0544 s/iter. Eval: 0.0347 s/iter. Total: 0.0904 s/iter. ETA=0:00:52
[12/10 03:38:39 d2.evaluation.evaluator]: Inference done 4480/5000. Dataloading: 0.0012 s/iter. Inference: 0.0544 s/iter. Eval: 0.0347 s/iter. Total: 0.0904 s/iter. ETA=0:00:46
[12/10 03:38:44 d2.evaluation.evaluator]: Inference done 4537/5000. Dataloading: 0.0012 s/iter. Inference: 0.0544 s/iter. Eval: 0.0347 s/iter. Total: 0.0903 s/iter. ETA=0:00:41
[12/10 03:38:49 d2.evaluation.evaluator]: Inference done 4594/5000. Dataloading: 0.0012 s/iter. Inference: 0.0544 s/iter. Eval: 0.0347 s/iter. Total: 0.0903 s/iter. ETA=0:00:36
[12/10 03:38:54 d2.evaluation.evaluator]: Inference done 4650/5000. Dataloading: 0.0012 s/iter. Inference: 0.0544 s/iter. Eval: 0.0347 s/iter. Total: 0.0903 s/iter. ETA=0:00:31
[12/10 03:38:59 d2.evaluation.evaluator]: Inference done 4707/5000. Dataloading: 0.0012 s/iter. Inference: 0.0544 s/iter. Eval: 0.0347 s/iter. Total: 0.0903 s/iter. ETA=0:00:26
[12/10 03:39:04 d2.evaluation.evaluator]: Inference done 4765/5000. Dataloading: 0.0012 s/iter. Inference: 0.0544 s/iter. Eval: 0.0347 s/iter. Total: 0.0903 s/iter. ETA=0:00:21
[12/10 03:39:09 d2.evaluation.evaluator]: Inference done 4820/5000. Dataloading: 0.0012 s/iter. Inference: 0.0544 s/iter. Eval: 0.0347 s/iter. Total: 0.0903 s/iter. ETA=0:00:16
[12/10 03:39:14 d2.evaluation.evaluator]: Inference done 4877/5000. Dataloading: 0.0012 s/iter. Inference: 0.0544 s/iter. Eval: 0.0347 s/iter. Total: 0.0903 s/iter. ETA=0:00:11
[12/10 03:39:19 d2.evaluation.evaluator]: Inference done 4931/5000. Dataloading: 0.0012 s/iter. Inference: 0.0544 s/iter. Eval: 0.0347 s/iter. Total: 0.0903 s/iter. ETA=0:00:06
[12/10 03:39:24 d2.evaluation.evaluator]: Inference done 4990/5000. Dataloading: 0.0012 s/iter. Inference: 0.0544 s/iter. Eval: 0.0346 s/iter. Total: 0.0903 s/iter. ETA=0:00:00
[12/10 03:39:25 d2.evaluation.evaluator]: Total inference time: 0:07:30.991013 (0.090288 s / iter per device, on 1 devices)
[12/10 03:39:25 d2.evaluation.evaluator]: Total inference pure compute time: 0:04:31 (0.054398 s / iter per device, on 1 devices)
[12/10 03:39:25 d2.evaluation.panoptic_evaluation]: Writing all panoptic predictions to /tmp/panoptic_evalpm2c64sd ...
[12/10 03:39:49 d2.evaluation.panoptic_evaluation]: Panoptic Evaluation Results:
|        |  PQ   |   SQ   |   RQ   |  #categories  |
|:------:|:-----:|:------:|:------:|:-------------:|
|  All   | 5.858 | 39.385 | 8.033  |      133      |
| Things | 3.976 | 40.535 | 5.617  |      80       |
| Stuff  | 8.699 | 37.648 | 11.680 |      53       |
[12/10 03:39:49 d2.evaluation.coco_evaluation]: Preparing results for COCO format ...
[12/10 03:39:49 d2.evaluation.coco_evaluation]: Saving results to ./output/inference/coco_instances_results.json
[12/10 03:39:50 d2.evaluation.coco_evaluation]: Evaluating predictions with unofficial COCO API...
Loading and preparing results...
DONE (t=0.03s)
creating index...
index created!
[12/10 03:39:50 d2.evaluation.fast_eval_api]: Evaluate annotation type *bbox*
[12/10 03:39:57 d2.evaluation.fast_eval_api]: COCOeval_opt.evaluate() finished in 7.59 seconds.
[12/10 03:39:57 d2.evaluation.fast_eval_api]: Accumulating evaluation results...
[12/10 03:39:58 d2.evaluation.fast_eval_api]: COCOeval_opt.accumulate() finished in 0.61 seconds.
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.010
 Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.023
 Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.007
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.001
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.007
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.017
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.021
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.030
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.030
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.001
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.016
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.053
[12/10 03:39:58 d2.evaluation.coco_evaluation]: Evaluation results for bbox: 
|  AP   |  AP50  |  AP75  |  APs  |  APm  |  APl  |
|:-----:|:------:|:------:|:-----:|:-----:|:-----:|
| 0.971 | 2.347  | 0.716  | 0.102 | 0.750 | 1.725 |
[12/10 03:39:58 d2.evaluation.coco_evaluation]: Per-category bbox AP: 
| category      | AP    | category     | AP     | category       | AP    |
|:--------------|:------|:-------------|:-------|:---------------|:------|
| person        | 5.180 | bicycle      | 0.176  | car            | 2.042 |
| motorcycle    | 1.446 | airplane     | 0.773  | bus            | 5.809 |
| train         | 2.300 | truck        | 0.468  | boat           | 0.112 |
| traffic light | 0.316 | fire hydrant | 0.000  | stop sign      | 8.666 |
| parking meter | 0.000 | bench        | 0.000  | bird           | 0.693 |
| cat           | 0.933 | dog          | 0.218  | horse          | 0.000 |
| sheep         | 0.806 | cow          | 1.476  | elephant       | 4.854 |
| bear          | 3.494 | zebra        | 12.261 | giraffe        | 3.881 |
| backpack      | 0.000 | umbrella     | 0.198  | handbag        | 0.000 |
| tie           | 0.000 | suitcase     | 0.000  | frisbee        | 0.000 |
| skis          | 0.000 | snowboard    | 0.000  | sports ball    | 0.891 |
| kite          | 1.149 | baseball bat | 0.000  | baseball glove | 0.000 |
| skateboard    | 0.000 | surfboard    | 0.055  | tennis racket  | 0.000 |
| bottle        | 0.100 | wine glass   | 0.000  | cup            | 0.186 |
| fork          | 0.000 | knife        | 0.000  | spoon          | 0.000 |
| bowl          | 0.586 | banana       | 0.155  | apple          | 0.231 |
| sandwich      | 0.000 | orange       | 0.792  | broccoli       | 0.033 |
| carrot        | 0.050 | hot dog      | 0.000  | pizza          | 1.055 |
| donut         | 0.000 | cake         | 0.000  | chair          | 0.355 |
| couch         | 1.228 | potted plant | 0.105  | bed            | 2.216 |
| dining table  | 2.087 | toilet       | 3.645  | tv             | 2.962 |
| laptop        | 1.280 | mouse        | 0.000  | remote         | 0.000 |
| keyboard      | 0.167 | cell phone   | 0.000  | microwave      | 0.000 |
| oven          | 0.058 | toaster      | 0.000  | sink           | 0.384 |
| refrigerator  | 0.270 | book         | 0.000  | clock          | 1.410 |
| vase          | 0.099 | scissors     | 0.000  | teddy bear     | 0.050 |
| hair drier    | 0.000 | toothbrush   | 0.000  |                |       |
Loading and preparing results...
DONE (t=0.46s)
creating index...
index created!
[12/10 03:39:59 d2.evaluation.fast_eval_api]: Evaluate annotation type *segm*
[12/10 03:40:08 d2.evaluation.fast_eval_api]: COCOeval_opt.evaluate() finished in 8.86 seconds.
[12/10 03:40:08 d2.evaluation.fast_eval_api]: Accumulating evaluation results...
[12/10 03:40:09 d2.evaluation.fast_eval_api]: COCOeval_opt.accumulate() finished in 0.68 seconds.
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.010
 Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.023
 Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.008
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.001
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.006
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.022
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.018
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.023
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.024
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.001
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.014
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.041
[12/10 03:40:11 d2.evaluation.coco_evaluation]: Evaluation results for segm: 
|  AP   |  AP50  |  AP75  |  APs  |  APm  |  APl  |
|:-----:|:------:|:------:|:-----:|:-----:|:-----:|
| 0.970 | 2.306  | 0.759  | 0.062 | 0.647 | 2.238 |
[12/10 03:40:11 d2.evaluation.coco_evaluation]: Per-category segm AP: 
| category      | AP    | category     | AP    | category       | AP     |
|:--------------|:------|:-------------|:------|:---------------|:-------|
| person        | 3.050 | bicycle      | 0.113 | car            | 1.737  |
| motorcycle    | 0.997 | airplane     | 0.792 | bus            | 5.694  |
| train         | 1.928 | truck        | 0.488 | boat           | 0.020  |
| traffic light | 0.239 | fire hydrant | 0.000 | stop sign      | 11.430 |
| parking meter | 0.000 | bench        | 0.000 | bird           | 0.693  |
| cat           | 1.917 | dog          | 0.178 | horse          | 0.000  |
| sheep         | 0.841 | cow          | 1.612 | elephant       | 4.712  |
| bear          | 6.412 | zebra        | 9.745 | giraffe        | 3.065  |
| backpack      | 0.000 | umbrella     | 0.099 | handbag        | 0.000  |
| tie           | 0.000 | suitcase     | 0.000 | frisbee        | 0.000  |
| skis          | 0.000 | snowboard    | 0.000 | sports ball    | 0.792  |
| kite          | 1.137 | baseball bat | 0.000 | baseball glove | 0.000  |
| skateboard    | 0.000 | surfboard    | 0.032 | tennis racket  | 0.000  |
| bottle        | 0.005 | wine glass   | 0.000 | cup            | 0.100  |
| fork          | 0.000 | knife        | 0.000 | spoon          | 0.000  |
| bowl          | 0.698 | banana       | 0.067 | apple          | 0.000  |
| sandwich      | 0.000 | orange       | 0.914 | broccoli       | 0.005  |
| carrot        | 0.000 | hot dog      | 0.000 | pizza          | 0.435  |
| donut         | 0.000 | cake         | 0.000 | chair          | 0.271  |
| couch         | 0.956 | potted plant | 0.050 | bed            | 1.007  |
| dining table  | 0.570 | toilet       | 5.095 | tv             | 3.531  |
| laptop        | 1.281 | mouse        | 0.000 | remote         | 0.000  |
| keyboard      | 0.598 | cell phone   | 0.000 | microwave      | 0.000  |
| oven          | 0.034 | toaster      | 0.000 | sink           | 0.601  |
| refrigerator  | 0.009 | book         | 0.006 | clock          | 3.151  |
| vase          | 0.495 | scissors     | 0.000 | teddy bear     | 0.000  |
| hair drier    | 0.000 | toothbrush   | 0.000 |                |        |
[12/10 03:40:13 d2.engine.defaults]: Evaluation results for coco_2017_val_panoptic in csv format:
[12/10 03:40:13 d2.evaluation.testing]: copypaste: Task: panoptic_seg
[12/10 03:40:13 d2.evaluation.testing]: copypaste: PQ,SQ,RQ,PQ_th,SQ_th,RQ_th,PQ_st,SQ_st,RQ_st
[12/10 03:40:13 d2.evaluation.testing]: copypaste: 5.8578,39.3846,8.0331,3.9758,40.5352,5.6174,8.6986,37.6478,11.6795
[12/10 03:40:13 d2.evaluation.testing]: copypaste: Task: bbox
[12/10 03:40:13 d2.evaluation.testing]: copypaste: AP,AP50,AP75,APs,APm,APl
[12/10 03:40:13 d2.evaluation.testing]: copypaste: 0.9713,2.3471,0.7160,0.1020,0.7497,1.7253
[12/10 03:40:13 d2.evaluation.testing]: copypaste: Task: segm
[12/10 03:40:13 d2.evaluation.testing]: copypaste: AP,AP50,AP75,APs,APm,APl
[12/10 03:40:13 d2.evaluation.testing]: copypaste: 0.9701,2.3056,0.7588,0.0622,0.6470,2.2379