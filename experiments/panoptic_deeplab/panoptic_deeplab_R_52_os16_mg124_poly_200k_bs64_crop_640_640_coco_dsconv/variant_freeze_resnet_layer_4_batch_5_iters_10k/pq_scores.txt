env: DETECTRON2_DATASETS=/content/datasets
Command Line Args: Namespace(config_file='./detectron2/projects/Panoptic-DeepLab/configs/COCO-PanopticSegmentation/panoptic_deeplab_R_52_os16_mg124_poly_200k_bs64_crop_640_640_coco_dsconv.yaml', dist_url='tcp://127.0.0.1:49152', eval_only=False, machine_rank=0, num_gpus=1, num_machines=1, opts=['MODEL.RESNETS.NORM', 'BN', 'MODEL.INS_EMBED_HEAD.NORM', 'BN', 'MODEL.SEM_SEG_HEAD.NORM', 'BN', 'SOLVER.MAX_ITER', '10000', 'SOLVER.IMS_PER_BATCH', '5', 'SOLVER.BASE_LR', '0.0025', 'MODEL.BACKBONE.FREEZE_AT', '4'], resume=False)
Loading config ./detectron2/projects/Panoptic-DeepLab/configs/COCO-PanopticSegmentation/panoptic_deeplab_R_52_os16_mg124_poly_200k_bs64_crop_640_640_coco_dsconv.yaml with yaml.unsafe_load. Your machine may be at risk if the file contains malicious content.
[12/10 23:32:50 detectron2]: Rank of current process: 0. World size: 1
[12/10 23:32:51 detectron2]: Environment info:
----------------------  ----------------------------------------------------------------
sys.platform            linux
Python                  3.7.12 (default, Jan 15 2022, 18:48:18) [GCC 7.5.0]
numpy                   1.21.5
detectron2              0.6 @/content/detectron2/detectron2
Compiler                GCC 7.5
CUDA compiler           CUDA 11.1
detectron2 arch flags   7.0
DETECTRON2_ENV_MODULE   <not set>
PyTorch                 1.10.0+cu111 @/usr/local/lib/python3.7/dist-packages/torch
PyTorch debug build     False
GPU available           Yes
GPU 0                   Tesla V100-SXM2-16GB (arch=7.0)
Driver version          460.32.03
CUDA_HOME               /usr/local/cuda
Pillow                  7.1.2
torchvision             0.11.1+cu111 @/usr/local/lib/python3.7/dist-packages/torchvision
torchvision arch flags  3.5, 5.0, 6.0, 7.0, 7.5, 8.0, 8.6
fvcore                  0.1.5.post20221122
iopath                  0.1.9
cv2                     4.1.2
----------------------  ----------------------------------------------------------------
PyTorch built with:
  - GCC 7.3
  - C++ Version: 201402
  - Intel(R) Math Kernel Library Version 2020.0.0 Product Build 20191122 for Intel(R) 64 architecture applications
  - Intel(R) MKL-DNN v2.2.3 (Git Hash 7336ca9f055cf1bfa13efb658fe15dc9b41f0740)
  - OpenMP 201511 (a.k.a. OpenMP 4.5)
  - LAPACK is enabled (usually provided by MKL)
  - NNPACK is enabled
  - CPU capability usage: AVX512
  - CUDA Runtime 11.1
  - NVCC architecture flags: -gencode;arch=compute_37,code=sm_37;-gencode;arch=compute_50,code=sm_50;-gencode;arch=compute_60,code=sm_60;-gencode;arch=compute_70,code=sm_70;-gencode;arch=compute_75,code=sm_75;-gencode;arch=compute_80,code=sm_80;-gencode;arch=compute_86,code=sm_86
  - CuDNN 8.0.5
  - Magma 2.5.2
  - Build settings: BLAS_INFO=mkl, BUILD_TYPE=Release, CUDA_VERSION=11.1, CUDNN_VERSION=8.0.5, CXX_COMPILER=/opt/rh/devtoolset-7/root/usr/bin/c++, CXX_FLAGS= -Wno-deprecated -fvisibility-inlines-hidden -DUSE_PTHREADPOOL -fopenmp -DNDEBUG -DUSE_KINETO -DUSE_FBGEMM -DUSE_QNNPACK -DUSE_PYTORCH_QNNPACK -DUSE_XNNPACK -DSYMBOLICATE_MOBILE_DEBUG_HANDLE -DEDGE_PROFILER_USE_KINETO -O2 -fPIC -Wno-narrowing -Wall -Wextra -Werror=return-type -Wno-missing-field-initializers -Wno-type-limits -Wno-array-bounds -Wno-unknown-pragmas -Wno-sign-compare -Wno-unused-parameter -Wno-unused-variable -Wno-unused-function -Wno-unused-result -Wno-unused-local-typedefs -Wno-strict-overflow -Wno-strict-aliasing -Wno-error=deprecated-declarations -Wno-stringop-overflow -Wno-psabi -Wno-error=pedantic -Wno-error=redundant-decls -Wno-error=old-style-cast -fdiagnostics-color=always -faligned-new -Wno-unused-but-set-variable -Wno-maybe-uninitialized -fno-math-errno -fno-trapping-math -Werror=format -Wno-stringop-overflow, LAPACK_INFO=mkl, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, TORCH_VERSION=1.10.0, USE_CUDA=ON, USE_CUDNN=ON, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_MKL=ON, USE_MKLDNN=ON, USE_MPI=OFF, USE_NCCL=ON, USE_NNPACK=ON, USE_OPENMP=ON, 

[12/10 23:32:51 detectron2]: Command line arguments: Namespace(config_file='./detectron2/projects/Panoptic-DeepLab/configs/COCO-PanopticSegmentation/panoptic_deeplab_R_52_os16_mg124_poly_200k_bs64_crop_640_640_coco_dsconv.yaml', dist_url='tcp://127.0.0.1:49152', eval_only=False, machine_rank=0, num_gpus=1, num_machines=1, opts=['MODEL.RESNETS.NORM', 'BN', 'MODEL.INS_EMBED_HEAD.NORM', 'BN', 'MODEL.SEM_SEG_HEAD.NORM', 'BN', 'SOLVER.MAX_ITER', '10000', 'SOLVER.IMS_PER_BATCH', '5', 'SOLVER.BASE_LR', '0.0025', 'MODEL.BACKBONE.FREEZE_AT', '4'], resume=False)
[12/10 23:32:51 detectron2]: Contents of args.config_file=./detectron2/projects/Panoptic-DeepLab/configs/COCO-PanopticSegmentation/panoptic_deeplab_R_52_os16_mg124_poly_200k_bs64_crop_640_640_coco_dsconv.yaml:
_BASE_: ../Cityscapes-PanopticSegmentation/Base-PanopticDeepLab-OS16.yaml
MODEL:
  WEIGHTS: "detectron2://DeepLab/R-52.pkl"
  PIXEL_MEAN: [123.675, 116.280, 103.530]
  PIXEL_STD: [58.395, 57.120, 57.375]
  BACKBONE:
    NAME: "build_resnet_deeplab_backbone"
  RESNETS:
    DEPTH: 50
    NORM: "SyncBN"
    RES5_MULTI_GRID: [1, 2, 4]
    STEM_TYPE: "deeplab"
    STEM_OUT_CHANNELS: 128
    STRIDE_IN_1X1: False
  SEM_SEG_HEAD:
    NUM_CLASSES: 133
    LOSS_TOP_K: 1.0
    USE_DEPTHWISE_SEPARABLE_CONV: True
  PANOPTIC_DEEPLAB:
    STUFF_AREA: 4096
    NMS_KERNEL: 41
    SIZE_DIVISIBILITY: 640
    USE_DEPTHWISE_SEPARABLE_CONV: True
DATASETS:
  TRAIN: ("coco_2017_train_panoptic",)
  TEST: ("coco_2017_val_panoptic",)
SOLVER:
  BASE_LR: 0.0005
  MAX_ITER: 200000
  IMS_PER_BATCH: 64
INPUT:
  FORMAT: "RGB"
  GAUSSIAN_SIGMA: 8
  MIN_SIZE_TRAIN: !!python/object/apply:eval ["[int(x * 0.1 * 640) for x in range(5, 16)]"]
  MIN_SIZE_TRAIN_SAMPLING: "choice"
  MIN_SIZE_TEST: 640
  MAX_SIZE_TRAIN: 960
  MAX_SIZE_TEST: 640
  CROP:
    ENABLED: True
    TYPE: "absolute"
    SIZE: (640, 640)

[12/10 23:32:51 detectron2]: Running with full config:
CUDNN_BENCHMARK: false
DATALOADER:
  ASPECT_RATIO_GROUPING: true
  FILTER_EMPTY_ANNOTATIONS: true
  NUM_WORKERS: 10
  REPEAT_THRESHOLD: 0.0
  SAMPLER_TRAIN: TrainingSampler
DATASETS:
  PRECOMPUTED_PROPOSAL_TOPK_TEST: 1000
  PRECOMPUTED_PROPOSAL_TOPK_TRAIN: 2000
  PROPOSAL_FILES_TEST: []
  PROPOSAL_FILES_TRAIN: []
  TEST:
  - coco_2017_val_panoptic
  TRAIN:
  - coco_2017_train_panoptic
GLOBAL:
  HACK: 1.0
INPUT:
  CROP:
    ENABLED: true
    SINGLE_CATEGORY_MAX_AREA: 1.0
    SIZE:
    - 640
    - 640
    TYPE: absolute
  FORMAT: RGB
  GAUSSIAN_SIGMA: 8
  IGNORE_CROWD_IN_SEMANTIC: false
  IGNORE_STUFF_IN_OFFSET: true
  MASK_FORMAT: polygon
  MAX_SIZE_TEST: 640
  MAX_SIZE_TRAIN: 960
  MIN_SIZE_TEST: 640
  MIN_SIZE_TRAIN:
  - 320
  - 384
  - 448
  - 512
  - 576
  - 640
  - 704
  - 768
  - 832
  - 896
  - 960
  MIN_SIZE_TRAIN_SAMPLING: choice
  RANDOM_FLIP: horizontal
  SMALL_INSTANCE_AREA: 4096
  SMALL_INSTANCE_WEIGHT: 3
MODEL:
  ANCHOR_GENERATOR:
    ANGLES:
    - - -90
      - 0
      - 90
    ASPECT_RATIOS:
    - - 0.5
      - 1.0
      - 2.0
    NAME: DefaultAnchorGenerator
    OFFSET: 0.0
    SIZES:
    - - 32
      - 64
      - 128
      - 256
      - 512
  BACKBONE:
    FREEZE_AT: 4
    NAME: build_resnet_deeplab_backbone
  DEVICE: cuda
  FPN:
    FUSE_TYPE: sum
    IN_FEATURES: []
    NORM: ''
    OUT_CHANNELS: 256
  INS_EMBED_HEAD:
    ASPP_CHANNELS: 256
    ASPP_DILATIONS:
    - 6
    - 12
    - 18
    ASPP_DROPOUT: 0.1
    CENTER_LOSS_WEIGHT: 200.0
    COMMON_STRIDE: 4
    CONVS_DIM: 128
    HEAD_CHANNELS: 32
    IN_FEATURES:
    - res2
    - res3
    - res5
    NAME: PanopticDeepLabInsEmbedHead
    NORM: BN
    OFFSET_LOSS_WEIGHT: 0.01
    PROJECT_CHANNELS:
    - 32
    - 64
    PROJECT_FEATURES:
    - res2
    - res3
  KEYPOINT_ON: false
  LOAD_PROPOSALS: false
  MASK_ON: false
  META_ARCHITECTURE: PanopticDeepLab
  PANOPTIC_DEEPLAB:
    BENCHMARK_NETWORK_SPEED: false
    CENTER_THRESHOLD: 0.1
    NMS_KERNEL: 41
    PREDICT_INSTANCES: true
    SIZE_DIVISIBILITY: 640
    STUFF_AREA: 4096
    TOP_K_INSTANCE: 200
    USE_DEPTHWISE_SEPARABLE_CONV: true
  PANOPTIC_FPN:
    COMBINE:
      ENABLED: true
      INSTANCES_CONFIDENCE_THRESH: 0.5
      OVERLAP_THRESH: 0.5
      STUFF_AREA_LIMIT: 4096
    INSTANCE_LOSS_WEIGHT: 1.0
  PIXEL_MEAN:
  - 123.675
  - 116.28
  - 103.53
  PIXEL_STD:
  - 58.395
  - 57.12
  - 57.375
  PROPOSAL_GENERATOR:
    MIN_SIZE: 0
    NAME: RPN
  RESNETS:
    DEFORM_MODULATED: false
    DEFORM_NUM_GROUPS: 1
    DEFORM_ON_PER_STAGE:
    - false
    - false
    - false
    - false
    DEPTH: 50
    NORM: BN
    NUM_GROUPS: 1
    OUT_FEATURES:
    - res2
    - res3
    - res5
    RES2_OUT_CHANNELS: 256
    RES4_DILATION: 1
    RES5_DILATION: 2
    RES5_MULTI_GRID:
    - 1
    - 2
    - 4
    STEM_OUT_CHANNELS: 128
    STEM_TYPE: deeplab
    STRIDE_IN_1X1: false
    WIDTH_PER_GROUP: 64
  RETINANET:
    BBOX_REG_LOSS_TYPE: smooth_l1
    BBOX_REG_WEIGHTS: &id001
    - 1.0
    - 1.0
    - 1.0
    - 1.0
    FOCAL_LOSS_ALPHA: 0.25
    FOCAL_LOSS_GAMMA: 2.0
    IN_FEATURES:
    - p3
    - p4
    - p5
    - p6
    - p7
    IOU_LABELS:
    - 0
    - -1
    - 1
    IOU_THRESHOLDS:
    - 0.4
    - 0.5
    NMS_THRESH_TEST: 0.5
    NORM: ''
    NUM_CLASSES: 80
    NUM_CONVS: 4
    PRIOR_PROB: 0.01
    SCORE_THRESH_TEST: 0.05
    SMOOTH_L1_LOSS_BETA: 0.1
    TOPK_CANDIDATES_TEST: 1000
  ROI_BOX_CASCADE_HEAD:
    BBOX_REG_WEIGHTS:
    - - 10.0
      - 10.0
      - 5.0
      - 5.0
    - - 20.0
      - 20.0
      - 10.0
      - 10.0
    - - 30.0
      - 30.0
      - 15.0
      - 15.0
    IOUS:
    - 0.5
    - 0.6
    - 0.7
  ROI_BOX_HEAD:
    BBOX_REG_LOSS_TYPE: smooth_l1
    BBOX_REG_LOSS_WEIGHT: 1.0
    BBOX_REG_WEIGHTS:
    - 10.0
    - 10.0
    - 5.0
    - 5.0
    CLS_AGNOSTIC_BBOX_REG: false
    CONV_DIM: 256
    FC_DIM: 1024
    FED_LOSS_FREQ_WEIGHT_POWER: 0.5
    FED_LOSS_NUM_CLASSES: 50
    NAME: ''
    NORM: ''
    NUM_CONV: 0
    NUM_FC: 0
    POOLER_RESOLUTION: 14
    POOLER_SAMPLING_RATIO: 0
    POOLER_TYPE: ROIAlignV2
    SMOOTH_L1_BETA: 0.0
    TRAIN_ON_PRED_BOXES: false
    USE_FED_LOSS: false
    USE_SIGMOID_CE: false
  ROI_HEADS:
    BATCH_SIZE_PER_IMAGE: 512
    IN_FEATURES:
    - res4
    IOU_LABELS:
    - 0
    - 1
    IOU_THRESHOLDS:
    - 0.5
    NAME: Res5ROIHeads
    NMS_THRESH_TEST: 0.5
    NUM_CLASSES: 80
    POSITIVE_FRACTION: 0.25
    PROPOSAL_APPEND_GT: true
    SCORE_THRESH_TEST: 0.05
  ROI_KEYPOINT_HEAD:
    CONV_DIMS:
    - 512
    - 512
    - 512
    - 512
    - 512
    - 512
    - 512
    - 512
    LOSS_WEIGHT: 1.0
    MIN_KEYPOINTS_PER_IMAGE: 1
    NAME: KRCNNConvDeconvUpsampleHead
    NORMALIZE_LOSS_BY_VISIBLE_KEYPOINTS: true
    NUM_KEYPOINTS: 17
    POOLER_RESOLUTION: 14
    POOLER_SAMPLING_RATIO: 0
    POOLER_TYPE: ROIAlignV2
  ROI_MASK_HEAD:
    CLS_AGNOSTIC_MASK: false
    CONV_DIM: 256
    NAME: MaskRCNNConvUpsampleHead
    NORM: ''
    NUM_CONV: 0
    POOLER_RESOLUTION: 14
    POOLER_SAMPLING_RATIO: 0
    POOLER_TYPE: ROIAlignV2
  RPN:
    BATCH_SIZE_PER_IMAGE: 256
    BBOX_REG_LOSS_TYPE: smooth_l1
    BBOX_REG_LOSS_WEIGHT: 1.0
    BBOX_REG_WEIGHTS: *id001
    BOUNDARY_THRESH: -1
    CONV_DIMS:
    - -1
    HEAD_NAME: StandardRPNHead
    IN_FEATURES:
    - res4
    IOU_LABELS:
    - 0
    - -1
    - 1
    IOU_THRESHOLDS:
    - 0.3
    - 0.7
    LOSS_WEIGHT: 1.0
    NMS_THRESH: 0.7
    POSITIVE_FRACTION: 0.5
    POST_NMS_TOPK_TEST: 1000
    POST_NMS_TOPK_TRAIN: 2000
    PRE_NMS_TOPK_TEST: 6000
    PRE_NMS_TOPK_TRAIN: 12000
    SMOOTH_L1_BETA: 0.0
  SEM_SEG_HEAD:
    ASPP_CHANNELS: 256
    ASPP_DILATIONS:
    - 6
    - 12
    - 18
    ASPP_DROPOUT: 0.1
    COMMON_STRIDE: 4
    CONVS_DIM: 256
    HEAD_CHANNELS: 256
    IGNORE_VALUE: 255
    IN_FEATURES:
    - res2
    - res3
    - res5
    LOSS_TOP_K: 1.0
    LOSS_TYPE: hard_pixel_mining
    LOSS_WEIGHT: 1.0
    NAME: PanopticDeepLabSemSegHead
    NORM: BN
    NUM_CLASSES: 133
    PROJECT_CHANNELS:
    - 32
    - 64
    PROJECT_FEATURES:
    - res2
    - res3
    USE_DEPTHWISE_SEPARABLE_CONV: true
  WEIGHTS: detectron2://DeepLab/R-52.pkl
OUTPUT_DIR: ./output
SEED: -1
SOLVER:
  AMP:
    ENABLED: false
  BASE_LR: 0.0025
  BASE_LR_END: 0.0
  BIAS_LR_FACTOR: 1.0
  CHECKPOINT_PERIOD: 5000
  CLIP_GRADIENTS:
    CLIP_TYPE: value
    CLIP_VALUE: 1.0
    ENABLED: false
    NORM_TYPE: 2.0
  GAMMA: 0.1
  IMS_PER_BATCH: 5
  LR_SCHEDULER_NAME: WarmupPolyLR
  MAX_ITER: 10000
  MOMENTUM: 0.9
  NESTEROV: false
  NUM_DECAYS: 3
  OPTIMIZER: ADAM
  POLY_LR_CONSTANT_ENDING: 0.0
  POLY_LR_POWER: 0.9
  REFERENCE_WORLD_SIZE: 0
  RESCALE_INTERVAL: false
  STEPS:
  - 30000
  WARMUP_FACTOR: 0.001
  WARMUP_ITERS: 1000
  WARMUP_METHOD: linear
  WEIGHT_DECAY: 0.0
  WEIGHT_DECAY_BIAS: 0.0
  WEIGHT_DECAY_NORM: 0.0
TEST:
  AUG:
    ENABLED: false
    FLIP: true
    MAX_SIZE: 4000
    MIN_SIZES:
    - 400
    - 500
    - 600
    - 700
    - 800
    - 900
    - 1000
    - 1100
    - 1200
  DETECTIONS_PER_IMAGE: 100
  EVAL_PERIOD: 0
  EXPECTED_RESULTS: []
  KEYPOINT_OKS_SIGMAS: []
  PRECISE_BN:
    ENABLED: false
    NUM_ITER: 200
VERSION: 2
VIS_PERIOD: 0

[12/10 23:32:51 detectron2]: Full config saved to ./output/config.yaml
[12/10 23:32:52 d2.utils.env]: Using a generated random seed 52134847
[12/10 23:32:56 d2.engine.defaults]: Model:
PanopticDeepLab(
  (backbone): ResNet(
    (stem): DeepLabStem(
      (conv1): Conv2d(
        3, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False
        (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
      )
      (conv2): Conv2d(
        64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
        (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
      )
      (conv3): Conv2d(
        64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
        (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
      )
    )
    (res2): Sequential(
      (0): BottleneckBlock(
        (shortcut): Conv2d(
          128, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv1): Conv2d(
          128, 64, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
        )
        (conv2): Conv2d(
          64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
        )
        (conv3): Conv2d(
          64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
      )
      (1): BottleneckBlock(
        (conv1): Conv2d(
          256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
        )
        (conv2): Conv2d(
          64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
        )
        (conv3): Conv2d(
          64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
      )
      (2): BottleneckBlock(
        (conv1): Conv2d(
          256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
        )
        (conv2): Conv2d(
          64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
        )
        (conv3): Conv2d(
          64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
      )
    )
    (res3): Sequential(
      (0): BottleneckBlock(
        (shortcut): Conv2d(
          256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False
          (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
        )
        (conv1): Conv2d(
          256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
        )
        (conv2): Conv2d(
          128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
        )
        (conv3): Conv2d(
          128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
        )
      )
      (1): BottleneckBlock(
        (conv1): Conv2d(
          512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
        )
        (conv2): Conv2d(
          128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
        )
        (conv3): Conv2d(
          128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
        )
      )
      (2): BottleneckBlock(
        (conv1): Conv2d(
          512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
        )
        (conv2): Conv2d(
          128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
        )
        (conv3): Conv2d(
          128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
        )
      )
      (3): BottleneckBlock(
        (conv1): Conv2d(
          512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
        )
        (conv2): Conv2d(
          128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
        )
        (conv3): Conv2d(
          128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
        )
      )
    )
    (res4): Sequential(
      (0): BottleneckBlock(
        (shortcut): Conv2d(
          512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False
          (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
        )
        (conv1): Conv2d(
          512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv2): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv3): Conv2d(
          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
        )
      )
      (1): BottleneckBlock(
        (conv1): Conv2d(
          1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv2): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv3): Conv2d(
          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
        )
      )
      (2): BottleneckBlock(
        (conv1): Conv2d(
          1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv2): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv3): Conv2d(
          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
        )
      )
      (3): BottleneckBlock(
        (conv1): Conv2d(
          1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv2): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv3): Conv2d(
          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
        )
      )
      (4): BottleneckBlock(
        (conv1): Conv2d(
          1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv2): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv3): Conv2d(
          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
        )
      )
      (5): BottleneckBlock(
        (conv1): Conv2d(
          1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv2): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv3): Conv2d(
          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
        )
      )
    )
    (res5): Sequential(
      (0): BottleneckBlock(
        (shortcut): Conv2d(
          1024, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv1): Conv2d(
          1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv2): Conv2d(
          512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2), dilation=(2, 2), bias=False
          (norm): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv3): Conv2d(
          512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (1): BottleneckBlock(
        (conv1): Conv2d(
          2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv2): Conv2d(
          512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(4, 4), dilation=(4, 4), bias=False
          (norm): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv3): Conv2d(
          512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (2): BottleneckBlock(
        (conv1): Conv2d(
          2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv2): Conv2d(
          512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(8, 8), dilation=(8, 8), bias=False
          (norm): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv3): Conv2d(
          512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
    )
  )
  (sem_seg_head): PanopticDeepLabSemSegHead(
    (decoder): ModuleDict(
      (res2): ModuleDict(
        (project_conv): Conv2d(
          256, 32, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (fuse_conv): DepthwiseSeparableConv2d(
          (depthwise): Conv2d(
            288, 288, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=288, bias=False
            (norm): BatchNorm2d(288, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          )
          (pointwise): Conv2d(
            288, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
      )
      (res3): ModuleDict(
        (project_conv): Conv2d(
          512, 64, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (fuse_conv): DepthwiseSeparableConv2d(
          (depthwise): Conv2d(
            320, 320, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=320, bias=False
            (norm): BatchNorm2d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          )
          (pointwise): Conv2d(
            320, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
      )
      (res5): ModuleDict(
        (project_conv): ASPP(
          (convs): ModuleList(
            (0): Conv2d(
              2048, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
              (norm): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            )
            (1): DepthwiseSeparableConv2d(
              (depthwise): Conv2d(
                2048, 2048, kernel_size=(3, 3), stride=(1, 1), padding=(6, 6), dilation=(6, 6), groups=2048, bias=False
                (norm): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
              (pointwise): Conv2d(
                2048, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
            )
            (2): DepthwiseSeparableConv2d(
              (depthwise): Conv2d(
                2048, 2048, kernel_size=(3, 3), stride=(1, 1), padding=(12, 12), dilation=(12, 12), groups=2048, bias=False
                (norm): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
              (pointwise): Conv2d(
                2048, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
            )
            (3): DepthwiseSeparableConv2d(
              (depthwise): Conv2d(
                2048, 2048, kernel_size=(3, 3), stride=(1, 1), padding=(18, 18), dilation=(18, 18), groups=2048, bias=False
                (norm): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
              (pointwise): Conv2d(
                2048, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
            )
            (4): Sequential(
              (0): AvgPool2d(kernel_size=(40, 40), stride=1, padding=0)
              (1): Conv2d(2048, 256, kernel_size=(1, 1), stride=(1, 1))
            )
          )
          (project): Conv2d(
            1280, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (fuse_conv): None
      )
    )
    (head): DepthwiseSeparableConv2d(
      (depthwise): Conv2d(
        256, 256, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=256, bias=False
        (norm): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (pointwise): Conv2d(
        256, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
        (norm): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (predictor): Conv2d(256, 133, kernel_size=(1, 1), stride=(1, 1))
    (loss): DeepLabCE(
      (criterion): CrossEntropyLoss()
    )
  )
  (ins_embed_head): PanopticDeepLabInsEmbedHead(
    (decoder): ModuleDict(
      (res2): ModuleDict(
        (project_conv): Conv2d(
          256, 32, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (fuse_conv): DepthwiseSeparableConv2d(
          (depthwise): Conv2d(
            160, 160, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=160, bias=False
            (norm): BatchNorm2d(160, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          )
          (pointwise): Conv2d(
            160, 128, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
      )
      (res3): ModuleDict(
        (project_conv): Conv2d(
          512, 64, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (fuse_conv): DepthwiseSeparableConv2d(
          (depthwise): Conv2d(
            320, 320, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=320, bias=False
            (norm): BatchNorm2d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          )
          (pointwise): Conv2d(
            320, 128, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
      )
      (res5): ModuleDict(
        (project_conv): ASPP(
          (convs): ModuleList(
            (0): Conv2d(
              2048, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
              (norm): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            )
            (1): DepthwiseSeparableConv2d(
              (depthwise): Conv2d(
                2048, 2048, kernel_size=(3, 3), stride=(1, 1), padding=(6, 6), dilation=(6, 6), groups=2048, bias=False
                (norm): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
              (pointwise): Conv2d(
                2048, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
            )
            (2): DepthwiseSeparableConv2d(
              (depthwise): Conv2d(
                2048, 2048, kernel_size=(3, 3), stride=(1, 1), padding=(12, 12), dilation=(12, 12), groups=2048, bias=False
                (norm): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
              (pointwise): Conv2d(
                2048, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
            )
            (3): DepthwiseSeparableConv2d(
              (depthwise): Conv2d(
                2048, 2048, kernel_size=(3, 3), stride=(1, 1), padding=(18, 18), dilation=(18, 18), groups=2048, bias=False
                (norm): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
              (pointwise): Conv2d(
                2048, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
            )
            (4): Sequential(
              (0): AvgPool2d(kernel_size=(40, 40), stride=1, padding=0)
              (1): Conv2d(2048, 256, kernel_size=(1, 1), stride=(1, 1))
            )
          )
          (project): Conv2d(
            1280, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (fuse_conv): None
      )
    )
    (center_head): Sequential(
      (0): Conv2d(
        128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
        (norm): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (1): Conv2d(
        128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
        (norm): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (center_predictor): Conv2d(32, 1, kernel_size=(1, 1), stride=(1, 1))
    (offset_head): DepthwiseSeparableConv2d(
      (depthwise): Conv2d(
        128, 128, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=128, bias=False
        (norm): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (pointwise): Conv2d(
        128, 32, kernel_size=(1, 1), stride=(1, 1), bias=False
        (norm): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (offset_predictor): Conv2d(32, 2, kernel_size=(1, 1), stride=(1, 1))
    (center_loss): MSELoss()
    (offset_loss): L1Loss()
  )
)
[12/10 23:32:56 d2.projects.panoptic_deeplab.dataset_mapper]: Augmentations used in training: [ResizeShortestEdge(short_edge_length=(320, 384, 448, 512, 576, 640, 704, 768, 832, 896, 960), max_size=960, sample_style='choice'), RandomCrop(crop_type='absolute', crop_size=[640, 640]), RandomFlip()]
[12/10 23:33:04 d2.data.build]: Using training sampler TrainingSampler
[12/10 23:33:04 d2.data.common]: Serializing the dataset using: <class 'detectron2.data.common.NumpySerializedList'>
[12/10 23:33:04 d2.data.common]: Serializing 118287 elements to byte tensors and concatenating them all ...
[12/10 23:33:05 d2.data.common]: Serialized dataset takes 80.32 MiB
/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:481: UserWarning: This DataLoader will create 10 worker processes in total. Our suggested max number of worker in current system is 8, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.
  cpuset_checked))
[12/10 23:33:08 fvcore.common.checkpoint]: [Checkpointer] Loading from detectron2://DeepLab/R-52.pkl ...
[12/10 23:33:08 fvcore.common.checkpoint]: Reading a file from 'torchvision'
[12/10 23:33:08 d2.checkpoint.c2_model_loading]: Following weights matched with submodule backbone:
| Names in Model    | Names in Checkpoint                                                                                        | Shapes                                             |
|:------------------|:-----------------------------------------------------------------------------------------------------------|:---------------------------------------------------|
| res2.0.conv1.*    | res2.0.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}                             | (64,) (64,) (64,) (64,) (64,128,1,1)               |
| res2.0.conv2.*    | res2.0.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}                             | (64,) (64,) (64,) (64,) (64,64,3,3)                |
| res2.0.conv3.*    | res2.0.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}                             | (256,) (256,) (256,) (256,) (256,64,1,1)           |
| res2.0.shortcut.* | res2.0.shortcut.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}                          | (256,) (256,) (256,) (256,) (256,128,1,1)          |
| res2.1.conv1.*    | res2.1.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}                             | (64,) (64,) (64,) (64,) (64,256,1,1)               |
| res2.1.conv2.*    | res2.1.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}                             | (64,) (64,) (64,) (64,) (64,64,3,3)                |
| res2.1.conv3.*    | res2.1.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}                             | (256,) (256,) (256,) (256,) (256,64,1,1)           |
| res2.2.conv1.*    | res2.2.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}                             | (64,) (64,) (64,) (64,) (64,256,1,1)               |
| res2.2.conv2.*    | res2.2.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}                             | (64,) (64,) (64,) (64,) (64,64,3,3)                |
| res2.2.conv3.*    | res2.2.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}                             | (256,) (256,) (256,) (256,) (256,64,1,1)           |
| res3.0.conv1.*    | res3.0.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}                             | (128,) (128,) (128,) (128,) (128,256,1,1)          |
| res3.0.conv2.*    | res3.0.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}                             | (128,) (128,) (128,) (128,) (128,128,3,3)          |
| res3.0.conv3.*    | res3.0.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}                             | (512,) (512,) (512,) (512,) (512,128,1,1)          |
| res3.0.shortcut.* | res3.0.shortcut.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}                          | (512,) (512,) (512,) (512,) (512,256,1,1)          |
| res3.1.conv1.*    | res3.1.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}                             | (128,) (128,) (128,) (128,) (128,512,1,1)          |
| res3.1.conv2.*    | res3.1.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}                             | (128,) (128,) (128,) (128,) (128,128,3,3)          |
| res3.1.conv3.*    | res3.1.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}                             | (512,) (512,) (512,) (512,) (512,128,1,1)          |
| res3.2.conv1.*    | res3.2.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}                             | (128,) (128,) (128,) (128,) (128,512,1,1)          |
| res3.2.conv2.*    | res3.2.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}                             | (128,) (128,) (128,) (128,) (128,128,3,3)          |
| res3.2.conv3.*    | res3.2.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}                             | (512,) (512,) (512,) (512,) (512,128,1,1)          |
| res3.3.conv1.*    | res3.3.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}                             | (128,) (128,) (128,) (128,) (128,512,1,1)          |
| res3.3.conv2.*    | res3.3.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}                             | (128,) (128,) (128,) (128,) (128,128,3,3)          |
| res3.3.conv3.*    | res3.3.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}                             | (512,) (512,) (512,) (512,) (512,128,1,1)          |
| res4.0.conv1.*    | res4.0.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}                             | (256,) (256,) (256,) (256,) (256,512,1,1)          |
| res4.0.conv2.*    | res4.0.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}                             | (256,) (256,) (256,) (256,) (256,256,3,3)          |
| res4.0.conv3.*    | res4.0.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}                             | (1024,) (1024,) (1024,) (1024,) (1024,256,1,1)     |
| res4.0.shortcut.* | res4.0.shortcut.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}                          | (1024,) (1024,) (1024,) (1024,) (1024,512,1,1)     |
| res4.1.conv1.*    | res4.1.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}                             | (256,) (256,) (256,) (256,) (256,1024,1,1)         |
| res4.1.conv2.*    | res4.1.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}                             | (256,) (256,) (256,) (256,) (256,256,3,3)          |
| res4.1.conv3.*    | res4.1.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}                             | (1024,) (1024,) (1024,) (1024,) (1024,256,1,1)     |
| res4.2.conv1.*    | res4.2.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}                             | (256,) (256,) (256,) (256,) (256,1024,1,1)         |
| res4.2.conv2.*    | res4.2.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}                             | (256,) (256,) (256,) (256,) (256,256,3,3)          |
| res4.2.conv3.*    | res4.2.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}                             | (1024,) (1024,) (1024,) (1024,) (1024,256,1,1)     |
| res4.3.conv1.*    | res4.3.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}                             | (256,) (256,) (256,) (256,) (256,1024,1,1)         |
| res4.3.conv2.*    | res4.3.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}                             | (256,) (256,) (256,) (256,) (256,256,3,3)          |
| res4.3.conv3.*    | res4.3.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}                             | (1024,) (1024,) (1024,) (1024,) (1024,256,1,1)     |
| res4.4.conv1.*    | res4.4.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}                             | (256,) (256,) (256,) (256,) (256,1024,1,1)         |
| res4.4.conv2.*    | res4.4.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}                             | (256,) (256,) (256,) (256,) (256,256,3,3)          |
| res4.4.conv3.*    | res4.4.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}                             | (1024,) (1024,) (1024,) (1024,) (1024,256,1,1)     |
| res4.5.conv1.*    | res4.5.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}                             | (256,) (256,) (256,) (256,) (256,1024,1,1)         |
| res4.5.conv2.*    | res4.5.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}                             | (256,) (256,) (256,) (256,) (256,256,3,3)          |
| res4.5.conv3.*    | res4.5.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}                             | (1024,) (1024,) (1024,) (1024,) (1024,256,1,1)     |
| res5.0.conv1.*    | res5.0.conv1.{norm.bias,norm.num_batches_tracked,norm.running_mean,norm.running_var,norm.weight,weight}    | (512,) () (512,) (512,) (512,) (512,1024,1,1)      |
| res5.0.conv2.*    | res5.0.conv2.{norm.bias,norm.num_batches_tracked,norm.running_mean,norm.running_var,norm.weight,weight}    | (512,) () (512,) (512,) (512,) (512,512,3,3)       |
| res5.0.conv3.*    | res5.0.conv3.{norm.bias,norm.num_batches_tracked,norm.running_mean,norm.running_var,norm.weight,weight}    | (2048,) () (2048,) (2048,) (2048,) (2048,512,1,1)  |
| res5.0.shortcut.* | res5.0.shortcut.{norm.bias,norm.num_batches_tracked,norm.running_mean,norm.running_var,norm.weight,weight} | (2048,) () (2048,) (2048,) (2048,) (2048,1024,1,1) |
| res5.1.conv1.*    | res5.1.conv1.{norm.bias,norm.num_batches_tracked,norm.running_mean,norm.running_var,norm.weight,weight}    | (512,) () (512,) (512,) (512,) (512,2048,1,1)      |
| res5.1.conv2.*    | res5.1.conv2.{norm.bias,norm.num_batches_tracked,norm.running_mean,norm.running_var,norm.weight,weight}    | (512,) () (512,) (512,) (512,) (512,512,3,3)       |
| res5.1.conv3.*    | res5.1.conv3.{norm.bias,norm.num_batches_tracked,norm.running_mean,norm.running_var,norm.weight,weight}    | (2048,) () (2048,) (2048,) (2048,) (2048,512,1,1)  |
| res5.2.conv1.*    | res5.2.conv1.{norm.bias,norm.num_batches_tracked,norm.running_mean,norm.running_var,norm.weight,weight}    | (512,) () (512,) (512,) (512,) (512,2048,1,1)      |
| res5.2.conv2.*    | res5.2.conv2.{norm.bias,norm.num_batches_tracked,norm.running_mean,norm.running_var,norm.weight,weight}    | (512,) () (512,) (512,) (512,) (512,512,3,3)       |
| res5.2.conv3.*    | res5.2.conv3.{norm.bias,norm.num_batches_tracked,norm.running_mean,norm.running_var,norm.weight,weight}    | (2048,) () (2048,) (2048,) (2048,) (2048,512,1,1)  |
| stem.conv1.*      | stem.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}                               | (64,) (64,) (64,) (64,) (64,3,3,3)                 |
| stem.conv2.*      | stem.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}                               | (64,) (64,) (64,) (64,) (64,64,3,3)                |
| stem.conv3.*      | stem.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}                               | (128,) (128,) (128,) (128,) (128,64,3,3)           |
WARNING [12/10 23:33:09 fvcore.common.checkpoint]: Some model parameters or buffers are not found in the checkpoint:
ins_embed_head.center_head.0.norm.{bias, running_mean, running_var, weight}
ins_embed_head.center_head.0.weight
ins_embed_head.center_head.1.norm.{bias, running_mean, running_var, weight}
ins_embed_head.center_head.1.weight
ins_embed_head.center_predictor.{bias, weight}
ins_embed_head.decoder.res2.fuse_conv.depthwise.norm.{bias, running_mean, running_var, weight}
ins_embed_head.decoder.res2.fuse_conv.depthwise.weight
ins_embed_head.decoder.res2.fuse_conv.pointwise.norm.{bias, running_mean, running_var, weight}
ins_embed_head.decoder.res2.fuse_conv.pointwise.weight
ins_embed_head.decoder.res2.project_conv.norm.{bias, running_mean, running_var, weight}
ins_embed_head.decoder.res2.project_conv.weight
ins_embed_head.decoder.res3.fuse_conv.depthwise.norm.{bias, running_mean, running_var, weight}
ins_embed_head.decoder.res3.fuse_conv.depthwise.weight
ins_embed_head.decoder.res3.fuse_conv.pointwise.norm.{bias, running_mean, running_var, weight}
ins_embed_head.decoder.res3.fuse_conv.pointwise.weight
ins_embed_head.decoder.res3.project_conv.norm.{bias, running_mean, running_var, weight}
ins_embed_head.decoder.res3.project_conv.weight
ins_embed_head.decoder.res5.project_conv.convs.0.norm.{bias, running_mean, running_var, weight}
ins_embed_head.decoder.res5.project_conv.convs.0.weight
ins_embed_head.decoder.res5.project_conv.convs.1.depthwise.norm.{bias, running_mean, running_var, weight}
ins_embed_head.decoder.res5.project_conv.convs.1.depthwise.weight
ins_embed_head.decoder.res5.project_conv.convs.1.pointwise.norm.{bias, running_mean, running_var, weight}
ins_embed_head.decoder.res5.project_conv.convs.1.pointwise.weight
ins_embed_head.decoder.res5.project_conv.convs.2.depthwise.norm.{bias, running_mean, running_var, weight}
ins_embed_head.decoder.res5.project_conv.convs.2.depthwise.weight
ins_embed_head.decoder.res5.project_conv.convs.2.pointwise.norm.{bias, running_mean, running_var, weight}
ins_embed_head.decoder.res5.project_conv.convs.2.pointwise.weight
ins_embed_head.decoder.res5.project_conv.convs.3.depthwise.norm.{bias, running_mean, running_var, weight}
ins_embed_head.decoder.res5.project_conv.convs.3.depthwise.weight
ins_embed_head.decoder.res5.project_conv.convs.3.pointwise.norm.{bias, running_mean, running_var, weight}
ins_embed_head.decoder.res5.project_conv.convs.3.pointwise.weight
ins_embed_head.decoder.res5.project_conv.convs.4.1.{bias, weight}
ins_embed_head.decoder.res5.project_conv.project.norm.{bias, running_mean, running_var, weight}
ins_embed_head.decoder.res5.project_conv.project.weight
ins_embed_head.offset_head.depthwise.norm.{bias, running_mean, running_var, weight}
ins_embed_head.offset_head.depthwise.weight
ins_embed_head.offset_head.pointwise.norm.{bias, running_mean, running_var, weight}
ins_embed_head.offset_head.pointwise.weight
ins_embed_head.offset_predictor.{bias, weight}
sem_seg_head.decoder.res2.fuse_conv.depthwise.norm.{bias, running_mean, running_var, weight}
sem_seg_head.decoder.res2.fuse_conv.depthwise.weight
sem_seg_head.decoder.res2.fuse_conv.pointwise.norm.{bias, running_mean, running_var, weight}
sem_seg_head.decoder.res2.fuse_conv.pointwise.weight
sem_seg_head.decoder.res2.project_conv.norm.{bias, running_mean, running_var, weight}
sem_seg_head.decoder.res2.project_conv.weight
sem_seg_head.decoder.res3.fuse_conv.depthwise.norm.{bias, running_mean, running_var, weight}
sem_seg_head.decoder.res3.fuse_conv.depthwise.weight
sem_seg_head.decoder.res3.fuse_conv.pointwise.norm.{bias, running_mean, running_var, weight}
sem_seg_head.decoder.res3.fuse_conv.pointwise.weight
sem_seg_head.decoder.res3.project_conv.norm.{bias, running_mean, running_var, weight}
sem_seg_head.decoder.res3.project_conv.weight
sem_seg_head.decoder.res5.project_conv.convs.0.norm.{bias, running_mean, running_var, weight}
sem_seg_head.decoder.res5.project_conv.convs.0.weight
sem_seg_head.decoder.res5.project_conv.convs.1.depthwise.norm.{bias, running_mean, running_var, weight}
sem_seg_head.decoder.res5.project_conv.convs.1.depthwise.weight
sem_seg_head.decoder.res5.project_conv.convs.1.pointwise.norm.{bias, running_mean, running_var, weight}
sem_seg_head.decoder.res5.project_conv.convs.1.pointwise.weight
sem_seg_head.decoder.res5.project_conv.convs.2.depthwise.norm.{bias, running_mean, running_var, weight}
sem_seg_head.decoder.res5.project_conv.convs.2.depthwise.weight
sem_seg_head.decoder.res5.project_conv.convs.2.pointwise.norm.{bias, running_mean, running_var, weight}
sem_seg_head.decoder.res5.project_conv.convs.2.pointwise.weight
sem_seg_head.decoder.res5.project_conv.convs.3.depthwise.norm.{bias, running_mean, running_var, weight}
sem_seg_head.decoder.res5.project_conv.convs.3.depthwise.weight
sem_seg_head.decoder.res5.project_conv.convs.3.pointwise.norm.{bias, running_mean, running_var, weight}
sem_seg_head.decoder.res5.project_conv.convs.3.pointwise.weight
sem_seg_head.decoder.res5.project_conv.convs.4.1.{bias, weight}
sem_seg_head.decoder.res5.project_conv.project.norm.{bias, running_mean, running_var, weight}
sem_seg_head.decoder.res5.project_conv.project.weight
sem_seg_head.head.depthwise.norm.{bias, running_mean, running_var, weight}
sem_seg_head.head.depthwise.weight
sem_seg_head.head.pointwise.norm.{bias, running_mean, running_var, weight}
sem_seg_head.head.pointwise.weight
sem_seg_head.predictor.{bias, weight}
WARNING [12/10 23:33:09 fvcore.common.checkpoint]: The checkpoint state_dict contains keys that are not used by the model:
  res2.0.conv1.norm.num_batches_tracked
  res2.0.conv2.norm.num_batches_tracked
  res2.0.conv3.norm.num_batches_tracked
  res2.0.shortcut.norm.num_batches_tracked
  res2.1.conv1.norm.num_batches_tracked
  res2.1.conv2.norm.num_batches_tracked
  res2.1.conv3.norm.num_batches_tracked
  res2.2.conv1.norm.num_batches_tracked
  res2.2.conv2.norm.num_batches_tracked
  res2.2.conv3.norm.num_batches_tracked
  res3.0.conv1.norm.num_batches_tracked
  res3.0.conv2.norm.num_batches_tracked
  res3.0.conv3.norm.num_batches_tracked
  res3.0.shortcut.norm.num_batches_tracked
  res3.1.conv1.norm.num_batches_tracked
  res3.1.conv2.norm.num_batches_tracked
  res3.1.conv3.norm.num_batches_tracked
  res3.2.conv1.norm.num_batches_tracked
  res3.2.conv2.norm.num_batches_tracked
  res3.2.conv3.norm.num_batches_tracked
  res3.3.conv1.norm.num_batches_tracked
  res3.3.conv2.norm.num_batches_tracked
  res3.3.conv3.norm.num_batches_tracked
  res4.0.conv1.norm.num_batches_tracked
  res4.0.conv2.norm.num_batches_tracked
  res4.0.conv3.norm.num_batches_tracked
  res4.0.shortcut.norm.num_batches_tracked
  res4.1.conv1.norm.num_batches_tracked
  res4.1.conv2.norm.num_batches_tracked
  res4.1.conv3.norm.num_batches_tracked
  res4.2.conv1.norm.num_batches_tracked
  res4.2.conv2.norm.num_batches_tracked
  res4.2.conv3.norm.num_batches_tracked
  res4.3.conv1.norm.num_batches_tracked
  res4.3.conv2.norm.num_batches_tracked
  res4.3.conv3.norm.num_batches_tracked
  res4.4.conv1.norm.num_batches_tracked
  res4.4.conv2.norm.num_batches_tracked
  res4.4.conv3.norm.num_batches_tracked
  res4.5.conv1.norm.num_batches_tracked
  res4.5.conv2.norm.num_batches_tracked
  res4.5.conv3.norm.num_batches_tracked
  stem.conv1.norm.num_batches_tracked
  stem.conv2.norm.num_batches_tracked
  stem.conv3.norm.num_batches_tracked
  stem.fc.{bias, weight}
[12/10 23:33:09 d2.engine.train_loop]: Starting training from iteration 0
/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:481: UserWarning: This DataLoader will create 10 worker processes in total. Our suggested max number of worker in current system is 8, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.
  cpuset_checked))
[12/10 23:33:16 d2.utils.events]:  eta: 0:53:05  iter: 19  total_loss: 6.514  loss_sem_seg: 3.852  loss_center: 0.745  loss_offset: 1.713  time: 0.3216  data_time: 0.0780  lr: 4.9867e-05  max_mem: 7343M
[12/10 23:33:23 d2.utils.events]:  eta: 0:53:26  iter: 39  total_loss: 6.075  loss_sem_seg: 3.775  loss_center: 0.6933  loss_offset: 1.647  time: 0.3226  data_time: 0.0270  lr: 9.9552e-05  max_mem: 7343M
[12/10 23:33:29 d2.utils.events]:  eta: 0:53:26  iter: 59  total_loss: 5.487  loss_sem_seg: 3.491  loss_center: 0.65  loss_offset: 1.544  time: 0.3230  data_time: 0.0264  lr: 0.00014906  max_mem: 7343M
[12/10 23:33:36 d2.utils.events]:  eta: 0:53:13  iter: 79  total_loss: 5.841  loss_sem_seg: 3.551  loss_center: 0.6814  loss_offset: 1.694  time: 0.3238  data_time: 0.0282  lr: 0.00019838  max_mem: 7343M
[12/10 23:33:42 d2.utils.events]:  eta: 0:53:06  iter: 99  total_loss: 5.094  loss_sem_seg: 2.979  loss_center: 0.5618  loss_offset: 1.405  time: 0.3232  data_time: 0.0261  lr: 0.00024753  max_mem: 7343M
[12/10 23:33:49 d2.utils.events]:  eta: 0:53:02  iter: 119  total_loss: 5.389  loss_sem_seg: 3.064  loss_center: 0.6821  loss_offset: 1.676  time: 0.3235  data_time: 0.0280  lr: 0.00029649  max_mem: 7343M
[12/10 23:33:55 d2.utils.events]:  eta: 0:52:55  iter: 139  total_loss: 5.006  loss_sem_seg: 2.844  loss_center: 0.5851  loss_offset: 1.545  time: 0.3234  data_time: 0.0270  lr: 0.00034528  max_mem: 7343M
[12/10 23:34:02 d2.utils.events]:  eta: 0:52:57  iter: 159  total_loss: 5.391  loss_sem_seg: 3.016  loss_center: 0.5362  loss_offset: 1.547  time: 0.3234  data_time: 0.0259  lr: 0.00039388  max_mem: 7343M
[12/10 23:34:08 d2.utils.events]:  eta: 0:52:43  iter: 179  total_loss: 4.809  loss_sem_seg: 2.8  loss_center: 0.6248  loss_offset: 1.551  time: 0.3234  data_time: 0.0272  lr: 0.0004423  max_mem: 7343M
[12/10 23:34:15 d2.utils.events]:  eta: 0:52:45  iter: 199  total_loss: 4.852  loss_sem_seg: 2.715  loss_center: 0.554  loss_offset: 1.601  time: 0.3232  data_time: 0.0271  lr: 0.00049055  max_mem: 7343M
[12/10 23:34:21 d2.utils.events]:  eta: 0:52:38  iter: 219  total_loss: 5.009  loss_sem_seg: 2.447  loss_center: 0.7142  loss_offset: 1.509  time: 0.3234  data_time: 0.0304  lr: 0.00053861  max_mem: 7343M
[12/10 23:34:28 d2.utils.events]:  eta: 0:52:32  iter: 239  total_loss: 4.694  loss_sem_seg: 2.603  loss_center: 0.5157  loss_offset: 1.496  time: 0.3236  data_time: 0.0273  lr: 0.00058649  max_mem: 7343M
[12/10 23:34:34 d2.utils.events]:  eta: 0:52:19  iter: 259  total_loss: 4.823  loss_sem_seg: 2.459  loss_center: 0.6375  loss_offset: 1.662  time: 0.3233  data_time: 0.0247  lr: 0.0006342  max_mem: 7343M
[12/10 23:34:41 d2.utils.events]:  eta: 0:52:17  iter: 279  total_loss: 4.17  loss_sem_seg: 2.268  loss_center: 0.4724  loss_offset: 1.352  time: 0.3236  data_time: 0.0302  lr: 0.00068172  max_mem: 7343M
[12/10 23:34:47 d2.utils.events]:  eta: 0:52:10  iter: 299  total_loss: 4.357  loss_sem_seg: 2.257  loss_center: 0.6129  loss_offset: 1.459  time: 0.3236  data_time: 0.0270  lr: 0.00072906  max_mem: 7343M
[12/10 23:34:54 d2.utils.events]:  eta: 0:52:02  iter: 319  total_loss: 4.258  loss_sem_seg: 2.125  loss_center: 0.6286  loss_offset: 1.401  time: 0.3236  data_time: 0.0259  lr: 0.00077622  max_mem: 7343M
[12/10 23:35:00 d2.utils.events]:  eta: 0:51:56  iter: 339  total_loss: 4.66  loss_sem_seg: 2.423  loss_center: 0.6777  loss_offset: 1.546  time: 0.3236  data_time: 0.0266  lr: 0.0008232  max_mem: 7343M
[12/10 23:35:06 d2.utils.events]:  eta: 0:51:49  iter: 359  total_loss: 4.312  loss_sem_seg: 2.355  loss_center: 0.6416  loss_offset: 1.036  time: 0.3236  data_time: 0.0269  lr: 0.00087  max_mem: 7344M
[12/10 23:35:13 d2.utils.events]:  eta: 0:51:46  iter: 379  total_loss: 4.293  loss_sem_seg: 2.334  loss_center: 0.6317  loss_offset: 1.214  time: 0.3237  data_time: 0.0296  lr: 0.00091662  max_mem: 7344M
[12/10 23:35:20 d2.utils.events]:  eta: 0:51:39  iter: 399  total_loss: 4.294  loss_sem_seg: 2.196  loss_center: 0.6573  loss_offset: 1.28  time: 0.3237  data_time: 0.0266  lr: 0.00096306  max_mem: 7344M
[12/10 23:35:26 d2.utils.events]:  eta: 0:51:34  iter: 419  total_loss: 3.911  loss_sem_seg: 2.171  loss_center: 0.5477  loss_offset: 0.9396  time: 0.3238  data_time: 0.0272  lr: 0.0010093  max_mem: 7344M
[12/10 23:35:32 d2.utils.events]:  eta: 0:51:29  iter: 439  total_loss: 3.925  loss_sem_seg: 1.974  loss_center: 0.7322  loss_offset: 1.091  time: 0.3237  data_time: 0.0269  lr: 0.0010554  max_mem: 7344M
[12/10 23:35:39 d2.utils.events]:  eta: 0:51:20  iter: 459  total_loss: 3.819  loss_sem_seg: 2.206  loss_center: 0.6405  loss_offset: 0.8668  time: 0.3236  data_time: 0.0257  lr: 0.0011013  max_mem: 7344M
[12/10 23:35:45 d2.utils.events]:  eta: 0:51:14  iter: 479  total_loss: 3.94  loss_sem_seg: 1.853  loss_center: 0.781  loss_offset: 0.9771  time: 0.3237  data_time: 0.0280  lr: 0.001147  max_mem: 7344M
[12/10 23:35:52 d2.utils.events]:  eta: 0:51:08  iter: 499  total_loss: 3.786  loss_sem_seg: 2.009  loss_center: 0.6892  loss_offset: 1.031  time: 0.3237  data_time: 0.0263  lr: 0.0011925  max_mem: 7344M
[12/10 23:35:58 d2.utils.events]:  eta: 0:51:03  iter: 519  total_loss: 3.806  loss_sem_seg: 2.08  loss_center: 0.6771  loss_offset: 1.037  time: 0.3237  data_time: 0.0276  lr: 0.0012379  max_mem: 7344M
[12/10 23:36:05 d2.utils.events]:  eta: 0:50:57  iter: 539  total_loss: 4.043  loss_sem_seg: 2.168  loss_center: 0.8085  loss_offset: 1.073  time: 0.3238  data_time: 0.0273  lr: 0.001283  max_mem: 7344M
[12/10 23:36:11 d2.utils.events]:  eta: 0:50:51  iter: 559  total_loss: 3.337  loss_sem_seg: 1.882  loss_center: 0.709  loss_offset: 0.8945  time: 0.3238  data_time: 0.0268  lr: 0.001328  max_mem: 7344M
[12/10 23:36:18 d2.utils.events]:  eta: 0:50:46  iter: 579  total_loss: 3.932  loss_sem_seg: 2.376  loss_center: 0.5082  loss_offset: 0.9637  time: 0.3240  data_time: 0.0302  lr: 0.0013728  max_mem: 7344M
[12/10 23:36:25 d2.utils.events]:  eta: 0:50:39  iter: 599  total_loss: 3.476  loss_sem_seg: 1.964  loss_center: 0.6163  loss_offset: 0.9559  time: 0.3240  data_time: 0.0273  lr: 0.0014175  max_mem: 7344M
[12/10 23:36:31 d2.utils.events]:  eta: 0:50:33  iter: 619  total_loss: 3.609  loss_sem_seg: 2.058  loss_center: 0.5573  loss_offset: 0.8224  time: 0.3242  data_time: 0.0322  lr: 0.0014619  max_mem: 7344M
[12/10 23:36:38 d2.utils.events]:  eta: 0:50:27  iter: 639  total_loss: 3.513  loss_sem_seg: 1.98  loss_center: 0.7154  loss_offset: 0.8255  time: 0.3242  data_time: 0.0264  lr: 0.0015062  max_mem: 7344M
[12/10 23:36:44 d2.utils.events]:  eta: 0:50:22  iter: 659  total_loss: 3.763  loss_sem_seg: 2.064  loss_center: 0.5587  loss_offset: 1.087  time: 0.3242  data_time: 0.0270  lr: 0.0015503  max_mem: 7344M
[12/10 23:36:51 d2.utils.events]:  eta: 0:50:16  iter: 679  total_loss: 3.528  loss_sem_seg: 1.871  loss_center: 0.6631  loss_offset: 0.9366  time: 0.3242  data_time: 0.0274  lr: 0.0015942  max_mem: 7344M
[12/10 23:36:57 d2.utils.events]:  eta: 0:50:10  iter: 699  total_loss: 3.744  loss_sem_seg: 1.902  loss_center: 0.745  loss_offset: 0.9856  time: 0.3242  data_time: 0.0273  lr: 0.0016379  max_mem: 7344M
[12/10 23:37:04 d2.utils.events]:  eta: 0:50:03  iter: 719  total_loss: 3.77  loss_sem_seg: 1.973  loss_center: 0.745  loss_offset: 0.9972  time: 0.3242  data_time: 0.0264  lr: 0.0016814  max_mem: 7344M
[12/10 23:37:10 d2.utils.events]:  eta: 0:49:57  iter: 739  total_loss: 3.353  loss_sem_seg: 1.867  loss_center: 0.6554  loss_offset: 0.7914  time: 0.3242  data_time: 0.0278  lr: 0.0017248  max_mem: 7344M
[12/10 23:37:17 d2.utils.events]:  eta: 0:49:50  iter: 759  total_loss: 3.606  loss_sem_seg: 2.069  loss_center: 0.7054  loss_offset: 0.8481  time: 0.3243  data_time: 0.0292  lr: 0.0017679  max_mem: 7344M
[12/10 23:37:23 d2.utils.events]:  eta: 0:49:44  iter: 779  total_loss: 3.596  loss_sem_seg: 1.862  loss_center: 0.5134  loss_offset: 0.9946  time: 0.3243  data_time: 0.0286  lr: 0.0018109  max_mem: 7344M
[12/10 23:37:30 d2.utils.events]:  eta: 0:49:37  iter: 799  total_loss: 3.555  loss_sem_seg: 2.347  loss_center: 0.4941  loss_offset: 0.8732  time: 0.3243  data_time: 0.0272  lr: 0.0018537  max_mem: 7344M
[12/10 23:37:36 d2.utils.events]:  eta: 0:49:31  iter: 819  total_loss: 3.729  loss_sem_seg: 2.126  loss_center: 0.5338  loss_offset: 0.8795  time: 0.3244  data_time: 0.0268  lr: 0.0018964  max_mem: 7344M
[12/10 23:37:43 d2.utils.events]:  eta: 0:49:25  iter: 839  total_loss: 3.462  loss_sem_seg: 1.908  loss_center: 0.526  loss_offset: 0.8378  time: 0.3244  data_time: 0.0290  lr: 0.0019388  max_mem: 7344M
[12/10 23:37:49 d2.utils.events]:  eta: 0:49:18  iter: 859  total_loss: 3.55  loss_sem_seg: 1.924  loss_center: 0.719  loss_offset: 0.8788  time: 0.3243  data_time: 0.0270  lr: 0.0019811  max_mem: 7344M
[12/10 23:37:56 d2.utils.events]:  eta: 0:49:11  iter: 879  total_loss: 3.185  loss_sem_seg: 1.866  loss_center: 0.4855  loss_offset: 0.8095  time: 0.3243  data_time: 0.0285  lr: 0.0020231  max_mem: 7344M
[12/10 23:38:02 d2.utils.events]:  eta: 0:49:05  iter: 899  total_loss: 3.49  loss_sem_seg: 2.061  loss_center: 0.5038  loss_offset: 0.9432  time: 0.3243  data_time: 0.0275  lr: 0.002065  max_mem: 7344M
[12/10 23:38:09 d2.utils.events]:  eta: 0:48:58  iter: 919  total_loss: 3.374  loss_sem_seg: 1.871  loss_center: 0.6117  loss_offset: 0.9078  time: 0.3242  data_time: 0.0275  lr: 0.0021068  max_mem: 7344M
[12/10 23:38:15 d2.utils.events]:  eta: 0:48:52  iter: 939  total_loss: 3.484  loss_sem_seg: 1.94  loss_center: 0.544  loss_offset: 0.768  time: 0.3242  data_time: 0.0264  lr: 0.0021483  max_mem: 7344M
[12/10 23:38:22 d2.utils.events]:  eta: 0:48:45  iter: 959  total_loss: 3.384  loss_sem_seg: 1.967  loss_center: 0.5709  loss_offset: 0.8039  time: 0.3242  data_time: 0.0263  lr: 0.0021896  max_mem: 7344M
[12/10 23:38:28 d2.utils.events]:  eta: 0:48:38  iter: 979  total_loss: 3.261  loss_sem_seg: 1.731  loss_center: 0.6547  loss_offset: 0.7962  time: 0.3242  data_time: 0.0273  lr: 0.0022308  max_mem: 7344M
[12/10 23:38:34 d2.utils.events]:  eta: 0:48:30  iter: 999  total_loss: 3.449  loss_sem_seg: 1.822  loss_center: 0.7482  loss_offset: 0.8539  time: 0.3241  data_time: 0.0260  lr: 0.0022718  max_mem: 7344M
[12/10 23:38:41 d2.utils.events]:  eta: 0:48:24  iter: 1019  total_loss: 3.297  loss_sem_seg: 1.886  loss_center: 0.5269  loss_offset: 0.8394  time: 0.3241  data_time: 0.0273  lr: 0.0022695  max_mem: 7344M
[12/10 23:38:47 d2.utils.events]:  eta: 0:48:17  iter: 1039  total_loss: 3.12  loss_sem_seg: 1.52  loss_center: 0.5211  loss_offset: 0.9177  time: 0.3240  data_time: 0.0265  lr: 0.002265  max_mem: 7344M
[12/10 23:38:54 d2.utils.events]:  eta: 0:48:11  iter: 1059  total_loss: 3.616  loss_sem_seg: 1.884  loss_center: 0.6893  loss_offset: 0.9732  time: 0.3241  data_time: 0.0292  lr: 0.0022604  max_mem: 7344M
[12/10 23:39:00 d2.utils.events]:  eta: 0:48:04  iter: 1079  total_loss: 3.061  loss_sem_seg: 1.592  loss_center: 0.6985  loss_offset: 0.7723  time: 0.3241  data_time: 0.0288  lr: 0.0022559  max_mem: 7344M
[12/10 23:39:07 d2.utils.events]:  eta: 0:47:59  iter: 1099  total_loss: 3.432  loss_sem_seg: 1.903  loss_center: 0.5261  loss_offset: 0.8263  time: 0.3241  data_time: 0.0289  lr: 0.0022513  max_mem: 7344M
[12/10 23:39:13 d2.utils.events]:  eta: 0:47:52  iter: 1119  total_loss: 3.389  loss_sem_seg: 1.84  loss_center: 0.6199  loss_offset: 0.8326  time: 0.3241  data_time: 0.0268  lr: 0.0022468  max_mem: 7344M
[12/10 23:39:20 d2.utils.events]:  eta: 0:47:45  iter: 1139  total_loss: 3.199  loss_sem_seg: 1.677  loss_center: 0.7054  loss_offset: 0.736  time: 0.3241  data_time: 0.0271  lr: 0.0022422  max_mem: 7344M
[12/10 23:39:26 d2.utils.events]:  eta: 0:47:38  iter: 1159  total_loss: 3.153  loss_sem_seg: 1.627  loss_center: 0.5199  loss_offset: 0.8567  time: 0.3241  data_time: 0.0263  lr: 0.0022376  max_mem: 7344M
[12/10 23:39:33 d2.utils.events]:  eta: 0:47:32  iter: 1179  total_loss: 3.512  loss_sem_seg: 1.957  loss_center: 0.7137  loss_offset: 0.8678  time: 0.3241  data_time: 0.0300  lr: 0.0022331  max_mem: 7344M
[12/10 23:39:39 d2.utils.events]:  eta: 0:47:26  iter: 1199  total_loss: 3.304  loss_sem_seg: 1.603  loss_center: 0.6605  loss_offset: 0.7697  time: 0.3242  data_time: 0.0312  lr: 0.0022285  max_mem: 7344M
[12/10 23:39:46 d2.utils.events]:  eta: 0:47:19  iter: 1219  total_loss: 3.026  loss_sem_seg: 1.802  loss_center: 0.6194  loss_offset: 0.7488  time: 0.3242  data_time: 0.0272  lr: 0.002224  max_mem: 7344M
[12/10 23:39:52 d2.utils.events]:  eta: 0:47:13  iter: 1239  total_loss: 3.227  loss_sem_seg: 1.667  loss_center: 0.6061  loss_offset: 0.8732  time: 0.3243  data_time: 0.0299  lr: 0.0022194  max_mem: 7344M
[12/10 23:39:59 d2.utils.events]:  eta: 0:47:08  iter: 1259  total_loss: 3.27  loss_sem_seg: 1.966  loss_center: 0.5098  loss_offset: 0.8242  time: 0.3243  data_time: 0.0273  lr: 0.0022149  max_mem: 7344M
[12/10 23:40:05 d2.utils.events]:  eta: 0:47:00  iter: 1279  total_loss: 3.242  loss_sem_seg: 1.609  loss_center: 0.8049  loss_offset: 0.7716  time: 0.3242  data_time: 0.0277  lr: 0.0022103  max_mem: 7344M
[12/10 23:40:12 d2.utils.events]:  eta: 0:46:55  iter: 1299  total_loss: 3.243  loss_sem_seg: 1.769  loss_center: 0.5904  loss_offset: 0.8269  time: 0.3243  data_time: 0.0274  lr: 0.0022057  max_mem: 7344M
[12/10 23:40:18 d2.utils.events]:  eta: 0:46:49  iter: 1319  total_loss: 3.051  loss_sem_seg: 1.548  loss_center: 0.6649  loss_offset: 0.8847  time: 0.3243  data_time: 0.0272  lr: 0.0022012  max_mem: 7344M
[12/10 23:40:25 d2.utils.events]:  eta: 0:46:44  iter: 1339  total_loss: 3.082  loss_sem_seg: 1.579  loss_center: 0.6304  loss_offset: 0.7572  time: 0.3243  data_time: 0.0291  lr: 0.0021966  max_mem: 7344M
[12/10 23:40:32 d2.utils.events]:  eta: 0:46:37  iter: 1359  total_loss: 3.234  loss_sem_seg: 1.672  loss_center: 0.6742  loss_offset: 0.8354  time: 0.3243  data_time: 0.0267  lr: 0.002192  max_mem: 7344M
[12/10 23:40:38 d2.utils.events]:  eta: 0:46:31  iter: 1379  total_loss: 3.602  loss_sem_seg: 1.819  loss_center: 0.6196  loss_offset: 0.9353  time: 0.3244  data_time: 0.0290  lr: 0.0021875  max_mem: 7344M
[12/10 23:40:45 d2.utils.events]:  eta: 0:46:25  iter: 1399  total_loss: 2.872  loss_sem_seg: 1.517  loss_center: 0.6629  loss_offset: 0.6646  time: 0.3244  data_time: 0.0271  lr: 0.0021829  max_mem: 7344M
[12/10 23:40:51 d2.utils.events]:  eta: 0:46:18  iter: 1419  total_loss: 3.194  loss_sem_seg: 1.655  loss_center: 0.6863  loss_offset: 0.8172  time: 0.3244  data_time: 0.0294  lr: 0.0021783  max_mem: 7344M
[12/10 23:40:58 d2.utils.events]:  eta: 0:46:13  iter: 1439  total_loss: 2.781  loss_sem_seg: 1.446  loss_center: 0.5605  loss_offset: 0.8229  time: 0.3244  data_time: 0.0281  lr: 0.0021738  max_mem: 7344M
[12/10 23:41:04 d2.utils.events]:  eta: 0:46:08  iter: 1459  total_loss: 2.919  loss_sem_seg: 1.519  loss_center: 0.6113  loss_offset: 0.7367  time: 0.3245  data_time: 0.0286  lr: 0.0021692  max_mem: 7344M
[12/10 23:41:11 d2.utils.events]:  eta: 0:46:01  iter: 1479  total_loss: 3.204  loss_sem_seg: 1.84  loss_center: 0.5427  loss_offset: 0.8544  time: 0.3245  data_time: 0.0284  lr: 0.0021646  max_mem: 7344M
[12/10 23:41:17 d2.utils.events]:  eta: 0:45:55  iter: 1499  total_loss: 3.189  loss_sem_seg: 1.766  loss_center: 0.481  loss_offset: 0.7614  time: 0.3246  data_time: 0.0271  lr: 0.00216  max_mem: 7344M
[12/10 23:41:24 d2.utils.events]:  eta: 0:45:48  iter: 1519  total_loss: 3.111  loss_sem_seg: 1.595  loss_center: 0.6193  loss_offset: 0.7809  time: 0.3246  data_time: 0.0285  lr: 0.0021555  max_mem: 7344M
[12/10 23:41:30 d2.utils.events]:  eta: 0:45:42  iter: 1539  total_loss: 2.892  loss_sem_seg: 1.532  loss_center: 0.5919  loss_offset: 0.6822  time: 0.3246  data_time: 0.0310  lr: 0.0021509  max_mem: 7344M
[12/10 23:41:37 d2.utils.events]:  eta: 0:45:36  iter: 1559  total_loss: 3.028  loss_sem_seg: 1.45  loss_center: 0.6118  loss_offset: 0.7986  time: 0.3247  data_time: 0.0286  lr: 0.0021463  max_mem: 7344M
[12/10 23:41:44 d2.utils.events]:  eta: 0:45:29  iter: 1579  total_loss: 3.119  loss_sem_seg: 1.629  loss_center: 0.5513  loss_offset: 0.771  time: 0.3247  data_time: 0.0290  lr: 0.0021417  max_mem: 7344M
[12/10 23:41:50 d2.utils.events]:  eta: 0:45:23  iter: 1599  total_loss: 3.063  loss_sem_seg: 1.685  loss_center: 0.4866  loss_offset: 0.8036  time: 0.3247  data_time: 0.0291  lr: 0.0021372  max_mem: 7344M
[12/10 23:41:57 d2.utils.events]:  eta: 0:45:17  iter: 1619  total_loss: 3.104  loss_sem_seg: 1.591  loss_center: 0.5259  loss_offset: 0.8116  time: 0.3248  data_time: 0.0296  lr: 0.0021326  max_mem: 7344M
[12/10 23:42:03 d2.utils.events]:  eta: 0:45:12  iter: 1639  total_loss: 2.804  loss_sem_seg: 1.545  loss_center: 0.5878  loss_offset: 0.6927  time: 0.3248  data_time: 0.0306  lr: 0.002128  max_mem: 7344M
[12/10 23:42:10 d2.utils.events]:  eta: 0:45:06  iter: 1659  total_loss: 3.154  loss_sem_seg: 1.859  loss_center: 0.4875  loss_offset: 0.8318  time: 0.3249  data_time: 0.0304  lr: 0.0021234  max_mem: 7344M
[12/10 23:42:17 d2.utils.events]:  eta: 0:45:00  iter: 1679  total_loss: 3.005  loss_sem_seg: 1.668  loss_center: 0.6206  loss_offset: 0.7866  time: 0.3250  data_time: 0.0306  lr: 0.0021188  max_mem: 7344M
[12/10 23:42:23 d2.utils.events]:  eta: 0:44:54  iter: 1699  total_loss: 3.187  loss_sem_seg: 1.666  loss_center: 0.589  loss_offset: 0.7386  time: 0.3250  data_time: 0.0308  lr: 0.0021143  max_mem: 7344M
[12/10 23:42:30 d2.utils.events]:  eta: 0:44:47  iter: 1719  total_loss: 2.926  loss_sem_seg: 1.554  loss_center: 0.675  loss_offset: 0.6626  time: 0.3251  data_time: 0.0270  lr: 0.0021097  max_mem: 7344M
[12/10 23:42:36 d2.utils.events]:  eta: 0:44:42  iter: 1739  total_loss: 2.97  loss_sem_seg: 1.558  loss_center: 0.7238  loss_offset: 0.6779  time: 0.3251  data_time: 0.0315  lr: 0.0021051  max_mem: 7344M
[12/10 23:42:43 d2.utils.events]:  eta: 0:44:36  iter: 1759  total_loss: 2.945  loss_sem_seg: 1.551  loss_center: 0.565  loss_offset: 0.7005  time: 0.3252  data_time: 0.0305  lr: 0.0021005  max_mem: 7344M
[12/10 23:42:50 d2.utils.events]:  eta: 0:44:30  iter: 1779  total_loss: 3.061  loss_sem_seg: 1.42  loss_center: 0.6475  loss_offset: 0.7531  time: 0.3252  data_time: 0.0290  lr: 0.0020959  max_mem: 7344M
[12/10 23:42:56 d2.utils.events]:  eta: 0:44:25  iter: 1799  total_loss: 3.17  loss_sem_seg: 1.754  loss_center: 0.6046  loss_offset: 0.8121  time: 0.3253  data_time: 0.0300  lr: 0.0020913  max_mem: 7344M
[12/10 23:43:03 d2.utils.events]:  eta: 0:44:18  iter: 1819  total_loss: 2.856  loss_sem_seg: 1.724  loss_center: 0.536  loss_offset: 0.7266  time: 0.3253  data_time: 0.0285  lr: 0.0020867  max_mem: 7344M
[12/10 23:43:09 d2.utils.events]:  eta: 0:44:14  iter: 1839  total_loss: 2.949  loss_sem_seg: 1.762  loss_center: 0.5343  loss_offset: 0.5558  time: 0.3254  data_time: 0.0308  lr: 0.0020821  max_mem: 7344M
[12/10 23:43:16 d2.utils.events]:  eta: 0:44:09  iter: 1859  total_loss: 3.146  loss_sem_seg: 1.615  loss_center: 0.5423  loss_offset: 0.7505  time: 0.3254  data_time: 0.0300  lr: 0.0020775  max_mem: 7344M
[12/10 23:43:23 d2.utils.events]:  eta: 0:44:04  iter: 1879  total_loss: 3.076  loss_sem_seg: 1.55  loss_center: 0.6418  loss_offset: 0.7571  time: 0.3254  data_time: 0.0292  lr: 0.0020729  max_mem: 7344M
[12/10 23:43:29 d2.utils.events]:  eta: 0:43:58  iter: 1899  total_loss: 2.947  loss_sem_seg: 1.623  loss_center: 0.568  loss_offset: 0.7405  time: 0.3255  data_time: 0.0301  lr: 0.0020684  max_mem: 7344M
[12/10 23:43:36 d2.utils.events]:  eta: 0:43:52  iter: 1919  total_loss: 3.18  loss_sem_seg: 1.605  loss_center: 0.524  loss_offset: 0.7235  time: 0.3255  data_time: 0.0313  lr: 0.0020638  max_mem: 7344M
[12/10 23:43:42 d2.utils.events]:  eta: 0:43:46  iter: 1939  total_loss: 3.267  loss_sem_seg: 1.683  loss_center: 0.6171  loss_offset: 0.832  time: 0.3255  data_time: 0.0305  lr: 0.0020592  max_mem: 7344M
[12/10 23:43:49 d2.utils.events]:  eta: 0:43:41  iter: 1959  total_loss: 2.887  loss_sem_seg: 1.586  loss_center: 0.5191  loss_offset: 0.6764  time: 0.3256  data_time: 0.0303  lr: 0.0020546  max_mem: 7344M
[12/10 23:43:56 d2.utils.events]:  eta: 0:43:37  iter: 1979  total_loss: 3.264  loss_sem_seg: 1.739  loss_center: 0.6699  loss_offset: 0.8876  time: 0.3256  data_time: 0.0304  lr: 0.00205  max_mem: 7344M
[12/10 23:44:02 d2.utils.events]:  eta: 0:43:33  iter: 1999  total_loss: 3.199  loss_sem_seg: 1.744  loss_center: 0.6255  loss_offset: 0.8091  time: 0.3257  data_time: 0.0298  lr: 0.0020454  max_mem: 7344M
[12/10 23:44:09 d2.utils.events]:  eta: 0:43:29  iter: 2019  total_loss: 2.751  loss_sem_seg: 1.532  loss_center: 0.6662  loss_offset: 0.6902  time: 0.3257  data_time: 0.0300  lr: 0.0020408  max_mem: 7344M
[12/10 23:44:15 d2.utils.events]:  eta: 0:43:24  iter: 2039  total_loss: 2.635  loss_sem_seg: 1.359  loss_center: 0.6606  loss_offset: 0.6345  time: 0.3258  data_time: 0.0299  lr: 0.0020362  max_mem: 7344M
[12/10 23:44:22 d2.utils.events]:  eta: 0:43:19  iter: 2059  total_loss: 2.94  loss_sem_seg: 1.497  loss_center: 0.5757  loss_offset: 0.6681  time: 0.3259  data_time: 0.0311  lr: 0.0020316  max_mem: 7344M
[12/10 23:44:29 d2.utils.events]:  eta: 0:43:11  iter: 2079  total_loss: 2.967  loss_sem_seg: 1.603  loss_center: 0.5682  loss_offset: 0.8358  time: 0.3258  data_time: 0.0273  lr: 0.0020269  max_mem: 7344M
[12/10 23:44:35 d2.utils.events]:  eta: 0:43:04  iter: 2099  total_loss: 2.774  loss_sem_seg: 1.529  loss_center: 0.6325  loss_offset: 0.7515  time: 0.3258  data_time: 0.0294  lr: 0.0020223  max_mem: 7344M
[12/10 23:44:42 d2.utils.events]:  eta: 0:42:59  iter: 2119  total_loss: 2.91  loss_sem_seg: 1.507  loss_center: 0.5371  loss_offset: 0.8186  time: 0.3258  data_time: 0.0277  lr: 0.0020177  max_mem: 7344M
[12/10 23:44:48 d2.utils.events]:  eta: 0:42:54  iter: 2139  total_loss: 2.923  loss_sem_seg: 1.458  loss_center: 0.6455  loss_offset: 0.6538  time: 0.3258  data_time: 0.0262  lr: 0.0020131  max_mem: 7344M
[12/10 23:44:55 d2.utils.events]:  eta: 0:42:47  iter: 2159  total_loss: 2.788  loss_sem_seg: 1.616  loss_center: 0.563  loss_offset: 0.748  time: 0.3258  data_time: 0.0283  lr: 0.0020085  max_mem: 7344M
[12/10 23:45:01 d2.utils.events]:  eta: 0:42:40  iter: 2179  total_loss: 3.007  loss_sem_seg: 1.627  loss_center: 0.6717  loss_offset: 0.7462  time: 0.3257  data_time: 0.0262  lr: 0.0020039  max_mem: 7344M
[12/10 23:45:07 d2.utils.events]:  eta: 0:42:34  iter: 2199  total_loss: 2.771  loss_sem_seg: 1.453  loss_center: 0.5705  loss_offset: 0.7158  time: 0.3257  data_time: 0.0287  lr: 0.0019993  max_mem: 7344M
[12/10 23:45:14 d2.utils.events]:  eta: 0:42:27  iter: 2219  total_loss: 2.948  loss_sem_seg: 1.547  loss_center: 0.5417  loss_offset: 0.6129  time: 0.3257  data_time: 0.0270  lr: 0.0019947  max_mem: 7344M
[12/10 23:45:21 d2.utils.events]:  eta: 0:42:21  iter: 2239  total_loss: 2.668  loss_sem_seg: 1.421  loss_center: 0.5262  loss_offset: 0.7356  time: 0.3257  data_time: 0.0278  lr: 0.0019901  max_mem: 7344M
[12/10 23:45:27 d2.utils.events]:  eta: 0:42:13  iter: 2259  total_loss: 2.712  loss_sem_seg: 1.531  loss_center: 0.6085  loss_offset: 0.6114  time: 0.3257  data_time: 0.0273  lr: 0.0019854  max_mem: 7344M
[12/10 23:45:33 d2.utils.events]:  eta: 0:42:06  iter: 2279  total_loss: 2.871  loss_sem_seg: 1.376  loss_center: 0.6494  loss_offset: 0.7891  time: 0.3257  data_time: 0.0264  lr: 0.0019808  max_mem: 7344M
[12/10 23:45:40 d2.utils.events]:  eta: 0:42:00  iter: 2299  total_loss: 2.754  loss_sem_seg: 1.362  loss_center: 0.5898  loss_offset: 0.6645  time: 0.3256  data_time: 0.0269  lr: 0.0019762  max_mem: 7344M
[12/10 23:45:46 d2.utils.events]:  eta: 0:41:53  iter: 2319  total_loss: 3.082  loss_sem_seg: 1.603  loss_center: 0.5378  loss_offset: 0.6848  time: 0.3256  data_time: 0.0276  lr: 0.0019716  max_mem: 7344M
[12/10 23:45:53 d2.utils.events]:  eta: 0:41:45  iter: 2339  total_loss: 2.859  loss_sem_seg: 1.505  loss_center: 0.5433  loss_offset: 0.7272  time: 0.3256  data_time: 0.0281  lr: 0.001967  max_mem: 7344M
[12/10 23:45:59 d2.utils.events]:  eta: 0:41:39  iter: 2359  total_loss: 2.972  loss_sem_seg: 1.605  loss_center: 0.5331  loss_offset: 0.8846  time: 0.3256  data_time: 0.0270  lr: 0.0019623  max_mem: 7344M
[12/10 23:46:06 d2.utils.events]:  eta: 0:41:31  iter: 2379  total_loss: 2.986  loss_sem_seg: 1.628  loss_center: 0.6713  loss_offset: 0.6923  time: 0.3256  data_time: 0.0295  lr: 0.0019577  max_mem: 7344M
[12/10 23:46:12 d2.utils.events]:  eta: 0:41:26  iter: 2399  total_loss: 3.006  loss_sem_seg: 1.545  loss_center: 0.6647  loss_offset: 0.771  time: 0.3256  data_time: 0.0259  lr: 0.0019531  max_mem: 7344M
[12/10 23:46:19 d2.utils.events]:  eta: 0:41:18  iter: 2419  total_loss: 2.592  loss_sem_seg: 1.339  loss_center: 0.6231  loss_offset: 0.5924  time: 0.3256  data_time: 0.0280  lr: 0.0019485  max_mem: 7344M
[12/10 23:46:25 d2.utils.events]:  eta: 0:41:10  iter: 2439  total_loss: 2.909  loss_sem_seg: 1.436  loss_center: 0.6198  loss_offset: 0.8462  time: 0.3256  data_time: 0.0274  lr: 0.0019438  max_mem: 7344M
[12/10 23:46:32 d2.utils.events]:  eta: 0:41:02  iter: 2459  total_loss: 2.601  loss_sem_seg: 1.476  loss_center: 0.5887  loss_offset: 0.6766  time: 0.3255  data_time: 0.0278  lr: 0.0019392  max_mem: 7344M
[12/10 23:46:38 d2.utils.events]:  eta: 0:40:57  iter: 2479  total_loss: 2.945  loss_sem_seg: 1.536  loss_center: 0.5056  loss_offset: 0.7441  time: 0.3255  data_time: 0.0273  lr: 0.0019346  max_mem: 7344M
[12/10 23:46:45 d2.utils.events]:  eta: 0:40:49  iter: 2499  total_loss: 2.647  loss_sem_seg: 1.379  loss_center: 0.5074  loss_offset: 0.6251  time: 0.3255  data_time: 0.0267  lr: 0.00193  max_mem: 7344M
[12/10 23:46:51 d2.utils.events]:  eta: 0:40:43  iter: 2519  total_loss: 2.783  loss_sem_seg: 1.577  loss_center: 0.5525  loss_offset: 0.6356  time: 0.3255  data_time: 0.0295  lr: 0.0019253  max_mem: 7344M
[12/10 23:46:58 d2.utils.events]:  eta: 0:40:34  iter: 2539  total_loss: 2.574  loss_sem_seg: 1.422  loss_center: 0.5982  loss_offset: 0.5956  time: 0.3255  data_time: 0.0277  lr: 0.0019207  max_mem: 7344M
[12/10 23:47:04 d2.utils.events]:  eta: 0:40:27  iter: 2559  total_loss: 2.678  loss_sem_seg: 1.531  loss_center: 0.5718  loss_offset: 0.7225  time: 0.3255  data_time: 0.0297  lr: 0.0019161  max_mem: 7344M
[12/10 23:47:11 d2.utils.events]:  eta: 0:40:21  iter: 2579  total_loss: 2.775  loss_sem_seg: 1.348  loss_center: 0.7698  loss_offset: 0.711  time: 0.3255  data_time: 0.0289  lr: 0.0019114  max_mem: 7344M
[12/10 23:47:17 d2.utils.events]:  eta: 0:40:13  iter: 2599  total_loss: 3.038  loss_sem_seg: 1.614  loss_center: 0.6137  loss_offset: 0.6836  time: 0.3255  data_time: 0.0265  lr: 0.0019068  max_mem: 7344M
[12/10 23:47:24 d2.utils.events]:  eta: 0:40:05  iter: 2619  total_loss: 3.091  loss_sem_seg: 1.602  loss_center: 0.5907  loss_offset: 0.6691  time: 0.3255  data_time: 0.0283  lr: 0.0019021  max_mem: 7344M
[12/10 23:47:30 d2.utils.events]:  eta: 0:39:58  iter: 2639  total_loss: 2.579  loss_sem_seg: 1.367  loss_center: 0.5425  loss_offset: 0.6714  time: 0.3255  data_time: 0.0268  lr: 0.0018975  max_mem: 7344M
[12/10 23:47:37 d2.utils.events]:  eta: 0:39:48  iter: 2659  total_loss: 2.796  loss_sem_seg: 1.467  loss_center: 0.5665  loss_offset: 0.7004  time: 0.3255  data_time: 0.0283  lr: 0.0018929  max_mem: 7344M
[12/10 23:47:43 d2.utils.events]:  eta: 0:39:41  iter: 2679  total_loss: 2.728  loss_sem_seg: 1.34  loss_center: 0.4951  loss_offset: 0.7547  time: 0.3255  data_time: 0.0281  lr: 0.0018882  max_mem: 7344M
[12/10 23:47:50 d2.utils.events]:  eta: 0:39:33  iter: 2699  total_loss: 3.027  loss_sem_seg: 1.566  loss_center: 0.6056  loss_offset: 0.6573  time: 0.3254  data_time: 0.0278  lr: 0.0018836  max_mem: 7344M
[12/10 23:47:56 d2.utils.events]:  eta: 0:39:27  iter: 2719  total_loss: 2.645  loss_sem_seg: 1.414  loss_center: 0.5283  loss_offset: 0.6836  time: 0.3254  data_time: 0.0268  lr: 0.0018789  max_mem: 7344M
[12/10 23:48:03 d2.utils.events]:  eta: 0:39:19  iter: 2739  total_loss: 2.716  loss_sem_seg: 1.457  loss_center: 0.5556  loss_offset: 0.7605  time: 0.3254  data_time: 0.0266  lr: 0.0018743  max_mem: 7344M
[12/10 23:48:09 d2.utils.events]:  eta: 0:39:13  iter: 2759  total_loss: 2.585  loss_sem_seg: 1.243  loss_center: 0.644  loss_offset: 0.7772  time: 0.3254  data_time: 0.0271  lr: 0.0018696  max_mem: 7344M
[12/10 23:48:16 d2.utils.events]:  eta: 0:39:04  iter: 2779  total_loss: 2.868  loss_sem_seg: 1.334  loss_center: 0.7325  loss_offset: 0.6819  time: 0.3254  data_time: 0.0269  lr: 0.001865  max_mem: 7344M
[12/10 23:48:22 d2.utils.events]:  eta: 0:38:57  iter: 2799  total_loss: 2.484  loss_sem_seg: 1.245  loss_center: 0.458  loss_offset: 0.6986  time: 0.3253  data_time: 0.0262  lr: 0.0018603  max_mem: 7344M
[12/10 23:48:29 d2.utils.events]:  eta: 0:38:51  iter: 2819  total_loss: 2.398  loss_sem_seg: 1.281  loss_center: 0.6107  loss_offset: 0.6636  time: 0.3253  data_time: 0.0270  lr: 0.0018557  max_mem: 7344M
[12/10 23:48:35 d2.utils.events]:  eta: 0:38:43  iter: 2839  total_loss: 2.763  loss_sem_seg: 1.323  loss_center: 0.733  loss_offset: 0.6929  time: 0.3253  data_time: 0.0271  lr: 0.001851  max_mem: 7344M
[12/10 23:48:41 d2.utils.events]:  eta: 0:38:36  iter: 2859  total_loss: 2.797  loss_sem_seg: 1.206  loss_center: 0.5826  loss_offset: 0.6757  time: 0.3253  data_time: 0.0276  lr: 0.0018464  max_mem: 7344M
[12/10 23:48:48 d2.utils.events]:  eta: 0:38:29  iter: 2879  total_loss: 2.682  loss_sem_seg: 1.512  loss_center: 0.6471  loss_offset: 0.658  time: 0.3253  data_time: 0.0280  lr: 0.0018417  max_mem: 7344M
[12/10 23:48:54 d2.utils.events]:  eta: 0:38:22  iter: 2899  total_loss: 2.731  loss_sem_seg: 1.567  loss_center: 0.6436  loss_offset: 0.6732  time: 0.3253  data_time: 0.0304  lr: 0.0018371  max_mem: 7344M
[12/10 23:49:01 d2.utils.events]:  eta: 0:38:15  iter: 2919  total_loss: 3.093  loss_sem_seg: 1.636  loss_center: 0.5369  loss_offset: 0.6943  time: 0.3253  data_time: 0.0300  lr: 0.0018324  max_mem: 7344M
[12/10 23:49:07 d2.utils.events]:  eta: 0:38:08  iter: 2939  total_loss: 2.441  loss_sem_seg: 1.223  loss_center: 0.5167  loss_offset: 0.7137  time: 0.3253  data_time: 0.0284  lr: 0.0018278  max_mem: 7344M
[12/10 23:49:14 d2.utils.events]:  eta: 0:38:01  iter: 2959  total_loss: 2.911  loss_sem_seg: 1.508  loss_center: 0.5501  loss_offset: 0.7534  time: 0.3252  data_time: 0.0263  lr: 0.0018231  max_mem: 7344M
[12/10 23:49:20 d2.utils.events]:  eta: 0:37:52  iter: 2979  total_loss: 2.842  loss_sem_seg: 1.344  loss_center: 0.6235  loss_offset: 0.638  time: 0.3252  data_time: 0.0278  lr: 0.0018184  max_mem: 7344M
[12/10 23:49:27 d2.utils.events]:  eta: 0:37:45  iter: 2999  total_loss: 2.477  loss_sem_seg: 1.276  loss_center: 0.5159  loss_offset: 0.6394  time: 0.3252  data_time: 0.0279  lr: 0.0018138  max_mem: 7344M
[12/10 23:49:33 d2.utils.events]:  eta: 0:37:38  iter: 3019  total_loss: 2.819  loss_sem_seg: 1.497  loss_center: 0.6265  loss_offset: 0.7446  time: 0.3252  data_time: 0.0266  lr: 0.0018091  max_mem: 7344M
[12/10 23:49:40 d2.utils.events]:  eta: 0:37:31  iter: 3039  total_loss: 2.739  loss_sem_seg: 1.296  loss_center: 0.6216  loss_offset: 0.7783  time: 0.3252  data_time: 0.0271  lr: 0.0018044  max_mem: 7344M
[12/10 23:49:46 d2.utils.events]:  eta: 0:37:23  iter: 3059  total_loss: 2.282  loss_sem_seg: 1.268  loss_center: 0.4383  loss_offset: 0.5401  time: 0.3252  data_time: 0.0271  lr: 0.0017998  max_mem: 7344M
[12/10 23:49:53 d2.utils.events]:  eta: 0:37:17  iter: 3079  total_loss: 2.989  loss_sem_seg: 1.524  loss_center: 0.5152  loss_offset: 0.6657  time: 0.3252  data_time: 0.0289  lr: 0.0017951  max_mem: 7344M
[12/10 23:49:59 d2.utils.events]:  eta: 0:37:10  iter: 3099  total_loss: 2.668  loss_sem_seg: 1.517  loss_center: 0.5056  loss_offset: 0.6569  time: 0.3252  data_time: 0.0291  lr: 0.0017904  max_mem: 7344M
[12/10 23:50:06 d2.utils.events]:  eta: 0:37:04  iter: 3119  total_loss: 2.719  loss_sem_seg: 1.411  loss_center: 0.5451  loss_offset: 0.65  time: 0.3252  data_time: 0.0273  lr: 0.0017858  max_mem: 7344M
[12/10 23:50:12 d2.utils.events]:  eta: 0:36:57  iter: 3139  total_loss: 2.432  loss_sem_seg: 1.188  loss_center: 0.6466  loss_offset: 0.6656  time: 0.3252  data_time: 0.0287  lr: 0.0017811  max_mem: 7344M
[12/10 23:50:19 d2.utils.events]:  eta: 0:36:51  iter: 3159  total_loss: 2.611  loss_sem_seg: 1.245  loss_center: 0.5255  loss_offset: 0.5534  time: 0.3252  data_time: 0.0275  lr: 0.0017764  max_mem: 7344M
[12/10 23:50:25 d2.utils.events]:  eta: 0:36:44  iter: 3179  total_loss: 2.655  loss_sem_seg: 1.317  loss_center: 0.6795  loss_offset: 0.6687  time: 0.3252  data_time: 0.0282  lr: 0.0017718  max_mem: 7344M
[12/10 23:50:32 d2.utils.events]:  eta: 0:36:38  iter: 3199  total_loss: 2.786  loss_sem_seg: 1.428  loss_center: 0.4805  loss_offset: 0.786  time: 0.3251  data_time: 0.0256  lr: 0.0017671  max_mem: 7344M
[12/10 23:50:38 d2.utils.events]:  eta: 0:36:32  iter: 3219  total_loss: 2.494  loss_sem_seg: 1.296  loss_center: 0.5581  loss_offset: 0.7738  time: 0.3251  data_time: 0.0274  lr: 0.0017624  max_mem: 7344M
[12/10 23:50:45 d2.utils.events]:  eta: 0:36:25  iter: 3239  total_loss: 2.622  loss_sem_seg: 1.281  loss_center: 0.6446  loss_offset: 0.5707  time: 0.3251  data_time: 0.0274  lr: 0.0017577  max_mem: 7344M
[12/10 23:50:51 d2.utils.events]:  eta: 0:36:18  iter: 3259  total_loss: 2.769  loss_sem_seg: 1.435  loss_center: 0.6375  loss_offset: 0.7243  time: 0.3251  data_time: 0.0276  lr: 0.001753  max_mem: 7344M
[12/10 23:50:58 d2.utils.events]:  eta: 0:36:12  iter: 3279  total_loss: 2.647  loss_sem_seg: 1.317  loss_center: 0.5531  loss_offset: 0.6876  time: 0.3251  data_time: 0.0289  lr: 0.0017484  max_mem: 7344M
[12/10 23:51:04 d2.utils.events]:  eta: 0:36:06  iter: 3299  total_loss: 2.565  loss_sem_seg: 1.347  loss_center: 0.6137  loss_offset: 0.577  time: 0.3251  data_time: 0.0279  lr: 0.0017437  max_mem: 7344M
[12/10 23:51:11 d2.utils.events]:  eta: 0:35:59  iter: 3319  total_loss: 2.747  loss_sem_seg: 1.421  loss_center: 0.636  loss_offset: 0.6558  time: 0.3251  data_time: 0.0289  lr: 0.001739  max_mem: 7344M
[12/10 23:51:17 d2.utils.events]:  eta: 0:35:53  iter: 3339  total_loss: 2.696  loss_sem_seg: 1.349  loss_center: 0.4955  loss_offset: 0.641  time: 0.3251  data_time: 0.0276  lr: 0.0017343  max_mem: 7344M
[12/10 23:51:24 d2.utils.events]:  eta: 0:35:46  iter: 3359  total_loss: 2.637  loss_sem_seg: 1.266  loss_center: 0.6054  loss_offset: 0.6984  time: 0.3251  data_time: 0.0267  lr: 0.0017296  max_mem: 7344M
[12/10 23:51:30 d2.utils.events]:  eta: 0:35:40  iter: 3379  total_loss: 2.743  loss_sem_seg: 1.34  loss_center: 0.6517  loss_offset: 0.6775  time: 0.3251  data_time: 0.0258  lr: 0.0017249  max_mem: 7344M
[12/10 23:51:37 d2.utils.events]:  eta: 0:35:33  iter: 3399  total_loss: 2.559  loss_sem_seg: 1.226  loss_center: 0.6805  loss_offset: 0.6284  time: 0.3251  data_time: 0.0260  lr: 0.0017202  max_mem: 7344M
[12/10 23:51:43 d2.utils.events]:  eta: 0:35:27  iter: 3419  total_loss: 2.812  loss_sem_seg: 1.315  loss_center: 0.4709  loss_offset: 0.8274  time: 0.3250  data_time: 0.0281  lr: 0.0017155  max_mem: 7344M
[12/10 23:51:49 d2.utils.events]:  eta: 0:35:21  iter: 3439  total_loss: 2.299  loss_sem_seg: 1.081  loss_center: 0.6368  loss_offset: 0.5506  time: 0.3250  data_time: 0.0260  lr: 0.0017109  max_mem: 7344M
[12/10 23:51:56 d2.utils.events]:  eta: 0:35:15  iter: 3459  total_loss: 2.715  loss_sem_seg: 1.376  loss_center: 0.6076  loss_offset: 0.6685  time: 0.3250  data_time: 0.0273  lr: 0.0017062  max_mem: 7344M
[12/10 23:52:02 d2.utils.events]:  eta: 0:35:07  iter: 3479  total_loss: 2.465  loss_sem_seg: 1.295  loss_center: 0.5568  loss_offset: 0.6371  time: 0.3250  data_time: 0.0285  lr: 0.0017015  max_mem: 7344M
[12/10 23:52:09 d2.utils.events]:  eta: 0:35:01  iter: 3499  total_loss: 2.617  loss_sem_seg: 1.302  loss_center: 0.5561  loss_offset: 0.5903  time: 0.3250  data_time: 0.0261  lr: 0.0016968  max_mem: 7344M
[12/10 23:52:15 d2.utils.events]:  eta: 0:34:55  iter: 3519  total_loss: 2.677  loss_sem_seg: 1.293  loss_center: 0.4428  loss_offset: 0.7597  time: 0.3250  data_time: 0.0268  lr: 0.0016921  max_mem: 7344M
[12/10 23:52:22 d2.utils.events]:  eta: 0:34:48  iter: 3539  total_loss: 2.541  loss_sem_seg: 1.345  loss_center: 0.5167  loss_offset: 0.6353  time: 0.3250  data_time: 0.0277  lr: 0.0016874  max_mem: 7344M
[12/10 23:52:28 d2.utils.events]:  eta: 0:34:42  iter: 3559  total_loss: 2.483  loss_sem_seg: 1.126  loss_center: 0.5907  loss_offset: 0.5744  time: 0.3250  data_time: 0.0279  lr: 0.0016827  max_mem: 7344M
[12/10 23:52:35 d2.utils.events]:  eta: 0:34:35  iter: 3579  total_loss: 2.632  loss_sem_seg: 1.338  loss_center: 0.5545  loss_offset: 0.7026  time: 0.3250  data_time: 0.0272  lr: 0.001678  max_mem: 7344M
[12/10 23:52:41 d2.utils.events]:  eta: 0:34:29  iter: 3599  total_loss: 2.854  loss_sem_seg: 1.393  loss_center: 0.5955  loss_offset: 0.6478  time: 0.3250  data_time: 0.0271  lr: 0.0016733  max_mem: 7344M
[12/10 23:52:48 d2.utils.events]:  eta: 0:34:22  iter: 3619  total_loss: 2.633  loss_sem_seg: 1.391  loss_center: 0.5179  loss_offset: 0.6396  time: 0.3250  data_time: 0.0272  lr: 0.0016686  max_mem: 7344M
[12/10 23:52:54 d2.utils.events]:  eta: 0:34:15  iter: 3639  total_loss: 2.747  loss_sem_seg: 1.307  loss_center: 0.6149  loss_offset: 0.6146  time: 0.3249  data_time: 0.0257  lr: 0.0016638  max_mem: 7344M
[12/10 23:53:01 d2.utils.events]:  eta: 0:34:09  iter: 3659  total_loss: 2.583  loss_sem_seg: 1.338  loss_center: 0.5576  loss_offset: 0.6467  time: 0.3249  data_time: 0.0265  lr: 0.0016591  max_mem: 7344M
[12/10 23:53:07 d2.utils.events]:  eta: 0:34:03  iter: 3679  total_loss: 2.69  loss_sem_seg: 1.361  loss_center: 0.6502  loss_offset: 0.6121  time: 0.3249  data_time: 0.0272  lr: 0.0016544  max_mem: 7344M
[12/10 23:53:14 d2.utils.events]:  eta: 0:33:57  iter: 3699  total_loss: 2.595  loss_sem_seg: 1.28  loss_center: 0.6512  loss_offset: 0.6962  time: 0.3249  data_time: 0.0260  lr: 0.0016497  max_mem: 7344M
[12/10 23:53:20 d2.utils.events]:  eta: 0:33:50  iter: 3719  total_loss: 2.548  loss_sem_seg: 1.369  loss_center: 0.5267  loss_offset: 0.588  time: 0.3249  data_time: 0.0284  lr: 0.001645  max_mem: 7344M
[12/10 23:53:27 d2.utils.events]:  eta: 0:33:43  iter: 3739  total_loss: 2.605  loss_sem_seg: 1.351  loss_center: 0.516  loss_offset: 0.6488  time: 0.3249  data_time: 0.0279  lr: 0.0016403  max_mem: 7344M
[12/10 23:53:33 d2.utils.events]:  eta: 0:33:37  iter: 3759  total_loss: 2.543  loss_sem_seg: 1.301  loss_center: 0.5965  loss_offset: 0.6334  time: 0.3249  data_time: 0.0265  lr: 0.0016356  max_mem: 7344M
[12/10 23:53:40 d2.utils.events]:  eta: 0:33:31  iter: 3779  total_loss: 2.477  loss_sem_seg: 1.177  loss_center: 0.6034  loss_offset: 0.5888  time: 0.3249  data_time: 0.0273  lr: 0.0016309  max_mem: 7344M
[12/10 23:53:46 d2.utils.events]:  eta: 0:33:24  iter: 3799  total_loss: 2.333  loss_sem_seg: 1.12  loss_center: 0.557  loss_offset: 0.7138  time: 0.3248  data_time: 0.0276  lr: 0.0016261  max_mem: 7344M
[12/10 23:53:52 d2.utils.events]:  eta: 0:33:18  iter: 3819  total_loss: 2.518  loss_sem_seg: 1.149  loss_center: 0.6755  loss_offset: 0.606  time: 0.3248  data_time: 0.0265  lr: 0.0016214  max_mem: 7344M
[12/10 23:53:59 d2.utils.events]:  eta: 0:33:11  iter: 3839  total_loss: 2.648  loss_sem_seg: 1.333  loss_center: 0.6753  loss_offset: 0.6139  time: 0.3248  data_time: 0.0272  lr: 0.0016167  max_mem: 7344M
[12/10 23:54:05 d2.utils.events]:  eta: 0:33:05  iter: 3859  total_loss: 2.648  loss_sem_seg: 1.28  loss_center: 0.6111  loss_offset: 0.6041  time: 0.3248  data_time: 0.0268  lr: 0.001612  max_mem: 7344M
[12/10 23:54:12 d2.utils.events]:  eta: 0:32:58  iter: 3879  total_loss: 2.478  loss_sem_seg: 1.108  loss_center: 0.5286  loss_offset: 0.7246  time: 0.3248  data_time: 0.0277  lr: 0.0016072  max_mem: 7344M
[12/10 23:54:18 d2.utils.events]:  eta: 0:32:52  iter: 3899  total_loss: 2.796  loss_sem_seg: 1.318  loss_center: 0.6619  loss_offset: 0.6859  time: 0.3248  data_time: 0.0256  lr: 0.0016025  max_mem: 7344M
[12/10 23:54:25 d2.utils.events]:  eta: 0:32:45  iter: 3919  total_loss: 2.542  loss_sem_seg: 1.224  loss_center: 0.6125  loss_offset: 0.5461  time: 0.3248  data_time: 0.0271  lr: 0.0015978  max_mem: 7344M
[12/10 23:54:31 d2.utils.events]:  eta: 0:32:39  iter: 3939  total_loss: 2.901  loss_sem_seg: 1.579  loss_center: 0.5307  loss_offset: 0.7727  time: 0.3248  data_time: 0.0284  lr: 0.0015931  max_mem: 7344M
[12/10 23:54:38 d2.utils.events]:  eta: 0:32:33  iter: 3959  total_loss: 2.593  loss_sem_seg: 1.199  loss_center: 0.5962  loss_offset: 0.618  time: 0.3248  data_time: 0.0278  lr: 0.0015883  max_mem: 7344M
[12/10 23:54:44 d2.utils.events]:  eta: 0:32:26  iter: 3979  total_loss: 2.763  loss_sem_seg: 1.456  loss_center: 0.4847  loss_offset: 0.6547  time: 0.3248  data_time: 0.0273  lr: 0.0015836  max_mem: 7344M
[12/10 23:54:51 d2.utils.events]:  eta: 0:32:20  iter: 3999  total_loss: 2.927  loss_sem_seg: 1.411  loss_center: 0.5819  loss_offset: 0.6806  time: 0.3248  data_time: 0.0299  lr: 0.0015789  max_mem: 7344M
[12/10 23:54:57 d2.utils.events]:  eta: 0:32:13  iter: 4019  total_loss: 2.739  loss_sem_seg: 1.452  loss_center: 0.5198  loss_offset: 0.6367  time: 0.3248  data_time: 0.0261  lr: 0.0015741  max_mem: 7344M
[12/10 23:55:04 d2.utils.events]:  eta: 0:32:07  iter: 4039  total_loss: 2.435  loss_sem_seg: 1.207  loss_center: 0.5421  loss_offset: 0.5108  time: 0.3248  data_time: 0.0278  lr: 0.0015694  max_mem: 7344M
[12/10 23:55:10 d2.utils.events]:  eta: 0:32:00  iter: 4059  total_loss: 2.528  loss_sem_seg: 1.268  loss_center: 0.4971  loss_offset: 0.6168  time: 0.3248  data_time: 0.0273  lr: 0.0015646  max_mem: 7344M
[12/10 23:55:17 d2.utils.events]:  eta: 0:31:54  iter: 4079  total_loss: 2.614  loss_sem_seg: 1.297  loss_center: 0.5509  loss_offset: 0.6596  time: 0.3248  data_time: 0.0276  lr: 0.0015599  max_mem: 7344M
[12/10 23:55:23 d2.utils.events]:  eta: 0:31:47  iter: 4099  total_loss: 2.532  loss_sem_seg: 1.332  loss_center: 0.45  loss_offset: 0.6  time: 0.3248  data_time: 0.0285  lr: 0.0015552  max_mem: 7344M
[12/10 23:55:30 d2.utils.events]:  eta: 0:31:39  iter: 4119  total_loss: 2.602  loss_sem_seg: 1.328  loss_center: 0.6295  loss_offset: 0.6773  time: 0.3248  data_time: 0.0281  lr: 0.0015504  max_mem: 7344M
[12/10 23:55:36 d2.utils.events]:  eta: 0:31:32  iter: 4139  total_loss: 2.58  loss_sem_seg: 1.279  loss_center: 0.6179  loss_offset: 0.7445  time: 0.3248  data_time: 0.0282  lr: 0.0015457  max_mem: 7344M
[12/10 23:55:43 d2.utils.events]:  eta: 0:31:26  iter: 4159  total_loss: 2.638  loss_sem_seg: 1.295  loss_center: 0.5966  loss_offset: 0.5336  time: 0.3248  data_time: 0.0278  lr: 0.0015409  max_mem: 7344M
[12/10 23:55:49 d2.utils.events]:  eta: 0:31:20  iter: 4179  total_loss: 2.524  loss_sem_seg: 1.268  loss_center: 0.529  loss_offset: 0.6402  time: 0.3248  data_time: 0.0278  lr: 0.0015362  max_mem: 7344M
[12/10 23:55:56 d2.utils.events]:  eta: 0:31:12  iter: 4199  total_loss: 2.878  loss_sem_seg: 1.369  loss_center: 0.4899  loss_offset: 0.6424  time: 0.3247  data_time: 0.0286  lr: 0.0015314  max_mem: 7344M
[12/10 23:56:02 d2.utils.events]:  eta: 0:31:06  iter: 4219  total_loss: 2.454  loss_sem_seg: 1.24  loss_center: 0.5271  loss_offset: 0.6441  time: 0.3247  data_time: 0.0270  lr: 0.0015267  max_mem: 7344M
[12/10 23:56:09 d2.utils.events]:  eta: 0:30:59  iter: 4239  total_loss: 2.509  loss_sem_seg: 1.342  loss_center: 0.5847  loss_offset: 0.6426  time: 0.3247  data_time: 0.0272  lr: 0.0015219  max_mem: 7344M
[12/10 23:56:15 d2.utils.events]:  eta: 0:30:53  iter: 4259  total_loss: 2.699  loss_sem_seg: 1.309  loss_center: 0.5759  loss_offset: 0.7711  time: 0.3247  data_time: 0.0257  lr: 0.0015172  max_mem: 7344M
[12/10 23:56:22 d2.utils.events]:  eta: 0:30:45  iter: 4279  total_loss: 2.47  loss_sem_seg: 1.284  loss_center: 0.4703  loss_offset: 0.732  time: 0.3247  data_time: 0.0275  lr: 0.0015124  max_mem: 7344M
[12/10 23:56:28 d2.utils.events]:  eta: 0:30:38  iter: 4299  total_loss: 2.511  loss_sem_seg: 1.184  loss_center: 0.4625  loss_offset: 0.7299  time: 0.3247  data_time: 0.0268  lr: 0.0015076  max_mem: 7344M
[12/10 23:56:34 d2.utils.events]:  eta: 0:30:33  iter: 4319  total_loss: 2.409  loss_sem_seg: 1.28  loss_center: 0.6743  loss_offset: 0.6521  time: 0.3247  data_time: 0.0248  lr: 0.0015029  max_mem: 7344M
[12/10 23:56:41 d2.utils.events]:  eta: 0:30:26  iter: 4339  total_loss: 2.446  loss_sem_seg: 1.11  loss_center: 0.5302  loss_offset: 0.7268  time: 0.3247  data_time: 0.0265  lr: 0.0014981  max_mem: 7344M
[12/10 23:56:47 d2.utils.events]:  eta: 0:30:21  iter: 4359  total_loss: 2.662  loss_sem_seg: 1.361  loss_center: 0.4701  loss_offset: 0.6546  time: 0.3247  data_time: 0.0270  lr: 0.0014933  max_mem: 7344M
[12/10 23:56:54 d2.utils.events]:  eta: 0:30:15  iter: 4379  total_loss: 2.829  loss_sem_seg: 1.42  loss_center: 0.6029  loss_offset: 0.6303  time: 0.3247  data_time: 0.0271  lr: 0.0014886  max_mem: 7344M
[12/10 23:57:00 d2.utils.events]:  eta: 0:30:10  iter: 4399  total_loss: 2.312  loss_sem_seg: 1.139  loss_center: 0.5447  loss_offset: 0.5772  time: 0.3247  data_time: 0.0267  lr: 0.0014838  max_mem: 7344M
[12/10 23:57:07 d2.utils.events]:  eta: 0:30:04  iter: 4419  total_loss: 2.656  loss_sem_seg: 1.3  loss_center: 0.4678  loss_offset: 0.6592  time: 0.3247  data_time: 0.0267  lr: 0.001479  max_mem: 7344M
[12/10 23:57:13 d2.utils.events]:  eta: 0:29:57  iter: 4439  total_loss: 2.474  loss_sem_seg: 1.445  loss_center: 0.494  loss_offset: 0.6142  time: 0.3246  data_time: 0.0265  lr: 0.0014743  max_mem: 7344M
[12/10 23:57:20 d2.utils.events]:  eta: 0:29:51  iter: 4459  total_loss: 2.691  loss_sem_seg: 1.374  loss_center: 0.6125  loss_offset: 0.7081  time: 0.3246  data_time: 0.0272  lr: 0.0014695  max_mem: 7344M
[12/10 23:57:26 d2.utils.events]:  eta: 0:29:44  iter: 4479  total_loss: 2.438  loss_sem_seg: 1.218  loss_center: 0.5376  loss_offset: 0.7301  time: 0.3246  data_time: 0.0277  lr: 0.0014647  max_mem: 7344M
[12/10 23:57:33 d2.utils.events]:  eta: 0:29:38  iter: 4499  total_loss: 2.753  loss_sem_seg: 1.289  loss_center: 0.5751  loss_offset: 0.6576  time: 0.3246  data_time: 0.0277  lr: 0.0014599  max_mem: 7344M
[12/10 23:57:39 d2.utils.events]:  eta: 0:29:32  iter: 4519  total_loss: 2.579  loss_sem_seg: 1.293  loss_center: 0.502  loss_offset: 0.6915  time: 0.3246  data_time: 0.0266  lr: 0.0014552  max_mem: 7344M
[12/10 23:57:46 d2.utils.events]:  eta: 0:29:25  iter: 4539  total_loss: 2.317  loss_sem_seg: 1.18  loss_center: 0.5832  loss_offset: 0.5458  time: 0.3246  data_time: 0.0273  lr: 0.0014504  max_mem: 7344M
[12/10 23:57:52 d2.utils.events]:  eta: 0:29:18  iter: 4559  total_loss: 2.532  loss_sem_seg: 1.219  loss_center: 0.6364  loss_offset: 0.6166  time: 0.3246  data_time: 0.0269  lr: 0.0014456  max_mem: 7344M
[12/10 23:57:59 d2.utils.events]:  eta: 0:29:12  iter: 4579  total_loss: 2.597  loss_sem_seg: 1.39  loss_center: 0.6253  loss_offset: 0.6837  time: 0.3246  data_time: 0.0292  lr: 0.0014408  max_mem: 7344M
[12/10 23:58:05 d2.utils.events]:  eta: 0:29:05  iter: 4599  total_loss: 2.504  loss_sem_seg: 1.296  loss_center: 0.6473  loss_offset: 0.6182  time: 0.3246  data_time: 0.0269  lr: 0.001436  max_mem: 7344M
[12/10 23:58:12 d2.utils.events]:  eta: 0:28:59  iter: 4619  total_loss: 2.447  loss_sem_seg: 1.212  loss_center: 0.5298  loss_offset: 0.6726  time: 0.3246  data_time: 0.0277  lr: 0.0014313  max_mem: 7344M
[12/10 23:58:18 d2.utils.events]:  eta: 0:28:52  iter: 4639  total_loss: 2.46  loss_sem_seg: 1.241  loss_center: 0.5883  loss_offset: 0.6906  time: 0.3246  data_time: 0.0274  lr: 0.0014265  max_mem: 7344M
[12/10 23:58:25 d2.utils.events]:  eta: 0:28:46  iter: 4659  total_loss: 2.658  loss_sem_seg: 1.162  loss_center: 0.6494  loss_offset: 0.7078  time: 0.3246  data_time: 0.0271  lr: 0.0014217  max_mem: 7344M
[12/10 23:58:31 d2.utils.events]:  eta: 0:28:40  iter: 4679  total_loss: 2.342  loss_sem_seg: 1.164  loss_center: 0.4748  loss_offset: 0.6361  time: 0.3246  data_time: 0.0288  lr: 0.0014169  max_mem: 7344M
[12/10 23:58:38 d2.utils.events]:  eta: 0:28:33  iter: 4699  total_loss: 2.544  loss_sem_seg: 1.255  loss_center: 0.4427  loss_offset: 0.6312  time: 0.3246  data_time: 0.0268  lr: 0.0014121  max_mem: 7344M
[12/10 23:58:44 d2.utils.events]:  eta: 0:28:28  iter: 4719  total_loss: 2.1  loss_sem_seg: 1.105  loss_center: 0.5296  loss_offset: 0.4869  time: 0.3246  data_time: 0.0284  lr: 0.0014073  max_mem: 7344M
[12/10 23:58:51 d2.utils.events]:  eta: 0:28:22  iter: 4739  total_loss: 2.418  loss_sem_seg: 1.134  loss_center: 0.5198  loss_offset: 0.6053  time: 0.3246  data_time: 0.0279  lr: 0.0014025  max_mem: 7344M
[12/10 23:58:57 d2.utils.events]:  eta: 0:28:15  iter: 4759  total_loss: 2.624  loss_sem_seg: 1.282  loss_center: 0.6454  loss_offset: 0.6595  time: 0.3246  data_time: 0.0283  lr: 0.0013977  max_mem: 7344M
[12/10 23:59:04 d2.utils.events]:  eta: 0:28:09  iter: 4779  total_loss: 2.391  loss_sem_seg: 1.45  loss_center: 0.5025  loss_offset: 0.5471  time: 0.3246  data_time: 0.0272  lr: 0.0013929  max_mem: 7344M
[12/10 23:59:10 d2.utils.events]:  eta: 0:28:01  iter: 4799  total_loss: 2.646  loss_sem_seg: 1.185  loss_center: 0.6258  loss_offset: 0.5937  time: 0.3246  data_time: 0.0262  lr: 0.0013881  max_mem: 7344M
[12/10 23:59:17 d2.utils.events]:  eta: 0:27:55  iter: 4819  total_loss: 2.624  loss_sem_seg: 1.325  loss_center: 0.5072  loss_offset: 0.6738  time: 0.3246  data_time: 0.0288  lr: 0.0013833  max_mem: 7344M
[12/10 23:59:23 d2.utils.events]:  eta: 0:27:48  iter: 4839  total_loss: 2.42  loss_sem_seg: 1.208  loss_center: 0.5757  loss_offset: 0.5844  time: 0.3246  data_time: 0.0267  lr: 0.0013785  max_mem: 7344M
[12/10 23:59:30 d2.utils.events]:  eta: 0:27:43  iter: 4859  total_loss: 2.635  loss_sem_seg: 1.337  loss_center: 0.5153  loss_offset: 0.6415  time: 0.3246  data_time: 0.0285  lr: 0.0013737  max_mem: 7344M
[12/10 23:59:36 d2.utils.events]:  eta: 0:27:36  iter: 4879  total_loss: 2.402  loss_sem_seg: 1.244  loss_center: 0.5156  loss_offset: 0.6118  time: 0.3246  data_time: 0.0249  lr: 0.0013689  max_mem: 7344M
[12/10 23:59:42 d2.utils.events]:  eta: 0:27:29  iter: 4899  total_loss: 2.389  loss_sem_seg: 1.242  loss_center: 0.46  loss_offset: 0.5807  time: 0.3246  data_time: 0.0266  lr: 0.001364  max_mem: 7344M
[12/10 23:59:49 d2.utils.events]:  eta: 0:27:22  iter: 4919  total_loss: 2.272  loss_sem_seg: 1.115  loss_center: 0.4246  loss_offset: 0.5277  time: 0.3246  data_time: 0.0269  lr: 0.0013592  max_mem: 7344M
[12/10 23:59:55 d2.utils.events]:  eta: 0:27:15  iter: 4939  total_loss: 2.463  loss_sem_seg: 1.026  loss_center: 0.6301  loss_offset: 0.6069  time: 0.3246  data_time: 0.0275  lr: 0.0013544  max_mem: 7344M
[12/11 00:00:02 d2.utils.events]:  eta: 0:27:08  iter: 4959  total_loss: 2.321  loss_sem_seg: 1.182  loss_center: 0.6085  loss_offset: 0.5934  time: 0.3246  data_time: 0.0272  lr: 0.0013496  max_mem: 7344M
[12/11 00:00:08 d2.utils.events]:  eta: 0:27:02  iter: 4979  total_loss: 2.541  loss_sem_seg: 1.279  loss_center: 0.5194  loss_offset: 0.5548  time: 0.3246  data_time: 0.0267  lr: 0.0013448  max_mem: 7344M
[12/11 00:00:15 fvcore.common.checkpoint]: Saving checkpoint to ./output/model_0004999.pth
[12/11 00:00:15 d2.utils.events]:  eta: 0:26:55  iter: 4999  total_loss: 2.47  loss_sem_seg: 1.135  loss_center: 0.6065  loss_offset: 0.7012  time: 0.3245  data_time: 0.0274  lr: 0.00134  max_mem: 7344M
[12/11 00:00:23 d2.utils.events]:  eta: 0:26:50  iter: 5019  total_loss: 2.378  loss_sem_seg: 1.135  loss_center: 0.6264  loss_offset: 0.5978  time: 0.3245  data_time: 0.0277  lr: 0.0013351  max_mem: 7344M
[12/11 00:00:29 d2.utils.events]:  eta: 0:26:42  iter: 5039  total_loss: 2.433  loss_sem_seg: 1.224  loss_center: 0.5424  loss_offset: 0.6643  time: 0.3245  data_time: 0.0263  lr: 0.0013303  max_mem: 7344M
[12/11 00:00:35 d2.utils.events]:  eta: 0:26:36  iter: 5059  total_loss: 2.277  loss_sem_seg: 1.166  loss_center: 0.4722  loss_offset: 0.5648  time: 0.3245  data_time: 0.0261  lr: 0.0013255  max_mem: 7344M
[12/11 00:00:42 d2.utils.events]:  eta: 0:26:30  iter: 5079  total_loss: 2.375  loss_sem_seg: 1.089  loss_center: 0.4914  loss_offset: 0.6597  time: 0.3245  data_time: 0.0278  lr: 0.0013207  max_mem: 7344M
[12/11 00:00:48 d2.utils.events]:  eta: 0:26:24  iter: 5099  total_loss: 2.569  loss_sem_seg: 1.274  loss_center: 0.4991  loss_offset: 0.6993  time: 0.3245  data_time: 0.0256  lr: 0.0013158  max_mem: 7344M
[12/11 00:00:55 d2.utils.events]:  eta: 0:26:17  iter: 5119  total_loss: 2.48  loss_sem_seg: 1.264  loss_center: 0.5123  loss_offset: 0.5846  time: 0.3245  data_time: 0.0276  lr: 0.001311  max_mem: 7344M
[12/11 00:01:01 d2.utils.events]:  eta: 0:26:11  iter: 5139  total_loss: 2.203  loss_sem_seg: 1.078  loss_center: 0.4793  loss_offset: 0.5187  time: 0.3245  data_time: 0.0273  lr: 0.0013062  max_mem: 7344M
[12/11 00:01:08 d2.utils.events]:  eta: 0:26:04  iter: 5159  total_loss: 2.232  loss_sem_seg: 1.121  loss_center: 0.581  loss_offset: 0.581  time: 0.3245  data_time: 0.0265  lr: 0.0013013  max_mem: 7344M
[12/11 00:01:14 d2.utils.events]:  eta: 0:25:57  iter: 5179  total_loss: 2.819  loss_sem_seg: 1.353  loss_center: 0.543  loss_offset: 0.6783  time: 0.3245  data_time: 0.0266  lr: 0.0012965  max_mem: 7344M
[12/11 00:01:21 d2.utils.events]:  eta: 0:25:50  iter: 5199  total_loss: 2.39  loss_sem_seg: 1.258  loss_center: 0.5441  loss_offset: 0.645  time: 0.3245  data_time: 0.0253  lr: 0.0012916  max_mem: 7344M
[12/11 00:01:27 d2.utils.events]:  eta: 0:25:45  iter: 5219  total_loss: 2.497  loss_sem_seg: 1.323  loss_center: 0.5052  loss_offset: 0.5173  time: 0.3245  data_time: 0.0274  lr: 0.0012868  max_mem: 7344M
[12/11 00:01:34 d2.utils.events]:  eta: 0:25:38  iter: 5239  total_loss: 2.6  loss_sem_seg: 1.234  loss_center: 0.5787  loss_offset: 0.5935  time: 0.3245  data_time: 0.0271  lr: 0.0012819  max_mem: 7344M
[12/11 00:01:40 d2.utils.events]:  eta: 0:25:32  iter: 5259  total_loss: 2.289  loss_sem_seg: 1.039  loss_center: 0.5792  loss_offset: 0.5389  time: 0.3245  data_time: 0.0268  lr: 0.0012771  max_mem: 7344M
[12/11 00:01:47 d2.utils.events]:  eta: 0:25:25  iter: 5279  total_loss: 2.401  loss_sem_seg: 1.211  loss_center: 0.5602  loss_offset: 0.6428  time: 0.3245  data_time: 0.0270  lr: 0.0012722  max_mem: 7344M
[12/11 00:01:53 d2.utils.events]:  eta: 0:25:19  iter: 5299  total_loss: 2.501  loss_sem_seg: 1.295  loss_center: 0.6108  loss_offset: 0.6496  time: 0.3245  data_time: 0.0280  lr: 0.0012674  max_mem: 7344M
[12/11 00:02:00 d2.utils.events]:  eta: 0:25:12  iter: 5319  total_loss: 2.304  loss_sem_seg: 1.168  loss_center: 0.5712  loss_offset: 0.6516  time: 0.3245  data_time: 0.0282  lr: 0.0012625  max_mem: 7344M
[12/11 00:02:06 d2.utils.events]:  eta: 0:25:06  iter: 5339  total_loss: 2.366  loss_sem_seg: 1.23  loss_center: 0.5444  loss_offset: 0.5742  time: 0.3245  data_time: 0.0299  lr: 0.0012577  max_mem: 7344M
[12/11 00:02:13 d2.utils.events]:  eta: 0:24:59  iter: 5359  total_loss: 2.555  loss_sem_seg: 1.272  loss_center: 0.5547  loss_offset: 0.6769  time: 0.3245  data_time: 0.0292  lr: 0.0012528  max_mem: 7344M
[12/11 00:02:19 d2.utils.events]:  eta: 0:24:52  iter: 5379  total_loss: 2.222  loss_sem_seg: 1.076  loss_center: 0.5369  loss_offset: 0.6022  time: 0.3245  data_time: 0.0269  lr: 0.001248  max_mem: 7344M
[12/11 00:02:26 d2.utils.events]:  eta: 0:24:46  iter: 5399  total_loss: 2.187  loss_sem_seg: 1.121  loss_center: 0.443  loss_offset: 0.4639  time: 0.3245  data_time: 0.0283  lr: 0.0012431  max_mem: 7344M
[12/11 00:02:32 d2.utils.events]:  eta: 0:24:39  iter: 5419  total_loss: 2.373  loss_sem_seg: 1.173  loss_center: 0.5907  loss_offset: 0.6145  time: 0.3245  data_time: 0.0277  lr: 0.0012382  max_mem: 7344M
[12/11 00:02:39 d2.utils.events]:  eta: 0:24:33  iter: 5439  total_loss: 2.379  loss_sem_seg: 1.162  loss_center: 0.5242  loss_offset: 0.5892  time: 0.3245  data_time: 0.0267  lr: 0.0012334  max_mem: 7344M
[12/11 00:02:45 d2.utils.events]:  eta: 0:24:26  iter: 5459  total_loss: 2.312  loss_sem_seg: 1.096  loss_center: 0.5809  loss_offset: 0.5759  time: 0.3245  data_time: 0.0274  lr: 0.0012285  max_mem: 7344M
[12/11 00:02:52 d2.utils.events]:  eta: 0:24:21  iter: 5479  total_loss: 2.372  loss_sem_seg: 1.25  loss_center: 0.4914  loss_offset: 0.6713  time: 0.3245  data_time: 0.0266  lr: 0.0012236  max_mem: 7344M
[12/11 00:02:58 d2.utils.events]:  eta: 0:24:13  iter: 5499  total_loss: 2.258  loss_sem_seg: 1.129  loss_center: 0.553  loss_offset: 0.5063  time: 0.3244  data_time: 0.0278  lr: 0.0012188  max_mem: 7344M
[12/11 00:03:05 d2.utils.events]:  eta: 0:24:07  iter: 5519  total_loss: 2.509  loss_sem_seg: 1.242  loss_center: 0.5115  loss_offset: 0.6799  time: 0.3244  data_time: 0.0274  lr: 0.0012139  max_mem: 7344M
[12/11 00:03:11 d2.utils.events]:  eta: 0:24:00  iter: 5539  total_loss: 2.306  loss_sem_seg: 1.232  loss_center: 0.5459  loss_offset: 0.6222  time: 0.3244  data_time: 0.0289  lr: 0.001209  max_mem: 7344M
[12/11 00:03:17 d2.utils.events]:  eta: 0:23:53  iter: 5559  total_loss: 2.397  loss_sem_seg: 1.285  loss_center: 0.5743  loss_offset: 0.6728  time: 0.3244  data_time: 0.0263  lr: 0.0012041  max_mem: 7344M
[12/11 00:03:24 d2.utils.events]:  eta: 0:23:47  iter: 5579  total_loss: 2.558  loss_sem_seg: 1.318  loss_center: 0.5954  loss_offset: 0.6454  time: 0.3244  data_time: 0.0282  lr: 0.0011992  max_mem: 7344M
[12/11 00:03:30 d2.utils.events]:  eta: 0:23:40  iter: 5599  total_loss: 2.307  loss_sem_seg: 1.096  loss_center: 0.5201  loss_offset: 0.5863  time: 0.3244  data_time: 0.0261  lr: 0.0011944  max_mem: 7344M
[12/11 00:03:37 d2.utils.events]:  eta: 0:23:33  iter: 5619  total_loss: 2.242  loss_sem_seg: 0.9714  loss_center: 0.6443  loss_offset: 0.5713  time: 0.3244  data_time: 0.0260  lr: 0.0011895  max_mem: 7344M
[12/11 00:03:43 d2.utils.events]:  eta: 0:23:27  iter: 5639  total_loss: 2.459  loss_sem_seg: 1.214  loss_center: 0.5678  loss_offset: 0.6518  time: 0.3244  data_time: 0.0272  lr: 0.0011846  max_mem: 7344M
[12/11 00:03:50 d2.utils.events]:  eta: 0:23:20  iter: 5659  total_loss: 2.648  loss_sem_seg: 1.278  loss_center: 0.4865  loss_offset: 0.6934  time: 0.3244  data_time: 0.0271  lr: 0.0011797  max_mem: 7344M
[12/11 00:03:56 d2.utils.events]:  eta: 0:23:13  iter: 5679  total_loss: 2.504  loss_sem_seg: 1.203  loss_center: 0.6579  loss_offset: 0.5454  time: 0.3244  data_time: 0.0263  lr: 0.0011748  max_mem: 7344M
[12/11 00:04:03 d2.utils.events]:  eta: 0:23:07  iter: 5699  total_loss: 2.253  loss_sem_seg: 1.104  loss_center: 0.5611  loss_offset: 0.5942  time: 0.3244  data_time: 0.0285  lr: 0.0011699  max_mem: 7344M
[12/11 00:04:09 d2.utils.events]:  eta: 0:23:00  iter: 5719  total_loss: 2.437  loss_sem_seg: 1.258  loss_center: 0.5327  loss_offset: 0.5556  time: 0.3244  data_time: 0.0290  lr: 0.001165  max_mem: 7344M
[12/11 00:04:16 d2.utils.events]:  eta: 0:22:54  iter: 5739  total_loss: 2.519  loss_sem_seg: 1.286  loss_center: 0.4912  loss_offset: 0.6273  time: 0.3244  data_time: 0.0286  lr: 0.0011601  max_mem: 7344M
[12/11 00:04:22 d2.utils.events]:  eta: 0:22:47  iter: 5759  total_loss: 2.303  loss_sem_seg: 1.182  loss_center: 0.4509  loss_offset: 0.524  time: 0.3244  data_time: 0.0273  lr: 0.0011552  max_mem: 7344M
[12/11 00:04:29 d2.utils.events]:  eta: 0:22:41  iter: 5779  total_loss: 2.341  loss_sem_seg: 1.182  loss_center: 0.5477  loss_offset: 0.561  time: 0.3244  data_time: 0.0277  lr: 0.0011503  max_mem: 7344M
[12/11 00:04:35 d2.utils.events]:  eta: 0:22:35  iter: 5799  total_loss: 2.449  loss_sem_seg: 1.201  loss_center: 0.5381  loss_offset: 0.7084  time: 0.3244  data_time: 0.0273  lr: 0.0011454  max_mem: 7344M
[12/11 00:04:42 d2.utils.events]:  eta: 0:22:28  iter: 5819  total_loss: 2.467  loss_sem_seg: 1.076  loss_center: 0.5176  loss_offset: 0.6662  time: 0.3244  data_time: 0.0278  lr: 0.0011405  max_mem: 7344M
[12/11 00:04:48 d2.utils.events]:  eta: 0:22:22  iter: 5839  total_loss: 2.173  loss_sem_seg: 1.189  loss_center: 0.4835  loss_offset: 0.6909  time: 0.3244  data_time: 0.0292  lr: 0.0011356  max_mem: 7344M
[12/11 00:04:55 d2.utils.events]:  eta: 0:22:15  iter: 5859  total_loss: 2.292  loss_sem_seg: 1.146  loss_center: 0.535  loss_offset: 0.5551  time: 0.3244  data_time: 0.0268  lr: 0.0011307  max_mem: 7344M
[12/11 00:05:01 d2.utils.events]:  eta: 0:22:09  iter: 5879  total_loss: 2.62  loss_sem_seg: 1.349  loss_center: 0.387  loss_offset: 0.7037  time: 0.3244  data_time: 0.0263  lr: 0.0011258  max_mem: 7344M
[12/11 00:05:08 d2.utils.events]:  eta: 0:22:03  iter: 5899  total_loss: 2.561  loss_sem_seg: 1.328  loss_center: 0.6235  loss_offset: 0.6176  time: 0.3244  data_time: 0.0277  lr: 0.0011208  max_mem: 7344M
[12/11 00:05:14 d2.utils.events]:  eta: 0:21:56  iter: 5919  total_loss: 2.293  loss_sem_seg: 1.144  loss_center: 0.5564  loss_offset: 0.5663  time: 0.3244  data_time: 0.0274  lr: 0.0011159  max_mem: 7344M
[12/11 00:05:21 d2.utils.events]:  eta: 0:21:50  iter: 5939  total_loss: 2.587  loss_sem_seg: 1.19  loss_center: 0.5713  loss_offset: 0.6701  time: 0.3244  data_time: 0.0281  lr: 0.001111  max_mem: 7344M
[12/11 00:05:27 d2.utils.events]:  eta: 0:21:44  iter: 5959  total_loss: 2.21  loss_sem_seg: 1.188  loss_center: 0.4544  loss_offset: 0.5611  time: 0.3244  data_time: 0.0272  lr: 0.0011061  max_mem: 7344M
[12/11 00:05:34 d2.utils.events]:  eta: 0:21:37  iter: 5979  total_loss: 2.564  loss_sem_seg: 1.219  loss_center: 0.5721  loss_offset: 0.5678  time: 0.3244  data_time: 0.0268  lr: 0.0011011  max_mem: 7344M
[12/11 00:05:40 d2.utils.events]:  eta: 0:21:31  iter: 5999  total_loss: 2.105  loss_sem_seg: 1.002  loss_center: 0.4831  loss_offset: 0.472  time: 0.3244  data_time: 0.0276  lr: 0.0010962  max_mem: 7344M
[12/11 00:05:47 d2.utils.events]:  eta: 0:21:24  iter: 6019  total_loss: 2.265  loss_sem_seg: 1.09  loss_center: 0.5296  loss_offset: 0.5107  time: 0.3244  data_time: 0.0255  lr: 0.0010913  max_mem: 7344M
[12/11 00:05:53 d2.utils.events]:  eta: 0:21:17  iter: 6039  total_loss: 2.625  loss_sem_seg: 1.284  loss_center: 0.5564  loss_offset: 0.6593  time: 0.3244  data_time: 0.0284  lr: 0.0010863  max_mem: 7344M
[12/11 00:06:00 d2.utils.events]:  eta: 0:21:11  iter: 6059  total_loss: 2.327  loss_sem_seg: 1.147  loss_center: 0.4844  loss_offset: 0.5304  time: 0.3244  data_time: 0.0297  lr: 0.0010814  max_mem: 7344M
[12/11 00:06:06 d2.utils.events]:  eta: 0:21:04  iter: 6079  total_loss: 2.269  loss_sem_seg: 1.135  loss_center: 0.4999  loss_offset: 0.524  time: 0.3244  data_time: 0.0258  lr: 0.0010765  max_mem: 7344M
[12/11 00:06:12 d2.utils.events]:  eta: 0:20:57  iter: 6099  total_loss: 2.21  loss_sem_seg: 1.038  loss_center: 0.5214  loss_offset: 0.4497  time: 0.3244  data_time: 0.0267  lr: 0.0010715  max_mem: 7344M
[12/11 00:06:19 d2.utils.events]:  eta: 0:20:51  iter: 6119  total_loss: 2.462  loss_sem_seg: 1.214  loss_center: 0.4467  loss_offset: 0.6497  time: 0.3244  data_time: 0.0271  lr: 0.0010666  max_mem: 7344M
[12/11 00:06:25 d2.utils.events]:  eta: 0:20:44  iter: 6139  total_loss: 2.331  loss_sem_seg: 1.263  loss_center: 0.6548  loss_offset: 0.5634  time: 0.3244  data_time: 0.0276  lr: 0.0010616  max_mem: 7344M
[12/11 00:06:32 d2.utils.events]:  eta: 0:20:38  iter: 6159  total_loss: 2.413  loss_sem_seg: 1.264  loss_center: 0.6055  loss_offset: 0.5365  time: 0.3243  data_time: 0.0264  lr: 0.0010567  max_mem: 7344M
[12/11 00:06:38 d2.utils.events]:  eta: 0:20:31  iter: 6179  total_loss: 2.636  loss_sem_seg: 1.303  loss_center: 0.63  loss_offset: 0.715  time: 0.3243  data_time: 0.0274  lr: 0.0010517  max_mem: 7344M
[12/11 00:06:45 d2.utils.events]:  eta: 0:20:26  iter: 6199  total_loss: 2.28  loss_sem_seg: 1.194  loss_center: 0.4763  loss_offset: 0.6521  time: 0.3243  data_time: 0.0273  lr: 0.0010468  max_mem: 7344M
[12/11 00:06:51 d2.utils.events]:  eta: 0:20:19  iter: 6219  total_loss: 2.23  loss_sem_seg: 1.217  loss_center: 0.4888  loss_offset: 0.5154  time: 0.3243  data_time: 0.0281  lr: 0.0010418  max_mem: 7344M
[12/11 00:06:58 d2.utils.events]:  eta: 0:20:12  iter: 6239  total_loss: 2.404  loss_sem_seg: 1.156  loss_center: 0.5592  loss_offset: 0.6251  time: 0.3243  data_time: 0.0281  lr: 0.0010368  max_mem: 7344M
[12/11 00:07:04 d2.utils.events]:  eta: 0:20:06  iter: 6259  total_loss: 2.342  loss_sem_seg: 1.177  loss_center: 0.4873  loss_offset: 0.6038  time: 0.3243  data_time: 0.0275  lr: 0.0010319  max_mem: 7344M
[12/11 00:07:11 d2.utils.events]:  eta: 0:20:00  iter: 6279  total_loss: 2.552  loss_sem_seg: 1.241  loss_center: 0.5242  loss_offset: 0.634  time: 0.3243  data_time: 0.0294  lr: 0.0010269  max_mem: 7344M
[12/11 00:07:17 d2.utils.events]:  eta: 0:19:53  iter: 6299  total_loss: 2.378  loss_sem_seg: 1.249  loss_center: 0.4546  loss_offset: 0.6679  time: 0.3243  data_time: 0.0263  lr: 0.0010219  max_mem: 7344M
[12/11 00:07:24 d2.utils.events]:  eta: 0:19:47  iter: 6319  total_loss: 2.311  loss_sem_seg: 1.14  loss_center: 0.534  loss_offset: 0.5538  time: 0.3244  data_time: 0.0287  lr: 0.001017  max_mem: 7344M
[12/11 00:07:30 d2.utils.events]:  eta: 0:19:40  iter: 6339  total_loss: 2.403  loss_sem_seg: 1.205  loss_center: 0.5971  loss_offset: 0.5654  time: 0.3244  data_time: 0.0279  lr: 0.001012  max_mem: 7344M
[12/11 00:07:37 d2.utils.events]:  eta: 0:19:33  iter: 6359  total_loss: 2.08  loss_sem_seg: 1.081  loss_center: 0.4908  loss_offset: 0.5318  time: 0.3244  data_time: 0.0283  lr: 0.001007  max_mem: 7344M
[12/11 00:07:43 d2.utils.events]:  eta: 0:19:27  iter: 6379  total_loss: 2.487  loss_sem_seg: 1.177  loss_center: 0.518  loss_offset: 0.6748  time: 0.3243  data_time: 0.0261  lr: 0.001002  max_mem: 7344M
[12/11 00:07:50 d2.utils.events]:  eta: 0:19:20  iter: 6399  total_loss: 2.57  loss_sem_seg: 1.218  loss_center: 0.708  loss_offset: 0.5916  time: 0.3243  data_time: 0.0272  lr: 0.00099706  max_mem: 7344M
[12/11 00:07:56 d2.utils.events]:  eta: 0:19:13  iter: 6419  total_loss: 2.218  loss_sem_seg: 1.113  loss_center: 0.5155  loss_offset: 0.5799  time: 0.3243  data_time: 0.0275  lr: 0.00099207  max_mem: 7344M
[12/11 00:08:03 d2.utils.events]:  eta: 0:19:07  iter: 6439  total_loss: 2.192  loss_sem_seg: 1.046  loss_center: 0.5576  loss_offset: 0.556  time: 0.3243  data_time: 0.0279  lr: 0.00098709  max_mem: 7344M
[12/11 00:08:09 d2.utils.events]:  eta: 0:19:01  iter: 6459  total_loss: 2.33  loss_sem_seg: 1.184  loss_center: 0.5731  loss_offset: 0.5335  time: 0.3243  data_time: 0.0264  lr: 0.00098209  max_mem: 7344M
[12/11 00:08:16 d2.utils.events]:  eta: 0:18:54  iter: 6479  total_loss: 2.41  loss_sem_seg: 1.091  loss_center: 0.5538  loss_offset: 0.5786  time: 0.3243  data_time: 0.0262  lr: 0.0009771  max_mem: 7344M
[12/11 00:08:22 d2.utils.events]:  eta: 0:18:47  iter: 6499  total_loss: 2.332  loss_sem_seg: 1.159  loss_center: 0.4965  loss_offset: 0.5847  time: 0.3243  data_time: 0.0270  lr: 0.0009721  max_mem: 7344M
[12/11 00:08:29 d2.utils.events]:  eta: 0:18:41  iter: 6519  total_loss: 2.303  loss_sem_seg: 1.039  loss_center: 0.5356  loss_offset: 0.5652  time: 0.3243  data_time: 0.0282  lr: 0.00096711  max_mem: 7344M
[12/11 00:08:35 d2.utils.events]:  eta: 0:18:34  iter: 6539  total_loss: 2.286  loss_sem_seg: 1.075  loss_center: 0.5641  loss_offset: 0.6386  time: 0.3243  data_time: 0.0270  lr: 0.0009621  max_mem: 7344M
[12/11 00:08:42 d2.utils.events]:  eta: 0:18:28  iter: 6559  total_loss: 2.431  loss_sem_seg: 1.258  loss_center: 0.5535  loss_offset: 0.59  time: 0.3243  data_time: 0.0291  lr: 0.0009571  max_mem: 7344M
[12/11 00:08:48 d2.utils.events]:  eta: 0:18:21  iter: 6579  total_loss: 2.312  loss_sem_seg: 1.11  loss_center: 0.4416  loss_offset: 0.5565  time: 0.3243  data_time: 0.0269  lr: 0.00095209  max_mem: 7344M
[12/11 00:08:54 d2.utils.events]:  eta: 0:18:15  iter: 6599  total_loss: 2.277  loss_sem_seg: 1.075  loss_center: 0.5705  loss_offset: 0.611  time: 0.3243  data_time: 0.0282  lr: 0.00094708  max_mem: 7344M
[12/11 00:09:01 d2.utils.events]:  eta: 0:18:09  iter: 6619  total_loss: 2.208  loss_sem_seg: 1.053  loss_center: 0.5127  loss_offset: 0.5887  time: 0.3243  data_time: 0.0264  lr: 0.00094206  max_mem: 7344M
[12/11 00:09:07 d2.utils.events]:  eta: 0:18:02  iter: 6639  total_loss: 2.33  loss_sem_seg: 1.157  loss_center: 0.5543  loss_offset: 0.5552  time: 0.3243  data_time: 0.0272  lr: 0.00093705  max_mem: 7344M
[12/11 00:09:14 d2.utils.events]:  eta: 0:17:56  iter: 6659  total_loss: 2.221  loss_sem_seg: 0.9666  loss_center: 0.6492  loss_offset: 0.4696  time: 0.3243  data_time: 0.0257  lr: 0.00093203  max_mem: 7344M
[12/11 00:09:20 d2.utils.events]:  eta: 0:17:49  iter: 6679  total_loss: 2.613  loss_sem_seg: 1.269  loss_center: 0.6537  loss_offset: 0.6954  time: 0.3243  data_time: 0.0266  lr: 0.000927  max_mem: 7344M
[12/11 00:09:27 d2.utils.events]:  eta: 0:17:43  iter: 6699  total_loss: 2.325  loss_sem_seg: 1.221  loss_center: 0.467  loss_offset: 0.5734  time: 0.3243  data_time: 0.0283  lr: 0.00092198  max_mem: 7344M
[12/11 00:09:33 d2.utils.events]:  eta: 0:17:37  iter: 6719  total_loss: 2.436  loss_sem_seg: 1.187  loss_center: 0.5787  loss_offset: 0.5586  time: 0.3243  data_time: 0.0267  lr: 0.00091695  max_mem: 7344M
[12/11 00:09:40 d2.utils.events]:  eta: 0:17:30  iter: 6739  total_loss: 2.567  loss_sem_seg: 1.475  loss_center: 0.4228  loss_offset: 0.6916  time: 0.3243  data_time: 0.0275  lr: 0.00091192  max_mem: 7344M
[12/11 00:09:46 d2.utils.events]:  eta: 0:17:24  iter: 6759  total_loss: 2.564  loss_sem_seg: 1.182  loss_center: 0.6156  loss_offset: 0.5829  time: 0.3243  data_time: 0.0300  lr: 0.00090688  max_mem: 7344M
[12/11 00:09:53 d2.utils.events]:  eta: 0:17:17  iter: 6779  total_loss: 2.41  loss_sem_seg: 1.113  loss_center: 0.5327  loss_offset: 0.5928  time: 0.3243  data_time: 0.0276  lr: 0.00090184  max_mem: 7344M
[12/11 00:09:59 d2.utils.events]:  eta: 0:17:11  iter: 6799  total_loss: 2.433  loss_sem_seg: 1.309  loss_center: 0.5251  loss_offset: 0.6177  time: 0.3243  data_time: 0.0256  lr: 0.0008968  max_mem: 7344M
[12/11 00:10:06 d2.utils.events]:  eta: 0:17:05  iter: 6819  total_loss: 2.624  loss_sem_seg: 1.27  loss_center: 0.6236  loss_offset: 0.6428  time: 0.3243  data_time: 0.0306  lr: 0.00089176  max_mem: 7344M
[12/11 00:10:12 d2.utils.events]:  eta: 0:16:58  iter: 6839  total_loss: 2.041  loss_sem_seg: 1.13  loss_center: 0.5064  loss_offset: 0.4579  time: 0.3243  data_time: 0.0273  lr: 0.00088671  max_mem: 7344M
[12/11 00:10:19 d2.utils.events]:  eta: 0:16:52  iter: 6859  total_loss: 2.399  loss_sem_seg: 1.143  loss_center: 0.4704  loss_offset: 0.6632  time: 0.3243  data_time: 0.0283  lr: 0.00088166  max_mem: 7344M
[12/11 00:10:25 d2.utils.events]:  eta: 0:16:45  iter: 6879  total_loss: 2.605  loss_sem_seg: 1.279  loss_center: 0.6206  loss_offset: 0.6382  time: 0.3243  data_time: 0.0277  lr: 0.00087661  max_mem: 7344M
[12/11 00:10:32 d2.utils.events]:  eta: 0:16:39  iter: 6899  total_loss: 2.453  loss_sem_seg: 1.026  loss_center: 0.4998  loss_offset: 0.6423  time: 0.3243  data_time: 0.0274  lr: 0.00087155  max_mem: 7344M
[12/11 00:10:38 d2.utils.events]:  eta: 0:16:33  iter: 6919  total_loss: 2.127  loss_sem_seg: 1.038  loss_center: 0.4615  loss_offset: 0.6136  time: 0.3243  data_time: 0.0279  lr: 0.00086649  max_mem: 7344M
[12/11 00:10:45 d2.utils.events]:  eta: 0:16:26  iter: 6939  total_loss: 2.095  loss_sem_seg: 0.9135  loss_center: 0.471  loss_offset: 0.5687  time: 0.3243  data_time: 0.0281  lr: 0.00086142  max_mem: 7344M
[12/11 00:10:51 d2.utils.events]:  eta: 0:16:20  iter: 6959  total_loss: 2.421  loss_sem_seg: 0.9996  loss_center: 0.6213  loss_offset: 0.6434  time: 0.3243  data_time: 0.0269  lr: 0.00085636  max_mem: 7344M
[12/11 00:10:58 d2.utils.events]:  eta: 0:16:13  iter: 6979  total_loss: 2.417  loss_sem_seg: 1.173  loss_center: 0.5513  loss_offset: 0.571  time: 0.3243  data_time: 0.0285  lr: 0.00085129  max_mem: 7344M
[12/11 00:11:04 d2.utils.events]:  eta: 0:16:07  iter: 6999  total_loss: 2.442  loss_sem_seg: 1.193  loss_center: 0.637  loss_offset: 0.574  time: 0.3243  data_time: 0.0279  lr: 0.00084621  max_mem: 7344M
[12/11 00:11:11 d2.utils.events]:  eta: 0:16:01  iter: 7019  total_loss: 2.396  loss_sem_seg: 1.23  loss_center: 0.5603  loss_offset: 0.55  time: 0.3243  data_time: 0.0267  lr: 0.00084114  max_mem: 7344M
[12/11 00:11:17 d2.utils.events]:  eta: 0:15:54  iter: 7039  total_loss: 2.278  loss_sem_seg: 1.054  loss_center: 0.4984  loss_offset: 0.5499  time: 0.3243  data_time: 0.0288  lr: 0.00083605  max_mem: 7344M
[12/11 00:11:24 d2.utils.events]:  eta: 0:15:48  iter: 7059  total_loss: 2.518  loss_sem_seg: 1.107  loss_center: 0.6273  loss_offset: 0.5742  time: 0.3243  data_time: 0.0290  lr: 0.00083097  max_mem: 7344M
[12/11 00:11:30 d2.utils.events]:  eta: 0:15:42  iter: 7079  total_loss: 2.168  loss_sem_seg: 0.9774  loss_center: 0.4308  loss_offset: 0.6018  time: 0.3243  data_time: 0.0288  lr: 0.00082588  max_mem: 7344M
[12/11 00:11:37 d2.utils.events]:  eta: 0:15:36  iter: 7099  total_loss: 2.007  loss_sem_seg: 1.039  loss_center: 0.4527  loss_offset: 0.552  time: 0.3243  data_time: 0.0274  lr: 0.00082079  max_mem: 7344M
[12/11 00:11:43 d2.utils.events]:  eta: 0:15:30  iter: 7119  total_loss: 2.238  loss_sem_seg: 0.9571  loss_center: 0.6122  loss_offset: 0.5567  time: 0.3243  data_time: 0.0291  lr: 0.0008157  max_mem: 7344M
[12/11 00:11:50 d2.utils.events]:  eta: 0:15:23  iter: 7139  total_loss: 2.41  loss_sem_seg: 1.042  loss_center: 0.5718  loss_offset: 0.7249  time: 0.3243  data_time: 0.0284  lr: 0.0008106  max_mem: 7344M
[12/11 00:11:56 d2.utils.events]:  eta: 0:15:17  iter: 7159  total_loss: 2.155  loss_sem_seg: 0.9567  loss_center: 0.4533  loss_offset: 0.5692  time: 0.3243  data_time: 0.0275  lr: 0.0008055  max_mem: 7344M
[12/11 00:12:03 d2.utils.events]:  eta: 0:15:10  iter: 7179  total_loss: 2.233  loss_sem_seg: 1.07  loss_center: 0.4809  loss_offset: 0.5453  time: 0.3243  data_time: 0.0274  lr: 0.00080039  max_mem: 7344M
[12/11 00:12:09 d2.utils.events]:  eta: 0:15:04  iter: 7199  total_loss: 2.052  loss_sem_seg: 0.9283  loss_center: 0.4739  loss_offset: 0.6501  time: 0.3243  data_time: 0.0295  lr: 0.00079528  max_mem: 7344M
[12/11 00:12:16 d2.utils.events]:  eta: 0:14:57  iter: 7219  total_loss: 2.238  loss_sem_seg: 1.096  loss_center: 0.5498  loss_offset: 0.4907  time: 0.3243  data_time: 0.0262  lr: 0.00079017  max_mem: 7344M
[12/11 00:12:22 d2.utils.events]:  eta: 0:14:51  iter: 7239  total_loss: 1.961  loss_sem_seg: 0.9342  loss_center: 0.4904  loss_offset: 0.671  time: 0.3243  data_time: 0.0267  lr: 0.00078505  max_mem: 7344M
[12/11 00:12:29 d2.utils.events]:  eta: 0:14:44  iter: 7259  total_loss: 2.091  loss_sem_seg: 0.9855  loss_center: 0.591  loss_offset: 0.6275  time: 0.3243  data_time: 0.0274  lr: 0.00077993  max_mem: 7344M
[12/11 00:12:35 d2.utils.events]:  eta: 0:14:38  iter: 7279  total_loss: 2.428  loss_sem_seg: 1.147  loss_center: 0.5649  loss_offset: 0.5723  time: 0.3243  data_time: 0.0293  lr: 0.00077481  max_mem: 7344M
[12/11 00:12:42 d2.utils.events]:  eta: 0:14:31  iter: 7299  total_loss: 2.538  loss_sem_seg: 1.169  loss_center: 0.5761  loss_offset: 0.5665  time: 0.3243  data_time: 0.0282  lr: 0.00076968  max_mem: 7344M
[12/11 00:12:48 d2.utils.events]:  eta: 0:14:24  iter: 7319  total_loss: 2.322  loss_sem_seg: 1.077  loss_center: 0.7463  loss_offset: 0.5035  time: 0.3243  data_time: 0.0265  lr: 0.00076455  max_mem: 7344M
[12/11 00:12:55 d2.utils.events]:  eta: 0:14:18  iter: 7339  total_loss: 2.151  loss_sem_seg: 0.9694  loss_center: 0.5675  loss_offset: 0.5192  time: 0.3243  data_time: 0.0269  lr: 0.00075942  max_mem: 7344M
[12/11 00:13:01 d2.utils.events]:  eta: 0:14:12  iter: 7359  total_loss: 2.325  loss_sem_seg: 1.036  loss_center: 0.6243  loss_offset: 0.6179  time: 0.3243  data_time: 0.0275  lr: 0.00075428  max_mem: 7344M
[12/11 00:13:08 d2.utils.events]:  eta: 0:14:06  iter: 7379  total_loss: 2.292  loss_sem_seg: 1.094  loss_center: 0.4604  loss_offset: 0.6171  time: 0.3243  data_time: 0.0269  lr: 0.00074914  max_mem: 7344M
[12/11 00:13:14 d2.utils.events]:  eta: 0:14:00  iter: 7399  total_loss: 2.374  loss_sem_seg: 1.078  loss_center: 0.5527  loss_offset: 0.5206  time: 0.3243  data_time: 0.0276  lr: 0.00074399  max_mem: 7344M
[12/11 00:13:21 d2.utils.events]:  eta: 0:13:53  iter: 7419  total_loss: 2.01  loss_sem_seg: 0.9894  loss_center: 0.4958  loss_offset: 0.5663  time: 0.3243  data_time: 0.0282  lr: 0.00073884  max_mem: 7344M
[12/11 00:13:27 d2.utils.events]:  eta: 0:13:46  iter: 7439  total_loss: 2.238  loss_sem_seg: 0.9696  loss_center: 0.5014  loss_offset: 0.4795  time: 0.3243  data_time: 0.0253  lr: 0.00073368  max_mem: 7344M
[12/11 00:13:34 d2.utils.events]:  eta: 0:13:40  iter: 7459  total_loss: 2.264  loss_sem_seg: 1.03  loss_center: 0.6412  loss_offset: 0.6331  time: 0.3243  data_time: 0.0272  lr: 0.00072852  max_mem: 7344M
[12/11 00:13:40 d2.utils.events]:  eta: 0:13:34  iter: 7479  total_loss: 2.238  loss_sem_seg: 1.096  loss_center: 0.6704  loss_offset: 0.5591  time: 0.3243  data_time: 0.0269  lr: 0.00072336  max_mem: 7344M
[12/11 00:13:47 d2.utils.events]:  eta: 0:13:27  iter: 7499  total_loss: 2.405  loss_sem_seg: 1.108  loss_center: 0.5185  loss_offset: 0.5645  time: 0.3243  data_time: 0.0282  lr: 0.00071819  max_mem: 7344M
[12/11 00:13:53 d2.utils.events]:  eta: 0:13:21  iter: 7519  total_loss: 2.528  loss_sem_seg: 1.183  loss_center: 0.6763  loss_offset: 0.6283  time: 0.3243  data_time: 0.0278  lr: 0.00071302  max_mem: 7344M
[12/11 00:14:00 d2.utils.events]:  eta: 0:13:15  iter: 7539  total_loss: 2.144  loss_sem_seg: 0.9396  loss_center: 0.5199  loss_offset: 0.5014  time: 0.3243  data_time: 0.0277  lr: 0.00070785  max_mem: 7344M
[12/11 00:14:06 d2.utils.events]:  eta: 0:13:08  iter: 7559  total_loss: 2.235  loss_sem_seg: 1.137  loss_center: 0.5208  loss_offset: 0.4929  time: 0.3243  data_time: 0.0282  lr: 0.00070267  max_mem: 7344M
[12/11 00:14:13 d2.utils.events]:  eta: 0:13:02  iter: 7579  total_loss: 2.124  loss_sem_seg: 1.046  loss_center: 0.5458  loss_offset: 0.4685  time: 0.3243  data_time: 0.0281  lr: 0.00069749  max_mem: 7344M
[12/11 00:14:19 d2.utils.events]:  eta: 0:12:56  iter: 7599  total_loss: 2.251  loss_sem_seg: 1.132  loss_center: 0.4337  loss_offset: 0.522  time: 0.3243  data_time: 0.0286  lr: 0.0006923  max_mem: 7344M
[12/11 00:14:26 d2.utils.events]:  eta: 0:12:49  iter: 7619  total_loss: 2.485  loss_sem_seg: 1.251  loss_center: 0.5297  loss_offset: 0.6153  time: 0.3243  data_time: 0.0278  lr: 0.00068711  max_mem: 7344M
[12/11 00:14:32 d2.utils.events]:  eta: 0:12:43  iter: 7639  total_loss: 2.368  loss_sem_seg: 1.194  loss_center: 0.6821  loss_offset: 0.5243  time: 0.3243  data_time: 0.0286  lr: 0.00068191  max_mem: 7344M
[12/11 00:14:39 d2.utils.events]:  eta: 0:12:36  iter: 7659  total_loss: 2.538  loss_sem_seg: 1.131  loss_center: 0.5455  loss_offset: 0.5965  time: 0.3243  data_time: 0.0254  lr: 0.00067671  max_mem: 7344M
[12/11 00:14:45 d2.utils.events]:  eta: 0:12:30  iter: 7679  total_loss: 2.188  loss_sem_seg: 1.039  loss_center: 0.5995  loss_offset: 0.4872  time: 0.3243  data_time: 0.0272  lr: 0.0006715  max_mem: 7344M
[12/11 00:14:52 d2.utils.events]:  eta: 0:12:23  iter: 7699  total_loss: 2.034  loss_sem_seg: 1.048  loss_center: 0.5373  loss_offset: 0.6294  time: 0.3243  data_time: 0.0281  lr: 0.00066629  max_mem: 7344M
[12/11 00:14:58 d2.utils.events]:  eta: 0:12:17  iter: 7719  total_loss: 2.274  loss_sem_seg: 1.04  loss_center: 0.5873  loss_offset: 0.5277  time: 0.3243  data_time: 0.0267  lr: 0.00066108  max_mem: 7344M
[12/11 00:15:05 d2.utils.events]:  eta: 0:12:10  iter: 7739  total_loss: 2.312  loss_sem_seg: 1.14  loss_center: 0.4501  loss_offset: 0.5469  time: 0.3243  data_time: 0.0281  lr: 0.00065586  max_mem: 7344M
[12/11 00:15:11 d2.utils.events]:  eta: 0:12:04  iter: 7759  total_loss: 2.221  loss_sem_seg: 1.113  loss_center: 0.6041  loss_offset: 0.5737  time: 0.3243  data_time: 0.0279  lr: 0.00065064  max_mem: 7344M
[12/11 00:15:18 d2.utils.events]:  eta: 0:11:57  iter: 7779  total_loss: 2.261  loss_sem_seg: 1.071  loss_center: 0.5212  loss_offset: 0.5958  time: 0.3243  data_time: 0.0301  lr: 0.00064541  max_mem: 7344M
[12/11 00:15:24 d2.utils.events]:  eta: 0:11:51  iter: 7799  total_loss: 2.035  loss_sem_seg: 0.9899  loss_center: 0.59  loss_offset: 0.4656  time: 0.3243  data_time: 0.0295  lr: 0.00064017  max_mem: 7344M
[12/11 00:15:31 d2.utils.events]:  eta: 0:11:44  iter: 7819  total_loss: 2.15  loss_sem_seg: 0.9579  loss_center: 0.5378  loss_offset: 0.5642  time: 0.3243  data_time: 0.0270  lr: 0.00063494  max_mem: 7344M
[12/11 00:15:37 d2.utils.events]:  eta: 0:11:38  iter: 7839  total_loss: 2.264  loss_sem_seg: 1.153  loss_center: 0.5683  loss_offset: 0.635  time: 0.3243  data_time: 0.0261  lr: 0.00062969  max_mem: 7344M
[12/11 00:15:44 d2.utils.events]:  eta: 0:11:31  iter: 7859  total_loss: 2.21  loss_sem_seg: 1.096  loss_center: 0.4775  loss_offset: 0.5933  time: 0.3243  data_time: 0.0275  lr: 0.00062445  max_mem: 7344M
[12/11 00:15:50 d2.utils.events]:  eta: 0:11:25  iter: 7879  total_loss: 2.511  loss_sem_seg: 1.136  loss_center: 0.3752  loss_offset: 0.5793  time: 0.3243  data_time: 0.0265  lr: 0.00061919  max_mem: 7344M
[12/11 00:15:57 d2.utils.events]:  eta: 0:11:18  iter: 7899  total_loss: 2.079  loss_sem_seg: 1.107  loss_center: 0.5634  loss_offset: 0.4864  time: 0.3243  data_time: 0.0284  lr: 0.00061394  max_mem: 7344M
[12/11 00:16:03 d2.utils.events]:  eta: 0:11:12  iter: 7919  total_loss: 1.824  loss_sem_seg: 0.8473  loss_center: 0.3972  loss_offset: 0.482  time: 0.3243  data_time: 0.0284  lr: 0.00060867  max_mem: 7344M
[12/11 00:16:10 d2.utils.events]:  eta: 0:11:05  iter: 7939  total_loss: 2.238  loss_sem_seg: 1.076  loss_center: 0.6807  loss_offset: 0.5688  time: 0.3243  data_time: 0.0278  lr: 0.00060341  max_mem: 7344M
[12/11 00:16:16 d2.utils.events]:  eta: 0:10:59  iter: 7959  total_loss: 2.466  loss_sem_seg: 1.016  loss_center: 0.6395  loss_offset: 0.6654  time: 0.3243  data_time: 0.0270  lr: 0.00059813  max_mem: 7344M
[12/11 00:16:23 d2.utils.events]:  eta: 0:10:52  iter: 7979  total_loss: 2.139  loss_sem_seg: 0.8626  loss_center: 0.6761  loss_offset: 0.5483  time: 0.3243  data_time: 0.0267  lr: 0.00059286  max_mem: 7344M
[12/11 00:16:29 d2.utils.events]:  eta: 0:10:46  iter: 7999  total_loss: 2.414  loss_sem_seg: 1.122  loss_center: 0.5203  loss_offset: 0.5839  time: 0.3243  data_time: 0.0284  lr: 0.00058757  max_mem: 7344M
[12/11 00:16:36 d2.utils.events]:  eta: 0:10:39  iter: 8019  total_loss: 2.348  loss_sem_seg: 1.156  loss_center: 0.5886  loss_offset: 0.4892  time: 0.3243  data_time: 0.0260  lr: 0.00058229  max_mem: 7344M
[12/11 00:16:42 d2.utils.events]:  eta: 0:10:32  iter: 8039  total_loss: 2.484  loss_sem_seg: 1.026  loss_center: 0.5474  loss_offset: 0.5634  time: 0.3243  data_time: 0.0265  lr: 0.00057699  max_mem: 7344M
[12/11 00:16:49 d2.utils.events]:  eta: 0:10:26  iter: 8059  total_loss: 2.035  loss_sem_seg: 1.191  loss_center: 0.4077  loss_offset: 0.4813  time: 0.3243  data_time: 0.0280  lr: 0.00057169  max_mem: 7344M
[12/11 00:16:55 d2.utils.events]:  eta: 0:10:20  iter: 8079  total_loss: 2.302  loss_sem_seg: 1.044  loss_center: 0.3869  loss_offset: 0.6938  time: 0.3243  data_time: 0.0279  lr: 0.00056639  max_mem: 7344M
[12/11 00:17:02 d2.utils.events]:  eta: 0:10:13  iter: 8099  total_loss: 2.055  loss_sem_seg: 1.024  loss_center: 0.5212  loss_offset: 0.5773  time: 0.3243  data_time: 0.0267  lr: 0.00056108  max_mem: 7344M
[12/11 00:17:08 d2.utils.events]:  eta: 0:10:06  iter: 8119  total_loss: 2.332  loss_sem_seg: 1.11  loss_center: 0.5717  loss_offset: 0.6609  time: 0.3243  data_time: 0.0270  lr: 0.00055576  max_mem: 7344M
[12/11 00:17:15 d2.utils.events]:  eta: 0:10:00  iter: 8139  total_loss: 2.261  loss_sem_seg: 0.9662  loss_center: 0.4763  loss_offset: 0.6137  time: 0.3243  data_time: 0.0261  lr: 0.00055044  max_mem: 7344M
[12/11 00:17:21 d2.utils.events]:  eta: 0:09:53  iter: 8159  total_loss: 2.336  loss_sem_seg: 1.134  loss_center: 0.5655  loss_offset: 0.5701  time: 0.3243  data_time: 0.0261  lr: 0.00054512  max_mem: 7344M
[12/11 00:17:28 d2.utils.events]:  eta: 0:09:47  iter: 8179  total_loss: 2.057  loss_sem_seg: 1.044  loss_center: 0.5717  loss_offset: 0.5242  time: 0.3243  data_time: 0.0283  lr: 0.00053978  max_mem: 7344M
[12/11 00:17:34 d2.utils.events]:  eta: 0:09:40  iter: 8199  total_loss: 1.961  loss_sem_seg: 0.9224  loss_center: 0.4634  loss_offset: 0.5453  time: 0.3243  data_time: 0.0273  lr: 0.00053444  max_mem: 7344M
[12/11 00:17:41 d2.utils.events]:  eta: 0:09:34  iter: 8219  total_loss: 2.28  loss_sem_seg: 1.068  loss_center: 0.5066  loss_offset: 0.5156  time: 0.3243  data_time: 0.0278  lr: 0.0005291  max_mem: 7344M
[12/11 00:17:47 d2.utils.events]:  eta: 0:09:28  iter: 8239  total_loss: 2.249  loss_sem_seg: 1.041  loss_center: 0.6079  loss_offset: 0.5596  time: 0.3243  data_time: 0.0277  lr: 0.00052375  max_mem: 7344M
[12/11 00:17:53 d2.utils.events]:  eta: 0:09:21  iter: 8259  total_loss: 2.087  loss_sem_seg: 0.9522  loss_center: 0.6446  loss_offset: 0.4422  time: 0.3243  data_time: 0.0268  lr: 0.00051839  max_mem: 7344M
[12/11 00:18:00 d2.utils.events]:  eta: 0:09:15  iter: 8279  total_loss: 2.24  loss_sem_seg: 1.154  loss_center: 0.4812  loss_offset: 0.5238  time: 0.3243  data_time: 0.0273  lr: 0.00051303  max_mem: 7344M
[12/11 00:18:06 d2.utils.events]:  eta: 0:09:08  iter: 8299  total_loss: 1.775  loss_sem_seg: 0.8475  loss_center: 0.4776  loss_offset: 0.4537  time: 0.3243  data_time: 0.0278  lr: 0.00050766  max_mem: 7344M
[12/11 00:18:13 d2.utils.events]:  eta: 0:09:02  iter: 8319  total_loss: 1.934  loss_sem_seg: 0.9595  loss_center: 0.4199  loss_offset: 0.4989  time: 0.3243  data_time: 0.0264  lr: 0.00050229  max_mem: 7344M
[12/11 00:18:19 d2.utils.events]:  eta: 0:08:56  iter: 8339  total_loss: 2.366  loss_sem_seg: 1.194  loss_center: 0.4225  loss_offset: 0.6779  time: 0.3243  data_time: 0.0282  lr: 0.0004969  max_mem: 7344M
[12/11 00:18:26 d2.utils.events]:  eta: 0:08:49  iter: 8359  total_loss: 2.167  loss_sem_seg: 0.962  loss_center: 0.4899  loss_offset: 0.5777  time: 0.3243  data_time: 0.0278  lr: 0.00049152  max_mem: 7344M
[12/11 00:18:32 d2.utils.events]:  eta: 0:08:42  iter: 8379  total_loss: 2.094  loss_sem_seg: 0.9445  loss_center: 0.5416  loss_offset: 0.4632  time: 0.3243  data_time: 0.0264  lr: 0.00048612  max_mem: 7344M
[12/11 00:18:39 d2.utils.events]:  eta: 0:08:36  iter: 8399  total_loss: 2.324  loss_sem_seg: 0.992  loss_center: 0.5458  loss_offset: 0.634  time: 0.3243  data_time: 0.0271  lr: 0.00048072  max_mem: 7344M
[12/11 00:18:45 d2.utils.events]:  eta: 0:08:29  iter: 8419  total_loss: 2.252  loss_sem_seg: 1.19  loss_center: 0.4163  loss_offset: 0.6002  time: 0.3243  data_time: 0.0287  lr: 0.00047531  max_mem: 7344M
[12/11 00:18:52 d2.utils.events]:  eta: 0:08:23  iter: 8439  total_loss: 1.993  loss_sem_seg: 1.09  loss_center: 0.5877  loss_offset: 0.4726  time: 0.3243  data_time: 0.0253  lr: 0.0004699  max_mem: 7344M
[12/11 00:18:58 d2.utils.events]:  eta: 0:08:16  iter: 8459  total_loss: 2.123  loss_sem_seg: 0.8611  loss_center: 0.5832  loss_offset: 0.5403  time: 0.3243  data_time: 0.0264  lr: 0.00046448  max_mem: 7344M
[12/11 00:19:05 d2.utils.events]:  eta: 0:08:10  iter: 8479  total_loss: 2.361  loss_sem_seg: 1.062  loss_center: 0.5645  loss_offset: 0.7165  time: 0.3243  data_time: 0.0277  lr: 0.00045905  max_mem: 7344M
[12/11 00:19:11 d2.utils.events]:  eta: 0:08:04  iter: 8499  total_loss: 2.082  loss_sem_seg: 0.9259  loss_center: 0.5699  loss_offset: 0.4743  time: 0.3243  data_time: 0.0274  lr: 0.00045361  max_mem: 7344M
[12/11 00:19:18 d2.utils.events]:  eta: 0:07:57  iter: 8519  total_loss: 2.382  loss_sem_seg: 1.002  loss_center: 0.6099  loss_offset: 0.5819  time: 0.3243  data_time: 0.0260  lr: 0.00044817  max_mem: 7344M
[12/11 00:19:24 d2.utils.events]:  eta: 0:07:50  iter: 8539  total_loss: 1.998  loss_sem_seg: 0.9753  loss_center: 0.55  loss_offset: 0.4976  time: 0.3243  data_time: 0.0278  lr: 0.00044272  max_mem: 7344M
[12/11 00:19:31 d2.utils.events]:  eta: 0:07:44  iter: 8559  total_loss: 2.074  loss_sem_seg: 1.007  loss_center: 0.5734  loss_offset: 0.5497  time: 0.3243  data_time: 0.0278  lr: 0.00043726  max_mem: 7344M
[12/11 00:19:37 d2.utils.events]:  eta: 0:07:38  iter: 8579  total_loss: 2.065  loss_sem_seg: 1.099  loss_center: 0.4174  loss_offset: 0.5585  time: 0.3243  data_time: 0.0264  lr: 0.00043179  max_mem: 7344M
[12/11 00:19:43 d2.utils.events]:  eta: 0:07:31  iter: 8599  total_loss: 2.322  loss_sem_seg: 1.03  loss_center: 0.4655  loss_offset: 0.5594  time: 0.3243  data_time: 0.0267  lr: 0.00042632  max_mem: 7344M
[12/11 00:19:50 d2.utils.events]:  eta: 0:07:25  iter: 8619  total_loss: 2.272  loss_sem_seg: 1.084  loss_center: 0.5834  loss_offset: 0.5368  time: 0.3243  data_time: 0.0273  lr: 0.00042084  max_mem: 7344M
[12/11 00:19:56 d2.utils.events]:  eta: 0:07:18  iter: 8639  total_loss: 2.052  loss_sem_seg: 0.8694  loss_center: 0.5294  loss_offset: 0.4466  time: 0.3243  data_time: 0.0272  lr: 0.00041535  max_mem: 7344M
[12/11 00:20:03 d2.utils.events]:  eta: 0:07:12  iter: 8659  total_loss: 2.094  loss_sem_seg: 0.9332  loss_center: 0.4101  loss_offset: 0.4733  time: 0.3242  data_time: 0.0284  lr: 0.00040985  max_mem: 7344M
[12/11 00:20:09 d2.utils.events]:  eta: 0:07:05  iter: 8679  total_loss: 2.108  loss_sem_seg: 1.145  loss_center: 0.5042  loss_offset: 0.422  time: 0.3243  data_time: 0.0277  lr: 0.00040435  max_mem: 7344M
[12/11 00:20:16 d2.utils.events]:  eta: 0:06:59  iter: 8699  total_loss: 2.235  loss_sem_seg: 0.9124  loss_center: 0.5815  loss_offset: 0.5724  time: 0.3242  data_time: 0.0262  lr: 0.00039883  max_mem: 7344M
[12/11 00:20:22 d2.utils.events]:  eta: 0:06:52  iter: 8719  total_loss: 2.343  loss_sem_seg: 1.12  loss_center: 0.4968  loss_offset: 0.5679  time: 0.3242  data_time: 0.0265  lr: 0.00039331  max_mem: 7344M
[12/11 00:20:29 d2.utils.events]:  eta: 0:06:46  iter: 8739  total_loss: 2.16  loss_sem_seg: 0.974  loss_center: 0.4276  loss_offset: 0.51  time: 0.3242  data_time: 0.0269  lr: 0.00038778  max_mem: 7344M
[12/11 00:20:35 d2.utils.events]:  eta: 0:06:39  iter: 8759  total_loss: 2.291  loss_sem_seg: 0.9963  loss_center: 0.5375  loss_offset: 0.554  time: 0.3242  data_time: 0.0274  lr: 0.00038224  max_mem: 7344M
[12/11 00:20:42 d2.utils.events]:  eta: 0:06:33  iter: 8779  total_loss: 2.25  loss_sem_seg: 1.173  loss_center: 0.5113  loss_offset: 0.5644  time: 0.3242  data_time: 0.0277  lr: 0.00037669  max_mem: 7344M
[12/11 00:20:48 d2.utils.events]:  eta: 0:06:26  iter: 8799  total_loss: 2.252  loss_sem_seg: 1.013  loss_center: 0.4765  loss_offset: 0.713  time: 0.3242  data_time: 0.0261  lr: 0.00037113  max_mem: 7344M
[12/11 00:20:55 d2.utils.events]:  eta: 0:06:20  iter: 8819  total_loss: 2.027  loss_sem_seg: 0.9723  loss_center: 0.4899  loss_offset: 0.5486  time: 0.3242  data_time: 0.0283  lr: 0.00036557  max_mem: 7344M
[12/11 00:21:01 d2.utils.events]:  eta: 0:06:14  iter: 8839  total_loss: 2.24  loss_sem_seg: 1.078  loss_center: 0.5177  loss_offset: 0.554  time: 0.3242  data_time: 0.0271  lr: 0.00035999  max_mem: 7344M
[12/11 00:21:08 d2.utils.events]:  eta: 0:06:07  iter: 8859  total_loss: 1.975  loss_sem_seg: 0.9864  loss_center: 0.3707  loss_offset: 0.5314  time: 0.3242  data_time: 0.0289  lr: 0.0003544  max_mem: 7344M
[12/11 00:21:14 d2.utils.events]:  eta: 0:06:01  iter: 8879  total_loss: 2.293  loss_sem_seg: 1.159  loss_center: 0.5893  loss_offset: 0.6757  time: 0.3242  data_time: 0.0280  lr: 0.00034881  max_mem: 7344M
[12/11 00:21:21 d2.utils.events]:  eta: 0:05:54  iter: 8899  total_loss: 2.167  loss_sem_seg: 1.113  loss_center: 0.3767  loss_offset: 0.5573  time: 0.3242  data_time: 0.0264  lr: 0.0003432  max_mem: 7344M
[12/11 00:21:27 d2.utils.events]:  eta: 0:05:48  iter: 8919  total_loss: 2.092  loss_sem_seg: 1.031  loss_center: 0.481  loss_offset: 0.5503  time: 0.3242  data_time: 0.0266  lr: 0.00033758  max_mem: 7344M
[12/11 00:21:34 d2.utils.events]:  eta: 0:05:41  iter: 8939  total_loss: 2.235  loss_sem_seg: 1.049  loss_center: 0.482  loss_offset: 0.5976  time: 0.3242  data_time: 0.0289  lr: 0.00033196  max_mem: 7344M
[12/11 00:21:40 d2.utils.events]:  eta: 0:05:35  iter: 8959  total_loss: 2.056  loss_sem_seg: 0.9865  loss_center: 0.4827  loss_offset: 0.45  time: 0.3242  data_time: 0.0276  lr: 0.00032632  max_mem: 7344M
[12/11 00:21:47 d2.utils.events]:  eta: 0:05:28  iter: 8979  total_loss: 2.235  loss_sem_seg: 1.06  loss_center: 0.5482  loss_offset: 0.4866  time: 0.3242  data_time: 0.0276  lr: 0.00032067  max_mem: 7344M
[12/11 00:21:53 d2.utils.events]:  eta: 0:05:22  iter: 8999  total_loss: 2.022  loss_sem_seg: 0.9871  loss_center: 0.4669  loss_offset: 0.5578  time: 0.3242  data_time: 0.0275  lr: 0.00031501  max_mem: 7344M
[12/11 00:22:00 d2.utils.events]:  eta: 0:05:16  iter: 9019  total_loss: 2.109  loss_sem_seg: 0.9177  loss_center: 0.5596  loss_offset: 0.4506  time: 0.3242  data_time: 0.0272  lr: 0.00030934  max_mem: 7344M
[12/11 00:22:06 d2.utils.events]:  eta: 0:05:09  iter: 9039  total_loss: 2.051  loss_sem_seg: 0.929  loss_center: 0.3764  loss_offset: 0.5861  time: 0.3242  data_time: 0.0274  lr: 0.00030366  max_mem: 7344M
[12/11 00:22:13 d2.utils.events]:  eta: 0:05:03  iter: 9059  total_loss: 2.22  loss_sem_seg: 1.072  loss_center: 0.4032  loss_offset: 0.5703  time: 0.3242  data_time: 0.0258  lr: 0.00029797  max_mem: 7344M
[12/11 00:22:19 d2.utils.events]:  eta: 0:04:56  iter: 9079  total_loss: 1.888  loss_sem_seg: 0.8472  loss_center: 0.4902  loss_offset: 0.5504  time: 0.3242  data_time: 0.0261  lr: 0.00029226  max_mem: 7344M
[12/11 00:22:26 d2.utils.events]:  eta: 0:04:50  iter: 9099  total_loss: 2.294  loss_sem_seg: 1.004  loss_center: 0.5406  loss_offset: 0.4486  time: 0.3242  data_time: 0.0261  lr: 0.00028654  max_mem: 7344M
[12/11 00:22:32 d2.utils.events]:  eta: 0:04:43  iter: 9119  total_loss: 2.041  loss_sem_seg: 1.001  loss_center: 0.5659  loss_offset: 0.5317  time: 0.3242  data_time: 0.0263  lr: 0.00028081  max_mem: 7344M
[12/11 00:22:38 d2.utils.events]:  eta: 0:04:37  iter: 9139  total_loss: 2.386  loss_sem_seg: 1.175  loss_center: 0.6367  loss_offset: 0.5758  time: 0.3242  data_time: 0.0266  lr: 0.00027507  max_mem: 7344M
[12/11 00:22:45 d2.utils.events]:  eta: 0:04:31  iter: 9159  total_loss: 2.09  loss_sem_seg: 0.9668  loss_center: 0.4844  loss_offset: 0.6698  time: 0.3242  data_time: 0.0280  lr: 0.00026931  max_mem: 7344M
[12/11 00:22:51 d2.utils.events]:  eta: 0:04:24  iter: 9179  total_loss: 2.076  loss_sem_seg: 0.9626  loss_center: 0.467  loss_offset: 0.5015  time: 0.3242  data_time: 0.0302  lr: 0.00026354  max_mem: 7344M
[12/11 00:22:58 d2.utils.events]:  eta: 0:04:18  iter: 9199  total_loss: 2.191  loss_sem_seg: 0.9295  loss_center: 0.6403  loss_offset: 0.5275  time: 0.3242  data_time: 0.0263  lr: 0.00025776  max_mem: 7344M
[12/11 00:23:04 d2.utils.events]:  eta: 0:04:11  iter: 9219  total_loss: 2.137  loss_sem_seg: 1.015  loss_center: 0.6735  loss_offset: 0.4773  time: 0.3242  data_time: 0.0257  lr: 0.00025196  max_mem: 7344M
[12/11 00:23:11 d2.utils.events]:  eta: 0:04:05  iter: 9239  total_loss: 1.997  loss_sem_seg: 1.122  loss_center: 0.5302  loss_offset: 0.4239  time: 0.3242  data_time: 0.0290  lr: 0.00024614  max_mem: 7344M
[12/11 00:23:17 d2.utils.events]:  eta: 0:03:58  iter: 9259  total_loss: 2.113  loss_sem_seg: 0.8689  loss_center: 0.5668  loss_offset: 0.6751  time: 0.3242  data_time: 0.0280  lr: 0.00024031  max_mem: 7344M
[12/11 00:23:24 d2.utils.events]:  eta: 0:03:52  iter: 9279  total_loss: 2.074  loss_sem_seg: 0.9012  loss_center: 0.6016  loss_offset: 0.4967  time: 0.3242  data_time: 0.0278  lr: 0.00023447  max_mem: 7344M
[12/11 00:23:30 d2.utils.events]:  eta: 0:03:45  iter: 9299  total_loss: 1.94  loss_sem_seg: 0.852  loss_center: 0.474  loss_offset: 0.432  time: 0.3242  data_time: 0.0261  lr: 0.00022861  max_mem: 7344M
[12/11 00:23:37 d2.utils.events]:  eta: 0:03:39  iter: 9319  total_loss: 2.158  loss_sem_seg: 0.9541  loss_center: 0.5416  loss_offset: 0.5178  time: 0.3242  data_time: 0.0256  lr: 0.00022273  max_mem: 7344M
[12/11 00:23:43 d2.utils.events]:  eta: 0:03:32  iter: 9339  total_loss: 2.188  loss_sem_seg: 1.074  loss_center: 0.4737  loss_offset: 0.6309  time: 0.3242  data_time: 0.0280  lr: 0.00021683  max_mem: 7344M
[12/11 00:23:50 d2.utils.events]:  eta: 0:03:26  iter: 9359  total_loss: 2.14  loss_sem_seg: 1.048  loss_center: 0.4732  loss_offset: 0.4732  time: 0.3242  data_time: 0.0271  lr: 0.00021092  max_mem: 7344M
[12/11 00:23:56 d2.utils.events]:  eta: 0:03:20  iter: 9379  total_loss: 2.309  loss_sem_seg: 1.006  loss_center: 0.5019  loss_offset: 0.616  time: 0.3242  data_time: 0.0275  lr: 0.00020499  max_mem: 7344M
[12/11 00:24:03 d2.utils.events]:  eta: 0:03:13  iter: 9399  total_loss: 2.093  loss_sem_seg: 0.9113  loss_center: 0.4947  loss_offset: 0.6003  time: 0.3242  data_time: 0.0274  lr: 0.00019903  max_mem: 7344M
[12/11 00:24:09 d2.utils.events]:  eta: 0:03:07  iter: 9419  total_loss: 2.22  loss_sem_seg: 0.979  loss_center: 0.5645  loss_offset: 0.5019  time: 0.3242  data_time: 0.0275  lr: 0.00019306  max_mem: 7344M
[12/11 00:24:16 d2.utils.events]:  eta: 0:03:00  iter: 9439  total_loss: 2.139  loss_sem_seg: 1.128  loss_center: 0.5457  loss_offset: 0.5027  time: 0.3242  data_time: 0.0273  lr: 0.00018707  max_mem: 7344M
[12/11 00:24:22 d2.utils.events]:  eta: 0:02:54  iter: 9459  total_loss: 1.896  loss_sem_seg: 0.8829  loss_center: 0.411  loss_offset: 0.4779  time: 0.3242  data_time: 0.0276  lr: 0.00018106  max_mem: 7344M
[12/11 00:24:29 d2.utils.events]:  eta: 0:02:47  iter: 9479  total_loss: 2.234  loss_sem_seg: 1.12  loss_center: 0.5684  loss_offset: 0.5561  time: 0.3242  data_time: 0.0273  lr: 0.00017502  max_mem: 7344M
[12/11 00:24:35 d2.utils.events]:  eta: 0:02:41  iter: 9499  total_loss: 2.217  loss_sem_seg: 0.9693  loss_center: 0.5524  loss_offset: 0.5445  time: 0.3242  data_time: 0.0255  lr: 0.00016896  max_mem: 7344M
[12/11 00:24:41 d2.utils.events]:  eta: 0:02:34  iter: 9519  total_loss: 2.292  loss_sem_seg: 1.096  loss_center: 0.4708  loss_offset: 0.5627  time: 0.3242  data_time: 0.0282  lr: 0.00016288  max_mem: 7344M
[12/11 00:24:48 d2.utils.events]:  eta: 0:02:28  iter: 9539  total_loss: 2.064  loss_sem_seg: 0.8353  loss_center: 0.553  loss_offset: 0.5362  time: 0.3242  data_time: 0.0266  lr: 0.00015677  max_mem: 7344M
[12/11 00:24:54 d2.utils.events]:  eta: 0:02:22  iter: 9559  total_loss: 2.061  loss_sem_seg: 0.9919  loss_center: 0.4838  loss_offset: 0.4784  time: 0.3242  data_time: 0.0269  lr: 0.00015064  max_mem: 7344M
[12/11 00:25:01 d2.utils.events]:  eta: 0:02:15  iter: 9579  total_loss: 2.049  loss_sem_seg: 0.9523  loss_center: 0.535  loss_offset: 0.5446  time: 0.3242  data_time: 0.0285  lr: 0.00014448  max_mem: 7344M
[12/11 00:25:07 d2.utils.events]:  eta: 0:02:09  iter: 9599  total_loss: 2.068  loss_sem_seg: 0.9618  loss_center: 0.5238  loss_offset: 0.5162  time: 0.3242  data_time: 0.0251  lr: 0.00013828  max_mem: 7344M
[12/11 00:25:14 d2.utils.events]:  eta: 0:02:02  iter: 9619  total_loss: 1.916  loss_sem_seg: 0.9686  loss_center: 0.4119  loss_offset: 0.5717  time: 0.3242  data_time: 0.0273  lr: 0.00013206  max_mem: 7344M
[12/11 00:25:20 d2.utils.events]:  eta: 0:01:56  iter: 9639  total_loss: 2.219  loss_sem_seg: 1.164  loss_center: 0.5493  loss_offset: 0.541  time: 0.3242  data_time: 0.0273  lr: 0.0001258  max_mem: 7344M
[12/11 00:25:27 d2.utils.events]:  eta: 0:01:49  iter: 9659  total_loss: 2.218  loss_sem_seg: 0.9765  loss_center: 0.4655  loss_offset: 0.4389  time: 0.3242  data_time: 0.0260  lr: 0.00011951  max_mem: 7344M
[12/11 00:25:33 d2.utils.events]:  eta: 0:01:43  iter: 9679  total_loss: 2.186  loss_sem_seg: 1.1  loss_center: 0.3922  loss_offset: 0.5482  time: 0.3242  data_time: 0.0279  lr: 0.00011319  max_mem: 7344M
[12/11 00:25:40 d2.utils.events]:  eta: 0:01:36  iter: 9699  total_loss: 1.866  loss_sem_seg: 0.8359  loss_center: 0.4653  loss_offset: 0.5072  time: 0.3242  data_time: 0.0270  lr: 0.00010682  max_mem: 7344M
[12/11 00:25:46 d2.utils.events]:  eta: 0:01:30  iter: 9719  total_loss: 2.196  loss_sem_seg: 1.142  loss_center: 0.4364  loss_offset: 0.584  time: 0.3242  data_time: 0.0287  lr: 0.00010041  max_mem: 7344M
[12/11 00:25:53 d2.utils.events]:  eta: 0:01:23  iter: 9739  total_loss: 2.007  loss_sem_seg: 0.8895  loss_center: 0.5331  loss_offset: 0.5399  time: 0.3242  data_time: 0.0266  lr: 9.3954e-05  max_mem: 7344M
[12/11 00:25:59 d2.utils.events]:  eta: 0:01:17  iter: 9759  total_loss: 2.319  loss_sem_seg: 1.03  loss_center: 0.5432  loss_offset: 0.5727  time: 0.3241  data_time: 0.0265  lr: 8.7449e-05  max_mem: 7344M
[12/11 00:26:06 d2.utils.events]:  eta: 0:01:10  iter: 9779  total_loss: 2.201  loss_sem_seg: 1.013  loss_center: 0.4844  loss_offset: 0.4508  time: 0.3241  data_time: 0.0280  lr: 8.089e-05  max_mem: 7344M
[12/11 00:26:12 d2.utils.events]:  eta: 0:01:04  iter: 9799  total_loss: 1.751  loss_sem_seg: 0.9188  loss_center: 0.4487  loss_offset: 0.5068  time: 0.3241  data_time: 0.0252  lr: 7.4271e-05  max_mem: 7344M
[12/11 00:26:19 d2.utils.events]:  eta: 0:00:57  iter: 9819  total_loss: 2.046  loss_sem_seg: 0.984  loss_center: 0.4553  loss_offset: 0.487  time: 0.3241  data_time: 0.0279  lr: 6.7585e-05  max_mem: 7344M
[12/11 00:26:25 d2.utils.events]:  eta: 0:00:51  iter: 9839  total_loss: 2.211  loss_sem_seg: 0.984  loss_center: 0.5801  loss_offset: 0.5584  time: 0.3241  data_time: 0.0260  lr: 6.0825e-05  max_mem: 7344M
[12/11 00:26:32 d2.utils.events]:  eta: 0:00:45  iter: 9859  total_loss: 2.189  loss_sem_seg: 0.9507  loss_center: 0.5268  loss_offset: 0.4957  time: 0.3241  data_time: 0.0279  lr: 5.3981e-05  max_mem: 7344M
[12/11 00:26:38 d2.utils.events]:  eta: 0:00:38  iter: 9879  total_loss: 2.224  loss_sem_seg: 0.8966  loss_center: 0.5423  loss_offset: 0.5606  time: 0.3241  data_time: 0.0260  lr: 4.7038e-05  max_mem: 7344M
[12/11 00:26:44 d2.utils.events]:  eta: 0:00:32  iter: 9899  total_loss: 2.067  loss_sem_seg: 0.7795  loss_center: 0.5126  loss_offset: 0.4962  time: 0.3241  data_time: 0.0272  lr: 3.9979e-05  max_mem: 7344M
[12/11 00:26:51 d2.utils.events]:  eta: 0:00:25  iter: 9919  total_loss: 2.401  loss_sem_seg: 1.097  loss_center: 0.4883  loss_offset: 0.5513  time: 0.3241  data_time: 0.0276  lr: 3.2778e-05  max_mem: 7344M
[12/11 00:26:57 d2.utils.events]:  eta: 0:00:19  iter: 9939  total_loss: 2.225  loss_sem_seg: 0.9622  loss_center: 0.5695  loss_offset: 0.5372  time: 0.3241  data_time: 0.0264  lr: 2.5394e-05  max_mem: 7344M
[12/11 00:27:04 d2.utils.events]:  eta: 0:00:12  iter: 9959  total_loss: 1.946  loss_sem_seg: 0.835  loss_center: 0.5268  loss_offset: 0.461  time: 0.3241  data_time: 0.0274  lr: 1.776e-05  max_mem: 7344M
[12/11 00:27:10 d2.utils.events]:  eta: 0:00:06  iter: 9979  total_loss: 1.988  loss_sem_seg: 0.8125  loss_center: 0.4695  loss_offset: 0.4608  time: 0.3241  data_time: 0.0274  lr: 9.7261e-06  max_mem: 7344M
[12/11 00:27:17 fvcore.common.checkpoint]: Saving checkpoint to ./output/model_0009999.pth
[12/11 00:27:17 fvcore.common.checkpoint]: Saving checkpoint to ./output/model_final.pth
[12/11 00:27:18 d2.utils.events]:  eta: 0:00:00  iter: 9999  total_loss: 2.152  loss_sem_seg: 1.103  loss_center: 0.477  loss_offset: 0.5376  time: 0.3241  data_time: 0.0270  lr: 6.2797e-07  max_mem: 7344M
[12/11 00:27:19 d2.engine.hooks]: Overall training speed: 9998 iterations in 0:54:00 (0.3241 s / it)
[12/11 00:27:19 d2.engine.hooks]: Total training time: 0:54:08 (0:00:07 on hooks)
[12/11 00:27:19 d2.data.dataset_mapper]: [DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(640, 640), max_size=640, sample_style='choice')]
[12/11 00:27:19 d2.data.common]: Serializing the dataset using: <class 'detectron2.data.common.NumpySerializedList'>
[12/11 00:27:19 d2.data.common]: Serializing 5000 elements to byte tensors and concatenating them all ...
[12/11 00:27:19 d2.data.common]: Serialized dataset takes 3.40 MiB
/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:481: UserWarning: This DataLoader will create 10 worker processes in total. Our suggested max number of worker in current system is 8, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.
  cpuset_checked))
[12/11 00:27:20 d2.evaluation.evaluator]: Start inference on 5000 batches
/usr/local/lib/python3.7/dist-packages/torch/functional.py:445: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at  ../aten/src/ATen/native/TensorShape.cpp:2157.)
  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]
[12/11 00:27:22 d2.evaluation.evaluator]: Inference done 11/5000. Dataloading: 0.0002 s/iter. Inference: 0.0505 s/iter. Eval: 0.0369 s/iter. Total: 0.0877 s/iter. ETA=0:07:17
[12/11 00:27:27 d2.evaluation.evaluator]: Inference done 72/5000. Dataloading: 0.0010 s/iter. Inference: 0.0503 s/iter. Eval: 0.0319 s/iter. Total: 0.0833 s/iter. ETA=0:06:50
[12/11 00:27:32 d2.evaluation.evaluator]: Inference done 127/5000. Dataloading: 0.0011 s/iter. Inference: 0.0517 s/iter. Eval: 0.0342 s/iter. Total: 0.0871 s/iter. ETA=0:07:04
[12/11 00:27:37 d2.evaluation.evaluator]: Inference done 182/5000. Dataloading: 0.0011 s/iter. Inference: 0.0522 s/iter. Eval: 0.0350 s/iter. Total: 0.0883 s/iter. ETA=0:07:05
[12/11 00:27:42 d2.evaluation.evaluator]: Inference done 243/5000. Dataloading: 0.0011 s/iter. Inference: 0.0514 s/iter. Eval: 0.0343 s/iter. Total: 0.0869 s/iter. ETA=0:06:53
[12/11 00:27:47 d2.evaluation.evaluator]: Inference done 300/5000. Dataloading: 0.0011 s/iter. Inference: 0.0515 s/iter. Eval: 0.0344 s/iter. Total: 0.0871 s/iter. ETA=0:06:49
[12/11 00:27:52 d2.evaluation.evaluator]: Inference done 357/5000. Dataloading: 0.0011 s/iter. Inference: 0.0517 s/iter. Eval: 0.0345 s/iter. Total: 0.0874 s/iter. ETA=0:06:45
[12/11 00:27:57 d2.evaluation.evaluator]: Inference done 418/5000. Dataloading: 0.0011 s/iter. Inference: 0.0513 s/iter. Eval: 0.0342 s/iter. Total: 0.0867 s/iter. ETA=0:06:37
[12/11 00:28:02 d2.evaluation.evaluator]: Inference done 479/5000. Dataloading: 0.0011 s/iter. Inference: 0.0511 s/iter. Eval: 0.0339 s/iter. Total: 0.0862 s/iter. ETA=0:06:29
[12/11 00:28:07 d2.evaluation.evaluator]: Inference done 536/5000. Dataloading: 0.0012 s/iter. Inference: 0.0514 s/iter. Eval: 0.0340 s/iter. Total: 0.0865 s/iter. ETA=0:06:26
[12/11 00:28:12 d2.evaluation.evaluator]: Inference done 591/5000. Dataloading: 0.0012 s/iter. Inference: 0.0517 s/iter. Eval: 0.0342 s/iter. Total: 0.0871 s/iter. ETA=0:06:23
[12/11 00:28:17 d2.evaluation.evaluator]: Inference done 647/5000. Dataloading: 0.0012 s/iter. Inference: 0.0518 s/iter. Eval: 0.0342 s/iter. Total: 0.0873 s/iter. ETA=0:06:20
[12/11 00:28:22 d2.evaluation.evaluator]: Inference done 701/5000. Dataloading: 0.0012 s/iter. Inference: 0.0523 s/iter. Eval: 0.0343 s/iter. Total: 0.0878 s/iter. ETA=0:06:17
[12/11 00:28:27 d2.evaluation.evaluator]: Inference done 760/5000. Dataloading: 0.0012 s/iter. Inference: 0.0522 s/iter. Eval: 0.0343 s/iter. Total: 0.0877 s/iter. ETA=0:06:11
[12/11 00:28:33 d2.evaluation.evaluator]: Inference done 820/5000. Dataloading: 0.0012 s/iter. Inference: 0.0520 s/iter. Eval: 0.0342 s/iter. Total: 0.0875 s/iter. ETA=0:06:05
[12/11 00:28:38 d2.evaluation.evaluator]: Inference done 879/5000. Dataloading: 0.0012 s/iter. Inference: 0.0520 s/iter. Eval: 0.0342 s/iter. Total: 0.0874 s/iter. ETA=0:06:00
[12/11 00:28:43 d2.evaluation.evaluator]: Inference done 940/5000. Dataloading: 0.0012 s/iter. Inference: 0.0518 s/iter. Eval: 0.0341 s/iter. Total: 0.0871 s/iter. ETA=0:05:53
[12/11 00:28:48 d2.evaluation.evaluator]: Inference done 1000/5000. Dataloading: 0.0012 s/iter. Inference: 0.0517 s/iter. Eval: 0.0340 s/iter. Total: 0.0869 s/iter. ETA=0:05:47
[12/11 00:28:53 d2.evaluation.evaluator]: Inference done 1058/5000. Dataloading: 0.0012 s/iter. Inference: 0.0517 s/iter. Eval: 0.0341 s/iter. Total: 0.0870 s/iter. ETA=0:05:42
[12/11 00:28:58 d2.evaluation.evaluator]: Inference done 1118/5000. Dataloading: 0.0012 s/iter. Inference: 0.0515 s/iter. Eval: 0.0340 s/iter. Total: 0.0868 s/iter. ETA=0:05:36
[12/11 00:29:03 d2.evaluation.evaluator]: Inference done 1177/5000. Dataloading: 0.0012 s/iter. Inference: 0.0515 s/iter. Eval: 0.0340 s/iter. Total: 0.0867 s/iter. ETA=0:05:31
[12/11 00:29:08 d2.evaluation.evaluator]: Inference done 1232/5000. Dataloading: 0.0012 s/iter. Inference: 0.0516 s/iter. Eval: 0.0341 s/iter. Total: 0.0869 s/iter. ETA=0:05:27
[12/11 00:29:13 d2.evaluation.evaluator]: Inference done 1288/5000. Dataloading: 0.0012 s/iter. Inference: 0.0517 s/iter. Eval: 0.0341 s/iter. Total: 0.0870 s/iter. ETA=0:05:23
[12/11 00:29:18 d2.evaluation.evaluator]: Inference done 1346/5000. Dataloading: 0.0012 s/iter. Inference: 0.0517 s/iter. Eval: 0.0341 s/iter. Total: 0.0870 s/iter. ETA=0:05:17
[12/11 00:29:23 d2.evaluation.evaluator]: Inference done 1405/5000. Dataloading: 0.0012 s/iter. Inference: 0.0516 s/iter. Eval: 0.0341 s/iter. Total: 0.0869 s/iter. ETA=0:05:12
[12/11 00:29:28 d2.evaluation.evaluator]: Inference done 1462/5000. Dataloading: 0.0012 s/iter. Inference: 0.0516 s/iter. Eval: 0.0341 s/iter. Total: 0.0870 s/iter. ETA=0:05:07
[12/11 00:29:33 d2.evaluation.evaluator]: Inference done 1519/5000. Dataloading: 0.0012 s/iter. Inference: 0.0516 s/iter. Eval: 0.0342 s/iter. Total: 0.0870 s/iter. ETA=0:05:02
[12/11 00:29:38 d2.evaluation.evaluator]: Inference done 1575/5000. Dataloading: 0.0012 s/iter. Inference: 0.0516 s/iter. Eval: 0.0342 s/iter. Total: 0.0871 s/iter. ETA=0:04:58
[12/11 00:29:43 d2.evaluation.evaluator]: Inference done 1631/5000. Dataloading: 0.0012 s/iter. Inference: 0.0517 s/iter. Eval: 0.0343 s/iter. Total: 0.0872 s/iter. ETA=0:04:53
[12/11 00:29:48 d2.evaluation.evaluator]: Inference done 1688/5000. Dataloading: 0.0012 s/iter. Inference: 0.0517 s/iter. Eval: 0.0343 s/iter. Total: 0.0872 s/iter. ETA=0:04:48
[12/11 00:29:53 d2.evaluation.evaluator]: Inference done 1747/5000. Dataloading: 0.0012 s/iter. Inference: 0.0517 s/iter. Eval: 0.0343 s/iter. Total: 0.0872 s/iter. ETA=0:04:43
[12/11 00:29:58 d2.evaluation.evaluator]: Inference done 1806/5000. Dataloading: 0.0012 s/iter. Inference: 0.0516 s/iter. Eval: 0.0342 s/iter. Total: 0.0871 s/iter. ETA=0:04:38
[12/11 00:30:03 d2.evaluation.evaluator]: Inference done 1861/5000. Dataloading: 0.0012 s/iter. Inference: 0.0517 s/iter. Eval: 0.0343 s/iter. Total: 0.0872 s/iter. ETA=0:04:33
[12/11 00:30:08 d2.evaluation.evaluator]: Inference done 1918/5000. Dataloading: 0.0012 s/iter. Inference: 0.0518 s/iter. Eval: 0.0343 s/iter. Total: 0.0873 s/iter. ETA=0:04:28
[12/11 00:30:13 d2.evaluation.evaluator]: Inference done 1976/5000. Dataloading: 0.0012 s/iter. Inference: 0.0518 s/iter. Eval: 0.0343 s/iter. Total: 0.0873 s/iter. ETA=0:04:23
[12/11 00:30:18 d2.evaluation.evaluator]: Inference done 2032/5000. Dataloading: 0.0012 s/iter. Inference: 0.0518 s/iter. Eval: 0.0343 s/iter. Total: 0.0874 s/iter. ETA=0:04:19
[12/11 00:30:23 d2.evaluation.evaluator]: Inference done 2090/5000. Dataloading: 0.0012 s/iter. Inference: 0.0518 s/iter. Eval: 0.0343 s/iter. Total: 0.0873 s/iter. ETA=0:04:14
[12/11 00:30:28 d2.evaluation.evaluator]: Inference done 2149/5000. Dataloading: 0.0012 s/iter. Inference: 0.0518 s/iter. Eval: 0.0342 s/iter. Total: 0.0873 s/iter. ETA=0:04:08
[12/11 00:30:34 d2.evaluation.evaluator]: Inference done 2206/5000. Dataloading: 0.0012 s/iter. Inference: 0.0519 s/iter. Eval: 0.0342 s/iter. Total: 0.0874 s/iter. ETA=0:04:04
[12/11 00:30:39 d2.evaluation.evaluator]: Inference done 2264/5000. Dataloading: 0.0012 s/iter. Inference: 0.0519 s/iter. Eval: 0.0342 s/iter. Total: 0.0873 s/iter. ETA=0:03:58
[12/11 00:30:44 d2.evaluation.evaluator]: Inference done 2325/5000. Dataloading: 0.0012 s/iter. Inference: 0.0518 s/iter. Eval: 0.0341 s/iter. Total: 0.0872 s/iter. ETA=0:03:53
[12/11 00:30:49 d2.evaluation.evaluator]: Inference done 2384/5000. Dataloading: 0.0012 s/iter. Inference: 0.0518 s/iter. Eval: 0.0341 s/iter. Total: 0.0872 s/iter. ETA=0:03:48
[12/11 00:30:54 d2.evaluation.evaluator]: Inference done 2439/5000. Dataloading: 0.0012 s/iter. Inference: 0.0519 s/iter. Eval: 0.0342 s/iter. Total: 0.0873 s/iter. ETA=0:03:43
[12/11 00:30:59 d2.evaluation.evaluator]: Inference done 2496/5000. Dataloading: 0.0012 s/iter. Inference: 0.0519 s/iter. Eval: 0.0342 s/iter. Total: 0.0873 s/iter. ETA=0:03:38
[12/11 00:31:04 d2.evaluation.evaluator]: Inference done 2553/5000. Dataloading: 0.0012 s/iter. Inference: 0.0519 s/iter. Eval: 0.0342 s/iter. Total: 0.0873 s/iter. ETA=0:03:33
[12/11 00:31:09 d2.evaluation.evaluator]: Inference done 2610/5000. Dataloading: 0.0012 s/iter. Inference: 0.0519 s/iter. Eval: 0.0342 s/iter. Total: 0.0873 s/iter. ETA=0:03:28
[12/11 00:31:14 d2.evaluation.evaluator]: Inference done 2667/5000. Dataloading: 0.0012 s/iter. Inference: 0.0520 s/iter. Eval: 0.0342 s/iter. Total: 0.0874 s/iter. ETA=0:03:23
[12/11 00:31:19 d2.evaluation.evaluator]: Inference done 2728/5000. Dataloading: 0.0012 s/iter. Inference: 0.0519 s/iter. Eval: 0.0341 s/iter. Total: 0.0873 s/iter. ETA=0:03:18
[12/11 00:31:24 d2.evaluation.evaluator]: Inference done 2786/5000. Dataloading: 0.0012 s/iter. Inference: 0.0519 s/iter. Eval: 0.0341 s/iter. Total: 0.0872 s/iter. ETA=0:03:13
[12/11 00:31:29 d2.evaluation.evaluator]: Inference done 2844/5000. Dataloading: 0.0012 s/iter. Inference: 0.0519 s/iter. Eval: 0.0341 s/iter. Total: 0.0872 s/iter. ETA=0:03:08
[12/11 00:31:34 d2.evaluation.evaluator]: Inference done 2902/5000. Dataloading: 0.0012 s/iter. Inference: 0.0519 s/iter. Eval: 0.0341 s/iter. Total: 0.0872 s/iter. ETA=0:03:03
[12/11 00:31:39 d2.evaluation.evaluator]: Inference done 2960/5000. Dataloading: 0.0012 s/iter. Inference: 0.0519 s/iter. Eval: 0.0341 s/iter. Total: 0.0872 s/iter. ETA=0:02:57
[12/11 00:31:44 d2.evaluation.evaluator]: Inference done 3018/5000. Dataloading: 0.0012 s/iter. Inference: 0.0519 s/iter. Eval: 0.0341 s/iter. Total: 0.0872 s/iter. ETA=0:02:52
[12/11 00:31:49 d2.evaluation.evaluator]: Inference done 3079/5000. Dataloading: 0.0012 s/iter. Inference: 0.0518 s/iter. Eval: 0.0341 s/iter. Total: 0.0871 s/iter. ETA=0:02:47
[12/11 00:31:54 d2.evaluation.evaluator]: Inference done 3137/5000. Dataloading: 0.0012 s/iter. Inference: 0.0518 s/iter. Eval: 0.0341 s/iter. Total: 0.0871 s/iter. ETA=0:02:42
[12/11 00:31:59 d2.evaluation.evaluator]: Inference done 3194/5000. Dataloading: 0.0012 s/iter. Inference: 0.0518 s/iter. Eval: 0.0341 s/iter. Total: 0.0871 s/iter. ETA=0:02:37
[12/11 00:32:04 d2.evaluation.evaluator]: Inference done 3251/5000. Dataloading: 0.0012 s/iter. Inference: 0.0518 s/iter. Eval: 0.0341 s/iter. Total: 0.0872 s/iter. ETA=0:02:32
[12/11 00:32:09 d2.evaluation.evaluator]: Inference done 3306/5000. Dataloading: 0.0012 s/iter. Inference: 0.0519 s/iter. Eval: 0.0342 s/iter. Total: 0.0873 s/iter. ETA=0:02:27
[12/11 00:32:14 d2.evaluation.evaluator]: Inference done 3363/5000. Dataloading: 0.0012 s/iter. Inference: 0.0519 s/iter. Eval: 0.0342 s/iter. Total: 0.0873 s/iter. ETA=0:02:22
[12/11 00:32:19 d2.evaluation.evaluator]: Inference done 3421/5000. Dataloading: 0.0012 s/iter. Inference: 0.0518 s/iter. Eval: 0.0342 s/iter. Total: 0.0873 s/iter. ETA=0:02:17
[12/11 00:32:24 d2.evaluation.evaluator]: Inference done 3478/5000. Dataloading: 0.0012 s/iter. Inference: 0.0518 s/iter. Eval: 0.0342 s/iter. Total: 0.0873 s/iter. ETA=0:02:12
[12/11 00:32:29 d2.evaluation.evaluator]: Inference done 3536/5000. Dataloading: 0.0012 s/iter. Inference: 0.0518 s/iter. Eval: 0.0342 s/iter. Total: 0.0873 s/iter. ETA=0:02:07
[12/11 00:32:34 d2.evaluation.evaluator]: Inference done 3593/5000. Dataloading: 0.0012 s/iter. Inference: 0.0518 s/iter. Eval: 0.0342 s/iter. Total: 0.0873 s/iter. ETA=0:02:02
[12/11 00:32:39 d2.evaluation.evaluator]: Inference done 3653/5000. Dataloading: 0.0012 s/iter. Inference: 0.0518 s/iter. Eval: 0.0342 s/iter. Total: 0.0872 s/iter. ETA=0:01:57
[12/11 00:32:45 d2.evaluation.evaluator]: Inference done 3711/5000. Dataloading: 0.0012 s/iter. Inference: 0.0518 s/iter. Eval: 0.0342 s/iter. Total: 0.0872 s/iter. ETA=0:01:52
[12/11 00:32:50 d2.evaluation.evaluator]: Inference done 3769/5000. Dataloading: 0.0012 s/iter. Inference: 0.0518 s/iter. Eval: 0.0342 s/iter. Total: 0.0872 s/iter. ETA=0:01:47
[12/11 00:32:55 d2.evaluation.evaluator]: Inference done 3826/5000. Dataloading: 0.0012 s/iter. Inference: 0.0518 s/iter. Eval: 0.0342 s/iter. Total: 0.0873 s/iter. ETA=0:01:42
[12/11 00:33:00 d2.evaluation.evaluator]: Inference done 3886/5000. Dataloading: 0.0012 s/iter. Inference: 0.0518 s/iter. Eval: 0.0342 s/iter. Total: 0.0872 s/iter. ETA=0:01:37
[12/11 00:33:05 d2.evaluation.evaluator]: Inference done 3944/5000. Dataloading: 0.0012 s/iter. Inference: 0.0517 s/iter. Eval: 0.0342 s/iter. Total: 0.0872 s/iter. ETA=0:01:32
[12/11 00:33:10 d2.evaluation.evaluator]: Inference done 4004/5000. Dataloading: 0.0012 s/iter. Inference: 0.0517 s/iter. Eval: 0.0342 s/iter. Total: 0.0872 s/iter. ETA=0:01:26
[12/11 00:33:15 d2.evaluation.evaluator]: Inference done 4061/5000. Dataloading: 0.0012 s/iter. Inference: 0.0517 s/iter. Eval: 0.0343 s/iter. Total: 0.0872 s/iter. ETA=0:01:21
[12/11 00:33:20 d2.evaluation.evaluator]: Inference done 4119/5000. Dataloading: 0.0012 s/iter. Inference: 0.0517 s/iter. Eval: 0.0343 s/iter. Total: 0.0872 s/iter. ETA=0:01:16
[12/11 00:33:25 d2.evaluation.evaluator]: Inference done 4175/5000. Dataloading: 0.0012 s/iter. Inference: 0.0517 s/iter. Eval: 0.0343 s/iter. Total: 0.0872 s/iter. ETA=0:01:11
[12/11 00:33:30 d2.evaluation.evaluator]: Inference done 4235/5000. Dataloading: 0.0012 s/iter. Inference: 0.0517 s/iter. Eval: 0.0343 s/iter. Total: 0.0872 s/iter. ETA=0:01:06
[12/11 00:33:35 d2.evaluation.evaluator]: Inference done 4293/5000. Dataloading: 0.0012 s/iter. Inference: 0.0517 s/iter. Eval: 0.0343 s/iter. Total: 0.0872 s/iter. ETA=0:01:01
[12/11 00:33:40 d2.evaluation.evaluator]: Inference done 4355/5000. Dataloading: 0.0012 s/iter. Inference: 0.0516 s/iter. Eval: 0.0342 s/iter. Total: 0.0871 s/iter. ETA=0:00:56
[12/11 00:33:45 d2.evaluation.evaluator]: Inference done 4414/5000. Dataloading: 0.0012 s/iter. Inference: 0.0516 s/iter. Eval: 0.0342 s/iter. Total: 0.0871 s/iter. ETA=0:00:51
[12/11 00:33:50 d2.evaluation.evaluator]: Inference done 4472/5000. Dataloading: 0.0012 s/iter. Inference: 0.0516 s/iter. Eval: 0.0342 s/iter. Total: 0.0871 s/iter. ETA=0:00:45
[12/11 00:33:55 d2.evaluation.evaluator]: Inference done 4532/5000. Dataloading: 0.0012 s/iter. Inference: 0.0516 s/iter. Eval: 0.0342 s/iter. Total: 0.0870 s/iter. ETA=0:00:40
[12/11 00:34:00 d2.evaluation.evaluator]: Inference done 4590/5000. Dataloading: 0.0012 s/iter. Inference: 0.0516 s/iter. Eval: 0.0342 s/iter. Total: 0.0870 s/iter. ETA=0:00:35
[12/11 00:34:05 d2.evaluation.evaluator]: Inference done 4649/5000. Dataloading: 0.0012 s/iter. Inference: 0.0515 s/iter. Eval: 0.0342 s/iter. Total: 0.0870 s/iter. ETA=0:00:30
[12/11 00:34:10 d2.evaluation.evaluator]: Inference done 4708/5000. Dataloading: 0.0012 s/iter. Inference: 0.0515 s/iter. Eval: 0.0342 s/iter. Total: 0.0870 s/iter. ETA=0:00:25
[12/11 00:34:15 d2.evaluation.evaluator]: Inference done 4769/5000. Dataloading: 0.0012 s/iter. Inference: 0.0515 s/iter. Eval: 0.0342 s/iter. Total: 0.0869 s/iter. ETA=0:00:20
[12/11 00:34:20 d2.evaluation.evaluator]: Inference done 4825/5000. Dataloading: 0.0012 s/iter. Inference: 0.0515 s/iter. Eval: 0.0342 s/iter. Total: 0.0870 s/iter. ETA=0:00:15
[12/11 00:34:26 d2.evaluation.evaluator]: Inference done 4886/5000. Dataloading: 0.0012 s/iter. Inference: 0.0515 s/iter. Eval: 0.0342 s/iter. Total: 0.0869 s/iter. ETA=0:00:09
[12/11 00:34:31 d2.evaluation.evaluator]: Inference done 4942/5000. Dataloading: 0.0012 s/iter. Inference: 0.0515 s/iter. Eval: 0.0342 s/iter. Total: 0.0870 s/iter. ETA=0:00:05
[12/11 00:34:36 d2.evaluation.evaluator]: Total inference time: 0:07:14.433168 (0.086974 s / iter per device, on 1 devices)
[12/11 00:34:36 d2.evaluation.evaluator]: Total inference pure compute time: 0:04:17 (0.051482 s / iter per device, on 1 devices)
[12/11 00:34:36 d2.evaluation.panoptic_evaluation]: Writing all panoptic predictions to /tmp/panoptic_eval43u85yg4 ...
[12/11 00:34:59 d2.evaluation.panoptic_evaluation]: Panoptic Evaluation Results:
|        |   PQ   |   SQ   |   RQ   |  #categories  |
|:------:|:------:|:------:|:------:|:-------------:|
|  All   | 16.016 | 59.563 | 20.934 |      133      |
| Things | 15.349 | 60.892 | 20.136 |      80       |
| Stuff  | 17.021 | 57.557 | 22.138 |      53       |
[12/11 00:35:00 d2.evaluation.coco_evaluation]: Preparing results for COCO format ...
[12/11 00:35:00 d2.evaluation.coco_evaluation]: Saving results to ./output/inference/coco_instances_results.json
[12/11 00:35:00 d2.evaluation.coco_evaluation]: Evaluating predictions with unofficial COCO API...
Loading and preparing results...
DONE (t=0.04s)
creating index...
index created!
[12/11 00:35:00 d2.evaluation.fast_eval_api]: Evaluate annotation type *bbox*
[12/11 00:35:08 d2.evaluation.fast_eval_api]: COCOeval_opt.evaluate() finished in 8.01 seconds.
[12/11 00:35:08 d2.evaluation.fast_eval_api]: Accumulating evaluation results...
[12/11 00:35:09 d2.evaluation.fast_eval_api]: COCOeval_opt.accumulate() finished in 0.65 seconds.
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.058
 Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.110
 Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.054
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.007
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.051
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.098
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.078
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.107
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.108
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.009
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.086
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.184
[12/11 00:35:09 d2.evaluation.coco_evaluation]: Evaluation results for bbox: 
|  AP   |  AP50  |  AP75  |  APs  |  APm  |  APl  |
|:-----:|:------:|:------:|:-----:|:-----:|:-----:|
| 5.795 | 11.048 | 5.375  | 0.679 | 5.121 | 9.775 |
[12/11 00:35:09 d2.evaluation.coco_evaluation]: Per-category bbox AP: 
| category      | AP     | category     | AP     | category       | AP     |
|:--------------|:-------|:-------------|:-------|:---------------|:-------|
| person        | 14.938 | bicycle      | 2.639  | car            | 6.564  |
| motorcycle    | 7.309  | airplane     | 16.079 | bus            | 30.161 |
| train         | 31.208 | truck        | 0.567  | boat           | 2.084  |
| traffic light | 3.296  | fire hydrant | 16.901 | stop sign      | 29.820 |
| parking meter | 0.000  | bench        | 1.916  | bird           | 3.135  |
| cat           | 11.092 | dog          | 12.838 | horse          | 9.713  |
| sheep         | 7.721  | cow          | 5.292  | elephant       | 18.377 |
| bear          | 17.211 | zebra        | 27.132 | giraffe        | 26.788 |
| backpack      | 0.000  | umbrella     | 5.215  | handbag        | 0.000  |
| tie           | 0.000  | suitcase     | 2.643  | frisbee        | 7.831  |
| skis          | 1.573  | snowboard    | 0.792  | sports ball    | 2.826  |
| kite          | 6.021  | baseball bat | 0.198  | baseball glove | 2.924  |
| skateboard    | 3.514  | surfboard    | 2.626  | tennis racket  | 6.821  |
| bottle        | 1.501  | wine glass   | 0.000  | cup            | 1.545  |
| fork          | 0.000  | knife        | 0.025  | spoon          | 0.000  |
| bowl          | 1.823  | banana       | 1.344  | apple          | 1.178  |
| sandwich      | 0.218  | orange       | 1.457  | broccoli       | 1.300  |
| carrot        | 0.445  | hot dog      | 0.000  | pizza          | 5.255  |
| donut         | 2.090  | cake         | 0.211  | chair          | 1.818  |
| couch         | 7.361  | potted plant | 0.958  | bed            | 13.418 |
| dining table  | 1.970  | toilet       | 20.063 | tv             | 15.109 |
| laptop        | 9.393  | mouse        | 3.192  | remote         | 0.387  |
| keyboard      | 2.771  | cell phone   | 1.368  | microwave      | 0.000  |
| oven          | 1.570  | toaster      | 0.000  | sink           | 4.762  |
| refrigerator  | 4.731  | book         | 0.583  | clock          | 6.749  |
| vase          | 0.467  | scissors     | 0.000  | teddy bear     | 2.767  |
| hair drier    | 0.000  | toothbrush   | 0.000  |                |        |
Loading and preparing results...
DONE (t=0.45s)
creating index...
index created!
[12/11 00:35:10 d2.evaluation.fast_eval_api]: Evaluate annotation type *segm*
[12/11 00:35:19 d2.evaluation.fast_eval_api]: COCOeval_opt.evaluate() finished in 9.22 seconds.
[12/11 00:35:19 d2.evaluation.fast_eval_api]: Accumulating evaluation results...
[12/11 00:35:20 d2.evaluation.fast_eval_api]: COCOeval_opt.accumulate() finished in 0.73 seconds.
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.060
 Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.118
 Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.055
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.003
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.051
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.127
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.077
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.101
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.102
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.006
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.085
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.178
[12/11 00:35:23 d2.evaluation.coco_evaluation]: Evaluation results for segm: 
|  AP   |  AP50  |  AP75  |  APs  |  APm  |  APl   |
|:-----:|:------:|:------:|:-----:|:-----:|:------:|
| 6.044 | 11.780 | 5.517  | 0.350 | 5.106 | 12.689 |
[12/11 00:35:23 d2.evaluation.coco_evaluation]: Per-category segm AP: 
| category      | AP     | category     | AP     | category       | AP     |
|:--------------|:-------|:-------------|:-------|:---------------|:-------|
| person        | 10.373 | bicycle      | 1.902  | car            | 6.663  |
| motorcycle    | 4.786  | airplane     | 14.733 | bus            | 29.713 |
| train         | 34.581 | truck        | 0.493  | boat           | 1.638  |
| traffic light | 3.344  | fire hydrant | 22.437 | stop sign      | 32.712 |
| parking meter | 0.000  | bench        | 1.348  | bird           | 2.150  |
| cat           | 15.717 | dog          | 13.455 | horse          | 7.037  |
| sheep         | 6.731  | cow          | 4.495  | elephant       | 18.628 |
| bear          | 20.377 | zebra        | 16.850 | giraffe        | 19.401 |
| backpack      | 0.000  | umbrella     | 8.041  | handbag        | 0.000  |
| tie           | 0.000  | suitcase     | 3.251  | frisbee        | 7.201  |
| skis          | 0.058  | snowboard    | 0.792  | sports ball    | 2.820  |
| kite          | 2.695  | baseball bat | 0.184  | baseball glove | 4.949  |
| skateboard    | 1.698  | surfboard    | 2.150  | tennis racket  | 15.225 |
| bottle        | 1.807  | wine glass   | 0.000  | cup            | 2.772  |
| fork          | 0.000  | knife        | 0.000  | spoon          | 0.000  |
| bowl          | 3.206  | banana       | 0.834  | apple          | 1.253  |
| sandwich      | 0.681  | orange       | 4.242  | broccoli       | 1.927  |
| carrot        | 0.517  | hot dog      | 0.000  | pizza          | 5.275  |
| donut         | 3.264  | cake         | 0.337  | chair          | 1.309  |
| couch         | 7.054  | potted plant | 1.766  | bed            | 10.625 |
| dining table  | 0.125  | toilet       | 26.517 | tv             | 20.657 |
| laptop        | 11.042 | mouse        | 4.124  | remote         | 0.266  |
| keyboard      | 4.198  | cell phone   | 2.476  | microwave      | 0.000  |
| oven          | 1.218  | toaster      | 0.000  | sink           | 6.551  |
| refrigerator  | 4.738  | book         | 0.307  | clock          | 9.579  |
| vase          | 1.249  | scissors     | 0.000  | teddy bear     | 4.968  |
| hair drier    | 0.000  | toothbrush   | 0.000  |                |        |
[12/11 00:35:28 d2.engine.defaults]: Evaluation results for coco_2017_val_panoptic in csv format:
[12/11 00:35:28 d2.evaluation.testing]: copypaste: Task: panoptic_seg
[12/11 00:35:28 d2.evaluation.testing]: copypaste: PQ,SQ,RQ,PQ_th,SQ_th,RQ_th,PQ_st,SQ_st,RQ_st
[12/11 00:35:28 d2.evaluation.testing]: copypaste: 16.0157,59.5632,20.9337,15.3494,60.8921,20.1359,17.0213,57.5572,22.1378
[12/11 00:35:28 d2.evaluation.testing]: copypaste: Task: bbox
[12/11 00:35:28 d2.evaluation.testing]: copypaste: AP,AP50,AP75,APs,APm,APl
[12/11 00:35:28 d2.evaluation.testing]: copypaste: 5.7950,11.0476,5.3754,0.6794,5.1212,9.7745
[12/11 00:35:28 d2.evaluation.testing]: copypaste: Task: segm
[12/11 00:35:28 d2.evaluation.testing]: copypaste: AP,AP50,AP75,APs,APm,APl
[12/11 00:35:28 d2.evaluation.testing]: copypaste: 6.0439,11.7796,5.5166,0.3495,5.1063,12.6892