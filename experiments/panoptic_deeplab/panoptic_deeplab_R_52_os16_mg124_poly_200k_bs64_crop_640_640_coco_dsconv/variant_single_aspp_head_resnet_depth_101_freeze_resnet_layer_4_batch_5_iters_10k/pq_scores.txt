env: DETECTRON2_DATASETS=/content/datasets
Command Line Args: Namespace(config_file='./detectron2/projects/Panoptic-DeepLab/configs/COCO-PanopticSegmentation/panoptic_deeplab_R_52_os16_mg124_poly_200k_bs64_crop_640_640_coco_dsconv.yaml', dist_url='tcp://127.0.0.1:49152', eval_only=False, machine_rank=0, num_gpus=1, num_machines=1, opts=['MODEL.RESNETS.NORM', 'BN', 'MODEL.INS_EMBED_HEAD.NORM', 'BN', 'MODEL.SEM_SEG_HEAD.NORM', 'BN', 'SOLVER.MAX_ITER', '10000', 'SOLVER.IMS_PER_BATCH', '5', 'SOLVER.BASE_LR', '0.0025', 'MODEL.BACKBONE.FREEZE_AT', '4', 'MODEL.RESNETS.DEPTH', '101', 'MODEL.WEIGHTS', 'detectron2://DeepLab/R-103.pkl', 'MODEL.BACKBONE.FREEZE_AT', '4', 'MODEL.SEM_SEG_HEAD.NAME', 'PanopticDeepLabASPPHead'], resume=False)
Loading config ./detectron2/projects/Panoptic-DeepLab/configs/COCO-PanopticSegmentation/panoptic_deeplab_R_52_os16_mg124_poly_200k_bs64_crop_640_640_coco_dsconv.yaml with yaml.unsafe_load. Your machine may be at risk if the file contains malicious content.
[12/11 21:11:41 detectron2]: Rank of current process: 0. World size: 1
[12/11 21:11:42 detectron2]: Environment info:
----------------------  ----------------------------------------------------------------
sys.platform            linux
Python                  3.7.12 (default, Jan 15 2022, 18:48:18) [GCC 7.5.0]
numpy                   1.21.5
detectron2              0.6 @/content/detectron2/detectron2
Compiler                GCC 7.5
CUDA compiler           CUDA 11.1
detectron2 arch flags   7.0
DETECTRON2_ENV_MODULE   <not set>
PyTorch                 1.10.0+cu111 @/usr/local/lib/python3.7/dist-packages/torch
PyTorch debug build     False
GPU available           Yes
GPU 0                   Tesla V100-SXM2-16GB (arch=7.0)
Driver version          460.32.03
CUDA_HOME               /usr/local/cuda
Pillow                  7.1.2
torchvision             0.11.1+cu111 @/usr/local/lib/python3.7/dist-packages/torchvision
torchvision arch flags  3.5, 5.0, 6.0, 7.0, 7.5, 8.0, 8.6
fvcore                  0.1.5.post20221122
iopath                  0.1.9
cv2                     4.1.2
----------------------  ----------------------------------------------------------------
PyTorch built with:
  - GCC 7.3
  - C++ Version: 201402
  - Intel(R) Math Kernel Library Version 2020.0.0 Product Build 20191122 for Intel(R) 64 architecture applications
  - Intel(R) MKL-DNN v2.2.3 (Git Hash 7336ca9f055cf1bfa13efb658fe15dc9b41f0740)
  - OpenMP 201511 (a.k.a. OpenMP 4.5)
  - LAPACK is enabled (usually provided by MKL)
  - NNPACK is enabled
  - CPU capability usage: AVX2
  - CUDA Runtime 11.1
  - NVCC architecture flags: -gencode;arch=compute_37,code=sm_37;-gencode;arch=compute_50,code=sm_50;-gencode;arch=compute_60,code=sm_60;-gencode;arch=compute_70,code=sm_70;-gencode;arch=compute_75,code=sm_75;-gencode;arch=compute_80,code=sm_80;-gencode;arch=compute_86,code=sm_86
  - CuDNN 8.0.5
  - Magma 2.5.2
  - Build settings: BLAS_INFO=mkl, BUILD_TYPE=Release, CUDA_VERSION=11.1, CUDNN_VERSION=8.0.5, CXX_COMPILER=/opt/rh/devtoolset-7/root/usr/bin/c++, CXX_FLAGS= -Wno-deprecated -fvisibility-inlines-hidden -DUSE_PTHREADPOOL -fopenmp -DNDEBUG -DUSE_KINETO -DUSE_FBGEMM -DUSE_QNNPACK -DUSE_PYTORCH_QNNPACK -DUSE_XNNPACK -DSYMBOLICATE_MOBILE_DEBUG_HANDLE -DEDGE_PROFILER_USE_KINETO -O2 -fPIC -Wno-narrowing -Wall -Wextra -Werror=return-type -Wno-missing-field-initializers -Wno-type-limits -Wno-array-bounds -Wno-unknown-pragmas -Wno-sign-compare -Wno-unused-parameter -Wno-unused-variable -Wno-unused-function -Wno-unused-result -Wno-unused-local-typedefs -Wno-strict-overflow -Wno-strict-aliasing -Wno-error=deprecated-declarations -Wno-stringop-overflow -Wno-psabi -Wno-error=pedantic -Wno-error=redundant-decls -Wno-error=old-style-cast -fdiagnostics-color=always -faligned-new -Wno-unused-but-set-variable -Wno-maybe-uninitialized -fno-math-errno -fno-trapping-math -Werror=format -Wno-stringop-overflow, LAPACK_INFO=mkl, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, TORCH_VERSION=1.10.0, USE_CUDA=ON, USE_CUDNN=ON, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_MKL=ON, USE_MKLDNN=ON, USE_MPI=OFF, USE_NCCL=ON, USE_NNPACK=ON, USE_OPENMP=ON, 

[12/11 21:11:42 detectron2]: Command line arguments: Namespace(config_file='./detectron2/projects/Panoptic-DeepLab/configs/COCO-PanopticSegmentation/panoptic_deeplab_R_52_os16_mg124_poly_200k_bs64_crop_640_640_coco_dsconv.yaml', dist_url='tcp://127.0.0.1:49152', eval_only=False, machine_rank=0, num_gpus=1, num_machines=1, opts=['MODEL.RESNETS.NORM', 'BN', 'MODEL.INS_EMBED_HEAD.NORM', 'BN', 'MODEL.SEM_SEG_HEAD.NORM', 'BN', 'SOLVER.MAX_ITER', '10000', 'SOLVER.IMS_PER_BATCH', '5', 'SOLVER.BASE_LR', '0.0025', 'MODEL.BACKBONE.FREEZE_AT', '4', 'MODEL.RESNETS.DEPTH', '101', 'MODEL.WEIGHTS', 'detectron2://DeepLab/R-103.pkl', 'MODEL.BACKBONE.FREEZE_AT', '4', 'MODEL.SEM_SEG_HEAD.NAME', 'PanopticDeepLabASPPHead'], resume=False)
[12/11 21:11:42 detectron2]: Contents of args.config_file=./detectron2/projects/Panoptic-DeepLab/configs/COCO-PanopticSegmentation/panoptic_deeplab_R_52_os16_mg124_poly_200k_bs64_crop_640_640_coco_dsconv.yaml:
_BASE_: ../Cityscapes-PanopticSegmentation/Base-PanopticDeepLab-OS16.yaml
MODEL:
  WEIGHTS: "detectron2://DeepLab/R-52.pkl"
  PIXEL_MEAN: [123.675, 116.280, 103.530]
  PIXEL_STD: [58.395, 57.120, 57.375]
  BACKBONE:
    NAME: "build_resnet_deeplab_backbone"
  RESNETS:
    DEPTH: 50
    NORM: "SyncBN"
    RES5_MULTI_GRID: [1, 2, 4]
    STEM_TYPE: "deeplab"
    STEM_OUT_CHANNELS: 128
    STRIDE_IN_1X1: False
  SEM_SEG_HEAD:
    NUM_CLASSES: 133
    LOSS_TOP_K: 1.0
    USE_DEPTHWISE_SEPARABLE_CONV: True
  PANOPTIC_DEEPLAB:
    STUFF_AREA: 4096
    NMS_KERNEL: 41
    SIZE_DIVISIBILITY: 640
    USE_DEPTHWISE_SEPARABLE_CONV: True
DATASETS:
  TRAIN: ("coco_2017_train_panoptic",)
  TEST: ("coco_2017_val_panoptic",)
SOLVER:
  BASE_LR: 0.0005
  MAX_ITER: 200000
  IMS_PER_BATCH: 64
INPUT:
  FORMAT: "RGB"
  GAUSSIAN_SIGMA: 8
  MIN_SIZE_TRAIN: !!python/object/apply:eval ["[int(x * 0.1 * 640) for x in range(5, 16)]"]
  MIN_SIZE_TRAIN_SAMPLING: "choice"
  MIN_SIZE_TEST: 640
  MAX_SIZE_TRAIN: 960
  MAX_SIZE_TEST: 640
  CROP:
    ENABLED: True
    TYPE: "absolute"
    SIZE: (640, 640)

[12/11 21:11:42 detectron2]: Running with full config:
CUDNN_BENCHMARK: false
DATALOADER:
  ASPECT_RATIO_GROUPING: true
  FILTER_EMPTY_ANNOTATIONS: true
  NUM_WORKERS: 10
  REPEAT_THRESHOLD: 0.0
  SAMPLER_TRAIN: TrainingSampler
DATASETS:
  PRECOMPUTED_PROPOSAL_TOPK_TEST: 1000
  PRECOMPUTED_PROPOSAL_TOPK_TRAIN: 2000
  PROPOSAL_FILES_TEST: []
  PROPOSAL_FILES_TRAIN: []
  TEST:
  - coco_2017_val_panoptic
  TRAIN:
  - coco_2017_train_panoptic
GLOBAL:
  HACK: 1.0
INPUT:
  CROP:
    ENABLED: true
    SINGLE_CATEGORY_MAX_AREA: 1.0
    SIZE:
    - 640
    - 640
    TYPE: absolute
  FORMAT: RGB
  GAUSSIAN_SIGMA: 8
  IGNORE_CROWD_IN_SEMANTIC: false
  IGNORE_STUFF_IN_OFFSET: true
  MASK_FORMAT: polygon
  MAX_SIZE_TEST: 640
  MAX_SIZE_TRAIN: 960
  MIN_SIZE_TEST: 640
  MIN_SIZE_TRAIN:
  - 320
  - 384
  - 448
  - 512
  - 576
  - 640
  - 704
  - 768
  - 832
  - 896
  - 960
  MIN_SIZE_TRAIN_SAMPLING: choice
  RANDOM_FLIP: horizontal
  SMALL_INSTANCE_AREA: 4096
  SMALL_INSTANCE_WEIGHT: 3
MODEL:
  ANCHOR_GENERATOR:
    ANGLES:
    - - -90
      - 0
      - 90
    ASPECT_RATIOS:
    - - 0.5
      - 1.0
      - 2.0
    NAME: DefaultAnchorGenerator
    OFFSET: 0.0
    SIZES:
    - - 32
      - 64
      - 128
      - 256
      - 512
  BACKBONE:
    FREEZE_AT: 4
    NAME: build_resnet_deeplab_backbone
  DEVICE: cuda
  FPN:
    FUSE_TYPE: sum
    IN_FEATURES: []
    NORM: ''
    OUT_CHANNELS: 256
  INS_EMBED_HEAD:
    ASPP_CHANNELS: 256
    ASPP_DILATIONS:
    - 6
    - 12
    - 18
    ASPP_DROPOUT: 0.1
    CENTER_LOSS_WEIGHT: 200.0
    COMMON_STRIDE: 4
    CONVS_DIM: 128
    HEAD_CHANNELS: 32
    IN_FEATURES:
    - res2
    - res3
    - res5
    NAME: PanopticDeepLabInsEmbedHead
    NORM: BN
    OFFSET_LOSS_WEIGHT: 0.01
    PROJECT_CHANNELS:
    - 32
    - 64
    PROJECT_FEATURES:
    - res2
    - res3
  KEYPOINT_ON: false
  LOAD_PROPOSALS: false
  MASK_ON: false
  META_ARCHITECTURE: PanopticDeepLab
  PANOPTIC_DEEPLAB:
    BENCHMARK_NETWORK_SPEED: false
    CENTER_THRESHOLD: 0.1
    NMS_KERNEL: 41
    PREDICT_INSTANCES: true
    SIZE_DIVISIBILITY: 640
    STUFF_AREA: 4096
    TOP_K_INSTANCE: 200
    USE_DEPTHWISE_SEPARABLE_CONV: true
  PANOPTIC_FPN:
    COMBINE:
      ENABLED: true
      INSTANCES_CONFIDENCE_THRESH: 0.5
      OVERLAP_THRESH: 0.5
      STUFF_AREA_LIMIT: 4096
    INSTANCE_LOSS_WEIGHT: 1.0
  PIXEL_MEAN:
  - 123.675
  - 116.28
  - 103.53
  PIXEL_STD:
  - 58.395
  - 57.12
  - 57.375
  PROPOSAL_GENERATOR:
    MIN_SIZE: 0
    NAME: RPN
  RESNETS:
    DEFORM_MODULATED: false
    DEFORM_NUM_GROUPS: 1
    DEFORM_ON_PER_STAGE:
    - false
    - false
    - false
    - false
    DEPTH: 101
    NORM: BN
    NUM_GROUPS: 1
    OUT_FEATURES:
    - res2
    - res3
    - res5
    RES2_OUT_CHANNELS: 256
    RES4_DILATION: 1
    RES5_DILATION: 2
    RES5_MULTI_GRID:
    - 1
    - 2
    - 4
    STEM_OUT_CHANNELS: 128
    STEM_TYPE: deeplab
    STRIDE_IN_1X1: false
    WIDTH_PER_GROUP: 64
  RETINANET:
    BBOX_REG_LOSS_TYPE: smooth_l1
    BBOX_REG_WEIGHTS: &id001
    - 1.0
    - 1.0
    - 1.0
    - 1.0
    FOCAL_LOSS_ALPHA: 0.25
    FOCAL_LOSS_GAMMA: 2.0
    IN_FEATURES:
    - p3
    - p4
    - p5
    - p6
    - p7
    IOU_LABELS:
    - 0
    - -1
    - 1
    IOU_THRESHOLDS:
    - 0.4
    - 0.5
    NMS_THRESH_TEST: 0.5
    NORM: ''
    NUM_CLASSES: 80
    NUM_CONVS: 4
    PRIOR_PROB: 0.01
    SCORE_THRESH_TEST: 0.05
    SMOOTH_L1_LOSS_BETA: 0.1
    TOPK_CANDIDATES_TEST: 1000
  ROI_BOX_CASCADE_HEAD:
    BBOX_REG_WEIGHTS:
    - - 10.0
      - 10.0
      - 5.0
      - 5.0
    - - 20.0
      - 20.0
      - 10.0
      - 10.0
    - - 30.0
      - 30.0
      - 15.0
      - 15.0
    IOUS:
    - 0.5
    - 0.6
    - 0.7
  ROI_BOX_HEAD:
    BBOX_REG_LOSS_TYPE: smooth_l1
    BBOX_REG_LOSS_WEIGHT: 1.0
    BBOX_REG_WEIGHTS:
    - 10.0
    - 10.0
    - 5.0
    - 5.0
    CLS_AGNOSTIC_BBOX_REG: false
    CONV_DIM: 256
    FC_DIM: 1024
    FED_LOSS_FREQ_WEIGHT_POWER: 0.5
    FED_LOSS_NUM_CLASSES: 50
    NAME: ''
    NORM: ''
    NUM_CONV: 0
    NUM_FC: 0
    POOLER_RESOLUTION: 14
    POOLER_SAMPLING_RATIO: 0
    POOLER_TYPE: ROIAlignV2
    SMOOTH_L1_BETA: 0.0
    TRAIN_ON_PRED_BOXES: false
    USE_FED_LOSS: false
    USE_SIGMOID_CE: false
  ROI_HEADS:
    BATCH_SIZE_PER_IMAGE: 512
    IN_FEATURES:
    - res4
    IOU_LABELS:
    - 0
    - 1
    IOU_THRESHOLDS:
    - 0.5
    NAME: Res5ROIHeads
    NMS_THRESH_TEST: 0.5
    NUM_CLASSES: 80
    POSITIVE_FRACTION: 0.25
    PROPOSAL_APPEND_GT: true
    SCORE_THRESH_TEST: 0.05
  ROI_KEYPOINT_HEAD:
    CONV_DIMS:
    - 512
    - 512
    - 512
    - 512
    - 512
    - 512
    - 512
    - 512
    LOSS_WEIGHT: 1.0
    MIN_KEYPOINTS_PER_IMAGE: 1
    NAME: KRCNNConvDeconvUpsampleHead
    NORMALIZE_LOSS_BY_VISIBLE_KEYPOINTS: true
    NUM_KEYPOINTS: 17
    POOLER_RESOLUTION: 14
    POOLER_SAMPLING_RATIO: 0
    POOLER_TYPE: ROIAlignV2
  ROI_MASK_HEAD:
    CLS_AGNOSTIC_MASK: false
    CONV_DIM: 256
    NAME: MaskRCNNConvUpsampleHead
    NORM: ''
    NUM_CONV: 0
    POOLER_RESOLUTION: 14
    POOLER_SAMPLING_RATIO: 0
    POOLER_TYPE: ROIAlignV2
  RPN:
    BATCH_SIZE_PER_IMAGE: 256
    BBOX_REG_LOSS_TYPE: smooth_l1
    BBOX_REG_LOSS_WEIGHT: 1.0
    BBOX_REG_WEIGHTS: *id001
    BOUNDARY_THRESH: -1
    CONV_DIMS:
    - -1
    HEAD_NAME: StandardRPNHead
    IN_FEATURES:
    - res4
    IOU_LABELS:
    - 0
    - -1
    - 1
    IOU_THRESHOLDS:
    - 0.3
    - 0.7
    LOSS_WEIGHT: 1.0
    NMS_THRESH: 0.7
    POSITIVE_FRACTION: 0.5
    POST_NMS_TOPK_TEST: 1000
    POST_NMS_TOPK_TRAIN: 2000
    PRE_NMS_TOPK_TEST: 6000
    PRE_NMS_TOPK_TRAIN: 12000
    SMOOTH_L1_BETA: 0.0
  SEM_SEG_HEAD:
    ASPP_CHANNELS: 256
    ASPP_DILATIONS:
    - 6
    - 12
    - 18
    ASPP_DROPOUT: 0.1
    COMMON_STRIDE: 4
    CONVS_DIM: 256
    HEAD_CHANNELS: 256
    IGNORE_VALUE: 255
    IN_FEATURES:
    - res2
    - res3
    - res5
    LOSS_TOP_K: 1.0
    LOSS_TYPE: hard_pixel_mining
    LOSS_WEIGHT: 1.0
    NAME: PanopticDeepLabASPPHead
    NORM: BN
    NUM_CLASSES: 133
    PROJECT_CHANNELS:
    - 32
    - 64
    PROJECT_FEATURES:
    - res2
    - res3
    USE_DEPTHWISE_SEPARABLE_CONV: true
  WEIGHTS: detectron2://DeepLab/R-103.pkl
OUTPUT_DIR: ./output
SEED: -1
SOLVER:
  AMP:
    ENABLED: false
  BASE_LR: 0.0025
  BASE_LR_END: 0.0
  BIAS_LR_FACTOR: 1.0
  CHECKPOINT_PERIOD: 5000
  CLIP_GRADIENTS:
    CLIP_TYPE: value
    CLIP_VALUE: 1.0
    ENABLED: false
    NORM_TYPE: 2.0
  GAMMA: 0.1
  IMS_PER_BATCH: 5
  LR_SCHEDULER_NAME: WarmupPolyLR
  MAX_ITER: 10000
  MOMENTUM: 0.9
  NESTEROV: false
  NUM_DECAYS: 3
  OPTIMIZER: ADAM
  POLY_LR_CONSTANT_ENDING: 0.0
  POLY_LR_POWER: 0.9
  REFERENCE_WORLD_SIZE: 0
  RESCALE_INTERVAL: false
  STEPS:
  - 30000
  WARMUP_FACTOR: 0.001
  WARMUP_ITERS: 1000
  WARMUP_METHOD: linear
  WEIGHT_DECAY: 0.0
  WEIGHT_DECAY_BIAS: 0.0
  WEIGHT_DECAY_NORM: 0.0
TEST:
  AUG:
    ENABLED: false
    FLIP: true
    MAX_SIZE: 4000
    MIN_SIZES:
    - 400
    - 500
    - 600
    - 700
    - 800
    - 900
    - 1000
    - 1100
    - 1200
  DETECTIONS_PER_IMAGE: 100
  EVAL_PERIOD: 0
  EXPECTED_RESULTS: []
  KEYPOINT_OKS_SIGMAS: []
  PRECISE_BN:
    ENABLED: false
    NUM_ITER: 200
VERSION: 2
VIS_PERIOD: 0

[12/11 21:11:42 detectron2]: Full config saved to ./output/config.yaml
[12/11 21:11:42 d2.utils.env]: Using a generated random seed 42906514
[12/11 21:11:48 d2.engine.defaults]: Model:
PanopticDeepLab(
  (backbone): ResNet(
    (stem): DeepLabStem(
      (conv1): Conv2d(
        3, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False
        (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
      )
      (conv2): Conv2d(
        64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
        (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
      )
      (conv3): Conv2d(
        64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
        (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
      )
    )
    (res2): Sequential(
      (0): BottleneckBlock(
        (shortcut): Conv2d(
          128, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv1): Conv2d(
          128, 64, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
        )
        (conv2): Conv2d(
          64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
        )
        (conv3): Conv2d(
          64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
      )
      (1): BottleneckBlock(
        (conv1): Conv2d(
          256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
        )
        (conv2): Conv2d(
          64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
        )
        (conv3): Conv2d(
          64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
      )
      (2): BottleneckBlock(
        (conv1): Conv2d(
          256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
        )
        (conv2): Conv2d(
          64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
        )
        (conv3): Conv2d(
          64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
      )
    )
    (res3): Sequential(
      (0): BottleneckBlock(
        (shortcut): Conv2d(
          256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False
          (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
        )
        (conv1): Conv2d(
          256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
        )
        (conv2): Conv2d(
          128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
        )
        (conv3): Conv2d(
          128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
        )
      )
      (1): BottleneckBlock(
        (conv1): Conv2d(
          512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
        )
        (conv2): Conv2d(
          128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
        )
        (conv3): Conv2d(
          128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
        )
      )
      (2): BottleneckBlock(
        (conv1): Conv2d(
          512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
        )
        (conv2): Conv2d(
          128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
        )
        (conv3): Conv2d(
          128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
        )
      )
      (3): BottleneckBlock(
        (conv1): Conv2d(
          512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
        )
        (conv2): Conv2d(
          128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
        )
        (conv3): Conv2d(
          128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
        )
      )
    )
    (res4): Sequential(
      (0): BottleneckBlock(
        (shortcut): Conv2d(
          512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False
          (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
        )
        (conv1): Conv2d(
          512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv2): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv3): Conv2d(
          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
        )
      )
      (1): BottleneckBlock(
        (conv1): Conv2d(
          1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv2): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv3): Conv2d(
          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
        )
      )
      (2): BottleneckBlock(
        (conv1): Conv2d(
          1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv2): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv3): Conv2d(
          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
        )
      )
      (3): BottleneckBlock(
        (conv1): Conv2d(
          1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv2): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv3): Conv2d(
          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
        )
      )
      (4): BottleneckBlock(
        (conv1): Conv2d(
          1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv2): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv3): Conv2d(
          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
        )
      )
      (5): BottleneckBlock(
        (conv1): Conv2d(
          1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv2): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv3): Conv2d(
          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
        )
      )
      (6): BottleneckBlock(
        (conv1): Conv2d(
          1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv2): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv3): Conv2d(
          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
        )
      )
      (7): BottleneckBlock(
        (conv1): Conv2d(
          1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv2): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv3): Conv2d(
          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
        )
      )
      (8): BottleneckBlock(
        (conv1): Conv2d(
          1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv2): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv3): Conv2d(
          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
        )
      )
      (9): BottleneckBlock(
        (conv1): Conv2d(
          1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv2): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv3): Conv2d(
          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
        )
      )
      (10): BottleneckBlock(
        (conv1): Conv2d(
          1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv2): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv3): Conv2d(
          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
        )
      )
      (11): BottleneckBlock(
        (conv1): Conv2d(
          1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv2): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv3): Conv2d(
          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
        )
      )
      (12): BottleneckBlock(
        (conv1): Conv2d(
          1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv2): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv3): Conv2d(
          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
        )
      )
      (13): BottleneckBlock(
        (conv1): Conv2d(
          1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv2): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv3): Conv2d(
          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
        )
      )
      (14): BottleneckBlock(
        (conv1): Conv2d(
          1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv2): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv3): Conv2d(
          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
        )
      )
      (15): BottleneckBlock(
        (conv1): Conv2d(
          1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv2): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv3): Conv2d(
          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
        )
      )
      (16): BottleneckBlock(
        (conv1): Conv2d(
          1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv2): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv3): Conv2d(
          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
        )
      )
      (17): BottleneckBlock(
        (conv1): Conv2d(
          1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv2): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv3): Conv2d(
          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
        )
      )
      (18): BottleneckBlock(
        (conv1): Conv2d(
          1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv2): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv3): Conv2d(
          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
        )
      )
      (19): BottleneckBlock(
        (conv1): Conv2d(
          1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv2): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv3): Conv2d(
          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
        )
      )
      (20): BottleneckBlock(
        (conv1): Conv2d(
          1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv2): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv3): Conv2d(
          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
        )
      )
      (21): BottleneckBlock(
        (conv1): Conv2d(
          1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv2): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv3): Conv2d(
          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
        )
      )
      (22): BottleneckBlock(
        (conv1): Conv2d(
          1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv2): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv3): Conv2d(
          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
        )
      )
    )
    (res5): Sequential(
      (0): BottleneckBlock(
        (shortcut): Conv2d(
          1024, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv1): Conv2d(
          1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv2): Conv2d(
          512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2), dilation=(2, 2), bias=False
          (norm): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv3): Conv2d(
          512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (1): BottleneckBlock(
        (conv1): Conv2d(
          2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv2): Conv2d(
          512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(4, 4), dilation=(4, 4), bias=False
          (norm): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv3): Conv2d(
          512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (2): BottleneckBlock(
        (conv1): Conv2d(
          2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv2): Conv2d(
          512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(8, 8), dilation=(8, 8), bias=False
          (norm): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv3): Conv2d(
          512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
    )
  )
  (aspp_head): PanopticDeepLabASPPHead(
    (decoder): ModuleDict(
      (res2): ModuleDict(
        (project_conv): Conv2d(
          256, 32, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (fuse_conv): DepthwiseSeparableConv2d(
          (depthwise): Conv2d(
            288, 288, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=288, bias=False
            (norm): BatchNorm2d(288, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          )
          (pointwise): Conv2d(
            288, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
      )
      (res3): ModuleDict(
        (project_conv): Conv2d(
          512, 64, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (fuse_conv): DepthwiseSeparableConv2d(
          (depthwise): Conv2d(
            320, 320, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=320, bias=False
            (norm): BatchNorm2d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          )
          (pointwise): Conv2d(
            320, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
      )
      (res5): ModuleDict(
        (project_conv): ASPP(
          (convs): ModuleList(
            (0): Conv2d(
              2048, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
              (norm): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            )
            (1): DepthwiseSeparableConv2d(
              (depthwise): Conv2d(
                2048, 2048, kernel_size=(3, 3), stride=(1, 1), padding=(6, 6), dilation=(6, 6), groups=2048, bias=False
                (norm): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
              (pointwise): Conv2d(
                2048, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
            )
            (2): DepthwiseSeparableConv2d(
              (depthwise): Conv2d(
                2048, 2048, kernel_size=(3, 3), stride=(1, 1), padding=(12, 12), dilation=(12, 12), groups=2048, bias=False
                (norm): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
              (pointwise): Conv2d(
                2048, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
            )
            (3): DepthwiseSeparableConv2d(
              (depthwise): Conv2d(
                2048, 2048, kernel_size=(3, 3), stride=(1, 1), padding=(18, 18), dilation=(18, 18), groups=2048, bias=False
                (norm): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
              (pointwise): Conv2d(
                2048, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
            )
            (4): Sequential(
              (0): AvgPool2d(kernel_size=(40, 40), stride=1, padding=0)
              (1): Conv2d(2048, 256, kernel_size=(1, 1), stride=(1, 1))
            )
          )
          (project): Conv2d(
            1280, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (fuse_conv): None
      )
    )
    (loss): DeepLabCE(
      (criterion): CrossEntropyLoss()
    )
  )
  (sem_seg_head): PanopticDeepLabSemSegHead(
    (aspp_head): PanopticDeepLabASPPHead(
      (decoder): ModuleDict(
        (res2): ModuleDict(
          (project_conv): Conv2d(
            256, 32, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          )
          (fuse_conv): DepthwiseSeparableConv2d(
            (depthwise): Conv2d(
              288, 288, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=288, bias=False
              (norm): BatchNorm2d(288, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            )
            (pointwise): Conv2d(
              288, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
              (norm): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            )
          )
        )
        (res3): ModuleDict(
          (project_conv): Conv2d(
            512, 64, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          )
          (fuse_conv): DepthwiseSeparableConv2d(
            (depthwise): Conv2d(
              320, 320, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=320, bias=False
              (norm): BatchNorm2d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            )
            (pointwise): Conv2d(
              320, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
              (norm): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            )
          )
        )
        (res5): ModuleDict(
          (project_conv): ASPP(
            (convs): ModuleList(
              (0): Conv2d(
                2048, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
              (1): DepthwiseSeparableConv2d(
                (depthwise): Conv2d(
                  2048, 2048, kernel_size=(3, 3), stride=(1, 1), padding=(6, 6), dilation=(6, 6), groups=2048, bias=False
                  (norm): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                )
                (pointwise): Conv2d(
                  2048, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
                  (norm): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                )
              )
              (2): DepthwiseSeparableConv2d(
                (depthwise): Conv2d(
                  2048, 2048, kernel_size=(3, 3), stride=(1, 1), padding=(12, 12), dilation=(12, 12), groups=2048, bias=False
                  (norm): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                )
                (pointwise): Conv2d(
                  2048, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
                  (norm): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                )
              )
              (3): DepthwiseSeparableConv2d(
                (depthwise): Conv2d(
                  2048, 2048, kernel_size=(3, 3), stride=(1, 1), padding=(18, 18), dilation=(18, 18), groups=2048, bias=False
                  (norm): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                )
                (pointwise): Conv2d(
                  2048, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
                  (norm): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                )
              )
              (4): Sequential(
                (0): AvgPool2d(kernel_size=(40, 40), stride=1, padding=0)
                (1): Conv2d(2048, 256, kernel_size=(1, 1), stride=(1, 1))
              )
            )
            (project): Conv2d(
              1280, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
              (norm): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            )
          )
          (fuse_conv): None
        )
      )
      (loss): DeepLabCE(
        (criterion): CrossEntropyLoss()
      )
    )
    (head): DepthwiseSeparableConv2d(
      (depthwise): Conv2d(
        256, 256, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=256, bias=False
        (norm): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (pointwise): Conv2d(
        256, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
        (norm): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (predictor): Conv2d(256, 133, kernel_size=(1, 1), stride=(1, 1))
    (loss): DeepLabCE(
      (criterion): CrossEntropyLoss()
    )
  )
  (ins_embed_head): PanopticDeepLabInsEmbedHead(
    (aspp_head): PanopticDeepLabASPPHead(
      (decoder): ModuleDict(
        (res2): ModuleDict(
          (project_conv): Conv2d(
            256, 32, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          )
          (fuse_conv): DepthwiseSeparableConv2d(
            (depthwise): Conv2d(
              288, 288, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=288, bias=False
              (norm): BatchNorm2d(288, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            )
            (pointwise): Conv2d(
              288, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
              (norm): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            )
          )
        )
        (res3): ModuleDict(
          (project_conv): Conv2d(
            512, 64, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          )
          (fuse_conv): DepthwiseSeparableConv2d(
            (depthwise): Conv2d(
              320, 320, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=320, bias=False
              (norm): BatchNorm2d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            )
            (pointwise): Conv2d(
              320, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
              (norm): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            )
          )
        )
        (res5): ModuleDict(
          (project_conv): ASPP(
            (convs): ModuleList(
              (0): Conv2d(
                2048, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
              (1): DepthwiseSeparableConv2d(
                (depthwise): Conv2d(
                  2048, 2048, kernel_size=(3, 3), stride=(1, 1), padding=(6, 6), dilation=(6, 6), groups=2048, bias=False
                  (norm): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                )
                (pointwise): Conv2d(
                  2048, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
                  (norm): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                )
              )
              (2): DepthwiseSeparableConv2d(
                (depthwise): Conv2d(
                  2048, 2048, kernel_size=(3, 3), stride=(1, 1), padding=(12, 12), dilation=(12, 12), groups=2048, bias=False
                  (norm): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                )
                (pointwise): Conv2d(
                  2048, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
                  (norm): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                )
              )
              (3): DepthwiseSeparableConv2d(
                (depthwise): Conv2d(
                  2048, 2048, kernel_size=(3, 3), stride=(1, 1), padding=(18, 18), dilation=(18, 18), groups=2048, bias=False
                  (norm): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                )
                (pointwise): Conv2d(
                  2048, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
                  (norm): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                )
              )
              (4): Sequential(
                (0): AvgPool2d(kernel_size=(40, 40), stride=1, padding=0)
                (1): Conv2d(2048, 256, kernel_size=(1, 1), stride=(1, 1))
              )
            )
            (project): Conv2d(
              1280, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
              (norm): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            )
          )
          (fuse_conv): None
        )
      )
      (loss): DeepLabCE(
        (criterion): CrossEntropyLoss()
      )
    )
    (center_head): Sequential(
      (0): Conv2d(
        256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
        (norm): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (1): Conv2d(
        256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
        (norm): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (center_predictor): Conv2d(256, 1, kernel_size=(1, 1), stride=(1, 1))
    (offset_head): DepthwiseSeparableConv2d(
      (depthwise): Conv2d(
        256, 256, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=256, bias=False
        (norm): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (pointwise): Conv2d(
        256, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
        (norm): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (offset_predictor): Conv2d(256, 2, kernel_size=(1, 1), stride=(1, 1))
    (center_loss): MSELoss()
    (offset_loss): L1Loss()
  )
)
[12/11 21:11:48 d2.projects.panoptic_deeplab.dataset_mapper]: Augmentations used in training: [ResizeShortestEdge(short_edge_length=(320, 384, 448, 512, 576, 640, 704, 768, 832, 896, 960), max_size=960, sample_style='choice'), RandomCrop(crop_type='absolute', crop_size=[640, 640]), RandomFlip()]
[12/11 21:11:57 d2.data.build]: Using training sampler TrainingSampler
[12/11 21:11:57 d2.data.common]: Serializing the dataset using: <class 'detectron2.data.common.NumpySerializedList'>
[12/11 21:11:57 d2.data.common]: Serializing 118287 elements to byte tensors and concatenating them all ...
[12/11 21:11:58 d2.data.common]: Serialized dataset takes 80.32 MiB
/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:481: UserWarning: This DataLoader will create 10 worker processes in total. Our suggested max number of worker in current system is 8, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.
  cpuset_checked))
[12/11 21:12:02 fvcore.common.checkpoint]: [Checkpointer] Loading from detectron2://DeepLab/R-103.pkl ...
[12/11 21:12:03 fvcore.common.checkpoint]: Reading a file from 'torchvision'
[12/11 21:12:03 d2.checkpoint.c2_model_loading]: Following weights matched with submodule backbone:
| Names in Model    | Names in Checkpoint                                                                                        | Shapes                                             |
|:------------------|:-----------------------------------------------------------------------------------------------------------|:---------------------------------------------------|
| res2.0.conv1.*    | res2.0.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}                             | (64,) (64,) (64,) (64,) (64,128,1,1)               |
| res2.0.conv2.*    | res2.0.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}                             | (64,) (64,) (64,) (64,) (64,64,3,3)                |
| res2.0.conv3.*    | res2.0.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}                             | (256,) (256,) (256,) (256,) (256,64,1,1)           |
| res2.0.shortcut.* | res2.0.shortcut.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}                          | (256,) (256,) (256,) (256,) (256,128,1,1)          |
| res2.1.conv1.*    | res2.1.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}                             | (64,) (64,) (64,) (64,) (64,256,1,1)               |
| res2.1.conv2.*    | res2.1.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}                             | (64,) (64,) (64,) (64,) (64,64,3,3)                |
| res2.1.conv3.*    | res2.1.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}                             | (256,) (256,) (256,) (256,) (256,64,1,1)           |
| res2.2.conv1.*    | res2.2.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}                             | (64,) (64,) (64,) (64,) (64,256,1,1)               |
| res2.2.conv2.*    | res2.2.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}                             | (64,) (64,) (64,) (64,) (64,64,3,3)                |
| res2.2.conv3.*    | res2.2.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}                             | (256,) (256,) (256,) (256,) (256,64,1,1)           |
| res3.0.conv1.*    | res3.0.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}                             | (128,) (128,) (128,) (128,) (128,256,1,1)          |
| res3.0.conv2.*    | res3.0.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}                             | (128,) (128,) (128,) (128,) (128,128,3,3)          |
| res3.0.conv3.*    | res3.0.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}                             | (512,) (512,) (512,) (512,) (512,128,1,1)          |
| res3.0.shortcut.* | res3.0.shortcut.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}                          | (512,) (512,) (512,) (512,) (512,256,1,1)          |
| res3.1.conv1.*    | res3.1.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}                             | (128,) (128,) (128,) (128,) (128,512,1,1)          |
| res3.1.conv2.*    | res3.1.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}                             | (128,) (128,) (128,) (128,) (128,128,3,3)          |
| res3.1.conv3.*    | res3.1.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}                             | (512,) (512,) (512,) (512,) (512,128,1,1)          |
| res3.2.conv1.*    | res3.2.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}                             | (128,) (128,) (128,) (128,) (128,512,1,1)          |
| res3.2.conv2.*    | res3.2.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}                             | (128,) (128,) (128,) (128,) (128,128,3,3)          |
| res3.2.conv3.*    | res3.2.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}                             | (512,) (512,) (512,) (512,) (512,128,1,1)          |
| res3.3.conv1.*    | res3.3.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}                             | (128,) (128,) (128,) (128,) (128,512,1,1)          |
| res3.3.conv2.*    | res3.3.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}                             | (128,) (128,) (128,) (128,) (128,128,3,3)          |
| res3.3.conv3.*    | res3.3.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}                             | (512,) (512,) (512,) (512,) (512,128,1,1)          |
| res4.0.conv1.*    | res4.0.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}                             | (256,) (256,) (256,) (256,) (256,512,1,1)          |
| res4.0.conv2.*    | res4.0.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}                             | (256,) (256,) (256,) (256,) (256,256,3,3)          |
| res4.0.conv3.*    | res4.0.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}                             | (1024,) (1024,) (1024,) (1024,) (1024,256,1,1)     |
| res4.0.shortcut.* | res4.0.shortcut.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}                          | (1024,) (1024,) (1024,) (1024,) (1024,512,1,1)     |
| res4.1.conv1.*    | res4.1.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}                             | (256,) (256,) (256,) (256,) (256,1024,1,1)         |
| res4.1.conv2.*    | res4.1.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}                             | (256,) (256,) (256,) (256,) (256,256,3,3)          |
| res4.1.conv3.*    | res4.1.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}                             | (1024,) (1024,) (1024,) (1024,) (1024,256,1,1)     |
| res4.10.conv1.*   | res4.10.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}                            | (256,) (256,) (256,) (256,) (256,1024,1,1)         |
| res4.10.conv2.*   | res4.10.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}                            | (256,) (256,) (256,) (256,) (256,256,3,3)          |
| res4.10.conv3.*   | res4.10.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}                            | (1024,) (1024,) (1024,) (1024,) (1024,256,1,1)     |
| res4.11.conv1.*   | res4.11.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}                            | (256,) (256,) (256,) (256,) (256,1024,1,1)         |
| res4.11.conv2.*   | res4.11.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}                            | (256,) (256,) (256,) (256,) (256,256,3,3)          |
| res4.11.conv3.*   | res4.11.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}                            | (1024,) (1024,) (1024,) (1024,) (1024,256,1,1)     |
| res4.12.conv1.*   | res4.12.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}                            | (256,) (256,) (256,) (256,) (256,1024,1,1)         |
| res4.12.conv2.*   | res4.12.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}                            | (256,) (256,) (256,) (256,) (256,256,3,3)          |
| res4.12.conv3.*   | res4.12.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}                            | (1024,) (1024,) (1024,) (1024,) (1024,256,1,1)     |
| res4.13.conv1.*   | res4.13.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}                            | (256,) (256,) (256,) (256,) (256,1024,1,1)         |
| res4.13.conv2.*   | res4.13.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}                            | (256,) (256,) (256,) (256,) (256,256,3,3)          |
| res4.13.conv3.*   | res4.13.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}                            | (1024,) (1024,) (1024,) (1024,) (1024,256,1,1)     |
| res4.14.conv1.*   | res4.14.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}                            | (256,) (256,) (256,) (256,) (256,1024,1,1)         |
| res4.14.conv2.*   | res4.14.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}                            | (256,) (256,) (256,) (256,) (256,256,3,3)          |
| res4.14.conv3.*   | res4.14.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}                            | (1024,) (1024,) (1024,) (1024,) (1024,256,1,1)     |
| res4.15.conv1.*   | res4.15.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}                            | (256,) (256,) (256,) (256,) (256,1024,1,1)         |
| res4.15.conv2.*   | res4.15.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}                            | (256,) (256,) (256,) (256,) (256,256,3,3)          |
| res4.15.conv3.*   | res4.15.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}                            | (1024,) (1024,) (1024,) (1024,) (1024,256,1,1)     |
| res4.16.conv1.*   | res4.16.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}                            | (256,) (256,) (256,) (256,) (256,1024,1,1)         |
| res4.16.conv2.*   | res4.16.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}                            | (256,) (256,) (256,) (256,) (256,256,3,3)          |
| res4.16.conv3.*   | res4.16.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}                            | (1024,) (1024,) (1024,) (1024,) (1024,256,1,1)     |
| res4.17.conv1.*   | res4.17.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}                            | (256,) (256,) (256,) (256,) (256,1024,1,1)         |
| res4.17.conv2.*   | res4.17.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}                            | (256,) (256,) (256,) (256,) (256,256,3,3)          |
| res4.17.conv3.*   | res4.17.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}                            | (1024,) (1024,) (1024,) (1024,) (1024,256,1,1)     |
| res4.18.conv1.*   | res4.18.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}                            | (256,) (256,) (256,) (256,) (256,1024,1,1)         |
| res4.18.conv2.*   | res4.18.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}                            | (256,) (256,) (256,) (256,) (256,256,3,3)          |
| res4.18.conv3.*   | res4.18.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}                            | (1024,) (1024,) (1024,) (1024,) (1024,256,1,1)     |
| res4.19.conv1.*   | res4.19.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}                            | (256,) (256,) (256,) (256,) (256,1024,1,1)         |
| res4.19.conv2.*   | res4.19.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}                            | (256,) (256,) (256,) (256,) (256,256,3,3)          |
| res4.19.conv3.*   | res4.19.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}                            | (1024,) (1024,) (1024,) (1024,) (1024,256,1,1)     |
| res4.2.conv1.*    | res4.2.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}                             | (256,) (256,) (256,) (256,) (256,1024,1,1)         |
| res4.2.conv2.*    | res4.2.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}                             | (256,) (256,) (256,) (256,) (256,256,3,3)          |
| res4.2.conv3.*    | res4.2.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}                             | (1024,) (1024,) (1024,) (1024,) (1024,256,1,1)     |
| res4.20.conv1.*   | res4.20.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}                            | (256,) (256,) (256,) (256,) (256,1024,1,1)         |
| res4.20.conv2.*   | res4.20.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}                            | (256,) (256,) (256,) (256,) (256,256,3,3)          |
| res4.20.conv3.*   | res4.20.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}                            | (1024,) (1024,) (1024,) (1024,) (1024,256,1,1)     |
| res4.21.conv1.*   | res4.21.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}                            | (256,) (256,) (256,) (256,) (256,1024,1,1)         |
| res4.21.conv2.*   | res4.21.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}                            | (256,) (256,) (256,) (256,) (256,256,3,3)          |
| res4.21.conv3.*   | res4.21.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}                            | (1024,) (1024,) (1024,) (1024,) (1024,256,1,1)     |
| res4.22.conv1.*   | res4.22.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}                            | (256,) (256,) (256,) (256,) (256,1024,1,1)         |
| res4.22.conv2.*   | res4.22.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}                            | (256,) (256,) (256,) (256,) (256,256,3,3)          |
| res4.22.conv3.*   | res4.22.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}                            | (1024,) (1024,) (1024,) (1024,) (1024,256,1,1)     |
| res4.3.conv1.*    | res4.3.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}                             | (256,) (256,) (256,) (256,) (256,1024,1,1)         |
| res4.3.conv2.*    | res4.3.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}                             | (256,) (256,) (256,) (256,) (256,256,3,3)          |
| res4.3.conv3.*    | res4.3.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}                             | (1024,) (1024,) (1024,) (1024,) (1024,256,1,1)     |
| res4.4.conv1.*    | res4.4.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}                             | (256,) (256,) (256,) (256,) (256,1024,1,1)         |
| res4.4.conv2.*    | res4.4.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}                             | (256,) (256,) (256,) (256,) (256,256,3,3)          |
| res4.4.conv3.*    | res4.4.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}                             | (1024,) (1024,) (1024,) (1024,) (1024,256,1,1)     |
| res4.5.conv1.*    | res4.5.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}                             | (256,) (256,) (256,) (256,) (256,1024,1,1)         |
| res4.5.conv2.*    | res4.5.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}                             | (256,) (256,) (256,) (256,) (256,256,3,3)          |
| res4.5.conv3.*    | res4.5.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}                             | (1024,) (1024,) (1024,) (1024,) (1024,256,1,1)     |
| res4.6.conv1.*    | res4.6.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}                             | (256,) (256,) (256,) (256,) (256,1024,1,1)         |
| res4.6.conv2.*    | res4.6.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}                             | (256,) (256,) (256,) (256,) (256,256,3,3)          |
| res4.6.conv3.*    | res4.6.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}                             | (1024,) (1024,) (1024,) (1024,) (1024,256,1,1)     |
| res4.7.conv1.*    | res4.7.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}                             | (256,) (256,) (256,) (256,) (256,1024,1,1)         |
| res4.7.conv2.*    | res4.7.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}                             | (256,) (256,) (256,) (256,) (256,256,3,3)          |
| res4.7.conv3.*    | res4.7.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}                             | (1024,) (1024,) (1024,) (1024,) (1024,256,1,1)     |
| res4.8.conv1.*    | res4.8.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}                             | (256,) (256,) (256,) (256,) (256,1024,1,1)         |
| res4.8.conv2.*    | res4.8.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}                             | (256,) (256,) (256,) (256,) (256,256,3,3)          |
| res4.8.conv3.*    | res4.8.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}                             | (1024,) (1024,) (1024,) (1024,) (1024,256,1,1)     |
| res4.9.conv1.*    | res4.9.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}                             | (256,) (256,) (256,) (256,) (256,1024,1,1)         |
| res4.9.conv2.*    | res4.9.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}                             | (256,) (256,) (256,) (256,) (256,256,3,3)          |
| res4.9.conv3.*    | res4.9.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}                             | (1024,) (1024,) (1024,) (1024,) (1024,256,1,1)     |
| res5.0.conv1.*    | res5.0.conv1.{norm.bias,norm.num_batches_tracked,norm.running_mean,norm.running_var,norm.weight,weight}    | (512,) () (512,) (512,) (512,) (512,1024,1,1)      |
| res5.0.conv2.*    | res5.0.conv2.{norm.bias,norm.num_batches_tracked,norm.running_mean,norm.running_var,norm.weight,weight}    | (512,) () (512,) (512,) (512,) (512,512,3,3)       |
| res5.0.conv3.*    | res5.0.conv3.{norm.bias,norm.num_batches_tracked,norm.running_mean,norm.running_var,norm.weight,weight}    | (2048,) () (2048,) (2048,) (2048,) (2048,512,1,1)  |
| res5.0.shortcut.* | res5.0.shortcut.{norm.bias,norm.num_batches_tracked,norm.running_mean,norm.running_var,norm.weight,weight} | (2048,) () (2048,) (2048,) (2048,) (2048,1024,1,1) |
| res5.1.conv1.*    | res5.1.conv1.{norm.bias,norm.num_batches_tracked,norm.running_mean,norm.running_var,norm.weight,weight}    | (512,) () (512,) (512,) (512,) (512,2048,1,1)      |
| res5.1.conv2.*    | res5.1.conv2.{norm.bias,norm.num_batches_tracked,norm.running_mean,norm.running_var,norm.weight,weight}    | (512,) () (512,) (512,) (512,) (512,512,3,3)       |
| res5.1.conv3.*    | res5.1.conv3.{norm.bias,norm.num_batches_tracked,norm.running_mean,norm.running_var,norm.weight,weight}    | (2048,) () (2048,) (2048,) (2048,) (2048,512,1,1)  |
| res5.2.conv1.*    | res5.2.conv1.{norm.bias,norm.num_batches_tracked,norm.running_mean,norm.running_var,norm.weight,weight}    | (512,) () (512,) (512,) (512,) (512,2048,1,1)      |
| res5.2.conv2.*    | res5.2.conv2.{norm.bias,norm.num_batches_tracked,norm.running_mean,norm.running_var,norm.weight,weight}    | (512,) () (512,) (512,) (512,) (512,512,3,3)       |
| res5.2.conv3.*    | res5.2.conv3.{norm.bias,norm.num_batches_tracked,norm.running_mean,norm.running_var,norm.weight,weight}    | (2048,) () (2048,) (2048,) (2048,) (2048,512,1,1)  |
| stem.conv1.*      | stem.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}                               | (64,) (64,) (64,) (64,) (64,3,3,3)                 |
| stem.conv2.*      | stem.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}                               | (64,) (64,) (64,) (64,) (64,64,3,3)                |
| stem.conv3.*      | stem.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}                               | (128,) (128,) (128,) (128,) (128,64,3,3)           |
WARNING [12/11 21:12:04 fvcore.common.checkpoint]: Some model parameters or buffers are not found in the checkpoint:
aspp_head.decoder.res2.fuse_conv.depthwise.norm.{bias, running_mean, running_var, weight}
aspp_head.decoder.res2.fuse_conv.depthwise.weight
aspp_head.decoder.res2.fuse_conv.pointwise.norm.{bias, running_mean, running_var, weight}
aspp_head.decoder.res2.fuse_conv.pointwise.weight
aspp_head.decoder.res2.project_conv.norm.{bias, running_mean, running_var, weight}
aspp_head.decoder.res2.project_conv.weight
aspp_head.decoder.res3.fuse_conv.depthwise.norm.{bias, running_mean, running_var, weight}
aspp_head.decoder.res3.fuse_conv.depthwise.weight
aspp_head.decoder.res3.fuse_conv.pointwise.norm.{bias, running_mean, running_var, weight}
aspp_head.decoder.res3.fuse_conv.pointwise.weight
aspp_head.decoder.res3.project_conv.norm.{bias, running_mean, running_var, weight}
aspp_head.decoder.res3.project_conv.weight
aspp_head.decoder.res5.project_conv.convs.0.norm.{bias, running_mean, running_var, weight}
aspp_head.decoder.res5.project_conv.convs.0.weight
aspp_head.decoder.res5.project_conv.convs.1.depthwise.norm.{bias, running_mean, running_var, weight}
aspp_head.decoder.res5.project_conv.convs.1.depthwise.weight
aspp_head.decoder.res5.project_conv.convs.1.pointwise.norm.{bias, running_mean, running_var, weight}
aspp_head.decoder.res5.project_conv.convs.1.pointwise.weight
aspp_head.decoder.res5.project_conv.convs.2.depthwise.norm.{bias, running_mean, running_var, weight}
aspp_head.decoder.res5.project_conv.convs.2.depthwise.weight
aspp_head.decoder.res5.project_conv.convs.2.pointwise.norm.{bias, running_mean, running_var, weight}
aspp_head.decoder.res5.project_conv.convs.2.pointwise.weight
aspp_head.decoder.res5.project_conv.convs.3.depthwise.norm.{bias, running_mean, running_var, weight}
aspp_head.decoder.res5.project_conv.convs.3.depthwise.weight
aspp_head.decoder.res5.project_conv.convs.3.pointwise.norm.{bias, running_mean, running_var, weight}
aspp_head.decoder.res5.project_conv.convs.3.pointwise.weight
aspp_head.decoder.res5.project_conv.convs.4.1.{bias, weight}
aspp_head.decoder.res5.project_conv.project.norm.{bias, running_mean, running_var, weight}
aspp_head.decoder.res5.project_conv.project.weight
ins_embed_head.aspp_head.decoder.res2.fuse_conv.depthwise.norm.{bias, running_mean, running_var, weight}
ins_embed_head.aspp_head.decoder.res2.fuse_conv.depthwise.weight
ins_embed_head.aspp_head.decoder.res2.fuse_conv.pointwise.norm.{bias, running_mean, running_var, weight}
ins_embed_head.aspp_head.decoder.res2.fuse_conv.pointwise.weight
ins_embed_head.aspp_head.decoder.res2.project_conv.norm.{bias, running_mean, running_var, weight}
ins_embed_head.aspp_head.decoder.res2.project_conv.weight
ins_embed_head.aspp_head.decoder.res3.fuse_conv.depthwise.norm.{bias, running_mean, running_var, weight}
ins_embed_head.aspp_head.decoder.res3.fuse_conv.depthwise.weight
ins_embed_head.aspp_head.decoder.res3.fuse_conv.pointwise.norm.{bias, running_mean, running_var, weight}
ins_embed_head.aspp_head.decoder.res3.fuse_conv.pointwise.weight
ins_embed_head.aspp_head.decoder.res3.project_conv.norm.{bias, running_mean, running_var, weight}
ins_embed_head.aspp_head.decoder.res3.project_conv.weight
ins_embed_head.aspp_head.decoder.res5.project_conv.convs.0.norm.{bias, running_mean, running_var, weight}
ins_embed_head.aspp_head.decoder.res5.project_conv.convs.0.weight
ins_embed_head.aspp_head.decoder.res5.project_conv.convs.1.depthwise.norm.{bias, running_mean, running_var, weight}
ins_embed_head.aspp_head.decoder.res5.project_conv.convs.1.depthwise.weight
ins_embed_head.aspp_head.decoder.res5.project_conv.convs.1.pointwise.norm.{bias, running_mean, running_var, weight}
ins_embed_head.aspp_head.decoder.res5.project_conv.convs.1.pointwise.weight
ins_embed_head.aspp_head.decoder.res5.project_conv.convs.2.depthwise.norm.{bias, running_mean, running_var, weight}
ins_embed_head.aspp_head.decoder.res5.project_conv.convs.2.depthwise.weight
ins_embed_head.aspp_head.decoder.res5.project_conv.convs.2.pointwise.norm.{bias, running_mean, running_var, weight}
ins_embed_head.aspp_head.decoder.res5.project_conv.convs.2.pointwise.weight
ins_embed_head.aspp_head.decoder.res5.project_conv.convs.3.depthwise.norm.{bias, running_mean, running_var, weight}
ins_embed_head.aspp_head.decoder.res5.project_conv.convs.3.depthwise.weight
ins_embed_head.aspp_head.decoder.res5.project_conv.convs.3.pointwise.norm.{bias, running_mean, running_var, weight}
ins_embed_head.aspp_head.decoder.res5.project_conv.convs.3.pointwise.weight
ins_embed_head.aspp_head.decoder.res5.project_conv.convs.4.1.{bias, weight}
ins_embed_head.aspp_head.decoder.res5.project_conv.project.norm.{bias, running_mean, running_var, weight}
ins_embed_head.aspp_head.decoder.res5.project_conv.project.weight
ins_embed_head.center_head.0.norm.{bias, running_mean, running_var, weight}
ins_embed_head.center_head.0.weight
ins_embed_head.center_head.1.norm.{bias, running_mean, running_var, weight}
ins_embed_head.center_head.1.weight
ins_embed_head.center_predictor.{bias, weight}
ins_embed_head.offset_head.depthwise.norm.{bias, running_mean, running_var, weight}
ins_embed_head.offset_head.depthwise.weight
ins_embed_head.offset_head.pointwise.norm.{bias, running_mean, running_var, weight}
ins_embed_head.offset_head.pointwise.weight
ins_embed_head.offset_predictor.{bias, weight}
sem_seg_head.aspp_head.decoder.res2.fuse_conv.depthwise.norm.{bias, running_mean, running_var, weight}
sem_seg_head.aspp_head.decoder.res2.fuse_conv.depthwise.weight
sem_seg_head.aspp_head.decoder.res2.fuse_conv.pointwise.norm.{bias, running_mean, running_var, weight}
sem_seg_head.aspp_head.decoder.res2.fuse_conv.pointwise.weight
sem_seg_head.aspp_head.decoder.res2.project_conv.norm.{bias, running_mean, running_var, weight}
sem_seg_head.aspp_head.decoder.res2.project_conv.weight
sem_seg_head.aspp_head.decoder.res3.fuse_conv.depthwise.norm.{bias, running_mean, running_var, weight}
sem_seg_head.aspp_head.decoder.res3.fuse_conv.depthwise.weight
sem_seg_head.aspp_head.decoder.res3.fuse_conv.pointwise.norm.{bias, running_mean, running_var, weight}
sem_seg_head.aspp_head.decoder.res3.fuse_conv.pointwise.weight
sem_seg_head.aspp_head.decoder.res3.project_conv.norm.{bias, running_mean, running_var, weight}
sem_seg_head.aspp_head.decoder.res3.project_conv.weight
sem_seg_head.aspp_head.decoder.res5.project_conv.convs.0.norm.{bias, running_mean, running_var, weight}
sem_seg_head.aspp_head.decoder.res5.project_conv.convs.0.weight
sem_seg_head.aspp_head.decoder.res5.project_conv.convs.1.depthwise.norm.{bias, running_mean, running_var, weight}
sem_seg_head.aspp_head.decoder.res5.project_conv.convs.1.depthwise.weight
sem_seg_head.aspp_head.decoder.res5.project_conv.convs.1.pointwise.norm.{bias, running_mean, running_var, weight}
sem_seg_head.aspp_head.decoder.res5.project_conv.convs.1.pointwise.weight
sem_seg_head.aspp_head.decoder.res5.project_conv.convs.2.depthwise.norm.{bias, running_mean, running_var, weight}
sem_seg_head.aspp_head.decoder.res5.project_conv.convs.2.depthwise.weight
sem_seg_head.aspp_head.decoder.res5.project_conv.convs.2.pointwise.norm.{bias, running_mean, running_var, weight}
sem_seg_head.aspp_head.decoder.res5.project_conv.convs.2.pointwise.weight
sem_seg_head.aspp_head.decoder.res5.project_conv.convs.3.depthwise.norm.{bias, running_mean, running_var, weight}
sem_seg_head.aspp_head.decoder.res5.project_conv.convs.3.depthwise.weight
sem_seg_head.aspp_head.decoder.res5.project_conv.convs.3.pointwise.norm.{bias, running_mean, running_var, weight}
sem_seg_head.aspp_head.decoder.res5.project_conv.convs.3.pointwise.weight
sem_seg_head.aspp_head.decoder.res5.project_conv.convs.4.1.{bias, weight}
sem_seg_head.aspp_head.decoder.res5.project_conv.project.norm.{bias, running_mean, running_var, weight}
sem_seg_head.aspp_head.decoder.res5.project_conv.project.weight
sem_seg_head.head.depthwise.norm.{bias, running_mean, running_var, weight}
sem_seg_head.head.depthwise.weight
sem_seg_head.head.pointwise.norm.{bias, running_mean, running_var, weight}
sem_seg_head.head.pointwise.weight
sem_seg_head.predictor.{bias, weight}
WARNING [12/11 21:12:04 fvcore.common.checkpoint]: The checkpoint state_dict contains keys that are not used by the model:
  res2.0.conv1.norm.num_batches_tracked
  res2.0.conv2.norm.num_batches_tracked
  res2.0.conv3.norm.num_batches_tracked
  res2.0.shortcut.norm.num_batches_tracked
  res2.1.conv1.norm.num_batches_tracked
  res2.1.conv2.norm.num_batches_tracked
  res2.1.conv3.norm.num_batches_tracked
  res2.2.conv1.norm.num_batches_tracked
  res2.2.conv2.norm.num_batches_tracked
  res2.2.conv3.norm.num_batches_tracked
  res3.0.conv1.norm.num_batches_tracked
  res3.0.conv2.norm.num_batches_tracked
  res3.0.conv3.norm.num_batches_tracked
  res3.0.shortcut.norm.num_batches_tracked
  res3.1.conv1.norm.num_batches_tracked
  res3.1.conv2.norm.num_batches_tracked
  res3.1.conv3.norm.num_batches_tracked
  res3.2.conv1.norm.num_batches_tracked
  res3.2.conv2.norm.num_batches_tracked
  res3.2.conv3.norm.num_batches_tracked
  res3.3.conv1.norm.num_batches_tracked
  res3.3.conv2.norm.num_batches_tracked
  res3.3.conv3.norm.num_batches_tracked
  res4.0.conv1.norm.num_batches_tracked
  res4.0.conv2.norm.num_batches_tracked
  res4.0.conv3.norm.num_batches_tracked
  res4.0.shortcut.norm.num_batches_tracked
  res4.1.conv1.norm.num_batches_tracked
  res4.1.conv2.norm.num_batches_tracked
  res4.1.conv3.norm.num_batches_tracked
  res4.10.conv1.norm.num_batches_tracked
  res4.10.conv2.norm.num_batches_tracked
  res4.10.conv3.norm.num_batches_tracked
  res4.11.conv1.norm.num_batches_tracked
  res4.11.conv2.norm.num_batches_tracked
  res4.11.conv3.norm.num_batches_tracked
  res4.12.conv1.norm.num_batches_tracked
  res4.12.conv2.norm.num_batches_tracked
  res4.12.conv3.norm.num_batches_tracked
  res4.13.conv1.norm.num_batches_tracked
  res4.13.conv2.norm.num_batches_tracked
  res4.13.conv3.norm.num_batches_tracked
  res4.14.conv1.norm.num_batches_tracked
  res4.14.conv2.norm.num_batches_tracked
  res4.14.conv3.norm.num_batches_tracked
  res4.15.conv1.norm.num_batches_tracked
  res4.15.conv2.norm.num_batches_tracked
  res4.15.conv3.norm.num_batches_tracked
  res4.16.conv1.norm.num_batches_tracked
  res4.16.conv2.norm.num_batches_tracked
  res4.16.conv3.norm.num_batches_tracked
  res4.17.conv1.norm.num_batches_tracked
  res4.17.conv2.norm.num_batches_tracked
  res4.17.conv3.norm.num_batches_tracked
  res4.18.conv1.norm.num_batches_tracked
  res4.18.conv2.norm.num_batches_tracked
  res4.18.conv3.norm.num_batches_tracked
  res4.19.conv1.norm.num_batches_tracked
  res4.19.conv2.norm.num_batches_tracked
  res4.19.conv3.norm.num_batches_tracked
  res4.2.conv1.norm.num_batches_tracked
  res4.2.conv2.norm.num_batches_tracked
  res4.2.conv3.norm.num_batches_tracked
  res4.20.conv1.norm.num_batches_tracked
  res4.20.conv2.norm.num_batches_tracked
  res4.20.conv3.norm.num_batches_tracked
  res4.21.conv1.norm.num_batches_tracked
  res4.21.conv2.norm.num_batches_tracked
  res4.21.conv3.norm.num_batches_tracked
  res4.22.conv1.norm.num_batches_tracked
  res4.22.conv2.norm.num_batches_tracked
  res4.22.conv3.norm.num_batches_tracked
  res4.3.conv1.norm.num_batches_tracked
  res4.3.conv2.norm.num_batches_tracked
  res4.3.conv3.norm.num_batches_tracked
  res4.4.conv1.norm.num_batches_tracked
  res4.4.conv2.norm.num_batches_tracked
  res4.4.conv3.norm.num_batches_tracked
  res4.5.conv1.norm.num_batches_tracked
  res4.5.conv2.norm.num_batches_tracked
  res4.5.conv3.norm.num_batches_tracked
  res4.6.conv1.norm.num_batches_tracked
  res4.6.conv2.norm.num_batches_tracked
  res4.6.conv3.norm.num_batches_tracked
  res4.7.conv1.norm.num_batches_tracked
  res4.7.conv2.norm.num_batches_tracked
  res4.7.conv3.norm.num_batches_tracked
  res4.8.conv1.norm.num_batches_tracked
  res4.8.conv2.norm.num_batches_tracked
  res4.8.conv3.norm.num_batches_tracked
  res4.9.conv1.norm.num_batches_tracked
  res4.9.conv2.norm.num_batches_tracked
  res4.9.conv3.norm.num_batches_tracked
  stem.conv1.norm.num_batches_tracked
  stem.conv2.norm.num_batches_tracked
  stem.conv3.norm.num_batches_tracked
  stem.fc.{bias, weight}
[12/11 21:12:04 d2.engine.train_loop]: Starting training from iteration 0
/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:481: UserWarning: This DataLoader will create 10 worker processes in total. Our suggested max number of worker in current system is 8, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.
  cpuset_checked))
[12/11 21:12:13 d2.utils.events]:  eta: 1:05:10  iter: 19  total_loss: 6.056  loss_sem_seg: 3.686  loss_center: 0.8461  loss_offset: 1.587  time: 0.3967  data_time: 0.0799  lr: 4.9867e-05  max_mem: 7924M
[12/11 21:12:21 d2.utils.events]:  eta: 1:05:15  iter: 39  total_loss: 6.196  loss_sem_seg: 3.77  loss_center: 0.7496  loss_offset: 1.536  time: 0.3984  data_time: 0.0290  lr: 9.9552e-05  max_mem: 7924M
[12/11 21:12:29 d2.utils.events]:  eta: 1:05:29  iter: 59  total_loss: 5.758  loss_sem_seg: 3.519  loss_center: 0.7986  loss_offset: 1.315  time: 0.3990  data_time: 0.0293  lr: 0.00014906  max_mem: 7924M
[12/11 21:12:37 d2.utils.events]:  eta: 1:05:42  iter: 79  total_loss: 5.999  loss_sem_seg: 3.513  loss_center: 0.6663  loss_offset: 1.672  time: 0.3991  data_time: 0.0283  lr: 0.00019838  max_mem: 7924M
[12/11 21:12:45 d2.utils.events]:  eta: 1:05:22  iter: 99  total_loss: 5.325  loss_sem_seg: 3.107  loss_center: 0.7554  loss_offset: 1.338  time: 0.3987  data_time: 0.0266  lr: 0.00024753  max_mem: 7924M
[12/11 21:12:53 d2.utils.events]:  eta: 1:05:22  iter: 119  total_loss: 5.278  loss_sem_seg: 3.129  loss_center: 0.5195  loss_offset: 1.609  time: 0.3983  data_time: 0.0270  lr: 0.00029649  max_mem: 7924M
[12/11 21:13:01 d2.utils.events]:  eta: 1:05:14  iter: 139  total_loss: 5.433  loss_sem_seg: 2.875  loss_center: 0.7616  loss_offset: 1.594  time: 0.3978  data_time: 0.0269  lr: 0.00034528  max_mem: 7924M
[12/11 21:13:09 d2.utils.events]:  eta: 1:05:02  iter: 159  total_loss: 4.803  loss_sem_seg: 2.867  loss_center: 0.5496  loss_offset: 1.774  time: 0.3980  data_time: 0.0299  lr: 0.00039388  max_mem: 7924M
[12/11 21:13:17 d2.utils.events]:  eta: 1:05:02  iter: 179  total_loss: 5.157  loss_sem_seg: 2.906  loss_center: 0.576  loss_offset: 1.262  time: 0.3985  data_time: 0.0310  lr: 0.0004423  max_mem: 7924M
[12/11 21:13:25 d2.utils.events]:  eta: 1:04:57  iter: 199  total_loss: 4.347  loss_sem_seg: 2.497  loss_center: 0.6873  loss_offset: 1.212  time: 0.3988  data_time: 0.0294  lr: 0.00049055  max_mem: 7924M
[12/11 21:13:33 d2.utils.events]:  eta: 1:04:56  iter: 219  total_loss: 4.394  loss_sem_seg: 2.527  loss_center: 0.5693  loss_offset: 1.126  time: 0.3993  data_time: 0.0311  lr: 0.00053861  max_mem: 7924M
[12/11 21:13:41 d2.utils.events]:  eta: 1:04:51  iter: 239  total_loss: 4.574  loss_sem_seg: 2.559  loss_center: 0.7141  loss_offset: 1.128  time: 0.3995  data_time: 0.0298  lr: 0.00058649  max_mem: 7924M
[12/11 21:13:50 d2.utils.events]:  eta: 1:04:42  iter: 259  total_loss: 4.559  loss_sem_seg: 2.597  loss_center: 1.132  loss_offset: 1.109  time: 0.3997  data_time: 0.0293  lr: 0.0006342  max_mem: 7924M
[12/11 21:13:57 d2.utils.events]:  eta: 1:04:30  iter: 279  total_loss: 4.228  loss_sem_seg: 2.427  loss_center: 0.8527  loss_offset: 1.072  time: 0.3995  data_time: 0.0286  lr: 0.00068172  max_mem: 7924M
[12/11 21:14:05 d2.utils.events]:  eta: 1:04:27  iter: 299  total_loss: 4.429  loss_sem_seg: 2.403  loss_center: 0.7371  loss_offset: 1.194  time: 0.3995  data_time: 0.0298  lr: 0.00072906  max_mem: 7924M
[12/11 21:14:14 d2.utils.events]:  eta: 1:04:19  iter: 319  total_loss: 3.794  loss_sem_seg: 2.089  loss_center: 0.7129  loss_offset: 0.9766  time: 0.3996  data_time: 0.0304  lr: 0.00077622  max_mem: 7924M
[12/11 21:14:22 d2.utils.events]:  eta: 1:04:13  iter: 339  total_loss: 3.903  loss_sem_seg: 2.274  loss_center: 0.5839  loss_offset: 1.002  time: 0.3999  data_time: 0.0318  lr: 0.0008232  max_mem: 7924M
[12/11 21:14:30 d2.utils.events]:  eta: 1:04:10  iter: 359  total_loss: 4.176  loss_sem_seg: 2.306  loss_center: 0.6948  loss_offset: 0.9965  time: 0.3999  data_time: 0.0306  lr: 0.00087  max_mem: 7924M
[12/11 21:14:38 d2.utils.events]:  eta: 1:04:03  iter: 379  total_loss: 4.257  loss_sem_seg: 2.417  loss_center: 0.5781  loss_offset: 1  time: 0.4000  data_time: 0.0293  lr: 0.00091662  max_mem: 7924M
[12/11 21:14:46 d2.utils.events]:  eta: 1:03:55  iter: 399  total_loss: 4.226  loss_sem_seg: 2.502  loss_center: 0.5958  loss_offset: 0.9858  time: 0.4002  data_time: 0.0306  lr: 0.00096306  max_mem: 7924M
[12/11 21:14:54 d2.utils.events]:  eta: 1:03:46  iter: 419  total_loss: 3.768  loss_sem_seg: 2.227  loss_center: 0.6502  loss_offset: 0.9176  time: 0.4002  data_time: 0.0288  lr: 0.0010093  max_mem: 7924M
[12/11 21:15:02 d2.utils.events]:  eta: 1:03:38  iter: 439  total_loss: 3.962  loss_sem_seg: 1.912  loss_center: 0.7264  loss_offset: 0.9161  time: 0.4001  data_time: 0.0301  lr: 0.0010554  max_mem: 7924M
[12/11 21:15:10 d2.utils.events]:  eta: 1:03:31  iter: 459  total_loss: 3.626  loss_sem_seg: 2.133  loss_center: 0.5611  loss_offset: 0.9417  time: 0.4001  data_time: 0.0293  lr: 0.0011013  max_mem: 7924M
[12/11 21:15:18 d2.utils.events]:  eta: 1:03:24  iter: 479  total_loss: 3.466  loss_sem_seg: 2.136  loss_center: 0.6585  loss_offset: 0.8674  time: 0.4002  data_time: 0.0305  lr: 0.001147  max_mem: 7924M
[12/11 21:15:26 d2.utils.events]:  eta: 1:03:15  iter: 499  total_loss: 3.515  loss_sem_seg: 2.023  loss_center: 0.5372  loss_offset: 0.861  time: 0.4001  data_time: 0.0286  lr: 0.0011925  max_mem: 7924M
[12/11 21:15:34 d2.utils.events]:  eta: 1:03:07  iter: 519  total_loss: 3.793  loss_sem_seg: 2.133  loss_center: 0.6086  loss_offset: 0.9576  time: 0.4001  data_time: 0.0298  lr: 0.0012379  max_mem: 7924M
[12/11 21:15:42 d2.utils.events]:  eta: 1:02:59  iter: 539  total_loss: 3.611  loss_sem_seg: 2.032  loss_center: 0.6061  loss_offset: 0.8721  time: 0.4001  data_time: 0.0289  lr: 0.001283  max_mem: 7924M
[12/11 21:15:50 d2.utils.events]:  eta: 1:02:51  iter: 559  total_loss: 3.796  loss_sem_seg: 2.086  loss_center: 0.5986  loss_offset: 0.9433  time: 0.4002  data_time: 0.0303  lr: 0.001328  max_mem: 7924M
[12/11 21:15:58 d2.utils.events]:  eta: 1:02:44  iter: 579  total_loss: 3.378  loss_sem_seg: 2.013  loss_center: 0.6251  loss_offset: 0.7926  time: 0.4002  data_time: 0.0291  lr: 0.0013728  max_mem: 7924M
[12/11 21:16:06 d2.utils.events]:  eta: 1:02:37  iter: 599  total_loss: 3.426  loss_sem_seg: 1.957  loss_center: 0.5618  loss_offset: 0.9629  time: 0.4002  data_time: 0.0298  lr: 0.0014175  max_mem: 7924M
[12/11 21:16:14 d2.utils.events]:  eta: 1:02:27  iter: 619  total_loss: 3.714  loss_sem_seg: 1.985  loss_center: 0.7476  loss_offset: 0.8783  time: 0.4001  data_time: 0.0293  lr: 0.0014619  max_mem: 7924M
[12/11 21:16:22 d2.utils.events]:  eta: 1:02:18  iter: 639  total_loss: 3.503  loss_sem_seg: 1.974  loss_center: 0.5868  loss_offset: 0.9975  time: 0.4001  data_time: 0.0303  lr: 0.0015062  max_mem: 7924M
[12/11 21:16:30 d2.utils.events]:  eta: 1:02:11  iter: 659  total_loss: 3.765  loss_sem_seg: 2.05  loss_center: 0.7476  loss_offset: 0.9448  time: 0.4002  data_time: 0.0296  lr: 0.0015503  max_mem: 7924M
[12/11 21:16:38 d2.utils.events]:  eta: 1:02:03  iter: 679  total_loss: 3.317  loss_sem_seg: 1.741  loss_center: 0.6136  loss_offset: 0.8112  time: 0.4001  data_time: 0.0300  lr: 0.0015942  max_mem: 7924M
[12/11 21:16:46 d2.utils.events]:  eta: 1:01:55  iter: 699  total_loss: 3.252  loss_sem_seg: 1.934  loss_center: 0.6153  loss_offset: 0.7615  time: 0.4001  data_time: 0.0299  lr: 0.0016379  max_mem: 7924M
[12/11 21:16:54 d2.utils.events]:  eta: 1:01:47  iter: 719  total_loss: 3.405  loss_sem_seg: 1.845  loss_center: 0.5195  loss_offset: 0.9045  time: 0.4002  data_time: 0.0316  lr: 0.0016814  max_mem: 7924M
[12/11 21:17:02 d2.utils.events]:  eta: 1:01:40  iter: 739  total_loss: 3.59  loss_sem_seg: 1.998  loss_center: 0.5872  loss_offset: 0.9167  time: 0.4002  data_time: 0.0313  lr: 0.0017248  max_mem: 7924M
[12/11 21:17:10 d2.utils.events]:  eta: 1:01:33  iter: 759  total_loss: 3.652  loss_sem_seg: 2.109  loss_center: 0.6998  loss_offset: 0.8679  time: 0.4002  data_time: 0.0281  lr: 0.0017679  max_mem: 7924M
[12/11 21:17:18 d2.utils.events]:  eta: 1:01:26  iter: 779  total_loss: 3.534  loss_sem_seg: 1.992  loss_center: 0.579  loss_offset: 0.8778  time: 0.4002  data_time: 0.0307  lr: 0.0018109  max_mem: 7924M
[12/11 21:17:26 d2.utils.events]:  eta: 1:01:19  iter: 799  total_loss: 3.561  loss_sem_seg: 2.06  loss_center: 0.4966  loss_offset: 0.8712  time: 0.4003  data_time: 0.0297  lr: 0.0018537  max_mem: 7924M
[12/11 21:17:34 d2.utils.events]:  eta: 1:01:12  iter: 819  total_loss: 3.246  loss_sem_seg: 1.793  loss_center: 0.666  loss_offset: 0.8973  time: 0.4004  data_time: 0.0312  lr: 0.0018964  max_mem: 7924M
[12/11 21:17:42 d2.utils.events]:  eta: 1:01:04  iter: 839  total_loss: 3.524  loss_sem_seg: 1.892  loss_center: 0.6366  loss_offset: 0.7621  time: 0.4005  data_time: 0.0308  lr: 0.0019388  max_mem: 7924M
[12/11 21:17:50 d2.utils.events]:  eta: 1:00:56  iter: 859  total_loss: 3.339  loss_sem_seg: 1.83  loss_center: 0.6817  loss_offset: 0.8723  time: 0.4004  data_time: 0.0285  lr: 0.0019811  max_mem: 7924M
[12/11 21:17:58 d2.utils.events]:  eta: 1:00:49  iter: 879  total_loss: 3.361  loss_sem_seg: 1.908  loss_center: 0.5954  loss_offset: 0.8258  time: 0.4006  data_time: 0.0325  lr: 0.0020231  max_mem: 7924M
[12/11 21:18:07 d2.utils.events]:  eta: 1:00:41  iter: 899  total_loss: 3.437  loss_sem_seg: 1.877  loss_center: 0.5349  loss_offset: 0.9219  time: 0.4006  data_time: 0.0299  lr: 0.002065  max_mem: 7924M
[12/11 21:18:15 d2.utils.events]:  eta: 1:00:33  iter: 919  total_loss: 3.454  loss_sem_seg: 1.878  loss_center: 0.707  loss_offset: 0.6967  time: 0.4006  data_time: 0.0293  lr: 0.0021068  max_mem: 7924M
[12/11 21:18:23 d2.utils.events]:  eta: 1:00:26  iter: 939  total_loss: 3.337  loss_sem_seg: 1.659  loss_center: 0.648  loss_offset: 0.8633  time: 0.4006  data_time: 0.0297  lr: 0.0021483  max_mem: 7924M
[12/11 21:18:31 d2.utils.events]:  eta: 1:00:19  iter: 959  total_loss: 3.34  loss_sem_seg: 1.848  loss_center: 0.5175  loss_offset: 0.7608  time: 0.4007  data_time: 0.0325  lr: 0.0021896  max_mem: 7924M
[12/11 21:18:39 d2.utils.events]:  eta: 1:00:12  iter: 979  total_loss: 3.265  loss_sem_seg: 1.697  loss_center: 0.6619  loss_offset: 0.7385  time: 0.4007  data_time: 0.0295  lr: 0.0022308  max_mem: 7924M
[12/11 21:18:47 d2.utils.events]:  eta: 1:00:05  iter: 999  total_loss: 3.372  loss_sem_seg: 1.806  loss_center: 0.5648  loss_offset: 0.732  time: 0.4008  data_time: 0.0314  lr: 0.0022718  max_mem: 7924M
[12/11 21:18:55 d2.utils.events]:  eta: 0:59:58  iter: 1019  total_loss: 3.309  loss_sem_seg: 1.712  loss_center: 0.6985  loss_offset: 0.8156  time: 0.4008  data_time: 0.0281  lr: 0.0022695  max_mem: 7924M
[12/11 21:19:03 d2.utils.events]:  eta: 0:59:51  iter: 1039  total_loss: 3.304  loss_sem_seg: 1.726  loss_center: 0.5673  loss_offset: 0.9212  time: 0.4008  data_time: 0.0305  lr: 0.002265  max_mem: 7924M
[12/11 21:19:11 d2.utils.events]:  eta: 0:59:43  iter: 1059  total_loss: 3.186  loss_sem_seg: 1.751  loss_center: 0.6343  loss_offset: 0.7493  time: 0.4008  data_time: 0.0291  lr: 0.0022604  max_mem: 7924M
[12/11 21:19:19 d2.utils.events]:  eta: 0:59:35  iter: 1079  total_loss: 3.529  loss_sem_seg: 1.86  loss_center: 0.7123  loss_offset: 0.8036  time: 0.4007  data_time: 0.0292  lr: 0.0022559  max_mem: 7924M
[12/11 21:19:27 d2.utils.events]:  eta: 0:59:27  iter: 1099  total_loss: 2.996  loss_sem_seg: 1.686  loss_center: 0.5417  loss_offset: 0.7847  time: 0.4007  data_time: 0.0287  lr: 0.0022513  max_mem: 7924M
[12/11 21:19:35 d2.utils.events]:  eta: 0:59:20  iter: 1119  total_loss: 3.301  loss_sem_seg: 1.667  loss_center: 0.6011  loss_offset: 0.799  time: 0.4007  data_time: 0.0310  lr: 0.0022468  max_mem: 7924M
[12/11 21:19:43 d2.utils.events]:  eta: 0:59:13  iter: 1139  total_loss: 3.097  loss_sem_seg: 1.608  loss_center: 0.7005  loss_offset: 0.8377  time: 0.4008  data_time: 0.0313  lr: 0.0022422  max_mem: 7924M
[12/11 21:19:51 d2.utils.events]:  eta: 0:59:05  iter: 1159  total_loss: 3.138  loss_sem_seg: 1.506  loss_center: 0.716  loss_offset: 0.8373  time: 0.4008  data_time: 0.0286  lr: 0.0022376  max_mem: 7924M
[12/11 21:19:59 d2.utils.events]:  eta: 0:58:57  iter: 1179  total_loss: 3.13  loss_sem_seg: 1.656  loss_center: 0.5216  loss_offset: 0.7711  time: 0.4008  data_time: 0.0315  lr: 0.0022331  max_mem: 7924M
[12/11 21:20:07 d2.utils.events]:  eta: 0:58:50  iter: 1199  total_loss: 3.26  loss_sem_seg: 1.695  loss_center: 0.6852  loss_offset: 0.8701  time: 0.4008  data_time: 0.0305  lr: 0.0022285  max_mem: 7924M
[12/11 21:20:15 d2.utils.events]:  eta: 0:58:42  iter: 1219  total_loss: 3.008  loss_sem_seg: 1.515  loss_center: 0.6608  loss_offset: 0.7532  time: 0.4008  data_time: 0.0296  lr: 0.002224  max_mem: 7924M
[12/11 21:20:23 d2.utils.events]:  eta: 0:58:35  iter: 1239  total_loss: 3.11  loss_sem_seg: 1.738  loss_center: 0.6493  loss_offset: 0.7611  time: 0.4009  data_time: 0.0317  lr: 0.0022194  max_mem: 7924M
[12/11 21:20:31 d2.utils.events]:  eta: 0:58:27  iter: 1259  total_loss: 2.868  loss_sem_seg: 1.557  loss_center: 0.6049  loss_offset: 0.6769  time: 0.4009  data_time: 0.0302  lr: 0.0022149  max_mem: 7924M
[12/11 21:20:39 d2.utils.events]:  eta: 0:58:19  iter: 1279  total_loss: 3.001  loss_sem_seg: 1.674  loss_center: 0.6103  loss_offset: 0.7582  time: 0.4009  data_time: 0.0307  lr: 0.0022103  max_mem: 7924M
[12/11 21:20:48 d2.utils.events]:  eta: 0:58:11  iter: 1299  total_loss: 3.2  loss_sem_seg: 1.783  loss_center: 0.4836  loss_offset: 0.8517  time: 0.4010  data_time: 0.0321  lr: 0.0022057  max_mem: 7924M
[12/11 21:20:56 d2.utils.events]:  eta: 0:58:04  iter: 1319  total_loss: 3.035  loss_sem_seg: 1.504  loss_center: 0.6928  loss_offset: 0.7509  time: 0.4010  data_time: 0.0283  lr: 0.0022012  max_mem: 7924M
[12/11 21:21:04 d2.utils.events]:  eta: 0:57:55  iter: 1339  total_loss: 3.299  loss_sem_seg: 1.83  loss_center: 0.5586  loss_offset: 0.938  time: 0.4010  data_time: 0.0294  lr: 0.0021966  max_mem: 7924M
[12/11 21:21:12 d2.utils.events]:  eta: 0:57:47  iter: 1359  total_loss: 3.126  loss_sem_seg: 1.653  loss_center: 0.5738  loss_offset: 0.8491  time: 0.4010  data_time: 0.0306  lr: 0.002192  max_mem: 7924M
[12/11 21:21:20 d2.utils.events]:  eta: 0:57:39  iter: 1379  total_loss: 3.117  loss_sem_seg: 1.552  loss_center: 0.5569  loss_offset: 0.7299  time: 0.4010  data_time: 0.0297  lr: 0.0021875  max_mem: 7924M
[12/11 21:21:28 d2.utils.events]:  eta: 0:57:31  iter: 1399  total_loss: 2.696  loss_sem_seg: 1.426  loss_center: 0.6048  loss_offset: 0.6501  time: 0.4010  data_time: 0.0305  lr: 0.0021829  max_mem: 7924M
[12/11 21:21:36 d2.utils.events]:  eta: 0:57:25  iter: 1419  total_loss: 2.951  loss_sem_seg: 1.594  loss_center: 0.5629  loss_offset: 0.8659  time: 0.4010  data_time: 0.0317  lr: 0.0021783  max_mem: 7924M
[12/11 21:21:44 d2.utils.events]:  eta: 0:57:16  iter: 1439  total_loss: 2.848  loss_sem_seg: 1.63  loss_center: 0.5728  loss_offset: 0.7968  time: 0.4010  data_time: 0.0292  lr: 0.0021738  max_mem: 7924M
[12/11 21:21:52 d2.utils.events]:  eta: 0:57:08  iter: 1459  total_loss: 2.93  loss_sem_seg: 1.587  loss_center: 0.6324  loss_offset: 0.7087  time: 0.4010  data_time: 0.0305  lr: 0.0021692  max_mem: 7924M
[12/11 21:22:00 d2.utils.events]:  eta: 0:56:58  iter: 1479  total_loss: 2.815  loss_sem_seg: 1.5  loss_center: 0.5793  loss_offset: 0.7368  time: 0.4010  data_time: 0.0298  lr: 0.0021646  max_mem: 7924M
[12/11 21:22:08 d2.utils.events]:  eta: 0:56:50  iter: 1499  total_loss: 3.07  loss_sem_seg: 1.754  loss_center: 0.5677  loss_offset: 0.7528  time: 0.4010  data_time: 0.0304  lr: 0.00216  max_mem: 7924M
[12/11 21:22:16 d2.utils.events]:  eta: 0:56:43  iter: 1519  total_loss: 2.948  loss_sem_seg: 1.755  loss_center: 0.5793  loss_offset: 0.7098  time: 0.4010  data_time: 0.0296  lr: 0.0021555  max_mem: 7924M
[12/11 21:22:24 d2.utils.events]:  eta: 0:56:37  iter: 1539  total_loss: 3.446  loss_sem_seg: 1.759  loss_center: 0.6381  loss_offset: 0.9047  time: 0.4010  data_time: 0.0312  lr: 0.0021509  max_mem: 7924M
[12/11 21:22:32 d2.utils.events]:  eta: 0:56:29  iter: 1559  total_loss: 2.962  loss_sem_seg: 1.628  loss_center: 0.5418  loss_offset: 0.6919  time: 0.4010  data_time: 0.0298  lr: 0.0021463  max_mem: 7924M
[12/11 21:22:40 d2.utils.events]:  eta: 0:56:20  iter: 1579  total_loss: 2.848  loss_sem_seg: 1.368  loss_center: 0.496  loss_offset: 0.7919  time: 0.4010  data_time: 0.0298  lr: 0.0021417  max_mem: 7924M
[12/11 21:22:48 d2.utils.events]:  eta: 0:56:11  iter: 1599  total_loss: 2.851  loss_sem_seg: 1.423  loss_center: 0.6072  loss_offset: 0.7395  time: 0.4010  data_time: 0.0310  lr: 0.0021372  max_mem: 7924M
[12/11 21:22:56 d2.utils.events]:  eta: 0:56:04  iter: 1619  total_loss: 2.681  loss_sem_seg: 1.447  loss_center: 0.5556  loss_offset: 0.6329  time: 0.4010  data_time: 0.0299  lr: 0.0021326  max_mem: 7924M
[12/11 21:23:04 d2.utils.events]:  eta: 0:55:56  iter: 1639  total_loss: 2.898  loss_sem_seg: 1.591  loss_center: 0.5849  loss_offset: 0.629  time: 0.4010  data_time: 0.0292  lr: 0.002128  max_mem: 7924M
[12/11 21:23:12 d2.utils.events]:  eta: 0:55:46  iter: 1659  total_loss: 2.769  loss_sem_seg: 1.51  loss_center: 0.5819  loss_offset: 0.7101  time: 0.4010  data_time: 0.0305  lr: 0.0021234  max_mem: 7924M
[12/11 21:23:20 d2.utils.events]:  eta: 0:55:41  iter: 1679  total_loss: 2.785  loss_sem_seg: 1.391  loss_center: 0.6198  loss_offset: 0.742  time: 0.4011  data_time: 0.0313  lr: 0.0021188  max_mem: 7924M
[12/11 21:23:28 d2.utils.events]:  eta: 0:55:32  iter: 1699  total_loss: 2.94  loss_sem_seg: 1.476  loss_center: 0.5859  loss_offset: 0.7222  time: 0.4011  data_time: 0.0300  lr: 0.0021143  max_mem: 7924M
[12/11 21:23:36 d2.utils.events]:  eta: 0:55:24  iter: 1719  total_loss: 2.891  loss_sem_seg: 1.61  loss_center: 0.5208  loss_offset: 0.7807  time: 0.4011  data_time: 0.0320  lr: 0.0021097  max_mem: 7924M
[12/11 21:23:44 d2.utils.events]:  eta: 0:55:14  iter: 1739  total_loss: 3.005  loss_sem_seg: 1.477  loss_center: 0.6213  loss_offset: 0.7593  time: 0.4011  data_time: 0.0296  lr: 0.0021051  max_mem: 7924M
[12/11 21:23:53 d2.utils.events]:  eta: 0:55:09  iter: 1759  total_loss: 3.063  loss_sem_seg: 1.607  loss_center: 0.567  loss_offset: 0.7408  time: 0.4012  data_time: 0.0331  lr: 0.0021005  max_mem: 7924M
[12/11 21:24:01 d2.utils.events]:  eta: 0:55:00  iter: 1779  total_loss: 2.903  loss_sem_seg: 1.528  loss_center: 0.6345  loss_offset: 0.7483  time: 0.4012  data_time: 0.0285  lr: 0.0020959  max_mem: 7924M
[12/11 21:24:09 d2.utils.events]:  eta: 0:54:51  iter: 1799  total_loss: 2.733  loss_sem_seg: 1.57  loss_center: 0.5856  loss_offset: 0.7128  time: 0.4012  data_time: 0.0310  lr: 0.0020913  max_mem: 7924M
[12/11 21:24:17 d2.utils.events]:  eta: 0:54:42  iter: 1819  total_loss: 2.93  loss_sem_seg: 1.456  loss_center: 0.6521  loss_offset: 0.7718  time: 0.4012  data_time: 0.0322  lr: 0.0020867  max_mem: 7924M
[12/11 21:24:25 d2.utils.events]:  eta: 0:54:34  iter: 1839  total_loss: 3.163  loss_sem_seg: 1.658  loss_center: 0.5378  loss_offset: 0.7769  time: 0.4012  data_time: 0.0284  lr: 0.0020821  max_mem: 7924M
[12/11 21:24:33 d2.utils.events]:  eta: 0:54:26  iter: 1859  total_loss: 2.877  loss_sem_seg: 1.444  loss_center: 0.6691  loss_offset: 0.6969  time: 0.4012  data_time: 0.0321  lr: 0.0020775  max_mem: 7924M
[12/11 21:24:41 d2.utils.events]:  eta: 0:54:17  iter: 1879  total_loss: 2.87  loss_sem_seg: 1.55  loss_center: 0.6214  loss_offset: 0.6966  time: 0.4013  data_time: 0.0310  lr: 0.0020729  max_mem: 7924M
[12/11 21:24:49 d2.utils.events]:  eta: 0:54:10  iter: 1899  total_loss: 2.911  loss_sem_seg: 1.521  loss_center: 0.6133  loss_offset: 0.7733  time: 0.4013  data_time: 0.0292  lr: 0.0020684  max_mem: 7924M
[12/11 21:24:57 d2.utils.events]:  eta: 0:54:03  iter: 1919  total_loss: 2.814  loss_sem_seg: 1.459  loss_center: 0.6516  loss_offset: 0.6363  time: 0.4013  data_time: 0.0298  lr: 0.0020638  max_mem: 7924M
[12/11 21:25:05 d2.utils.events]:  eta: 0:53:54  iter: 1939  total_loss: 2.943  loss_sem_seg: 1.633  loss_center: 0.5582  loss_offset: 0.6783  time: 0.4013  data_time: 0.0300  lr: 0.0020592  max_mem: 7924M
[12/11 21:25:13 d2.utils.events]:  eta: 0:53:45  iter: 1959  total_loss: 3.06  loss_sem_seg: 1.551  loss_center: 0.6385  loss_offset: 0.713  time: 0.4013  data_time: 0.0306  lr: 0.0020546  max_mem: 7924M
[12/11 21:25:21 d2.utils.events]:  eta: 0:53:37  iter: 1979  total_loss: 2.53  loss_sem_seg: 1.314  loss_center: 0.5702  loss_offset: 0.6208  time: 0.4013  data_time: 0.0301  lr: 0.00205  max_mem: 7924M
[12/11 21:25:29 d2.utils.events]:  eta: 0:53:28  iter: 1999  total_loss: 2.979  loss_sem_seg: 1.424  loss_center: 0.5846  loss_offset: 0.6747  time: 0.4013  data_time: 0.0307  lr: 0.0020454  max_mem: 7924M
[12/11 21:25:37 d2.utils.events]:  eta: 0:53:20  iter: 2019  total_loss: 2.748  loss_sem_seg: 1.382  loss_center: 0.511  loss_offset: 0.7451  time: 0.4013  data_time: 0.0307  lr: 0.0020408  max_mem: 7924M
[12/11 21:25:45 d2.utils.events]:  eta: 0:53:12  iter: 2039  total_loss: 3.173  loss_sem_seg: 1.701  loss_center: 0.4557  loss_offset: 0.8522  time: 0.4013  data_time: 0.0296  lr: 0.0020362  max_mem: 7924M
[12/11 21:25:53 d2.utils.events]:  eta: 0:53:04  iter: 2059  total_loss: 2.64  loss_sem_seg: 1.287  loss_center: 0.661  loss_offset: 0.6787  time: 0.4013  data_time: 0.0311  lr: 0.0020316  max_mem: 7924M
[12/11 21:26:01 d2.utils.events]:  eta: 0:52:55  iter: 2079  total_loss: 2.812  loss_sem_seg: 1.645  loss_center: 0.5636  loss_offset: 0.7403  time: 0.4013  data_time: 0.0307  lr: 0.0020269  max_mem: 7924M
[12/11 21:26:10 d2.utils.events]:  eta: 0:52:49  iter: 2099  total_loss: 2.925  loss_sem_seg: 1.416  loss_center: 0.7012  loss_offset: 0.6832  time: 0.4014  data_time: 0.0310  lr: 0.0020223  max_mem: 7924M
[12/11 21:26:18 d2.utils.events]:  eta: 0:52:40  iter: 2119  total_loss: 2.847  loss_sem_seg: 1.569  loss_center: 0.5574  loss_offset: 0.6501  time: 0.4014  data_time: 0.0326  lr: 0.0020177  max_mem: 7924M
[12/11 21:26:26 d2.utils.events]:  eta: 0:52:31  iter: 2139  total_loss: 2.583  loss_sem_seg: 1.204  loss_center: 0.6475  loss_offset: 0.733  time: 0.4014  data_time: 0.0312  lr: 0.0020131  max_mem: 7924M
[12/11 21:26:34 d2.utils.events]:  eta: 0:52:24  iter: 2159  total_loss: 2.711  loss_sem_seg: 1.367  loss_center: 0.619  loss_offset: 0.7055  time: 0.4014  data_time: 0.0308  lr: 0.0020085  max_mem: 7924M
[12/11 21:26:42 d2.utils.events]:  eta: 0:52:16  iter: 2179  total_loss: 2.609  loss_sem_seg: 1.377  loss_center: 0.6015  loss_offset: 0.647  time: 0.4014  data_time: 0.0305  lr: 0.0020039  max_mem: 7924M
[12/11 21:26:50 d2.utils.events]:  eta: 0:52:07  iter: 2199  total_loss: 2.714  loss_sem_seg: 1.348  loss_center: 0.6767  loss_offset: 0.7518  time: 0.4014  data_time: 0.0290  lr: 0.0019993  max_mem: 7924M
[12/11 21:26:58 d2.utils.events]:  eta: 0:51:58  iter: 2219  total_loss: 2.381  loss_sem_seg: 1.254  loss_center: 0.5116  loss_offset: 0.6713  time: 0.4014  data_time: 0.0306  lr: 0.0019947  max_mem: 7924M
[12/11 21:27:06 d2.utils.events]:  eta: 0:51:49  iter: 2239  total_loss: 2.67  loss_sem_seg: 1.401  loss_center: 0.5058  loss_offset: 0.671  time: 0.4014  data_time: 0.0306  lr: 0.0019901  max_mem: 7924M
[12/11 21:27:14 d2.utils.events]:  eta: 0:51:40  iter: 2259  total_loss: 2.978  loss_sem_seg: 1.521  loss_center: 0.551  loss_offset: 0.755  time: 0.4014  data_time: 0.0292  lr: 0.0019854  max_mem: 7924M
[12/11 21:27:22 d2.utils.events]:  eta: 0:51:32  iter: 2279  total_loss: 2.819  loss_sem_seg: 1.444  loss_center: 0.6432  loss_offset: 0.7305  time: 0.4014  data_time: 0.0301  lr: 0.0019808  max_mem: 7924M
[12/11 21:27:30 d2.utils.events]:  eta: 0:51:24  iter: 2299  total_loss: 2.559  loss_sem_seg: 1.349  loss_center: 0.5432  loss_offset: 0.6647  time: 0.4014  data_time: 0.0304  lr: 0.0019762  max_mem: 7924M
[12/11 21:27:38 d2.utils.events]:  eta: 0:51:16  iter: 2319  total_loss: 2.615  loss_sem_seg: 1.329  loss_center: 0.5213  loss_offset: 0.7381  time: 0.4014  data_time: 0.0327  lr: 0.0019716  max_mem: 7924M
[12/11 21:27:46 d2.utils.events]:  eta: 0:51:08  iter: 2339  total_loss: 2.385  loss_sem_seg: 1.205  loss_center: 0.5032  loss_offset: 0.6378  time: 0.4014  data_time: 0.0307  lr: 0.001967  max_mem: 7924M
[12/11 21:27:54 d2.utils.events]:  eta: 0:51:01  iter: 2359  total_loss: 2.615  loss_sem_seg: 1.461  loss_center: 0.5814  loss_offset: 0.6118  time: 0.4015  data_time: 0.0315  lr: 0.0019623  max_mem: 7924M
[12/11 21:28:02 d2.utils.events]:  eta: 0:50:53  iter: 2379  total_loss: 2.684  loss_sem_seg: 1.312  loss_center: 0.5596  loss_offset: 0.7191  time: 0.4015  data_time: 0.0306  lr: 0.0019577  max_mem: 7924M
[12/11 21:28:10 d2.utils.events]:  eta: 0:50:46  iter: 2399  total_loss: 2.702  loss_sem_seg: 1.411  loss_center: 0.5744  loss_offset: 0.6862  time: 0.4015  data_time: 0.0312  lr: 0.0019531  max_mem: 7924M
[12/11 21:28:18 d2.utils.events]:  eta: 0:50:37  iter: 2419  total_loss: 2.604  loss_sem_seg: 1.271  loss_center: 0.5664  loss_offset: 0.6577  time: 0.4015  data_time: 0.0286  lr: 0.0019485  max_mem: 7924M
[12/11 21:28:27 d2.utils.events]:  eta: 0:50:31  iter: 2439  total_loss: 2.805  loss_sem_seg: 1.338  loss_center: 0.6391  loss_offset: 0.6506  time: 0.4015  data_time: 0.0312  lr: 0.0019438  max_mem: 7924M
[12/11 21:28:35 d2.utils.events]:  eta: 0:50:23  iter: 2459  total_loss: 2.945  loss_sem_seg: 1.372  loss_center: 0.5225  loss_offset: 0.7656  time: 0.4015  data_time: 0.0308  lr: 0.0019392  max_mem: 7924M
[12/11 21:28:43 d2.utils.events]:  eta: 0:50:15  iter: 2479  total_loss: 2.729  loss_sem_seg: 1.299  loss_center: 0.5218  loss_offset: 0.6628  time: 0.4015  data_time: 0.0294  lr: 0.0019346  max_mem: 7924M
[12/11 21:28:51 d2.utils.events]:  eta: 0:50:08  iter: 2499  total_loss: 2.817  loss_sem_seg: 1.515  loss_center: 0.5484  loss_offset: 0.7428  time: 0.4015  data_time: 0.0312  lr: 0.00193  max_mem: 7924M
[12/11 21:28:59 d2.utils.events]:  eta: 0:49:58  iter: 2519  total_loss: 2.834  loss_sem_seg: 1.514  loss_center: 0.6558  loss_offset: 0.6715  time: 0.4015  data_time: 0.0297  lr: 0.0019253  max_mem: 7924M
[12/11 21:29:07 d2.utils.events]:  eta: 0:49:50  iter: 2539  total_loss: 2.915  loss_sem_seg: 1.521  loss_center: 0.6256  loss_offset: 0.6714  time: 0.4015  data_time: 0.0309  lr: 0.0019207  max_mem: 7924M
[12/11 21:29:15 d2.utils.events]:  eta: 0:49:42  iter: 2559  total_loss: 2.62  loss_sem_seg: 1.424  loss_center: 0.5189  loss_offset: 0.637  time: 0.4015  data_time: 0.0315  lr: 0.0019161  max_mem: 7924M
[12/11 21:29:23 d2.utils.events]:  eta: 0:49:35  iter: 2579  total_loss: 2.656  loss_sem_seg: 1.313  loss_center: 0.5404  loss_offset: 0.7631  time: 0.4015  data_time: 0.0306  lr: 0.0019114  max_mem: 7924M
[12/11 21:29:31 d2.utils.events]:  eta: 0:49:27  iter: 2599  total_loss: 2.746  loss_sem_seg: 1.371  loss_center: 0.5192  loss_offset: 0.742  time: 0.4015  data_time: 0.0296  lr: 0.0019068  max_mem: 7924M
[12/11 21:29:39 d2.utils.events]:  eta: 0:49:20  iter: 2619  total_loss: 2.577  loss_sem_seg: 1.255  loss_center: 0.5433  loss_offset: 0.637  time: 0.4015  data_time: 0.0312  lr: 0.0019021  max_mem: 7924M
[12/11 21:29:47 d2.utils.events]:  eta: 0:49:13  iter: 2639  total_loss: 2.714  loss_sem_seg: 1.458  loss_center: 0.5096  loss_offset: 0.7678  time: 0.4015  data_time: 0.0299  lr: 0.0018975  max_mem: 7924M
[12/11 21:29:55 d2.utils.events]:  eta: 0:49:04  iter: 2659  total_loss: 2.671  loss_sem_seg: 1.29  loss_center: 0.6531  loss_offset: 0.7033  time: 0.4015  data_time: 0.0310  lr: 0.0018929  max_mem: 7924M
[12/11 21:30:03 d2.utils.events]:  eta: 0:48:56  iter: 2679  total_loss: 2.569  loss_sem_seg: 1.311  loss_center: 0.5931  loss_offset: 0.6409  time: 0.4015  data_time: 0.0303  lr: 0.0018882  max_mem: 7924M
[12/11 21:30:11 d2.utils.events]:  eta: 0:48:48  iter: 2699  total_loss: 2.739  loss_sem_seg: 1.374  loss_center: 0.6725  loss_offset: 0.6474  time: 0.4015  data_time: 0.0308  lr: 0.0018836  max_mem: 7924M
[12/11 21:30:19 d2.utils.events]:  eta: 0:48:40  iter: 2719  total_loss: 2.6  loss_sem_seg: 1.167  loss_center: 0.6188  loss_offset: 0.7029  time: 0.4015  data_time: 0.0305  lr: 0.0018789  max_mem: 7924M
[12/11 21:30:27 d2.utils.events]:  eta: 0:48:32  iter: 2739  total_loss: 2.61  loss_sem_seg: 1.326  loss_center: 0.672  loss_offset: 0.724  time: 0.4015  data_time: 0.0303  lr: 0.0018743  max_mem: 7924M
[12/11 21:30:35 d2.utils.events]:  eta: 0:48:24  iter: 2759  total_loss: 2.523  loss_sem_seg: 1.429  loss_center: 0.5768  loss_offset: 0.6651  time: 0.4015  data_time: 0.0309  lr: 0.0018696  max_mem: 7924M
[12/11 21:30:43 d2.utils.events]:  eta: 0:48:16  iter: 2779  total_loss: 2.531  loss_sem_seg: 1.306  loss_center: 0.6362  loss_offset: 0.6143  time: 0.4015  data_time: 0.0290  lr: 0.001865  max_mem: 7924M
[12/11 21:30:51 d2.utils.events]:  eta: 0:48:08  iter: 2799  total_loss: 2.524  loss_sem_seg: 1.257  loss_center: 0.5367  loss_offset: 0.6227  time: 0.4015  data_time: 0.0306  lr: 0.0018603  max_mem: 7924M
[12/11 21:30:59 d2.utils.events]:  eta: 0:48:01  iter: 2819  total_loss: 2.437  loss_sem_seg: 1.198  loss_center: 0.5034  loss_offset: 0.6186  time: 0.4015  data_time: 0.0306  lr: 0.0018557  max_mem: 7924M
[12/11 21:31:07 d2.utils.events]:  eta: 0:47:52  iter: 2839  total_loss: 2.568  loss_sem_seg: 1.276  loss_center: 0.5257  loss_offset: 0.6411  time: 0.4015  data_time: 0.0279  lr: 0.001851  max_mem: 7924M
[12/11 21:31:15 d2.utils.events]:  eta: 0:47:44  iter: 2859  total_loss: 2.529  loss_sem_seg: 1.216  loss_center: 0.5728  loss_offset: 0.6232  time: 0.4015  data_time: 0.0298  lr: 0.0018464  max_mem: 7924M
[12/11 21:31:23 d2.utils.events]:  eta: 0:47:36  iter: 2879  total_loss: 2.586  loss_sem_seg: 1.243  loss_center: 0.6021  loss_offset: 0.7204  time: 0.4015  data_time: 0.0305  lr: 0.0018417  max_mem: 7924M
[12/11 21:31:31 d2.utils.events]:  eta: 0:47:26  iter: 2899  total_loss: 2.741  loss_sem_seg: 1.265  loss_center: 0.6438  loss_offset: 0.728  time: 0.4014  data_time: 0.0297  lr: 0.0018371  max_mem: 7924M
[12/11 21:31:39 d2.utils.events]:  eta: 0:47:19  iter: 2919  total_loss: 2.511  loss_sem_seg: 1.236  loss_center: 0.5241  loss_offset: 0.6355  time: 0.4014  data_time: 0.0308  lr: 0.0018324  max_mem: 7924M
[12/11 21:31:47 d2.utils.events]:  eta: 0:47:10  iter: 2939  total_loss: 2.648  loss_sem_seg: 1.468  loss_center: 0.4964  loss_offset: 0.6692  time: 0.4014  data_time: 0.0300  lr: 0.0018278  max_mem: 7924M
[12/11 21:31:56 d2.utils.events]:  eta: 0:47:01  iter: 2959  total_loss: 2.413  loss_sem_seg: 1.371  loss_center: 0.49  loss_offset: 0.6282  time: 0.4014  data_time: 0.0287  lr: 0.0018231  max_mem: 7924M
[12/11 21:32:03 d2.utils.events]:  eta: 0:46:53  iter: 2979  total_loss: 2.36  loss_sem_seg: 1.179  loss_center: 0.597  loss_offset: 0.5711  time: 0.4014  data_time: 0.0290  lr: 0.0018184  max_mem: 7924M
[12/11 21:32:12 d2.utils.events]:  eta: 0:46:46  iter: 2999  total_loss: 2.789  loss_sem_seg: 1.35  loss_center: 0.5761  loss_offset: 0.6918  time: 0.4014  data_time: 0.0312  lr: 0.0018138  max_mem: 7924M
[12/11 21:32:20 d2.utils.events]:  eta: 0:46:39  iter: 3019  total_loss: 2.525  loss_sem_seg: 1.252  loss_center: 0.4915  loss_offset: 0.6119  time: 0.4014  data_time: 0.0300  lr: 0.0018091  max_mem: 7924M
[12/11 21:32:28 d2.utils.events]:  eta: 0:46:31  iter: 3039  total_loss: 2.709  loss_sem_seg: 1.36  loss_center: 0.6545  loss_offset: 0.5769  time: 0.4014  data_time: 0.0289  lr: 0.0018044  max_mem: 7924M
[12/11 21:32:36 d2.utils.events]:  eta: 0:46:23  iter: 3059  total_loss: 2.643  loss_sem_seg: 1.343  loss_center: 0.561  loss_offset: 0.6467  time: 0.4014  data_time: 0.0303  lr: 0.0017998  max_mem: 7924M
[12/11 21:32:44 d2.utils.events]:  eta: 0:46:16  iter: 3079  total_loss: 2.635  loss_sem_seg: 1.339  loss_center: 0.46  loss_offset: 0.7452  time: 0.4014  data_time: 0.0313  lr: 0.0017951  max_mem: 7924M
[12/11 21:32:52 d2.utils.events]:  eta: 0:46:07  iter: 3099  total_loss: 2.518  loss_sem_seg: 1.263  loss_center: 0.6549  loss_offset: 0.621  time: 0.4014  data_time: 0.0303  lr: 0.0017904  max_mem: 7924M
[12/11 21:33:00 d2.utils.events]:  eta: 0:45:58  iter: 3119  total_loss: 2.767  loss_sem_seg: 1.452  loss_center: 0.491  loss_offset: 0.636  time: 0.4014  data_time: 0.0279  lr: 0.0017858  max_mem: 7924M
[12/11 21:33:08 d2.utils.events]:  eta: 0:45:52  iter: 3139  total_loss: 2.552  loss_sem_seg: 1.259  loss_center: 0.6326  loss_offset: 0.6438  time: 0.4014  data_time: 0.0289  lr: 0.0017811  max_mem: 7924M
[12/11 21:33:16 d2.utils.events]:  eta: 0:45:43  iter: 3159  total_loss: 2.36  loss_sem_seg: 1.177  loss_center: 0.436  loss_offset: 0.6617  time: 0.4014  data_time: 0.0299  lr: 0.0017764  max_mem: 7924M
[12/11 21:33:24 d2.utils.events]:  eta: 0:45:34  iter: 3179  total_loss: 2.718  loss_sem_seg: 1.345  loss_center: 0.5972  loss_offset: 0.6654  time: 0.4014  data_time: 0.0282  lr: 0.0017718  max_mem: 7924M
[12/11 21:33:32 d2.utils.events]:  eta: 0:45:27  iter: 3199  total_loss: 2.693  loss_sem_seg: 1.274  loss_center: 0.6622  loss_offset: 0.756  time: 0.4014  data_time: 0.0305  lr: 0.0017671  max_mem: 7924M
[12/11 21:33:40 d2.utils.events]:  eta: 0:45:20  iter: 3219  total_loss: 2.83  loss_sem_seg: 1.5  loss_center: 0.6475  loss_offset: 0.7086  time: 0.4014  data_time: 0.0302  lr: 0.0017624  max_mem: 7924M
[12/11 21:33:48 d2.utils.events]:  eta: 0:45:12  iter: 3239  total_loss: 2.539  loss_sem_seg: 1.362  loss_center: 0.5032  loss_offset: 0.673  time: 0.4014  data_time: 0.0309  lr: 0.0017577  max_mem: 7924M
[12/11 21:33:56 d2.utils.events]:  eta: 0:45:04  iter: 3259  total_loss: 2.579  loss_sem_seg: 1.261  loss_center: 0.5141  loss_offset: 0.5962  time: 0.4014  data_time: 0.0279  lr: 0.001753  max_mem: 7924M
[12/11 21:34:04 d2.utils.events]:  eta: 0:44:56  iter: 3279  total_loss: 2.495  loss_sem_seg: 1.204  loss_center: 0.5317  loss_offset: 0.6169  time: 0.4014  data_time: 0.0295  lr: 0.0017484  max_mem: 7924M
[12/11 21:34:12 d2.utils.events]:  eta: 0:44:48  iter: 3299  total_loss: 2.671  loss_sem_seg: 1.283  loss_center: 0.5979  loss_offset: 0.6485  time: 0.4014  data_time: 0.0311  lr: 0.0017437  max_mem: 7924M
[12/11 21:34:20 d2.utils.events]:  eta: 0:44:40  iter: 3319  total_loss: 2.31  loss_sem_seg: 1.228  loss_center: 0.5823  loss_offset: 0.6817  time: 0.4014  data_time: 0.0299  lr: 0.001739  max_mem: 7924M
[12/11 21:34:28 d2.utils.events]:  eta: 0:44:32  iter: 3339  total_loss: 2.485  loss_sem_seg: 1.086  loss_center: 0.6555  loss_offset: 0.5947  time: 0.4014  data_time: 0.0300  lr: 0.0017343  max_mem: 7924M
[12/11 21:34:36 d2.utils.events]:  eta: 0:44:23  iter: 3359  total_loss: 2.303  loss_sem_seg: 1.155  loss_center: 0.4629  loss_offset: 0.6117  time: 0.4014  data_time: 0.0294  lr: 0.0017296  max_mem: 7924M
[12/11 21:34:44 d2.utils.events]:  eta: 0:44:15  iter: 3379  total_loss: 2.313  loss_sem_seg: 1.23  loss_center: 0.5051  loss_offset: 0.5525  time: 0.4014  data_time: 0.0305  lr: 0.0017249  max_mem: 7924M
[12/11 21:34:52 d2.utils.events]:  eta: 0:44:07  iter: 3399  total_loss: 2.275  loss_sem_seg: 1.211  loss_center: 0.5266  loss_offset: 0.696  time: 0.4014  data_time: 0.0280  lr: 0.0017202  max_mem: 7924M
[12/11 21:35:00 d2.utils.events]:  eta: 0:43:59  iter: 3419  total_loss: 2.661  loss_sem_seg: 1.388  loss_center: 0.622  loss_offset: 0.6707  time: 0.4013  data_time: 0.0291  lr: 0.0017155  max_mem: 7924M
[12/11 21:35:08 d2.utils.events]:  eta: 0:43:50  iter: 3439  total_loss: 2.61  loss_sem_seg: 1.194  loss_center: 0.5154  loss_offset: 0.7744  time: 0.4013  data_time: 0.0320  lr: 0.0017109  max_mem: 7924M
[12/11 21:35:16 d2.utils.events]:  eta: 0:43:42  iter: 3459  total_loss: 2.524  loss_sem_seg: 1.214  loss_center: 0.6031  loss_offset: 0.6511  time: 0.4014  data_time: 0.0319  lr: 0.0017062  max_mem: 7924M
[12/11 21:35:24 d2.utils.events]:  eta: 0:43:34  iter: 3479  total_loss: 2.886  loss_sem_seg: 1.429  loss_center: 0.6085  loss_offset: 0.6923  time: 0.4013  data_time: 0.0293  lr: 0.0017015  max_mem: 7924M
[12/11 21:35:32 d2.utils.events]:  eta: 0:43:25  iter: 3499  total_loss: 2.223  loss_sem_seg: 1.171  loss_center: 0.5031  loss_offset: 0.5948  time: 0.4013  data_time: 0.0292  lr: 0.0016968  max_mem: 7924M
[12/11 21:35:40 d2.utils.events]:  eta: 0:43:18  iter: 3519  total_loss: 2.165  loss_sem_seg: 1.111  loss_center: 0.5295  loss_offset: 0.61  time: 0.4013  data_time: 0.0303  lr: 0.0016921  max_mem: 7924M
[12/11 21:35:48 d2.utils.events]:  eta: 0:43:08  iter: 3539  total_loss: 2.306  loss_sem_seg: 1.196  loss_center: 0.555  loss_offset: 0.6926  time: 0.4013  data_time: 0.0297  lr: 0.0016874  max_mem: 7924M
[12/11 21:35:56 d2.utils.events]:  eta: 0:43:00  iter: 3559  total_loss: 2.455  loss_sem_seg: 1.153  loss_center: 0.3864  loss_offset: 0.6308  time: 0.4013  data_time: 0.0297  lr: 0.0016827  max_mem: 7924M
[12/11 21:36:04 d2.utils.events]:  eta: 0:42:52  iter: 3579  total_loss: 2.497  loss_sem_seg: 1.259  loss_center: 0.5986  loss_offset: 0.7422  time: 0.4013  data_time: 0.0288  lr: 0.001678  max_mem: 7924M
[12/11 21:36:12 d2.utils.events]:  eta: 0:42:45  iter: 3599  total_loss: 2.511  loss_sem_seg: 1.264  loss_center: 0.4577  loss_offset: 0.7717  time: 0.4013  data_time: 0.0297  lr: 0.0016733  max_mem: 7924M
[12/11 21:36:20 d2.utils.events]:  eta: 0:42:37  iter: 3619  total_loss: 2.426  loss_sem_seg: 1.09  loss_center: 0.6466  loss_offset: 0.5645  time: 0.4013  data_time: 0.0282  lr: 0.0016686  max_mem: 7924M
[12/11 21:36:28 d2.utils.events]:  eta: 0:42:28  iter: 3639  total_loss: 2.402  loss_sem_seg: 1.343  loss_center: 0.4732  loss_offset: 0.6705  time: 0.4013  data_time: 0.0312  lr: 0.0016638  max_mem: 7924M
[12/11 21:36:37 d2.utils.events]:  eta: 0:42:21  iter: 3659  total_loss: 2.782  loss_sem_seg: 1.311  loss_center: 0.6312  loss_offset: 0.6495  time: 0.4013  data_time: 0.0305  lr: 0.0016591  max_mem: 7924M
[12/11 21:36:45 d2.utils.events]:  eta: 0:42:13  iter: 3679  total_loss: 2.453  loss_sem_seg: 1.217  loss_center: 0.4702  loss_offset: 0.6911  time: 0.4013  data_time: 0.0311  lr: 0.0016544  max_mem: 7924M
[12/11 21:36:53 d2.utils.events]:  eta: 0:42:05  iter: 3699  total_loss: 2.804  loss_sem_seg: 1.374  loss_center: 0.5865  loss_offset: 0.7249  time: 0.4013  data_time: 0.0288  lr: 0.0016497  max_mem: 7924M
[12/11 21:37:01 d2.utils.events]:  eta: 0:41:57  iter: 3719  total_loss: 2.725  loss_sem_seg: 1.306  loss_center: 0.6881  loss_offset: 0.6946  time: 0.4013  data_time: 0.0296  lr: 0.001645  max_mem: 7924M
[12/11 21:37:09 d2.utils.events]:  eta: 0:41:49  iter: 3739  total_loss: 2.648  loss_sem_seg: 1.207  loss_center: 0.5457  loss_offset: 0.6682  time: 0.4013  data_time: 0.0312  lr: 0.0016403  max_mem: 7924M
[12/11 21:37:17 d2.utils.events]:  eta: 0:41:41  iter: 3759  total_loss: 2.383  loss_sem_seg: 1.126  loss_center: 0.5421  loss_offset: 0.6523  time: 0.4013  data_time: 0.0297  lr: 0.0016356  max_mem: 7924M
[12/11 21:37:25 d2.utils.events]:  eta: 0:41:32  iter: 3779  total_loss: 2.204  loss_sem_seg: 1.121  loss_center: 0.4243  loss_offset: 0.7221  time: 0.4013  data_time: 0.0294  lr: 0.0016309  max_mem: 7924M
[12/11 21:37:33 d2.utils.events]:  eta: 0:41:23  iter: 3799  total_loss: 2.38  loss_sem_seg: 1.199  loss_center: 0.4197  loss_offset: 0.6608  time: 0.4013  data_time: 0.0309  lr: 0.0016261  max_mem: 7924M
[12/11 21:37:41 d2.utils.events]:  eta: 0:41:14  iter: 3819  total_loss: 2.623  loss_sem_seg: 1.324  loss_center: 0.4924  loss_offset: 0.5832  time: 0.4013  data_time: 0.0304  lr: 0.0016214  max_mem: 7924M
[12/11 21:37:49 d2.utils.events]:  eta: 0:41:06  iter: 3839  total_loss: 2.662  loss_sem_seg: 1.187  loss_center: 0.6397  loss_offset: 0.5835  time: 0.4013  data_time: 0.0310  lr: 0.0016167  max_mem: 7924M
[12/11 21:37:57 d2.utils.events]:  eta: 0:40:58  iter: 3859  total_loss: 2.412  loss_sem_seg: 1.212  loss_center: 0.5654  loss_offset: 0.6797  time: 0.4013  data_time: 0.0293  lr: 0.001612  max_mem: 7924M
[12/11 21:38:05 d2.utils.events]:  eta: 0:40:50  iter: 3879  total_loss: 2.722  loss_sem_seg: 1.268  loss_center: 0.6394  loss_offset: 0.736  time: 0.4013  data_time: 0.0318  lr: 0.0016072  max_mem: 7924M
[12/11 21:38:13 d2.utils.events]:  eta: 0:40:43  iter: 3899  total_loss: 2.329  loss_sem_seg: 1.198  loss_center: 0.4922  loss_offset: 0.5515  time: 0.4013  data_time: 0.0302  lr: 0.0016025  max_mem: 7924M
[12/11 21:38:21 d2.utils.events]:  eta: 0:40:34  iter: 3919  total_loss: 2.497  loss_sem_seg: 1.286  loss_center: 0.4793  loss_offset: 0.6857  time: 0.4013  data_time: 0.0293  lr: 0.0015978  max_mem: 7924M
[12/11 21:38:29 d2.utils.events]:  eta: 0:40:27  iter: 3939  total_loss: 2.594  loss_sem_seg: 1.405  loss_center: 0.5507  loss_offset: 0.7292  time: 0.4013  data_time: 0.0312  lr: 0.0015931  max_mem: 7924M
[12/11 21:38:37 d2.utils.events]:  eta: 0:40:19  iter: 3959  total_loss: 2.639  loss_sem_seg: 1.332  loss_center: 0.4468  loss_offset: 0.7054  time: 0.4013  data_time: 0.0301  lr: 0.0015883  max_mem: 7924M
[12/11 21:38:45 d2.utils.events]:  eta: 0:40:10  iter: 3979  total_loss: 2.106  loss_sem_seg: 0.9791  loss_center: 0.5318  loss_offset: 0.5911  time: 0.4013  data_time: 0.0305  lr: 0.0015836  max_mem: 7924M
[12/11 21:38:53 d2.utils.events]:  eta: 0:40:03  iter: 3999  total_loss: 2.612  loss_sem_seg: 1.087  loss_center: 0.6674  loss_offset: 0.6903  time: 0.4013  data_time: 0.0301  lr: 0.0015789  max_mem: 7924M
[12/11 21:39:01 d2.utils.events]:  eta: 0:39:54  iter: 4019  total_loss: 2.345  loss_sem_seg: 1.237  loss_center: 0.5591  loss_offset: 0.6155  time: 0.4013  data_time: 0.0299  lr: 0.0015741  max_mem: 7924M
[12/11 21:39:09 d2.utils.events]:  eta: 0:39:46  iter: 4039  total_loss: 2.404  loss_sem_seg: 1.208  loss_center: 0.5407  loss_offset: 0.6475  time: 0.4013  data_time: 0.0304  lr: 0.0015694  max_mem: 7924M
[12/11 21:39:17 d2.utils.events]:  eta: 0:39:38  iter: 4059  total_loss: 2.484  loss_sem_seg: 1.217  loss_center: 0.5249  loss_offset: 0.5769  time: 0.4013  data_time: 0.0289  lr: 0.0015646  max_mem: 7924M
[12/11 21:39:25 d2.utils.events]:  eta: 0:39:30  iter: 4079  total_loss: 2.399  loss_sem_seg: 1.04  loss_center: 0.5979  loss_offset: 0.6336  time: 0.4013  data_time: 0.0296  lr: 0.0015599  max_mem: 7924M
[12/11 21:39:33 d2.utils.events]:  eta: 0:39:22  iter: 4099  total_loss: 2.448  loss_sem_seg: 1.141  loss_center: 0.6406  loss_offset: 0.6018  time: 0.4013  data_time: 0.0310  lr: 0.0015552  max_mem: 7924M
[12/11 21:39:41 d2.utils.events]:  eta: 0:39:14  iter: 4119  total_loss: 2.138  loss_sem_seg: 1.131  loss_center: 0.4754  loss_offset: 0.4797  time: 0.4013  data_time: 0.0303  lr: 0.0015504  max_mem: 7924M
[12/11 21:39:49 d2.utils.events]:  eta: 0:39:05  iter: 4139  total_loss: 2.387  loss_sem_seg: 1.22  loss_center: 0.6065  loss_offset: 0.5724  time: 0.4013  data_time: 0.0304  lr: 0.0015457  max_mem: 7924M
[12/11 21:39:57 d2.utils.events]:  eta: 0:38:57  iter: 4159  total_loss: 2.322  loss_sem_seg: 1.151  loss_center: 0.4876  loss_offset: 0.6848  time: 0.4013  data_time: 0.0302  lr: 0.0015409  max_mem: 7924M
[12/11 21:40:05 d2.utils.events]:  eta: 0:38:49  iter: 4179  total_loss: 2.716  loss_sem_seg: 1.32  loss_center: 0.6366  loss_offset: 0.6887  time: 0.4013  data_time: 0.0307  lr: 0.0015362  max_mem: 7924M
[12/11 21:40:13 d2.utils.events]:  eta: 0:38:41  iter: 4199  total_loss: 2.52  loss_sem_seg: 1.166  loss_center: 0.5632  loss_offset: 0.7371  time: 0.4013  data_time: 0.0297  lr: 0.0015314  max_mem: 7924M
[12/11 21:40:21 d2.utils.events]:  eta: 0:38:32  iter: 4219  total_loss: 2.547  loss_sem_seg: 1.336  loss_center: 0.5171  loss_offset: 0.6313  time: 0.4013  data_time: 0.0314  lr: 0.0015267  max_mem: 7924M
[12/11 21:40:30 d2.utils.events]:  eta: 0:38:24  iter: 4239  total_loss: 2.445  loss_sem_seg: 1.209  loss_center: 0.5106  loss_offset: 0.6542  time: 0.4013  data_time: 0.0305  lr: 0.0015219  max_mem: 7924M
[12/11 21:40:38 d2.utils.events]:  eta: 0:38:16  iter: 4259  total_loss: 2.571  loss_sem_seg: 1.265  loss_center: 0.5442  loss_offset: 0.5167  time: 0.4013  data_time: 0.0287  lr: 0.0015172  max_mem: 7924M
[12/11 21:40:46 d2.utils.events]:  eta: 0:38:07  iter: 4279  total_loss: 2.668  loss_sem_seg: 1.362  loss_center: 0.58  loss_offset: 0.7355  time: 0.4013  data_time: 0.0319  lr: 0.0015124  max_mem: 7924M
[12/11 21:40:54 d2.utils.events]:  eta: 0:38:00  iter: 4299  total_loss: 2.207  loss_sem_seg: 1.129  loss_center: 0.4497  loss_offset: 0.626  time: 0.4013  data_time: 0.0300  lr: 0.0015076  max_mem: 7924M
[12/11 21:41:02 d2.utils.events]:  eta: 0:37:53  iter: 4319  total_loss: 2.324  loss_sem_seg: 1.243  loss_center: 0.5528  loss_offset: 0.5701  time: 0.4013  data_time: 0.0300  lr: 0.0015029  max_mem: 7924M
[12/11 21:41:10 d2.utils.events]:  eta: 0:37:45  iter: 4339  total_loss: 2.354  loss_sem_seg: 1.143  loss_center: 0.6148  loss_offset: 0.5975  time: 0.4013  data_time: 0.0300  lr: 0.0014981  max_mem: 7924M
[12/11 21:41:18 d2.utils.events]:  eta: 0:37:37  iter: 4359  total_loss: 2.75  loss_sem_seg: 1.376  loss_center: 0.5862  loss_offset: 0.7015  time: 0.4013  data_time: 0.0302  lr: 0.0014933  max_mem: 7924M
[12/11 21:41:26 d2.utils.events]:  eta: 0:37:28  iter: 4379  total_loss: 2.1  loss_sem_seg: 1.047  loss_center: 0.5449  loss_offset: 0.4901  time: 0.4013  data_time: 0.0298  lr: 0.0014886  max_mem: 7924M
[12/11 21:41:34 d2.utils.events]:  eta: 0:37:20  iter: 4399  total_loss: 2.242  loss_sem_seg: 0.9922  loss_center: 0.5219  loss_offset: 0.5717  time: 0.4013  data_time: 0.0288  lr: 0.0014838  max_mem: 7924M
[12/11 21:41:42 d2.utils.events]:  eta: 0:37:12  iter: 4419  total_loss: 2.794  loss_sem_seg: 1.172  loss_center: 0.6376  loss_offset: 0.6989  time: 0.4013  data_time: 0.0319  lr: 0.001479  max_mem: 7924M
[12/11 21:41:50 d2.utils.events]:  eta: 0:37:03  iter: 4439  total_loss: 2.421  loss_sem_seg: 1.09  loss_center: 0.6161  loss_offset: 0.6069  time: 0.4013  data_time: 0.0274  lr: 0.0014743  max_mem: 7924M
[12/11 21:41:58 d2.utils.events]:  eta: 0:36:55  iter: 4459  total_loss: 2.428  loss_sem_seg: 1.269  loss_center: 0.5469  loss_offset: 0.5774  time: 0.4013  data_time: 0.0295  lr: 0.0014695  max_mem: 7924M
[12/11 21:42:06 d2.utils.events]:  eta: 0:36:47  iter: 4479  total_loss: 2.533  loss_sem_seg: 1.324  loss_center: 0.6144  loss_offset: 0.6923  time: 0.4013  data_time: 0.0316  lr: 0.0014647  max_mem: 7924M
[12/11 21:42:14 d2.utils.events]:  eta: 0:36:40  iter: 4499  total_loss: 2.375  loss_sem_seg: 1.082  loss_center: 0.6126  loss_offset: 0.5879  time: 0.4012  data_time: 0.0298  lr: 0.0014599  max_mem: 7924M
[12/11 21:42:22 d2.utils.events]:  eta: 0:36:32  iter: 4519  total_loss: 2.651  loss_sem_seg: 1.319  loss_center: 0.569  loss_offset: 0.7215  time: 0.4013  data_time: 0.0306  lr: 0.0014552  max_mem: 7924M
[12/11 21:42:30 d2.utils.events]:  eta: 0:36:24  iter: 4539  total_loss: 2.396  loss_sem_seg: 1.13  loss_center: 0.4971  loss_offset: 0.6583  time: 0.4012  data_time: 0.0291  lr: 0.0014504  max_mem: 7924M
[12/11 21:42:38 d2.utils.events]:  eta: 0:36:15  iter: 4559  total_loss: 2.579  loss_sem_seg: 1.362  loss_center: 0.5495  loss_offset: 0.5562  time: 0.4012  data_time: 0.0286  lr: 0.0014456  max_mem: 7924M
[12/11 21:42:46 d2.utils.events]:  eta: 0:36:07  iter: 4579  total_loss: 2.522  loss_sem_seg: 1.36  loss_center: 0.48  loss_offset: 0.6656  time: 0.4012  data_time: 0.0296  lr: 0.0014408  max_mem: 7924M
[12/11 21:42:54 d2.utils.events]:  eta: 0:35:59  iter: 4599  total_loss: 2.669  loss_sem_seg: 1.352  loss_center: 0.5057  loss_offset: 0.5816  time: 0.4012  data_time: 0.0306  lr: 0.001436  max_mem: 7924M
[12/11 21:43:02 d2.utils.events]:  eta: 0:35:51  iter: 4619  total_loss: 2.338  loss_sem_seg: 1.169  loss_center: 0.5953  loss_offset: 0.5388  time: 0.4012  data_time: 0.0295  lr: 0.0014313  max_mem: 7924M
[12/11 21:43:10 d2.utils.events]:  eta: 0:35:42  iter: 4639  total_loss: 2.364  loss_sem_seg: 1.325  loss_center: 0.4823  loss_offset: 0.6007  time: 0.4012  data_time: 0.0288  lr: 0.0014265  max_mem: 7924M
[12/11 21:43:18 d2.utils.events]:  eta: 0:35:35  iter: 4659  total_loss: 2.285  loss_sem_seg: 1.057  loss_center: 0.5296  loss_offset: 0.6037  time: 0.4012  data_time: 0.0312  lr: 0.0014217  max_mem: 7924M
[12/11 21:43:26 d2.utils.events]:  eta: 0:35:26  iter: 4679  total_loss: 2.507  loss_sem_seg: 1.229  loss_center: 0.6151  loss_offset: 0.6516  time: 0.4012  data_time: 0.0278  lr: 0.0014169  max_mem: 7924M
[12/11 21:43:34 d2.utils.events]:  eta: 0:35:18  iter: 4699  total_loss: 2.318  loss_sem_seg: 1.15  loss_center: 0.4642  loss_offset: 0.6249  time: 0.4012  data_time: 0.0315  lr: 0.0014121  max_mem: 7924M
[12/11 21:43:42 d2.utils.events]:  eta: 0:35:10  iter: 4719  total_loss: 2.559  loss_sem_seg: 1.098  loss_center: 0.6059  loss_offset: 0.765  time: 0.4012  data_time: 0.0291  lr: 0.0014073  max_mem: 7924M
[12/11 21:43:50 d2.utils.events]:  eta: 0:35:02  iter: 4739  total_loss: 2.315  loss_sem_seg: 1.087  loss_center: 0.4297  loss_offset: 0.7238  time: 0.4012  data_time: 0.0284  lr: 0.0014025  max_mem: 7924M
[12/11 21:43:58 d2.utils.events]:  eta: 0:34:53  iter: 4759  total_loss: 2.471  loss_sem_seg: 1.253  loss_center: 0.5661  loss_offset: 0.6312  time: 0.4012  data_time: 0.0295  lr: 0.0013977  max_mem: 7924M
[12/11 21:44:06 d2.utils.events]:  eta: 0:34:45  iter: 4779  total_loss: 2.422  loss_sem_seg: 1.211  loss_center: 0.587  loss_offset: 0.5944  time: 0.4012  data_time: 0.0290  lr: 0.0013929  max_mem: 7924M
[12/11 21:44:14 d2.utils.events]:  eta: 0:34:37  iter: 4799  total_loss: 2.459  loss_sem_seg: 1.248  loss_center: 0.5352  loss_offset: 0.6458  time: 0.4012  data_time: 0.0291  lr: 0.0013881  max_mem: 7924M
[12/11 21:44:22 d2.utils.events]:  eta: 0:34:29  iter: 4819  total_loss: 2.295  loss_sem_seg: 1.037  loss_center: 0.6055  loss_offset: 0.5923  time: 0.4012  data_time: 0.0327  lr: 0.0013833  max_mem: 7924M
[12/11 21:44:30 d2.utils.events]:  eta: 0:34:21  iter: 4839  total_loss: 2.441  loss_sem_seg: 1.229  loss_center: 0.6639  loss_offset: 0.5186  time: 0.4012  data_time: 0.0314  lr: 0.0013785  max_mem: 7924M
[12/11 21:44:38 d2.utils.events]:  eta: 0:34:13  iter: 4859  total_loss: 2.141  loss_sem_seg: 1.067  loss_center: 0.5024  loss_offset: 0.5604  time: 0.4012  data_time: 0.0291  lr: 0.0013737  max_mem: 7924M
[12/11 21:44:46 d2.utils.events]:  eta: 0:34:04  iter: 4879  total_loss: 2.407  loss_sem_seg: 1.037  loss_center: 0.6233  loss_offset: 0.6337  time: 0.4012  data_time: 0.0293  lr: 0.0013689  max_mem: 7924M
[12/11 21:44:54 d2.utils.events]:  eta: 0:33:57  iter: 4899  total_loss: 2.476  loss_sem_seg: 1.226  loss_center: 0.554  loss_offset: 0.6003  time: 0.4012  data_time: 0.0305  lr: 0.001364  max_mem: 7924M
[12/11 21:45:02 d2.utils.events]:  eta: 0:33:49  iter: 4919  total_loss: 2.45  loss_sem_seg: 1.236  loss_center: 0.5726  loss_offset: 0.5437  time: 0.4012  data_time: 0.0284  lr: 0.0013592  max_mem: 7924M
[12/11 21:45:10 d2.utils.events]:  eta: 0:33:41  iter: 4939  total_loss: 2.615  loss_sem_seg: 1.302  loss_center: 0.6566  loss_offset: 0.673  time: 0.4012  data_time: 0.0308  lr: 0.0013544  max_mem: 7924M
[12/11 21:45:18 d2.utils.events]:  eta: 0:33:33  iter: 4959  total_loss: 2.268  loss_sem_seg: 0.992  loss_center: 0.5637  loss_offset: 0.7691  time: 0.4012  data_time: 0.0289  lr: 0.0013496  max_mem: 7924M
[12/11 21:45:26 d2.utils.events]:  eta: 0:33:24  iter: 4979  total_loss: 2.229  loss_sem_seg: 1.091  loss_center: 0.5637  loss_offset: 0.5701  time: 0.4011  data_time: 0.0302  lr: 0.0013448  max_mem: 7924M
[12/11 21:45:34 fvcore.common.checkpoint]: Saving checkpoint to ./output/model_0004999.pth
[12/11 21:45:35 d2.utils.events]:  eta: 0:33:16  iter: 4999  total_loss: 2.405  loss_sem_seg: 1.322  loss_center: 0.4835  loss_offset: 0.7415  time: 0.4012  data_time: 0.0325  lr: 0.00134  max_mem: 7924M
[12/11 21:45:44 d2.utils.events]:  eta: 0:33:08  iter: 5019  total_loss: 2.394  loss_sem_seg: 1.203  loss_center: 0.5316  loss_offset: 0.6461  time: 0.4011  data_time: 0.0280  lr: 0.0013351  max_mem: 7924M
[12/11 21:45:52 d2.utils.events]:  eta: 0:33:00  iter: 5039  total_loss: 2.151  loss_sem_seg: 1.117  loss_center: 0.4765  loss_offset: 0.5236  time: 0.4011  data_time: 0.0285  lr: 0.0013303  max_mem: 7924M
[12/11 21:46:00 d2.utils.events]:  eta: 0:32:51  iter: 5059  total_loss: 2.459  loss_sem_seg: 1.275  loss_center: 0.4508  loss_offset: 0.6858  time: 0.4011  data_time: 0.0307  lr: 0.0013255  max_mem: 7924M
[12/11 21:46:08 d2.utils.events]:  eta: 0:32:44  iter: 5079  total_loss: 2.408  loss_sem_seg: 1.16  loss_center: 0.5349  loss_offset: 0.6526  time: 0.4011  data_time: 0.0291  lr: 0.0013207  max_mem: 7924M
[12/11 21:46:16 d2.utils.events]:  eta: 0:32:36  iter: 5099  total_loss: 2.475  loss_sem_seg: 1.147  loss_center: 0.5681  loss_offset: 0.6674  time: 0.4011  data_time: 0.0323  lr: 0.0013158  max_mem: 7924M
[12/11 21:46:24 d2.utils.events]:  eta: 0:32:28  iter: 5119  total_loss: 2.099  loss_sem_seg: 1.028  loss_center: 0.5414  loss_offset: 0.5693  time: 0.4011  data_time: 0.0293  lr: 0.001311  max_mem: 7924M
[12/11 21:46:32 d2.utils.events]:  eta: 0:32:20  iter: 5139  total_loss: 2.497  loss_sem_seg: 1.106  loss_center: 0.6988  loss_offset: 0.5843  time: 0.4011  data_time: 0.0299  lr: 0.0013062  max_mem: 7924M
[12/11 21:46:40 d2.utils.events]:  eta: 0:32:12  iter: 5159  total_loss: 2.152  loss_sem_seg: 0.9857  loss_center: 0.5452  loss_offset: 0.5869  time: 0.4011  data_time: 0.0295  lr: 0.0013013  max_mem: 7924M
[12/11 21:46:48 d2.utils.events]:  eta: 0:32:03  iter: 5179  total_loss: 2.394  loss_sem_seg: 1.143  loss_center: 0.5553  loss_offset: 0.6528  time: 0.4011  data_time: 0.0285  lr: 0.0012965  max_mem: 7924M
[12/11 21:46:56 d2.utils.events]:  eta: 0:31:56  iter: 5199  total_loss: 2.224  loss_sem_seg: 1.053  loss_center: 0.4767  loss_offset: 0.5672  time: 0.4011  data_time: 0.0318  lr: 0.0012916  max_mem: 7924M
[12/11 21:47:04 d2.utils.events]:  eta: 0:31:48  iter: 5219  total_loss: 2.242  loss_sem_seg: 1.063  loss_center: 0.5951  loss_offset: 0.6021  time: 0.4011  data_time: 0.0286  lr: 0.0012868  max_mem: 7924M
[12/11 21:47:12 d2.utils.events]:  eta: 0:31:39  iter: 5239  total_loss: 2.27  loss_sem_seg: 1.142  loss_center: 0.4671  loss_offset: 0.5079  time: 0.4011  data_time: 0.0294  lr: 0.0012819  max_mem: 7924M
[12/11 21:47:20 d2.utils.events]:  eta: 0:31:31  iter: 5259  total_loss: 1.968  loss_sem_seg: 0.9305  loss_center: 0.5319  loss_offset: 0.5048  time: 0.4011  data_time: 0.0291  lr: 0.0012771  max_mem: 7924M
[12/11 21:47:28 d2.utils.events]:  eta: 0:31:23  iter: 5279  total_loss: 2.302  loss_sem_seg: 1.103  loss_center: 0.5675  loss_offset: 0.5958  time: 0.4011  data_time: 0.0297  lr: 0.0012722  max_mem: 7924M
[12/11 21:47:36 d2.utils.events]:  eta: 0:31:15  iter: 5299  total_loss: 2.243  loss_sem_seg: 1.039  loss_center: 0.5574  loss_offset: 0.628  time: 0.4011  data_time: 0.0286  lr: 0.0012674  max_mem: 7924M
[12/11 21:47:44 d2.utils.events]:  eta: 0:31:07  iter: 5319  total_loss: 2.233  loss_sem_seg: 1.126  loss_center: 0.5085  loss_offset: 0.6994  time: 0.4011  data_time: 0.0314  lr: 0.0012625  max_mem: 7924M
[12/11 21:47:52 d2.utils.events]:  eta: 0:30:59  iter: 5339  total_loss: 2.267  loss_sem_seg: 1.051  loss_center: 0.5453  loss_offset: 0.6  time: 0.4011  data_time: 0.0292  lr: 0.0012577  max_mem: 7924M
[12/11 21:48:00 d2.utils.events]:  eta: 0:30:51  iter: 5359  total_loss: 2.316  loss_sem_seg: 1.135  loss_center: 0.5647  loss_offset: 0.5784  time: 0.4011  data_time: 0.0320  lr: 0.0012528  max_mem: 7924M
[12/11 21:48:08 d2.utils.events]:  eta: 0:30:43  iter: 5379  total_loss: 2.31  loss_sem_seg: 1.171  loss_center: 0.5374  loss_offset: 0.6045  time: 0.4011  data_time: 0.0298  lr: 0.001248  max_mem: 7924M
[12/11 21:48:16 d2.utils.events]:  eta: 0:30:35  iter: 5399  total_loss: 2.411  loss_sem_seg: 0.9894  loss_center: 0.4399  loss_offset: 0.5782  time: 0.4011  data_time: 0.0290  lr: 0.0012431  max_mem: 7924M
[12/11 21:48:24 d2.utils.events]:  eta: 0:30:28  iter: 5419  total_loss: 2.392  loss_sem_seg: 1.108  loss_center: 0.4905  loss_offset: 0.5679  time: 0.4011  data_time: 0.0308  lr: 0.0012382  max_mem: 7924M
[12/11 21:48:32 d2.utils.events]:  eta: 0:30:20  iter: 5439  total_loss: 2.459  loss_sem_seg: 1.129  loss_center: 0.5002  loss_offset: 0.7609  time: 0.4011  data_time: 0.0275  lr: 0.0012334  max_mem: 7924M
[12/11 21:48:40 d2.utils.events]:  eta: 0:30:12  iter: 5459  total_loss: 2.389  loss_sem_seg: 1.004  loss_center: 0.6797  loss_offset: 0.5997  time: 0.4011  data_time: 0.0317  lr: 0.0012285  max_mem: 7924M
[12/11 21:48:48 d2.utils.events]:  eta: 0:30:04  iter: 5479  total_loss: 2.432  loss_sem_seg: 0.9769  loss_center: 0.6849  loss_offset: 0.6375  time: 0.4011  data_time: 0.0281  lr: 0.0012236  max_mem: 7924M
[12/11 21:48:56 d2.utils.events]:  eta: 0:29:56  iter: 5499  total_loss: 2.593  loss_sem_seg: 1.149  loss_center: 0.5623  loss_offset: 0.7263  time: 0.4011  data_time: 0.0297  lr: 0.0012188  max_mem: 7924M
[12/11 21:49:04 d2.utils.events]:  eta: 0:29:48  iter: 5519  total_loss: 2.126  loss_sem_seg: 1.124  loss_center: 0.5508  loss_offset: 0.5421  time: 0.4011  data_time: 0.0298  lr: 0.0012139  max_mem: 7924M
[12/11 21:49:12 d2.utils.events]:  eta: 0:29:40  iter: 5539  total_loss: 2.508  loss_sem_seg: 1.143  loss_center: 0.5698  loss_offset: 0.6597  time: 0.4011  data_time: 0.0295  lr: 0.001209  max_mem: 7924M
[12/11 21:49:20 d2.utils.events]:  eta: 0:29:32  iter: 5559  total_loss: 1.988  loss_sem_seg: 0.9317  loss_center: 0.4523  loss_offset: 0.4769  time: 0.4011  data_time: 0.0304  lr: 0.0012041  max_mem: 7924M
[12/11 21:49:28 d2.utils.events]:  eta: 0:29:24  iter: 5579  total_loss: 2.451  loss_sem_seg: 1.106  loss_center: 0.4926  loss_offset: 0.7448  time: 0.4011  data_time: 0.0290  lr: 0.0011992  max_mem: 7924M
[12/11 21:49:36 d2.utils.events]:  eta: 0:29:16  iter: 5599  total_loss: 2.241  loss_sem_seg: 1.127  loss_center: 0.5535  loss_offset: 0.6321  time: 0.4011  data_time: 0.0304  lr: 0.0011944  max_mem: 7924M
[12/11 21:49:44 d2.utils.events]:  eta: 0:29:09  iter: 5619  total_loss: 2.593  loss_sem_seg: 1.368  loss_center: 0.551  loss_offset: 0.6531  time: 0.4011  data_time: 0.0304  lr: 0.0011895  max_mem: 7924M
[12/11 21:49:52 d2.utils.events]:  eta: 0:29:00  iter: 5639  total_loss: 2.15  loss_sem_seg: 1.027  loss_center: 0.5175  loss_offset: 0.5152  time: 0.4011  data_time: 0.0286  lr: 0.0011846  max_mem: 7924M
[12/11 21:50:00 d2.utils.events]:  eta: 0:28:52  iter: 5659  total_loss: 2.24  loss_sem_seg: 0.994  loss_center: 0.4628  loss_offset: 0.5799  time: 0.4010  data_time: 0.0300  lr: 0.0011797  max_mem: 7924M
[12/11 21:50:08 d2.utils.events]:  eta: 0:28:44  iter: 5679  total_loss: 2.57  loss_sem_seg: 1.066  loss_center: 0.6878  loss_offset: 0.6416  time: 0.4010  data_time: 0.0298  lr: 0.0011748  max_mem: 7924M
[12/11 21:50:16 d2.utils.events]:  eta: 0:28:36  iter: 5699  total_loss: 2.214  loss_sem_seg: 1.04  loss_center: 0.4887  loss_offset: 0.6067  time: 0.4010  data_time: 0.0287  lr: 0.0011699  max_mem: 7924M
[12/11 21:50:24 d2.utils.events]:  eta: 0:28:28  iter: 5719  total_loss: 2.339  loss_sem_seg: 0.9711  loss_center: 0.6036  loss_offset: 0.5771  time: 0.4011  data_time: 0.0310  lr: 0.001165  max_mem: 7924M
[12/11 21:50:32 d2.utils.events]:  eta: 0:28:20  iter: 5739  total_loss: 2.294  loss_sem_seg: 1.142  loss_center: 0.47  loss_offset: 0.5352  time: 0.4010  data_time: 0.0290  lr: 0.0011601  max_mem: 7924M
[12/11 21:50:40 d2.utils.events]:  eta: 0:28:13  iter: 5759  total_loss: 2.318  loss_sem_seg: 1.103  loss_center: 0.4646  loss_offset: 0.6208  time: 0.4010  data_time: 0.0278  lr: 0.0011552  max_mem: 7924M
[12/11 21:50:48 d2.utils.events]:  eta: 0:28:05  iter: 5779  total_loss: 2.387  loss_sem_seg: 1.07  loss_center: 0.5424  loss_offset: 0.654  time: 0.4010  data_time: 0.0295  lr: 0.0011503  max_mem: 7924M
[12/11 21:50:56 d2.utils.events]:  eta: 0:27:56  iter: 5799  total_loss: 2.097  loss_sem_seg: 1.013  loss_center: 0.6519  loss_offset: 0.5356  time: 0.4010  data_time: 0.0297  lr: 0.0011454  max_mem: 7924M
[12/11 21:51:04 d2.utils.events]:  eta: 0:27:48  iter: 5819  total_loss: 2.262  loss_sem_seg: 1.063  loss_center: 0.6274  loss_offset: 0.5082  time: 0.4010  data_time: 0.0284  lr: 0.0011405  max_mem: 7924M
[12/11 21:51:12 d2.utils.events]:  eta: 0:27:40  iter: 5839  total_loss: 2.345  loss_sem_seg: 1.096  loss_center: 0.511  loss_offset: 0.5541  time: 0.4010  data_time: 0.0303  lr: 0.0011356  max_mem: 7924M
[12/11 21:51:20 d2.utils.events]:  eta: 0:27:33  iter: 5859  total_loss: 2.283  loss_sem_seg: 0.9967  loss_center: 0.4586  loss_offset: 0.6933  time: 0.4010  data_time: 0.0287  lr: 0.0011307  max_mem: 7924M
[12/11 21:51:28 d2.utils.events]:  eta: 0:27:25  iter: 5879  total_loss: 2.634  loss_sem_seg: 1.19  loss_center: 0.433  loss_offset: 0.6912  time: 0.4010  data_time: 0.0314  lr: 0.0011258  max_mem: 7924M
[12/11 21:51:36 d2.utils.events]:  eta: 0:27:16  iter: 5899  total_loss: 2.067  loss_sem_seg: 1.054  loss_center: 0.475  loss_offset: 0.5793  time: 0.4010  data_time: 0.0293  lr: 0.0011208  max_mem: 7924M
[12/11 21:51:45 d2.utils.events]:  eta: 0:27:09  iter: 5919  total_loss: 2.319  loss_sem_seg: 1.161  loss_center: 0.5552  loss_offset: 0.6182  time: 0.4010  data_time: 0.0299  lr: 0.0011159  max_mem: 7924M
[12/11 21:51:52 d2.utils.events]:  eta: 0:27:00  iter: 5939  total_loss: 2.252  loss_sem_seg: 1.089  loss_center: 0.5405  loss_offset: 0.5714  time: 0.4010  data_time: 0.0274  lr: 0.001111  max_mem: 7924M
[12/11 21:52:01 d2.utils.events]:  eta: 0:26:52  iter: 5959  total_loss: 2.723  loss_sem_seg: 1.245  loss_center: 0.6456  loss_offset: 0.7777  time: 0.4010  data_time: 0.0297  lr: 0.0011061  max_mem: 7924M
[12/11 21:52:09 d2.utils.events]:  eta: 0:26:45  iter: 5979  total_loss: 2.141  loss_sem_seg: 0.8831  loss_center: 0.5666  loss_offset: 0.5296  time: 0.4010  data_time: 0.0283  lr: 0.0011011  max_mem: 7924M
[12/11 21:52:17 d2.utils.events]:  eta: 0:26:37  iter: 5999  total_loss: 2.554  loss_sem_seg: 1.056  loss_center: 0.5448  loss_offset: 0.6954  time: 0.4010  data_time: 0.0293  lr: 0.0010962  max_mem: 7924M
[12/11 21:52:25 d2.utils.events]:  eta: 0:26:29  iter: 6019  total_loss: 2.372  loss_sem_seg: 1.116  loss_center: 0.5234  loss_offset: 0.6808  time: 0.4010  data_time: 0.0299  lr: 0.0010913  max_mem: 7924M
[12/11 21:52:33 d2.utils.events]:  eta: 0:26:22  iter: 6039  total_loss: 2.341  loss_sem_seg: 1.13  loss_center: 0.5069  loss_offset: 0.5966  time: 0.4010  data_time: 0.0297  lr: 0.0010863  max_mem: 7924M
[12/11 21:52:41 d2.utils.events]:  eta: 0:26:13  iter: 6059  total_loss: 2.237  loss_sem_seg: 1.154  loss_center: 0.5038  loss_offset: 0.542  time: 0.4010  data_time: 0.0303  lr: 0.0010814  max_mem: 7924M
[12/11 21:52:49 d2.utils.events]:  eta: 0:26:05  iter: 6079  total_loss: 2.205  loss_sem_seg: 0.9764  loss_center: 0.5093  loss_offset: 0.5729  time: 0.4010  data_time: 0.0295  lr: 0.0010765  max_mem: 7924M
[12/11 21:52:57 d2.utils.events]:  eta: 0:25:57  iter: 6099  total_loss: 2.079  loss_sem_seg: 1.05  loss_center: 0.4263  loss_offset: 0.6147  time: 0.4010  data_time: 0.0283  lr: 0.0010715  max_mem: 7924M
[12/11 21:53:05 d2.utils.events]:  eta: 0:25:49  iter: 6119  total_loss: 2.343  loss_sem_seg: 0.9906  loss_center: 0.5878  loss_offset: 0.5232  time: 0.4010  data_time: 0.0300  lr: 0.0010666  max_mem: 7924M
[12/11 21:53:13 d2.utils.events]:  eta: 0:25:42  iter: 6139  total_loss: 2.204  loss_sem_seg: 1.109  loss_center: 0.519  loss_offset: 0.6312  time: 0.4010  data_time: 0.0309  lr: 0.0010616  max_mem: 7924M
[12/11 21:53:21 d2.utils.events]:  eta: 0:25:34  iter: 6159  total_loss: 2.075  loss_sem_seg: 0.8912  loss_center: 0.4557  loss_offset: 0.5019  time: 0.4010  data_time: 0.0302  lr: 0.0010567  max_mem: 7924M
[12/11 21:53:29 d2.utils.events]:  eta: 0:25:26  iter: 6179  total_loss: 2.12  loss_sem_seg: 0.9809  loss_center: 0.6102  loss_offset: 0.5705  time: 0.4010  data_time: 0.0304  lr: 0.0010517  max_mem: 7924M
[12/11 21:53:37 d2.utils.events]:  eta: 0:25:19  iter: 6199  total_loss: 2.003  loss_sem_seg: 0.9177  loss_center: 0.5323  loss_offset: 0.5358  time: 0.4010  data_time: 0.0323  lr: 0.0010468  max_mem: 7924M
[12/11 21:53:45 d2.utils.events]:  eta: 0:25:10  iter: 6219  total_loss: 1.991  loss_sem_seg: 0.9474  loss_center: 0.623  loss_offset: 0.4872  time: 0.4010  data_time: 0.0281  lr: 0.0010418  max_mem: 7924M
[12/11 21:53:53 d2.utils.events]:  eta: 0:25:02  iter: 6239  total_loss: 2.237  loss_sem_seg: 1.072  loss_center: 0.4928  loss_offset: 0.6199  time: 0.4010  data_time: 0.0311  lr: 0.0010368  max_mem: 7924M
[12/11 21:54:01 d2.utils.events]:  eta: 0:24:54  iter: 6259  total_loss: 2.278  loss_sem_seg: 1.076  loss_center: 0.6764  loss_offset: 0.4972  time: 0.4010  data_time: 0.0301  lr: 0.0010319  max_mem: 7924M
[12/11 21:54:09 d2.utils.events]:  eta: 0:24:47  iter: 6279  total_loss: 2.419  loss_sem_seg: 1.059  loss_center: 0.5639  loss_offset: 0.72  time: 0.4010  data_time: 0.0308  lr: 0.0010269  max_mem: 7924M
[12/11 21:54:17 d2.utils.events]:  eta: 0:24:39  iter: 6299  total_loss: 2.363  loss_sem_seg: 1.189  loss_center: 0.4766  loss_offset: 0.6745  time: 0.4010  data_time: 0.0304  lr: 0.0010219  max_mem: 7924M
[12/11 21:54:25 d2.utils.events]:  eta: 0:24:31  iter: 6319  total_loss: 2.383  loss_sem_seg: 1.183  loss_center: 0.5334  loss_offset: 0.569  time: 0.4010  data_time: 0.0326  lr: 0.001017  max_mem: 7924M
[12/11 21:54:33 d2.utils.events]:  eta: 0:24:22  iter: 6339  total_loss: 2.32  loss_sem_seg: 1.077  loss_center: 0.49  loss_offset: 0.6682  time: 0.4010  data_time: 0.0291  lr: 0.001012  max_mem: 7924M
[12/11 21:54:41 d2.utils.events]:  eta: 0:24:14  iter: 6359  total_loss: 2.086  loss_sem_seg: 0.968  loss_center: 0.5688  loss_offset: 0.6377  time: 0.4010  data_time: 0.0312  lr: 0.001007  max_mem: 7924M
[12/11 21:54:49 d2.utils.events]:  eta: 0:24:06  iter: 6379  total_loss: 2.311  loss_sem_seg: 1.089  loss_center: 0.4661  loss_offset: 0.6776  time: 0.4010  data_time: 0.0296  lr: 0.001002  max_mem: 7924M
[12/11 21:54:57 d2.utils.events]:  eta: 0:23:58  iter: 6399  total_loss: 2.414  loss_sem_seg: 1.094  loss_center: 0.5949  loss_offset: 0.5987  time: 0.4010  data_time: 0.0297  lr: 0.00099706  max_mem: 7924M
[12/11 21:55:05 d2.utils.events]:  eta: 0:23:50  iter: 6419  total_loss: 2.425  loss_sem_seg: 1.182  loss_center: 0.5166  loss_offset: 0.6494  time: 0.4010  data_time: 0.0311  lr: 0.00099207  max_mem: 7924M
[12/11 21:55:13 d2.utils.events]:  eta: 0:23:42  iter: 6439  total_loss: 2.35  loss_sem_seg: 1.058  loss_center: 0.5479  loss_offset: 0.5976  time: 0.4010  data_time: 0.0286  lr: 0.00098709  max_mem: 7924M
[12/11 21:55:21 d2.utils.events]:  eta: 0:23:34  iter: 6459  total_loss: 2.216  loss_sem_seg: 0.9099  loss_center: 0.6073  loss_offset: 0.6201  time: 0.4010  data_time: 0.0307  lr: 0.00098209  max_mem: 7924M
[12/11 21:55:29 d2.utils.events]:  eta: 0:23:26  iter: 6479  total_loss: 2.394  loss_sem_seg: 1.075  loss_center: 0.574  loss_offset: 0.598  time: 0.4010  data_time: 0.0299  lr: 0.0009771  max_mem: 7924M
[12/11 21:55:37 d2.utils.events]:  eta: 0:23:18  iter: 6499  total_loss: 2.549  loss_sem_seg: 1.156  loss_center: 0.5802  loss_offset: 0.6034  time: 0.4010  data_time: 0.0296  lr: 0.0009721  max_mem: 7924M
[12/11 21:55:45 d2.utils.events]:  eta: 0:23:09  iter: 6519  total_loss: 2.231  loss_sem_seg: 1.09  loss_center: 0.4582  loss_offset: 0.5728  time: 0.4010  data_time: 0.0284  lr: 0.00096711  max_mem: 7924M
[12/11 21:55:53 d2.utils.events]:  eta: 0:23:02  iter: 6539  total_loss: 2.356  loss_sem_seg: 1.078  loss_center: 0.5473  loss_offset: 0.6096  time: 0.4010  data_time: 0.0323  lr: 0.0009621  max_mem: 7924M
[12/11 21:56:01 d2.utils.events]:  eta: 0:22:53  iter: 6559  total_loss: 2.162  loss_sem_seg: 1.066  loss_center: 0.4915  loss_offset: 0.5746  time: 0.4009  data_time: 0.0279  lr: 0.0009571  max_mem: 7924M
[12/11 21:56:09 d2.utils.events]:  eta: 0:22:45  iter: 6579  total_loss: 2.369  loss_sem_seg: 1.176  loss_center: 0.4741  loss_offset: 0.7012  time: 0.4009  data_time: 0.0310  lr: 0.00095209  max_mem: 7924M
[12/11 21:56:17 d2.utils.events]:  eta: 0:22:37  iter: 6599  total_loss: 2.232  loss_sem_seg: 1.043  loss_center: 0.5622  loss_offset: 0.513  time: 0.4009  data_time: 0.0289  lr: 0.00094708  max_mem: 7924M
[12/11 21:56:25 d2.utils.events]:  eta: 0:22:29  iter: 6619  total_loss: 2.254  loss_sem_seg: 1.225  loss_center: 0.5412  loss_offset: 0.5932  time: 0.4009  data_time: 0.0340  lr: 0.00094206  max_mem: 7924M
[12/11 21:56:33 d2.utils.events]:  eta: 0:22:21  iter: 6639  total_loss: 2.021  loss_sem_seg: 0.9756  loss_center: 0.5841  loss_offset: 0.4707  time: 0.4009  data_time: 0.0282  lr: 0.00093705  max_mem: 7924M
[12/11 21:56:41 d2.utils.events]:  eta: 0:22:14  iter: 6659  total_loss: 2.229  loss_sem_seg: 0.9769  loss_center: 0.5601  loss_offset: 0.5539  time: 0.4009  data_time: 0.0302  lr: 0.00093203  max_mem: 7924M
[12/11 21:56:49 d2.utils.events]:  eta: 0:22:05  iter: 6679  total_loss: 2.481  loss_sem_seg: 1.117  loss_center: 0.599  loss_offset: 0.6079  time: 0.4009  data_time: 0.0281  lr: 0.000927  max_mem: 7924M
[12/11 21:56:57 d2.utils.events]:  eta: 0:21:57  iter: 6699  total_loss: 2.23  loss_sem_seg: 1.043  loss_center: 0.5562  loss_offset: 0.6616  time: 0.4009  data_time: 0.0286  lr: 0.00092198  max_mem: 7924M
[12/11 21:57:05 d2.utils.events]:  eta: 0:21:49  iter: 6719  total_loss: 2.128  loss_sem_seg: 0.9902  loss_center: 0.5401  loss_offset: 0.6311  time: 0.4009  data_time: 0.0299  lr: 0.00091695  max_mem: 7924M
[12/11 21:57:13 d2.utils.events]:  eta: 0:21:41  iter: 6739  total_loss: 2.372  loss_sem_seg: 1.15  loss_center: 0.5286  loss_offset: 0.6106  time: 0.4009  data_time: 0.0284  lr: 0.00091192  max_mem: 7924M
[12/11 21:57:21 d2.utils.events]:  eta: 0:21:33  iter: 6759  total_loss: 2.217  loss_sem_seg: 1.045  loss_center: 0.6131  loss_offset: 0.5755  time: 0.4009  data_time: 0.0305  lr: 0.00090688  max_mem: 7924M
[12/11 21:57:29 d2.utils.events]:  eta: 0:21:25  iter: 6779  total_loss: 2.093  loss_sem_seg: 0.9559  loss_center: 0.4997  loss_offset: 0.6007  time: 0.4009  data_time: 0.0283  lr: 0.00090184  max_mem: 7924M
[12/11 21:57:37 d2.utils.events]:  eta: 0:21:17  iter: 6799  total_loss: 2.104  loss_sem_seg: 1.085  loss_center: 0.5299  loss_offset: 0.552  time: 0.4009  data_time: 0.0294  lr: 0.0008968  max_mem: 7924M
[12/11 21:57:45 d2.utils.events]:  eta: 0:21:09  iter: 6819  total_loss: 1.932  loss_sem_seg: 0.9875  loss_center: 0.4021  loss_offset: 0.5753  time: 0.4009  data_time: 0.0290  lr: 0.00089176  max_mem: 7924M
[12/11 21:57:53 d2.utils.events]:  eta: 0:21:01  iter: 6839  total_loss: 2.187  loss_sem_seg: 0.9916  loss_center: 0.5505  loss_offset: 0.5582  time: 0.4009  data_time: 0.0289  lr: 0.00088671  max_mem: 7924M
[12/11 21:58:01 d2.utils.events]:  eta: 0:20:53  iter: 6859  total_loss: 2.089  loss_sem_seg: 1.078  loss_center: 0.5392  loss_offset: 0.5296  time: 0.4009  data_time: 0.0297  lr: 0.00088166  max_mem: 7924M
[12/11 21:58:09 d2.utils.events]:  eta: 0:20:45  iter: 6879  total_loss: 2.333  loss_sem_seg: 1.04  loss_center: 0.5769  loss_offset: 0.5946  time: 0.4009  data_time: 0.0285  lr: 0.00087661  max_mem: 7924M
[12/11 21:58:17 d2.utils.events]:  eta: 0:20:37  iter: 6899  total_loss: 2.066  loss_sem_seg: 0.9662  loss_center: 0.4703  loss_offset: 0.4821  time: 0.4009  data_time: 0.0275  lr: 0.00087155  max_mem: 7924M
[12/11 21:58:25 d2.utils.events]:  eta: 0:20:29  iter: 6919  total_loss: 2.142  loss_sem_seg: 1.116  loss_center: 0.4218  loss_offset: 0.534  time: 0.4009  data_time: 0.0305  lr: 0.00086649  max_mem: 7924M
[12/11 21:58:33 d2.utils.events]:  eta: 0:20:21  iter: 6939  total_loss: 1.888  loss_sem_seg: 0.9756  loss_center: 0.5287  loss_offset: 0.5703  time: 0.4009  data_time: 0.0293  lr: 0.00086142  max_mem: 7924M
[12/11 21:58:41 d2.utils.events]:  eta: 0:20:13  iter: 6959  total_loss: 2.068  loss_sem_seg: 1.016  loss_center: 0.44  loss_offset: 0.5534  time: 0.4009  data_time: 0.0308  lr: 0.00085636  max_mem: 7924M
[12/11 21:58:49 d2.utils.events]:  eta: 0:20:04  iter: 6979  total_loss: 2.158  loss_sem_seg: 0.9908  loss_center: 0.5456  loss_offset: 0.5349  time: 0.4008  data_time: 0.0285  lr: 0.00085129  max_mem: 7924M
[12/11 21:58:57 d2.utils.events]:  eta: 0:19:56  iter: 6999  total_loss: 2.225  loss_sem_seg: 0.9848  loss_center: 0.6015  loss_offset: 0.5652  time: 0.4008  data_time: 0.0292  lr: 0.00084621  max_mem: 7924M
[12/11 21:59:05 d2.utils.events]:  eta: 0:19:48  iter: 7019  total_loss: 2.556  loss_sem_seg: 1.19  loss_center: 0.6564  loss_offset: 0.5728  time: 0.4008  data_time: 0.0298  lr: 0.00084114  max_mem: 7924M
[12/11 21:59:13 d2.utils.events]:  eta: 0:19:39  iter: 7039  total_loss: 2.363  loss_sem_seg: 1.091  loss_center: 0.4857  loss_offset: 0.6581  time: 0.4008  data_time: 0.0288  lr: 0.00083605  max_mem: 7924M
[12/11 21:59:21 d2.utils.events]:  eta: 0:19:32  iter: 7059  total_loss: 2.241  loss_sem_seg: 1.089  loss_center: 0.495  loss_offset: 0.6216  time: 0.4008  data_time: 0.0286  lr: 0.00083097  max_mem: 7924M
[12/11 21:59:29 d2.utils.events]:  eta: 0:19:23  iter: 7079  total_loss: 2.31  loss_sem_seg: 1.159  loss_center: 0.5329  loss_offset: 0.5965  time: 0.4008  data_time: 0.0295  lr: 0.00082588  max_mem: 7924M
[12/11 21:59:37 d2.utils.events]:  eta: 0:19:16  iter: 7099  total_loss: 2.235  loss_sem_seg: 0.9991  loss_center: 0.457  loss_offset: 0.5296  time: 0.4008  data_time: 0.0286  lr: 0.00082079  max_mem: 7924M
[12/11 21:59:45 d2.utils.events]:  eta: 0:19:07  iter: 7119  total_loss: 2.094  loss_sem_seg: 0.9702  loss_center: 0.5966  loss_offset: 0.5171  time: 0.4008  data_time: 0.0284  lr: 0.0008157  max_mem: 7924M
[12/11 21:59:53 d2.utils.events]:  eta: 0:18:59  iter: 7139  total_loss: 1.934  loss_sem_seg: 0.9494  loss_center: 0.4846  loss_offset: 0.5033  time: 0.4008  data_time: 0.0281  lr: 0.0008106  max_mem: 7924M
[12/11 22:00:01 d2.utils.events]:  eta: 0:18:50  iter: 7159  total_loss: 2.452  loss_sem_seg: 1.167  loss_center: 0.5441  loss_offset: 0.5372  time: 0.4008  data_time: 0.0315  lr: 0.0008055  max_mem: 7924M
[12/11 22:00:09 d2.utils.events]:  eta: 0:18:42  iter: 7179  total_loss: 2.232  loss_sem_seg: 0.9373  loss_center: 0.5521  loss_offset: 0.5544  time: 0.4008  data_time: 0.0292  lr: 0.00080039  max_mem: 7924M
[12/11 22:00:17 d2.utils.events]:  eta: 0:18:35  iter: 7199  total_loss: 1.989  loss_sem_seg: 1.055  loss_center: 0.4332  loss_offset: 0.5625  time: 0.4008  data_time: 0.0291  lr: 0.00079528  max_mem: 7924M
[12/11 22:00:25 d2.utils.events]:  eta: 0:18:27  iter: 7219  total_loss: 2.016  loss_sem_seg: 1.072  loss_center: 0.4027  loss_offset: 0.5361  time: 0.4008  data_time: 0.0301  lr: 0.00079017  max_mem: 7924M
[12/11 22:00:33 d2.utils.events]:  eta: 0:18:18  iter: 7239  total_loss: 2.452  loss_sem_seg: 1.149  loss_center: 0.5267  loss_offset: 0.6058  time: 0.4008  data_time: 0.0288  lr: 0.00078505  max_mem: 7924M
[12/11 22:00:41 d2.utils.events]:  eta: 0:18:11  iter: 7259  total_loss: 2.251  loss_sem_seg: 1.002  loss_center: 0.5642  loss_offset: 0.5372  time: 0.4008  data_time: 0.0278  lr: 0.00077993  max_mem: 7924M
[12/11 22:00:49 d2.utils.events]:  eta: 0:18:03  iter: 7279  total_loss: 2.234  loss_sem_seg: 0.9109  loss_center: 0.6666  loss_offset: 0.5738  time: 0.4008  data_time: 0.0294  lr: 0.00077481  max_mem: 7924M
[12/11 22:00:57 d2.utils.events]:  eta: 0:17:55  iter: 7299  total_loss: 2.038  loss_sem_seg: 0.9996  loss_center: 0.3717  loss_offset: 0.4756  time: 0.4008  data_time: 0.0287  lr: 0.00076968  max_mem: 7924M
[12/11 22:01:05 d2.utils.events]:  eta: 0:17:47  iter: 7319  total_loss: 2.359  loss_sem_seg: 1.082  loss_center: 0.6026  loss_offset: 0.5724  time: 0.4008  data_time: 0.0292  lr: 0.00076455  max_mem: 7924M
[12/11 22:01:13 d2.utils.events]:  eta: 0:17:39  iter: 7339  total_loss: 2.25  loss_sem_seg: 0.9177  loss_center: 0.5178  loss_offset: 0.6408  time: 0.4008  data_time: 0.0291  lr: 0.00075942  max_mem: 7924M
[12/11 22:01:21 d2.utils.events]:  eta: 0:17:31  iter: 7359  total_loss: 2.086  loss_sem_seg: 1.015  loss_center: 0.5058  loss_offset: 0.5068  time: 0.4007  data_time: 0.0285  lr: 0.00075428  max_mem: 7924M
[12/11 22:01:29 d2.utils.events]:  eta: 0:17:22  iter: 7379  total_loss: 2.043  loss_sem_seg: 0.9512  loss_center: 0.513  loss_offset: 0.5149  time: 0.4007  data_time: 0.0302  lr: 0.00074914  max_mem: 7924M
[12/11 22:01:37 d2.utils.events]:  eta: 0:17:14  iter: 7399  total_loss: 2.032  loss_sem_seg: 1.005  loss_center: 0.3801  loss_offset: 0.5697  time: 0.4007  data_time: 0.0307  lr: 0.00074399  max_mem: 7924M
[12/11 22:01:45 d2.utils.events]:  eta: 0:17:07  iter: 7419  total_loss: 2.324  loss_sem_seg: 1.123  loss_center: 0.5991  loss_offset: 0.5921  time: 0.4007  data_time: 0.0292  lr: 0.00073884  max_mem: 7924M
[12/11 22:01:53 d2.utils.events]:  eta: 0:16:59  iter: 7439  total_loss: 2.146  loss_sem_seg: 0.9857  loss_center: 0.6586  loss_offset: 0.5321  time: 0.4007  data_time: 0.0299  lr: 0.00073368  max_mem: 7924M
[12/11 22:02:01 d2.utils.events]:  eta: 0:16:51  iter: 7459  total_loss: 2.522  loss_sem_seg: 1.266  loss_center: 0.5812  loss_offset: 0.5212  time: 0.4007  data_time: 0.0289  lr: 0.00072852  max_mem: 7924M
[12/11 22:02:09 d2.utils.events]:  eta: 0:16:43  iter: 7479  total_loss: 2.226  loss_sem_seg: 0.9253  loss_center: 0.6243  loss_offset: 0.4854  time: 0.4007  data_time: 0.0287  lr: 0.00072336  max_mem: 7924M
[12/11 22:02:17 d2.utils.events]:  eta: 0:16:35  iter: 7499  total_loss: 2.183  loss_sem_seg: 1.092  loss_center: 0.4894  loss_offset: 0.6114  time: 0.4007  data_time: 0.0281  lr: 0.00071819  max_mem: 7924M
[12/11 22:02:25 d2.utils.events]:  eta: 0:16:27  iter: 7519  total_loss: 2.297  loss_sem_seg: 1.069  loss_center: 0.5596  loss_offset: 0.6621  time: 0.4007  data_time: 0.0306  lr: 0.00071302  max_mem: 7924M
[12/11 22:02:33 d2.utils.events]:  eta: 0:16:19  iter: 7539  total_loss: 2.396  loss_sem_seg: 1.14  loss_center: 0.5831  loss_offset: 0.7097  time: 0.4007  data_time: 0.0290  lr: 0.00070785  max_mem: 7924M
[12/11 22:02:41 d2.utils.events]:  eta: 0:16:11  iter: 7559  total_loss: 2.278  loss_sem_seg: 0.979  loss_center: 0.5109  loss_offset: 0.5921  time: 0.4007  data_time: 0.0293  lr: 0.00070267  max_mem: 7924M
[12/11 22:02:49 d2.utils.events]:  eta: 0:16:04  iter: 7579  total_loss: 2.214  loss_sem_seg: 0.8418  loss_center: 0.591  loss_offset: 0.5506  time: 0.4007  data_time: 0.0296  lr: 0.00069749  max_mem: 7924M
[12/11 22:02:57 d2.utils.events]:  eta: 0:15:56  iter: 7599  total_loss: 2.083  loss_sem_seg: 0.9934  loss_center: 0.4723  loss_offset: 0.4657  time: 0.4007  data_time: 0.0286  lr: 0.0006923  max_mem: 7924M
[12/11 22:03:05 d2.utils.events]:  eta: 0:15:47  iter: 7619  total_loss: 2.055  loss_sem_seg: 1.01  loss_center: 0.3492  loss_offset: 0.5586  time: 0.4007  data_time: 0.0321  lr: 0.00068711  max_mem: 7924M
[12/11 22:03:13 d2.utils.events]:  eta: 0:15:40  iter: 7639  total_loss: 2.11  loss_sem_seg: 1.027  loss_center: 0.435  loss_offset: 0.4914  time: 0.4007  data_time: 0.0298  lr: 0.00068191  max_mem: 7924M
[12/11 22:03:21 d2.utils.events]:  eta: 0:15:31  iter: 7659  total_loss: 2.149  loss_sem_seg: 0.8435  loss_center: 0.5928  loss_offset: 0.4388  time: 0.4007  data_time: 0.0279  lr: 0.00067671  max_mem: 7924M
[12/11 22:03:29 d2.utils.events]:  eta: 0:15:24  iter: 7679  total_loss: 2.232  loss_sem_seg: 0.9304  loss_center: 0.4335  loss_offset: 0.5098  time: 0.4007  data_time: 0.0297  lr: 0.0006715  max_mem: 7924M
[12/11 22:03:37 d2.utils.events]:  eta: 0:15:16  iter: 7699  total_loss: 2.213  loss_sem_seg: 0.9638  loss_center: 0.4965  loss_offset: 0.5954  time: 0.4007  data_time: 0.0311  lr: 0.00066629  max_mem: 7924M
[12/11 22:03:45 d2.utils.events]:  eta: 0:15:08  iter: 7719  total_loss: 2.381  loss_sem_seg: 1.157  loss_center: 0.454  loss_offset: 0.5331  time: 0.4007  data_time: 0.0296  lr: 0.00066108  max_mem: 7924M
[12/11 22:03:53 d2.utils.events]:  eta: 0:15:00  iter: 7739  total_loss: 2.017  loss_sem_seg: 0.8845  loss_center: 0.4859  loss_offset: 0.5581  time: 0.4007  data_time: 0.0292  lr: 0.00065586  max_mem: 7924M
[12/11 22:04:01 d2.utils.events]:  eta: 0:14:52  iter: 7759  total_loss: 2.052  loss_sem_seg: 0.9111  loss_center: 0.4243  loss_offset: 0.5934  time: 0.4007  data_time: 0.0301  lr: 0.00065064  max_mem: 7924M
[12/11 22:04:09 d2.utils.events]:  eta: 0:14:44  iter: 7779  total_loss: 1.87  loss_sem_seg: 0.954  loss_center: 0.4448  loss_offset: 0.4442  time: 0.4007  data_time: 0.0294  lr: 0.00064541  max_mem: 7924M
[12/11 22:04:17 d2.utils.events]:  eta: 0:14:36  iter: 7799  total_loss: 2.351  loss_sem_seg: 1.051  loss_center: 0.6164  loss_offset: 0.599  time: 0.4007  data_time: 0.0294  lr: 0.00064017  max_mem: 7924M
[12/11 22:04:25 d2.utils.events]:  eta: 0:14:28  iter: 7819  total_loss: 2.116  loss_sem_seg: 0.9929  loss_center: 0.5924  loss_offset: 0.4602  time: 0.4007  data_time: 0.0295  lr: 0.00063494  max_mem: 7924M
[12/11 22:04:33 d2.utils.events]:  eta: 0:14:20  iter: 7839  total_loss: 1.959  loss_sem_seg: 0.9097  loss_center: 0.5773  loss_offset: 0.548  time: 0.4007  data_time: 0.0309  lr: 0.00062969  max_mem: 7924M
[12/11 22:04:41 d2.utils.events]:  eta: 0:14:12  iter: 7859  total_loss: 2.175  loss_sem_seg: 1.137  loss_center: 0.4602  loss_offset: 0.5945  time: 0.4007  data_time: 0.0272  lr: 0.00062445  max_mem: 7924M
[12/11 22:04:49 d2.utils.events]:  eta: 0:14:04  iter: 7879  total_loss: 2.269  loss_sem_seg: 1.066  loss_center: 0.4689  loss_offset: 0.5958  time: 0.4007  data_time: 0.0284  lr: 0.00061919  max_mem: 7924M
[12/11 22:04:57 d2.utils.events]:  eta: 0:13:56  iter: 7899  total_loss: 2.308  loss_sem_seg: 1.201  loss_center: 0.5063  loss_offset: 0.5243  time: 0.4007  data_time: 0.0291  lr: 0.00061394  max_mem: 7924M
[12/11 22:05:05 d2.utils.events]:  eta: 0:13:48  iter: 7919  total_loss: 2.069  loss_sem_seg: 0.9209  loss_center: 0.5309  loss_offset: 0.4108  time: 0.4007  data_time: 0.0289  lr: 0.00060867  max_mem: 7924M
[12/11 22:05:13 d2.utils.events]:  eta: 0:13:40  iter: 7939  total_loss: 2.129  loss_sem_seg: 1.108  loss_center: 0.4853  loss_offset: 0.5686  time: 0.4007  data_time: 0.0291  lr: 0.00060341  max_mem: 7924M
[12/11 22:05:21 d2.utils.events]:  eta: 0:13:32  iter: 7959  total_loss: 2.284  loss_sem_seg: 1.093  loss_center: 0.5079  loss_offset: 0.5526  time: 0.4007  data_time: 0.0302  lr: 0.00059813  max_mem: 7924M
[12/11 22:05:29 d2.utils.events]:  eta: 0:13:24  iter: 7979  total_loss: 2.234  loss_sem_seg: 0.965  loss_center: 0.7428  loss_offset: 0.5194  time: 0.4006  data_time: 0.0300  lr: 0.00059286  max_mem: 7924M
[12/11 22:05:37 d2.utils.events]:  eta: 0:13:16  iter: 7999  total_loss: 1.938  loss_sem_seg: 0.8008  loss_center: 0.5552  loss_offset: 0.4028  time: 0.4006  data_time: 0.0282  lr: 0.00058757  max_mem: 7924M
[12/11 22:05:45 d2.utils.events]:  eta: 0:13:08  iter: 8019  total_loss: 2.244  loss_sem_seg: 1.052  loss_center: 0.7029  loss_offset: 0.6209  time: 0.4006  data_time: 0.0303  lr: 0.00058229  max_mem: 7924M
[12/11 22:05:53 d2.utils.events]:  eta: 0:13:00  iter: 8039  total_loss: 2.287  loss_sem_seg: 1.031  loss_center: 0.5178  loss_offset: 0.5289  time: 0.4006  data_time: 0.0282  lr: 0.00057699  max_mem: 7924M
[12/11 22:06:01 d2.utils.events]:  eta: 0:12:52  iter: 8059  total_loss: 2.238  loss_sem_seg: 0.9987  loss_center: 0.5694  loss_offset: 0.5869  time: 0.4006  data_time: 0.0294  lr: 0.00057169  max_mem: 7924M
[12/11 22:06:09 d2.utils.events]:  eta: 0:12:44  iter: 8079  total_loss: 2.185  loss_sem_seg: 0.9931  loss_center: 0.5264  loss_offset: 0.5855  time: 0.4006  data_time: 0.0284  lr: 0.00056639  max_mem: 7924M
[12/11 22:06:17 d2.utils.events]:  eta: 0:12:36  iter: 8099  total_loss: 1.766  loss_sem_seg: 0.8024  loss_center: 0.4785  loss_offset: 0.4476  time: 0.4006  data_time: 0.0279  lr: 0.00056108  max_mem: 7924M
[12/11 22:06:25 d2.utils.events]:  eta: 0:12:28  iter: 8119  total_loss: 2.11  loss_sem_seg: 1.019  loss_center: 0.5353  loss_offset: 0.5257  time: 0.4006  data_time: 0.0296  lr: 0.00055576  max_mem: 7924M
[12/11 22:06:33 d2.utils.events]:  eta: 0:12:20  iter: 8139  total_loss: 2.015  loss_sem_seg: 0.9625  loss_center: 0.483  loss_offset: 0.5795  time: 0.4006  data_time: 0.0304  lr: 0.00055044  max_mem: 7924M
[12/11 22:06:41 d2.utils.events]:  eta: 0:12:13  iter: 8159  total_loss: 2.049  loss_sem_seg: 0.8783  loss_center: 0.4422  loss_offset: 0.4772  time: 0.4006  data_time: 0.0288  lr: 0.00054512  max_mem: 7924M
[12/11 22:06:49 d2.utils.events]:  eta: 0:12:05  iter: 8179  total_loss: 1.964  loss_sem_seg: 0.8378  loss_center: 0.5  loss_offset: 0.5338  time: 0.4006  data_time: 0.0308  lr: 0.00053978  max_mem: 7924M
[12/11 22:06:57 d2.utils.events]:  eta: 0:11:57  iter: 8199  total_loss: 2.147  loss_sem_seg: 0.9472  loss_center: 0.5823  loss_offset: 0.5935  time: 0.4006  data_time: 0.0287  lr: 0.00053444  max_mem: 7924M
[12/11 22:07:05 d2.utils.events]:  eta: 0:11:49  iter: 8219  total_loss: 2.177  loss_sem_seg: 0.9778  loss_center: 0.5242  loss_offset: 0.4108  time: 0.4006  data_time: 0.0295  lr: 0.0005291  max_mem: 7924M
[12/11 22:07:13 d2.utils.events]:  eta: 0:11:41  iter: 8239  total_loss: 2.128  loss_sem_seg: 0.932  loss_center: 0.5865  loss_offset: 0.4964  time: 0.4006  data_time: 0.0265  lr: 0.00052375  max_mem: 7924M
[12/11 22:07:20 d2.utils.events]:  eta: 0:11:33  iter: 8259  total_loss: 2.137  loss_sem_seg: 0.8758  loss_center: 0.6585  loss_offset: 0.5196  time: 0.4006  data_time: 0.0289  lr: 0.00051839  max_mem: 7924M
[12/11 22:07:28 d2.utils.events]:  eta: 0:11:24  iter: 8279  total_loss: 2.216  loss_sem_seg: 1.016  loss_center: 0.517  loss_offset: 0.5863  time: 0.4006  data_time: 0.0289  lr: 0.00051303  max_mem: 7924M
[12/11 22:07:36 d2.utils.events]:  eta: 0:11:16  iter: 8299  total_loss: 1.958  loss_sem_seg: 0.942  loss_center: 0.4729  loss_offset: 0.4603  time: 0.4006  data_time: 0.0297  lr: 0.00050766  max_mem: 7924M
[12/11 22:07:44 d2.utils.events]:  eta: 0:11:08  iter: 8319  total_loss: 1.978  loss_sem_seg: 0.902  loss_center: 0.5014  loss_offset: 0.5545  time: 0.4005  data_time: 0.0300  lr: 0.00050229  max_mem: 7924M
[12/11 22:07:52 d2.utils.events]:  eta: 0:11:00  iter: 8339  total_loss: 2.153  loss_sem_seg: 1.044  loss_center: 0.5076  loss_offset: 0.5879  time: 0.4005  data_time: 0.0288  lr: 0.0004969  max_mem: 7924M
[12/11 22:08:00 d2.utils.events]:  eta: 0:10:52  iter: 8359  total_loss: 2.143  loss_sem_seg: 0.9993  loss_center: 0.4448  loss_offset: 0.5314  time: 0.4005  data_time: 0.0303  lr: 0.00049152  max_mem: 7924M
[12/11 22:08:08 d2.utils.events]:  eta: 0:10:44  iter: 8379  total_loss: 2.093  loss_sem_seg: 1.005  loss_center: 0.4906  loss_offset: 0.5157  time: 0.4005  data_time: 0.0286  lr: 0.00048612  max_mem: 7924M
[12/11 22:08:16 d2.utils.events]:  eta: 0:10:36  iter: 8399  total_loss: 2.155  loss_sem_seg: 0.9234  loss_center: 0.5668  loss_offset: 0.6278  time: 0.4005  data_time: 0.0280  lr: 0.00048072  max_mem: 7924M
[12/11 22:08:24 d2.utils.events]:  eta: 0:10:28  iter: 8419  total_loss: 2.174  loss_sem_seg: 1.022  loss_center: 0.5057  loss_offset: 0.5941  time: 0.4005  data_time: 0.0292  lr: 0.00047531  max_mem: 7924M
[12/11 22:08:32 d2.utils.events]:  eta: 0:10:20  iter: 8439  total_loss: 2.258  loss_sem_seg: 1.221  loss_center: 0.4689  loss_offset: 0.5076  time: 0.4005  data_time: 0.0298  lr: 0.0004699  max_mem: 7924M
[12/11 22:08:40 d2.utils.events]:  eta: 0:10:12  iter: 8459  total_loss: 2.191  loss_sem_seg: 1.103  loss_center: 0.4923  loss_offset: 0.5433  time: 0.4005  data_time: 0.0283  lr: 0.00046448  max_mem: 7924M
[12/11 22:08:48 d2.utils.events]:  eta: 0:10:04  iter: 8479  total_loss: 2.013  loss_sem_seg: 0.8214  loss_center: 0.5467  loss_offset: 0.483  time: 0.4005  data_time: 0.0272  lr: 0.00045905  max_mem: 7924M
[12/11 22:08:56 d2.utils.events]:  eta: 0:09:56  iter: 8499  total_loss: 1.995  loss_sem_seg: 0.9462  loss_center: 0.4336  loss_offset: 0.5143  time: 0.4005  data_time: 0.0300  lr: 0.00045361  max_mem: 7924M
[12/11 22:09:04 d2.utils.events]:  eta: 0:09:48  iter: 8519  total_loss: 2.151  loss_sem_seg: 0.9179  loss_center: 0.6238  loss_offset: 0.5879  time: 0.4005  data_time: 0.0316  lr: 0.00044817  max_mem: 7924M
[12/11 22:09:12 d2.utils.events]:  eta: 0:09:40  iter: 8539  total_loss: 2.031  loss_sem_seg: 0.8926  loss_center: 0.4562  loss_offset: 0.5283  time: 0.4005  data_time: 0.0287  lr: 0.00044272  max_mem: 7924M
[12/11 22:09:20 d2.utils.events]:  eta: 0:09:32  iter: 8559  total_loss: 2.295  loss_sem_seg: 1.105  loss_center: 0.6245  loss_offset: 0.5042  time: 0.4005  data_time: 0.0290  lr: 0.00043726  max_mem: 7924M
[12/11 22:09:28 d2.utils.events]:  eta: 0:09:24  iter: 8579  total_loss: 2.224  loss_sem_seg: 1.009  loss_center: 0.4455  loss_offset: 0.6359  time: 0.4005  data_time: 0.0279  lr: 0.00043179  max_mem: 7924M
[12/11 22:09:36 d2.utils.events]:  eta: 0:09:16  iter: 8599  total_loss: 2.063  loss_sem_seg: 0.8337  loss_center: 0.5215  loss_offset: 0.5717  time: 0.4005  data_time: 0.0292  lr: 0.00042632  max_mem: 7924M
[12/11 22:09:44 d2.utils.events]:  eta: 0:09:09  iter: 8619  total_loss: 2.1  loss_sem_seg: 1.047  loss_center: 0.491  loss_offset: 0.5318  time: 0.4005  data_time: 0.0307  lr: 0.00042084  max_mem: 7924M
[12/11 22:09:52 d2.utils.events]:  eta: 0:09:00  iter: 8639  total_loss: 1.853  loss_sem_seg: 0.9548  loss_center: 0.4587  loss_offset: 0.4954  time: 0.4005  data_time: 0.0285  lr: 0.00041535  max_mem: 7924M
[12/11 22:10:00 d2.utils.events]:  eta: 0:08:52  iter: 8659  total_loss: 1.921  loss_sem_seg: 0.9464  loss_center: 0.516  loss_offset: 0.4034  time: 0.4005  data_time: 0.0291  lr: 0.00040985  max_mem: 7924M
[12/11 22:10:08 d2.utils.events]:  eta: 0:08:44  iter: 8679  total_loss: 2.229  loss_sem_seg: 0.915  loss_center: 0.5871  loss_offset: 0.5712  time: 0.4005  data_time: 0.0285  lr: 0.00040435  max_mem: 7924M
[12/11 22:10:16 d2.utils.events]:  eta: 0:08:36  iter: 8699  total_loss: 1.889  loss_sem_seg: 0.8477  loss_center: 0.4676  loss_offset: 0.5857  time: 0.4004  data_time: 0.0280  lr: 0.00039883  max_mem: 7924M
[12/11 22:10:24 d2.utils.events]:  eta: 0:08:28  iter: 8719  total_loss: 2.346  loss_sem_seg: 0.9954  loss_center: 0.6062  loss_offset: 0.5485  time: 0.4004  data_time: 0.0278  lr: 0.00039331  max_mem: 7924M
[12/11 22:10:32 d2.utils.events]:  eta: 0:08:20  iter: 8739  total_loss: 2.184  loss_sem_seg: 0.8991  loss_center: 0.4877  loss_offset: 0.6442  time: 0.4004  data_time: 0.0284  lr: 0.00038778  max_mem: 7924M
[12/11 22:10:40 d2.utils.events]:  eta: 0:08:12  iter: 8759  total_loss: 2.013  loss_sem_seg: 0.9537  loss_center: 0.5631  loss_offset: 0.4818  time: 0.4004  data_time: 0.0275  lr: 0.00038224  max_mem: 7924M
[12/11 22:10:48 d2.utils.events]:  eta: 0:08:04  iter: 8779  total_loss: 2.328  loss_sem_seg: 1.039  loss_center: 0.6158  loss_offset: 0.5577  time: 0.4004  data_time: 0.0274  lr: 0.00037669  max_mem: 7924M
[12/11 22:10:56 d2.utils.events]:  eta: 0:07:56  iter: 8799  total_loss: 1.983  loss_sem_seg: 0.8661  loss_center: 0.5501  loss_offset: 0.4985  time: 0.4004  data_time: 0.0288  lr: 0.00037113  max_mem: 7924M
[12/11 22:11:04 d2.utils.events]:  eta: 0:07:48  iter: 8819  total_loss: 1.903  loss_sem_seg: 0.886  loss_center: 0.4962  loss_offset: 0.4995  time: 0.4004  data_time: 0.0282  lr: 0.00036557  max_mem: 7924M
[12/11 22:11:12 d2.utils.events]:  eta: 0:07:40  iter: 8839  total_loss: 2.048  loss_sem_seg: 0.8983  loss_center: 0.5122  loss_offset: 0.4733  time: 0.4004  data_time: 0.0300  lr: 0.00035999  max_mem: 7924M
[12/11 22:11:20 d2.utils.events]:  eta: 0:07:32  iter: 8859  total_loss: 2.077  loss_sem_seg: 0.9555  loss_center: 0.4549  loss_offset: 0.5902  time: 0.4004  data_time: 0.0291  lr: 0.0003544  max_mem: 7924M
[12/11 22:11:28 d2.utils.events]:  eta: 0:07:24  iter: 8879  total_loss: 2.039  loss_sem_seg: 0.9672  loss_center: 0.5277  loss_offset: 0.4851  time: 0.4004  data_time: 0.0309  lr: 0.00034881  max_mem: 7924M
[12/11 22:11:36 d2.utils.events]:  eta: 0:07:16  iter: 8899  total_loss: 1.92  loss_sem_seg: 0.9755  loss_center: 0.4231  loss_offset: 0.481  time: 0.4004  data_time: 0.0268  lr: 0.0003432  max_mem: 7924M
[12/11 22:11:44 d2.utils.events]:  eta: 0:07:08  iter: 8919  total_loss: 2.165  loss_sem_seg: 0.9536  loss_center: 0.5706  loss_offset: 0.5892  time: 0.4004  data_time: 0.0287  lr: 0.00033758  max_mem: 7924M
[12/11 22:11:52 d2.utils.events]:  eta: 0:07:00  iter: 8939  total_loss: 2.179  loss_sem_seg: 0.8329  loss_center: 0.5636  loss_offset: 0.4561  time: 0.4004  data_time: 0.0278  lr: 0.00033196  max_mem: 7924M
[12/11 22:12:00 d2.utils.events]:  eta: 0:06:52  iter: 8959  total_loss: 2.024  loss_sem_seg: 0.8997  loss_center: 0.5275  loss_offset: 0.4712  time: 0.4004  data_time: 0.0301  lr: 0.00032632  max_mem: 7924M
[12/11 22:12:08 d2.utils.events]:  eta: 0:06:45  iter: 8979  total_loss: 1.994  loss_sem_seg: 0.8371  loss_center: 0.5778  loss_offset: 0.5021  time: 0.4004  data_time: 0.0283  lr: 0.00032067  max_mem: 7924M
[12/11 22:12:16 d2.utils.events]:  eta: 0:06:37  iter: 8999  total_loss: 2.241  loss_sem_seg: 1.165  loss_center: 0.5304  loss_offset: 0.5662  time: 0.4004  data_time: 0.0304  lr: 0.00031501  max_mem: 7924M
[12/11 22:12:24 d2.utils.events]:  eta: 0:06:29  iter: 9019  total_loss: 2.078  loss_sem_seg: 0.9626  loss_center: 0.5191  loss_offset: 0.4363  time: 0.4004  data_time: 0.0288  lr: 0.00030934  max_mem: 7924M
[12/11 22:12:32 d2.utils.events]:  eta: 0:06:21  iter: 9039  total_loss: 1.89  loss_sem_seg: 0.9761  loss_center: 0.4224  loss_offset: 0.4382  time: 0.4004  data_time: 0.0282  lr: 0.00030366  max_mem: 7924M
[12/11 22:12:40 d2.utils.events]:  eta: 0:06:13  iter: 9059  total_loss: 2.339  loss_sem_seg: 1.057  loss_center: 0.646  loss_offset: 0.6284  time: 0.4004  data_time: 0.0288  lr: 0.00029797  max_mem: 7924M
[12/11 22:12:48 d2.utils.events]:  eta: 0:06:05  iter: 9079  total_loss: 2.24  loss_sem_seg: 1.039  loss_center: 0.7033  loss_offset: 0.4784  time: 0.4004  data_time: 0.0292  lr: 0.00029226  max_mem: 7924M
[12/11 22:12:56 d2.utils.events]:  eta: 0:05:57  iter: 9099  total_loss: 2.192  loss_sem_seg: 0.8477  loss_center: 0.6186  loss_offset: 0.6565  time: 0.4003  data_time: 0.0293  lr: 0.00028654  max_mem: 7924M
[12/11 22:13:04 d2.utils.events]:  eta: 0:05:49  iter: 9119  total_loss: 1.973  loss_sem_seg: 0.9497  loss_center: 0.5192  loss_offset: 0.4918  time: 0.4003  data_time: 0.0286  lr: 0.00028081  max_mem: 7924M
[12/11 22:13:11 d2.utils.events]:  eta: 0:05:41  iter: 9139  total_loss: 2.026  loss_sem_seg: 0.8433  loss_center: 0.4777  loss_offset: 0.5708  time: 0.4003  data_time: 0.0282  lr: 0.00027507  max_mem: 7924M
[12/11 22:13:19 d2.utils.events]:  eta: 0:05:33  iter: 9159  total_loss: 2.018  loss_sem_seg: 0.9081  loss_center: 0.5153  loss_offset: 0.4557  time: 0.4003  data_time: 0.0292  lr: 0.00026931  max_mem: 7924M
[12/11 22:13:27 d2.utils.events]:  eta: 0:05:25  iter: 9179  total_loss: 1.86  loss_sem_seg: 0.8266  loss_center: 0.539  loss_offset: 0.4717  time: 0.4003  data_time: 0.0268  lr: 0.00026354  max_mem: 7924M
[12/11 22:13:35 d2.utils.events]:  eta: 0:05:17  iter: 9199  total_loss: 1.937  loss_sem_seg: 0.9045  loss_center: 0.4965  loss_offset: 0.431  time: 0.4003  data_time: 0.0282  lr: 0.00025776  max_mem: 7924M
[12/11 22:13:43 d2.utils.events]:  eta: 0:05:09  iter: 9219  total_loss: 2.118  loss_sem_seg: 0.9677  loss_center: 0.4827  loss_offset: 0.6508  time: 0.4003  data_time: 0.0276  lr: 0.00025196  max_mem: 7924M
[12/11 22:13:51 d2.utils.events]:  eta: 0:05:01  iter: 9239  total_loss: 2.223  loss_sem_seg: 1.004  loss_center: 0.4948  loss_offset: 0.5686  time: 0.4003  data_time: 0.0287  lr: 0.00024614  max_mem: 7924M
[12/11 22:13:59 d2.utils.events]:  eta: 0:04:53  iter: 9259  total_loss: 1.971  loss_sem_seg: 0.8583  loss_center: 0.4677  loss_offset: 0.566  time: 0.4003  data_time: 0.0292  lr: 0.00024031  max_mem: 7924M
[12/11 22:14:07 d2.utils.events]:  eta: 0:04:45  iter: 9279  total_loss: 1.93  loss_sem_seg: 0.8842  loss_center: 0.4477  loss_offset: 0.5398  time: 0.4003  data_time: 0.0275  lr: 0.00023447  max_mem: 7924M
[12/11 22:14:15 d2.utils.events]:  eta: 0:04:37  iter: 9299  total_loss: 2.041  loss_sem_seg: 0.8997  loss_center: 0.5156  loss_offset: 0.5504  time: 0.4003  data_time: 0.0304  lr: 0.00022861  max_mem: 7924M
[12/11 22:14:23 d2.utils.events]:  eta: 0:04:29  iter: 9319  total_loss: 1.954  loss_sem_seg: 0.9301  loss_center: 0.4715  loss_offset: 0.4822  time: 0.4003  data_time: 0.0267  lr: 0.00022273  max_mem: 7924M
[12/11 22:14:31 d2.utils.events]:  eta: 0:04:22  iter: 9339  total_loss: 2.092  loss_sem_seg: 0.968  loss_center: 0.6064  loss_offset: 0.4441  time: 0.4003  data_time: 0.0287  lr: 0.00021683  max_mem: 7924M
[12/11 22:14:39 d2.utils.events]:  eta: 0:04:14  iter: 9359  total_loss: 2.013  loss_sem_seg: 0.9661  loss_center: 0.5095  loss_offset: 0.5489  time: 0.4003  data_time: 0.0291  lr: 0.00021092  max_mem: 7924M
[12/11 22:14:47 d2.utils.events]:  eta: 0:04:06  iter: 9379  total_loss: 1.979  loss_sem_seg: 0.9621  loss_center: 0.4322  loss_offset: 0.4635  time: 0.4003  data_time: 0.0268  lr: 0.00020499  max_mem: 7924M
[12/11 22:14:55 d2.utils.events]:  eta: 0:03:58  iter: 9399  total_loss: 1.965  loss_sem_seg: 0.8804  loss_center: 0.4765  loss_offset: 0.5563  time: 0.4002  data_time: 0.0284  lr: 0.00019903  max_mem: 7924M
[12/11 22:15:03 d2.utils.events]:  eta: 0:03:50  iter: 9419  total_loss: 2.045  loss_sem_seg: 0.9402  loss_center: 0.4726  loss_offset: 0.4353  time: 0.4002  data_time: 0.0284  lr: 0.00019306  max_mem: 7924M
[12/11 22:15:11 d2.utils.events]:  eta: 0:03:42  iter: 9439  total_loss: 2.267  loss_sem_seg: 1.063  loss_center: 0.4953  loss_offset: 0.6416  time: 0.4002  data_time: 0.0287  lr: 0.00018707  max_mem: 7924M
[12/11 22:15:19 d2.utils.events]:  eta: 0:03:34  iter: 9459  total_loss: 1.947  loss_sem_seg: 0.8272  loss_center: 0.48  loss_offset: 0.5183  time: 0.4002  data_time: 0.0262  lr: 0.00018106  max_mem: 7924M
[12/11 22:15:27 d2.utils.events]:  eta: 0:03:26  iter: 9479  total_loss: 2.202  loss_sem_seg: 0.9698  loss_center: 0.6606  loss_offset: 0.5431  time: 0.4002  data_time: 0.0274  lr: 0.00017502  max_mem: 7924M
[12/11 22:15:35 d2.utils.events]:  eta: 0:03:18  iter: 9499  total_loss: 1.924  loss_sem_seg: 0.7234  loss_center: 0.4975  loss_offset: 0.5447  time: 0.4002  data_time: 0.0283  lr: 0.00016896  max_mem: 7924M
[12/11 22:15:42 d2.utils.events]:  eta: 0:03:10  iter: 9519  total_loss: 1.86  loss_sem_seg: 0.8476  loss_center: 0.4996  loss_offset: 0.5063  time: 0.4002  data_time: 0.0270  lr: 0.00016288  max_mem: 7924M
[12/11 22:15:50 d2.utils.events]:  eta: 0:03:02  iter: 9539  total_loss: 1.962  loss_sem_seg: 0.7696  loss_center: 0.6436  loss_offset: 0.4419  time: 0.4002  data_time: 0.0281  lr: 0.00015677  max_mem: 7924M
[12/11 22:15:58 d2.utils.events]:  eta: 0:02:54  iter: 9559  total_loss: 2.198  loss_sem_seg: 0.9404  loss_center: 0.6375  loss_offset: 0.5282  time: 0.4002  data_time: 0.0278  lr: 0.00015064  max_mem: 7924M
[12/11 22:16:06 d2.utils.events]:  eta: 0:02:46  iter: 9579  total_loss: 2.029  loss_sem_seg: 1.001  loss_center: 0.5258  loss_offset: 0.5058  time: 0.4002  data_time: 0.0289  lr: 0.00014448  max_mem: 7924M
[12/11 22:16:14 d2.utils.events]:  eta: 0:02:38  iter: 9599  total_loss: 1.902  loss_sem_seg: 0.7878  loss_center: 0.4285  loss_offset: 0.478  time: 0.4002  data_time: 0.0277  lr: 0.00013828  max_mem: 7924M
[12/11 22:16:22 d2.utils.events]:  eta: 0:02:30  iter: 9619  total_loss: 1.883  loss_sem_seg: 0.8545  loss_center: 0.5155  loss_offset: 0.4899  time: 0.4002  data_time: 0.0275  lr: 0.00013206  max_mem: 7924M
[12/11 22:16:30 d2.utils.events]:  eta: 0:02:22  iter: 9639  total_loss: 1.868  loss_sem_seg: 0.8739  loss_center: 0.5941  loss_offset: 0.4665  time: 0.4002  data_time: 0.0277  lr: 0.0001258  max_mem: 7924M
[12/11 22:16:38 d2.utils.events]:  eta: 0:02:14  iter: 9659  total_loss: 1.822  loss_sem_seg: 0.8507  loss_center: 0.4887  loss_offset: 0.4865  time: 0.4002  data_time: 0.0267  lr: 0.00011951  max_mem: 7924M
[12/11 22:16:46 d2.utils.events]:  eta: 0:02:06  iter: 9679  total_loss: 2.044  loss_sem_seg: 0.9066  loss_center: 0.6047  loss_offset: 0.5269  time: 0.4001  data_time: 0.0297  lr: 0.00011319  max_mem: 7924M
[12/11 22:16:54 d2.utils.events]:  eta: 0:01:58  iter: 9699  total_loss: 1.916  loss_sem_seg: 1.005  loss_center: 0.4144  loss_offset: 0.4646  time: 0.4001  data_time: 0.0296  lr: 0.00010682  max_mem: 7924M
[12/11 22:17:02 d2.utils.events]:  eta: 0:01:50  iter: 9719  total_loss: 1.886  loss_sem_seg: 0.8781  loss_center: 0.5146  loss_offset: 0.5248  time: 0.4001  data_time: 0.0280  lr: 0.00010041  max_mem: 7924M
[12/11 22:17:10 d2.utils.events]:  eta: 0:01:43  iter: 9739  total_loss: 2.016  loss_sem_seg: 0.9839  loss_center: 0.4018  loss_offset: 0.5016  time: 0.4001  data_time: 0.0298  lr: 9.3954e-05  max_mem: 7924M
[12/11 22:17:18 d2.utils.events]:  eta: 0:01:35  iter: 9759  total_loss: 2.128  loss_sem_seg: 1.05  loss_center: 0.4859  loss_offset: 0.549  time: 0.4001  data_time: 0.0258  lr: 8.7449e-05  max_mem: 7924M
[12/11 22:17:26 d2.utils.events]:  eta: 0:01:27  iter: 9779  total_loss: 1.97  loss_sem_seg: 0.8832  loss_center: 0.5227  loss_offset: 0.5056  time: 0.4001  data_time: 0.0277  lr: 8.089e-05  max_mem: 7924M
[12/11 22:17:34 d2.utils.events]:  eta: 0:01:19  iter: 9799  total_loss: 2.203  loss_sem_seg: 0.8513  loss_center: 0.5693  loss_offset: 0.5827  time: 0.4001  data_time: 0.0286  lr: 7.4271e-05  max_mem: 7924M
[12/11 22:17:42 d2.utils.events]:  eta: 0:01:11  iter: 9819  total_loss: 2.116  loss_sem_seg: 0.9442  loss_center: 0.4878  loss_offset: 0.5045  time: 0.4001  data_time: 0.0274  lr: 6.7585e-05  max_mem: 7924M
[12/11 22:17:50 d2.utils.events]:  eta: 0:01:03  iter: 9839  total_loss: 2.198  loss_sem_seg: 1.012  loss_center: 0.5257  loss_offset: 0.6213  time: 0.4001  data_time: 0.0269  lr: 6.0825e-05  max_mem: 7924M
[12/11 22:17:58 d2.utils.events]:  eta: 0:00:55  iter: 9859  total_loss: 2.025  loss_sem_seg: 0.9367  loss_center: 0.4961  loss_offset: 0.4924  time: 0.4001  data_time: 0.0299  lr: 5.3981e-05  max_mem: 7924M
[12/11 22:18:06 d2.utils.events]:  eta: 0:00:47  iter: 9879  total_loss: 2.068  loss_sem_seg: 0.9822  loss_center: 0.4784  loss_offset: 0.4881  time: 0.4001  data_time: 0.0274  lr: 4.7038e-05  max_mem: 7924M
[12/11 22:18:13 d2.utils.events]:  eta: 0:00:39  iter: 9899  total_loss: 2.131  loss_sem_seg: 0.9299  loss_center: 0.5019  loss_offset: 0.6147  time: 0.4001  data_time: 0.0276  lr: 3.9979e-05  max_mem: 7924M
[12/11 22:18:21 d2.utils.events]:  eta: 0:00:31  iter: 9919  total_loss: 1.894  loss_sem_seg: 0.8928  loss_center: 0.4157  loss_offset: 0.4989  time: 0.4001  data_time: 0.0281  lr: 3.2778e-05  max_mem: 7924M
[12/11 22:18:29 d2.utils.events]:  eta: 0:00:23  iter: 9939  total_loss: 1.93  loss_sem_seg: 0.9366  loss_center: 0.4025  loss_offset: 0.4619  time: 0.4001  data_time: 0.0282  lr: 2.5394e-05  max_mem: 7924M
[12/11 22:18:37 d2.utils.events]:  eta: 0:00:15  iter: 9959  total_loss: 2.018  loss_sem_seg: 0.9701  loss_center: 0.4568  loss_offset: 0.5092  time: 0.4000  data_time: 0.0285  lr: 1.776e-05  max_mem: 7924M
[12/11 22:18:45 d2.utils.events]:  eta: 0:00:07  iter: 9979  total_loss: 1.774  loss_sem_seg: 0.7952  loss_center: 0.5902  loss_offset: 0.4168  time: 0.4000  data_time: 0.0283  lr: 9.7261e-06  max_mem: 7924M
[12/11 22:18:53 fvcore.common.checkpoint]: Saving checkpoint to ./output/model_0009999.pth
[12/11 22:18:54 fvcore.common.checkpoint]: Saving checkpoint to ./output/model_final.pth
[12/11 22:18:55 d2.utils.events]:  eta: 0:00:00  iter: 9999  total_loss: 2.031  loss_sem_seg: 0.8071  loss_center: 0.5075  loss_offset: 0.5131  time: 0.4000  data_time: 0.0271  lr: 6.2797e-07  max_mem: 7924M
[12/11 22:18:55 d2.engine.hooks]: Overall training speed: 9998 iterations in 1:06:39 (0.4001 s / it)
[12/11 22:18:55 d2.engine.hooks]: Total training time: 1:06:49 (0:00:09 on hooks)
[12/11 22:18:56 d2.data.dataset_mapper]: [DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(640, 640), max_size=640, sample_style='choice')]
[12/11 22:18:56 d2.data.common]: Serializing the dataset using: <class 'detectron2.data.common.NumpySerializedList'>
[12/11 22:18:56 d2.data.common]: Serializing 5000 elements to byte tensors and concatenating them all ...
[12/11 22:18:56 d2.data.common]: Serialized dataset takes 3.40 MiB
/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:481: UserWarning: This DataLoader will create 10 worker processes in total. Our suggested max number of worker in current system is 8, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.
  cpuset_checked))
[12/11 22:18:57 d2.evaluation.evaluator]: Start inference on 5000 batches
/usr/local/lib/python3.7/dist-packages/torch/functional.py:445: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at  ../aten/src/ATen/native/TensorShape.cpp:2157.)
  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]
[12/11 22:18:59 d2.evaluation.evaluator]: Inference done 11/5000. Dataloading: 0.0009 s/iter. Inference: 0.0730 s/iter. Eval: 0.0415 s/iter. Total: 0.1153 s/iter. ETA=0:09:35
[12/11 22:19:04 d2.evaluation.evaluator]: Inference done 56/5000. Dataloading: 0.0012 s/iter. Inference: 0.0772 s/iter. Eval: 0.0347 s/iter. Total: 0.1132 s/iter. ETA=0:09:19
[12/11 22:19:09 d2.evaluation.evaluator]: Inference done 102/5000. Dataloading: 0.0013 s/iter. Inference: 0.0744 s/iter. Eval: 0.0359 s/iter. Total: 0.1116 s/iter. ETA=0:09:06
[12/11 22:19:14 d2.evaluation.evaluator]: Inference done 147/5000. Dataloading: 0.0013 s/iter. Inference: 0.0740 s/iter. Eval: 0.0367 s/iter. Total: 0.1121 s/iter. ETA=0:09:03
[12/11 22:19:19 d2.evaluation.evaluator]: Inference done 192/5000. Dataloading: 0.0013 s/iter. Inference: 0.0737 s/iter. Eval: 0.0371 s/iter. Total: 0.1122 s/iter. ETA=0:08:59
[12/11 22:19:24 d2.evaluation.evaluator]: Inference done 241/5000. Dataloading: 0.0014 s/iter. Inference: 0.0725 s/iter. Eval: 0.0365 s/iter. Total: 0.1104 s/iter. ETA=0:08:45
[12/11 22:19:30 d2.evaluation.evaluator]: Inference done 289/5000. Dataloading: 0.0014 s/iter. Inference: 0.0718 s/iter. Eval: 0.0364 s/iter. Total: 0.1096 s/iter. ETA=0:08:36
[12/11 22:19:35 d2.evaluation.evaluator]: Inference done 335/5000. Dataloading: 0.0014 s/iter. Inference: 0.0718 s/iter. Eval: 0.0366 s/iter. Total: 0.1098 s/iter. ETA=0:08:32
[12/11 22:19:40 d2.evaluation.evaluator]: Inference done 383/5000. Dataloading: 0.0014 s/iter. Inference: 0.0713 s/iter. Eval: 0.0365 s/iter. Total: 0.1092 s/iter. ETA=0:08:24
[12/11 22:19:45 d2.evaluation.evaluator]: Inference done 433/5000. Dataloading: 0.0014 s/iter. Inference: 0.0706 s/iter. Eval: 0.0362 s/iter. Total: 0.1083 s/iter. ETA=0:08:14
[12/11 22:19:50 d2.evaluation.evaluator]: Inference done 483/5000. Dataloading: 0.0014 s/iter. Inference: 0.0702 s/iter. Eval: 0.0360 s/iter. Total: 0.1076 s/iter. ETA=0:08:06
[12/11 22:19:55 d2.evaluation.evaluator]: Inference done 530/5000. Dataloading: 0.0014 s/iter. Inference: 0.0701 s/iter. Eval: 0.0360 s/iter. Total: 0.1076 s/iter. ETA=0:08:01
[12/11 22:20:00 d2.evaluation.evaluator]: Inference done 576/5000. Dataloading: 0.0014 s/iter. Inference: 0.0702 s/iter. Eval: 0.0361 s/iter. Total: 0.1078 s/iter. ETA=0:07:56
[12/11 22:20:05 d2.evaluation.evaluator]: Inference done 622/5000. Dataloading: 0.0014 s/iter. Inference: 0.0703 s/iter. Eval: 0.0362 s/iter. Total: 0.1079 s/iter. ETA=0:07:52
[12/11 22:20:10 d2.evaluation.evaluator]: Inference done 666/5000. Dataloading: 0.0014 s/iter. Inference: 0.0705 s/iter. Eval: 0.0365 s/iter. Total: 0.1084 s/iter. ETA=0:07:49
[12/11 22:20:15 d2.evaluation.evaluator]: Inference done 714/5000. Dataloading: 0.0014 s/iter. Inference: 0.0703 s/iter. Eval: 0.0364 s/iter. Total: 0.1081 s/iter. ETA=0:07:43
[12/11 22:20:20 d2.evaluation.evaluator]: Inference done 762/5000. Dataloading: 0.0014 s/iter. Inference: 0.0701 s/iter. Eval: 0.0364 s/iter. Total: 0.1080 s/iter. ETA=0:07:37
[12/11 22:20:25 d2.evaluation.evaluator]: Inference done 811/5000. Dataloading: 0.0014 s/iter. Inference: 0.0699 s/iter. Eval: 0.0363 s/iter. Total: 0.1077 s/iter. ETA=0:07:31
[12/11 22:20:30 d2.evaluation.evaluator]: Inference done 861/5000. Dataloading: 0.0014 s/iter. Inference: 0.0697 s/iter. Eval: 0.0362 s/iter. Total: 0.1073 s/iter. ETA=0:07:24
[12/11 22:20:35 d2.evaluation.evaluator]: Inference done 911/5000. Dataloading: 0.0014 s/iter. Inference: 0.0695 s/iter. Eval: 0.0361 s/iter. Total: 0.1070 s/iter. ETA=0:07:17
[12/11 22:20:40 d2.evaluation.evaluator]: Inference done 960/5000. Dataloading: 0.0014 s/iter. Inference: 0.0694 s/iter. Eval: 0.0360 s/iter. Total: 0.1068 s/iter. ETA=0:07:11
[12/11 22:20:45 d2.evaluation.evaluator]: Inference done 1008/5000. Dataloading: 0.0014 s/iter. Inference: 0.0694 s/iter. Eval: 0.0359 s/iter. Total: 0.1067 s/iter. ETA=0:07:06
[12/11 22:20:51 d2.evaluation.evaluator]: Inference done 1055/5000. Dataloading: 0.0014 s/iter. Inference: 0.0694 s/iter. Eval: 0.0360 s/iter. Total: 0.1068 s/iter. ETA=0:07:01
[12/11 22:20:56 d2.evaluation.evaluator]: Inference done 1103/5000. Dataloading: 0.0014 s/iter. Inference: 0.0694 s/iter. Eval: 0.0359 s/iter. Total: 0.1067 s/iter. ETA=0:06:55
[12/11 22:21:01 d2.evaluation.evaluator]: Inference done 1152/5000. Dataloading: 0.0014 s/iter. Inference: 0.0692 s/iter. Eval: 0.0359 s/iter. Total: 0.1066 s/iter. ETA=0:06:50
[12/11 22:21:06 d2.evaluation.evaluator]: Inference done 1201/5000. Dataloading: 0.0014 s/iter. Inference: 0.0692 s/iter. Eval: 0.0358 s/iter. Total: 0.1064 s/iter. ETA=0:06:44
[12/11 22:21:11 d2.evaluation.evaluator]: Inference done 1246/5000. Dataloading: 0.0014 s/iter. Inference: 0.0693 s/iter. Eval: 0.0359 s/iter. Total: 0.1067 s/iter. ETA=0:06:40
[12/11 22:21:16 d2.evaluation.evaluator]: Inference done 1293/5000. Dataloading: 0.0014 s/iter. Inference: 0.0693 s/iter. Eval: 0.0360 s/iter. Total: 0.1067 s/iter. ETA=0:06:35
[12/11 22:21:21 d2.evaluation.evaluator]: Inference done 1341/5000. Dataloading: 0.0014 s/iter. Inference: 0.0693 s/iter. Eval: 0.0359 s/iter. Total: 0.1067 s/iter. ETA=0:06:30
[12/11 22:21:26 d2.evaluation.evaluator]: Inference done 1388/5000. Dataloading: 0.0014 s/iter. Inference: 0.0693 s/iter. Eval: 0.0359 s/iter. Total: 0.1067 s/iter. ETA=0:06:25
[12/11 22:21:31 d2.evaluation.evaluator]: Inference done 1435/5000. Dataloading: 0.0014 s/iter. Inference: 0.0693 s/iter. Eval: 0.0359 s/iter. Total: 0.1066 s/iter. ETA=0:06:20
[12/11 22:21:36 d2.evaluation.evaluator]: Inference done 1482/5000. Dataloading: 0.0014 s/iter. Inference: 0.0692 s/iter. Eval: 0.0360 s/iter. Total: 0.1067 s/iter. ETA=0:06:15
[12/11 22:21:41 d2.evaluation.evaluator]: Inference done 1530/5000. Dataloading: 0.0014 s/iter. Inference: 0.0692 s/iter. Eval: 0.0360 s/iter. Total: 0.1066 s/iter. ETA=0:06:09
[12/11 22:21:46 d2.evaluation.evaluator]: Inference done 1577/5000. Dataloading: 0.0014 s/iter. Inference: 0.0692 s/iter. Eval: 0.0361 s/iter. Total: 0.1067 s/iter. ETA=0:06:05
[12/11 22:21:51 d2.evaluation.evaluator]: Inference done 1624/5000. Dataloading: 0.0014 s/iter. Inference: 0.0692 s/iter. Eval: 0.0361 s/iter. Total: 0.1067 s/iter. ETA=0:06:00
[12/11 22:21:56 d2.evaluation.evaluator]: Inference done 1671/5000. Dataloading: 0.0014 s/iter. Inference: 0.0692 s/iter. Eval: 0.0361 s/iter. Total: 0.1067 s/iter. ETA=0:05:55
[12/11 22:22:01 d2.evaluation.evaluator]: Inference done 1719/5000. Dataloading: 0.0014 s/iter. Inference: 0.0692 s/iter. Eval: 0.0361 s/iter. Total: 0.1067 s/iter. ETA=0:05:50
[12/11 22:22:06 d2.evaluation.evaluator]: Inference done 1769/5000. Dataloading: 0.0014 s/iter. Inference: 0.0691 s/iter. Eval: 0.0361 s/iter. Total: 0.1066 s/iter. ETA=0:05:44
[12/11 22:22:11 d2.evaluation.evaluator]: Inference done 1816/5000. Dataloading: 0.0014 s/iter. Inference: 0.0691 s/iter. Eval: 0.0361 s/iter. Total: 0.1066 s/iter. ETA=0:05:39
[12/11 22:22:17 d2.evaluation.evaluator]: Inference done 1863/5000. Dataloading: 0.0014 s/iter. Inference: 0.0691 s/iter. Eval: 0.0361 s/iter. Total: 0.1066 s/iter. ETA=0:05:34
[12/11 22:22:22 d2.evaluation.evaluator]: Inference done 1910/5000. Dataloading: 0.0014 s/iter. Inference: 0.0691 s/iter. Eval: 0.0361 s/iter. Total: 0.1066 s/iter. ETA=0:05:29
[12/11 22:22:27 d2.evaluation.evaluator]: Inference done 1961/5000. Dataloading: 0.0014 s/iter. Inference: 0.0690 s/iter. Eval: 0.0361 s/iter. Total: 0.1065 s/iter. ETA=0:05:23
[12/11 22:22:32 d2.evaluation.evaluator]: Inference done 2008/5000. Dataloading: 0.0014 s/iter. Inference: 0.0690 s/iter. Eval: 0.0361 s/iter. Total: 0.1065 s/iter. ETA=0:05:18
[12/11 22:22:37 d2.evaluation.evaluator]: Inference done 2055/5000. Dataloading: 0.0014 s/iter. Inference: 0.0689 s/iter. Eval: 0.0361 s/iter. Total: 0.1065 s/iter. ETA=0:05:13
[12/11 22:22:42 d2.evaluation.evaluator]: Inference done 2104/5000. Dataloading: 0.0014 s/iter. Inference: 0.0689 s/iter. Eval: 0.0361 s/iter. Total: 0.1064 s/iter. ETA=0:05:08
[12/11 22:22:47 d2.evaluation.evaluator]: Inference done 2152/5000. Dataloading: 0.0014 s/iter. Inference: 0.0689 s/iter. Eval: 0.0361 s/iter. Total: 0.1064 s/iter. ETA=0:05:02
[12/11 22:22:52 d2.evaluation.evaluator]: Inference done 2201/5000. Dataloading: 0.0014 s/iter. Inference: 0.0688 s/iter. Eval: 0.0360 s/iter. Total: 0.1063 s/iter. ETA=0:04:57
[12/11 22:22:57 d2.evaluation.evaluator]: Inference done 2249/5000. Dataloading: 0.0014 s/iter. Inference: 0.0688 s/iter. Eval: 0.0360 s/iter. Total: 0.1063 s/iter. ETA=0:04:52
[12/11 22:23:02 d2.evaluation.evaluator]: Inference done 2298/5000. Dataloading: 0.0014 s/iter. Inference: 0.0688 s/iter. Eval: 0.0360 s/iter. Total: 0.1062 s/iter. ETA=0:04:46
[12/11 22:23:07 d2.evaluation.evaluator]: Inference done 2349/5000. Dataloading: 0.0014 s/iter. Inference: 0.0687 s/iter. Eval: 0.0359 s/iter. Total: 0.1060 s/iter. ETA=0:04:41
[12/11 22:23:12 d2.evaluation.evaluator]: Inference done 2396/5000. Dataloading: 0.0014 s/iter. Inference: 0.0687 s/iter. Eval: 0.0359 s/iter. Total: 0.1061 s/iter. ETA=0:04:36
[12/11 22:23:17 d2.evaluation.evaluator]: Inference done 2442/5000. Dataloading: 0.0014 s/iter. Inference: 0.0688 s/iter. Eval: 0.0359 s/iter. Total: 0.1061 s/iter. ETA=0:04:31
[12/11 22:23:22 d2.evaluation.evaluator]: Inference done 2489/5000. Dataloading: 0.0014 s/iter. Inference: 0.0688 s/iter. Eval: 0.0360 s/iter. Total: 0.1062 s/iter. ETA=0:04:26
[12/11 22:23:27 d2.evaluation.evaluator]: Inference done 2537/5000. Dataloading: 0.0014 s/iter. Inference: 0.0688 s/iter. Eval: 0.0360 s/iter. Total: 0.1062 s/iter. ETA=0:04:21
[12/11 22:23:32 d2.evaluation.evaluator]: Inference done 2584/5000. Dataloading: 0.0014 s/iter. Inference: 0.0688 s/iter. Eval: 0.0360 s/iter. Total: 0.1062 s/iter. ETA=0:04:16
[12/11 22:23:37 d2.evaluation.evaluator]: Inference done 2631/5000. Dataloading: 0.0014 s/iter. Inference: 0.0688 s/iter. Eval: 0.0360 s/iter. Total: 0.1062 s/iter. ETA=0:04:11
[12/11 22:23:42 d2.evaluation.evaluator]: Inference done 2681/5000. Dataloading: 0.0014 s/iter. Inference: 0.0688 s/iter. Eval: 0.0359 s/iter. Total: 0.1061 s/iter. ETA=0:04:06
[12/11 22:23:47 d2.evaluation.evaluator]: Inference done 2731/5000. Dataloading: 0.0014 s/iter. Inference: 0.0687 s/iter. Eval: 0.0359 s/iter. Total: 0.1060 s/iter. ETA=0:04:00
[12/11 22:23:52 d2.evaluation.evaluator]: Inference done 2780/5000. Dataloading: 0.0014 s/iter. Inference: 0.0687 s/iter. Eval: 0.0358 s/iter. Total: 0.1060 s/iter. ETA=0:03:55
[12/11 22:23:58 d2.evaluation.evaluator]: Inference done 2828/5000. Dataloading: 0.0014 s/iter. Inference: 0.0687 s/iter. Eval: 0.0359 s/iter. Total: 0.1060 s/iter. ETA=0:03:50
[12/11 22:24:03 d2.evaluation.evaluator]: Inference done 2876/5000. Dataloading: 0.0014 s/iter. Inference: 0.0687 s/iter. Eval: 0.0359 s/iter. Total: 0.1060 s/iter. ETA=0:03:45
[12/11 22:24:08 d2.evaluation.evaluator]: Inference done 2923/5000. Dataloading: 0.0014 s/iter. Inference: 0.0687 s/iter. Eval: 0.0359 s/iter. Total: 0.1060 s/iter. ETA=0:03:40
[12/11 22:24:13 d2.evaluation.evaluator]: Inference done 2972/5000. Dataloading: 0.0014 s/iter. Inference: 0.0686 s/iter. Eval: 0.0358 s/iter. Total: 0.1059 s/iter. ETA=0:03:34
[12/11 22:24:18 d2.evaluation.evaluator]: Inference done 3021/5000. Dataloading: 0.0014 s/iter. Inference: 0.0686 s/iter. Eval: 0.0358 s/iter. Total: 0.1059 s/iter. ETA=0:03:29
[12/11 22:24:23 d2.evaluation.evaluator]: Inference done 3072/5000. Dataloading: 0.0014 s/iter. Inference: 0.0686 s/iter. Eval: 0.0358 s/iter. Total: 0.1058 s/iter. ETA=0:03:23
[12/11 22:24:28 d2.evaluation.evaluator]: Inference done 3120/5000. Dataloading: 0.0014 s/iter. Inference: 0.0685 s/iter. Eval: 0.0358 s/iter. Total: 0.1058 s/iter. ETA=0:03:18
[12/11 22:24:33 d2.evaluation.evaluator]: Inference done 3166/5000. Dataloading: 0.0014 s/iter. Inference: 0.0686 s/iter. Eval: 0.0358 s/iter. Total: 0.1058 s/iter. ETA=0:03:14
[12/11 22:24:38 d2.evaluation.evaluator]: Inference done 3213/5000. Dataloading: 0.0014 s/iter. Inference: 0.0686 s/iter. Eval: 0.0358 s/iter. Total: 0.1059 s/iter. ETA=0:03:09
[12/11 22:24:43 d2.evaluation.evaluator]: Inference done 3260/5000. Dataloading: 0.0014 s/iter. Inference: 0.0686 s/iter. Eval: 0.0358 s/iter. Total: 0.1059 s/iter. ETA=0:03:04
[12/11 22:24:48 d2.evaluation.evaluator]: Inference done 3306/5000. Dataloading: 0.0014 s/iter. Inference: 0.0686 s/iter. Eval: 0.0359 s/iter. Total: 0.1059 s/iter. ETA=0:02:59
[12/11 22:24:53 d2.evaluation.evaluator]: Inference done 3353/5000. Dataloading: 0.0014 s/iter. Inference: 0.0686 s/iter. Eval: 0.0359 s/iter. Total: 0.1059 s/iter. ETA=0:02:54
[12/11 22:24:58 d2.evaluation.evaluator]: Inference done 3401/5000. Dataloading: 0.0014 s/iter. Inference: 0.0686 s/iter. Eval: 0.0359 s/iter. Total: 0.1059 s/iter. ETA=0:02:49
[12/11 22:25:03 d2.evaluation.evaluator]: Inference done 3447/5000. Dataloading: 0.0014 s/iter. Inference: 0.0686 s/iter. Eval: 0.0359 s/iter. Total: 0.1060 s/iter. ETA=0:02:44
[12/11 22:25:08 d2.evaluation.evaluator]: Inference done 3498/5000. Dataloading: 0.0014 s/iter. Inference: 0.0686 s/iter. Eval: 0.0359 s/iter. Total: 0.1059 s/iter. ETA=0:02:39
[12/11 22:25:13 d2.evaluation.evaluator]: Inference done 3545/5000. Dataloading: 0.0014 s/iter. Inference: 0.0686 s/iter. Eval: 0.0359 s/iter. Total: 0.1059 s/iter. ETA=0:02:34
[12/11 22:25:18 d2.evaluation.evaluator]: Inference done 3592/5000. Dataloading: 0.0014 s/iter. Inference: 0.0686 s/iter. Eval: 0.0359 s/iter. Total: 0.1059 s/iter. ETA=0:02:29
[12/11 22:25:23 d2.evaluation.evaluator]: Inference done 3641/5000. Dataloading: 0.0014 s/iter. Inference: 0.0686 s/iter. Eval: 0.0359 s/iter. Total: 0.1059 s/iter. ETA=0:02:23
[12/11 22:25:28 d2.evaluation.evaluator]: Inference done 3690/5000. Dataloading: 0.0014 s/iter. Inference: 0.0686 s/iter. Eval: 0.0359 s/iter. Total: 0.1059 s/iter. ETA=0:02:18
[12/11 22:25:33 d2.evaluation.evaluator]: Inference done 3739/5000. Dataloading: 0.0014 s/iter. Inference: 0.0685 s/iter. Eval: 0.0358 s/iter. Total: 0.1058 s/iter. ETA=0:02:13
[12/11 22:25:39 d2.evaluation.evaluator]: Inference done 3785/5000. Dataloading: 0.0014 s/iter. Inference: 0.0686 s/iter. Eval: 0.0358 s/iter. Total: 0.1059 s/iter. ETA=0:02:08
[12/11 22:25:44 d2.evaluation.evaluator]: Inference done 3833/5000. Dataloading: 0.0014 s/iter. Inference: 0.0686 s/iter. Eval: 0.0358 s/iter. Total: 0.1058 s/iter. ETA=0:02:03
[12/11 22:25:49 d2.evaluation.evaluator]: Inference done 3883/5000. Dataloading: 0.0014 s/iter. Inference: 0.0685 s/iter. Eval: 0.0358 s/iter. Total: 0.1058 s/iter. ETA=0:01:58
[12/11 22:25:54 d2.evaluation.evaluator]: Inference done 3932/5000. Dataloading: 0.0014 s/iter. Inference: 0.0685 s/iter. Eval: 0.0358 s/iter. Total: 0.1058 s/iter. ETA=0:01:52
[12/11 22:25:59 d2.evaluation.evaluator]: Inference done 3982/5000. Dataloading: 0.0014 s/iter. Inference: 0.0685 s/iter. Eval: 0.0358 s/iter. Total: 0.1057 s/iter. ETA=0:01:47
[12/11 22:26:04 d2.evaluation.evaluator]: Inference done 4030/5000. Dataloading: 0.0014 s/iter. Inference: 0.0685 s/iter. Eval: 0.0358 s/iter. Total: 0.1057 s/iter. ETA=0:01:42
[12/11 22:26:09 d2.evaluation.evaluator]: Inference done 4077/5000. Dataloading: 0.0014 s/iter. Inference: 0.0685 s/iter. Eval: 0.0358 s/iter. Total: 0.1057 s/iter. ETA=0:01:37
[12/11 22:26:14 d2.evaluation.evaluator]: Inference done 4123/5000. Dataloading: 0.0014 s/iter. Inference: 0.0685 s/iter. Eval: 0.0358 s/iter. Total: 0.1058 s/iter. ETA=0:01:32
[12/11 22:26:19 d2.evaluation.evaluator]: Inference done 4169/5000. Dataloading: 0.0014 s/iter. Inference: 0.0686 s/iter. Eval: 0.0358 s/iter. Total: 0.1058 s/iter. ETA=0:01:27
[12/11 22:26:24 d2.evaluation.evaluator]: Inference done 4218/5000. Dataloading: 0.0014 s/iter. Inference: 0.0685 s/iter. Eval: 0.0358 s/iter. Total: 0.1058 s/iter. ETA=0:01:22
[12/11 22:26:29 d2.evaluation.evaluator]: Inference done 4266/5000. Dataloading: 0.0014 s/iter. Inference: 0.0685 s/iter. Eval: 0.0358 s/iter. Total: 0.1058 s/iter. ETA=0:01:17
[12/11 22:26:34 d2.evaluation.evaluator]: Inference done 4315/5000. Dataloading: 0.0014 s/iter. Inference: 0.0685 s/iter. Eval: 0.0358 s/iter. Total: 0.1057 s/iter. ETA=0:01:12
[12/11 22:26:39 d2.evaluation.evaluator]: Inference done 4368/5000. Dataloading: 0.0014 s/iter. Inference: 0.0684 s/iter. Eval: 0.0357 s/iter. Total: 0.1056 s/iter. ETA=0:01:06
[12/11 22:26:44 d2.evaluation.evaluator]: Inference done 4416/5000. Dataloading: 0.0014 s/iter. Inference: 0.0684 s/iter. Eval: 0.0358 s/iter. Total: 0.1056 s/iter. ETA=0:01:01
[12/11 22:26:49 d2.evaluation.evaluator]: Inference done 4465/5000. Dataloading: 0.0014 s/iter. Inference: 0.0684 s/iter. Eval: 0.0358 s/iter. Total: 0.1056 s/iter. ETA=0:00:56
[12/11 22:26:55 d2.evaluation.evaluator]: Inference done 4515/5000. Dataloading: 0.0014 s/iter. Inference: 0.0684 s/iter. Eval: 0.0357 s/iter. Total: 0.1056 s/iter. ETA=0:00:51
[12/11 22:27:00 d2.evaluation.evaluator]: Inference done 4564/5000. Dataloading: 0.0014 s/iter. Inference: 0.0684 s/iter. Eval: 0.0357 s/iter. Total: 0.1056 s/iter. ETA=0:00:46
[12/11 22:27:05 d2.evaluation.evaluator]: Inference done 4613/5000. Dataloading: 0.0014 s/iter. Inference: 0.0684 s/iter. Eval: 0.0357 s/iter. Total: 0.1055 s/iter. ETA=0:00:40
[12/11 22:27:10 d2.evaluation.evaluator]: Inference done 4661/5000. Dataloading: 0.0014 s/iter. Inference: 0.0684 s/iter. Eval: 0.0357 s/iter. Total: 0.1055 s/iter. ETA=0:00:35
[12/11 22:27:15 d2.evaluation.evaluator]: Inference done 4710/5000. Dataloading: 0.0014 s/iter. Inference: 0.0684 s/iter. Eval: 0.0357 s/iter. Total: 0.1055 s/iter. ETA=0:00:30
[12/11 22:27:20 d2.evaluation.evaluator]: Inference done 4760/5000. Dataloading: 0.0014 s/iter. Inference: 0.0683 s/iter. Eval: 0.0357 s/iter. Total: 0.1055 s/iter. ETA=0:00:25
[12/11 22:27:25 d2.evaluation.evaluator]: Inference done 4807/5000. Dataloading: 0.0014 s/iter. Inference: 0.0683 s/iter. Eval: 0.0357 s/iter. Total: 0.1055 s/iter. ETA=0:00:20
[12/11 22:27:30 d2.evaluation.evaluator]: Inference done 4856/5000. Dataloading: 0.0014 s/iter. Inference: 0.0683 s/iter. Eval: 0.0357 s/iter. Total: 0.1054 s/iter. ETA=0:00:15
[12/11 22:27:35 d2.evaluation.evaluator]: Inference done 4906/5000. Dataloading: 0.0014 s/iter. Inference: 0.0683 s/iter. Eval: 0.0357 s/iter. Total: 0.1054 s/iter. ETA=0:00:09
[12/11 22:27:40 d2.evaluation.evaluator]: Inference done 4954/5000. Dataloading: 0.0014 s/iter. Inference: 0.0683 s/iter. Eval: 0.0357 s/iter. Total: 0.1054 s/iter. ETA=0:00:04
[12/11 22:27:45 d2.evaluation.evaluator]: Total inference time: 0:08:46.697768 (0.105445 s / iter per device, on 1 devices)
[12/11 22:27:45 d2.evaluation.evaluator]: Total inference pure compute time: 0:05:41 (0.068275 s / iter per device, on 1 devices)
[12/11 22:27:45 d2.evaluation.panoptic_evaluation]: Writing all panoptic predictions to /tmp/panoptic_evalzy3lt63x ...
[12/11 22:28:10 d2.evaluation.panoptic_evaluation]: Panoptic Evaluation Results:
|        |   PQ   |   SQ   |   RQ   |  #categories  |
|:------:|:------:|:------:|:------:|:-------------:|
|  All   | 18.104 | 62.888 | 23.520 |      133      |
| Things | 18.329 | 68.318 | 23.762 |      80       |
| Stuff  | 17.763 | 54.693 | 23.154 |      53       |
[12/11 22:28:10 d2.evaluation.coco_evaluation]: Preparing results for COCO format ...
[12/11 22:28:10 d2.evaluation.coco_evaluation]: Saving results to ./output/inference/coco_instances_results.json
[12/11 22:28:11 d2.evaluation.coco_evaluation]: Evaluating predictions with unofficial COCO API...
Loading and preparing results...
DONE (t=0.04s)
creating index...
index created!
[12/11 22:28:11 d2.evaluation.fast_eval_api]: Evaluate annotation type *bbox*
[12/11 22:28:19 d2.evaluation.fast_eval_api]: COCOeval_opt.evaluate() finished in 8.44 seconds.
[12/11 22:28:19 d2.evaluation.fast_eval_api]: Accumulating evaluation results...
[12/11 22:28:20 d2.evaluation.fast_eval_api]: COCOeval_opt.accumulate() finished in 0.67 seconds.
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.072
 Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.139
 Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.066
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.008
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.061
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.122
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.091
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.123
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.124
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.010
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.097
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.219
[12/11 22:28:20 d2.evaluation.coco_evaluation]: Evaluation results for bbox: 
|  AP   |  AP50  |  AP75  |  APs  |  APm  |  APl   |
|:-----:|:------:|:------:|:-----:|:-----:|:------:|
| 7.166 | 13.911 | 6.587  | 0.833 | 6.066 | 12.221 |
[12/11 22:28:20 d2.evaluation.coco_evaluation]: Per-category bbox AP: 
| category      | AP     | category     | AP     | category       | AP     |
|:--------------|:-------|:-------------|:-------|:---------------|:-------|
| person        | 14.658 | bicycle      | 4.002  | car            | 6.753  |
| motorcycle    | 7.620  | airplane     | 17.379 | bus            | 30.431 |
| train         | 31.834 | truck        | 3.245  | boat           | 2.147  |
| traffic light | 2.652  | fire hydrant | 25.263 | stop sign      | 32.051 |
| parking meter | 5.151  | bench        | 3.336  | bird           | 4.931  |
| cat           | 13.876 | dog          | 11.334 | horse          | 15.615 |
| sheep         | 11.696 | cow          | 9.678  | elephant       | 23.456 |
| bear          | 26.774 | zebra        | 29.450 | giraffe        | 29.318 |
| backpack      | 0.347  | umbrella     | 8.060  | handbag        | 0.000  |
| tie           | 0.198  | suitcase     | 4.445  | frisbee        | 10.330 |
| skis          | 1.086  | snowboard    | 0.523  | sports ball    | 2.221  |
| kite          | 10.242 | baseball bat | 0.073  | baseball glove | 2.463  |
| skateboard    | 6.010  | surfboard    | 3.496  | tennis racket  | 9.200  |
| bottle        | 0.891  | wine glass   | 0.198  | cup            | 2.182  |
| fork          | 0.014  | knife        | 0.000  | spoon          | 0.000  |
| bowl          | 2.790  | banana       | 1.946  | apple          | 0.625  |
| sandwich      | 0.319  | orange       | 2.685  | broccoli       | 1.784  |
| carrot        | 0.179  | hot dog      | 0.594  | pizza          | 6.012  |
| donut         | 2.713  | cake         | 0.438  | chair          | 2.429  |
| couch         | 10.213 | potted plant | 1.104  | bed            | 15.459 |
| dining table  | 2.106  | toilet       | 21.138 | tv             | 17.180 |
| laptop        | 10.627 | mouse        | 2.239  | remote         | 0.074  |
| keyboard      | 2.697  | cell phone   | 2.143  | microwave      | 6.611  |
| oven          | 2.355  | toaster      | 0.000  | sink           | 5.943  |
| refrigerator  | 9.893  | book         | 0.206  | clock          | 10.091 |
| vase          | 1.113  | scissors     | 0.000  | teddy bear     | 4.922  |
| hair drier    | 0.000  | toothbrush   | 0.000  |                |        |
Loading and preparing results...
DONE (t=0.46s)
creating index...
index created!
[12/11 22:28:21 d2.evaluation.fast_eval_api]: Evaluate annotation type *segm*
[12/11 22:28:31 d2.evaluation.fast_eval_api]: COCOeval_opt.evaluate() finished in 9.68 seconds.
[12/11 22:28:31 d2.evaluation.fast_eval_api]: Accumulating evaluation results...
[12/11 22:28:32 d2.evaluation.fast_eval_api]: COCOeval_opt.accumulate() finished in 0.72 seconds.
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.074
 Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.146
 Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.068
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.005
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.059
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.159
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.089
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.115
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.116
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.008
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.094
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.212
[12/11 22:28:34 d2.evaluation.coco_evaluation]: Evaluation results for segm: 
|  AP   |  AP50  |  AP75  |  APs  |  APm  |  APl   |
|:-----:|:------:|:------:|:-----:|:-----:|:------:|
| 7.419 | 14.572 | 6.767  | 0.521 | 5.916 | 15.865 |
[12/11 22:28:34 d2.evaluation.coco_evaluation]: Per-category segm AP: 
| category      | AP     | category     | AP     | category       | AP     |
|:--------------|:-------|:-------------|:-------|:---------------|:-------|
| person        | 10.426 | bicycle      | 1.874  | car            | 6.814  |
| motorcycle    | 5.076  | airplane     | 17.220 | bus            | 32.020 |
| train         | 36.620 | truck        | 3.283  | boat           | 1.757  |
| traffic light | 3.235  | fire hydrant | 30.832 | stop sign      | 35.743 |
| parking meter | 9.346  | bench        | 2.564  | bird           | 5.026  |
| cat           | 17.824 | dog          | 14.431 | horse          | 10.803 |
| sheep         | 10.126 | cow          | 7.509  | elephant       | 22.568 |
| bear          | 34.023 | zebra        | 21.088 | giraffe        | 21.180 |
| backpack      | 0.198  | umbrella     | 10.629 | handbag        | 0.000  |
| tie           | 0.099  | suitcase     | 5.678  | frisbee        | 10.369 |
| skis          | 0.020  | snowboard    | 0.354  | sports ball    | 2.330  |
| kite          | 5.005  | baseball bat | 0.130  | baseball glove | 3.162  |
| skateboard    | 1.385  | surfboard    | 2.578  | tennis racket  | 14.074 |
| bottle        | 1.746  | wine glass   | 0.190  | cup            | 4.867  |
| fork          | 0.000  | knife        | 0.000  | spoon          | 0.000  |
| bowl          | 5.453  | banana       | 1.027  | apple          | 0.954  |
| sandwich      | 1.594  | orange       | 4.571  | broccoli       | 1.989  |
| carrot        | 0.142  | hot dog      | 0.594  | pizza          | 6.768  |
| donut         | 3.825  | cake         | 0.985  | chair          | 1.563  |
| couch         | 9.989  | potted plant | 1.695  | bed            | 10.244 |
| dining table  | 0.158  | toilet       | 28.194 | tv             | 20.503 |
| laptop        | 15.771 | mouse        | 2.490  | remote         | 0.617  |
| keyboard      | 6.098  | cell phone   | 2.935  | microwave      | 6.048  |
| oven          | 1.557  | toaster      | 0.000  | sink           | 6.251  |
| refrigerator  | 8.416  | book         | 0.141  | clock          | 10.423 |
| vase          | 1.981  | scissors     | 0.000  | teddy bear     | 6.317  |
| hair drier    | 0.000  | toothbrush   | 0.000  |                |        |
[12/11 22:28:38 d2.engine.defaults]: Evaluation results for coco_2017_val_panoptic in csv format:
[12/11 22:28:38 d2.evaluation.testing]: copypaste: Task: panoptic_seg
[12/11 22:28:38 d2.evaluation.testing]: copypaste: PQ,SQ,RQ,PQ_th,SQ_th,RQ_th,PQ_st,SQ_st,RQ_st
[12/11 22:28:38 d2.evaluation.testing]: copypaste: 18.1035,62.8885,23.5199,18.3293,68.3183,23.7624,17.7627,54.6926,23.1537
[12/11 22:28:38 d2.evaluation.testing]: copypaste: Task: bbox
[12/11 22:28:38 d2.evaluation.testing]: copypaste: AP,AP50,AP75,APs,APm,APl
[12/11 22:28:38 d2.evaluation.testing]: copypaste: 7.1657,13.9110,6.5871,0.8334,6.0663,12.2211
[12/11 22:28:38 d2.evaluation.testing]: copypaste: Task: segm
[12/11 22:28:38 d2.evaluation.testing]: copypaste: AP,AP50,AP75,APs,APm,APl
[12/11 22:28:38 d2.evaluation.testing]: copypaste: 7.4187,14.5721,6.7667,0.5211,5.9156,15.8652