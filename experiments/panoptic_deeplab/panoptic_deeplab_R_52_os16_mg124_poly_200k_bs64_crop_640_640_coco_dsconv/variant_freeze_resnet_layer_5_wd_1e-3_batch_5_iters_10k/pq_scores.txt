env: DETECTRON2_DATASETS=/content/datasets
Command Line Args: Namespace(config_file='./detectron2/projects/Panoptic-DeepLab/configs/COCO-PanopticSegmentation/panoptic_deeplab_R_52_os16_mg124_poly_200k_bs64_crop_640_640_coco_dsconv.yaml', dist_url='tcp://127.0.0.1:49152', eval_only=False, machine_rank=0, num_gpus=1, num_machines=1, opts=['MODEL.RESNETS.NORM', 'BN', 'MODEL.INS_EMBED_HEAD.NORM', 'BN', 'MODEL.SEM_SEG_HEAD.NORM', 'BN', 'SOLVER.MAX_ITER', '10000', 'SOLVER.IMS_PER_BATCH', '5', 'SOLVER.BASE_LR', '0.0025', 'MODEL.BACKBONE.FREEZE_AT', '5', 'SOLVER.WEIGHT_DECAY', '0.001'], resume=False)
Loading config ./detectron2/projects/Panoptic-DeepLab/configs/COCO-PanopticSegmentation/panoptic_deeplab_R_52_os16_mg124_poly_200k_bs64_crop_640_640_coco_dsconv.yaml with yaml.unsafe_load. Your machine may be at risk if the file contains malicious content.
[12/11 00:38:47 detectron2]: Rank of current process: 0. World size: 1
[12/11 00:38:48 detectron2]: Environment info:
----------------------  ----------------------------------------------------------------
sys.platform            linux
Python                  3.7.12 (default, Jan 15 2022, 18:48:18) [GCC 7.5.0]
numpy                   1.21.5
detectron2              0.6 @/content/detectron2/detectron2
Compiler                GCC 7.5
CUDA compiler           CUDA 11.1
detectron2 arch flags   7.0
DETECTRON2_ENV_MODULE   <not set>
PyTorch                 1.10.0+cu111 @/usr/local/lib/python3.7/dist-packages/torch
PyTorch debug build     False
GPU available           Yes
GPU 0                   Tesla V100-SXM2-16GB (arch=7.0)
Driver version          460.32.03
CUDA_HOME               /usr/local/cuda
Pillow                  7.1.2
torchvision             0.11.1+cu111 @/usr/local/lib/python3.7/dist-packages/torchvision
torchvision arch flags  3.5, 5.0, 6.0, 7.0, 7.5, 8.0, 8.6
fvcore                  0.1.5.post20221122
iopath                  0.1.9
cv2                     4.1.2
----------------------  ----------------------------------------------------------------
PyTorch built with:
  - GCC 7.3
  - C++ Version: 201402
  - Intel(R) Math Kernel Library Version 2020.0.0 Product Build 20191122 for Intel(R) 64 architecture applications
  - Intel(R) MKL-DNN v2.2.3 (Git Hash 7336ca9f055cf1bfa13efb658fe15dc9b41f0740)
  - OpenMP 201511 (a.k.a. OpenMP 4.5)
  - LAPACK is enabled (usually provided by MKL)
  - NNPACK is enabled
  - CPU capability usage: AVX512
  - CUDA Runtime 11.1
  - NVCC architecture flags: -gencode;arch=compute_37,code=sm_37;-gencode;arch=compute_50,code=sm_50;-gencode;arch=compute_60,code=sm_60;-gencode;arch=compute_70,code=sm_70;-gencode;arch=compute_75,code=sm_75;-gencode;arch=compute_80,code=sm_80;-gencode;arch=compute_86,code=sm_86
  - CuDNN 8.0.5
  - Magma 2.5.2
  - Build settings: BLAS_INFO=mkl, BUILD_TYPE=Release, CUDA_VERSION=11.1, CUDNN_VERSION=8.0.5, CXX_COMPILER=/opt/rh/devtoolset-7/root/usr/bin/c++, CXX_FLAGS= -Wno-deprecated -fvisibility-inlines-hidden -DUSE_PTHREADPOOL -fopenmp -DNDEBUG -DUSE_KINETO -DUSE_FBGEMM -DUSE_QNNPACK -DUSE_PYTORCH_QNNPACK -DUSE_XNNPACK -DSYMBOLICATE_MOBILE_DEBUG_HANDLE -DEDGE_PROFILER_USE_KINETO -O2 -fPIC -Wno-narrowing -Wall -Wextra -Werror=return-type -Wno-missing-field-initializers -Wno-type-limits -Wno-array-bounds -Wno-unknown-pragmas -Wno-sign-compare -Wno-unused-parameter -Wno-unused-variable -Wno-unused-function -Wno-unused-result -Wno-unused-local-typedefs -Wno-strict-overflow -Wno-strict-aliasing -Wno-error=deprecated-declarations -Wno-stringop-overflow -Wno-psabi -Wno-error=pedantic -Wno-error=redundant-decls -Wno-error=old-style-cast -fdiagnostics-color=always -faligned-new -Wno-unused-but-set-variable -Wno-maybe-uninitialized -fno-math-errno -fno-trapping-math -Werror=format -Wno-stringop-overflow, LAPACK_INFO=mkl, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, TORCH_VERSION=1.10.0, USE_CUDA=ON, USE_CUDNN=ON, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_MKL=ON, USE_MKLDNN=ON, USE_MPI=OFF, USE_NCCL=ON, USE_NNPACK=ON, USE_OPENMP=ON, 

[12/11 00:38:48 detectron2]: Command line arguments: Namespace(config_file='./detectron2/projects/Panoptic-DeepLab/configs/COCO-PanopticSegmentation/panoptic_deeplab_R_52_os16_mg124_poly_200k_bs64_crop_640_640_coco_dsconv.yaml', dist_url='tcp://127.0.0.1:49152', eval_only=False, machine_rank=0, num_gpus=1, num_machines=1, opts=['MODEL.RESNETS.NORM', 'BN', 'MODEL.INS_EMBED_HEAD.NORM', 'BN', 'MODEL.SEM_SEG_HEAD.NORM', 'BN', 'SOLVER.MAX_ITER', '10000', 'SOLVER.IMS_PER_BATCH', '5', 'SOLVER.BASE_LR', '0.0025', 'MODEL.BACKBONE.FREEZE_AT', '5', 'SOLVER.WEIGHT_DECAY', '0.001'], resume=False)
[12/11 00:38:48 detectron2]: Contents of args.config_file=./detectron2/projects/Panoptic-DeepLab/configs/COCO-PanopticSegmentation/panoptic_deeplab_R_52_os16_mg124_poly_200k_bs64_crop_640_640_coco_dsconv.yaml:
_BASE_: ../Cityscapes-PanopticSegmentation/Base-PanopticDeepLab-OS16.yaml
MODEL:
  WEIGHTS: "detectron2://DeepLab/R-52.pkl"
  PIXEL_MEAN: [123.675, 116.280, 103.530]
  PIXEL_STD: [58.395, 57.120, 57.375]
  BACKBONE:
    NAME: "build_resnet_deeplab_backbone"
  RESNETS:
    DEPTH: 50
    NORM: "SyncBN"
    RES5_MULTI_GRID: [1, 2, 4]
    STEM_TYPE: "deeplab"
    STEM_OUT_CHANNELS: 128
    STRIDE_IN_1X1: False
  SEM_SEG_HEAD:
    NUM_CLASSES: 133
    LOSS_TOP_K: 1.0
    USE_DEPTHWISE_SEPARABLE_CONV: True
  PANOPTIC_DEEPLAB:
    STUFF_AREA: 4096
    NMS_KERNEL: 41
    SIZE_DIVISIBILITY: 640
    USE_DEPTHWISE_SEPARABLE_CONV: True
DATASETS:
  TRAIN: ("coco_2017_train_panoptic",)
  TEST: ("coco_2017_val_panoptic",)
SOLVER:
  BASE_LR: 0.0005
  MAX_ITER: 200000
  IMS_PER_BATCH: 64
INPUT:
  FORMAT: "RGB"
  GAUSSIAN_SIGMA: 8
  MIN_SIZE_TRAIN: !!python/object/apply:eval ["[int(x * 0.1 * 640) for x in range(5, 16)]"]
  MIN_SIZE_TRAIN_SAMPLING: "choice"
  MIN_SIZE_TEST: 640
  MAX_SIZE_TRAIN: 960
  MAX_SIZE_TEST: 640
  CROP:
    ENABLED: True
    TYPE: "absolute"
    SIZE: (640, 640)

[12/11 00:38:48 detectron2]: Running with full config:
CUDNN_BENCHMARK: false
DATALOADER:
  ASPECT_RATIO_GROUPING: true
  FILTER_EMPTY_ANNOTATIONS: true
  NUM_WORKERS: 10
  REPEAT_THRESHOLD: 0.0
  SAMPLER_TRAIN: TrainingSampler
DATASETS:
  PRECOMPUTED_PROPOSAL_TOPK_TEST: 1000
  PRECOMPUTED_PROPOSAL_TOPK_TRAIN: 2000
  PROPOSAL_FILES_TEST: []
  PROPOSAL_FILES_TRAIN: []
  TEST:
  - coco_2017_val_panoptic
  TRAIN:
  - coco_2017_train_panoptic
GLOBAL:
  HACK: 1.0
INPUT:
  CROP:
    ENABLED: true
    SINGLE_CATEGORY_MAX_AREA: 1.0
    SIZE:
    - 640
    - 640
    TYPE: absolute
  FORMAT: RGB
  GAUSSIAN_SIGMA: 8
  IGNORE_CROWD_IN_SEMANTIC: false
  IGNORE_STUFF_IN_OFFSET: true
  MASK_FORMAT: polygon
  MAX_SIZE_TEST: 640
  MAX_SIZE_TRAIN: 960
  MIN_SIZE_TEST: 640
  MIN_SIZE_TRAIN:
  - 320
  - 384
  - 448
  - 512
  - 576
  - 640
  - 704
  - 768
  - 832
  - 896
  - 960
  MIN_SIZE_TRAIN_SAMPLING: choice
  RANDOM_FLIP: horizontal
  SMALL_INSTANCE_AREA: 4096
  SMALL_INSTANCE_WEIGHT: 3
MODEL:
  ANCHOR_GENERATOR:
    ANGLES:
    - - -90
      - 0
      - 90
    ASPECT_RATIOS:
    - - 0.5
      - 1.0
      - 2.0
    NAME: DefaultAnchorGenerator
    OFFSET: 0.0
    SIZES:
    - - 32
      - 64
      - 128
      - 256
      - 512
  BACKBONE:
    FREEZE_AT: 5
    NAME: build_resnet_deeplab_backbone
  DEVICE: cuda
  FPN:
    FUSE_TYPE: sum
    IN_FEATURES: []
    NORM: ''
    OUT_CHANNELS: 256
  INS_EMBED_HEAD:
    ASPP_CHANNELS: 256
    ASPP_DILATIONS:
    - 6
    - 12
    - 18
    ASPP_DROPOUT: 0.1
    CENTER_LOSS_WEIGHT: 200.0
    COMMON_STRIDE: 4
    CONVS_DIM: 128
    HEAD_CHANNELS: 32
    IN_FEATURES:
    - res2
    - res3
    - res5
    NAME: PanopticDeepLabInsEmbedHead
    NORM: BN
    OFFSET_LOSS_WEIGHT: 0.01
    PROJECT_CHANNELS:
    - 32
    - 64
    PROJECT_FEATURES:
    - res2
    - res3
  KEYPOINT_ON: false
  LOAD_PROPOSALS: false
  MASK_ON: false
  META_ARCHITECTURE: PanopticDeepLab
  PANOPTIC_DEEPLAB:
    BENCHMARK_NETWORK_SPEED: false
    CENTER_THRESHOLD: 0.1
    NMS_KERNEL: 41
    PREDICT_INSTANCES: true
    SIZE_DIVISIBILITY: 640
    STUFF_AREA: 4096
    TOP_K_INSTANCE: 200
    USE_DEPTHWISE_SEPARABLE_CONV: true
  PANOPTIC_FPN:
    COMBINE:
      ENABLED: true
      INSTANCES_CONFIDENCE_THRESH: 0.5
      OVERLAP_THRESH: 0.5
      STUFF_AREA_LIMIT: 4096
    INSTANCE_LOSS_WEIGHT: 1.0
  PIXEL_MEAN:
  - 123.675
  - 116.28
  - 103.53
  PIXEL_STD:
  - 58.395
  - 57.12
  - 57.375
  PROPOSAL_GENERATOR:
    MIN_SIZE: 0
    NAME: RPN
  RESNETS:
    DEFORM_MODULATED: false
    DEFORM_NUM_GROUPS: 1
    DEFORM_ON_PER_STAGE:
    - false
    - false
    - false
    - false
    DEPTH: 50
    NORM: BN
    NUM_GROUPS: 1
    OUT_FEATURES:
    - res2
    - res3
    - res5
    RES2_OUT_CHANNELS: 256
    RES4_DILATION: 1
    RES5_DILATION: 2
    RES5_MULTI_GRID:
    - 1
    - 2
    - 4
    STEM_OUT_CHANNELS: 128
    STEM_TYPE: deeplab
    STRIDE_IN_1X1: false
    WIDTH_PER_GROUP: 64
  RETINANET:
    BBOX_REG_LOSS_TYPE: smooth_l1
    BBOX_REG_WEIGHTS: &id001
    - 1.0
    - 1.0
    - 1.0
    - 1.0
    FOCAL_LOSS_ALPHA: 0.25
    FOCAL_LOSS_GAMMA: 2.0
    IN_FEATURES:
    - p3
    - p4
    - p5
    - p6
    - p7
    IOU_LABELS:
    - 0
    - -1
    - 1
    IOU_THRESHOLDS:
    - 0.4
    - 0.5
    NMS_THRESH_TEST: 0.5
    NORM: ''
    NUM_CLASSES: 80
    NUM_CONVS: 4
    PRIOR_PROB: 0.01
    SCORE_THRESH_TEST: 0.05
    SMOOTH_L1_LOSS_BETA: 0.1
    TOPK_CANDIDATES_TEST: 1000
  ROI_BOX_CASCADE_HEAD:
    BBOX_REG_WEIGHTS:
    - - 10.0
      - 10.0
      - 5.0
      - 5.0
    - - 20.0
      - 20.0
      - 10.0
      - 10.0
    - - 30.0
      - 30.0
      - 15.0
      - 15.0
    IOUS:
    - 0.5
    - 0.6
    - 0.7
  ROI_BOX_HEAD:
    BBOX_REG_LOSS_TYPE: smooth_l1
    BBOX_REG_LOSS_WEIGHT: 1.0
    BBOX_REG_WEIGHTS:
    - 10.0
    - 10.0
    - 5.0
    - 5.0
    CLS_AGNOSTIC_BBOX_REG: false
    CONV_DIM: 256
    FC_DIM: 1024
    FED_LOSS_FREQ_WEIGHT_POWER: 0.5
    FED_LOSS_NUM_CLASSES: 50
    NAME: ''
    NORM: ''
    NUM_CONV: 0
    NUM_FC: 0
    POOLER_RESOLUTION: 14
    POOLER_SAMPLING_RATIO: 0
    POOLER_TYPE: ROIAlignV2
    SMOOTH_L1_BETA: 0.0
    TRAIN_ON_PRED_BOXES: false
    USE_FED_LOSS: false
    USE_SIGMOID_CE: false
  ROI_HEADS:
    BATCH_SIZE_PER_IMAGE: 512
    IN_FEATURES:
    - res4
    IOU_LABELS:
    - 0
    - 1
    IOU_THRESHOLDS:
    - 0.5
    NAME: Res5ROIHeads
    NMS_THRESH_TEST: 0.5
    NUM_CLASSES: 80
    POSITIVE_FRACTION: 0.25
    PROPOSAL_APPEND_GT: true
    SCORE_THRESH_TEST: 0.05
  ROI_KEYPOINT_HEAD:
    CONV_DIMS:
    - 512
    - 512
    - 512
    - 512
    - 512
    - 512
    - 512
    - 512
    LOSS_WEIGHT: 1.0
    MIN_KEYPOINTS_PER_IMAGE: 1
    NAME: KRCNNConvDeconvUpsampleHead
    NORMALIZE_LOSS_BY_VISIBLE_KEYPOINTS: true
    NUM_KEYPOINTS: 17
    POOLER_RESOLUTION: 14
    POOLER_SAMPLING_RATIO: 0
    POOLER_TYPE: ROIAlignV2
  ROI_MASK_HEAD:
    CLS_AGNOSTIC_MASK: false
    CONV_DIM: 256
    NAME: MaskRCNNConvUpsampleHead
    NORM: ''
    NUM_CONV: 0
    POOLER_RESOLUTION: 14
    POOLER_SAMPLING_RATIO: 0
    POOLER_TYPE: ROIAlignV2
  RPN:
    BATCH_SIZE_PER_IMAGE: 256
    BBOX_REG_LOSS_TYPE: smooth_l1
    BBOX_REG_LOSS_WEIGHT: 1.0
    BBOX_REG_WEIGHTS: *id001
    BOUNDARY_THRESH: -1
    CONV_DIMS:
    - -1
    HEAD_NAME: StandardRPNHead
    IN_FEATURES:
    - res4
    IOU_LABELS:
    - 0
    - -1
    - 1
    IOU_THRESHOLDS:
    - 0.3
    - 0.7
    LOSS_WEIGHT: 1.0
    NMS_THRESH: 0.7
    POSITIVE_FRACTION: 0.5
    POST_NMS_TOPK_TEST: 1000
    POST_NMS_TOPK_TRAIN: 2000
    PRE_NMS_TOPK_TEST: 6000
    PRE_NMS_TOPK_TRAIN: 12000
    SMOOTH_L1_BETA: 0.0
  SEM_SEG_HEAD:
    ASPP_CHANNELS: 256
    ASPP_DILATIONS:
    - 6
    - 12
    - 18
    ASPP_DROPOUT: 0.1
    COMMON_STRIDE: 4
    CONVS_DIM: 256
    HEAD_CHANNELS: 256
    IGNORE_VALUE: 255
    IN_FEATURES:
    - res2
    - res3
    - res5
    LOSS_TOP_K: 1.0
    LOSS_TYPE: hard_pixel_mining
    LOSS_WEIGHT: 1.0
    NAME: PanopticDeepLabSemSegHead
    NORM: BN
    NUM_CLASSES: 133
    PROJECT_CHANNELS:
    - 32
    - 64
    PROJECT_FEATURES:
    - res2
    - res3
    USE_DEPTHWISE_SEPARABLE_CONV: true
  WEIGHTS: detectron2://DeepLab/R-52.pkl
OUTPUT_DIR: ./output
SEED: -1
SOLVER:
  AMP:
    ENABLED: false
  BASE_LR: 0.0025
  BASE_LR_END: 0.0
  BIAS_LR_FACTOR: 1.0
  CHECKPOINT_PERIOD: 5000
  CLIP_GRADIENTS:
    CLIP_TYPE: value
    CLIP_VALUE: 1.0
    ENABLED: false
    NORM_TYPE: 2.0
  GAMMA: 0.1
  IMS_PER_BATCH: 5
  LR_SCHEDULER_NAME: WarmupPolyLR
  MAX_ITER: 10000
  MOMENTUM: 0.9
  NESTEROV: false
  NUM_DECAYS: 3
  OPTIMIZER: ADAM
  POLY_LR_CONSTANT_ENDING: 0.0
  POLY_LR_POWER: 0.9
  REFERENCE_WORLD_SIZE: 0
  RESCALE_INTERVAL: false
  STEPS:
  - 30000
  WARMUP_FACTOR: 0.001
  WARMUP_ITERS: 1000
  WARMUP_METHOD: linear
  WEIGHT_DECAY: 0.001
  WEIGHT_DECAY_BIAS: 0.0
  WEIGHT_DECAY_NORM: 0.0
TEST:
  AUG:
    ENABLED: false
    FLIP: true
    MAX_SIZE: 4000
    MIN_SIZES:
    - 400
    - 500
    - 600
    - 700
    - 800
    - 900
    - 1000
    - 1100
    - 1200
  DETECTIONS_PER_IMAGE: 100
  EVAL_PERIOD: 0
  EXPECTED_RESULTS: []
  KEYPOINT_OKS_SIGMAS: []
  PRECISE_BN:
    ENABLED: false
    NUM_ITER: 200
VERSION: 2
VIS_PERIOD: 0

[12/11 00:38:48 detectron2]: Full config saved to ./output/config.yaml
[12/11 00:38:48 d2.utils.env]: Using a generated random seed 48954416
[12/11 00:38:53 d2.engine.defaults]: Model:
PanopticDeepLab(
  (backbone): ResNet(
    (stem): DeepLabStem(
      (conv1): Conv2d(
        3, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False
        (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
      )
      (conv2): Conv2d(
        64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
        (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
      )
      (conv3): Conv2d(
        64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
        (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
      )
    )
    (res2): Sequential(
      (0): BottleneckBlock(
        (shortcut): Conv2d(
          128, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv1): Conv2d(
          128, 64, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
        )
        (conv2): Conv2d(
          64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
        )
        (conv3): Conv2d(
          64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
      )
      (1): BottleneckBlock(
        (conv1): Conv2d(
          256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
        )
        (conv2): Conv2d(
          64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
        )
        (conv3): Conv2d(
          64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
      )
      (2): BottleneckBlock(
        (conv1): Conv2d(
          256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
        )
        (conv2): Conv2d(
          64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
        )
        (conv3): Conv2d(
          64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
      )
    )
    (res3): Sequential(
      (0): BottleneckBlock(
        (shortcut): Conv2d(
          256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False
          (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
        )
        (conv1): Conv2d(
          256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
        )
        (conv2): Conv2d(
          128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
        )
        (conv3): Conv2d(
          128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
        )
      )
      (1): BottleneckBlock(
        (conv1): Conv2d(
          512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
        )
        (conv2): Conv2d(
          128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
        )
        (conv3): Conv2d(
          128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
        )
      )
      (2): BottleneckBlock(
        (conv1): Conv2d(
          512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
        )
        (conv2): Conv2d(
          128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
        )
        (conv3): Conv2d(
          128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
        )
      )
      (3): BottleneckBlock(
        (conv1): Conv2d(
          512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
        )
        (conv2): Conv2d(
          128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
        )
        (conv3): Conv2d(
          128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
        )
      )
    )
    (res4): Sequential(
      (0): BottleneckBlock(
        (shortcut): Conv2d(
          512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False
          (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
        )
        (conv1): Conv2d(
          512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv2): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv3): Conv2d(
          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
        )
      )
      (1): BottleneckBlock(
        (conv1): Conv2d(
          1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv2): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv3): Conv2d(
          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
        )
      )
      (2): BottleneckBlock(
        (conv1): Conv2d(
          1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv2): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv3): Conv2d(
          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
        )
      )
      (3): BottleneckBlock(
        (conv1): Conv2d(
          1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv2): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv3): Conv2d(
          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
        )
      )
      (4): BottleneckBlock(
        (conv1): Conv2d(
          1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv2): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv3): Conv2d(
          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
        )
      )
      (5): BottleneckBlock(
        (conv1): Conv2d(
          1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv2): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv3): Conv2d(
          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
        )
      )
    )
    (res5): Sequential(
      (0): BottleneckBlock(
        (shortcut): Conv2d(
          1024, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)
        )
        (conv1): Conv2d(
          1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
        )
        (conv2): Conv2d(
          512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2), dilation=(2, 2), bias=False
          (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
        )
        (conv3): Conv2d(
          512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)
        )
      )
      (1): BottleneckBlock(
        (conv1): Conv2d(
          2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
        )
        (conv2): Conv2d(
          512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(4, 4), dilation=(4, 4), bias=False
          (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
        )
        (conv3): Conv2d(
          512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)
        )
      )
      (2): BottleneckBlock(
        (conv1): Conv2d(
          2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
        )
        (conv2): Conv2d(
          512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(8, 8), dilation=(8, 8), bias=False
          (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
        )
        (conv3): Conv2d(
          512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)
        )
      )
    )
  )
  (sem_seg_head): PanopticDeepLabSemSegHead(
    (decoder): ModuleDict(
      (res2): ModuleDict(
        (project_conv): Conv2d(
          256, 32, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (fuse_conv): DepthwiseSeparableConv2d(
          (depthwise): Conv2d(
            288, 288, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=288, bias=False
            (norm): BatchNorm2d(288, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          )
          (pointwise): Conv2d(
            288, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
      )
      (res3): ModuleDict(
        (project_conv): Conv2d(
          512, 64, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (fuse_conv): DepthwiseSeparableConv2d(
          (depthwise): Conv2d(
            320, 320, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=320, bias=False
            (norm): BatchNorm2d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          )
          (pointwise): Conv2d(
            320, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
      )
      (res5): ModuleDict(
        (project_conv): ASPP(
          (convs): ModuleList(
            (0): Conv2d(
              2048, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
              (norm): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            )
            (1): DepthwiseSeparableConv2d(
              (depthwise): Conv2d(
                2048, 2048, kernel_size=(3, 3), stride=(1, 1), padding=(6, 6), dilation=(6, 6), groups=2048, bias=False
                (norm): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
              (pointwise): Conv2d(
                2048, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
            )
            (2): DepthwiseSeparableConv2d(
              (depthwise): Conv2d(
                2048, 2048, kernel_size=(3, 3), stride=(1, 1), padding=(12, 12), dilation=(12, 12), groups=2048, bias=False
                (norm): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
              (pointwise): Conv2d(
                2048, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
            )
            (3): DepthwiseSeparableConv2d(
              (depthwise): Conv2d(
                2048, 2048, kernel_size=(3, 3), stride=(1, 1), padding=(18, 18), dilation=(18, 18), groups=2048, bias=False
                (norm): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
              (pointwise): Conv2d(
                2048, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
            )
            (4): Sequential(
              (0): AvgPool2d(kernel_size=(40, 40), stride=1, padding=0)
              (1): Conv2d(2048, 256, kernel_size=(1, 1), stride=(1, 1))
            )
          )
          (project): Conv2d(
            1280, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (fuse_conv): None
      )
    )
    (head): DepthwiseSeparableConv2d(
      (depthwise): Conv2d(
        256, 256, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=256, bias=False
        (norm): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (pointwise): Conv2d(
        256, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
        (norm): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (predictor): Conv2d(256, 133, kernel_size=(1, 1), stride=(1, 1))
    (loss): DeepLabCE(
      (criterion): CrossEntropyLoss()
    )
  )
  (ins_embed_head): PanopticDeepLabInsEmbedHead(
    (decoder): ModuleDict(
      (res2): ModuleDict(
        (project_conv): Conv2d(
          256, 32, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (fuse_conv): DepthwiseSeparableConv2d(
          (depthwise): Conv2d(
            160, 160, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=160, bias=False
            (norm): BatchNorm2d(160, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          )
          (pointwise): Conv2d(
            160, 128, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
      )
      (res3): ModuleDict(
        (project_conv): Conv2d(
          512, 64, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (fuse_conv): DepthwiseSeparableConv2d(
          (depthwise): Conv2d(
            320, 320, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=320, bias=False
            (norm): BatchNorm2d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          )
          (pointwise): Conv2d(
            320, 128, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
      )
      (res5): ModuleDict(
        (project_conv): ASPP(
          (convs): ModuleList(
            (0): Conv2d(
              2048, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
              (norm): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            )
            (1): DepthwiseSeparableConv2d(
              (depthwise): Conv2d(
                2048, 2048, kernel_size=(3, 3), stride=(1, 1), padding=(6, 6), dilation=(6, 6), groups=2048, bias=False
                (norm): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
              (pointwise): Conv2d(
                2048, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
            )
            (2): DepthwiseSeparableConv2d(
              (depthwise): Conv2d(
                2048, 2048, kernel_size=(3, 3), stride=(1, 1), padding=(12, 12), dilation=(12, 12), groups=2048, bias=False
                (norm): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
              (pointwise): Conv2d(
                2048, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
            )
            (3): DepthwiseSeparableConv2d(
              (depthwise): Conv2d(
                2048, 2048, kernel_size=(3, 3), stride=(1, 1), padding=(18, 18), dilation=(18, 18), groups=2048, bias=False
                (norm): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
              (pointwise): Conv2d(
                2048, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
            )
            (4): Sequential(
              (0): AvgPool2d(kernel_size=(40, 40), stride=1, padding=0)
              (1): Conv2d(2048, 256, kernel_size=(1, 1), stride=(1, 1))
            )
          )
          (project): Conv2d(
            1280, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (fuse_conv): None
      )
    )
    (center_head): Sequential(
      (0): Conv2d(
        128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
        (norm): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (1): Conv2d(
        128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
        (norm): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (center_predictor): Conv2d(32, 1, kernel_size=(1, 1), stride=(1, 1))
    (offset_head): DepthwiseSeparableConv2d(
      (depthwise): Conv2d(
        128, 128, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=128, bias=False
        (norm): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (pointwise): Conv2d(
        128, 32, kernel_size=(1, 1), stride=(1, 1), bias=False
        (norm): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (offset_predictor): Conv2d(32, 2, kernel_size=(1, 1), stride=(1, 1))
    (center_loss): MSELoss()
    (offset_loss): L1Loss()
  )
)
[12/11 00:38:53 d2.projects.panoptic_deeplab.dataset_mapper]: Augmentations used in training: [ResizeShortestEdge(short_edge_length=(320, 384, 448, 512, 576, 640, 704, 768, 832, 896, 960), max_size=960, sample_style='choice'), RandomCrop(crop_type='absolute', crop_size=[640, 640]), RandomFlip()]
[12/11 00:39:01 d2.data.build]: Using training sampler TrainingSampler
[12/11 00:39:01 d2.data.common]: Serializing the dataset using: <class 'detectron2.data.common.NumpySerializedList'>
[12/11 00:39:01 d2.data.common]: Serializing 118287 elements to byte tensors and concatenating them all ...
[12/11 00:39:02 d2.data.common]: Serialized dataset takes 80.32 MiB
/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:481: UserWarning: This DataLoader will create 10 worker processes in total. Our suggested max number of worker in current system is 8, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.
  cpuset_checked))
[12/11 00:39:05 fvcore.common.checkpoint]: [Checkpointer] Loading from detectron2://DeepLab/R-52.pkl ...
[12/11 00:39:05 fvcore.common.checkpoint]: Reading a file from 'torchvision'
[12/11 00:39:05 d2.checkpoint.c2_model_loading]: Following weights matched with submodule backbone:
| Names in Model    | Names in Checkpoint                                                               | Shapes                                          |
|:------------------|:----------------------------------------------------------------------------------|:------------------------------------------------|
| res2.0.conv1.*    | res2.0.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (64,) (64,) (64,) (64,) (64,128,1,1)            |
| res2.0.conv2.*    | res2.0.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (64,) (64,) (64,) (64,) (64,64,3,3)             |
| res2.0.conv3.*    | res2.0.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) (256,) (256,) (256,) (256,64,1,1)        |
| res2.0.shortcut.* | res2.0.shortcut.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight} | (256,) (256,) (256,) (256,) (256,128,1,1)       |
| res2.1.conv1.*    | res2.1.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (64,) (64,) (64,) (64,) (64,256,1,1)            |
| res2.1.conv2.*    | res2.1.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (64,) (64,) (64,) (64,) (64,64,3,3)             |
| res2.1.conv3.*    | res2.1.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) (256,) (256,) (256,) (256,64,1,1)        |
| res2.2.conv1.*    | res2.2.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (64,) (64,) (64,) (64,) (64,256,1,1)            |
| res2.2.conv2.*    | res2.2.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (64,) (64,) (64,) (64,) (64,64,3,3)             |
| res2.2.conv3.*    | res2.2.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) (256,) (256,) (256,) (256,64,1,1)        |
| res3.0.conv1.*    | res3.0.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (128,) (128,) (128,) (128,) (128,256,1,1)       |
| res3.0.conv2.*    | res3.0.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (128,) (128,) (128,) (128,) (128,128,3,3)       |
| res3.0.conv3.*    | res3.0.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (512,) (512,) (512,) (512,) (512,128,1,1)       |
| res3.0.shortcut.* | res3.0.shortcut.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight} | (512,) (512,) (512,) (512,) (512,256,1,1)       |
| res3.1.conv1.*    | res3.1.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (128,) (128,) (128,) (128,) (128,512,1,1)       |
| res3.1.conv2.*    | res3.1.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (128,) (128,) (128,) (128,) (128,128,3,3)       |
| res3.1.conv3.*    | res3.1.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (512,) (512,) (512,) (512,) (512,128,1,1)       |
| res3.2.conv1.*    | res3.2.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (128,) (128,) (128,) (128,) (128,512,1,1)       |
| res3.2.conv2.*    | res3.2.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (128,) (128,) (128,) (128,) (128,128,3,3)       |
| res3.2.conv3.*    | res3.2.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (512,) (512,) (512,) (512,) (512,128,1,1)       |
| res3.3.conv1.*    | res3.3.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (128,) (128,) (128,) (128,) (128,512,1,1)       |
| res3.3.conv2.*    | res3.3.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (128,) (128,) (128,) (128,) (128,128,3,3)       |
| res3.3.conv3.*    | res3.3.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (512,) (512,) (512,) (512,) (512,128,1,1)       |
| res4.0.conv1.*    | res4.0.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) (256,) (256,) (256,) (256,512,1,1)       |
| res4.0.conv2.*    | res4.0.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) (256,) (256,) (256,) (256,256,3,3)       |
| res4.0.conv3.*    | res4.0.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (1024,) (1024,) (1024,) (1024,) (1024,256,1,1)  |
| res4.0.shortcut.* | res4.0.shortcut.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight} | (1024,) (1024,) (1024,) (1024,) (1024,512,1,1)  |
| res4.1.conv1.*    | res4.1.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) (256,) (256,) (256,) (256,1024,1,1)      |
| res4.1.conv2.*    | res4.1.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) (256,) (256,) (256,) (256,256,3,3)       |
| res4.1.conv3.*    | res4.1.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (1024,) (1024,) (1024,) (1024,) (1024,256,1,1)  |
| res4.2.conv1.*    | res4.2.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) (256,) (256,) (256,) (256,1024,1,1)      |
| res4.2.conv2.*    | res4.2.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) (256,) (256,) (256,) (256,256,3,3)       |
| res4.2.conv3.*    | res4.2.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (1024,) (1024,) (1024,) (1024,) (1024,256,1,1)  |
| res4.3.conv1.*    | res4.3.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) (256,) (256,) (256,) (256,1024,1,1)      |
| res4.3.conv2.*    | res4.3.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) (256,) (256,) (256,) (256,256,3,3)       |
| res4.3.conv3.*    | res4.3.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (1024,) (1024,) (1024,) (1024,) (1024,256,1,1)  |
| res4.4.conv1.*    | res4.4.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) (256,) (256,) (256,) (256,1024,1,1)      |
| res4.4.conv2.*    | res4.4.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) (256,) (256,) (256,) (256,256,3,3)       |
| res4.4.conv3.*    | res4.4.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (1024,) (1024,) (1024,) (1024,) (1024,256,1,1)  |
| res4.5.conv1.*    | res4.5.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) (256,) (256,) (256,) (256,1024,1,1)      |
| res4.5.conv2.*    | res4.5.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) (256,) (256,) (256,) (256,256,3,3)       |
| res4.5.conv3.*    | res4.5.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (1024,) (1024,) (1024,) (1024,) (1024,256,1,1)  |
| res5.0.conv1.*    | res5.0.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (512,) (512,) (512,) (512,) (512,1024,1,1)      |
| res5.0.conv2.*    | res5.0.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (512,) (512,) (512,) (512,) (512,512,3,3)       |
| res5.0.conv3.*    | res5.0.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (2048,) (2048,) (2048,) (2048,) (2048,512,1,1)  |
| res5.0.shortcut.* | res5.0.shortcut.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight} | (2048,) (2048,) (2048,) (2048,) (2048,1024,1,1) |
| res5.1.conv1.*    | res5.1.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (512,) (512,) (512,) (512,) (512,2048,1,1)      |
| res5.1.conv2.*    | res5.1.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (512,) (512,) (512,) (512,) (512,512,3,3)       |
| res5.1.conv3.*    | res5.1.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (2048,) (2048,) (2048,) (2048,) (2048,512,1,1)  |
| res5.2.conv1.*    | res5.2.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (512,) (512,) (512,) (512,) (512,2048,1,1)      |
| res5.2.conv2.*    | res5.2.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (512,) (512,) (512,) (512,) (512,512,3,3)       |
| res5.2.conv3.*    | res5.2.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (2048,) (2048,) (2048,) (2048,) (2048,512,1,1)  |
| stem.conv1.*      | stem.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}      | (64,) (64,) (64,) (64,) (64,3,3,3)              |
| stem.conv2.*      | stem.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}      | (64,) (64,) (64,) (64,) (64,64,3,3)             |
| stem.conv3.*      | stem.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}      | (128,) (128,) (128,) (128,) (128,64,3,3)        |
WARNING [12/11 00:39:06 fvcore.common.checkpoint]: Some model parameters or buffers are not found in the checkpoint:
ins_embed_head.center_head.0.norm.{bias, running_mean, running_var, weight}
ins_embed_head.center_head.0.weight
ins_embed_head.center_head.1.norm.{bias, running_mean, running_var, weight}
ins_embed_head.center_head.1.weight
ins_embed_head.center_predictor.{bias, weight}
ins_embed_head.decoder.res2.fuse_conv.depthwise.norm.{bias, running_mean, running_var, weight}
ins_embed_head.decoder.res2.fuse_conv.depthwise.weight
ins_embed_head.decoder.res2.fuse_conv.pointwise.norm.{bias, running_mean, running_var, weight}
ins_embed_head.decoder.res2.fuse_conv.pointwise.weight
ins_embed_head.decoder.res2.project_conv.norm.{bias, running_mean, running_var, weight}
ins_embed_head.decoder.res2.project_conv.weight
ins_embed_head.decoder.res3.fuse_conv.depthwise.norm.{bias, running_mean, running_var, weight}
ins_embed_head.decoder.res3.fuse_conv.depthwise.weight
ins_embed_head.decoder.res3.fuse_conv.pointwise.norm.{bias, running_mean, running_var, weight}
ins_embed_head.decoder.res3.fuse_conv.pointwise.weight
ins_embed_head.decoder.res3.project_conv.norm.{bias, running_mean, running_var, weight}
ins_embed_head.decoder.res3.project_conv.weight
ins_embed_head.decoder.res5.project_conv.convs.0.norm.{bias, running_mean, running_var, weight}
ins_embed_head.decoder.res5.project_conv.convs.0.weight
ins_embed_head.decoder.res5.project_conv.convs.1.depthwise.norm.{bias, running_mean, running_var, weight}
ins_embed_head.decoder.res5.project_conv.convs.1.depthwise.weight
ins_embed_head.decoder.res5.project_conv.convs.1.pointwise.norm.{bias, running_mean, running_var, weight}
ins_embed_head.decoder.res5.project_conv.convs.1.pointwise.weight
ins_embed_head.decoder.res5.project_conv.convs.2.depthwise.norm.{bias, running_mean, running_var, weight}
ins_embed_head.decoder.res5.project_conv.convs.2.depthwise.weight
ins_embed_head.decoder.res5.project_conv.convs.2.pointwise.norm.{bias, running_mean, running_var, weight}
ins_embed_head.decoder.res5.project_conv.convs.2.pointwise.weight
ins_embed_head.decoder.res5.project_conv.convs.3.depthwise.norm.{bias, running_mean, running_var, weight}
ins_embed_head.decoder.res5.project_conv.convs.3.depthwise.weight
ins_embed_head.decoder.res5.project_conv.convs.3.pointwise.norm.{bias, running_mean, running_var, weight}
ins_embed_head.decoder.res5.project_conv.convs.3.pointwise.weight
ins_embed_head.decoder.res5.project_conv.convs.4.1.{bias, weight}
ins_embed_head.decoder.res5.project_conv.project.norm.{bias, running_mean, running_var, weight}
ins_embed_head.decoder.res5.project_conv.project.weight
ins_embed_head.offset_head.depthwise.norm.{bias, running_mean, running_var, weight}
ins_embed_head.offset_head.depthwise.weight
ins_embed_head.offset_head.pointwise.norm.{bias, running_mean, running_var, weight}
ins_embed_head.offset_head.pointwise.weight
ins_embed_head.offset_predictor.{bias, weight}
sem_seg_head.decoder.res2.fuse_conv.depthwise.norm.{bias, running_mean, running_var, weight}
sem_seg_head.decoder.res2.fuse_conv.depthwise.weight
sem_seg_head.decoder.res2.fuse_conv.pointwise.norm.{bias, running_mean, running_var, weight}
sem_seg_head.decoder.res2.fuse_conv.pointwise.weight
sem_seg_head.decoder.res2.project_conv.norm.{bias, running_mean, running_var, weight}
sem_seg_head.decoder.res2.project_conv.weight
sem_seg_head.decoder.res3.fuse_conv.depthwise.norm.{bias, running_mean, running_var, weight}
sem_seg_head.decoder.res3.fuse_conv.depthwise.weight
sem_seg_head.decoder.res3.fuse_conv.pointwise.norm.{bias, running_mean, running_var, weight}
sem_seg_head.decoder.res3.fuse_conv.pointwise.weight
sem_seg_head.decoder.res3.project_conv.norm.{bias, running_mean, running_var, weight}
sem_seg_head.decoder.res3.project_conv.weight
sem_seg_head.decoder.res5.project_conv.convs.0.norm.{bias, running_mean, running_var, weight}
sem_seg_head.decoder.res5.project_conv.convs.0.weight
sem_seg_head.decoder.res5.project_conv.convs.1.depthwise.norm.{bias, running_mean, running_var, weight}
sem_seg_head.decoder.res5.project_conv.convs.1.depthwise.weight
sem_seg_head.decoder.res5.project_conv.convs.1.pointwise.norm.{bias, running_mean, running_var, weight}
sem_seg_head.decoder.res5.project_conv.convs.1.pointwise.weight
sem_seg_head.decoder.res5.project_conv.convs.2.depthwise.norm.{bias, running_mean, running_var, weight}
sem_seg_head.decoder.res5.project_conv.convs.2.depthwise.weight
sem_seg_head.decoder.res5.project_conv.convs.2.pointwise.norm.{bias, running_mean, running_var, weight}
sem_seg_head.decoder.res5.project_conv.convs.2.pointwise.weight
sem_seg_head.decoder.res5.project_conv.convs.3.depthwise.norm.{bias, running_mean, running_var, weight}
sem_seg_head.decoder.res5.project_conv.convs.3.depthwise.weight
sem_seg_head.decoder.res5.project_conv.convs.3.pointwise.norm.{bias, running_mean, running_var, weight}
sem_seg_head.decoder.res5.project_conv.convs.3.pointwise.weight
sem_seg_head.decoder.res5.project_conv.convs.4.1.{bias, weight}
sem_seg_head.decoder.res5.project_conv.project.norm.{bias, running_mean, running_var, weight}
sem_seg_head.decoder.res5.project_conv.project.weight
sem_seg_head.head.depthwise.norm.{bias, running_mean, running_var, weight}
sem_seg_head.head.depthwise.weight
sem_seg_head.head.pointwise.norm.{bias, running_mean, running_var, weight}
sem_seg_head.head.pointwise.weight
sem_seg_head.predictor.{bias, weight}
WARNING [12/11 00:39:06 fvcore.common.checkpoint]: The checkpoint state_dict contains keys that are not used by the model:
  res2.0.conv1.norm.num_batches_tracked
  res2.0.conv2.norm.num_batches_tracked
  res2.0.conv3.norm.num_batches_tracked
  res2.0.shortcut.norm.num_batches_tracked
  res2.1.conv1.norm.num_batches_tracked
  res2.1.conv2.norm.num_batches_tracked
  res2.1.conv3.norm.num_batches_tracked
  res2.2.conv1.norm.num_batches_tracked
  res2.2.conv2.norm.num_batches_tracked
  res2.2.conv3.norm.num_batches_tracked
  res3.0.conv1.norm.num_batches_tracked
  res3.0.conv2.norm.num_batches_tracked
  res3.0.conv3.norm.num_batches_tracked
  res3.0.shortcut.norm.num_batches_tracked
  res3.1.conv1.norm.num_batches_tracked
  res3.1.conv2.norm.num_batches_tracked
  res3.1.conv3.norm.num_batches_tracked
  res3.2.conv1.norm.num_batches_tracked
  res3.2.conv2.norm.num_batches_tracked
  res3.2.conv3.norm.num_batches_tracked
  res3.3.conv1.norm.num_batches_tracked
  res3.3.conv2.norm.num_batches_tracked
  res3.3.conv3.norm.num_batches_tracked
  res4.0.conv1.norm.num_batches_tracked
  res4.0.conv2.norm.num_batches_tracked
  res4.0.conv3.norm.num_batches_tracked
  res4.0.shortcut.norm.num_batches_tracked
  res4.1.conv1.norm.num_batches_tracked
  res4.1.conv2.norm.num_batches_tracked
  res4.1.conv3.norm.num_batches_tracked
  res4.2.conv1.norm.num_batches_tracked
  res4.2.conv2.norm.num_batches_tracked
  res4.2.conv3.norm.num_batches_tracked
  res4.3.conv1.norm.num_batches_tracked
  res4.3.conv2.norm.num_batches_tracked
  res4.3.conv3.norm.num_batches_tracked
  res4.4.conv1.norm.num_batches_tracked
  res4.4.conv2.norm.num_batches_tracked
  res4.4.conv3.norm.num_batches_tracked
  res4.5.conv1.norm.num_batches_tracked
  res4.5.conv2.norm.num_batches_tracked
  res4.5.conv3.norm.num_batches_tracked
  res5.0.conv1.norm.num_batches_tracked
  res5.0.conv2.norm.num_batches_tracked
  res5.0.conv3.norm.num_batches_tracked
  res5.0.shortcut.norm.num_batches_tracked
  res5.1.conv1.norm.num_batches_tracked
  res5.1.conv2.norm.num_batches_tracked
  res5.1.conv3.norm.num_batches_tracked
  res5.2.conv1.norm.num_batches_tracked
  res5.2.conv2.norm.num_batches_tracked
  res5.2.conv3.norm.num_batches_tracked
  stem.conv1.norm.num_batches_tracked
  stem.conv2.norm.num_batches_tracked
  stem.conv3.norm.num_batches_tracked
  stem.fc.{bias, weight}
[12/11 00:39:06 d2.engine.train_loop]: Starting training from iteration 0
/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:481: UserWarning: This DataLoader will create 10 worker processes in total. Our suggested max number of worker in current system is 8, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.
  cpuset_checked))
[12/11 00:39:12 d2.utils.events]:  eta: 0:45:06  iter: 19  total_loss: 6.222  loss_sem_seg: 3.763  loss_center: 0.6976  loss_offset: 1.578  time: 0.2686  data_time: 0.0761  lr: 4.9867e-05  max_mem: 6513M
[12/11 00:39:18 d2.utils.events]:  eta: 0:45:01  iter: 39  total_loss: 6.175  loss_sem_seg: 3.788  loss_center: 0.9774  loss_offset: 1.532  time: 0.2707  data_time: 0.0286  lr: 9.9552e-05  max_mem: 6513M
[12/11 00:39:23 d2.utils.events]:  eta: 0:44:46  iter: 59  total_loss: 5.641  loss_sem_seg: 3.29  loss_center: 0.7204  loss_offset: 1.502  time: 0.2701  data_time: 0.0253  lr: 0.00014906  max_mem: 6513M
[12/11 00:39:29 d2.utils.events]:  eta: 0:44:41  iter: 79  total_loss: 5.836  loss_sem_seg: 3.499  loss_center: 0.6491  loss_offset: 1.572  time: 0.2708  data_time: 0.0279  lr: 0.00019838  max_mem: 6513M
[12/11 00:39:34 d2.utils.events]:  eta: 0:44:38  iter: 99  total_loss: 5.827  loss_sem_seg: 3.518  loss_center: 0.7083  loss_offset: 1.638  time: 0.2712  data_time: 0.0272  lr: 0.00024753  max_mem: 6513M
[12/11 00:39:40 d2.utils.events]:  eta: 0:44:43  iter: 119  total_loss: 5.703  loss_sem_seg: 3.18  loss_center: 0.7197  loss_offset: 1.517  time: 0.2720  data_time: 0.0263  lr: 0.00029649  max_mem: 6513M
[12/11 00:39:45 d2.utils.events]:  eta: 0:44:38  iter: 139  total_loss: 5.041  loss_sem_seg: 2.695  loss_center: 0.5583  loss_offset: 1.709  time: 0.2718  data_time: 0.0266  lr: 0.00034528  max_mem: 6513M
[12/11 00:39:50 d2.utils.events]:  eta: 0:44:32  iter: 159  total_loss: 5.091  loss_sem_seg: 2.841  loss_center: 0.6958  loss_offset: 1.525  time: 0.2715  data_time: 0.0258  lr: 0.00039388  max_mem: 6513M
[12/11 00:39:56 d2.utils.events]:  eta: 0:44:24  iter: 179  total_loss: 5.259  loss_sem_seg: 2.681  loss_center: 0.681  loss_offset: 1.753  time: 0.2714  data_time: 0.0270  lr: 0.0004423  max_mem: 6513M
[12/11 00:40:01 d2.utils.events]:  eta: 0:44:14  iter: 199  total_loss: 4.79  loss_sem_seg: 2.595  loss_center: 0.7308  loss_offset: 1.386  time: 0.2712  data_time: 0.0245  lr: 0.00049055  max_mem: 6513M
[12/11 00:40:07 d2.utils.events]:  eta: 0:44:07  iter: 219  total_loss: 4.793  loss_sem_seg: 2.512  loss_center: 0.6477  loss_offset: 1.619  time: 0.2714  data_time: 0.0259  lr: 0.00053861  max_mem: 6513M
[12/11 00:40:12 d2.utils.events]:  eta: 0:44:03  iter: 239  total_loss: 4.681  loss_sem_seg: 2.389  loss_center: 0.7552  loss_offset: 1.416  time: 0.2715  data_time: 0.0288  lr: 0.00058649  max_mem: 6513M
[12/11 00:40:18 d2.utils.events]:  eta: 0:43:58  iter: 259  total_loss: 4.582  loss_sem_seg: 2.266  loss_center: 0.7819  loss_offset: 1.441  time: 0.2716  data_time: 0.0265  lr: 0.0006342  max_mem: 6513M
[12/11 00:40:23 d2.utils.events]:  eta: 0:43:54  iter: 279  total_loss: 4.435  loss_sem_seg: 2.416  loss_center: 0.6078  loss_offset: 1.402  time: 0.2716  data_time: 0.0260  lr: 0.00068172  max_mem: 6513M
[12/11 00:40:29 d2.utils.events]:  eta: 0:43:48  iter: 299  total_loss: 4.261  loss_sem_seg: 2.215  loss_center: 0.6338  loss_offset: 1.512  time: 0.2715  data_time: 0.0262  lr: 0.00072906  max_mem: 6513M
[12/11 00:40:34 d2.utils.events]:  eta: 0:43:48  iter: 319  total_loss: 4.694  loss_sem_seg: 2.367  loss_center: 0.6684  loss_offset: 1.451  time: 0.2717  data_time: 0.0283  lr: 0.00077622  max_mem: 6513M
[12/11 00:40:39 d2.utils.events]:  eta: 0:43:42  iter: 339  total_loss: 4.446  loss_sem_seg: 2.255  loss_center: 0.6608  loss_offset: 1.38  time: 0.2717  data_time: 0.0278  lr: 0.0008232  max_mem: 6513M
[12/11 00:40:45 d2.utils.events]:  eta: 0:43:37  iter: 359  total_loss: 4.284  loss_sem_seg: 2.117  loss_center: 0.6327  loss_offset: 1.458  time: 0.2718  data_time: 0.0270  lr: 0.00087  max_mem: 6513M
[12/11 00:40:50 d2.utils.events]:  eta: 0:43:32  iter: 379  total_loss: 4.189  loss_sem_seg: 2.119  loss_center: 0.6825  loss_offset: 1.216  time: 0.2719  data_time: 0.0276  lr: 0.00091662  max_mem: 6513M
[12/11 00:40:56 d2.utils.events]:  eta: 0:43:26  iter: 399  total_loss: 4.088  loss_sem_seg: 2.114  loss_center: 0.6454  loss_offset: 1.337  time: 0.2720  data_time: 0.0286  lr: 0.00096306  max_mem: 6513M
[12/11 00:41:01 d2.utils.events]:  eta: 0:43:21  iter: 419  total_loss: 4.003  loss_sem_seg: 2.136  loss_center: 0.5736  loss_offset: 1.461  time: 0.2719  data_time: 0.0263  lr: 0.0010093  max_mem: 6513M
[12/11 00:41:07 d2.utils.events]:  eta: 0:43:15  iter: 439  total_loss: 4.024  loss_sem_seg: 2.103  loss_center: 0.5809  loss_offset: 1.315  time: 0.2719  data_time: 0.0259  lr: 0.0010554  max_mem: 6513M
[12/11 00:41:12 d2.utils.events]:  eta: 0:43:11  iter: 459  total_loss: 4.066  loss_sem_seg: 1.982  loss_center: 0.7077  loss_offset: 1.333  time: 0.2720  data_time: 0.0265  lr: 0.0011013  max_mem: 6513M
[12/11 00:41:18 d2.utils.events]:  eta: 0:43:05  iter: 479  total_loss: 3.718  loss_sem_seg: 2.031  loss_center: 0.6143  loss_offset: 1.301  time: 0.2719  data_time: 0.0274  lr: 0.001147  max_mem: 6513M
[12/11 00:41:23 d2.utils.events]:  eta: 0:42:58  iter: 499  total_loss: 3.857  loss_sem_seg: 2.072  loss_center: 0.5437  loss_offset: 1.042  time: 0.2719  data_time: 0.0266  lr: 0.0011925  max_mem: 6513M
[12/11 00:41:29 d2.utils.events]:  eta: 0:42:52  iter: 519  total_loss: 4.161  loss_sem_seg: 2.241  loss_center: 0.5191  loss_offset: 1.261  time: 0.2719  data_time: 0.0267  lr: 0.0012379  max_mem: 6513M
[12/11 00:41:34 d2.utils.events]:  eta: 0:42:46  iter: 539  total_loss: 3.623  loss_sem_seg: 1.821  loss_center: 0.7508  loss_offset: 1.03  time: 0.2719  data_time: 0.0262  lr: 0.001283  max_mem: 6513M
[12/11 00:41:39 d2.utils.events]:  eta: 0:42:39  iter: 559  total_loss: 3.867  loss_sem_seg: 1.97  loss_center: 0.7549  loss_offset: 1.112  time: 0.2719  data_time: 0.0268  lr: 0.001328  max_mem: 6513M
[12/11 00:41:45 d2.utils.events]:  eta: 0:42:34  iter: 579  total_loss: 3.609  loss_sem_seg: 1.885  loss_center: 0.7334  loss_offset: 0.9615  time: 0.2719  data_time: 0.0263  lr: 0.0013728  max_mem: 6513M
[12/11 00:41:50 d2.utils.events]:  eta: 0:42:29  iter: 599  total_loss: 3.746  loss_sem_seg: 1.859  loss_center: 0.6225  loss_offset: 1.084  time: 0.2720  data_time: 0.0304  lr: 0.0014175  max_mem: 6513M
[12/11 00:41:56 d2.utils.events]:  eta: 0:42:25  iter: 619  total_loss: 3.727  loss_sem_seg: 1.846  loss_center: 0.5749  loss_offset: 1.021  time: 0.2720  data_time: 0.0243  lr: 0.0014619  max_mem: 6513M
[12/11 00:42:01 d2.utils.events]:  eta: 0:42:21  iter: 639  total_loss: 3.758  loss_sem_seg: 1.93  loss_center: 0.7276  loss_offset: 0.9832  time: 0.2720  data_time: 0.0268  lr: 0.0015062  max_mem: 6513M
[12/11 00:42:07 d2.utils.events]:  eta: 0:42:13  iter: 659  total_loss: 3.309  loss_sem_seg: 1.768  loss_center: 0.6288  loss_offset: 1.075  time: 0.2719  data_time: 0.0263  lr: 0.0015503  max_mem: 6513M
[12/11 00:42:12 d2.utils.events]:  eta: 0:42:07  iter: 679  total_loss: 3.592  loss_sem_seg: 1.819  loss_center: 0.6524  loss_offset: 1.04  time: 0.2719  data_time: 0.0260  lr: 0.0015942  max_mem: 6513M
[12/11 00:42:18 d2.utils.events]:  eta: 0:42:00  iter: 699  total_loss: 3.787  loss_sem_seg: 2.02  loss_center: 0.7179  loss_offset: 0.9335  time: 0.2719  data_time: 0.0266  lr: 0.0016379  max_mem: 6513M
[12/11 00:42:23 d2.utils.events]:  eta: 0:41:56  iter: 719  total_loss: 3.721  loss_sem_seg: 1.82  loss_center: 0.5929  loss_offset: 1.106  time: 0.2720  data_time: 0.0268  lr: 0.0016814  max_mem: 6513M
[12/11 00:42:29 d2.utils.events]:  eta: 0:41:50  iter: 739  total_loss: 3.336  loss_sem_seg: 1.457  loss_center: 0.8305  loss_offset: 0.9832  time: 0.2720  data_time: 0.0241  lr: 0.0017248  max_mem: 6513M
[12/11 00:42:34 d2.utils.events]:  eta: 0:41:46  iter: 759  total_loss: 3.676  loss_sem_seg: 1.913  loss_center: 0.8107  loss_offset: 1.015  time: 0.2720  data_time: 0.0264  lr: 0.0017679  max_mem: 6513M
[12/11 00:42:39 d2.utils.events]:  eta: 0:41:40  iter: 779  total_loss: 3.471  loss_sem_seg: 1.764  loss_center: 0.6436  loss_offset: 1.07  time: 0.2720  data_time: 0.0274  lr: 0.0018109  max_mem: 6513M
[12/11 00:42:45 d2.utils.events]:  eta: 0:41:35  iter: 799  total_loss: 3.296  loss_sem_seg: 1.679  loss_center: 0.6159  loss_offset: 0.9883  time: 0.2720  data_time: 0.0269  lr: 0.0018537  max_mem: 6513M
[12/11 00:42:50 d2.utils.events]:  eta: 0:41:30  iter: 819  total_loss: 4.01  loss_sem_seg: 2.093  loss_center: 0.7109  loss_offset: 1.093  time: 0.2720  data_time: 0.0259  lr: 0.0018964  max_mem: 6513M
[12/11 00:42:56 d2.utils.events]:  eta: 0:41:26  iter: 839  total_loss: 3.856  loss_sem_seg: 1.987  loss_center: 0.5871  loss_offset: 1.026  time: 0.2721  data_time: 0.0276  lr: 0.0019388  max_mem: 6513M
[12/11 00:43:01 d2.utils.events]:  eta: 0:41:22  iter: 859  total_loss: 3.893  loss_sem_seg: 1.836  loss_center: 0.7782  loss_offset: 1.019  time: 0.2722  data_time: 0.0272  lr: 0.0019811  max_mem: 6513M
[12/11 00:43:07 d2.utils.events]:  eta: 0:41:17  iter: 879  total_loss: 3.734  loss_sem_seg: 1.738  loss_center: 0.744  loss_offset: 0.9979  time: 0.2722  data_time: 0.0282  lr: 0.0020231  max_mem: 6513M
[12/11 00:43:12 d2.utils.events]:  eta: 0:41:12  iter: 899  total_loss: 3.685  loss_sem_seg: 1.972  loss_center: 0.7403  loss_offset: 1.061  time: 0.2722  data_time: 0.0267  lr: 0.002065  max_mem: 6513M
[12/11 00:43:18 d2.utils.events]:  eta: 0:41:07  iter: 919  total_loss: 3.715  loss_sem_seg: 1.767  loss_center: 0.8443  loss_offset: 1.022  time: 0.2723  data_time: 0.0289  lr: 0.0021068  max_mem: 6513M
[12/11 00:43:23 d2.utils.events]:  eta: 0:41:02  iter: 939  total_loss: 3.683  loss_sem_seg: 1.711  loss_center: 0.8137  loss_offset: 0.9691  time: 0.2723  data_time: 0.0284  lr: 0.0021483  max_mem: 6513M
[12/11 00:43:29 d2.utils.events]:  eta: 0:40:56  iter: 959  total_loss: 3.482  loss_sem_seg: 1.891  loss_center: 0.7157  loss_offset: 1.083  time: 0.2723  data_time: 0.0279  lr: 0.0021896  max_mem: 6513M
[12/11 00:43:34 d2.utils.events]:  eta: 0:40:51  iter: 979  total_loss: 3.76  loss_sem_seg: 1.812  loss_center: 0.5788  loss_offset: 1.089  time: 0.2723  data_time: 0.0274  lr: 0.0022308  max_mem: 6513M
[12/11 00:43:40 d2.utils.events]:  eta: 0:40:46  iter: 999  total_loss: 3.69  loss_sem_seg: 1.809  loss_center: 0.6848  loss_offset: 1.145  time: 0.2724  data_time: 0.0267  lr: 0.0022718  max_mem: 6513M
[12/11 00:43:45 d2.utils.events]:  eta: 0:40:42  iter: 1019  total_loss: 3.48  loss_sem_seg: 1.582  loss_center: 0.6499  loss_offset: 1.125  time: 0.2724  data_time: 0.0289  lr: 0.0022695  max_mem: 6513M
[12/11 00:43:51 d2.utils.events]:  eta: 0:40:38  iter: 1039  total_loss: 3.392  loss_sem_seg: 1.481  loss_center: 0.7151  loss_offset: 1.026  time: 0.2724  data_time: 0.0265  lr: 0.002265  max_mem: 6513M
[12/11 00:43:56 d2.utils.events]:  eta: 0:40:33  iter: 1059  total_loss: 3.204  loss_sem_seg: 1.611  loss_center: 0.5843  loss_offset: 0.9439  time: 0.2723  data_time: 0.0260  lr: 0.0022604  max_mem: 6513M
[12/11 00:44:02 d2.utils.events]:  eta: 0:40:27  iter: 1079  total_loss: 3.454  loss_sem_seg: 1.736  loss_center: 0.6359  loss_offset: 1.038  time: 0.2724  data_time: 0.0291  lr: 0.0022559  max_mem: 6513M
[12/11 00:44:07 d2.utils.events]:  eta: 0:40:22  iter: 1099  total_loss: 3.257  loss_sem_seg: 1.631  loss_center: 0.5882  loss_offset: 0.9371  time: 0.2724  data_time: 0.0265  lr: 0.0022513  max_mem: 6513M
[12/11 00:44:12 d2.utils.events]:  eta: 0:40:14  iter: 1119  total_loss: 3.595  loss_sem_seg: 1.878  loss_center: 0.7  loss_offset: 1.014  time: 0.2723  data_time: 0.0245  lr: 0.0022468  max_mem: 6513M
[12/11 00:44:18 d2.utils.events]:  eta: 0:40:08  iter: 1139  total_loss: 3.431  loss_sem_seg: 1.786  loss_center: 0.7893  loss_offset: 0.9527  time: 0.2723  data_time: 0.0276  lr: 0.0022422  max_mem: 6513M
[12/11 00:44:23 d2.utils.events]:  eta: 0:40:03  iter: 1159  total_loss: 3.529  loss_sem_seg: 1.789  loss_center: 0.71  loss_offset: 1.018  time: 0.2722  data_time: 0.0266  lr: 0.0022376  max_mem: 6513M
[12/11 00:44:29 d2.utils.events]:  eta: 0:39:58  iter: 1179  total_loss: 3.365  loss_sem_seg: 1.652  loss_center: 0.747  loss_offset: 0.9413  time: 0.2723  data_time: 0.0263  lr: 0.0022331  max_mem: 6513M
[12/11 00:44:34 d2.utils.events]:  eta: 0:39:52  iter: 1199  total_loss: 3.558  loss_sem_seg: 1.772  loss_center: 0.7325  loss_offset: 1.059  time: 0.2722  data_time: 0.0268  lr: 0.0022285  max_mem: 6513M
[12/11 00:44:40 d2.utils.events]:  eta: 0:39:48  iter: 1219  total_loss: 3.69  loss_sem_seg: 1.762  loss_center: 0.7282  loss_offset: 1.09  time: 0.2723  data_time: 0.0270  lr: 0.002224  max_mem: 6513M
[12/11 00:44:45 d2.utils.events]:  eta: 0:39:42  iter: 1239  total_loss: 3.399  loss_sem_seg: 1.75  loss_center: 0.5947  loss_offset: 1.027  time: 0.2723  data_time: 0.0280  lr: 0.0022194  max_mem: 6513M
[12/11 00:44:51 d2.utils.events]:  eta: 0:39:37  iter: 1259  total_loss: 3.354  loss_sem_seg: 1.82  loss_center: 0.6291  loss_offset: 0.9234  time: 0.2723  data_time: 0.0287  lr: 0.0022149  max_mem: 6513M
[12/11 00:44:56 d2.utils.events]:  eta: 0:39:33  iter: 1279  total_loss: 3.566  loss_sem_seg: 1.824  loss_center: 0.6054  loss_offset: 0.9844  time: 0.2724  data_time: 0.0285  lr: 0.0022103  max_mem: 6513M
[12/11 00:45:02 d2.utils.events]:  eta: 0:39:28  iter: 1299  total_loss: 3.547  loss_sem_seg: 1.873  loss_center: 0.687  loss_offset: 0.9911  time: 0.2724  data_time: 0.0264  lr: 0.0022057  max_mem: 6513M
[12/11 00:45:07 d2.utils.events]:  eta: 0:39:23  iter: 1319  total_loss: 3.358  loss_sem_seg: 1.763  loss_center: 0.6811  loss_offset: 0.8937  time: 0.2725  data_time: 0.0283  lr: 0.0022012  max_mem: 6513M
[12/11 00:45:13 d2.utils.events]:  eta: 0:39:18  iter: 1339  total_loss: 3.532  loss_sem_seg: 1.63  loss_center: 0.7504  loss_offset: 1.012  time: 0.2724  data_time: 0.0264  lr: 0.0021966  max_mem: 6513M
[12/11 00:45:18 d2.utils.events]:  eta: 0:39:12  iter: 1359  total_loss: 3.392  loss_sem_seg: 1.6  loss_center: 0.6668  loss_offset: 1.113  time: 0.2724  data_time: 0.0272  lr: 0.002192  max_mem: 6513M
[12/11 00:45:24 d2.utils.events]:  eta: 0:39:07  iter: 1379  total_loss: 3.613  loss_sem_seg: 1.843  loss_center: 0.7175  loss_offset: 1.029  time: 0.2724  data_time: 0.0266  lr: 0.0021875  max_mem: 6513M
[12/11 00:45:29 d2.utils.events]:  eta: 0:39:02  iter: 1399  total_loss: 3.511  loss_sem_seg: 1.841  loss_center: 0.6272  loss_offset: 1.081  time: 0.2724  data_time: 0.0280  lr: 0.0021829  max_mem: 6513M
[12/11 00:45:34 d2.utils.events]:  eta: 0:38:56  iter: 1419  total_loss: 3.411  loss_sem_seg: 1.59  loss_center: 0.6661  loss_offset: 0.9911  time: 0.2724  data_time: 0.0272  lr: 0.0021783  max_mem: 6513M
[12/11 00:45:40 d2.utils.events]:  eta: 0:38:51  iter: 1439  total_loss: 3.578  loss_sem_seg: 1.827  loss_center: 0.6613  loss_offset: 1.002  time: 0.2724  data_time: 0.0272  lr: 0.0021738  max_mem: 6513M
[12/11 00:45:45 d2.utils.events]:  eta: 0:38:46  iter: 1459  total_loss: 3.465  loss_sem_seg: 1.867  loss_center: 0.5459  loss_offset: 0.9808  time: 0.2725  data_time: 0.0268  lr: 0.0021692  max_mem: 6513M
[12/11 00:45:51 d2.utils.events]:  eta: 0:38:41  iter: 1479  total_loss: 3.483  loss_sem_seg: 1.797  loss_center: 0.6478  loss_offset: 1.069  time: 0.2725  data_time: 0.0297  lr: 0.0021646  max_mem: 6513M
[12/11 00:45:56 d2.utils.events]:  eta: 0:38:36  iter: 1499  total_loss: 3.624  loss_sem_seg: 1.77  loss_center: 0.6638  loss_offset: 1.05  time: 0.2725  data_time: 0.0260  lr: 0.00216  max_mem: 6513M
[12/11 00:46:02 d2.utils.events]:  eta: 0:38:30  iter: 1519  total_loss: 3.361  loss_sem_seg: 1.758  loss_center: 0.6022  loss_offset: 1  time: 0.2725  data_time: 0.0266  lr: 0.0021555  max_mem: 6513M
[12/11 00:46:07 d2.utils.events]:  eta: 0:38:25  iter: 1539  total_loss: 3.621  loss_sem_seg: 1.832  loss_center: 0.7434  loss_offset: 0.9846  time: 0.2726  data_time: 0.0290  lr: 0.0021509  max_mem: 6513M
[12/11 00:46:13 d2.utils.events]:  eta: 0:38:20  iter: 1559  total_loss: 3.501  loss_sem_seg: 1.74  loss_center: 0.6324  loss_offset: 0.9583  time: 0.2725  data_time: 0.0279  lr: 0.0021463  max_mem: 6513M
[12/11 00:46:18 d2.utils.events]:  eta: 0:38:15  iter: 1579  total_loss: 3.348  loss_sem_seg: 1.61  loss_center: 0.6099  loss_offset: 0.9291  time: 0.2726  data_time: 0.0274  lr: 0.0021417  max_mem: 6513M
[12/11 00:46:24 d2.utils.events]:  eta: 0:38:10  iter: 1599  total_loss: 3.268  loss_sem_seg: 1.696  loss_center: 0.6034  loss_offset: 0.9207  time: 0.2726  data_time: 0.0288  lr: 0.0021372  max_mem: 6513M
[12/11 00:46:29 d2.utils.events]:  eta: 0:38:05  iter: 1619  total_loss: 3.509  loss_sem_seg: 1.85  loss_center: 0.604  loss_offset: 1.039  time: 0.2726  data_time: 0.0272  lr: 0.0021326  max_mem: 6513M
[12/11 00:46:35 d2.utils.events]:  eta: 0:38:00  iter: 1639  total_loss: 3.412  loss_sem_seg: 1.716  loss_center: 0.7083  loss_offset: 0.914  time: 0.2726  data_time: 0.0266  lr: 0.002128  max_mem: 6513M
[12/11 00:46:40 d2.utils.events]:  eta: 0:37:57  iter: 1659  total_loss: 3.581  loss_sem_seg: 1.739  loss_center: 0.7812  loss_offset: 1.008  time: 0.2726  data_time: 0.0267  lr: 0.0021234  max_mem: 6513M
[12/11 00:46:46 d2.utils.events]:  eta: 0:37:52  iter: 1679  total_loss: 3.574  loss_sem_seg: 1.819  loss_center: 0.6383  loss_offset: 1.077  time: 0.2727  data_time: 0.0280  lr: 0.0021188  max_mem: 6513M
[12/11 00:46:51 d2.utils.events]:  eta: 0:37:47  iter: 1699  total_loss: 3.453  loss_sem_seg: 1.769  loss_center: 0.7333  loss_offset: 0.9543  time: 0.2727  data_time: 0.0262  lr: 0.0021143  max_mem: 6513M
[12/11 00:46:57 d2.utils.events]:  eta: 0:37:42  iter: 1719  total_loss: 3.182  loss_sem_seg: 1.724  loss_center: 0.5756  loss_offset: 0.9279  time: 0.2727  data_time: 0.0309  lr: 0.0021097  max_mem: 6513M
[12/11 00:47:02 d2.utils.events]:  eta: 0:37:38  iter: 1739  total_loss: 3.294  loss_sem_seg: 1.572  loss_center: 0.7295  loss_offset: 0.967  time: 0.2727  data_time: 0.0279  lr: 0.0021051  max_mem: 6513M
[12/11 00:47:08 d2.utils.events]:  eta: 0:37:31  iter: 1759  total_loss: 3.409  loss_sem_seg: 1.564  loss_center: 0.7245  loss_offset: 1.095  time: 0.2727  data_time: 0.0281  lr: 0.0021005  max_mem: 6513M
[12/11 00:47:13 d2.utils.events]:  eta: 0:37:27  iter: 1779  total_loss: 3.461  loss_sem_seg: 1.674  loss_center: 0.5933  loss_offset: 0.9228  time: 0.2728  data_time: 0.0294  lr: 0.0020959  max_mem: 6513M
[12/11 00:47:19 d2.utils.events]:  eta: 0:37:21  iter: 1799  total_loss: 3.697  loss_sem_seg: 1.907  loss_center: 0.6081  loss_offset: 1.095  time: 0.2728  data_time: 0.0272  lr: 0.0020913  max_mem: 6513M
[12/11 00:47:24 d2.utils.events]:  eta: 0:37:15  iter: 1819  total_loss: 3.436  loss_sem_seg: 1.694  loss_center: 0.7044  loss_offset: 0.9506  time: 0.2728  data_time: 0.0263  lr: 0.0020867  max_mem: 6513M
[12/11 00:47:30 d2.utils.events]:  eta: 0:37:11  iter: 1839  total_loss: 3.329  loss_sem_seg: 1.615  loss_center: 0.6483  loss_offset: 0.9572  time: 0.2728  data_time: 0.0301  lr: 0.0020821  max_mem: 6513M
[12/11 00:47:35 d2.utils.events]:  eta: 0:37:04  iter: 1859  total_loss: 3.252  loss_sem_seg: 1.67  loss_center: 0.6773  loss_offset: 0.9926  time: 0.2729  data_time: 0.0277  lr: 0.0020775  max_mem: 6513M
[12/11 00:47:41 d2.utils.events]:  eta: 0:36:59  iter: 1879  total_loss: 3.205  loss_sem_seg: 1.572  loss_center: 0.6634  loss_offset: 0.9433  time: 0.2729  data_time: 0.0275  lr: 0.0020729  max_mem: 6513M
[12/11 00:47:46 d2.utils.events]:  eta: 0:36:53  iter: 1899  total_loss: 3.322  loss_sem_seg: 1.826  loss_center: 0.5229  loss_offset: 0.8957  time: 0.2729  data_time: 0.0286  lr: 0.0020684  max_mem: 6513M
[12/11 00:47:52 d2.utils.events]:  eta: 0:36:48  iter: 1919  total_loss: 3.043  loss_sem_seg: 1.492  loss_center: 0.697  loss_offset: 0.8216  time: 0.2729  data_time: 0.0270  lr: 0.0020638  max_mem: 6513M
[12/11 00:47:57 d2.utils.events]:  eta: 0:36:42  iter: 1939  total_loss: 3.317  loss_sem_seg: 1.644  loss_center: 0.6625  loss_offset: 0.9915  time: 0.2729  data_time: 0.0279  lr: 0.0020592  max_mem: 6513M
[12/11 00:48:03 d2.utils.events]:  eta: 0:36:36  iter: 1959  total_loss: 3.221  loss_sem_seg: 1.556  loss_center: 0.6561  loss_offset: 0.9903  time: 0.2729  data_time: 0.0280  lr: 0.0020546  max_mem: 6513M
[12/11 00:48:08 d2.utils.events]:  eta: 0:36:30  iter: 1979  total_loss: 3.079  loss_sem_seg: 1.486  loss_center: 0.5656  loss_offset: 0.9952  time: 0.2729  data_time: 0.0270  lr: 0.00205  max_mem: 6513M
[12/11 00:48:14 d2.utils.events]:  eta: 0:36:25  iter: 1999  total_loss: 3.185  loss_sem_seg: 1.748  loss_center: 0.5466  loss_offset: 0.8954  time: 0.2729  data_time: 0.0289  lr: 0.0020454  max_mem: 6513M
[12/11 00:48:19 d2.utils.events]:  eta: 0:36:20  iter: 2019  total_loss: 3.486  loss_sem_seg: 1.758  loss_center: 0.6536  loss_offset: 1.044  time: 0.2729  data_time: 0.0264  lr: 0.0020408  max_mem: 6513M
[12/11 00:48:25 d2.utils.events]:  eta: 0:36:14  iter: 2039  total_loss: 3.238  loss_sem_seg: 1.479  loss_center: 0.6793  loss_offset: 0.9308  time: 0.2729  data_time: 0.0277  lr: 0.0020362  max_mem: 6513M
[12/11 00:48:30 d2.utils.events]:  eta: 0:36:08  iter: 2059  total_loss: 3.494  loss_sem_seg: 1.561  loss_center: 0.6245  loss_offset: 1.055  time: 0.2729  data_time: 0.0271  lr: 0.0020316  max_mem: 6513M
[12/11 00:48:36 d2.utils.events]:  eta: 0:36:02  iter: 2079  total_loss: 3.159  loss_sem_seg: 1.589  loss_center: 0.6953  loss_offset: 0.9644  time: 0.2729  data_time: 0.0271  lr: 0.0020269  max_mem: 6513M
[12/11 00:48:41 d2.utils.events]:  eta: 0:35:57  iter: 2099  total_loss: 3.437  loss_sem_seg: 1.766  loss_center: 0.6521  loss_offset: 1.02  time: 0.2729  data_time: 0.0279  lr: 0.0020223  max_mem: 6513M
[12/11 00:48:47 d2.utils.events]:  eta: 0:35:53  iter: 2119  total_loss: 3.407  loss_sem_seg: 1.693  loss_center: 0.5728  loss_offset: 1.012  time: 0.2730  data_time: 0.0281  lr: 0.0020177  max_mem: 6513M
[12/11 00:48:52 d2.utils.events]:  eta: 0:35:48  iter: 2139  total_loss: 3.567  loss_sem_seg: 1.719  loss_center: 0.7509  loss_offset: 0.9668  time: 0.2730  data_time: 0.0284  lr: 0.0020131  max_mem: 6513M
[12/11 00:48:58 d2.utils.events]:  eta: 0:35:43  iter: 2159  total_loss: 3.042  loss_sem_seg: 1.357  loss_center: 0.7616  loss_offset: 0.9626  time: 0.2729  data_time: 0.0265  lr: 0.0020085  max_mem: 6513M
[12/11 00:49:03 d2.utils.events]:  eta: 0:35:39  iter: 2179  total_loss: 3.286  loss_sem_seg: 1.491  loss_center: 0.7426  loss_offset: 0.9813  time: 0.2729  data_time: 0.0284  lr: 0.0020039  max_mem: 6513M
[12/11 00:49:09 d2.utils.events]:  eta: 0:35:34  iter: 2199  total_loss: 3.638  loss_sem_seg: 1.802  loss_center: 0.7102  loss_offset: 1.029  time: 0.2730  data_time: 0.0278  lr: 0.0019993  max_mem: 6513M
[12/11 00:49:14 d2.utils.events]:  eta: 0:35:30  iter: 2219  total_loss: 3.398  loss_sem_seg: 1.699  loss_center: 0.7928  loss_offset: 0.9101  time: 0.2730  data_time: 0.0278  lr: 0.0019947  max_mem: 6513M
[12/11 00:49:19 d2.utils.events]:  eta: 0:35:25  iter: 2239  total_loss: 3.312  loss_sem_seg: 1.601  loss_center: 0.7485  loss_offset: 0.9907  time: 0.2730  data_time: 0.0275  lr: 0.0019901  max_mem: 6513M
[12/11 00:49:25 d2.utils.events]:  eta: 0:35:19  iter: 2259  total_loss: 3.205  loss_sem_seg: 1.779  loss_center: 0.569  loss_offset: 0.9321  time: 0.2730  data_time: 0.0275  lr: 0.0019854  max_mem: 6513M
[12/11 00:49:30 d2.utils.events]:  eta: 0:35:12  iter: 2279  total_loss: 3.092  loss_sem_seg: 1.528  loss_center: 0.6675  loss_offset: 1.002  time: 0.2730  data_time: 0.0265  lr: 0.0019808  max_mem: 6513M
[12/11 00:49:36 d2.utils.events]:  eta: 0:35:07  iter: 2299  total_loss: 3.314  loss_sem_seg: 1.582  loss_center: 0.6753  loss_offset: 1.049  time: 0.2730  data_time: 0.0276  lr: 0.0019762  max_mem: 6513M
[12/11 00:49:41 d2.utils.events]:  eta: 0:35:01  iter: 2319  total_loss: 3.075  loss_sem_seg: 1.549  loss_center: 0.6033  loss_offset: 0.9271  time: 0.2730  data_time: 0.0279  lr: 0.0019716  max_mem: 6513M
[12/11 00:49:47 d2.utils.events]:  eta: 0:34:55  iter: 2339  total_loss: 3.12  loss_sem_seg: 1.471  loss_center: 0.5892  loss_offset: 0.9777  time: 0.2730  data_time: 0.0274  lr: 0.001967  max_mem: 6513M
[12/11 00:49:52 d2.utils.events]:  eta: 0:34:51  iter: 2359  total_loss: 3.223  loss_sem_seg: 1.57  loss_center: 0.5763  loss_offset: 0.8931  time: 0.2730  data_time: 0.0282  lr: 0.0019623  max_mem: 6513M
[12/11 00:49:58 d2.utils.events]:  eta: 0:34:45  iter: 2379  total_loss: 3.373  loss_sem_seg: 1.702  loss_center: 0.729  loss_offset: 0.8446  time: 0.2730  data_time: 0.0261  lr: 0.0019577  max_mem: 6513M
[12/11 00:50:03 d2.utils.events]:  eta: 0:34:41  iter: 2399  total_loss: 3.061  loss_sem_seg: 1.453  loss_center: 0.662  loss_offset: 1.026  time: 0.2730  data_time: 0.0284  lr: 0.0019531  max_mem: 6513M
[12/11 00:50:09 d2.utils.events]:  eta: 0:34:35  iter: 2419  total_loss: 3.099  loss_sem_seg: 1.639  loss_center: 0.631  loss_offset: 0.9108  time: 0.2730  data_time: 0.0271  lr: 0.0019485  max_mem: 6513M
[12/11 00:50:14 d2.utils.events]:  eta: 0:34:29  iter: 2439  total_loss: 3.353  loss_sem_seg: 1.725  loss_center: 0.5783  loss_offset: 1.004  time: 0.2730  data_time: 0.0275  lr: 0.0019438  max_mem: 6513M
[12/11 00:50:20 d2.utils.events]:  eta: 0:34:22  iter: 2459  total_loss: 3.36  loss_sem_seg: 1.702  loss_center: 0.6167  loss_offset: 1.022  time: 0.2731  data_time: 0.0270  lr: 0.0019392  max_mem: 6513M
[12/11 00:50:25 d2.utils.events]:  eta: 0:34:17  iter: 2479  total_loss: 3.211  loss_sem_seg: 1.644  loss_center: 0.6259  loss_offset: 0.9628  time: 0.2731  data_time: 0.0281  lr: 0.0019346  max_mem: 6513M
[12/11 00:50:31 d2.utils.events]:  eta: 0:34:12  iter: 2499  total_loss: 3.252  loss_sem_seg: 1.413  loss_center: 0.5819  loss_offset: 0.9711  time: 0.2731  data_time: 0.0272  lr: 0.00193  max_mem: 6513M
[12/11 00:50:36 d2.utils.events]:  eta: 0:34:06  iter: 2519  total_loss: 2.937  loss_sem_seg: 1.305  loss_center: 0.5864  loss_offset: 0.8428  time: 0.2731  data_time: 0.0269  lr: 0.0019253  max_mem: 6513M
[12/11 00:50:42 d2.utils.events]:  eta: 0:34:01  iter: 2539  total_loss: 3.159  loss_sem_seg: 1.637  loss_center: 0.6725  loss_offset: 0.8742  time: 0.2731  data_time: 0.0289  lr: 0.0019207  max_mem: 6513M
[12/11 00:50:47 d2.utils.events]:  eta: 0:33:57  iter: 2559  total_loss: 3.324  loss_sem_seg: 1.733  loss_center: 0.5578  loss_offset: 0.9717  time: 0.2731  data_time: 0.0281  lr: 0.0019161  max_mem: 6513M
[12/11 00:50:53 d2.utils.events]:  eta: 0:33:50  iter: 2579  total_loss: 3.213  loss_sem_seg: 1.494  loss_center: 0.7692  loss_offset: 0.9034  time: 0.2731  data_time: 0.0277  lr: 0.0019114  max_mem: 6513M
[12/11 00:50:58 d2.utils.events]:  eta: 0:33:44  iter: 2599  total_loss: 3.116  loss_sem_seg: 1.17  loss_center: 0.8128  loss_offset: 0.8657  time: 0.2731  data_time: 0.0286  lr: 0.0019068  max_mem: 6513M
[12/11 00:51:04 d2.utils.events]:  eta: 0:33:38  iter: 2619  total_loss: 3.097  loss_sem_seg: 1.457  loss_center: 0.6346  loss_offset: 0.8839  time: 0.2731  data_time: 0.0262  lr: 0.0019021  max_mem: 6513M
[12/11 00:51:09 d2.utils.events]:  eta: 0:33:32  iter: 2639  total_loss: 3.122  loss_sem_seg: 1.363  loss_center: 0.6545  loss_offset: 0.9383  time: 0.2731  data_time: 0.0276  lr: 0.0018975  max_mem: 6513M
[12/11 00:51:15 d2.utils.events]:  eta: 0:33:26  iter: 2659  total_loss: 3.154  loss_sem_seg: 1.566  loss_center: 0.6829  loss_offset: 1.002  time: 0.2731  data_time: 0.0267  lr: 0.0018929  max_mem: 6513M
[12/11 00:51:20 d2.utils.events]:  eta: 0:33:21  iter: 2679  total_loss: 3.119  loss_sem_seg: 1.579  loss_center: 0.6321  loss_offset: 0.9103  time: 0.2732  data_time: 0.0272  lr: 0.0018882  max_mem: 6513M
[12/11 00:51:26 d2.utils.events]:  eta: 0:33:16  iter: 2699  total_loss: 3.369  loss_sem_seg: 1.535  loss_center: 0.83  loss_offset: 0.9076  time: 0.2732  data_time: 0.0280  lr: 0.0018836  max_mem: 6513M
[12/11 00:51:31 d2.utils.events]:  eta: 0:33:10  iter: 2719  total_loss: 3.198  loss_sem_seg: 1.422  loss_center: 0.5452  loss_offset: 0.9136  time: 0.2732  data_time: 0.0292  lr: 0.0018789  max_mem: 6513M
[12/11 00:51:37 d2.utils.events]:  eta: 0:33:04  iter: 2739  total_loss: 3.036  loss_sem_seg: 1.515  loss_center: 0.597  loss_offset: 0.8851  time: 0.2732  data_time: 0.0285  lr: 0.0018743  max_mem: 6513M
[12/11 00:51:42 d2.utils.events]:  eta: 0:32:56  iter: 2759  total_loss: 3.121  loss_sem_seg: 1.335  loss_center: 0.5786  loss_offset: 0.9818  time: 0.2732  data_time: 0.0264  lr: 0.0018696  max_mem: 6513M
[12/11 00:51:48 d2.utils.events]:  eta: 0:32:51  iter: 2779  total_loss: 3.121  loss_sem_seg: 1.448  loss_center: 0.5484  loss_offset: 0.9338  time: 0.2732  data_time: 0.0286  lr: 0.001865  max_mem: 6513M
[12/11 00:51:53 d2.utils.events]:  eta: 0:32:46  iter: 2799  total_loss: 3.494  loss_sem_seg: 1.787  loss_center: 0.7242  loss_offset: 0.8675  time: 0.2732  data_time: 0.0280  lr: 0.0018603  max_mem: 6513M
[12/11 00:51:59 d2.utils.events]:  eta: 0:32:41  iter: 2819  total_loss: 3.324  loss_sem_seg: 1.649  loss_center: 0.668  loss_offset: 0.9778  time: 0.2732  data_time: 0.0270  lr: 0.0018557  max_mem: 6513M
[12/11 00:52:04 d2.utils.events]:  eta: 0:32:35  iter: 2839  total_loss: 3.352  loss_sem_seg: 1.709  loss_center: 0.6409  loss_offset: 1.023  time: 0.2732  data_time: 0.0274  lr: 0.001851  max_mem: 6513M
[12/11 00:52:10 d2.utils.events]:  eta: 0:32:31  iter: 2859  total_loss: 3.339  loss_sem_seg: 1.665  loss_center: 0.5868  loss_offset: 1.051  time: 0.2733  data_time: 0.0294  lr: 0.0018464  max_mem: 6513M
[12/11 00:52:15 d2.utils.events]:  eta: 0:32:26  iter: 2879  total_loss: 3.191  loss_sem_seg: 1.581  loss_center: 0.6814  loss_offset: 1.013  time: 0.2733  data_time: 0.0270  lr: 0.0018417  max_mem: 6513M
[12/11 00:52:21 d2.utils.events]:  eta: 0:32:19  iter: 2899  total_loss: 3.077  loss_sem_seg: 1.553  loss_center: 0.7245  loss_offset: 0.9268  time: 0.2733  data_time: 0.0276  lr: 0.0018371  max_mem: 6513M
[12/11 00:52:26 d2.utils.events]:  eta: 0:32:13  iter: 2919  total_loss: 3.101  loss_sem_seg: 1.485  loss_center: 0.5621  loss_offset: 0.8983  time: 0.2732  data_time: 0.0267  lr: 0.0018324  max_mem: 6513M
[12/11 00:52:32 d2.utils.events]:  eta: 0:32:07  iter: 2939  total_loss: 2.995  loss_sem_seg: 1.459  loss_center: 0.8271  loss_offset: 0.7995  time: 0.2732  data_time: 0.0274  lr: 0.0018278  max_mem: 6513M
[12/11 00:52:37 d2.utils.events]:  eta: 0:32:03  iter: 2959  total_loss: 3.087  loss_sem_seg: 1.561  loss_center: 0.4998  loss_offset: 0.8616  time: 0.2733  data_time: 0.0303  lr: 0.0018231  max_mem: 6513M
[12/11 00:52:43 d2.utils.events]:  eta: 0:31:58  iter: 2979  total_loss: 3.337  loss_sem_seg: 1.522  loss_center: 0.7579  loss_offset: 0.9729  time: 0.2733  data_time: 0.0282  lr: 0.0018184  max_mem: 6513M
[12/11 00:52:48 d2.utils.events]:  eta: 0:31:52  iter: 2999  total_loss: 2.859  loss_sem_seg: 1.396  loss_center: 0.5835  loss_offset: 0.8594  time: 0.2733  data_time: 0.0282  lr: 0.0018138  max_mem: 6513M
[12/11 00:52:54 d2.utils.events]:  eta: 0:31:46  iter: 3019  total_loss: 3.427  loss_sem_seg: 1.621  loss_center: 0.686  loss_offset: 0.9064  time: 0.2733  data_time: 0.0279  lr: 0.0018091  max_mem: 6513M
[12/11 00:52:59 d2.utils.events]:  eta: 0:31:41  iter: 3039  total_loss: 3.062  loss_sem_seg: 1.297  loss_center: 0.6558  loss_offset: 0.8965  time: 0.2733  data_time: 0.0258  lr: 0.0018044  max_mem: 6513M
[12/11 00:53:05 d2.utils.events]:  eta: 0:31:37  iter: 3059  total_loss: 3.245  loss_sem_seg: 1.421  loss_center: 0.7324  loss_offset: 0.8486  time: 0.2733  data_time: 0.0290  lr: 0.0017998  max_mem: 6513M
[12/11 00:53:10 d2.utils.events]:  eta: 0:31:31  iter: 3079  total_loss: 3.272  loss_sem_seg: 1.621  loss_center: 0.6378  loss_offset: 1.024  time: 0.2733  data_time: 0.0280  lr: 0.0017951  max_mem: 6513M
[12/11 00:53:16 d2.utils.events]:  eta: 0:31:25  iter: 3099  total_loss: 3.031  loss_sem_seg: 1.336  loss_center: 0.6693  loss_offset: 1.063  time: 0.2733  data_time: 0.0259  lr: 0.0017904  max_mem: 6513M
[12/11 00:53:21 d2.utils.events]:  eta: 0:31:20  iter: 3119  total_loss: 2.815  loss_sem_seg: 1.352  loss_center: 0.5393  loss_offset: 0.8863  time: 0.2733  data_time: 0.0273  lr: 0.0017858  max_mem: 6513M
[12/11 00:53:27 d2.utils.events]:  eta: 0:31:13  iter: 3139  total_loss: 3.133  loss_sem_seg: 1.49  loss_center: 0.769  loss_offset: 0.88  time: 0.2733  data_time: 0.0266  lr: 0.0017811  max_mem: 6513M
[12/11 00:53:32 d2.utils.events]:  eta: 0:31:08  iter: 3159  total_loss: 3.407  loss_sem_seg: 1.511  loss_center: 0.7021  loss_offset: 1.001  time: 0.2733  data_time: 0.0274  lr: 0.0017764  max_mem: 6513M
[12/11 00:53:37 d2.utils.events]:  eta: 0:31:03  iter: 3179  total_loss: 2.958  loss_sem_seg: 1.39  loss_center: 0.5559  loss_offset: 0.8524  time: 0.2733  data_time: 0.0263  lr: 0.0017718  max_mem: 6513M
[12/11 00:53:43 d2.utils.events]:  eta: 0:30:57  iter: 3199  total_loss: 3.275  loss_sem_seg: 1.566  loss_center: 0.6485  loss_offset: 0.8662  time: 0.2733  data_time: 0.0276  lr: 0.0017671  max_mem: 6513M
[12/11 00:53:48 d2.utils.events]:  eta: 0:30:51  iter: 3219  total_loss: 3.124  loss_sem_seg: 1.546  loss_center: 0.723  loss_offset: 0.8332  time: 0.2733  data_time: 0.0283  lr: 0.0017624  max_mem: 6513M
[12/11 00:53:54 d2.utils.events]:  eta: 0:30:45  iter: 3239  total_loss: 2.926  loss_sem_seg: 1.351  loss_center: 0.6383  loss_offset: 0.8999  time: 0.2733  data_time: 0.0277  lr: 0.0017577  max_mem: 6513M
[12/11 00:53:59 d2.utils.events]:  eta: 0:30:40  iter: 3259  total_loss: 3.075  loss_sem_seg: 1.447  loss_center: 0.5902  loss_offset: 0.9928  time: 0.2733  data_time: 0.0287  lr: 0.001753  max_mem: 6513M
[12/11 00:54:05 d2.utils.events]:  eta: 0:30:35  iter: 3279  total_loss: 3.242  loss_sem_seg: 1.695  loss_center: 0.5865  loss_offset: 0.9007  time: 0.2733  data_time: 0.0290  lr: 0.0017484  max_mem: 6513M
[12/11 00:54:10 d2.utils.events]:  eta: 0:30:29  iter: 3299  total_loss: 3.144  loss_sem_seg: 1.309  loss_center: 0.7245  loss_offset: 0.9486  time: 0.2733  data_time: 0.0275  lr: 0.0017437  max_mem: 6513M
[12/11 00:54:16 d2.utils.events]:  eta: 0:30:22  iter: 3319  total_loss: 3.309  loss_sem_seg: 1.476  loss_center: 0.7974  loss_offset: 1.004  time: 0.2733  data_time: 0.0289  lr: 0.001739  max_mem: 6513M
[12/11 00:54:21 d2.utils.events]:  eta: 0:30:17  iter: 3339  total_loss: 3.106  loss_sem_seg: 1.444  loss_center: 0.6186  loss_offset: 0.9761  time: 0.2733  data_time: 0.0284  lr: 0.0017343  max_mem: 6513M
[12/11 00:54:27 d2.utils.events]:  eta: 0:30:09  iter: 3359  total_loss: 3.203  loss_sem_seg: 1.646  loss_center: 0.565  loss_offset: 0.813  time: 0.2733  data_time: 0.0263  lr: 0.0017296  max_mem: 6513M
[12/11 00:54:32 d2.utils.events]:  eta: 0:30:05  iter: 3379  total_loss: 3.343  loss_sem_seg: 1.598  loss_center: 0.7682  loss_offset: 0.927  time: 0.2733  data_time: 0.0278  lr: 0.0017249  max_mem: 6513M
[12/11 00:54:38 d2.utils.events]:  eta: 0:29:59  iter: 3399  total_loss: 3.087  loss_sem_seg: 1.523  loss_center: 0.6793  loss_offset: 0.8236  time: 0.2733  data_time: 0.0277  lr: 0.0017202  max_mem: 6513M
[12/11 00:54:43 d2.utils.events]:  eta: 0:29:53  iter: 3419  total_loss: 3.208  loss_sem_seg: 1.473  loss_center: 0.6101  loss_offset: 0.9478  time: 0.2733  data_time: 0.0266  lr: 0.0017155  max_mem: 6513M
[12/11 00:54:49 d2.utils.events]:  eta: 0:29:48  iter: 3439  total_loss: 3.035  loss_sem_seg: 1.462  loss_center: 0.5671  loss_offset: 0.8952  time: 0.2733  data_time: 0.0270  lr: 0.0017109  max_mem: 6513M
[12/11 00:54:54 d2.utils.events]:  eta: 0:29:43  iter: 3459  total_loss: 3.165  loss_sem_seg: 1.431  loss_center: 0.62  loss_offset: 0.9154  time: 0.2733  data_time: 0.0277  lr: 0.0017062  max_mem: 6513M
[12/11 00:55:00 d2.utils.events]:  eta: 0:29:38  iter: 3479  total_loss: 3.172  loss_sem_seg: 1.562  loss_center: 0.6104  loss_offset: 0.8809  time: 0.2733  data_time: 0.0284  lr: 0.0017015  max_mem: 6513M
[12/11 00:55:05 d2.utils.events]:  eta: 0:29:32  iter: 3499  total_loss: 3.17  loss_sem_seg: 1.563  loss_center: 0.7368  loss_offset: 0.876  time: 0.2733  data_time: 0.0284  lr: 0.0016968  max_mem: 6513M
[12/11 00:55:11 d2.utils.events]:  eta: 0:29:28  iter: 3519  total_loss: 2.994  loss_sem_seg: 1.431  loss_center: 0.6877  loss_offset: 0.8151  time: 0.2733  data_time: 0.0273  lr: 0.0016921  max_mem: 6513M
[12/11 00:55:16 d2.utils.events]:  eta: 0:29:22  iter: 3539  total_loss: 2.934  loss_sem_seg: 1.283  loss_center: 0.5763  loss_offset: 0.9265  time: 0.2733  data_time: 0.0269  lr: 0.0016874  max_mem: 6513M
[12/11 00:55:21 d2.utils.events]:  eta: 0:29:16  iter: 3559  total_loss: 3.004  loss_sem_seg: 1.432  loss_center: 0.6917  loss_offset: 0.8939  time: 0.2733  data_time: 0.0284  lr: 0.0016827  max_mem: 6513M
[12/11 00:55:27 d2.utils.events]:  eta: 0:29:11  iter: 3579  total_loss: 3.28  loss_sem_seg: 1.542  loss_center: 0.6885  loss_offset: 1.028  time: 0.2733  data_time: 0.0276  lr: 0.001678  max_mem: 6513M
[12/11 00:55:33 d2.utils.events]:  eta: 0:29:06  iter: 3599  total_loss: 3.079  loss_sem_seg: 1.576  loss_center: 0.4326  loss_offset: 0.9306  time: 0.2733  data_time: 0.0281  lr: 0.0016733  max_mem: 6513M
[12/11 00:55:38 d2.utils.events]:  eta: 0:29:02  iter: 3619  total_loss: 3.067  loss_sem_seg: 1.453  loss_center: 0.5465  loss_offset: 0.9195  time: 0.2733  data_time: 0.0270  lr: 0.0016686  max_mem: 6513M
[12/11 00:55:43 d2.utils.events]:  eta: 0:28:56  iter: 3639  total_loss: 3.063  loss_sem_seg: 1.452  loss_center: 0.7186  loss_offset: 0.9135  time: 0.2733  data_time: 0.0265  lr: 0.0016638  max_mem: 6513M
[12/11 00:55:49 d2.utils.events]:  eta: 0:28:50  iter: 3659  total_loss: 3.151  loss_sem_seg: 1.397  loss_center: 0.6909  loss_offset: 0.9403  time: 0.2733  data_time: 0.0271  lr: 0.0016591  max_mem: 6513M
[12/11 00:55:54 d2.utils.events]:  eta: 0:28:43  iter: 3679  total_loss: 2.925  loss_sem_seg: 1.319  loss_center: 0.5259  loss_offset: 0.8804  time: 0.2733  data_time: 0.0284  lr: 0.0016544  max_mem: 6513M
[12/11 00:56:00 d2.utils.events]:  eta: 0:28:38  iter: 3699  total_loss: 3.026  loss_sem_seg: 1.31  loss_center: 0.6802  loss_offset: 0.8588  time: 0.2733  data_time: 0.0264  lr: 0.0016497  max_mem: 6513M
[12/11 00:56:05 d2.utils.events]:  eta: 0:28:33  iter: 3719  total_loss: 2.986  loss_sem_seg: 1.471  loss_center: 0.6695  loss_offset: 0.9505  time: 0.2733  data_time: 0.0293  lr: 0.001645  max_mem: 6513M
[12/11 00:56:11 d2.utils.events]:  eta: 0:28:27  iter: 3739  total_loss: 2.975  loss_sem_seg: 1.388  loss_center: 0.7643  loss_offset: 0.8195  time: 0.2733  data_time: 0.0284  lr: 0.0016403  max_mem: 6513M
[12/11 00:56:16 d2.utils.events]:  eta: 0:28:23  iter: 3759  total_loss: 2.97  loss_sem_seg: 1.323  loss_center: 0.5209  loss_offset: 0.946  time: 0.2733  data_time: 0.0267  lr: 0.0016356  max_mem: 6513M
[12/11 00:56:22 d2.utils.events]:  eta: 0:28:18  iter: 3779  total_loss: 3.026  loss_sem_seg: 1.42  loss_center: 0.6357  loss_offset: 0.9174  time: 0.2733  data_time: 0.0283  lr: 0.0016309  max_mem: 6513M
[12/11 00:56:27 d2.utils.events]:  eta: 0:28:10  iter: 3799  total_loss: 2.866  loss_sem_seg: 1.213  loss_center: 0.548  loss_offset: 0.831  time: 0.2733  data_time: 0.0255  lr: 0.0016261  max_mem: 6513M
[12/11 00:56:33 d2.utils.events]:  eta: 0:28:07  iter: 3819  total_loss: 2.827  loss_sem_seg: 1.325  loss_center: 0.549  loss_offset: 0.7784  time: 0.2733  data_time: 0.0270  lr: 0.0016214  max_mem: 6513M
[12/11 00:56:38 d2.utils.events]:  eta: 0:28:00  iter: 3839  total_loss: 2.715  loss_sem_seg: 1.2  loss_center: 0.6856  loss_offset: 0.8273  time: 0.2733  data_time: 0.0266  lr: 0.0016167  max_mem: 6513M
[12/11 00:56:44 d2.utils.events]:  eta: 0:27:55  iter: 3859  total_loss: 2.999  loss_sem_seg: 1.513  loss_center: 0.6006  loss_offset: 0.8716  time: 0.2733  data_time: 0.0282  lr: 0.001612  max_mem: 6513M
[12/11 00:56:49 d2.utils.events]:  eta: 0:27:49  iter: 3879  total_loss: 3.089  loss_sem_seg: 1.606  loss_center: 0.6879  loss_offset: 0.8905  time: 0.2733  data_time: 0.0279  lr: 0.0016072  max_mem: 6513M
[12/11 00:56:55 d2.utils.events]:  eta: 0:27:46  iter: 3899  total_loss: 2.945  loss_sem_seg: 1.351  loss_center: 0.6145  loss_offset: 0.8259  time: 0.2733  data_time: 0.0297  lr: 0.0016025  max_mem: 6513M
[12/11 00:57:00 d2.utils.events]:  eta: 0:27:40  iter: 3919  total_loss: 3.164  loss_sem_seg: 1.542  loss_center: 0.6366  loss_offset: 0.833  time: 0.2733  data_time: 0.0260  lr: 0.0015978  max_mem: 6513M
[12/11 00:57:06 d2.utils.events]:  eta: 0:27:33  iter: 3939  total_loss: 3.048  loss_sem_seg: 1.515  loss_center: 0.5904  loss_offset: 0.9453  time: 0.2733  data_time: 0.0284  lr: 0.0015931  max_mem: 6513M
[12/11 00:57:11 d2.utils.events]:  eta: 0:27:29  iter: 3959  total_loss: 3.456  loss_sem_seg: 1.512  loss_center: 0.831  loss_offset: 0.9294  time: 0.2733  data_time: 0.0260  lr: 0.0015883  max_mem: 6513M
[12/11 00:57:17 d2.utils.events]:  eta: 0:27:22  iter: 3979  total_loss: 2.887  loss_sem_seg: 1.455  loss_center: 0.611  loss_offset: 0.8765  time: 0.2733  data_time: 0.0278  lr: 0.0015836  max_mem: 6513M
[12/11 00:57:22 d2.utils.events]:  eta: 0:27:17  iter: 3999  total_loss: 3.196  loss_sem_seg: 1.561  loss_center: 0.7239  loss_offset: 0.8819  time: 0.2733  data_time: 0.0264  lr: 0.0015789  max_mem: 6513M
[12/11 00:57:27 d2.utils.events]:  eta: 0:27:10  iter: 4019  total_loss: 3.089  loss_sem_seg: 1.324  loss_center: 0.6201  loss_offset: 0.8051  time: 0.2733  data_time: 0.0274  lr: 0.0015741  max_mem: 6513M
[12/11 00:57:33 d2.utils.events]:  eta: 0:27:05  iter: 4039  total_loss: 2.869  loss_sem_seg: 1.286  loss_center: 0.6627  loss_offset: 0.8706  time: 0.2733  data_time: 0.0274  lr: 0.0015694  max_mem: 6513M
[12/11 00:57:38 d2.utils.events]:  eta: 0:26:59  iter: 4059  total_loss: 3.337  loss_sem_seg: 1.586  loss_center: 0.6779  loss_offset: 0.9454  time: 0.2733  data_time: 0.0266  lr: 0.0015646  max_mem: 6513M
[12/11 00:57:44 d2.utils.events]:  eta: 0:26:54  iter: 4079  total_loss: 3.042  loss_sem_seg: 1.464  loss_center: 0.6738  loss_offset: 0.8985  time: 0.2733  data_time: 0.0274  lr: 0.0015599  max_mem: 6513M
[12/11 00:57:49 d2.utils.events]:  eta: 0:26:48  iter: 4099  total_loss: 2.917  loss_sem_seg: 1.435  loss_center: 0.5603  loss_offset: 0.8786  time: 0.2733  data_time: 0.0276  lr: 0.0015552  max_mem: 6513M
[12/11 00:57:55 d2.utils.events]:  eta: 0:26:42  iter: 4119  total_loss: 2.793  loss_sem_seg: 1.296  loss_center: 0.6197  loss_offset: 0.852  time: 0.2733  data_time: 0.0269  lr: 0.0015504  max_mem: 6513M
[12/11 00:58:00 d2.utils.events]:  eta: 0:26:37  iter: 4139  total_loss: 3.005  loss_sem_seg: 1.3  loss_center: 0.7203  loss_offset: 0.8355  time: 0.2733  data_time: 0.0288  lr: 0.0015457  max_mem: 6513M
[12/11 00:58:06 d2.utils.events]:  eta: 0:26:32  iter: 4159  total_loss: 3  loss_sem_seg: 1.417  loss_center: 0.5765  loss_offset: 0.8662  time: 0.2733  data_time: 0.0257  lr: 0.0015409  max_mem: 6513M
[12/11 00:58:11 d2.utils.events]:  eta: 0:26:25  iter: 4179  total_loss: 3.148  loss_sem_seg: 1.376  loss_center: 0.7461  loss_offset: 0.8281  time: 0.2733  data_time: 0.0285  lr: 0.0015362  max_mem: 6513M
[12/11 00:58:17 d2.utils.events]:  eta: 0:26:20  iter: 4199  total_loss: 2.828  loss_sem_seg: 1.311  loss_center: 0.6152  loss_offset: 0.7847  time: 0.2733  data_time: 0.0303  lr: 0.0015314  max_mem: 6513M
[12/11 00:58:22 d2.utils.events]:  eta: 0:26:14  iter: 4219  total_loss: 3.148  loss_sem_seg: 1.444  loss_center: 0.6179  loss_offset: 0.8574  time: 0.2733  data_time: 0.0262  lr: 0.0015267  max_mem: 6513M
[12/11 00:58:28 d2.utils.events]:  eta: 0:26:09  iter: 4239  total_loss: 2.622  loss_sem_seg: 1.401  loss_center: 0.5318  loss_offset: 0.7973  time: 0.2733  data_time: 0.0259  lr: 0.0015219  max_mem: 6513M
[12/11 00:58:33 d2.utils.events]:  eta: 0:26:03  iter: 4259  total_loss: 2.817  loss_sem_seg: 1.312  loss_center: 0.587  loss_offset: 0.8441  time: 0.2733  data_time: 0.0268  lr: 0.0015172  max_mem: 6513M
[12/11 00:58:39 d2.utils.events]:  eta: 0:25:58  iter: 4279  total_loss: 3.16  loss_sem_seg: 1.431  loss_center: 0.684  loss_offset: 0.8215  time: 0.2733  data_time: 0.0283  lr: 0.0015124  max_mem: 6513M
[12/11 00:58:44 d2.utils.events]:  eta: 0:25:53  iter: 4299  total_loss: 2.987  loss_sem_seg: 1.396  loss_center: 0.5135  loss_offset: 0.9251  time: 0.2733  data_time: 0.0281  lr: 0.0015076  max_mem: 6513M
[12/11 00:58:50 d2.utils.events]:  eta: 0:25:48  iter: 4319  total_loss: 2.969  loss_sem_seg: 1.445  loss_center: 0.6226  loss_offset: 0.855  time: 0.2733  data_time: 0.0262  lr: 0.0015029  max_mem: 6513M
[12/11 00:58:55 d2.utils.events]:  eta: 0:25:43  iter: 4339  total_loss: 2.933  loss_sem_seg: 1.384  loss_center: 0.6647  loss_offset: 0.8257  time: 0.2733  data_time: 0.0266  lr: 0.0014981  max_mem: 6513M
[12/11 00:59:01 d2.utils.events]:  eta: 0:25:38  iter: 4359  total_loss: 3.119  loss_sem_seg: 1.549  loss_center: 0.5072  loss_offset: 0.9163  time: 0.2733  data_time: 0.0287  lr: 0.0014933  max_mem: 6513M
[12/11 00:59:06 d2.utils.events]:  eta: 0:25:33  iter: 4379  total_loss: 3.196  loss_sem_seg: 1.545  loss_center: 0.7026  loss_offset: 0.944  time: 0.2733  data_time: 0.0287  lr: 0.0014886  max_mem: 6513M
[12/11 00:59:12 d2.utils.events]:  eta: 0:25:27  iter: 4399  total_loss: 3.045  loss_sem_seg: 1.369  loss_center: 0.6478  loss_offset: 0.8568  time: 0.2733  data_time: 0.0277  lr: 0.0014838  max_mem: 6513M
[12/11 00:59:17 d2.utils.events]:  eta: 0:25:23  iter: 4419  total_loss: 3.27  loss_sem_seg: 1.501  loss_center: 0.725  loss_offset: 0.9465  time: 0.2733  data_time: 0.0278  lr: 0.001479  max_mem: 6513M
[12/11 00:59:23 d2.utils.events]:  eta: 0:25:18  iter: 4439  total_loss: 2.826  loss_sem_seg: 1.416  loss_center: 0.6242  loss_offset: 0.8325  time: 0.2733  data_time: 0.0290  lr: 0.0014743  max_mem: 6513M
[12/11 00:59:28 d2.utils.events]:  eta: 0:25:12  iter: 4459  total_loss: 2.965  loss_sem_seg: 1.45  loss_center: 0.6681  loss_offset: 0.8515  time: 0.2733  data_time: 0.0276  lr: 0.0014695  max_mem: 6513M
[12/11 00:59:34 d2.utils.events]:  eta: 0:25:06  iter: 4479  total_loss: 3.178  loss_sem_seg: 1.42  loss_center: 0.6182  loss_offset: 0.91  time: 0.2733  data_time: 0.0268  lr: 0.0014647  max_mem: 6513M
[12/11 00:59:39 d2.utils.events]:  eta: 0:25:01  iter: 4499  total_loss: 3.143  loss_sem_seg: 1.653  loss_center: 0.5744  loss_offset: 0.9345  time: 0.2733  data_time: 0.0292  lr: 0.0014599  max_mem: 6513M
[12/11 00:59:45 d2.utils.events]:  eta: 0:24:56  iter: 4519  total_loss: 2.923  loss_sem_seg: 1.387  loss_center: 0.6575  loss_offset: 0.9296  time: 0.2733  data_time: 0.0290  lr: 0.0014552  max_mem: 6513M
[12/11 00:59:50 d2.utils.events]:  eta: 0:24:51  iter: 4539  total_loss: 2.727  loss_sem_seg: 1.271  loss_center: 0.5145  loss_offset: 0.8017  time: 0.2733  data_time: 0.0282  lr: 0.0014504  max_mem: 6513M
[12/11 00:59:56 d2.utils.events]:  eta: 0:24:45  iter: 4559  total_loss: 2.766  loss_sem_seg: 1.351  loss_center: 0.6501  loss_offset: 0.8094  time: 0.2733  data_time: 0.0279  lr: 0.0014456  max_mem: 6513M
[12/11 01:00:01 d2.utils.events]:  eta: 0:24:40  iter: 4579  total_loss: 2.719  loss_sem_seg: 1.214  loss_center: 0.7056  loss_offset: 0.7318  time: 0.2733  data_time: 0.0281  lr: 0.0014408  max_mem: 6513M
[12/11 01:00:06 d2.utils.events]:  eta: 0:24:34  iter: 4599  total_loss: 2.985  loss_sem_seg: 1.348  loss_center: 0.7189  loss_offset: 0.7744  time: 0.2733  data_time: 0.0271  lr: 0.001436  max_mem: 6513M
[12/11 01:00:12 d2.utils.events]:  eta: 0:24:28  iter: 4619  total_loss: 2.758  loss_sem_seg: 1.066  loss_center: 0.721  loss_offset: 0.9012  time: 0.2733  data_time: 0.0252  lr: 0.0014313  max_mem: 6513M
[12/11 01:00:17 d2.utils.events]:  eta: 0:24:21  iter: 4639  total_loss: 3.114  loss_sem_seg: 1.56  loss_center: 0.639  loss_offset: 0.854  time: 0.2733  data_time: 0.0272  lr: 0.0014265  max_mem: 6513M
[12/11 01:00:23 d2.utils.events]:  eta: 0:24:16  iter: 4659  total_loss: 3.112  loss_sem_seg: 1.212  loss_center: 0.734  loss_offset: 0.8753  time: 0.2733  data_time: 0.0265  lr: 0.0014217  max_mem: 6513M
[12/11 01:00:28 d2.utils.events]:  eta: 0:24:10  iter: 4679  total_loss: 3.093  loss_sem_seg: 1.379  loss_center: 0.659  loss_offset: 0.8754  time: 0.2733  data_time: 0.0273  lr: 0.0014169  max_mem: 6513M
[12/11 01:00:34 d2.utils.events]:  eta: 0:24:05  iter: 4699  total_loss: 2.821  loss_sem_seg: 1.311  loss_center: 0.5758  loss_offset: 0.852  time: 0.2733  data_time: 0.0261  lr: 0.0014121  max_mem: 6513M
[12/11 01:00:39 d2.utils.events]:  eta: 0:23:59  iter: 4719  total_loss: 2.904  loss_sem_seg: 1.356  loss_center: 0.579  loss_offset: 0.9021  time: 0.2733  data_time: 0.0270  lr: 0.0014073  max_mem: 6513M
[12/11 01:00:45 d2.utils.events]:  eta: 0:23:54  iter: 4739  total_loss: 3.136  loss_sem_seg: 1.473  loss_center: 0.6954  loss_offset: 0.8889  time: 0.2733  data_time: 0.0276  lr: 0.0014025  max_mem: 6513M
[12/11 01:00:50 d2.utils.events]:  eta: 0:23:49  iter: 4759  total_loss: 2.955  loss_sem_seg: 1.297  loss_center: 0.672  loss_offset: 0.7765  time: 0.2733  data_time: 0.0279  lr: 0.0013977  max_mem: 6513M
[12/11 01:00:56 d2.utils.events]:  eta: 0:23:43  iter: 4779  total_loss: 2.983  loss_sem_seg: 1.225  loss_center: 0.7442  loss_offset: 0.8629  time: 0.2733  data_time: 0.0278  lr: 0.0013929  max_mem: 6513M
[12/11 01:01:01 d2.utils.events]:  eta: 0:23:38  iter: 4799  total_loss: 2.739  loss_sem_seg: 1.293  loss_center: 0.5035  loss_offset: 0.8526  time: 0.2733  data_time: 0.0295  lr: 0.0013881  max_mem: 6513M
[12/11 01:01:07 d2.utils.events]:  eta: 0:23:32  iter: 4819  total_loss: 2.904  loss_sem_seg: 1.327  loss_center: 0.6067  loss_offset: 0.7966  time: 0.2733  data_time: 0.0266  lr: 0.0013833  max_mem: 6513M
[12/11 01:01:12 d2.utils.events]:  eta: 0:23:27  iter: 4839  total_loss: 3.215  loss_sem_seg: 1.377  loss_center: 0.6848  loss_offset: 0.8996  time: 0.2733  data_time: 0.0279  lr: 0.0013785  max_mem: 6513M
[12/11 01:01:18 d2.utils.events]:  eta: 0:23:21  iter: 4859  total_loss: 2.954  loss_sem_seg: 1.374  loss_center: 0.6716  loss_offset: 0.81  time: 0.2733  data_time: 0.0281  lr: 0.0013737  max_mem: 6513M
[12/11 01:01:23 d2.utils.events]:  eta: 0:23:16  iter: 4879  total_loss: 3.255  loss_sem_seg: 1.525  loss_center: 0.8163  loss_offset: 0.8607  time: 0.2733  data_time: 0.0268  lr: 0.0013689  max_mem: 6513M
[12/11 01:01:29 d2.utils.events]:  eta: 0:23:10  iter: 4899  total_loss: 3.208  loss_sem_seg: 1.766  loss_center: 0.538  loss_offset: 0.8148  time: 0.2733  data_time: 0.0280  lr: 0.001364  max_mem: 6513M
[12/11 01:01:34 d2.utils.events]:  eta: 0:23:05  iter: 4919  total_loss: 3.086  loss_sem_seg: 1.458  loss_center: 0.6599  loss_offset: 0.8924  time: 0.2733  data_time: 0.0275  lr: 0.0013592  max_mem: 6513M
[12/11 01:01:39 d2.utils.events]:  eta: 0:22:59  iter: 4939  total_loss: 2.955  loss_sem_seg: 1.483  loss_center: 0.5898  loss_offset: 0.9122  time: 0.2733  data_time: 0.0277  lr: 0.0013544  max_mem: 6513M
[12/11 01:01:45 d2.utils.events]:  eta: 0:22:54  iter: 4959  total_loss: 3.114  loss_sem_seg: 1.618  loss_center: 0.4932  loss_offset: 0.9245  time: 0.2733  data_time: 0.0281  lr: 0.0013496  max_mem: 6513M
[12/11 01:01:50 d2.utils.events]:  eta: 0:22:49  iter: 4979  total_loss: 2.919  loss_sem_seg: 1.271  loss_center: 0.5965  loss_offset: 0.9216  time: 0.2733  data_time: 0.0283  lr: 0.0013448  max_mem: 6513M
[12/11 01:01:56 fvcore.common.checkpoint]: Saving checkpoint to ./output/model_0004999.pth
[12/11 01:01:56 d2.utils.events]:  eta: 0:22:44  iter: 4999  total_loss: 2.72  loss_sem_seg: 1.121  loss_center: 0.6421  loss_offset: 0.7952  time: 0.2733  data_time: 0.0293  lr: 0.00134  max_mem: 6513M
[12/11 01:02:02 d2.utils.events]:  eta: 0:22:39  iter: 5019  total_loss: 2.667  loss_sem_seg: 1.291  loss_center: 0.6789  loss_offset: 0.7225  time: 0.2733  data_time: 0.0292  lr: 0.0013351  max_mem: 6513M
[12/11 01:02:08 d2.utils.events]:  eta: 0:22:33  iter: 5039  total_loss: 3.065  loss_sem_seg: 1.495  loss_center: 0.6438  loss_offset: 0.9326  time: 0.2733  data_time: 0.0271  lr: 0.0013303  max_mem: 6513M
[12/11 01:02:13 d2.utils.events]:  eta: 0:22:28  iter: 5059  total_loss: 2.966  loss_sem_seg: 1.422  loss_center: 0.5888  loss_offset: 0.8248  time: 0.2733  data_time: 0.0280  lr: 0.0013255  max_mem: 6513M
[12/11 01:02:19 d2.utils.events]:  eta: 0:22:23  iter: 5079  total_loss: 2.857  loss_sem_seg: 1.221  loss_center: 0.6905  loss_offset: 0.8173  time: 0.2733  data_time: 0.0271  lr: 0.0013207  max_mem: 6513M
[12/11 01:02:24 d2.utils.events]:  eta: 0:22:18  iter: 5099  total_loss: 2.843  loss_sem_seg: 1.382  loss_center: 0.5952  loss_offset: 0.8528  time: 0.2733  data_time: 0.0286  lr: 0.0013158  max_mem: 6513M
[12/11 01:02:30 d2.utils.events]:  eta: 0:22:13  iter: 5119  total_loss: 2.917  loss_sem_seg: 1.386  loss_center: 0.6155  loss_offset: 0.873  time: 0.2734  data_time: 0.0269  lr: 0.001311  max_mem: 6513M
[12/11 01:02:35 d2.utils.events]:  eta: 0:22:08  iter: 5139  total_loss: 3.055  loss_sem_seg: 1.359  loss_center: 0.6795  loss_offset: 0.8489  time: 0.2734  data_time: 0.0258  lr: 0.0013062  max_mem: 6513M
[12/11 01:02:41 d2.utils.events]:  eta: 0:22:02  iter: 5159  total_loss: 2.873  loss_sem_seg: 1.31  loss_center: 0.7187  loss_offset: 0.9152  time: 0.2733  data_time: 0.0250  lr: 0.0013013  max_mem: 6513M
[12/11 01:02:46 d2.utils.events]:  eta: 0:21:57  iter: 5179  total_loss: 2.86  loss_sem_seg: 1.206  loss_center: 0.7025  loss_offset: 0.8653  time: 0.2733  data_time: 0.0270  lr: 0.0012965  max_mem: 6513M
[12/11 01:02:52 d2.utils.events]:  eta: 0:21:51  iter: 5199  total_loss: 3.003  loss_sem_seg: 1.457  loss_center: 0.6412  loss_offset: 0.9058  time: 0.2733  data_time: 0.0256  lr: 0.0012916  max_mem: 6513M
[12/11 01:02:57 d2.utils.events]:  eta: 0:21:46  iter: 5219  total_loss: 2.772  loss_sem_seg: 1.388  loss_center: 0.486  loss_offset: 0.8773  time: 0.2733  data_time: 0.0283  lr: 0.0012868  max_mem: 6513M
[12/11 01:03:03 d2.utils.events]:  eta: 0:21:40  iter: 5239  total_loss: 3.034  loss_sem_seg: 1.323  loss_center: 0.6779  loss_offset: 0.8479  time: 0.2733  data_time: 0.0266  lr: 0.0012819  max_mem: 6513M
[12/11 01:03:08 d2.utils.events]:  eta: 0:21:35  iter: 5259  total_loss: 2.745  loss_sem_seg: 1.25  loss_center: 0.6264  loss_offset: 0.8598  time: 0.2733  data_time: 0.0264  lr: 0.0012771  max_mem: 6513M
[12/11 01:03:14 d2.utils.events]:  eta: 0:21:30  iter: 5279  total_loss: 2.768  loss_sem_seg: 1.37  loss_center: 0.5323  loss_offset: 0.7876  time: 0.2733  data_time: 0.0291  lr: 0.0012722  max_mem: 6513M
[12/11 01:03:19 d2.utils.events]:  eta: 0:21:24  iter: 5299  total_loss: 2.75  loss_sem_seg: 1.233  loss_center: 0.5901  loss_offset: 0.8654  time: 0.2733  data_time: 0.0262  lr: 0.0012674  max_mem: 6513M
[12/11 01:03:24 d2.utils.events]:  eta: 0:21:18  iter: 5319  total_loss: 2.984  loss_sem_seg: 1.392  loss_center: 0.7017  loss_offset: 0.8492  time: 0.2733  data_time: 0.0270  lr: 0.0012625  max_mem: 6513M
[12/11 01:03:30 d2.utils.events]:  eta: 0:21:13  iter: 5339  total_loss: 3.344  loss_sem_seg: 1.452  loss_center: 0.7788  loss_offset: 0.8525  time: 0.2733  data_time: 0.0272  lr: 0.0012577  max_mem: 6513M
[12/11 01:03:35 d2.utils.events]:  eta: 0:21:07  iter: 5359  total_loss: 3.027  loss_sem_seg: 1.436  loss_center: 0.5925  loss_offset: 0.8123  time: 0.2733  data_time: 0.0269  lr: 0.0012528  max_mem: 6513M
[12/11 01:03:41 d2.utils.events]:  eta: 0:21:02  iter: 5379  total_loss: 2.922  loss_sem_seg: 1.236  loss_center: 0.7095  loss_offset: 0.8839  time: 0.2733  data_time: 0.0277  lr: 0.001248  max_mem: 6513M
[12/11 01:03:46 d2.utils.events]:  eta: 0:20:56  iter: 5399  total_loss: 2.974  loss_sem_seg: 1.33  loss_center: 0.6066  loss_offset: 0.9512  time: 0.2733  data_time: 0.0291  lr: 0.0012431  max_mem: 6513M
[12/11 01:03:52 d2.utils.events]:  eta: 0:20:51  iter: 5419  total_loss: 2.877  loss_sem_seg: 1.244  loss_center: 0.7373  loss_offset: 0.8986  time: 0.2733  data_time: 0.0277  lr: 0.0012382  max_mem: 6513M
[12/11 01:03:57 d2.utils.events]:  eta: 0:20:45  iter: 5439  total_loss: 2.732  loss_sem_seg: 1.198  loss_center: 0.7931  loss_offset: 0.8299  time: 0.2733  data_time: 0.0256  lr: 0.0012334  max_mem: 6513M
[12/11 01:04:03 d2.utils.events]:  eta: 0:20:40  iter: 5459  total_loss: 2.814  loss_sem_seg: 1.513  loss_center: 0.6513  loss_offset: 0.8554  time: 0.2733  data_time: 0.0299  lr: 0.0012285  max_mem: 6513M
[12/11 01:04:08 d2.utils.events]:  eta: 0:20:34  iter: 5479  total_loss: 2.765  loss_sem_seg: 1.181  loss_center: 0.6103  loss_offset: 0.6676  time: 0.2733  data_time: 0.0269  lr: 0.0012236  max_mem: 6513M
[12/11 01:04:14 d2.utils.events]:  eta: 0:20:28  iter: 5499  total_loss: 2.879  loss_sem_seg: 1.353  loss_center: 0.4661  loss_offset: 0.9308  time: 0.2733  data_time: 0.0278  lr: 0.0012188  max_mem: 6513M
[12/11 01:04:19 d2.utils.events]:  eta: 0:20:22  iter: 5519  total_loss: 2.87  loss_sem_seg: 1.534  loss_center: 0.6749  loss_offset: 0.7685  time: 0.2734  data_time: 0.0287  lr: 0.0012139  max_mem: 6513M
[12/11 01:04:25 d2.utils.events]:  eta: 0:20:17  iter: 5539  total_loss: 3.146  loss_sem_seg: 1.366  loss_center: 0.6293  loss_offset: 0.8421  time: 0.2734  data_time: 0.0272  lr: 0.001209  max_mem: 6513M
[12/11 01:04:30 d2.utils.events]:  eta: 0:20:12  iter: 5559  total_loss: 2.88  loss_sem_seg: 1.307  loss_center: 0.5359  loss_offset: 0.9179  time: 0.2734  data_time: 0.0282  lr: 0.0012041  max_mem: 6513M
[12/11 01:04:36 d2.utils.events]:  eta: 0:20:06  iter: 5579  total_loss: 2.939  loss_sem_seg: 1.344  loss_center: 0.6188  loss_offset: 0.7642  time: 0.2734  data_time: 0.0269  lr: 0.0011992  max_mem: 6513M
[12/11 01:04:41 d2.utils.events]:  eta: 0:20:01  iter: 5599  total_loss: 3.063  loss_sem_seg: 1.294  loss_center: 0.6393  loss_offset: 0.8746  time: 0.2734  data_time: 0.0279  lr: 0.0011944  max_mem: 6513M
[12/11 01:04:47 d2.utils.events]:  eta: 0:19:56  iter: 5619  total_loss: 2.654  loss_sem_seg: 1.172  loss_center: 0.7091  loss_offset: 0.8096  time: 0.2734  data_time: 0.0263  lr: 0.0011895  max_mem: 6513M
[12/11 01:04:52 d2.utils.events]:  eta: 0:19:51  iter: 5639  total_loss: 2.887  loss_sem_seg: 1.443  loss_center: 0.7166  loss_offset: 0.8184  time: 0.2734  data_time: 0.0275  lr: 0.0011846  max_mem: 6513M
[12/11 01:04:58 d2.utils.events]:  eta: 0:19:45  iter: 5659  total_loss: 2.999  loss_sem_seg: 1.312  loss_center: 0.6986  loss_offset: 0.9521  time: 0.2733  data_time: 0.0272  lr: 0.0011797  max_mem: 6513M
[12/11 01:05:03 d2.utils.events]:  eta: 0:19:40  iter: 5679  total_loss: 2.776  loss_sem_seg: 1.24  loss_center: 0.6061  loss_offset: 0.8831  time: 0.2734  data_time: 0.0267  lr: 0.0011748  max_mem: 6513M
[12/11 01:05:09 d2.utils.events]:  eta: 0:19:35  iter: 5699  total_loss: 2.765  loss_sem_seg: 1.239  loss_center: 0.5974  loss_offset: 0.9127  time: 0.2734  data_time: 0.0299  lr: 0.0011699  max_mem: 6513M
[12/11 01:05:14 d2.utils.events]:  eta: 0:19:30  iter: 5719  total_loss: 2.991  loss_sem_seg: 1.349  loss_center: 0.6725  loss_offset: 0.8429  time: 0.2734  data_time: 0.0280  lr: 0.001165  max_mem: 6513M
[12/11 01:05:20 d2.utils.events]:  eta: 0:19:25  iter: 5739  total_loss: 2.547  loss_sem_seg: 1.131  loss_center: 0.5957  loss_offset: 0.8168  time: 0.2734  data_time: 0.0267  lr: 0.0011601  max_mem: 6513M
[12/11 01:05:25 d2.utils.events]:  eta: 0:19:18  iter: 5759  total_loss: 2.779  loss_sem_seg: 1.287  loss_center: 0.644  loss_offset: 0.8458  time: 0.2734  data_time: 0.0269  lr: 0.0011552  max_mem: 6513M
[12/11 01:05:31 d2.utils.events]:  eta: 0:19:13  iter: 5779  total_loss: 2.962  loss_sem_seg: 1.446  loss_center: 0.7406  loss_offset: 0.8201  time: 0.2734  data_time: 0.0270  lr: 0.0011503  max_mem: 6513M
[12/11 01:05:36 d2.utils.events]:  eta: 0:19:08  iter: 5799  total_loss: 2.777  loss_sem_seg: 1.328  loss_center: 0.6054  loss_offset: 0.7795  time: 0.2734  data_time: 0.0278  lr: 0.0011454  max_mem: 6513M
[12/11 01:05:42 d2.utils.events]:  eta: 0:19:02  iter: 5819  total_loss: 2.912  loss_sem_seg: 1.311  loss_center: 0.7916  loss_offset: 0.8397  time: 0.2734  data_time: 0.0273  lr: 0.0011405  max_mem: 6513M
[12/11 01:05:47 d2.utils.events]:  eta: 0:18:56  iter: 5839  total_loss: 2.827  loss_sem_seg: 1.234  loss_center: 0.6362  loss_offset: 0.8748  time: 0.2734  data_time: 0.0261  lr: 0.0011356  max_mem: 6513M
[12/11 01:05:53 d2.utils.events]:  eta: 0:18:51  iter: 5859  total_loss: 2.634  loss_sem_seg: 1.166  loss_center: 0.5453  loss_offset: 0.8003  time: 0.2734  data_time: 0.0300  lr: 0.0011307  max_mem: 6513M
[12/11 01:05:58 d2.utils.events]:  eta: 0:18:45  iter: 5879  total_loss: 2.606  loss_sem_seg: 1.073  loss_center: 0.5907  loss_offset: 0.7504  time: 0.2734  data_time: 0.0265  lr: 0.0011258  max_mem: 6513M
[12/11 01:06:03 d2.utils.events]:  eta: 0:18:40  iter: 5899  total_loss: 2.719  loss_sem_seg: 1.216  loss_center: 0.5774  loss_offset: 0.8012  time: 0.2734  data_time: 0.0269  lr: 0.0011208  max_mem: 6513M
[12/11 01:06:09 d2.utils.events]:  eta: 0:18:34  iter: 5919  total_loss: 2.604  loss_sem_seg: 1.181  loss_center: 0.5171  loss_offset: 0.8502  time: 0.2734  data_time: 0.0276  lr: 0.0011159  max_mem: 6513M
[12/11 01:06:14 d2.utils.events]:  eta: 0:18:28  iter: 5939  total_loss: 2.603  loss_sem_seg: 1.157  loss_center: 0.5673  loss_offset: 0.8637  time: 0.2734  data_time: 0.0274  lr: 0.001111  max_mem: 6513M
[12/11 01:06:20 d2.utils.events]:  eta: 0:18:22  iter: 5959  total_loss: 2.753  loss_sem_seg: 1.182  loss_center: 0.7157  loss_offset: 0.8  time: 0.2734  data_time: 0.0284  lr: 0.0011061  max_mem: 6513M
[12/11 01:06:25 d2.utils.events]:  eta: 0:18:16  iter: 5979  total_loss: 3.015  loss_sem_seg: 1.297  loss_center: 0.7349  loss_offset: 0.8094  time: 0.2734  data_time: 0.0272  lr: 0.0011011  max_mem: 6513M
[12/11 01:06:31 d2.utils.events]:  eta: 0:18:10  iter: 5999  total_loss: 2.828  loss_sem_seg: 1.334  loss_center: 0.6222  loss_offset: 0.9262  time: 0.2734  data_time: 0.0281  lr: 0.0010962  max_mem: 6513M
[12/11 01:06:36 d2.utils.events]:  eta: 0:18:05  iter: 6019  total_loss: 2.631  loss_sem_seg: 1.111  loss_center: 0.8033  loss_offset: 0.8177  time: 0.2734  data_time: 0.0268  lr: 0.0010913  max_mem: 6513M
[12/11 01:06:42 d2.utils.events]:  eta: 0:17:59  iter: 6039  total_loss: 2.496  loss_sem_seg: 1.086  loss_center: 0.4865  loss_offset: 0.7866  time: 0.2734  data_time: 0.0275  lr: 0.0010863  max_mem: 6513M
[12/11 01:06:47 d2.utils.events]:  eta: 0:17:55  iter: 6059  total_loss: 2.805  loss_sem_seg: 1.426  loss_center: 0.6688  loss_offset: 0.7724  time: 0.2734  data_time: 0.0286  lr: 0.0010814  max_mem: 6513M
[12/11 01:06:53 d2.utils.events]:  eta: 0:17:49  iter: 6079  total_loss: 2.777  loss_sem_seg: 1.217  loss_center: 0.4527  loss_offset: 0.8179  time: 0.2734  data_time: 0.0280  lr: 0.0010765  max_mem: 6513M
[12/11 01:06:58 d2.utils.events]:  eta: 0:17:44  iter: 6099  total_loss: 2.888  loss_sem_seg: 1.484  loss_center: 0.4539  loss_offset: 0.802  time: 0.2734  data_time: 0.0272  lr: 0.0010715  max_mem: 6513M
[12/11 01:07:04 d2.utils.events]:  eta: 0:17:39  iter: 6119  total_loss: 2.536  loss_sem_seg: 1.154  loss_center: 0.5883  loss_offset: 0.8874  time: 0.2734  data_time: 0.0290  lr: 0.0010666  max_mem: 6513M
[12/11 01:07:09 d2.utils.events]:  eta: 0:17:33  iter: 6139  total_loss: 2.864  loss_sem_seg: 1.25  loss_center: 0.5606  loss_offset: 0.8667  time: 0.2734  data_time: 0.0262  lr: 0.0010616  max_mem: 6513M
[12/11 01:07:15 d2.utils.events]:  eta: 0:17:27  iter: 6159  total_loss: 2.842  loss_sem_seg: 1.43  loss_center: 0.6101  loss_offset: 0.8528  time: 0.2734  data_time: 0.0280  lr: 0.0010567  max_mem: 6513M
[12/11 01:07:20 d2.utils.events]:  eta: 0:17:22  iter: 6179  total_loss: 2.778  loss_sem_seg: 1.387  loss_center: 0.7025  loss_offset: 0.795  time: 0.2734  data_time: 0.0268  lr: 0.0010517  max_mem: 6513M
[12/11 01:07:26 d2.utils.events]:  eta: 0:17:17  iter: 6199  total_loss: 2.913  loss_sem_seg: 1.335  loss_center: 0.6415  loss_offset: 0.8457  time: 0.2734  data_time: 0.0280  lr: 0.0010468  max_mem: 6513M
[12/11 01:07:31 d2.utils.events]:  eta: 0:17:11  iter: 6219  total_loss: 2.769  loss_sem_seg: 1.063  loss_center: 0.638  loss_offset: 0.8173  time: 0.2734  data_time: 0.0265  lr: 0.0010418  max_mem: 6513M
[12/11 01:07:37 d2.utils.events]:  eta: 0:17:05  iter: 6239  total_loss: 2.569  loss_sem_seg: 1.121  loss_center: 0.6552  loss_offset: 0.7491  time: 0.2734  data_time: 0.0265  lr: 0.0010368  max_mem: 6513M
[12/11 01:07:42 d2.utils.events]:  eta: 0:16:59  iter: 6259  total_loss: 2.693  loss_sem_seg: 1.213  loss_center: 0.5921  loss_offset: 0.7533  time: 0.2734  data_time: 0.0280  lr: 0.0010319  max_mem: 6513M
[12/11 01:07:48 d2.utils.events]:  eta: 0:16:54  iter: 6279  total_loss: 2.821  loss_sem_seg: 1.238  loss_center: 0.6877  loss_offset: 0.7424  time: 0.2734  data_time: 0.0280  lr: 0.0010269  max_mem: 6513M
[12/11 01:07:53 d2.utils.events]:  eta: 0:16:49  iter: 6299  total_loss: 2.81  loss_sem_seg: 1.303  loss_center: 0.5597  loss_offset: 0.8567  time: 0.2734  data_time: 0.0268  lr: 0.0010219  max_mem: 6513M
[12/11 01:07:59 d2.utils.events]:  eta: 0:16:43  iter: 6319  total_loss: 2.822  loss_sem_seg: 1.353  loss_center: 0.6455  loss_offset: 0.8331  time: 0.2734  data_time: 0.0272  lr: 0.001017  max_mem: 6513M
[12/11 01:08:04 d2.utils.events]:  eta: 0:16:38  iter: 6339  total_loss: 3.068  loss_sem_seg: 1.27  loss_center: 0.6051  loss_offset: 0.963  time: 0.2734  data_time: 0.0280  lr: 0.001012  max_mem: 6513M
[12/11 01:08:10 d2.utils.events]:  eta: 0:16:33  iter: 6359  total_loss: 2.969  loss_sem_seg: 1.24  loss_center: 0.6676  loss_offset: 0.8412  time: 0.2734  data_time: 0.0286  lr: 0.001007  max_mem: 6513M
[12/11 01:08:15 d2.utils.events]:  eta: 0:16:27  iter: 6379  total_loss: 2.784  loss_sem_seg: 1.356  loss_center: 0.5588  loss_offset: 0.7634  time: 0.2734  data_time: 0.0306  lr: 0.001002  max_mem: 6513M
[12/11 01:08:21 d2.utils.events]:  eta: 0:16:22  iter: 6399  total_loss: 2.72  loss_sem_seg: 1.214  loss_center: 0.4485  loss_offset: 0.8574  time: 0.2734  data_time: 0.0268  lr: 0.00099706  max_mem: 6513M
[12/11 01:08:26 d2.utils.events]:  eta: 0:16:16  iter: 6419  total_loss: 2.74  loss_sem_seg: 1.25  loss_center: 0.4889  loss_offset: 0.7496  time: 0.2734  data_time: 0.0282  lr: 0.00099207  max_mem: 6513M
[12/11 01:08:32 d2.utils.events]:  eta: 0:16:10  iter: 6439  total_loss: 2.754  loss_sem_seg: 1.376  loss_center: 0.5934  loss_offset: 0.7887  time: 0.2734  data_time: 0.0269  lr: 0.00098709  max_mem: 6513M
[12/11 01:08:37 d2.utils.events]:  eta: 0:16:05  iter: 6459  total_loss: 2.767  loss_sem_seg: 1.232  loss_center: 0.6192  loss_offset: 0.8562  time: 0.2734  data_time: 0.0281  lr: 0.00098209  max_mem: 6513M
[12/11 01:08:43 d2.utils.events]:  eta: 0:16:00  iter: 6479  total_loss: 2.862  loss_sem_seg: 1.325  loss_center: 0.614  loss_offset: 0.8709  time: 0.2734  data_time: 0.0270  lr: 0.0009771  max_mem: 6513M
[12/11 01:08:48 d2.utils.events]:  eta: 0:15:54  iter: 6499  total_loss: 2.818  loss_sem_seg: 1.306  loss_center: 0.7237  loss_offset: 0.8326  time: 0.2734  data_time: 0.0268  lr: 0.0009721  max_mem: 6513M
[12/11 01:08:53 d2.utils.events]:  eta: 0:15:49  iter: 6519  total_loss: 2.637  loss_sem_seg: 1.064  loss_center: 0.6146  loss_offset: 0.7621  time: 0.2734  data_time: 0.0277  lr: 0.00096711  max_mem: 6513M
[12/11 01:08:59 d2.utils.events]:  eta: 0:15:43  iter: 6539  total_loss: 2.945  loss_sem_seg: 1.427  loss_center: 0.6002  loss_offset: 0.9417  time: 0.2734  data_time: 0.0266  lr: 0.0009621  max_mem: 6513M
[12/11 01:09:04 d2.utils.events]:  eta: 0:15:38  iter: 6559  total_loss: 2.672  loss_sem_seg: 1.227  loss_center: 0.6686  loss_offset: 0.8293  time: 0.2734  data_time: 0.0264  lr: 0.0009571  max_mem: 6513M
[12/11 01:09:10 d2.utils.events]:  eta: 0:15:33  iter: 6579  total_loss: 2.8  loss_sem_seg: 1.335  loss_center: 0.562  loss_offset: 0.7925  time: 0.2734  data_time: 0.0269  lr: 0.00095209  max_mem: 6513M
[12/11 01:09:15 d2.utils.events]:  eta: 0:15:28  iter: 6599  total_loss: 2.771  loss_sem_seg: 1.301  loss_center: 0.6568  loss_offset: 0.7538  time: 0.2734  data_time: 0.0280  lr: 0.00094708  max_mem: 6513M
[12/11 01:09:21 d2.utils.events]:  eta: 0:15:23  iter: 6619  total_loss: 2.623  loss_sem_seg: 1.201  loss_center: 0.5387  loss_offset: 0.76  time: 0.2734  data_time: 0.0272  lr: 0.00094206  max_mem: 6513M
[12/11 01:09:26 d2.utils.events]:  eta: 0:15:17  iter: 6639  total_loss: 2.575  loss_sem_seg: 1.026  loss_center: 0.593  loss_offset: 0.7174  time: 0.2734  data_time: 0.0277  lr: 0.00093705  max_mem: 6513M
[12/11 01:09:32 d2.utils.events]:  eta: 0:15:12  iter: 6659  total_loss: 2.626  loss_sem_seg: 1.028  loss_center: 0.583  loss_offset: 0.7972  time: 0.2734  data_time: 0.0269  lr: 0.00093203  max_mem: 6513M
[12/11 01:09:37 d2.utils.events]:  eta: 0:15:06  iter: 6679  total_loss: 2.891  loss_sem_seg: 1.368  loss_center: 0.5818  loss_offset: 0.9007  time: 0.2734  data_time: 0.0251  lr: 0.000927  max_mem: 6513M
[12/11 01:09:43 d2.utils.events]:  eta: 0:15:00  iter: 6699  total_loss: 2.724  loss_sem_seg: 1.15  loss_center: 0.5635  loss_offset: 0.7616  time: 0.2734  data_time: 0.0267  lr: 0.00092198  max_mem: 6513M
[12/11 01:09:48 d2.utils.events]:  eta: 0:14:54  iter: 6719  total_loss: 2.542  loss_sem_seg: 1.171  loss_center: 0.6235  loss_offset: 0.7552  time: 0.2734  data_time: 0.0268  lr: 0.00091695  max_mem: 6513M
[12/11 01:09:54 d2.utils.events]:  eta: 0:14:49  iter: 6739  total_loss: 2.857  loss_sem_seg: 1.332  loss_center: 0.5777  loss_offset: 0.8316  time: 0.2734  data_time: 0.0275  lr: 0.00091192  max_mem: 6513M
[12/11 01:09:59 d2.utils.events]:  eta: 0:14:43  iter: 6759  total_loss: 2.679  loss_sem_seg: 1.319  loss_center: 0.5559  loss_offset: 0.8168  time: 0.2734  data_time: 0.0274  lr: 0.00090688  max_mem: 6513M
[12/11 01:10:05 d2.utils.events]:  eta: 0:14:38  iter: 6779  total_loss: 2.941  loss_sem_seg: 1.28  loss_center: 0.6038  loss_offset: 0.7848  time: 0.2734  data_time: 0.0276  lr: 0.00090184  max_mem: 6513M
[12/11 01:10:10 d2.utils.events]:  eta: 0:14:32  iter: 6799  total_loss: 2.722  loss_sem_seg: 1.278  loss_center: 0.6527  loss_offset: 0.8113  time: 0.2734  data_time: 0.0270  lr: 0.0008968  max_mem: 6513M
[12/11 01:10:16 d2.utils.events]:  eta: 0:14:27  iter: 6819  total_loss: 2.421  loss_sem_seg: 1.189  loss_center: 0.5184  loss_offset: 0.8054  time: 0.2734  data_time: 0.0283  lr: 0.00089176  max_mem: 6513M
[12/11 01:10:21 d2.utils.events]:  eta: 0:14:22  iter: 6839  total_loss: 2.497  loss_sem_seg: 1.132  loss_center: 0.543  loss_offset: 0.8136  time: 0.2734  data_time: 0.0260  lr: 0.00088671  max_mem: 6513M
[12/11 01:10:26 d2.utils.events]:  eta: 0:14:17  iter: 6859  total_loss: 2.827  loss_sem_seg: 1.38  loss_center: 0.5424  loss_offset: 0.8859  time: 0.2734  data_time: 0.0262  lr: 0.00088166  max_mem: 6513M
[12/11 01:10:32 d2.utils.events]:  eta: 0:14:12  iter: 6879  total_loss: 2.539  loss_sem_seg: 1.106  loss_center: 0.53  loss_offset: 0.7898  time: 0.2734  data_time: 0.0273  lr: 0.00087661  max_mem: 6513M
[12/11 01:10:37 d2.utils.events]:  eta: 0:14:06  iter: 6899  total_loss: 2.864  loss_sem_seg: 1.284  loss_center: 0.6275  loss_offset: 0.9725  time: 0.2734  data_time: 0.0261  lr: 0.00087155  max_mem: 6513M
[12/11 01:10:43 d2.utils.events]:  eta: 0:14:01  iter: 6919  total_loss: 2.462  loss_sem_seg: 1.158  loss_center: 0.5946  loss_offset: 0.7942  time: 0.2734  data_time: 0.0268  lr: 0.00086649  max_mem: 6513M
[12/11 01:10:48 d2.utils.events]:  eta: 0:13:55  iter: 6939  total_loss: 2.71  loss_sem_seg: 1.128  loss_center: 0.542  loss_offset: 0.9237  time: 0.2734  data_time: 0.0267  lr: 0.00086142  max_mem: 6513M
[12/11 01:10:54 d2.utils.events]:  eta: 0:13:50  iter: 6959  total_loss: 2.758  loss_sem_seg: 1.241  loss_center: 0.5255  loss_offset: 0.9046  time: 0.2734  data_time: 0.0295  lr: 0.00085636  max_mem: 6513M
[12/11 01:10:59 d2.utils.events]:  eta: 0:13:45  iter: 6979  total_loss: 2.917  loss_sem_seg: 1.313  loss_center: 0.6619  loss_offset: 0.7972  time: 0.2734  data_time: 0.0267  lr: 0.00085129  max_mem: 6513M
[12/11 01:11:05 d2.utils.events]:  eta: 0:13:39  iter: 6999  total_loss: 2.739  loss_sem_seg: 1.1  loss_center: 0.5731  loss_offset: 0.7667  time: 0.2734  data_time: 0.0274  lr: 0.00084621  max_mem: 6513M
[12/11 01:11:10 d2.utils.events]:  eta: 0:13:34  iter: 7019  total_loss: 2.679  loss_sem_seg: 1.198  loss_center: 0.6338  loss_offset: 0.81  time: 0.2734  data_time: 0.0273  lr: 0.00084114  max_mem: 6513M
[12/11 01:11:16 d2.utils.events]:  eta: 0:13:28  iter: 7039  total_loss: 2.778  loss_sem_seg: 1.193  loss_center: 0.7124  loss_offset: 0.6631  time: 0.2734  data_time: 0.0267  lr: 0.00083605  max_mem: 6513M
[12/11 01:11:21 d2.utils.events]:  eta: 0:13:22  iter: 7059  total_loss: 2.773  loss_sem_seg: 1.172  loss_center: 0.6684  loss_offset: 0.8671  time: 0.2734  data_time: 0.0269  lr: 0.00083097  max_mem: 6513M
[12/11 01:11:27 d2.utils.events]:  eta: 0:13:17  iter: 7079  total_loss: 2.48  loss_sem_seg: 1.172  loss_center: 0.5263  loss_offset: 0.782  time: 0.2734  data_time: 0.0276  lr: 0.00082588  max_mem: 6513M
[12/11 01:11:32 d2.utils.events]:  eta: 0:13:12  iter: 7099  total_loss: 2.634  loss_sem_seg: 1.227  loss_center: 0.6546  loss_offset: 0.8226  time: 0.2734  data_time: 0.0287  lr: 0.00082079  max_mem: 6513M
[12/11 01:11:38 d2.utils.events]:  eta: 0:13:05  iter: 7119  total_loss: 2.688  loss_sem_seg: 1.203  loss_center: 0.6536  loss_offset: 0.7817  time: 0.2734  data_time: 0.0264  lr: 0.0008157  max_mem: 6513M
[12/11 01:11:43 d2.utils.events]:  eta: 0:13:00  iter: 7139  total_loss: 2.895  loss_sem_seg: 1.356  loss_center: 0.4988  loss_offset: 0.9262  time: 0.2734  data_time: 0.0278  lr: 0.0008106  max_mem: 6513M
[12/11 01:11:49 d2.utils.events]:  eta: 0:12:55  iter: 7159  total_loss: 2.742  loss_sem_seg: 1.275  loss_center: 0.5894  loss_offset: 0.7194  time: 0.2734  data_time: 0.0276  lr: 0.0008055  max_mem: 6513M
[12/11 01:11:54 d2.utils.events]:  eta: 0:12:49  iter: 7179  total_loss: 2.668  loss_sem_seg: 1.367  loss_center: 0.6409  loss_offset: 0.7436  time: 0.2734  data_time: 0.0281  lr: 0.00080039  max_mem: 6513M
[12/11 01:12:00 d2.utils.events]:  eta: 0:12:43  iter: 7199  total_loss: 2.707  loss_sem_seg: 1.157  loss_center: 0.5937  loss_offset: 0.7976  time: 0.2734  data_time: 0.0244  lr: 0.00079528  max_mem: 6513M
[12/11 01:12:05 d2.utils.events]:  eta: 0:12:37  iter: 7219  total_loss: 2.807  loss_sem_seg: 1.227  loss_center: 0.5603  loss_offset: 0.7981  time: 0.2734  data_time: 0.0285  lr: 0.00079017  max_mem: 6513M
[12/11 01:12:11 d2.utils.events]:  eta: 0:12:33  iter: 7239  total_loss: 2.857  loss_sem_seg: 1.515  loss_center: 0.7463  loss_offset: 0.8541  time: 0.2734  data_time: 0.0278  lr: 0.00078505  max_mem: 6513M
[12/11 01:12:16 d2.utils.events]:  eta: 0:12:27  iter: 7259  total_loss: 2.597  loss_sem_seg: 1.152  loss_center: 0.5543  loss_offset: 0.7545  time: 0.2734  data_time: 0.0271  lr: 0.00077993  max_mem: 6513M
[12/11 01:12:22 d2.utils.events]:  eta: 0:12:21  iter: 7279  total_loss: 2.55  loss_sem_seg: 1.226  loss_center: 0.6289  loss_offset: 0.8068  time: 0.2734  data_time: 0.0270  lr: 0.00077481  max_mem: 6513M
[12/11 01:12:27 d2.utils.events]:  eta: 0:12:16  iter: 7299  total_loss: 2.511  loss_sem_seg: 1.194  loss_center: 0.732  loss_offset: 0.7869  time: 0.2734  data_time: 0.0283  lr: 0.00076968  max_mem: 6513M
[12/11 01:12:32 d2.utils.events]:  eta: 0:12:10  iter: 7319  total_loss: 2.685  loss_sem_seg: 1.054  loss_center: 0.7202  loss_offset: 0.7089  time: 0.2734  data_time: 0.0267  lr: 0.00076455  max_mem: 6513M
[12/11 01:12:38 d2.utils.events]:  eta: 0:12:06  iter: 7339  total_loss: 2.669  loss_sem_seg: 1.19  loss_center: 0.6384  loss_offset: 0.8235  time: 0.2734  data_time: 0.0257  lr: 0.00075942  max_mem: 6513M
[12/11 01:12:43 d2.utils.events]:  eta: 0:12:00  iter: 7359  total_loss: 2.755  loss_sem_seg: 1.163  loss_center: 0.6358  loss_offset: 0.8786  time: 0.2734  data_time: 0.0275  lr: 0.00075428  max_mem: 6513M
[12/11 01:12:49 d2.utils.events]:  eta: 0:11:55  iter: 7379  total_loss: 2.717  loss_sem_seg: 1.225  loss_center: 0.6426  loss_offset: 0.8324  time: 0.2734  data_time: 0.0274  lr: 0.00074914  max_mem: 6513M
[12/11 01:12:54 d2.utils.events]:  eta: 0:11:50  iter: 7399  total_loss: 2.692  loss_sem_seg: 1.066  loss_center: 0.6431  loss_offset: 0.7513  time: 0.2734  data_time: 0.0258  lr: 0.00074399  max_mem: 6513M
[12/11 01:13:00 d2.utils.events]:  eta: 0:11:44  iter: 7419  total_loss: 2.938  loss_sem_seg: 1.402  loss_center: 0.6145  loss_offset: 0.959  time: 0.2734  data_time: 0.0283  lr: 0.00073884  max_mem: 6513M
[12/11 01:13:05 d2.utils.events]:  eta: 0:11:39  iter: 7439  total_loss: 2.812  loss_sem_seg: 1.198  loss_center: 0.6378  loss_offset: 0.8906  time: 0.2734  data_time: 0.0270  lr: 0.00073368  max_mem: 6513M
[12/11 01:13:11 d2.utils.events]:  eta: 0:11:33  iter: 7459  total_loss: 2.779  loss_sem_seg: 1.148  loss_center: 0.6338  loss_offset: 0.8596  time: 0.2734  data_time: 0.0282  lr: 0.00072852  max_mem: 6513M
[12/11 01:13:16 d2.utils.events]:  eta: 0:11:26  iter: 7479  total_loss: 2.756  loss_sem_seg: 1.272  loss_center: 0.6073  loss_offset: 0.8384  time: 0.2734  data_time: 0.0262  lr: 0.00072336  max_mem: 6513M
[12/11 01:13:22 d2.utils.events]:  eta: 0:11:21  iter: 7499  total_loss: 2.676  loss_sem_seg: 1.151  loss_center: 0.7304  loss_offset: 0.6824  time: 0.2734  data_time: 0.0263  lr: 0.00071819  max_mem: 6513M
[12/11 01:13:27 d2.utils.events]:  eta: 0:11:15  iter: 7519  total_loss: 2.778  loss_sem_seg: 1.246  loss_center: 0.7289  loss_offset: 0.7634  time: 0.2734  data_time: 0.0286  lr: 0.00071302  max_mem: 6513M
[12/11 01:13:33 d2.utils.events]:  eta: 0:11:10  iter: 7539  total_loss: 2.684  loss_sem_seg: 1.206  loss_center: 0.6252  loss_offset: 0.8294  time: 0.2734  data_time: 0.0285  lr: 0.00070785  max_mem: 6513M
[12/11 01:13:38 d2.utils.events]:  eta: 0:11:04  iter: 7559  total_loss: 2.628  loss_sem_seg: 1.201  loss_center: 0.5785  loss_offset: 0.8812  time: 0.2734  data_time: 0.0274  lr: 0.00070267  max_mem: 6513M
[12/11 01:13:44 d2.utils.events]:  eta: 0:10:59  iter: 7579  total_loss: 2.94  loss_sem_seg: 1.373  loss_center: 0.596  loss_offset: 0.7417  time: 0.2734  data_time: 0.0292  lr: 0.00069749  max_mem: 6513M
[12/11 01:13:49 d2.utils.events]:  eta: 0:10:53  iter: 7599  total_loss: 2.605  loss_sem_seg: 1.146  loss_center: 0.6666  loss_offset: 0.7713  time: 0.2734  data_time: 0.0261  lr: 0.0006923  max_mem: 6513M
[12/11 01:13:55 d2.utils.events]:  eta: 0:10:48  iter: 7619  total_loss: 3.059  loss_sem_seg: 1.403  loss_center: 0.4825  loss_offset: 0.9225  time: 0.2734  data_time: 0.0290  lr: 0.00068711  max_mem: 6513M
[12/11 01:14:00 d2.utils.events]:  eta: 0:10:42  iter: 7639  total_loss: 2.645  loss_sem_seg: 1.135  loss_center: 0.5442  loss_offset: 0.9262  time: 0.2734  data_time: 0.0274  lr: 0.00068191  max_mem: 6513M
[12/11 01:14:06 d2.utils.events]:  eta: 0:10:37  iter: 7659  total_loss: 2.746  loss_sem_seg: 1.14  loss_center: 0.5337  loss_offset: 0.807  time: 0.2734  data_time: 0.0274  lr: 0.00067671  max_mem: 6513M
[12/11 01:14:11 d2.utils.events]:  eta: 0:10:32  iter: 7679  total_loss: 2.811  loss_sem_seg: 1.325  loss_center: 0.5037  loss_offset: 0.9234  time: 0.2734  data_time: 0.0264  lr: 0.0006715  max_mem: 6513M
[12/11 01:14:17 d2.utils.events]:  eta: 0:10:27  iter: 7699  total_loss: 2.934  loss_sem_seg: 1.305  loss_center: 0.6432  loss_offset: 0.817  time: 0.2734  data_time: 0.0270  lr: 0.00066629  max_mem: 6513M
[12/11 01:14:22 d2.utils.events]:  eta: 0:10:21  iter: 7719  total_loss: 2.467  loss_sem_seg: 1.046  loss_center: 0.5186  loss_offset: 0.8529  time: 0.2734  data_time: 0.0284  lr: 0.00066108  max_mem: 6513M
[12/11 01:14:28 d2.utils.events]:  eta: 0:10:16  iter: 7739  total_loss: 2.716  loss_sem_seg: 1.441  loss_center: 0.5462  loss_offset: 0.7059  time: 0.2734  data_time: 0.0274  lr: 0.00065586  max_mem: 6513M
[12/11 01:14:33 d2.utils.events]:  eta: 0:10:11  iter: 7759  total_loss: 2.658  loss_sem_seg: 1.092  loss_center: 0.5698  loss_offset: 0.7401  time: 0.2734  data_time: 0.0261  lr: 0.00065064  max_mem: 6513M
[12/11 01:14:39 d2.utils.events]:  eta: 0:10:05  iter: 7779  total_loss: 2.471  loss_sem_seg: 1.057  loss_center: 0.5969  loss_offset: 0.7999  time: 0.2734  data_time: 0.0279  lr: 0.00064541  max_mem: 6513M
[12/11 01:14:44 d2.utils.events]:  eta: 0:09:59  iter: 7799  total_loss: 2.71  loss_sem_seg: 1.133  loss_center: 0.7186  loss_offset: 0.8511  time: 0.2734  data_time: 0.0252  lr: 0.00064017  max_mem: 6513M
[12/11 01:14:49 d2.utils.events]:  eta: 0:09:54  iter: 7819  total_loss: 2.75  loss_sem_seg: 1.221  loss_center: 0.6116  loss_offset: 0.8145  time: 0.2734  data_time: 0.0269  lr: 0.00063494  max_mem: 6513M
[12/11 01:14:55 d2.utils.events]:  eta: 0:09:49  iter: 7839  total_loss: 2.646  loss_sem_seg: 1.103  loss_center: 0.5979  loss_offset: 0.8094  time: 0.2734  data_time: 0.0284  lr: 0.00062969  max_mem: 6513M
[12/11 01:15:00 d2.utils.events]:  eta: 0:09:43  iter: 7859  total_loss: 2.641  loss_sem_seg: 1.166  loss_center: 0.5723  loss_offset: 0.7941  time: 0.2734  data_time: 0.0258  lr: 0.00062445  max_mem: 6513M
[12/11 01:15:06 d2.utils.events]:  eta: 0:09:38  iter: 7879  total_loss: 2.895  loss_sem_seg: 1.238  loss_center: 0.7135  loss_offset: 0.8572  time: 0.2734  data_time: 0.0281  lr: 0.00061919  max_mem: 6513M
[12/11 01:15:11 d2.utils.events]:  eta: 0:09:33  iter: 7899  total_loss: 2.737  loss_sem_seg: 1.168  loss_center: 0.7381  loss_offset: 0.7894  time: 0.2734  data_time: 0.0273  lr: 0.00061394  max_mem: 6513M
[12/11 01:15:17 d2.utils.events]:  eta: 0:09:27  iter: 7919  total_loss: 2.44  loss_sem_seg: 1.153  loss_center: 0.5958  loss_offset: 0.8136  time: 0.2734  data_time: 0.0275  lr: 0.00060867  max_mem: 6513M
[12/11 01:15:22 d2.utils.events]:  eta: 0:09:22  iter: 7939  total_loss: 2.733  loss_sem_seg: 1.065  loss_center: 0.6395  loss_offset: 0.8792  time: 0.2734  data_time: 0.0269  lr: 0.00060341  max_mem: 6513M
[12/11 01:15:28 d2.utils.events]:  eta: 0:09:16  iter: 7959  total_loss: 2.781  loss_sem_seg: 1.095  loss_center: 0.712  loss_offset: 0.8127  time: 0.2734  data_time: 0.0273  lr: 0.00059813  max_mem: 6513M
[12/11 01:15:33 d2.utils.events]:  eta: 0:09:11  iter: 7979  total_loss: 2.712  loss_sem_seg: 1.28  loss_center: 0.581  loss_offset: 0.8986  time: 0.2734  data_time: 0.0280  lr: 0.00059286  max_mem: 6513M
[12/11 01:15:39 d2.utils.events]:  eta: 0:09:05  iter: 7999  total_loss: 2.56  loss_sem_seg: 0.9902  loss_center: 0.6274  loss_offset: 0.8917  time: 0.2734  data_time: 0.0286  lr: 0.00058757  max_mem: 6513M
[12/11 01:15:44 d2.utils.events]:  eta: 0:08:59  iter: 8019  total_loss: 2.527  loss_sem_seg: 1.111  loss_center: 0.4897  loss_offset: 0.7467  time: 0.2734  data_time: 0.0267  lr: 0.00058229  max_mem: 6513M
[12/11 01:15:50 d2.utils.events]:  eta: 0:08:54  iter: 8039  total_loss: 2.566  loss_sem_seg: 1.194  loss_center: 0.6202  loss_offset: 0.8263  time: 0.2734  data_time: 0.0268  lr: 0.00057699  max_mem: 6513M
[12/11 01:15:55 d2.utils.events]:  eta: 0:08:49  iter: 8059  total_loss: 2.814  loss_sem_seg: 1.275  loss_center: 0.8396  loss_offset: 0.8485  time: 0.2734  data_time: 0.0286  lr: 0.00057169  max_mem: 6513M
[12/11 01:16:01 d2.utils.events]:  eta: 0:08:43  iter: 8079  total_loss: 2.512  loss_sem_seg: 1.092  loss_center: 0.62  loss_offset: 0.7787  time: 0.2734  data_time: 0.0260  lr: 0.00056639  max_mem: 6513M
[12/11 01:16:06 d2.utils.events]:  eta: 0:08:38  iter: 8099  total_loss: 2.751  loss_sem_seg: 1.206  loss_center: 0.6574  loss_offset: 0.8683  time: 0.2734  data_time: 0.0292  lr: 0.00056108  max_mem: 6513M
[12/11 01:16:12 d2.utils.events]:  eta: 0:08:33  iter: 8119  total_loss: 2.504  loss_sem_seg: 0.9812  loss_center: 0.733  loss_offset: 0.7788  time: 0.2734  data_time: 0.0260  lr: 0.00055576  max_mem: 6513M
[12/11 01:16:17 d2.utils.events]:  eta: 0:08:27  iter: 8139  total_loss: 2.485  loss_sem_seg: 1.074  loss_center: 0.6548  loss_offset: 0.7509  time: 0.2734  data_time: 0.0265  lr: 0.00055044  max_mem: 6513M
[12/11 01:16:23 d2.utils.events]:  eta: 0:08:21  iter: 8159  total_loss: 2.677  loss_sem_seg: 1.302  loss_center: 0.6722  loss_offset: 0.8363  time: 0.2734  data_time: 0.0263  lr: 0.00054512  max_mem: 6513M
[12/11 01:16:28 d2.utils.events]:  eta: 0:08:16  iter: 8179  total_loss: 2.644  loss_sem_seg: 1.182  loss_center: 0.7628  loss_offset: 0.7805  time: 0.2734  data_time: 0.0261  lr: 0.00053978  max_mem: 6513M
[12/11 01:16:33 d2.utils.events]:  eta: 0:08:11  iter: 8199  total_loss: 2.242  loss_sem_seg: 0.9891  loss_center: 0.4477  loss_offset: 0.7229  time: 0.2734  data_time: 0.0264  lr: 0.00053444  max_mem: 6513M
[12/11 01:16:39 d2.utils.events]:  eta: 0:08:05  iter: 8219  total_loss: 2.583  loss_sem_seg: 1.102  loss_center: 0.7055  loss_offset: 0.8456  time: 0.2734  data_time: 0.0281  lr: 0.0005291  max_mem: 6513M
[12/11 01:16:44 d2.utils.events]:  eta: 0:07:59  iter: 8239  total_loss: 2.625  loss_sem_seg: 1.175  loss_center: 0.6111  loss_offset: 0.8159  time: 0.2734  data_time: 0.0268  lr: 0.00052375  max_mem: 6513M
[12/11 01:16:50 d2.utils.events]:  eta: 0:07:54  iter: 8259  total_loss: 2.607  loss_sem_seg: 1.144  loss_center: 0.6349  loss_offset: 0.729  time: 0.2734  data_time: 0.0281  lr: 0.00051839  max_mem: 6513M
[12/11 01:16:55 d2.utils.events]:  eta: 0:07:49  iter: 8279  total_loss: 2.889  loss_sem_seg: 1.106  loss_center: 0.6481  loss_offset: 0.8832  time: 0.2734  data_time: 0.0273  lr: 0.00051303  max_mem: 6513M
[12/11 01:17:01 d2.utils.events]:  eta: 0:07:43  iter: 8299  total_loss: 2.629  loss_sem_seg: 1.146  loss_center: 0.5982  loss_offset: 0.8278  time: 0.2734  data_time: 0.0274  lr: 0.00050766  max_mem: 6513M
[12/11 01:17:06 d2.utils.events]:  eta: 0:07:38  iter: 8319  total_loss: 2.901  loss_sem_seg: 1.179  loss_center: 0.7991  loss_offset: 0.7659  time: 0.2734  data_time: 0.0261  lr: 0.00050229  max_mem: 6513M
[12/11 01:17:12 d2.utils.events]:  eta: 0:07:32  iter: 8339  total_loss: 2.776  loss_sem_seg: 1.185  loss_center: 0.5956  loss_offset: 0.8404  time: 0.2734  data_time: 0.0277  lr: 0.0004969  max_mem: 6513M
[12/11 01:17:17 d2.utils.events]:  eta: 0:07:27  iter: 8359  total_loss: 2.694  loss_sem_seg: 1.188  loss_center: 0.6414  loss_offset: 0.8368  time: 0.2734  data_time: 0.0276  lr: 0.00049152  max_mem: 6513M
[12/11 01:17:23 d2.utils.events]:  eta: 0:07:21  iter: 8379  total_loss: 2.469  loss_sem_seg: 1.062  loss_center: 0.53  loss_offset: 0.7893  time: 0.2734  data_time: 0.0265  lr: 0.00048612  max_mem: 6513M
[12/11 01:17:28 d2.utils.events]:  eta: 0:07:16  iter: 8399  total_loss: 2.336  loss_sem_seg: 0.947  loss_center: 0.4995  loss_offset: 0.7389  time: 0.2734  data_time: 0.0285  lr: 0.00048072  max_mem: 6513M
[12/11 01:17:34 d2.utils.events]:  eta: 0:07:10  iter: 8419  total_loss: 2.736  loss_sem_seg: 1.196  loss_center: 0.6013  loss_offset: 0.7627  time: 0.2734  data_time: 0.0272  lr: 0.00047531  max_mem: 6513M
[12/11 01:17:39 d2.utils.events]:  eta: 0:07:05  iter: 8439  total_loss: 2.67  loss_sem_seg: 1.174  loss_center: 0.5479  loss_offset: 0.8365  time: 0.2734  data_time: 0.0271  lr: 0.0004699  max_mem: 6513M
[12/11 01:17:45 d2.utils.events]:  eta: 0:06:59  iter: 8459  total_loss: 2.536  loss_sem_seg: 1.053  loss_center: 0.654  loss_offset: 0.771  time: 0.2734  data_time: 0.0281  lr: 0.00046448  max_mem: 6513M
[12/11 01:17:50 d2.utils.events]:  eta: 0:06:54  iter: 8479  total_loss: 2.601  loss_sem_seg: 1.148  loss_center: 0.6697  loss_offset: 0.8436  time: 0.2734  data_time: 0.0262  lr: 0.00045905  max_mem: 6513M
[12/11 01:17:56 d2.utils.events]:  eta: 0:06:49  iter: 8499  total_loss: 2.846  loss_sem_seg: 1.283  loss_center: 0.7018  loss_offset: 0.758  time: 0.2734  data_time: 0.0279  lr: 0.00045361  max_mem: 6513M
[12/11 01:18:01 d2.utils.events]:  eta: 0:06:43  iter: 8519  total_loss: 2.843  loss_sem_seg: 1.123  loss_center: 0.6513  loss_offset: 0.9067  time: 0.2734  data_time: 0.0269  lr: 0.00044817  max_mem: 6513M
[12/11 01:18:07 d2.utils.events]:  eta: 0:06:38  iter: 8539  total_loss: 2.595  loss_sem_seg: 1.021  loss_center: 0.5816  loss_offset: 0.8487  time: 0.2734  data_time: 0.0261  lr: 0.00044272  max_mem: 6513M
[12/11 01:18:12 d2.utils.events]:  eta: 0:06:33  iter: 8559  total_loss: 2.65  loss_sem_seg: 1.15  loss_center: 0.5063  loss_offset: 0.7715  time: 0.2734  data_time: 0.0276  lr: 0.00043726  max_mem: 6513M
[12/11 01:18:18 d2.utils.events]:  eta: 0:06:27  iter: 8579  total_loss: 2.448  loss_sem_seg: 1.03  loss_center: 0.7245  loss_offset: 0.7697  time: 0.2734  data_time: 0.0264  lr: 0.00043179  max_mem: 6513M
[12/11 01:18:23 d2.utils.events]:  eta: 0:06:22  iter: 8599  total_loss: 2.763  loss_sem_seg: 1.217  loss_center: 0.6922  loss_offset: 0.8762  time: 0.2734  data_time: 0.0262  lr: 0.00042632  max_mem: 6513M
[12/11 01:18:28 d2.utils.events]:  eta: 0:06:16  iter: 8619  total_loss: 2.595  loss_sem_seg: 1.209  loss_center: 0.614  loss_offset: 0.8048  time: 0.2734  data_time: 0.0268  lr: 0.00042084  max_mem: 6513M
[12/11 01:18:34 d2.utils.events]:  eta: 0:06:11  iter: 8639  total_loss: 2.511  loss_sem_seg: 1.04  loss_center: 0.5349  loss_offset: 0.7898  time: 0.2734  data_time: 0.0270  lr: 0.00041535  max_mem: 6513M
[12/11 01:18:39 d2.utils.events]:  eta: 0:06:05  iter: 8659  total_loss: 2.702  loss_sem_seg: 1.011  loss_center: 0.6004  loss_offset: 0.7474  time: 0.2734  data_time: 0.0276  lr: 0.00040985  max_mem: 6513M
[12/11 01:18:45 d2.utils.events]:  eta: 0:06:00  iter: 8679  total_loss: 2.358  loss_sem_seg: 1.006  loss_center: 0.5306  loss_offset: 0.8503  time: 0.2734  data_time: 0.0287  lr: 0.00040435  max_mem: 6513M
[12/11 01:18:50 d2.utils.events]:  eta: 0:05:54  iter: 8699  total_loss: 2.526  loss_sem_seg: 1.285  loss_center: 0.5472  loss_offset: 0.8142  time: 0.2734  data_time: 0.0272  lr: 0.00039883  max_mem: 6513M
[12/11 01:18:56 d2.utils.events]:  eta: 0:05:49  iter: 8719  total_loss: 2.573  loss_sem_seg: 1.15  loss_center: 0.583  loss_offset: 0.8523  time: 0.2734  data_time: 0.0273  lr: 0.00039331  max_mem: 6513M
[12/11 01:19:01 d2.utils.events]:  eta: 0:05:43  iter: 8739  total_loss: 2.656  loss_sem_seg: 1.08  loss_center: 0.5979  loss_offset: 0.7634  time: 0.2734  data_time: 0.0256  lr: 0.00038778  max_mem: 6513M
[12/11 01:19:07 d2.utils.events]:  eta: 0:05:38  iter: 8759  total_loss: 2.858  loss_sem_seg: 1.181  loss_center: 0.7565  loss_offset: 0.8291  time: 0.2734  data_time: 0.0273  lr: 0.00038224  max_mem: 6513M
[12/11 01:19:12 d2.utils.events]:  eta: 0:05:32  iter: 8779  total_loss: 2.488  loss_sem_seg: 1.019  loss_center: 0.6076  loss_offset: 0.7924  time: 0.2734  data_time: 0.0269  lr: 0.00037669  max_mem: 6513M
[12/11 01:19:18 d2.utils.events]:  eta: 0:05:27  iter: 8799  total_loss: 2.603  loss_sem_seg: 1.023  loss_center: 0.7484  loss_offset: 0.7181  time: 0.2734  data_time: 0.0275  lr: 0.00037113  max_mem: 6513M
[12/11 01:19:23 d2.utils.events]:  eta: 0:05:21  iter: 8819  total_loss: 2.515  loss_sem_seg: 1.196  loss_center: 0.5381  loss_offset: 0.7826  time: 0.2734  data_time: 0.0263  lr: 0.00036557  max_mem: 6513M
[12/11 01:19:29 d2.utils.events]:  eta: 0:05:16  iter: 8839  total_loss: 2.556  loss_sem_seg: 1.074  loss_center: 0.6569  loss_offset: 0.6987  time: 0.2734  data_time: 0.0275  lr: 0.00035999  max_mem: 6513M
[12/11 01:19:34 d2.utils.events]:  eta: 0:05:10  iter: 8859  total_loss: 2.413  loss_sem_seg: 1.185  loss_center: 0.5321  loss_offset: 0.7613  time: 0.2734  data_time: 0.0274  lr: 0.0003544  max_mem: 6513M
[12/11 01:19:40 d2.utils.events]:  eta: 0:05:05  iter: 8879  total_loss: 2.743  loss_sem_seg: 1.108  loss_center: 0.6186  loss_offset: 0.8862  time: 0.2734  data_time: 0.0266  lr: 0.00034881  max_mem: 6513M
[12/11 01:19:45 d2.utils.events]:  eta: 0:05:00  iter: 8899  total_loss: 2.44  loss_sem_seg: 1.036  loss_center: 0.6317  loss_offset: 0.7705  time: 0.2734  data_time: 0.0272  lr: 0.0003432  max_mem: 6513M
[12/11 01:19:51 d2.utils.events]:  eta: 0:04:54  iter: 8919  total_loss: 2.636  loss_sem_seg: 1.108  loss_center: 0.6613  loss_offset: 0.8242  time: 0.2734  data_time: 0.0285  lr: 0.00033758  max_mem: 6513M
[12/11 01:19:56 d2.utils.events]:  eta: 0:04:49  iter: 8939  total_loss: 2.37  loss_sem_seg: 1.056  loss_center: 0.6265  loss_offset: 0.7356  time: 0.2734  data_time: 0.0296  lr: 0.00033196  max_mem: 6513M
[12/11 01:20:02 d2.utils.events]:  eta: 0:04:43  iter: 8959  total_loss: 2.467  loss_sem_seg: 1.088  loss_center: 0.529  loss_offset: 0.6861  time: 0.2734  data_time: 0.0289  lr: 0.00032632  max_mem: 6513M
[12/11 01:20:07 d2.utils.events]:  eta: 0:04:38  iter: 8979  total_loss: 2.553  loss_sem_seg: 0.9691  loss_center: 0.7106  loss_offset: 0.8142  time: 0.2734  data_time: 0.0258  lr: 0.00032067  max_mem: 6513M
[12/11 01:20:13 d2.utils.events]:  eta: 0:04:32  iter: 8999  total_loss: 2.666  loss_sem_seg: 1.136  loss_center: 0.552  loss_offset: 0.853  time: 0.2734  data_time: 0.0287  lr: 0.00031501  max_mem: 6513M
[12/11 01:20:18 d2.utils.events]:  eta: 0:04:27  iter: 9019  total_loss: 2.508  loss_sem_seg: 1.03  loss_center: 0.6197  loss_offset: 0.7222  time: 0.2734  data_time: 0.0273  lr: 0.00030934  max_mem: 6513M
[12/11 01:20:24 d2.utils.events]:  eta: 0:04:21  iter: 9039  total_loss: 2.652  loss_sem_seg: 1.18  loss_center: 0.5966  loss_offset: 0.7452  time: 0.2734  data_time: 0.0274  lr: 0.00030366  max_mem: 6513M
[12/11 01:20:29 d2.utils.events]:  eta: 0:04:16  iter: 9059  total_loss: 2.388  loss_sem_seg: 0.9406  loss_center: 0.6188  loss_offset: 0.7581  time: 0.2734  data_time: 0.0277  lr: 0.00029797  max_mem: 6513M
[12/11 01:20:35 d2.utils.events]:  eta: 0:04:10  iter: 9079  total_loss: 2.384  loss_sem_seg: 0.9882  loss_center: 0.612  loss_offset: 0.7927  time: 0.2734  data_time: 0.0292  lr: 0.00029226  max_mem: 6513M
[12/11 01:20:40 d2.utils.events]:  eta: 0:04:05  iter: 9099  total_loss: 2.383  loss_sem_seg: 1.008  loss_center: 0.5486  loss_offset: 0.7334  time: 0.2734  data_time: 0.0266  lr: 0.00028654  max_mem: 6513M
[12/11 01:20:46 d2.utils.events]:  eta: 0:03:59  iter: 9119  total_loss: 2.447  loss_sem_seg: 1.153  loss_center: 0.6511  loss_offset: 0.7138  time: 0.2734  data_time: 0.0277  lr: 0.00028081  max_mem: 6513M
[12/11 01:20:51 d2.utils.events]:  eta: 0:03:54  iter: 9139  total_loss: 2.708  loss_sem_seg: 1.215  loss_center: 0.5729  loss_offset: 0.6765  time: 0.2734  data_time: 0.0274  lr: 0.00027507  max_mem: 6513M
[12/11 01:20:57 d2.utils.events]:  eta: 0:03:49  iter: 9159  total_loss: 2.502  loss_sem_seg: 1.097  loss_center: 0.672  loss_offset: 0.7203  time: 0.2734  data_time: 0.0316  lr: 0.00026931  max_mem: 6513M
[12/11 01:21:02 d2.utils.events]:  eta: 0:03:43  iter: 9179  total_loss: 2.638  loss_sem_seg: 1.098  loss_center: 0.6292  loss_offset: 0.7528  time: 0.2734  data_time: 0.0275  lr: 0.00026354  max_mem: 6513M
[12/11 01:21:08 d2.utils.events]:  eta: 0:03:38  iter: 9199  total_loss: 2.178  loss_sem_seg: 0.9079  loss_center: 0.5368  loss_offset: 0.7135  time: 0.2734  data_time: 0.0280  lr: 0.00025776  max_mem: 6513M
[12/11 01:21:13 d2.utils.events]:  eta: 0:03:32  iter: 9219  total_loss: 2.517  loss_sem_seg: 1.062  loss_center: 0.5951  loss_offset: 0.6838  time: 0.2734  data_time: 0.0286  lr: 0.00025196  max_mem: 6513M
[12/11 01:21:19 d2.utils.events]:  eta: 0:03:27  iter: 9239  total_loss: 2.68  loss_sem_seg: 1.002  loss_center: 0.6743  loss_offset: 0.8103  time: 0.2734  data_time: 0.0298  lr: 0.00024614  max_mem: 6513M
[12/11 01:21:24 d2.utils.events]:  eta: 0:03:21  iter: 9259  total_loss: 2.515  loss_sem_seg: 1.198  loss_center: 0.5268  loss_offset: 0.7272  time: 0.2734  data_time: 0.0273  lr: 0.00024031  max_mem: 6513M
[12/11 01:21:30 d2.utils.events]:  eta: 0:03:16  iter: 9279  total_loss: 2.301  loss_sem_seg: 1.029  loss_center: 0.5934  loss_offset: 0.6975  time: 0.2734  data_time: 0.0270  lr: 0.00023447  max_mem: 6513M
[12/11 01:21:35 d2.utils.events]:  eta: 0:03:11  iter: 9299  total_loss: 2.646  loss_sem_seg: 1.143  loss_center: 0.7276  loss_offset: 0.7947  time: 0.2734  data_time: 0.0283  lr: 0.00022861  max_mem: 6513M
[12/11 01:21:41 d2.utils.events]:  eta: 0:03:05  iter: 9319  total_loss: 2.344  loss_sem_seg: 1.003  loss_center: 0.5585  loss_offset: 0.6942  time: 0.2734  data_time: 0.0268  lr: 0.00022273  max_mem: 6513M
[12/11 01:21:46 d2.utils.events]:  eta: 0:03:00  iter: 9339  total_loss: 2.249  loss_sem_seg: 0.8378  loss_center: 0.6188  loss_offset: 0.803  time: 0.2734  data_time: 0.0254  lr: 0.00021683  max_mem: 6513M
[12/11 01:21:52 d2.utils.events]:  eta: 0:02:54  iter: 9359  total_loss: 2.646  loss_sem_seg: 1.134  loss_center: 0.5935  loss_offset: 0.7674  time: 0.2734  data_time: 0.0274  lr: 0.00021092  max_mem: 6513M
[12/11 01:21:57 d2.utils.events]:  eta: 0:02:49  iter: 9379  total_loss: 2.462  loss_sem_seg: 1.058  loss_center: 0.565  loss_offset: 0.8524  time: 0.2734  data_time: 0.0258  lr: 0.00020499  max_mem: 6513M
[12/11 01:22:02 d2.utils.events]:  eta: 0:02:43  iter: 9399  total_loss: 2.52  loss_sem_seg: 1.008  loss_center: 0.6893  loss_offset: 0.7022  time: 0.2734  data_time: 0.0282  lr: 0.00019903  max_mem: 6513M
[12/11 01:22:08 d2.utils.events]:  eta: 0:02:38  iter: 9419  total_loss: 2.327  loss_sem_seg: 0.865  loss_center: 0.5492  loss_offset: 0.7232  time: 0.2734  data_time: 0.0270  lr: 0.00019306  max_mem: 6513M
[12/11 01:22:13 d2.utils.events]:  eta: 0:02:32  iter: 9439  total_loss: 2.817  loss_sem_seg: 1.123  loss_center: 0.5673  loss_offset: 0.7242  time: 0.2734  data_time: 0.0271  lr: 0.00018707  max_mem: 6513M
[12/11 01:22:19 d2.utils.events]:  eta: 0:02:27  iter: 9459  total_loss: 2.372  loss_sem_seg: 1.022  loss_center: 0.5542  loss_offset: 0.7137  time: 0.2734  data_time: 0.0259  lr: 0.00018106  max_mem: 6513M
[12/11 01:22:24 d2.utils.events]:  eta: 0:02:21  iter: 9479  total_loss: 2.513  loss_sem_seg: 1.146  loss_center: 0.5979  loss_offset: 0.6792  time: 0.2734  data_time: 0.0283  lr: 0.00017502  max_mem: 6513M
[12/11 01:22:30 d2.utils.events]:  eta: 0:02:16  iter: 9499  total_loss: 2.556  loss_sem_seg: 1.127  loss_center: 0.6325  loss_offset: 0.8052  time: 0.2734  data_time: 0.0287  lr: 0.00016896  max_mem: 6513M
[12/11 01:22:35 d2.utils.events]:  eta: 0:02:10  iter: 9519  total_loss: 2.633  loss_sem_seg: 1.077  loss_center: 0.6291  loss_offset: 0.922  time: 0.2734  data_time: 0.0275  lr: 0.00016288  max_mem: 6513M
[12/11 01:22:41 d2.utils.events]:  eta: 0:02:05  iter: 9539  total_loss: 2.389  loss_sem_seg: 0.9915  loss_center: 0.5691  loss_offset: 0.7133  time: 0.2734  data_time: 0.0267  lr: 0.00015677  max_mem: 6513M
[12/11 01:22:46 d2.utils.events]:  eta: 0:02:00  iter: 9559  total_loss: 2.288  loss_sem_seg: 1.068  loss_center: 0.5014  loss_offset: 0.7653  time: 0.2734  data_time: 0.0280  lr: 0.00015064  max_mem: 6513M
[12/11 01:22:52 d2.utils.events]:  eta: 0:01:54  iter: 9579  total_loss: 2.545  loss_sem_seg: 1.116  loss_center: 0.5862  loss_offset: 0.7243  time: 0.2734  data_time: 0.0275  lr: 0.00014448  max_mem: 6513M
[12/11 01:22:57 d2.utils.events]:  eta: 0:01:49  iter: 9599  total_loss: 2.674  loss_sem_seg: 1.032  loss_center: 0.6989  loss_offset: 0.8168  time: 0.2734  data_time: 0.0275  lr: 0.00013828  max_mem: 6513M
[12/11 01:23:03 d2.utils.events]:  eta: 0:01:43  iter: 9619  total_loss: 2.37  loss_sem_seg: 0.9364  loss_center: 0.6652  loss_offset: 0.6906  time: 0.2734  data_time: 0.0253  lr: 0.00013206  max_mem: 6513M
[12/11 01:23:08 d2.utils.events]:  eta: 0:01:38  iter: 9639  total_loss: 2.606  loss_sem_seg: 1.09  loss_center: 0.5754  loss_offset: 0.8101  time: 0.2734  data_time: 0.0279  lr: 0.0001258  max_mem: 6513M
[12/11 01:23:14 d2.utils.events]:  eta: 0:01:32  iter: 9659  total_loss: 2.512  loss_sem_seg: 1.019  loss_center: 0.5841  loss_offset: 0.8176  time: 0.2734  data_time: 0.0290  lr: 0.00011951  max_mem: 6513M
[12/11 01:23:19 d2.utils.events]:  eta: 0:01:27  iter: 9679  total_loss: 2.412  loss_sem_seg: 1.004  loss_center: 0.484  loss_offset: 0.7296  time: 0.2734  data_time: 0.0296  lr: 0.00011319  max_mem: 6513M
[12/11 01:23:25 d2.utils.events]:  eta: 0:01:21  iter: 9699  total_loss: 2.561  loss_sem_seg: 1.175  loss_center: 0.6158  loss_offset: 0.7765  time: 0.2734  data_time: 0.0305  lr: 0.00010682  max_mem: 6513M
[12/11 01:23:30 d2.utils.events]:  eta: 0:01:16  iter: 9719  total_loss: 2.559  loss_sem_seg: 1.049  loss_center: 0.6375  loss_offset: 0.8019  time: 0.2734  data_time: 0.0300  lr: 0.00010041  max_mem: 6513M
[12/11 01:23:36 d2.utils.events]:  eta: 0:01:11  iter: 9739  total_loss: 2.454  loss_sem_seg: 1.086  loss_center: 0.6009  loss_offset: 0.6882  time: 0.2735  data_time: 0.0284  lr: 9.3954e-05  max_mem: 6513M
[12/11 01:23:42 d2.utils.events]:  eta: 0:01:05  iter: 9759  total_loss: 2.736  loss_sem_seg: 1.19  loss_center: 0.664  loss_offset: 0.8459  time: 0.2735  data_time: 0.0295  lr: 8.7449e-05  max_mem: 6513M
[12/11 01:23:47 d2.utils.events]:  eta: 0:01:00  iter: 9779  total_loss: 2.581  loss_sem_seg: 1.229  loss_center: 0.5102  loss_offset: 0.8228  time: 0.2735  data_time: 0.0284  lr: 8.089e-05  max_mem: 6513M
[12/11 01:23:53 d2.utils.events]:  eta: 0:00:54  iter: 9799  total_loss: 2.492  loss_sem_seg: 1.166  loss_center: 0.5226  loss_offset: 0.688  time: 0.2735  data_time: 0.0267  lr: 7.4271e-05  max_mem: 6513M
[12/11 01:23:58 d2.utils.events]:  eta: 0:00:49  iter: 9819  total_loss: 2.286  loss_sem_seg: 0.9746  loss_center: 0.6207  loss_offset: 0.676  time: 0.2735  data_time: 0.0291  lr: 6.7585e-05  max_mem: 6513M
[12/11 01:24:04 d2.utils.events]:  eta: 0:00:43  iter: 9839  total_loss: 2.449  loss_sem_seg: 1.152  loss_center: 0.5848  loss_offset: 0.7753  time: 0.2735  data_time: 0.0310  lr: 6.0825e-05  max_mem: 6513M
[12/11 01:24:09 d2.utils.events]:  eta: 0:00:38  iter: 9859  total_loss: 2.459  loss_sem_seg: 0.9705  loss_center: 0.613  loss_offset: 0.6923  time: 0.2735  data_time: 0.0271  lr: 5.3981e-05  max_mem: 6513M
[12/11 01:24:15 d2.utils.events]:  eta: 0:00:32  iter: 9879  total_loss: 2.328  loss_sem_seg: 0.94  loss_center: 0.429  loss_offset: 0.7036  time: 0.2735  data_time: 0.0285  lr: 4.7038e-05  max_mem: 6513M
[12/11 01:24:20 d2.utils.events]:  eta: 0:00:27  iter: 9899  total_loss: 2.479  loss_sem_seg: 1.033  loss_center: 0.5698  loss_offset: 0.7379  time: 0.2735  data_time: 0.0276  lr: 3.9979e-05  max_mem: 6513M
[12/11 01:24:26 d2.utils.events]:  eta: 0:00:21  iter: 9919  total_loss: 2.379  loss_sem_seg: 1.085  loss_center: 0.6683  loss_offset: 0.6604  time: 0.2735  data_time: 0.0297  lr: 3.2778e-05  max_mem: 6513M
[12/11 01:24:31 d2.utils.events]:  eta: 0:00:16  iter: 9939  total_loss: 2.6  loss_sem_seg: 1.013  loss_center: 0.6324  loss_offset: 0.6269  time: 0.2735  data_time: 0.0292  lr: 2.5394e-05  max_mem: 6513M
[12/11 01:24:37 d2.utils.events]:  eta: 0:00:10  iter: 9959  total_loss: 2.473  loss_sem_seg: 1.226  loss_center: 0.5472  loss_offset: 0.749  time: 0.2735  data_time: 0.0262  lr: 1.776e-05  max_mem: 6513M
[12/11 01:24:42 d2.utils.events]:  eta: 0:00:05  iter: 9979  total_loss: 2.251  loss_sem_seg: 0.8531  loss_center: 0.6435  loss_offset: 0.8161  time: 0.2735  data_time: 0.0276  lr: 9.7261e-06  max_mem: 6513M
[12/11 01:24:48 fvcore.common.checkpoint]: Saving checkpoint to ./output/model_0009999.pth
[12/11 01:24:48 fvcore.common.checkpoint]: Saving checkpoint to ./output/model_final.pth
[12/11 01:24:48 d2.utils.events]:  eta: 0:00:00  iter: 9999  total_loss: 2.423  loss_sem_seg: 0.9748  loss_center: 0.6467  loss_offset: 0.7545  time: 0.2735  data_time: 0.0265  lr: 6.2797e-07  max_mem: 6513M
[12/11 01:24:49 d2.engine.hooks]: Overall training speed: 9998 iterations in 0:45:34 (0.2735 s / it)
[12/11 01:24:49 d2.engine.hooks]: Total training time: 0:45:41 (0:00:07 on hooks)
[12/11 01:24:50 d2.data.dataset_mapper]: [DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(640, 640), max_size=640, sample_style='choice')]
[12/11 01:24:50 d2.data.common]: Serializing the dataset using: <class 'detectron2.data.common.NumpySerializedList'>
[12/11 01:24:50 d2.data.common]: Serializing 5000 elements to byte tensors and concatenating them all ...
[12/11 01:24:50 d2.data.common]: Serialized dataset takes 3.40 MiB
/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:481: UserWarning: This DataLoader will create 10 worker processes in total. Our suggested max number of worker in current system is 8, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.
  cpuset_checked))
[12/11 01:24:50 d2.evaluation.evaluator]: Start inference on 5000 batches
/usr/local/lib/python3.7/dist-packages/torch/functional.py:445: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at  ../aten/src/ATen/native/TensorShape.cpp:2157.)
  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]
[12/11 01:24:52 d2.evaluation.evaluator]: Inference done 11/5000. Dataloading: 0.0010 s/iter. Inference: 0.0517 s/iter. Eval: 0.0370 s/iter. Total: 0.0898 s/iter. ETA=0:07:27
[12/11 01:24:57 d2.evaluation.evaluator]: Inference done 73/5000. Dataloading: 0.0011 s/iter. Inference: 0.0494 s/iter. Eval: 0.0316 s/iter. Total: 0.0821 s/iter. ETA=0:06:44
[12/11 01:25:02 d2.evaluation.evaluator]: Inference done 127/5000. Dataloading: 0.0012 s/iter. Inference: 0.0514 s/iter. Eval: 0.0342 s/iter. Total: 0.0868 s/iter. ETA=0:07:02
[12/11 01:25:07 d2.evaluation.evaluator]: Inference done 182/5000. Dataloading: 0.0012 s/iter. Inference: 0.0523 s/iter. Eval: 0.0348 s/iter. Total: 0.0884 s/iter. ETA=0:07:05
[12/11 01:25:12 d2.evaluation.evaluator]: Inference done 241/5000. Dataloading: 0.0012 s/iter. Inference: 0.0520 s/iter. Eval: 0.0344 s/iter. Total: 0.0876 s/iter. ETA=0:06:57
[12/11 01:25:17 d2.evaluation.evaluator]: Inference done 297/5000. Dataloading: 0.0012 s/iter. Inference: 0.0521 s/iter. Eval: 0.0346 s/iter. Total: 0.0880 s/iter. ETA=0:06:53
[12/11 01:25:22 d2.evaluation.evaluator]: Inference done 353/5000. Dataloading: 0.0012 s/iter. Inference: 0.0522 s/iter. Eval: 0.0348 s/iter. Total: 0.0882 s/iter. ETA=0:06:50
[12/11 01:25:27 d2.evaluation.evaluator]: Inference done 411/5000. Dataloading: 0.0012 s/iter. Inference: 0.0520 s/iter. Eval: 0.0347 s/iter. Total: 0.0880 s/iter. ETA=0:06:44
[12/11 01:25:32 d2.evaluation.evaluator]: Inference done 471/5000. Dataloading: 0.0012 s/iter. Inference: 0.0517 s/iter. Eval: 0.0345 s/iter. Total: 0.0874 s/iter. ETA=0:06:36
[12/11 01:25:37 d2.evaluation.evaluator]: Inference done 528/5000. Dataloading: 0.0012 s/iter. Inference: 0.0517 s/iter. Eval: 0.0346 s/iter. Total: 0.0876 s/iter. ETA=0:06:31
[12/11 01:25:42 d2.evaluation.evaluator]: Inference done 579/5000. Dataloading: 0.0012 s/iter. Inference: 0.0524 s/iter. Eval: 0.0348 s/iter. Total: 0.0886 s/iter. ETA=0:06:31
[12/11 01:25:48 d2.evaluation.evaluator]: Inference done 635/5000. Dataloading: 0.0012 s/iter. Inference: 0.0524 s/iter. Eval: 0.0349 s/iter. Total: 0.0887 s/iter. ETA=0:06:27
[12/11 01:25:53 d2.evaluation.evaluator]: Inference done 692/5000. Dataloading: 0.0012 s/iter. Inference: 0.0524 s/iter. Eval: 0.0350 s/iter. Total: 0.0887 s/iter. ETA=0:06:22
[12/11 01:25:58 d2.evaluation.evaluator]: Inference done 749/5000. Dataloading: 0.0012 s/iter. Inference: 0.0523 s/iter. Eval: 0.0350 s/iter. Total: 0.0887 s/iter. ETA=0:06:16
[12/11 01:26:03 d2.evaluation.evaluator]: Inference done 805/5000. Dataloading: 0.0012 s/iter. Inference: 0.0523 s/iter. Eval: 0.0351 s/iter. Total: 0.0888 s/iter. ETA=0:06:12
[12/11 01:26:08 d2.evaluation.evaluator]: Inference done 863/5000. Dataloading: 0.0012 s/iter. Inference: 0.0523 s/iter. Eval: 0.0350 s/iter. Total: 0.0886 s/iter. ETA=0:06:06
[12/11 01:26:13 d2.evaluation.evaluator]: Inference done 924/5000. Dataloading: 0.0012 s/iter. Inference: 0.0520 s/iter. Eval: 0.0349 s/iter. Total: 0.0882 s/iter. ETA=0:05:59
[12/11 01:26:18 d2.evaluation.evaluator]: Inference done 982/5000. Dataloading: 0.0012 s/iter. Inference: 0.0519 s/iter. Eval: 0.0349 s/iter. Total: 0.0881 s/iter. ETA=0:05:54
[12/11 01:26:23 d2.evaluation.evaluator]: Inference done 1039/5000. Dataloading: 0.0012 s/iter. Inference: 0.0519 s/iter. Eval: 0.0349 s/iter. Total: 0.0882 s/iter. ETA=0:05:49
[12/11 01:26:28 d2.evaluation.evaluator]: Inference done 1098/5000. Dataloading: 0.0012 s/iter. Inference: 0.0519 s/iter. Eval: 0.0348 s/iter. Total: 0.0880 s/iter. ETA=0:05:43
[12/11 01:26:33 d2.evaluation.evaluator]: Inference done 1158/5000. Dataloading: 0.0012 s/iter. Inference: 0.0517 s/iter. Eval: 0.0347 s/iter. Total: 0.0878 s/iter. ETA=0:05:37
[12/11 01:26:38 d2.evaluation.evaluator]: Inference done 1214/5000. Dataloading: 0.0012 s/iter. Inference: 0.0518 s/iter. Eval: 0.0348 s/iter. Total: 0.0879 s/iter. ETA=0:05:32
[12/11 01:26:43 d2.evaluation.evaluator]: Inference done 1267/5000. Dataloading: 0.0013 s/iter. Inference: 0.0520 s/iter. Eval: 0.0349 s/iter. Total: 0.0882 s/iter. ETA=0:05:29
[12/11 01:26:48 d2.evaluation.evaluator]: Inference done 1325/5000. Dataloading: 0.0013 s/iter. Inference: 0.0520 s/iter. Eval: 0.0349 s/iter. Total: 0.0882 s/iter. ETA=0:05:24
[12/11 01:26:53 d2.evaluation.evaluator]: Inference done 1382/5000. Dataloading: 0.0013 s/iter. Inference: 0.0520 s/iter. Eval: 0.0349 s/iter. Total: 0.0882 s/iter. ETA=0:05:19
[12/11 01:26:58 d2.evaluation.evaluator]: Inference done 1439/5000. Dataloading: 0.0013 s/iter. Inference: 0.0521 s/iter. Eval: 0.0349 s/iter. Total: 0.0883 s/iter. ETA=0:05:14
[12/11 01:27:03 d2.evaluation.evaluator]: Inference done 1496/5000. Dataloading: 0.0013 s/iter. Inference: 0.0521 s/iter. Eval: 0.0349 s/iter. Total: 0.0883 s/iter. ETA=0:05:09
[12/11 01:27:08 d2.evaluation.evaluator]: Inference done 1553/5000. Dataloading: 0.0013 s/iter. Inference: 0.0521 s/iter. Eval: 0.0349 s/iter. Total: 0.0883 s/iter. ETA=0:05:04
[12/11 01:27:13 d2.evaluation.evaluator]: Inference done 1606/5000. Dataloading: 0.0013 s/iter. Inference: 0.0522 s/iter. Eval: 0.0350 s/iter. Total: 0.0885 s/iter. ETA=0:05:00
[12/11 01:27:19 d2.evaluation.evaluator]: Inference done 1664/5000. Dataloading: 0.0013 s/iter. Inference: 0.0522 s/iter. Eval: 0.0350 s/iter. Total: 0.0885 s/iter. ETA=0:04:55
[12/11 01:27:24 d2.evaluation.evaluator]: Inference done 1721/5000. Dataloading: 0.0013 s/iter. Inference: 0.0522 s/iter. Eval: 0.0350 s/iter. Total: 0.0885 s/iter. ETA=0:04:50
[12/11 01:27:29 d2.evaluation.evaluator]: Inference done 1780/5000. Dataloading: 0.0013 s/iter. Inference: 0.0521 s/iter. Eval: 0.0350 s/iter. Total: 0.0884 s/iter. ETA=0:04:44
[12/11 01:27:34 d2.evaluation.evaluator]: Inference done 1838/5000. Dataloading: 0.0013 s/iter. Inference: 0.0520 s/iter. Eval: 0.0350 s/iter. Total: 0.0884 s/iter. ETA=0:04:39
[12/11 01:27:39 d2.evaluation.evaluator]: Inference done 1894/5000. Dataloading: 0.0013 s/iter. Inference: 0.0521 s/iter. Eval: 0.0350 s/iter. Total: 0.0884 s/iter. ETA=0:04:34
[12/11 01:27:44 d2.evaluation.evaluator]: Inference done 1954/5000. Dataloading: 0.0013 s/iter. Inference: 0.0520 s/iter. Eval: 0.0350 s/iter. Total: 0.0883 s/iter. ETA=0:04:29
[12/11 01:27:49 d2.evaluation.evaluator]: Inference done 2009/5000. Dataloading: 0.0013 s/iter. Inference: 0.0520 s/iter. Eval: 0.0351 s/iter. Total: 0.0884 s/iter. ETA=0:04:24
[12/11 01:27:54 d2.evaluation.evaluator]: Inference done 2065/5000. Dataloading: 0.0013 s/iter. Inference: 0.0521 s/iter. Eval: 0.0351 s/iter. Total: 0.0885 s/iter. ETA=0:04:19
[12/11 01:27:59 d2.evaluation.evaluator]: Inference done 2123/5000. Dataloading: 0.0013 s/iter. Inference: 0.0520 s/iter. Eval: 0.0351 s/iter. Total: 0.0884 s/iter. ETA=0:04:14
[12/11 01:28:04 d2.evaluation.evaluator]: Inference done 2180/5000. Dataloading: 0.0013 s/iter. Inference: 0.0520 s/iter. Eval: 0.0351 s/iter. Total: 0.0884 s/iter. ETA=0:04:09
[12/11 01:28:09 d2.evaluation.evaluator]: Inference done 2239/5000. Dataloading: 0.0013 s/iter. Inference: 0.0520 s/iter. Eval: 0.0350 s/iter. Total: 0.0884 s/iter. ETA=0:04:03
[12/11 01:28:14 d2.evaluation.evaluator]: Inference done 2298/5000. Dataloading: 0.0013 s/iter. Inference: 0.0520 s/iter. Eval: 0.0350 s/iter. Total: 0.0883 s/iter. ETA=0:03:58
[12/11 01:28:19 d2.evaluation.evaluator]: Inference done 2358/5000. Dataloading: 0.0013 s/iter. Inference: 0.0519 s/iter. Eval: 0.0350 s/iter. Total: 0.0882 s/iter. ETA=0:03:52
[12/11 01:28:24 d2.evaluation.evaluator]: Inference done 2413/5000. Dataloading: 0.0013 s/iter. Inference: 0.0520 s/iter. Eval: 0.0350 s/iter. Total: 0.0883 s/iter. ETA=0:03:48
[12/11 01:28:29 d2.evaluation.evaluator]: Inference done 2470/5000. Dataloading: 0.0013 s/iter. Inference: 0.0520 s/iter. Eval: 0.0350 s/iter. Total: 0.0883 s/iter. ETA=0:03:43
[12/11 01:28:34 d2.evaluation.evaluator]: Inference done 2525/5000. Dataloading: 0.0013 s/iter. Inference: 0.0520 s/iter. Eval: 0.0350 s/iter. Total: 0.0884 s/iter. ETA=0:03:38
[12/11 01:28:39 d2.evaluation.evaluator]: Inference done 2580/5000. Dataloading: 0.0013 s/iter. Inference: 0.0521 s/iter. Eval: 0.0350 s/iter. Total: 0.0884 s/iter. ETA=0:03:34
[12/11 01:28:44 d2.evaluation.evaluator]: Inference done 2635/5000. Dataloading: 0.0013 s/iter. Inference: 0.0522 s/iter. Eval: 0.0350 s/iter. Total: 0.0885 s/iter. ETA=0:03:29
[12/11 01:28:50 d2.evaluation.evaluator]: Inference done 2696/5000. Dataloading: 0.0013 s/iter. Inference: 0.0521 s/iter. Eval: 0.0350 s/iter. Total: 0.0884 s/iter. ETA=0:03:23
[12/11 01:28:55 d2.evaluation.evaluator]: Inference done 2756/5000. Dataloading: 0.0013 s/iter. Inference: 0.0520 s/iter. Eval: 0.0349 s/iter. Total: 0.0883 s/iter. ETA=0:03:18
[12/11 01:29:00 d2.evaluation.evaluator]: Inference done 2815/5000. Dataloading: 0.0013 s/iter. Inference: 0.0520 s/iter. Eval: 0.0349 s/iter. Total: 0.0882 s/iter. ETA=0:03:12
[12/11 01:29:05 d2.evaluation.evaluator]: Inference done 2873/5000. Dataloading: 0.0013 s/iter. Inference: 0.0520 s/iter. Eval: 0.0349 s/iter. Total: 0.0882 s/iter. ETA=0:03:07
[12/11 01:29:10 d2.evaluation.evaluator]: Inference done 2930/5000. Dataloading: 0.0013 s/iter. Inference: 0.0520 s/iter. Eval: 0.0349 s/iter. Total: 0.0882 s/iter. ETA=0:03:02
[12/11 01:29:15 d2.evaluation.evaluator]: Inference done 2988/5000. Dataloading: 0.0013 s/iter. Inference: 0.0520 s/iter. Eval: 0.0349 s/iter. Total: 0.0882 s/iter. ETA=0:02:57
[12/11 01:29:20 d2.evaluation.evaluator]: Inference done 3048/5000. Dataloading: 0.0013 s/iter. Inference: 0.0519 s/iter. Eval: 0.0348 s/iter. Total: 0.0881 s/iter. ETA=0:02:51
[12/11 01:29:25 d2.evaluation.evaluator]: Inference done 3108/5000. Dataloading: 0.0013 s/iter. Inference: 0.0519 s/iter. Eval: 0.0348 s/iter. Total: 0.0880 s/iter. ETA=0:02:46
[12/11 01:29:30 d2.evaluation.evaluator]: Inference done 3163/5000. Dataloading: 0.0013 s/iter. Inference: 0.0519 s/iter. Eval: 0.0349 s/iter. Total: 0.0881 s/iter. ETA=0:02:41
[12/11 01:29:35 d2.evaluation.evaluator]: Inference done 3219/5000. Dataloading: 0.0013 s/iter. Inference: 0.0520 s/iter. Eval: 0.0349 s/iter. Total: 0.0882 s/iter. ETA=0:02:37
[12/11 01:29:40 d2.evaluation.evaluator]: Inference done 3276/5000. Dataloading: 0.0013 s/iter. Inference: 0.0520 s/iter. Eval: 0.0349 s/iter. Total: 0.0882 s/iter. ETA=0:02:31
[12/11 01:29:45 d2.evaluation.evaluator]: Inference done 3332/5000. Dataloading: 0.0013 s/iter. Inference: 0.0520 s/iter. Eval: 0.0349 s/iter. Total: 0.0882 s/iter. ETA=0:02:27
[12/11 01:29:50 d2.evaluation.evaluator]: Inference done 3388/5000. Dataloading: 0.0013 s/iter. Inference: 0.0520 s/iter. Eval: 0.0349 s/iter. Total: 0.0882 s/iter. ETA=0:02:22
[12/11 01:29:55 d2.evaluation.evaluator]: Inference done 3443/5000. Dataloading: 0.0013 s/iter. Inference: 0.0520 s/iter. Eval: 0.0349 s/iter. Total: 0.0883 s/iter. ETA=0:02:17
[12/11 01:30:00 d2.evaluation.evaluator]: Inference done 3504/5000. Dataloading: 0.0013 s/iter. Inference: 0.0520 s/iter. Eval: 0.0349 s/iter. Total: 0.0882 s/iter. ETA=0:02:11
[12/11 01:30:05 d2.evaluation.evaluator]: Inference done 3559/5000. Dataloading: 0.0013 s/iter. Inference: 0.0520 s/iter. Eval: 0.0349 s/iter. Total: 0.0883 s/iter. ETA=0:02:07
[12/11 01:30:10 d2.evaluation.evaluator]: Inference done 3616/5000. Dataloading: 0.0013 s/iter. Inference: 0.0520 s/iter. Eval: 0.0349 s/iter. Total: 0.0883 s/iter. ETA=0:02:02
[12/11 01:30:15 d2.evaluation.evaluator]: Inference done 3676/5000. Dataloading: 0.0013 s/iter. Inference: 0.0520 s/iter. Eval: 0.0349 s/iter. Total: 0.0882 s/iter. ETA=0:01:56
[12/11 01:30:20 d2.evaluation.evaluator]: Inference done 3734/5000. Dataloading: 0.0013 s/iter. Inference: 0.0519 s/iter. Eval: 0.0349 s/iter. Total: 0.0882 s/iter. ETA=0:01:51
[12/11 01:30:25 d2.evaluation.evaluator]: Inference done 3790/5000. Dataloading: 0.0013 s/iter. Inference: 0.0520 s/iter. Eval: 0.0349 s/iter. Total: 0.0882 s/iter. ETA=0:01:46
[12/11 01:30:30 d2.evaluation.evaluator]: Inference done 3849/5000. Dataloading: 0.0013 s/iter. Inference: 0.0520 s/iter. Eval: 0.0349 s/iter. Total: 0.0881 s/iter. ETA=0:01:41
[12/11 01:30:36 d2.evaluation.evaluator]: Inference done 3909/5000. Dataloading: 0.0013 s/iter. Inference: 0.0519 s/iter. Eval: 0.0348 s/iter. Total: 0.0881 s/iter. ETA=0:01:36
[12/11 01:30:41 d2.evaluation.evaluator]: Inference done 3968/5000. Dataloading: 0.0013 s/iter. Inference: 0.0519 s/iter. Eval: 0.0348 s/iter. Total: 0.0881 s/iter. ETA=0:01:30
[12/11 01:30:46 d2.evaluation.evaluator]: Inference done 4024/5000. Dataloading: 0.0013 s/iter. Inference: 0.0519 s/iter. Eval: 0.0349 s/iter. Total: 0.0881 s/iter. ETA=0:01:25
[12/11 01:30:51 d2.evaluation.evaluator]: Inference done 4079/5000. Dataloading: 0.0013 s/iter. Inference: 0.0519 s/iter. Eval: 0.0349 s/iter. Total: 0.0881 s/iter. ETA=0:01:21
[12/11 01:30:56 d2.evaluation.evaluator]: Inference done 4138/5000. Dataloading: 0.0013 s/iter. Inference: 0.0519 s/iter. Eval: 0.0349 s/iter. Total: 0.0881 s/iter. ETA=0:01:15
[12/11 01:31:01 d2.evaluation.evaluator]: Inference done 4192/5000. Dataloading: 0.0013 s/iter. Inference: 0.0520 s/iter. Eval: 0.0349 s/iter. Total: 0.0882 s/iter. ETA=0:01:11
[12/11 01:31:06 d2.evaluation.evaluator]: Inference done 4249/5000. Dataloading: 0.0013 s/iter. Inference: 0.0520 s/iter. Eval: 0.0349 s/iter. Total: 0.0882 s/iter. ETA=0:01:06
[12/11 01:31:11 d2.evaluation.evaluator]: Inference done 4307/5000. Dataloading: 0.0013 s/iter. Inference: 0.0519 s/iter. Eval: 0.0349 s/iter. Total: 0.0882 s/iter. ETA=0:01:01
[12/11 01:31:16 d2.evaluation.evaluator]: Inference done 4369/5000. Dataloading: 0.0013 s/iter. Inference: 0.0519 s/iter. Eval: 0.0348 s/iter. Total: 0.0881 s/iter. ETA=0:00:55
[12/11 01:31:21 d2.evaluation.evaluator]: Inference done 4426/5000. Dataloading: 0.0013 s/iter. Inference: 0.0519 s/iter. Eval: 0.0348 s/iter. Total: 0.0881 s/iter. ETA=0:00:50
[12/11 01:31:26 d2.evaluation.evaluator]: Inference done 4483/5000. Dataloading: 0.0013 s/iter. Inference: 0.0519 s/iter. Eval: 0.0349 s/iter. Total: 0.0881 s/iter. ETA=0:00:45
[12/11 01:31:31 d2.evaluation.evaluator]: Inference done 4541/5000. Dataloading: 0.0013 s/iter. Inference: 0.0519 s/iter. Eval: 0.0349 s/iter. Total: 0.0880 s/iter. ETA=0:00:40
[12/11 01:31:36 d2.evaluation.evaluator]: Inference done 4598/5000. Dataloading: 0.0013 s/iter. Inference: 0.0519 s/iter. Eval: 0.0349 s/iter. Total: 0.0880 s/iter. ETA=0:00:35
[12/11 01:31:41 d2.evaluation.evaluator]: Inference done 4655/5000. Dataloading: 0.0013 s/iter. Inference: 0.0519 s/iter. Eval: 0.0349 s/iter. Total: 0.0881 s/iter. ETA=0:00:30
[12/11 01:31:46 d2.evaluation.evaluator]: Inference done 4713/5000. Dataloading: 0.0013 s/iter. Inference: 0.0519 s/iter. Eval: 0.0349 s/iter. Total: 0.0880 s/iter. ETA=0:00:25
[12/11 01:31:51 d2.evaluation.evaluator]: Inference done 4773/5000. Dataloading: 0.0013 s/iter. Inference: 0.0518 s/iter. Eval: 0.0348 s/iter. Total: 0.0880 s/iter. ETA=0:00:19
[12/11 01:31:56 d2.evaluation.evaluator]: Inference done 4827/5000. Dataloading: 0.0013 s/iter. Inference: 0.0519 s/iter. Eval: 0.0349 s/iter. Total: 0.0880 s/iter. ETA=0:00:15
[12/11 01:32:01 d2.evaluation.evaluator]: Inference done 4887/5000. Dataloading: 0.0013 s/iter. Inference: 0.0518 s/iter. Eval: 0.0348 s/iter. Total: 0.0880 s/iter. ETA=0:00:09
[12/11 01:32:06 d2.evaluation.evaluator]: Inference done 4941/5000. Dataloading: 0.0013 s/iter. Inference: 0.0519 s/iter. Eval: 0.0349 s/iter. Total: 0.0880 s/iter. ETA=0:00:05
[12/11 01:32:11 d2.evaluation.evaluator]: Inference done 5000/5000. Dataloading: 0.0013 s/iter. Inference: 0.0518 s/iter. Eval: 0.0349 s/iter. Total: 0.0880 s/iter. ETA=0:00:00
[12/11 01:32:12 d2.evaluation.evaluator]: Total inference time: 0:07:19.842835 (0.088057 s / iter per device, on 1 devices)
[12/11 01:32:12 d2.evaluation.evaluator]: Total inference pure compute time: 0:04:18 (0.051836 s / iter per device, on 1 devices)
[12/11 01:32:12 d2.evaluation.panoptic_evaluation]: Writing all panoptic predictions to /tmp/panoptic_evalmn75w_3g ...
[12/11 01:32:36 d2.evaluation.panoptic_evaluation]: Panoptic Evaluation Results:
|        |   PQ   |   SQ   |   RQ   |  #categories  |
|:------:|:------:|:------:|:------:|:-------------:|
|  All   | 11.550 | 52.864 | 15.794 |      133      |
| Things | 9.353  | 53.097 | 13.307 |      80       |
| Stuff  | 14.867 | 52.512 | 19.547 |      53       |
[12/11 01:32:36 d2.evaluation.coco_evaluation]: Preparing results for COCO format ...
[12/11 01:32:36 d2.evaluation.coco_evaluation]: Saving results to ./output/inference/coco_instances_results.json
[12/11 01:32:36 d2.evaluation.coco_evaluation]: Evaluating predictions with unofficial COCO API...
Loading and preparing results...
DONE (t=0.04s)
creating index...
index created!
[12/11 01:32:37 d2.evaluation.fast_eval_api]: Evaluate annotation type *bbox*
[12/11 01:32:45 d2.evaluation.fast_eval_api]: COCOeval_opt.evaluate() finished in 8.08 seconds.
[12/11 01:32:45 d2.evaluation.fast_eval_api]: Accumulating evaluation results...
[12/11 01:32:45 d2.evaluation.fast_eval_api]: COCOeval_opt.accumulate() finished in 0.63 seconds.
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.020
 Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.053
 Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.012
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.003
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.025
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.032
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.037
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.058
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.059
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.004
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.048
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.105
[12/11 01:32:45 d2.evaluation.coco_evaluation]: Evaluation results for bbox: 
|  AP   |  AP50  |  AP75  |  APs  |  APm  |  APl  |
|:-----:|:------:|:------:|:-----:|:-----:|:-----:|
| 1.975 | 5.252  | 1.238  | 0.335 | 2.451 | 3.249 |
[12/11 01:32:45 d2.evaluation.coco_evaluation]: Per-category bbox AP: 
| category      | AP     | category     | AP     | category       | AP    |
|:--------------|:-------|:-------------|:-------|:---------------|:------|
| person        | 7.206  | bicycle      | 1.629  | car            | 2.592 |
| motorcycle    | 3.279  | airplane     | 4.744  | bus            | 7.001 |
| train         | 4.089  | truck        | 1.667  | boat           | 0.465 |
| traffic light | 0.412  | fire hydrant | 7.593  | stop sign      | 9.663 |
| parking meter | 0.902  | bench        | 0.447  | bird           | 1.322 |
| cat           | 3.882  | dog          | 5.248  | horse          | 5.985 |
| sheep         | 2.962  | cow          | 2.220  | elephant       | 9.514 |
| bear          | 10.055 | zebra        | 11.331 | giraffe        | 9.877 |
| backpack      | 0.000  | umbrella     | 1.050  | handbag        | 0.000 |
| tie           | 0.000  | suitcase     | 1.417  | frisbee        | 0.357 |
| skis          | 0.000  | snowboard    | 0.000  | sports ball    | 0.198 |
| kite          | 1.463  | baseball bat | 0.000  | baseball glove | 0.000 |
| skateboard    | 0.000  | surfboard    | 1.192  | tennis racket  | 2.847 |
| bottle        | 0.115  | wine glass   | 0.060  | cup            | 0.146 |
| fork          | 0.000  | knife        | 0.000  | spoon          | 0.000 |
| bowl          | 0.701  | banana       | 0.755  | apple          | 0.635 |
| sandwich      | 0.069  | orange       | 1.580  | broccoli       | 0.164 |
| carrot        | 0.297  | hot dog      | 0.396  | pizza          | 1.493 |
| donut         | 1.014  | cake         | 0.973  | chair          | 0.782 |
| couch         | 1.550  | potted plant | 0.474  | bed            | 2.388 |
| dining table  | 0.844  | toilet       | 4.816  | tv             | 4.148 |
| laptop        | 1.334  | mouse        | 0.000  | remote         | 0.000 |
| keyboard      | 0.577  | cell phone   | 0.077  | microwave      | 0.000 |
| oven          | 0.536  | toaster      | 0.000  | sink           | 2.158 |
| refrigerator  | 0.452  | book         | 0.373  | clock          | 4.865 |
| vase          | 0.617  | scissors     | 0.000  | teddy bear     | 1.010 |
| hair drier    | 0.000  | toothbrush   | 0.000  |                |       |
Loading and preparing results...
DONE (t=0.46s)
creating index...
index created!
[12/11 01:32:47 d2.evaluation.fast_eval_api]: Evaluate annotation type *segm*
[12/11 01:32:56 d2.evaluation.fast_eval_api]: COCOeval_opt.evaluate() finished in 9.29 seconds.
[12/11 01:32:56 d2.evaluation.fast_eval_api]: Accumulating evaluation results...
[12/11 01:32:57 d2.evaluation.fast_eval_api]: COCOeval_opt.accumulate() finished in 0.69 seconds.
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.020
 Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.054
 Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.012
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.002
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.023
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.052
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.035
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.051
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.051
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.004
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.044
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.090
[12/11 01:32:59 d2.evaluation.coco_evaluation]: Evaluation results for segm: 
|  AP   |  AP50  |  AP75  |  APs  |  APm  |  APl  |
|:-----:|:------:|:------:|:-----:|:-----:|:-----:|
| 1.990 | 5.360  | 1.191  | 0.238 | 2.328 | 5.219 |
[12/11 01:32:59 d2.evaluation.coco_evaluation]: Per-category segm AP: 
| category      | AP     | category     | AP     | category       | AP     |
|:--------------|:-------|:-------------|:-------|:---------------|:-------|
| person        | 4.242  | bicycle      | 0.331  | car            | 2.444  |
| motorcycle    | 1.682  | airplane     | 3.675  | bus            | 5.614  |
| train         | 7.436  | truck        | 0.971  | boat           | 0.358  |
| traffic light | 0.388  | fire hydrant | 10.151 | stop sign      | 15.425 |
| parking meter | 1.127  | bench        | 0.217  | bird           | 1.896  |
| cat           | 4.887  | dog          | 7.805  | horse          | 3.268  |
| sheep         | 3.020  | cow          | 2.483  | elephant       | 7.772  |
| bear          | 11.083 | zebra        | 7.677  | giraffe        | 7.179  |
| backpack      | 0.000  | umbrella     | 1.510  | handbag        | 0.000  |
| tie           | 0.000  | suitcase     | 1.603  | frisbee        | 0.681  |
| skis          | 0.000  | snowboard    | 0.000  | sports ball    | 0.099  |
| kite          | 1.535  | baseball bat | 0.000  | baseball glove | 0.000  |
| skateboard    | 0.000  | surfboard    | 0.784  | tennis racket  | 7.247  |
| bottle        | 0.284  | wine glass   | 0.095  | cup            | 0.377  |
| fork          | 0.000  | knife        | 0.000  | spoon          | 0.000  |
| bowl          | 0.945  | banana       | 0.274  | apple          | 0.211  |
| sandwich      | 0.023  | orange       | 1.760  | broccoli       | 0.519  |
| carrot        | 0.149  | hot dog      | 0.416  | pizza          | 1.345  |
| donut         | 1.179  | cake         | 0.727  | chair          | 0.546  |
| couch         | 0.756  | potted plant | 0.350  | bed            | 1.371  |
| dining table  | 0.058  | toilet       | 6.686  | tv             | 4.904  |
| laptop        | 0.730  | mouse        | 0.000  | remote         | 0.000  |
| keyboard      | 0.619  | cell phone   | 0.099  | microwave      | 0.000  |
| oven          | 0.254  | toaster      | 0.000  | sink           | 1.544  |
| refrigerator  | 0.107  | book         | 0.163  | clock          | 6.872  |
| vase          | 0.761  | scissors     | 0.000  | teddy bear     | 0.450  |
| hair drier    | 0.000  | toothbrush   | 0.000  |                |        |
[12/11 01:33:04 d2.engine.defaults]: Evaluation results for coco_2017_val_panoptic in csv format:
[12/11 01:33:04 d2.evaluation.testing]: copypaste: Task: panoptic_seg
[12/11 01:33:04 d2.evaluation.testing]: copypaste: PQ,SQ,RQ,PQ_th,SQ_th,RQ_th,PQ_st,SQ_st,RQ_st
[12/11 01:33:04 d2.evaluation.testing]: copypaste: 11.5501,52.8637,15.7937,9.3529,53.0967,13.3074,14.8667,52.5120,19.5466
[12/11 01:33:04 d2.evaluation.testing]: copypaste: Task: bbox
[12/11 01:33:04 d2.evaluation.testing]: copypaste: AP,AP50,AP75,APs,APm,APl
[12/11 01:33:04 d2.evaluation.testing]: copypaste: 1.9751,5.2522,1.2381,0.3345,2.4512,3.2491
[12/11 01:33:04 d2.evaluation.testing]: copypaste: Task: segm
[12/11 01:33:04 d2.evaluation.testing]: copypaste: AP,AP50,AP75,APs,APm,APl
[12/11 01:33:04 d2.evaluation.testing]: copypaste: 1.9895,5.3601,1.1912,0.2384,2.3283,5.2189