env: DETECTRON2_DATASETS=/content/datasets
Command Line Args: Namespace(config_file='./detectron2/projects/Panoptic-DeepLab/configs/COCO-PanopticSegmentation/panoptic_deeplab_R_52_os16_mg124_poly_200k_bs64_crop_640_640_coco_dsconv.yaml', dist_url='tcp://127.0.0.1:49152', eval_only=False, machine_rank=0, num_gpus=1, num_machines=1, opts=['MODEL.RESNETS.NORM', 'BN', 'MODEL.INS_EMBED_HEAD.NORM', 'BN', 'MODEL.SEM_SEG_HEAD.NORM', 'BN', 'SOLVER.MAX_ITER', '7000', 'SOLVER.IMS_PER_BATCH', '5', 'SOLVER.BASE_LR', '0.0025', 'MODEL.BACKBONE.FREEZE_AT', '2'], resume=False)
Loading config ./detectron2/projects/Panoptic-DeepLab/configs/COCO-PanopticSegmentation/panoptic_deeplab_R_52_os16_mg124_poly_200k_bs64_crop_640_640_coco_dsconv.yaml with yaml.unsafe_load. Your machine may be at risk if the file contains malicious content.
[12/09 10:59:31 detectron2]: Rank of current process: 0. World size: 1
[12/09 10:59:32 detectron2]: Environment info:
----------------------  ----------------------------------------------------------------
sys.platform            linux
Python                  3.7.12 (default, Jan 15 2022, 18:48:18) [GCC 7.5.0]
numpy                   1.21.5
detectron2              0.6 @/content/detectron2/detectron2
Compiler                GCC 7.5
CUDA compiler           CUDA 11.1
detectron2 arch flags   7.0
DETECTRON2_ENV_MODULE   <not set>
PyTorch                 1.10.0+cu111 @/usr/local/lib/python3.7/dist-packages/torch
PyTorch debug build     False
GPU available           Yes
GPU 0                   Tesla V100-SXM2-16GB (arch=7.0)
Driver version          460.32.03
CUDA_HOME               /usr/local/cuda
Pillow                  7.1.2
torchvision             0.11.1+cu111 @/usr/local/lib/python3.7/dist-packages/torchvision
torchvision arch flags  3.5, 5.0, 6.0, 7.0, 7.5, 8.0, 8.6
fvcore                  0.1.5.post20221122
iopath                  0.1.9
cv2                     4.1.2
----------------------  ----------------------------------------------------------------
PyTorch built with:
  - GCC 7.3
  - C++ Version: 201402
  - Intel(R) Math Kernel Library Version 2020.0.0 Product Build 20191122 for Intel(R) 64 architecture applications
  - Intel(R) MKL-DNN v2.2.3 (Git Hash 7336ca9f055cf1bfa13efb658fe15dc9b41f0740)
  - OpenMP 201511 (a.k.a. OpenMP 4.5)
  - LAPACK is enabled (usually provided by MKL)
  - NNPACK is enabled
  - CPU capability usage: AVX2
  - CUDA Runtime 11.1
  - NVCC architecture flags: -gencode;arch=compute_37,code=sm_37;-gencode;arch=compute_50,code=sm_50;-gencode;arch=compute_60,code=sm_60;-gencode;arch=compute_70,code=sm_70;-gencode;arch=compute_75,code=sm_75;-gencode;arch=compute_80,code=sm_80;-gencode;arch=compute_86,code=sm_86
  - CuDNN 8.0.5
  - Magma 2.5.2
  - Build settings: BLAS_INFO=mkl, BUILD_TYPE=Release, CUDA_VERSION=11.1, CUDNN_VERSION=8.0.5, CXX_COMPILER=/opt/rh/devtoolset-7/root/usr/bin/c++, CXX_FLAGS= -Wno-deprecated -fvisibility-inlines-hidden -DUSE_PTHREADPOOL -fopenmp -DNDEBUG -DUSE_KINETO -DUSE_FBGEMM -DUSE_QNNPACK -DUSE_PYTORCH_QNNPACK -DUSE_XNNPACK -DSYMBOLICATE_MOBILE_DEBUG_HANDLE -DEDGE_PROFILER_USE_KINETO -O2 -fPIC -Wno-narrowing -Wall -Wextra -Werror=return-type -Wno-missing-field-initializers -Wno-type-limits -Wno-array-bounds -Wno-unknown-pragmas -Wno-sign-compare -Wno-unused-parameter -Wno-unused-variable -Wno-unused-function -Wno-unused-result -Wno-unused-local-typedefs -Wno-strict-overflow -Wno-strict-aliasing -Wno-error=deprecated-declarations -Wno-stringop-overflow -Wno-psabi -Wno-error=pedantic -Wno-error=redundant-decls -Wno-error=old-style-cast -fdiagnostics-color=always -faligned-new -Wno-unused-but-set-variable -Wno-maybe-uninitialized -fno-math-errno -fno-trapping-math -Werror=format -Wno-stringop-overflow, LAPACK_INFO=mkl, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, TORCH_VERSION=1.10.0, USE_CUDA=ON, USE_CUDNN=ON, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_MKL=ON, USE_MKLDNN=ON, USE_MPI=OFF, USE_NCCL=ON, USE_NNPACK=ON, USE_OPENMP=ON, 

[12/09 10:59:32 detectron2]: Command line arguments: Namespace(config_file='./detectron2/projects/Panoptic-DeepLab/configs/COCO-PanopticSegmentation/panoptic_deeplab_R_52_os16_mg124_poly_200k_bs64_crop_640_640_coco_dsconv.yaml', dist_url='tcp://127.0.0.1:49152', eval_only=False, machine_rank=0, num_gpus=1, num_machines=1, opts=['MODEL.RESNETS.NORM', 'BN', 'MODEL.INS_EMBED_HEAD.NORM', 'BN', 'MODEL.SEM_SEG_HEAD.NORM', 'BN', 'SOLVER.MAX_ITER', '7000', 'SOLVER.IMS_PER_BATCH', '5', 'SOLVER.BASE_LR', '0.0025', 'MODEL.BACKBONE.FREEZE_AT', '2'], resume=False)
[12/09 10:59:32 detectron2]: Contents of args.config_file=./detectron2/projects/Panoptic-DeepLab/configs/COCO-PanopticSegmentation/panoptic_deeplab_R_52_os16_mg124_poly_200k_bs64_crop_640_640_coco_dsconv.yaml:
_BASE_: ../Cityscapes-PanopticSegmentation/Base-PanopticDeepLab-OS16.yaml
MODEL:
  WEIGHTS: "detectron2://DeepLab/R-52.pkl"
  PIXEL_MEAN: [123.675, 116.280, 103.530]
  PIXEL_STD: [58.395, 57.120, 57.375]
  BACKBONE:
    NAME: "build_resnet_deeplab_backbone"
  RESNETS:
    DEPTH: 50
    NORM: "SyncBN"
    RES5_MULTI_GRID: [1, 2, 4]
    STEM_TYPE: "deeplab"
    STEM_OUT_CHANNELS: 128
    STRIDE_IN_1X1: False
  SEM_SEG_HEAD:
    NUM_CLASSES: 133
    LOSS_TOP_K: 1.0
    USE_DEPTHWISE_SEPARABLE_CONV: True
  PANOPTIC_DEEPLAB:
    STUFF_AREA: 4096
    NMS_KERNEL: 41
    SIZE_DIVISIBILITY: 640
    USE_DEPTHWISE_SEPARABLE_CONV: True
DATASETS:
  TRAIN: ("coco_2017_train_panoptic",)
  TEST: ("coco_2017_val_panoptic",)
SOLVER:
  BASE_LR: 0.0005
  MAX_ITER: 200000
  IMS_PER_BATCH: 64
INPUT:
  FORMAT: "RGB"
  GAUSSIAN_SIGMA: 8
  MIN_SIZE_TRAIN: !!python/object/apply:eval ["[int(x * 0.1 * 640) for x in range(5, 16)]"]
  MIN_SIZE_TRAIN_SAMPLING: "choice"
  MIN_SIZE_TEST: 640
  MAX_SIZE_TRAIN: 960
  MAX_SIZE_TEST: 640
  CROP:
    ENABLED: True
    TYPE: "absolute"
    SIZE: (640, 640)

[12/09 10:59:32 detectron2]: Running with full config:
CUDNN_BENCHMARK: false
DATALOADER:
  ASPECT_RATIO_GROUPING: true
  FILTER_EMPTY_ANNOTATIONS: true
  NUM_WORKERS: 10
  REPEAT_THRESHOLD: 0.0
  SAMPLER_TRAIN: TrainingSampler
DATASETS:
  PRECOMPUTED_PROPOSAL_TOPK_TEST: 1000
  PRECOMPUTED_PROPOSAL_TOPK_TRAIN: 2000
  PROPOSAL_FILES_TEST: []
  PROPOSAL_FILES_TRAIN: []
  TEST:
  - coco_2017_val_panoptic
  TRAIN:
  - coco_2017_train_panoptic
GLOBAL:
  HACK: 1.0
INPUT:
  CROP:
    ENABLED: true
    SINGLE_CATEGORY_MAX_AREA: 1.0
    SIZE:
    - 640
    - 640
    TYPE: absolute
  FORMAT: RGB
  GAUSSIAN_SIGMA: 8
  IGNORE_CROWD_IN_SEMANTIC: false
  IGNORE_STUFF_IN_OFFSET: true
  MASK_FORMAT: polygon
  MAX_SIZE_TEST: 640
  MAX_SIZE_TRAIN: 960
  MIN_SIZE_TEST: 640
  MIN_SIZE_TRAIN:
  - 320
  - 384
  - 448
  - 512
  - 576
  - 640
  - 704
  - 768
  - 832
  - 896
  - 960
  MIN_SIZE_TRAIN_SAMPLING: choice
  RANDOM_FLIP: horizontal
  SMALL_INSTANCE_AREA: 4096
  SMALL_INSTANCE_WEIGHT: 3
MODEL:
  ANCHOR_GENERATOR:
    ANGLES:
    - - -90
      - 0
      - 90
    ASPECT_RATIOS:
    - - 0.5
      - 1.0
      - 2.0
    NAME: DefaultAnchorGenerator
    OFFSET: 0.0
    SIZES:
    - - 32
      - 64
      - 128
      - 256
      - 512
  BACKBONE:
    FREEZE_AT: 2
    NAME: build_resnet_deeplab_backbone
  DEVICE: cuda
  FPN:
    FUSE_TYPE: sum
    IN_FEATURES: []
    NORM: ''
    OUT_CHANNELS: 256
  INS_EMBED_HEAD:
    ASPP_CHANNELS: 256
    ASPP_DILATIONS:
    - 6
    - 12
    - 18
    ASPP_DROPOUT: 0.1
    CENTER_LOSS_WEIGHT: 200.0
    COMMON_STRIDE: 4
    CONVS_DIM: 128
    HEAD_CHANNELS: 32
    IN_FEATURES:
    - res2
    - res3
    - res5
    NAME: PanopticDeepLabInsEmbedHead
    NORM: BN
    OFFSET_LOSS_WEIGHT: 0.01
    PROJECT_CHANNELS:
    - 32
    - 64
    PROJECT_FEATURES:
    - res2
    - res3
  KEYPOINT_ON: false
  LOAD_PROPOSALS: false
  MASK_ON: false
  META_ARCHITECTURE: PanopticDeepLab
  PANOPTIC_DEEPLAB:
    BENCHMARK_NETWORK_SPEED: false
    CENTER_THRESHOLD: 0.1
    NMS_KERNEL: 41
    PREDICT_INSTANCES: true
    SIZE_DIVISIBILITY: 640
    STUFF_AREA: 4096
    TOP_K_INSTANCE: 200
    USE_DEPTHWISE_SEPARABLE_CONV: true
  PANOPTIC_FPN:
    COMBINE:
      ENABLED: true
      INSTANCES_CONFIDENCE_THRESH: 0.5
      OVERLAP_THRESH: 0.5
      STUFF_AREA_LIMIT: 4096
    INSTANCE_LOSS_WEIGHT: 1.0
  PIXEL_MEAN:
  - 123.675
  - 116.28
  - 103.53
  PIXEL_STD:
  - 58.395
  - 57.12
  - 57.375
  PROPOSAL_GENERATOR:
    MIN_SIZE: 0
    NAME: RPN
  RESNETS:
    DEFORM_MODULATED: false
    DEFORM_NUM_GROUPS: 1
    DEFORM_ON_PER_STAGE:
    - false
    - false
    - false
    - false
    DEPTH: 50
    NORM: BN
    NUM_GROUPS: 1
    OUT_FEATURES:
    - res2
    - res3
    - res5
    RES2_OUT_CHANNELS: 256
    RES4_DILATION: 1
    RES5_DILATION: 2
    RES5_MULTI_GRID:
    - 1
    - 2
    - 4
    STEM_OUT_CHANNELS: 128
    STEM_TYPE: deeplab
    STRIDE_IN_1X1: false
    WIDTH_PER_GROUP: 64
  RETINANET:
    BBOX_REG_LOSS_TYPE: smooth_l1
    BBOX_REG_WEIGHTS: &id001
    - 1.0
    - 1.0
    - 1.0
    - 1.0
    FOCAL_LOSS_ALPHA: 0.25
    FOCAL_LOSS_GAMMA: 2.0
    IN_FEATURES:
    - p3
    - p4
    - p5
    - p6
    - p7
    IOU_LABELS:
    - 0
    - -1
    - 1
    IOU_THRESHOLDS:
    - 0.4
    - 0.5
    NMS_THRESH_TEST: 0.5
    NORM: ''
    NUM_CLASSES: 80
    NUM_CONVS: 4
    PRIOR_PROB: 0.01
    SCORE_THRESH_TEST: 0.05
    SMOOTH_L1_LOSS_BETA: 0.1
    TOPK_CANDIDATES_TEST: 1000
  ROI_BOX_CASCADE_HEAD:
    BBOX_REG_WEIGHTS:
    - - 10.0
      - 10.0
      - 5.0
      - 5.0
    - - 20.0
      - 20.0
      - 10.0
      - 10.0
    - - 30.0
      - 30.0
      - 15.0
      - 15.0
    IOUS:
    - 0.5
    - 0.6
    - 0.7
  ROI_BOX_HEAD:
    BBOX_REG_LOSS_TYPE: smooth_l1
    BBOX_REG_LOSS_WEIGHT: 1.0
    BBOX_REG_WEIGHTS:
    - 10.0
    - 10.0
    - 5.0
    - 5.0
    CLS_AGNOSTIC_BBOX_REG: false
    CONV_DIM: 256
    FC_DIM: 1024
    FED_LOSS_FREQ_WEIGHT_POWER: 0.5
    FED_LOSS_NUM_CLASSES: 50
    NAME: ''
    NORM: ''
    NUM_CONV: 0
    NUM_FC: 0
    POOLER_RESOLUTION: 14
    POOLER_SAMPLING_RATIO: 0
    POOLER_TYPE: ROIAlignV2
    SMOOTH_L1_BETA: 0.0
    TRAIN_ON_PRED_BOXES: false
    USE_FED_LOSS: false
    USE_SIGMOID_CE: false
  ROI_HEADS:
    BATCH_SIZE_PER_IMAGE: 512
    IN_FEATURES:
    - res4
    IOU_LABELS:
    - 0
    - 1
    IOU_THRESHOLDS:
    - 0.5
    NAME: Res5ROIHeads
    NMS_THRESH_TEST: 0.5
    NUM_CLASSES: 80
    POSITIVE_FRACTION: 0.25
    PROPOSAL_APPEND_GT: true
    SCORE_THRESH_TEST: 0.05
  ROI_KEYPOINT_HEAD:
    CONV_DIMS:
    - 512
    - 512
    - 512
    - 512
    - 512
    - 512
    - 512
    - 512
    LOSS_WEIGHT: 1.0
    MIN_KEYPOINTS_PER_IMAGE: 1
    NAME: KRCNNConvDeconvUpsampleHead
    NORMALIZE_LOSS_BY_VISIBLE_KEYPOINTS: true
    NUM_KEYPOINTS: 17
    POOLER_RESOLUTION: 14
    POOLER_SAMPLING_RATIO: 0
    POOLER_TYPE: ROIAlignV2
  ROI_MASK_HEAD:
    CLS_AGNOSTIC_MASK: false
    CONV_DIM: 256
    NAME: MaskRCNNConvUpsampleHead
    NORM: ''
    NUM_CONV: 0
    POOLER_RESOLUTION: 14
    POOLER_SAMPLING_RATIO: 0
    POOLER_TYPE: ROIAlignV2
  RPN:
    BATCH_SIZE_PER_IMAGE: 256
    BBOX_REG_LOSS_TYPE: smooth_l1
    BBOX_REG_LOSS_WEIGHT: 1.0
    BBOX_REG_WEIGHTS: *id001
    BOUNDARY_THRESH: -1
    CONV_DIMS:
    - -1
    HEAD_NAME: StandardRPNHead
    IN_FEATURES:
    - res4
    IOU_LABELS:
    - 0
    - -1
    - 1
    IOU_THRESHOLDS:
    - 0.3
    - 0.7
    LOSS_WEIGHT: 1.0
    NMS_THRESH: 0.7
    POSITIVE_FRACTION: 0.5
    POST_NMS_TOPK_TEST: 1000
    POST_NMS_TOPK_TRAIN: 2000
    PRE_NMS_TOPK_TEST: 6000
    PRE_NMS_TOPK_TRAIN: 12000
    SMOOTH_L1_BETA: 0.0
  SEM_SEG_HEAD:
    ASPP_CHANNELS: 256
    ASPP_DILATIONS:
    - 6
    - 12
    - 18
    ASPP_DROPOUT: 0.1
    COMMON_STRIDE: 4
    CONVS_DIM: 256
    HEAD_CHANNELS: 256
    IGNORE_VALUE: 255
    IN_FEATURES:
    - res2
    - res3
    - res5
    LOSS_TOP_K: 1.0
    LOSS_TYPE: hard_pixel_mining
    LOSS_WEIGHT: 1.0
    NAME: PanopticDeepLabSemSegHead
    NORM: BN
    NUM_CLASSES: 133
    PROJECT_CHANNELS:
    - 32
    - 64
    PROJECT_FEATURES:
    - res2
    - res3
    USE_DEPTHWISE_SEPARABLE_CONV: true
  WEIGHTS: detectron2://DeepLab/R-52.pkl
OUTPUT_DIR: ./output
SEED: -1
SOLVER:
  AMP:
    ENABLED: false
  BASE_LR: 0.0025
  BASE_LR_END: 0.0
  BIAS_LR_FACTOR: 1.0
  CHECKPOINT_PERIOD: 5000
  CLIP_GRADIENTS:
    CLIP_TYPE: value
    CLIP_VALUE: 1.0
    ENABLED: false
    NORM_TYPE: 2.0
  GAMMA: 0.1
  IMS_PER_BATCH: 5
  LR_SCHEDULER_NAME: WarmupPolyLR
  MAX_ITER: 7000
  MOMENTUM: 0.9
  NESTEROV: false
  NUM_DECAYS: 3
  OPTIMIZER: ADAM
  POLY_LR_CONSTANT_ENDING: 0.0
  POLY_LR_POWER: 0.9
  REFERENCE_WORLD_SIZE: 0
  RESCALE_INTERVAL: false
  STEPS:
  - 30000
  WARMUP_FACTOR: 0.001
  WARMUP_ITERS: 1000
  WARMUP_METHOD: linear
  WEIGHT_DECAY: 0.0
  WEIGHT_DECAY_BIAS: 0.0
  WEIGHT_DECAY_NORM: 0.0
TEST:
  AUG:
    ENABLED: false
    FLIP: true
    MAX_SIZE: 4000
    MIN_SIZES:
    - 400
    - 500
    - 600
    - 700
    - 800
    - 900
    - 1000
    - 1100
    - 1200
  DETECTIONS_PER_IMAGE: 100
  EVAL_PERIOD: 0
  EXPECTED_RESULTS: []
  KEYPOINT_OKS_SIGMAS: []
  PRECISE_BN:
    ENABLED: false
    NUM_ITER: 200
VERSION: 2
VIS_PERIOD: 0

[12/09 10:59:32 detectron2]: Full config saved to ./output/config.yaml
[12/09 10:59:32 d2.utils.env]: Using a generated random seed 32769885
[12/09 10:59:37 d2.engine.defaults]: Model:
PanopticDeepLab(
  (backbone): ResNet(
    (stem): DeepLabStem(
      (conv1): Conv2d(
        3, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False
        (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
      )
      (conv2): Conv2d(
        64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
        (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
      )
      (conv3): Conv2d(
        64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
        (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
      )
    )
    (res2): Sequential(
      (0): BottleneckBlock(
        (shortcut): Conv2d(
          128, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv1): Conv2d(
          128, 64, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
        )
        (conv2): Conv2d(
          64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
        )
        (conv3): Conv2d(
          64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
      )
      (1): BottleneckBlock(
        (conv1): Conv2d(
          256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
        )
        (conv2): Conv2d(
          64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
        )
        (conv3): Conv2d(
          64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
      )
      (2): BottleneckBlock(
        (conv1): Conv2d(
          256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
        )
        (conv2): Conv2d(
          64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
        )
        (conv3): Conv2d(
          64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
      )
    )
    (res3): Sequential(
      (0): BottleneckBlock(
        (shortcut): Conv2d(
          256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False
          (norm): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv1): Conv2d(
          256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv2): Conv2d(
          128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False
          (norm): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv3): Conv2d(
          128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (1): BottleneckBlock(
        (conv1): Conv2d(
          512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv2): Conv2d(
          128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv3): Conv2d(
          128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (2): BottleneckBlock(
        (conv1): Conv2d(
          512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv2): Conv2d(
          128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv3): Conv2d(
          128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (3): BottleneckBlock(
        (conv1): Conv2d(
          512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv2): Conv2d(
          128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv3): Conv2d(
          128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
    )
    (res4): Sequential(
      (0): BottleneckBlock(
        (shortcut): Conv2d(
          512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False
          (norm): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv1): Conv2d(
          512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv2): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False
          (norm): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv3): Conv2d(
          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (1): BottleneckBlock(
        (conv1): Conv2d(
          1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv2): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv3): Conv2d(
          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (2): BottleneckBlock(
        (conv1): Conv2d(
          1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv2): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv3): Conv2d(
          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (3): BottleneckBlock(
        (conv1): Conv2d(
          1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv2): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv3): Conv2d(
          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (4): BottleneckBlock(
        (conv1): Conv2d(
          1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv2): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv3): Conv2d(
          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (5): BottleneckBlock(
        (conv1): Conv2d(
          1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv2): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv3): Conv2d(
          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
    )
    (res5): Sequential(
      (0): BottleneckBlock(
        (shortcut): Conv2d(
          1024, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv1): Conv2d(
          1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv2): Conv2d(
          512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2), dilation=(2, 2), bias=False
          (norm): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv3): Conv2d(
          512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (1): BottleneckBlock(
        (conv1): Conv2d(
          2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv2): Conv2d(
          512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(4, 4), dilation=(4, 4), bias=False
          (norm): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv3): Conv2d(
          512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (2): BottleneckBlock(
        (conv1): Conv2d(
          2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv2): Conv2d(
          512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(8, 8), dilation=(8, 8), bias=False
          (norm): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (conv3): Conv2d(
          512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
    )
  )
  (sem_seg_head): PanopticDeepLabSemSegHead(
    (decoder): ModuleDict(
      (res2): ModuleDict(
        (project_conv): Conv2d(
          256, 32, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (fuse_conv): DepthwiseSeparableConv2d(
          (depthwise): Conv2d(
            288, 288, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=288, bias=False
            (norm): BatchNorm2d(288, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          )
          (pointwise): Conv2d(
            288, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
      )
      (res3): ModuleDict(
        (project_conv): Conv2d(
          512, 64, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (fuse_conv): DepthwiseSeparableConv2d(
          (depthwise): Conv2d(
            320, 320, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=320, bias=False
            (norm): BatchNorm2d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          )
          (pointwise): Conv2d(
            320, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
      )
      (res5): ModuleDict(
        (project_conv): ASPP(
          (convs): ModuleList(
            (0): Conv2d(
              2048, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
              (norm): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            )
            (1): DepthwiseSeparableConv2d(
              (depthwise): Conv2d(
                2048, 2048, kernel_size=(3, 3), stride=(1, 1), padding=(6, 6), dilation=(6, 6), groups=2048, bias=False
                (norm): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
              (pointwise): Conv2d(
                2048, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
            )
            (2): DepthwiseSeparableConv2d(
              (depthwise): Conv2d(
                2048, 2048, kernel_size=(3, 3), stride=(1, 1), padding=(12, 12), dilation=(12, 12), groups=2048, bias=False
                (norm): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
              (pointwise): Conv2d(
                2048, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
            )
            (3): DepthwiseSeparableConv2d(
              (depthwise): Conv2d(
                2048, 2048, kernel_size=(3, 3), stride=(1, 1), padding=(18, 18), dilation=(18, 18), groups=2048, bias=False
                (norm): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
              (pointwise): Conv2d(
                2048, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
            )
            (4): Sequential(
              (0): AvgPool2d(kernel_size=(40, 40), stride=1, padding=0)
              (1): Conv2d(2048, 256, kernel_size=(1, 1), stride=(1, 1))
            )
          )
          (project): Conv2d(
            1280, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (fuse_conv): None
      )
    )
    (head): DepthwiseSeparableConv2d(
      (depthwise): Conv2d(
        256, 256, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=256, bias=False
        (norm): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (pointwise): Conv2d(
        256, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
        (norm): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (predictor): Conv2d(256, 133, kernel_size=(1, 1), stride=(1, 1))
    (loss): DeepLabCE(
      (criterion): CrossEntropyLoss()
    )
  )
  (ins_embed_head): PanopticDeepLabInsEmbedHead(
    (decoder): ModuleDict(
      (res2): ModuleDict(
        (project_conv): Conv2d(
          256, 32, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (fuse_conv): DepthwiseSeparableConv2d(
          (depthwise): Conv2d(
            160, 160, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=160, bias=False
            (norm): BatchNorm2d(160, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          )
          (pointwise): Conv2d(
            160, 128, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
      )
      (res3): ModuleDict(
        (project_conv): Conv2d(
          512, 64, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (fuse_conv): DepthwiseSeparableConv2d(
          (depthwise): Conv2d(
            320, 320, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=320, bias=False
            (norm): BatchNorm2d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          )
          (pointwise): Conv2d(
            320, 128, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
      )
      (res5): ModuleDict(
        (project_conv): ASPP(
          (convs): ModuleList(
            (0): Conv2d(
              2048, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
              (norm): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            )
            (1): DepthwiseSeparableConv2d(
              (depthwise): Conv2d(
                2048, 2048, kernel_size=(3, 3), stride=(1, 1), padding=(6, 6), dilation=(6, 6), groups=2048, bias=False
                (norm): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
              (pointwise): Conv2d(
                2048, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
            )
            (2): DepthwiseSeparableConv2d(
              (depthwise): Conv2d(
                2048, 2048, kernel_size=(3, 3), stride=(1, 1), padding=(12, 12), dilation=(12, 12), groups=2048, bias=False
                (norm): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
              (pointwise): Conv2d(
                2048, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
            )
            (3): DepthwiseSeparableConv2d(
              (depthwise): Conv2d(
                2048, 2048, kernel_size=(3, 3), stride=(1, 1), padding=(18, 18), dilation=(18, 18), groups=2048, bias=False
                (norm): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
              (pointwise): Conv2d(
                2048, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
                (norm): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
            )
            (4): Sequential(
              (0): AvgPool2d(kernel_size=(40, 40), stride=1, padding=0)
              (1): Conv2d(2048, 256, kernel_size=(1, 1), stride=(1, 1))
            )
          )
          (project): Conv2d(
            1280, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (fuse_conv): None
      )
    )
    (center_head): Sequential(
      (0): Conv2d(
        128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
        (norm): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (1): Conv2d(
        128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
        (norm): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (center_predictor): Conv2d(32, 1, kernel_size=(1, 1), stride=(1, 1))
    (offset_head): DepthwiseSeparableConv2d(
      (depthwise): Conv2d(
        128, 128, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=128, bias=False
        (norm): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (pointwise): Conv2d(
        128, 32, kernel_size=(1, 1), stride=(1, 1), bias=False
        (norm): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (offset_predictor): Conv2d(32, 2, kernel_size=(1, 1), stride=(1, 1))
    (center_loss): MSELoss()
    (offset_loss): L1Loss()
  )
)
[12/09 10:59:37 d2.projects.panoptic_deeplab.dataset_mapper]: Augmentations used in training: [ResizeShortestEdge(short_edge_length=(320, 384, 448, 512, 576, 640, 704, 768, 832, 896, 960), max_size=960, sample_style='choice'), RandomCrop(crop_type='absolute', crop_size=[640, 640]), RandomFlip()]
[12/09 10:59:44 d2.data.build]: Using training sampler TrainingSampler
[12/09 10:59:44 d2.data.common]: Serializing the dataset using: <class 'detectron2.data.common.NumpySerializedList'>
[12/09 10:59:44 d2.data.common]: Serializing 118287 elements to byte tensors and concatenating them all ...
[12/09 10:59:45 d2.data.common]: Serialized dataset takes 80.32 MiB
/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:481: UserWarning: This DataLoader will create 10 worker processes in total. Our suggested max number of worker in current system is 8, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.
  cpuset_checked))
[12/09 10:59:47 fvcore.common.checkpoint]: [Checkpointer] Loading from detectron2://DeepLab/R-52.pkl ...
[12/09 10:59:48 fvcore.common.checkpoint]: Reading a file from 'torchvision'
[12/09 10:59:48 d2.checkpoint.c2_model_loading]: Following weights matched with submodule backbone:
| Names in Model    | Names in Checkpoint                                                                                        | Shapes                                             |
|:------------------|:-----------------------------------------------------------------------------------------------------------|:---------------------------------------------------|
| res2.0.conv1.*    | res2.0.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}                             | (64,) (64,) (64,) (64,) (64,128,1,1)               |
| res2.0.conv2.*    | res2.0.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}                             | (64,) (64,) (64,) (64,) (64,64,3,3)                |
| res2.0.conv3.*    | res2.0.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}                             | (256,) (256,) (256,) (256,) (256,64,1,1)           |
| res2.0.shortcut.* | res2.0.shortcut.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}                          | (256,) (256,) (256,) (256,) (256,128,1,1)          |
| res2.1.conv1.*    | res2.1.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}                             | (64,) (64,) (64,) (64,) (64,256,1,1)               |
| res2.1.conv2.*    | res2.1.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}                             | (64,) (64,) (64,) (64,) (64,64,3,3)                |
| res2.1.conv3.*    | res2.1.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}                             | (256,) (256,) (256,) (256,) (256,64,1,1)           |
| res2.2.conv1.*    | res2.2.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}                             | (64,) (64,) (64,) (64,) (64,256,1,1)               |
| res2.2.conv2.*    | res2.2.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}                             | (64,) (64,) (64,) (64,) (64,64,3,3)                |
| res2.2.conv3.*    | res2.2.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}                             | (256,) (256,) (256,) (256,) (256,64,1,1)           |
| res3.0.conv1.*    | res3.0.conv1.{norm.bias,norm.num_batches_tracked,norm.running_mean,norm.running_var,norm.weight,weight}    | (128,) () (128,) (128,) (128,) (128,256,1,1)       |
| res3.0.conv2.*    | res3.0.conv2.{norm.bias,norm.num_batches_tracked,norm.running_mean,norm.running_var,norm.weight,weight}    | (128,) () (128,) (128,) (128,) (128,128,3,3)       |
| res3.0.conv3.*    | res3.0.conv3.{norm.bias,norm.num_batches_tracked,norm.running_mean,norm.running_var,norm.weight,weight}    | (512,) () (512,) (512,) (512,) (512,128,1,1)       |
| res3.0.shortcut.* | res3.0.shortcut.{norm.bias,norm.num_batches_tracked,norm.running_mean,norm.running_var,norm.weight,weight} | (512,) () (512,) (512,) (512,) (512,256,1,1)       |
| res3.1.conv1.*    | res3.1.conv1.{norm.bias,norm.num_batches_tracked,norm.running_mean,norm.running_var,norm.weight,weight}    | (128,) () (128,) (128,) (128,) (128,512,1,1)       |
| res3.1.conv2.*    | res3.1.conv2.{norm.bias,norm.num_batches_tracked,norm.running_mean,norm.running_var,norm.weight,weight}    | (128,) () (128,) (128,) (128,) (128,128,3,3)       |
| res3.1.conv3.*    | res3.1.conv3.{norm.bias,norm.num_batches_tracked,norm.running_mean,norm.running_var,norm.weight,weight}    | (512,) () (512,) (512,) (512,) (512,128,1,1)       |
| res3.2.conv1.*    | res3.2.conv1.{norm.bias,norm.num_batches_tracked,norm.running_mean,norm.running_var,norm.weight,weight}    | (128,) () (128,) (128,) (128,) (128,512,1,1)       |
| res3.2.conv2.*    | res3.2.conv2.{norm.bias,norm.num_batches_tracked,norm.running_mean,norm.running_var,norm.weight,weight}    | (128,) () (128,) (128,) (128,) (128,128,3,3)       |
| res3.2.conv3.*    | res3.2.conv3.{norm.bias,norm.num_batches_tracked,norm.running_mean,norm.running_var,norm.weight,weight}    | (512,) () (512,) (512,) (512,) (512,128,1,1)       |
| res3.3.conv1.*    | res3.3.conv1.{norm.bias,norm.num_batches_tracked,norm.running_mean,norm.running_var,norm.weight,weight}    | (128,) () (128,) (128,) (128,) (128,512,1,1)       |
| res3.3.conv2.*    | res3.3.conv2.{norm.bias,norm.num_batches_tracked,norm.running_mean,norm.running_var,norm.weight,weight}    | (128,) () (128,) (128,) (128,) (128,128,3,3)       |
| res3.3.conv3.*    | res3.3.conv3.{norm.bias,norm.num_batches_tracked,norm.running_mean,norm.running_var,norm.weight,weight}    | (512,) () (512,) (512,) (512,) (512,128,1,1)       |
| res4.0.conv1.*    | res4.0.conv1.{norm.bias,norm.num_batches_tracked,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) () (256,) (256,) (256,) (256,512,1,1)       |
| res4.0.conv2.*    | res4.0.conv2.{norm.bias,norm.num_batches_tracked,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) () (256,) (256,) (256,) (256,256,3,3)       |
| res4.0.conv3.*    | res4.0.conv3.{norm.bias,norm.num_batches_tracked,norm.running_mean,norm.running_var,norm.weight,weight}    | (1024,) () (1024,) (1024,) (1024,) (1024,256,1,1)  |
| res4.0.shortcut.* | res4.0.shortcut.{norm.bias,norm.num_batches_tracked,norm.running_mean,norm.running_var,norm.weight,weight} | (1024,) () (1024,) (1024,) (1024,) (1024,512,1,1)  |
| res4.1.conv1.*    | res4.1.conv1.{norm.bias,norm.num_batches_tracked,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) () (256,) (256,) (256,) (256,1024,1,1)      |
| res4.1.conv2.*    | res4.1.conv2.{norm.bias,norm.num_batches_tracked,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) () (256,) (256,) (256,) (256,256,3,3)       |
| res4.1.conv3.*    | res4.1.conv3.{norm.bias,norm.num_batches_tracked,norm.running_mean,norm.running_var,norm.weight,weight}    | (1024,) () (1024,) (1024,) (1024,) (1024,256,1,1)  |
| res4.2.conv1.*    | res4.2.conv1.{norm.bias,norm.num_batches_tracked,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) () (256,) (256,) (256,) (256,1024,1,1)      |
| res4.2.conv2.*    | res4.2.conv2.{norm.bias,norm.num_batches_tracked,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) () (256,) (256,) (256,) (256,256,3,3)       |
| res4.2.conv3.*    | res4.2.conv3.{norm.bias,norm.num_batches_tracked,norm.running_mean,norm.running_var,norm.weight,weight}    | (1024,) () (1024,) (1024,) (1024,) (1024,256,1,1)  |
| res4.3.conv1.*    | res4.3.conv1.{norm.bias,norm.num_batches_tracked,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) () (256,) (256,) (256,) (256,1024,1,1)      |
| res4.3.conv2.*    | res4.3.conv2.{norm.bias,norm.num_batches_tracked,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) () (256,) (256,) (256,) (256,256,3,3)       |
| res4.3.conv3.*    | res4.3.conv3.{norm.bias,norm.num_batches_tracked,norm.running_mean,norm.running_var,norm.weight,weight}    | (1024,) () (1024,) (1024,) (1024,) (1024,256,1,1)  |
| res4.4.conv1.*    | res4.4.conv1.{norm.bias,norm.num_batches_tracked,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) () (256,) (256,) (256,) (256,1024,1,1)      |
| res4.4.conv2.*    | res4.4.conv2.{norm.bias,norm.num_batches_tracked,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) () (256,) (256,) (256,) (256,256,3,3)       |
| res4.4.conv3.*    | res4.4.conv3.{norm.bias,norm.num_batches_tracked,norm.running_mean,norm.running_var,norm.weight,weight}    | (1024,) () (1024,) (1024,) (1024,) (1024,256,1,1)  |
| res4.5.conv1.*    | res4.5.conv1.{norm.bias,norm.num_batches_tracked,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) () (256,) (256,) (256,) (256,1024,1,1)      |
| res4.5.conv2.*    | res4.5.conv2.{norm.bias,norm.num_batches_tracked,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) () (256,) (256,) (256,) (256,256,3,3)       |
| res4.5.conv3.*    | res4.5.conv3.{norm.bias,norm.num_batches_tracked,norm.running_mean,norm.running_var,norm.weight,weight}    | (1024,) () (1024,) (1024,) (1024,) (1024,256,1,1)  |
| res5.0.conv1.*    | res5.0.conv1.{norm.bias,norm.num_batches_tracked,norm.running_mean,norm.running_var,norm.weight,weight}    | (512,) () (512,) (512,) (512,) (512,1024,1,1)      |
| res5.0.conv2.*    | res5.0.conv2.{norm.bias,norm.num_batches_tracked,norm.running_mean,norm.running_var,norm.weight,weight}    | (512,) () (512,) (512,) (512,) (512,512,3,3)       |
| res5.0.conv3.*    | res5.0.conv3.{norm.bias,norm.num_batches_tracked,norm.running_mean,norm.running_var,norm.weight,weight}    | (2048,) () (2048,) (2048,) (2048,) (2048,512,1,1)  |
| res5.0.shortcut.* | res5.0.shortcut.{norm.bias,norm.num_batches_tracked,norm.running_mean,norm.running_var,norm.weight,weight} | (2048,) () (2048,) (2048,) (2048,) (2048,1024,1,1) |
| res5.1.conv1.*    | res5.1.conv1.{norm.bias,norm.num_batches_tracked,norm.running_mean,norm.running_var,norm.weight,weight}    | (512,) () (512,) (512,) (512,) (512,2048,1,1)      |
| res5.1.conv2.*    | res5.1.conv2.{norm.bias,norm.num_batches_tracked,norm.running_mean,norm.running_var,norm.weight,weight}    | (512,) () (512,) (512,) (512,) (512,512,3,3)       |
| res5.1.conv3.*    | res5.1.conv3.{norm.bias,norm.num_batches_tracked,norm.running_mean,norm.running_var,norm.weight,weight}    | (2048,) () (2048,) (2048,) (2048,) (2048,512,1,1)  |
| res5.2.conv1.*    | res5.2.conv1.{norm.bias,norm.num_batches_tracked,norm.running_mean,norm.running_var,norm.weight,weight}    | (512,) () (512,) (512,) (512,) (512,2048,1,1)      |
| res5.2.conv2.*    | res5.2.conv2.{norm.bias,norm.num_batches_tracked,norm.running_mean,norm.running_var,norm.weight,weight}    | (512,) () (512,) (512,) (512,) (512,512,3,3)       |
| res5.2.conv3.*    | res5.2.conv3.{norm.bias,norm.num_batches_tracked,norm.running_mean,norm.running_var,norm.weight,weight}    | (2048,) () (2048,) (2048,) (2048,) (2048,512,1,1)  |
| stem.conv1.*      | stem.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}                               | (64,) (64,) (64,) (64,) (64,3,3,3)                 |
| stem.conv2.*      | stem.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}                               | (64,) (64,) (64,) (64,) (64,64,3,3)                |
| stem.conv3.*      | stem.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}                               | (128,) (128,) (128,) (128,) (128,64,3,3)           |
WARNING [12/09 10:59:48 fvcore.common.checkpoint]: Some model parameters or buffers are not found in the checkpoint:
ins_embed_head.center_head.0.norm.{bias, running_mean, running_var, weight}
ins_embed_head.center_head.0.weight
ins_embed_head.center_head.1.norm.{bias, running_mean, running_var, weight}
ins_embed_head.center_head.1.weight
ins_embed_head.center_predictor.{bias, weight}
ins_embed_head.decoder.res2.fuse_conv.depthwise.norm.{bias, running_mean, running_var, weight}
ins_embed_head.decoder.res2.fuse_conv.depthwise.weight
ins_embed_head.decoder.res2.fuse_conv.pointwise.norm.{bias, running_mean, running_var, weight}
ins_embed_head.decoder.res2.fuse_conv.pointwise.weight
ins_embed_head.decoder.res2.project_conv.norm.{bias, running_mean, running_var, weight}
ins_embed_head.decoder.res2.project_conv.weight
ins_embed_head.decoder.res3.fuse_conv.depthwise.norm.{bias, running_mean, running_var, weight}
ins_embed_head.decoder.res3.fuse_conv.depthwise.weight
ins_embed_head.decoder.res3.fuse_conv.pointwise.norm.{bias, running_mean, running_var, weight}
ins_embed_head.decoder.res3.fuse_conv.pointwise.weight
ins_embed_head.decoder.res3.project_conv.norm.{bias, running_mean, running_var, weight}
ins_embed_head.decoder.res3.project_conv.weight
ins_embed_head.decoder.res5.project_conv.convs.0.norm.{bias, running_mean, running_var, weight}
ins_embed_head.decoder.res5.project_conv.convs.0.weight
ins_embed_head.decoder.res5.project_conv.convs.1.depthwise.norm.{bias, running_mean, running_var, weight}
ins_embed_head.decoder.res5.project_conv.convs.1.depthwise.weight
ins_embed_head.decoder.res5.project_conv.convs.1.pointwise.norm.{bias, running_mean, running_var, weight}
ins_embed_head.decoder.res5.project_conv.convs.1.pointwise.weight
ins_embed_head.decoder.res5.project_conv.convs.2.depthwise.norm.{bias, running_mean, running_var, weight}
ins_embed_head.decoder.res5.project_conv.convs.2.depthwise.weight
ins_embed_head.decoder.res5.project_conv.convs.2.pointwise.norm.{bias, running_mean, running_var, weight}
ins_embed_head.decoder.res5.project_conv.convs.2.pointwise.weight
ins_embed_head.decoder.res5.project_conv.convs.3.depthwise.norm.{bias, running_mean, running_var, weight}
ins_embed_head.decoder.res5.project_conv.convs.3.depthwise.weight
ins_embed_head.decoder.res5.project_conv.convs.3.pointwise.norm.{bias, running_mean, running_var, weight}
ins_embed_head.decoder.res5.project_conv.convs.3.pointwise.weight
ins_embed_head.decoder.res5.project_conv.convs.4.1.{bias, weight}
ins_embed_head.decoder.res5.project_conv.project.norm.{bias, running_mean, running_var, weight}
ins_embed_head.decoder.res5.project_conv.project.weight
ins_embed_head.offset_head.depthwise.norm.{bias, running_mean, running_var, weight}
ins_embed_head.offset_head.depthwise.weight
ins_embed_head.offset_head.pointwise.norm.{bias, running_mean, running_var, weight}
ins_embed_head.offset_head.pointwise.weight
ins_embed_head.offset_predictor.{bias, weight}
sem_seg_head.decoder.res2.fuse_conv.depthwise.norm.{bias, running_mean, running_var, weight}
sem_seg_head.decoder.res2.fuse_conv.depthwise.weight
sem_seg_head.decoder.res2.fuse_conv.pointwise.norm.{bias, running_mean, running_var, weight}
sem_seg_head.decoder.res2.fuse_conv.pointwise.weight
sem_seg_head.decoder.res2.project_conv.norm.{bias, running_mean, running_var, weight}
sem_seg_head.decoder.res2.project_conv.weight
sem_seg_head.decoder.res3.fuse_conv.depthwise.norm.{bias, running_mean, running_var, weight}
sem_seg_head.decoder.res3.fuse_conv.depthwise.weight
sem_seg_head.decoder.res3.fuse_conv.pointwise.norm.{bias, running_mean, running_var, weight}
sem_seg_head.decoder.res3.fuse_conv.pointwise.weight
sem_seg_head.decoder.res3.project_conv.norm.{bias, running_mean, running_var, weight}
sem_seg_head.decoder.res3.project_conv.weight
sem_seg_head.decoder.res5.project_conv.convs.0.norm.{bias, running_mean, running_var, weight}
sem_seg_head.decoder.res5.project_conv.convs.0.weight
sem_seg_head.decoder.res5.project_conv.convs.1.depthwise.norm.{bias, running_mean, running_var, weight}
sem_seg_head.decoder.res5.project_conv.convs.1.depthwise.weight
sem_seg_head.decoder.res5.project_conv.convs.1.pointwise.norm.{bias, running_mean, running_var, weight}
sem_seg_head.decoder.res5.project_conv.convs.1.pointwise.weight
sem_seg_head.decoder.res5.project_conv.convs.2.depthwise.norm.{bias, running_mean, running_var, weight}
sem_seg_head.decoder.res5.project_conv.convs.2.depthwise.weight
sem_seg_head.decoder.res5.project_conv.convs.2.pointwise.norm.{bias, running_mean, running_var, weight}
sem_seg_head.decoder.res5.project_conv.convs.2.pointwise.weight
sem_seg_head.decoder.res5.project_conv.convs.3.depthwise.norm.{bias, running_mean, running_var, weight}
sem_seg_head.decoder.res5.project_conv.convs.3.depthwise.weight
sem_seg_head.decoder.res5.project_conv.convs.3.pointwise.norm.{bias, running_mean, running_var, weight}
sem_seg_head.decoder.res5.project_conv.convs.3.pointwise.weight
sem_seg_head.decoder.res5.project_conv.convs.4.1.{bias, weight}
sem_seg_head.decoder.res5.project_conv.project.norm.{bias, running_mean, running_var, weight}
sem_seg_head.decoder.res5.project_conv.project.weight
sem_seg_head.head.depthwise.norm.{bias, running_mean, running_var, weight}
sem_seg_head.head.depthwise.weight
sem_seg_head.head.pointwise.norm.{bias, running_mean, running_var, weight}
sem_seg_head.head.pointwise.weight
sem_seg_head.predictor.{bias, weight}
WARNING [12/09 10:59:48 fvcore.common.checkpoint]: The checkpoint state_dict contains keys that are not used by the model:
  res2.0.conv1.norm.num_batches_tracked
  res2.0.conv2.norm.num_batches_tracked
  res2.0.conv3.norm.num_batches_tracked
  res2.0.shortcut.norm.num_batches_tracked
  res2.1.conv1.norm.num_batches_tracked
  res2.1.conv2.norm.num_batches_tracked
  res2.1.conv3.norm.num_batches_tracked
  res2.2.conv1.norm.num_batches_tracked
  res2.2.conv2.norm.num_batches_tracked
  res2.2.conv3.norm.num_batches_tracked
  stem.conv1.norm.num_batches_tracked
  stem.conv2.norm.num_batches_tracked
  stem.conv3.norm.num_batches_tracked
  stem.fc.{bias, weight}
[12/09 10:59:48 d2.engine.train_loop]: Starting training from iteration 0
/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:481: UserWarning: This DataLoader will create 10 worker processes in total. Our suggested max number of worker in current system is 8, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.
  cpuset_checked))
[12/09 10:59:57 d2.utils.events]:  eta: 0:42:53  iter: 19  total_loss: 6.365  loss_sem_seg: 3.785  loss_center: 0.678  loss_offset: 1.801  time: 0.3737  data_time: 0.0673  lr: 4.983e-05  max_mem: 8976M
[12/09 11:00:04 d2.utils.events]:  eta: 0:43:00  iter: 39  total_loss: 6.191  loss_sem_seg: 3.974  loss_center: 0.6472  loss_offset: 1.682  time: 0.3743  data_time: 0.0253  lr: 9.9401e-05  max_mem: 8976M
[12/09 11:00:12 d2.utils.events]:  eta: 0:43:00  iter: 59  total_loss: 5.554  loss_sem_seg: 3.534  loss_center: 0.7423  loss_offset: 1.288  time: 0.3743  data_time: 0.0256  lr: 0.00014872  max_mem: 8976M
[12/09 11:00:19 d2.utils.events]:  eta: 0:43:18  iter: 79  total_loss: 5.801  loss_sem_seg: 3.368  loss_center: 0.5967  loss_offset: 1.605  time: 0.3756  data_time: 0.0263  lr: 0.00019777  max_mem: 8976M
[12/09 11:00:27 d2.utils.events]:  eta: 0:43:10  iter: 99  total_loss: 5.581  loss_sem_seg: 3.068  loss_center: 0.746  loss_offset: 1.646  time: 0.3756  data_time: 0.0261  lr: 0.00024657  max_mem: 8976M
[12/09 11:00:34 d2.utils.events]:  eta: 0:42:57  iter: 119  total_loss: 5.494  loss_sem_seg: 3.142  loss_center: 0.6835  loss_offset: 1.48  time: 0.3756  data_time: 0.0257  lr: 0.00029511  max_mem: 8976M
[12/09 11:00:42 d2.utils.events]:  eta: 0:42:39  iter: 139  total_loss: 5.052  loss_sem_seg: 2.872  loss_center: 0.7641  loss_offset: 1.531  time: 0.3753  data_time: 0.0252  lr: 0.0003434  max_mem: 8976M
[12/09 11:00:49 d2.utils.events]:  eta: 0:42:34  iter: 159  total_loss: 5.128  loss_sem_seg: 2.861  loss_center: 0.6801  loss_offset: 1.459  time: 0.3752  data_time: 0.0250  lr: 0.00039142  max_mem: 8976M
[12/09 11:00:57 d2.utils.events]:  eta: 0:42:34  iter: 179  total_loss: 5.126  loss_sem_seg: 2.735  loss_center: 0.7365  loss_offset: 1.651  time: 0.3755  data_time: 0.0262  lr: 0.00043919  max_mem: 8976M
[12/09 11:01:04 d2.utils.events]:  eta: 0:42:27  iter: 199  total_loss: 5.07  loss_sem_seg: 2.784  loss_center: 0.6523  loss_offset: 1.444  time: 0.3754  data_time: 0.0259  lr: 0.0004867  max_mem: 8976M
[12/09 11:01:12 d2.utils.events]:  eta: 0:42:19  iter: 219  total_loss: 4.665  loss_sem_seg: 2.564  loss_center: 0.5299  loss_offset: 1.461  time: 0.3754  data_time: 0.0259  lr: 0.00053396  max_mem: 8976M
[12/09 11:01:19 d2.utils.events]:  eta: 0:42:14  iter: 239  total_loss: 4.635  loss_sem_seg: 2.464  loss_center: 0.5126  loss_offset: 1.505  time: 0.3753  data_time: 0.0254  lr: 0.00058095  max_mem: 8976M
[12/09 11:01:27 d2.utils.events]:  eta: 0:42:06  iter: 259  total_loss: 5.055  loss_sem_seg: 2.641  loss_center: 0.6582  loss_offset: 1.646  time: 0.3755  data_time: 0.0264  lr: 0.00062769  max_mem: 8976M
[12/09 11:01:34 d2.utils.events]:  eta: 0:42:00  iter: 279  total_loss: 4.54  loss_sem_seg: 2.499  loss_center: 0.8562  loss_offset: 1.381  time: 0.3756  data_time: 0.0254  lr: 0.00067417  max_mem: 8976M
[12/09 11:01:42 d2.utils.events]:  eta: 0:41:55  iter: 299  total_loss: 4.789  loss_sem_seg: 2.887  loss_center: 0.6191  loss_offset: 1.489  time: 0.3757  data_time: 0.0265  lr: 0.00072039  max_mem: 8976M
[12/09 11:01:50 d2.utils.events]:  eta: 0:41:45  iter: 319  total_loss: 5.248  loss_sem_seg: 2.799  loss_center: 0.7059  loss_offset: 1.501  time: 0.3758  data_time: 0.0279  lr: 0.00076635  max_mem: 8976M
[12/09 11:01:57 d2.utils.events]:  eta: 0:41:36  iter: 339  total_loss: 4.776  loss_sem_seg: 2.55  loss_center: 0.5534  loss_offset: 1.513  time: 0.3758  data_time: 0.0272  lr: 0.00081205  max_mem: 8976M
[12/09 11:02:05 d2.utils.events]:  eta: 0:41:29  iter: 359  total_loss: 4.458  loss_sem_seg: 2.639  loss_center: 0.7405  loss_offset: 1.275  time: 0.3759  data_time: 0.0266  lr: 0.00085749  max_mem: 8976M
[12/09 11:02:12 d2.utils.events]:  eta: 0:41:20  iter: 379  total_loss: 4.612  loss_sem_seg: 2.422  loss_center: 0.6339  loss_offset: 1.455  time: 0.3757  data_time: 0.0260  lr: 0.00090268  max_mem: 8976M
[12/09 11:02:20 d2.utils.events]:  eta: 0:41:12  iter: 399  total_loss: 4.966  loss_sem_seg: 2.592  loss_center: 0.6739  loss_offset: 1.657  time: 0.3758  data_time: 0.0261  lr: 0.0009476  max_mem: 8976M
[12/09 11:02:27 d2.utils.events]:  eta: 0:41:04  iter: 419  total_loss: 4.508  loss_sem_seg: 2.541  loss_center: 0.6807  loss_offset: 1.25  time: 0.3758  data_time: 0.0261  lr: 0.00099227  max_mem: 8976M
[12/09 11:02:35 d2.utils.events]:  eta: 0:40:55  iter: 439  total_loss: 4.64  loss_sem_seg: 2.634  loss_center: 0.7687  loss_offset: 1.264  time: 0.3757  data_time: 0.0256  lr: 0.0010367  max_mem: 8976M
[12/09 11:02:42 d2.utils.events]:  eta: 0:40:48  iter: 459  total_loss: 4.281  loss_sem_seg: 2.127  loss_center: 0.7667  loss_offset: 1.225  time: 0.3758  data_time: 0.0265  lr: 0.0010808  max_mem: 8976M
[12/09 11:02:50 d2.utils.events]:  eta: 0:40:40  iter: 479  total_loss: 4.655  loss_sem_seg: 2.529  loss_center: 0.741  loss_offset: 1.275  time: 0.3758  data_time: 0.0250  lr: 0.0011247  max_mem: 8976M
[12/09 11:02:57 d2.utils.events]:  eta: 0:40:33  iter: 499  total_loss: 4.178  loss_sem_seg: 2.106  loss_center: 0.75  loss_offset: 1.166  time: 0.3759  data_time: 0.0259  lr: 0.0011683  max_mem: 8976M
[12/09 11:03:05 d2.utils.events]:  eta: 0:40:25  iter: 519  total_loss: 4.41  loss_sem_seg: 2.222  loss_center: 0.6  loss_offset: 1.289  time: 0.3760  data_time: 0.0246  lr: 0.0012117  max_mem: 8976M
[12/09 11:03:12 d2.utils.events]:  eta: 0:40:19  iter: 539  total_loss: 4.212  loss_sem_seg: 2.095  loss_center: 0.7418  loss_offset: 1.181  time: 0.3760  data_time: 0.0269  lr: 0.0012548  max_mem: 8976M
[12/09 11:03:20 d2.utils.events]:  eta: 0:40:10  iter: 559  total_loss: 4.552  loss_sem_seg: 2.556  loss_center: 0.7291  loss_offset: 1.355  time: 0.3759  data_time: 0.0253  lr: 0.0012977  max_mem: 8976M
[12/09 11:03:28 d2.utils.events]:  eta: 0:40:05  iter: 579  total_loss: 4.646  loss_sem_seg: 2.456  loss_center: 0.6893  loss_offset: 1.21  time: 0.3760  data_time: 0.0258  lr: 0.0013403  max_mem: 8976M
[12/09 11:03:35 d2.utils.events]:  eta: 0:39:58  iter: 599  total_loss: 4.337  loss_sem_seg: 2.407  loss_center: 0.7896  loss_offset: 1.147  time: 0.3759  data_time: 0.0265  lr: 0.0013826  max_mem: 8976M
[12/09 11:03:43 d2.utils.events]:  eta: 0:39:50  iter: 619  total_loss: 4.652  loss_sem_seg: 2.752  loss_center: 0.5848  loss_offset: 1.37  time: 0.3760  data_time: 0.0272  lr: 0.0014247  max_mem: 8976M
[12/09 11:03:50 d2.utils.events]:  eta: 0:39:43  iter: 639  total_loss: 4.458  loss_sem_seg: 2.438  loss_center: 0.6981  loss_offset: 1.256  time: 0.3760  data_time: 0.0259  lr: 0.0014665  max_mem: 8976M
[12/09 11:03:58 d2.utils.events]:  eta: 0:39:35  iter: 659  total_loss: 4.399  loss_sem_seg: 2.578  loss_center: 0.7698  loss_offset: 1.137  time: 0.3760  data_time: 0.0254  lr: 0.001508  max_mem: 8976M
[12/09 11:04:05 d2.utils.events]:  eta: 0:39:28  iter: 679  total_loss: 4.249  loss_sem_seg: 2.243  loss_center: 0.6626  loss_offset: 1.225  time: 0.3759  data_time: 0.0259  lr: 0.0015493  max_mem: 8976M
[12/09 11:04:13 d2.utils.events]:  eta: 0:39:21  iter: 699  total_loss: 4.25  loss_sem_seg: 2.293  loss_center: 0.61  loss_offset: 1.153  time: 0.3760  data_time: 0.0273  lr: 0.0015903  max_mem: 8976M
[12/09 11:04:20 d2.utils.events]:  eta: 0:39:14  iter: 719  total_loss: 4.11  loss_sem_seg: 2.252  loss_center: 0.6029  loss_offset: 1.153  time: 0.3760  data_time: 0.0245  lr: 0.0016311  max_mem: 8976M
[12/09 11:04:28 d2.utils.events]:  eta: 0:39:07  iter: 739  total_loss: 4.112  loss_sem_seg: 2.238  loss_center: 0.8497  loss_offset: 1.042  time: 0.3760  data_time: 0.0271  lr: 0.0016716  max_mem: 8976M
[12/09 11:04:35 d2.utils.events]:  eta: 0:38:59  iter: 759  total_loss: 4.491  loss_sem_seg: 2.532  loss_center: 0.5654  loss_offset: 1.185  time: 0.3761  data_time: 0.0272  lr: 0.0017118  max_mem: 8976M
[12/09 11:04:43 d2.utils.events]:  eta: 0:38:51  iter: 779  total_loss: 3.996  loss_sem_seg: 2.17  loss_center: 0.6866  loss_offset: 1.08  time: 0.3761  data_time: 0.0268  lr: 0.0017518  max_mem: 8976M
[12/09 11:04:51 d2.utils.events]:  eta: 0:38:44  iter: 799  total_loss: 4.305  loss_sem_seg: 2.33  loss_center: 0.738  loss_offset: 1.217  time: 0.3761  data_time: 0.0261  lr: 0.0017915  max_mem: 8976M
[12/09 11:04:58 d2.utils.events]:  eta: 0:38:35  iter: 819  total_loss: 3.953  loss_sem_seg: 2.191  loss_center: 0.7021  loss_offset: 1.039  time: 0.3761  data_time: 0.0258  lr: 0.001831  max_mem: 8976M
[12/09 11:05:06 d2.utils.events]:  eta: 0:38:29  iter: 839  total_loss: 4.258  loss_sem_seg: 2.296  loss_center: 0.6858  loss_offset: 1.201  time: 0.3762  data_time: 0.0275  lr: 0.0018702  max_mem: 8976M
[12/09 11:05:13 d2.utils.events]:  eta: 0:38:21  iter: 859  total_loss: 4.087  loss_sem_seg: 2.336  loss_center: 0.7298  loss_offset: 1.069  time: 0.3762  data_time: 0.0261  lr: 0.0019091  max_mem: 8976M
[12/09 11:05:21 d2.utils.events]:  eta: 0:38:15  iter: 879  total_loss: 3.972  loss_sem_seg: 2.274  loss_center: 0.6441  loss_offset: 1.094  time: 0.3762  data_time: 0.0251  lr: 0.0019478  max_mem: 8976M
[12/09 11:05:28 d2.utils.events]:  eta: 0:38:08  iter: 899  total_loss: 4.479  loss_sem_seg: 2.348  loss_center: 0.8121  loss_offset: 1.111  time: 0.3762  data_time: 0.0256  lr: 0.0019862  max_mem: 8976M
[12/09 11:05:36 d2.utils.events]:  eta: 0:38:00  iter: 919  total_loss: 4.055  loss_sem_seg: 2.396  loss_center: 0.5253  loss_offset: 1.078  time: 0.3762  data_time: 0.0257  lr: 0.0020243  max_mem: 8976M
[12/09 11:05:43 d2.utils.events]:  eta: 0:37:53  iter: 939  total_loss: 4.396  loss_sem_seg: 2.456  loss_center: 0.8787  loss_offset: 1.21  time: 0.3762  data_time: 0.0252  lr: 0.0020622  max_mem: 8976M
[12/09 11:05:51 d2.utils.events]:  eta: 0:37:45  iter: 959  total_loss: 4.181  loss_sem_seg: 2.246  loss_center: 0.6576  loss_offset: 1.084  time: 0.3761  data_time: 0.0252  lr: 0.0020998  max_mem: 8976M
[12/09 11:05:58 d2.utils.events]:  eta: 0:37:38  iter: 979  total_loss: 4.053  loss_sem_seg: 2.226  loss_center: 0.6682  loss_offset: 1.069  time: 0.3761  data_time: 0.0275  lr: 0.0021372  max_mem: 8976M
[12/09 11:06:06 d2.utils.events]:  eta: 0:37:29  iter: 999  total_loss: 3.979  loss_sem_seg: 2.086  loss_center: 0.7567  loss_offset: 1.086  time: 0.3760  data_time: 0.0241  lr: 0.0021743  max_mem: 8976M
[12/09 11:06:13 d2.utils.events]:  eta: 0:37:23  iter: 1019  total_loss: 4.215  loss_sem_seg: 2.378  loss_center: 0.6613  loss_offset: 1.09  time: 0.3761  data_time: 0.0281  lr: 0.0021699  max_mem: 8976M
[12/09 11:06:21 d2.utils.events]:  eta: 0:37:15  iter: 1039  total_loss: 4.136  loss_sem_seg: 2.321  loss_center: 0.68  loss_offset: 1.173  time: 0.3761  data_time: 0.0267  lr: 0.0021634  max_mem: 8976M
[12/09 11:06:28 d2.utils.events]:  eta: 0:37:08  iter: 1059  total_loss: 3.878  loss_sem_seg: 2.1  loss_center: 0.6957  loss_offset: 1.063  time: 0.3760  data_time: 0.0243  lr: 0.0021569  max_mem: 8976M
[12/09 11:06:36 d2.utils.events]:  eta: 0:37:00  iter: 1079  total_loss: 4.044  loss_sem_seg: 2.129  loss_center: 0.7135  loss_offset: 1.051  time: 0.3760  data_time: 0.0260  lr: 0.0021503  max_mem: 8976M
[12/09 11:06:43 d2.utils.events]:  eta: 0:36:52  iter: 1099  total_loss: 4  loss_sem_seg: 2.042  loss_center: 0.6092  loss_offset: 1.092  time: 0.3760  data_time: 0.0260  lr: 0.0021438  max_mem: 8976M
[12/09 11:06:51 d2.utils.events]:  eta: 0:36:45  iter: 1119  total_loss: 3.929  loss_sem_seg: 2.153  loss_center: 0.6828  loss_offset: 1.115  time: 0.3759  data_time: 0.0235  lr: 0.0021373  max_mem: 8976M
[12/09 11:06:58 d2.utils.events]:  eta: 0:36:38  iter: 1139  total_loss: 4.016  loss_sem_seg: 2.249  loss_center: 0.6363  loss_offset: 1.066  time: 0.3759  data_time: 0.0270  lr: 0.0021307  max_mem: 8976M
[12/09 11:07:06 d2.utils.events]:  eta: 0:36:30  iter: 1159  total_loss: 3.876  loss_sem_seg: 2.162  loss_center: 0.6349  loss_offset: 1.128  time: 0.3760  data_time: 0.0257  lr: 0.0021242  max_mem: 8976M
[12/09 11:07:13 d2.utils.events]:  eta: 0:36:23  iter: 1179  total_loss: 4.004  loss_sem_seg: 2.256  loss_center: 0.6295  loss_offset: 1.073  time: 0.3759  data_time: 0.0243  lr: 0.0021176  max_mem: 8976M
[12/09 11:07:21 d2.utils.events]:  eta: 0:36:15  iter: 1199  total_loss: 3.986  loss_sem_seg: 2.384  loss_center: 0.7555  loss_offset: 1.041  time: 0.3759  data_time: 0.0265  lr: 0.0021111  max_mem: 8976M
[12/09 11:07:29 d2.utils.events]:  eta: 0:36:08  iter: 1219  total_loss: 3.978  loss_sem_seg: 2.101  loss_center: 0.6991  loss_offset: 0.9848  time: 0.3759  data_time: 0.0266  lr: 0.0021045  max_mem: 8976M
[12/09 11:07:36 d2.utils.events]:  eta: 0:36:00  iter: 1239  total_loss: 3.862  loss_sem_seg: 2.174  loss_center: 0.5265  loss_offset: 1.057  time: 0.3759  data_time: 0.0270  lr: 0.002098  max_mem: 8976M
[12/09 11:07:44 d2.utils.events]:  eta: 0:35:53  iter: 1259  total_loss: 4.071  loss_sem_seg: 2.262  loss_center: 0.6589  loss_offset: 0.975  time: 0.3759  data_time: 0.0259  lr: 0.0020914  max_mem: 8976M
[12/09 11:07:51 d2.utils.events]:  eta: 0:35:45  iter: 1279  total_loss: 3.644  loss_sem_seg: 1.979  loss_center: 0.705  loss_offset: 0.9592  time: 0.3759  data_time: 0.0249  lr: 0.0020849  max_mem: 8976M
[12/09 11:07:59 d2.utils.events]:  eta: 0:35:38  iter: 1299  total_loss: 4.01  loss_sem_seg: 2.235  loss_center: 0.5716  loss_offset: 0.9437  time: 0.3759  data_time: 0.0260  lr: 0.0020783  max_mem: 8976M
[12/09 11:08:06 d2.utils.events]:  eta: 0:35:30  iter: 1319  total_loss: 4.002  loss_sem_seg: 2.373  loss_center: 0.5943  loss_offset: 1.018  time: 0.3759  data_time: 0.0257  lr: 0.0020717  max_mem: 8976M
[12/09 11:08:14 d2.utils.events]:  eta: 0:35:23  iter: 1339  total_loss: 4.004  loss_sem_seg: 2.138  loss_center: 0.767  loss_offset: 1.01  time: 0.3759  data_time: 0.0264  lr: 0.0020652  max_mem: 8976M
[12/09 11:08:21 d2.utils.events]:  eta: 0:35:15  iter: 1359  total_loss: 4.189  loss_sem_seg: 2.396  loss_center: 0.5748  loss_offset: 1.1  time: 0.3759  data_time: 0.0257  lr: 0.0020586  max_mem: 8976M
[12/09 11:08:29 d2.utils.events]:  eta: 0:35:08  iter: 1379  total_loss: 4.213  loss_sem_seg: 2.557  loss_center: 0.687  loss_offset: 1.053  time: 0.3759  data_time: 0.0252  lr: 0.002052  max_mem: 8976M
[12/09 11:08:36 d2.utils.events]:  eta: 0:35:00  iter: 1399  total_loss: 3.907  loss_sem_seg: 2.122  loss_center: 0.7286  loss_offset: 1.041  time: 0.3759  data_time: 0.0250  lr: 0.0020455  max_mem: 8976M
[12/09 11:08:44 d2.utils.events]:  eta: 0:34:53  iter: 1419  total_loss: 3.895  loss_sem_seg: 2.15  loss_center: 0.6519  loss_offset: 1.067  time: 0.3759  data_time: 0.0257  lr: 0.0020389  max_mem: 8976M
[12/09 11:08:51 d2.utils.events]:  eta: 0:34:45  iter: 1439  total_loss: 3.75  loss_sem_seg: 2.006  loss_center: 0.6633  loss_offset: 0.9777  time: 0.3759  data_time: 0.0247  lr: 0.0020323  max_mem: 8976M
[12/09 11:08:59 d2.utils.events]:  eta: 0:34:38  iter: 1459  total_loss: 3.808  loss_sem_seg: 2.254  loss_center: 0.7622  loss_offset: 0.986  time: 0.3759  data_time: 0.0268  lr: 0.0020257  max_mem: 8976M
[12/09 11:09:06 d2.utils.events]:  eta: 0:34:30  iter: 1479  total_loss: 3.953  loss_sem_seg: 2.158  loss_center: 0.6158  loss_offset: 1.056  time: 0.3759  data_time: 0.0263  lr: 0.0020191  max_mem: 8976M
[12/09 11:09:14 d2.utils.events]:  eta: 0:34:23  iter: 1499  total_loss: 3.671  loss_sem_seg: 2.068  loss_center: 0.6463  loss_offset: 0.9942  time: 0.3759  data_time: 0.0258  lr: 0.0020126  max_mem: 8976M
[12/09 11:09:21 d2.utils.events]:  eta: 0:34:15  iter: 1519  total_loss: 3.697  loss_sem_seg: 1.927  loss_center: 0.822  loss_offset: 1.02  time: 0.3759  data_time: 0.0249  lr: 0.002006  max_mem: 8976M
[12/09 11:09:29 d2.utils.events]:  eta: 0:34:08  iter: 1539  total_loss: 3.618  loss_sem_seg: 2.092  loss_center: 0.6082  loss_offset: 1.086  time: 0.3759  data_time: 0.0261  lr: 0.0019994  max_mem: 8976M
[12/09 11:09:37 d2.utils.events]:  eta: 0:34:00  iter: 1559  total_loss: 3.932  loss_sem_seg: 2.152  loss_center: 0.631  loss_offset: 1.045  time: 0.3759  data_time: 0.0274  lr: 0.0019928  max_mem: 8976M
[12/09 11:09:44 d2.utils.events]:  eta: 0:33:53  iter: 1579  total_loss: 3.73  loss_sem_seg: 2.078  loss_center: 0.6027  loss_offset: 1.005  time: 0.3759  data_time: 0.0267  lr: 0.0019862  max_mem: 8976M
[12/09 11:09:52 d2.utils.events]:  eta: 0:33:45  iter: 1599  total_loss: 3.809  loss_sem_seg: 2.193  loss_center: 0.6757  loss_offset: 1.052  time: 0.3760  data_time: 0.0270  lr: 0.0019796  max_mem: 8976M
[12/09 11:09:59 d2.utils.events]:  eta: 0:33:38  iter: 1619  total_loss: 3.467  loss_sem_seg: 1.903  loss_center: 0.7052  loss_offset: 0.9072  time: 0.3760  data_time: 0.0259  lr: 0.001973  max_mem: 8976M
[12/09 11:10:07 d2.utils.events]:  eta: 0:33:31  iter: 1639  total_loss: 3.792  loss_sem_seg: 2.066  loss_center: 0.7357  loss_offset: 0.9322  time: 0.3760  data_time: 0.0270  lr: 0.0019664  max_mem: 8976M
[12/09 11:10:14 d2.utils.events]:  eta: 0:33:23  iter: 1659  total_loss: 3.797  loss_sem_seg: 2.093  loss_center: 0.672  loss_offset: 1.081  time: 0.3760  data_time: 0.0268  lr: 0.0019598  max_mem: 8976M
[12/09 11:10:22 d2.utils.events]:  eta: 0:33:17  iter: 1679  total_loss: 3.745  loss_sem_seg: 2.176  loss_center: 0.6833  loss_offset: 0.9566  time: 0.3760  data_time: 0.0268  lr: 0.0019532  max_mem: 8976M
[12/09 11:10:29 d2.utils.events]:  eta: 0:33:09  iter: 1699  total_loss: 3.829  loss_sem_seg: 1.881  loss_center: 0.716  loss_offset: 0.9697  time: 0.3760  data_time: 0.0273  lr: 0.0019466  max_mem: 8976M
[12/09 11:10:37 d2.utils.events]:  eta: 0:33:02  iter: 1719  total_loss: 3.946  loss_sem_seg: 2.37  loss_center: 0.7769  loss_offset: 0.9889  time: 0.3761  data_time: 0.0283  lr: 0.00194  max_mem: 8976M
[12/09 11:10:45 d2.utils.events]:  eta: 0:32:53  iter: 1739  total_loss: 3.735  loss_sem_seg: 1.972  loss_center: 0.7219  loss_offset: 0.8842  time: 0.3761  data_time: 0.0244  lr: 0.0019334  max_mem: 8976M
[12/09 11:10:52 d2.utils.events]:  eta: 0:32:46  iter: 1759  total_loss: 3.818  loss_sem_seg: 2.008  loss_center: 0.628  loss_offset: 1.109  time: 0.3762  data_time: 0.0279  lr: 0.0019267  max_mem: 8976M
[12/09 11:11:00 d2.utils.events]:  eta: 0:32:40  iter: 1779  total_loss: 3.755  loss_sem_seg: 1.964  loss_center: 0.5977  loss_offset: 1.014  time: 0.3762  data_time: 0.0265  lr: 0.0019201  max_mem: 8976M
[12/09 11:11:07 d2.utils.events]:  eta: 0:32:33  iter: 1799  total_loss: 3.987  loss_sem_seg: 2.222  loss_center: 0.6137  loss_offset: 1.037  time: 0.3762  data_time: 0.0260  lr: 0.0019135  max_mem: 8976M
[12/09 11:11:15 d2.utils.events]:  eta: 0:32:26  iter: 1819  total_loss: 3.985  loss_sem_seg: 2.163  loss_center: 0.7046  loss_offset: 0.9997  time: 0.3762  data_time: 0.0260  lr: 0.0019069  max_mem: 8976M
[12/09 11:11:22 d2.utils.events]:  eta: 0:32:18  iter: 1839  total_loss: 3.796  loss_sem_seg: 2.025  loss_center: 0.6405  loss_offset: 0.912  time: 0.3762  data_time: 0.0278  lr: 0.0019003  max_mem: 8976M
[12/09 11:11:30 d2.utils.events]:  eta: 0:32:11  iter: 1859  total_loss: 3.75  loss_sem_seg: 2.016  loss_center: 0.5955  loss_offset: 1.01  time: 0.3762  data_time: 0.0257  lr: 0.0018936  max_mem: 8976M
[12/09 11:11:37 d2.utils.events]:  eta: 0:32:04  iter: 1879  total_loss: 3.843  loss_sem_seg: 2.171  loss_center: 0.7381  loss_offset: 0.9798  time: 0.3762  data_time: 0.0259  lr: 0.001887  max_mem: 8976M
[12/09 11:11:45 d2.utils.events]:  eta: 0:31:56  iter: 1899  total_loss: 3.938  loss_sem_seg: 1.917  loss_center: 0.8088  loss_offset: 1.032  time: 0.3762  data_time: 0.0276  lr: 0.0018804  max_mem: 8976M
[12/09 11:11:53 d2.utils.events]:  eta: 0:31:49  iter: 1919  total_loss: 3.288  loss_sem_seg: 1.832  loss_center: 0.6252  loss_offset: 0.83  time: 0.3762  data_time: 0.0267  lr: 0.0018737  max_mem: 8976M
[12/09 11:12:00 d2.utils.events]:  eta: 0:31:41  iter: 1939  total_loss: 3.795  loss_sem_seg: 2.081  loss_center: 0.6785  loss_offset: 0.9946  time: 0.3762  data_time: 0.0261  lr: 0.0018671  max_mem: 8976M
[12/09 11:12:08 d2.utils.events]:  eta: 0:31:34  iter: 1959  total_loss: 3.823  loss_sem_seg: 2.068  loss_center: 0.6442  loss_offset: 0.9739  time: 0.3762  data_time: 0.0261  lr: 0.0018604  max_mem: 8976M
[12/09 11:12:15 d2.utils.events]:  eta: 0:31:27  iter: 1979  total_loss: 3.521  loss_sem_seg: 2.007  loss_center: 0.6401  loss_offset: 0.9005  time: 0.3762  data_time: 0.0250  lr: 0.0018538  max_mem: 8976M
[12/09 11:12:23 d2.utils.events]:  eta: 0:31:19  iter: 1999  total_loss: 3.561  loss_sem_seg: 1.808  loss_center: 0.5816  loss_offset: 0.9675  time: 0.3762  data_time: 0.0264  lr: 0.0018472  max_mem: 8976M
[12/09 11:12:30 d2.utils.events]:  eta: 0:31:11  iter: 2019  total_loss: 3.64  loss_sem_seg: 1.948  loss_center: 0.6355  loss_offset: 0.8666  time: 0.3761  data_time: 0.0242  lr: 0.0018405  max_mem: 8976M
[12/09 11:12:38 d2.utils.events]:  eta: 0:31:03  iter: 2039  total_loss: 3.563  loss_sem_seg: 2.017  loss_center: 0.6705  loss_offset: 0.8507  time: 0.3762  data_time: 0.0278  lr: 0.0018339  max_mem: 8976M
[12/09 11:12:45 d2.utils.events]:  eta: 0:30:56  iter: 2059  total_loss: 3.665  loss_sem_seg: 1.837  loss_center: 0.8271  loss_offset: 0.9408  time: 0.3762  data_time: 0.0260  lr: 0.0018272  max_mem: 8976M
[12/09 11:12:53 d2.utils.events]:  eta: 0:30:48  iter: 2079  total_loss: 3.624  loss_sem_seg: 2.08  loss_center: 0.6101  loss_offset: 0.9864  time: 0.3761  data_time: 0.0243  lr: 0.0018205  max_mem: 8976M
[12/09 11:13:00 d2.utils.events]:  eta: 0:30:41  iter: 2099  total_loss: 3.637  loss_sem_seg: 2.063  loss_center: 0.5454  loss_offset: 1.023  time: 0.3762  data_time: 0.0270  lr: 0.0018139  max_mem: 8976M
[12/09 11:13:08 d2.utils.events]:  eta: 0:30:34  iter: 2119  total_loss: 3.516  loss_sem_seg: 1.813  loss_center: 0.6447  loss_offset: 0.9391  time: 0.3762  data_time: 0.0283  lr: 0.0018072  max_mem: 8976M
[12/09 11:13:15 d2.utils.events]:  eta: 0:30:26  iter: 2139  total_loss: 3.24  loss_sem_seg: 1.775  loss_center: 0.7008  loss_offset: 0.9702  time: 0.3762  data_time: 0.0263  lr: 0.0018005  max_mem: 8976M
[12/09 11:13:23 d2.utils.events]:  eta: 0:30:18  iter: 2159  total_loss: 3.58  loss_sem_seg: 1.771  loss_center: 0.6951  loss_offset: 0.9302  time: 0.3761  data_time: 0.0253  lr: 0.0017939  max_mem: 8976M
[12/09 11:13:30 d2.utils.events]:  eta: 0:30:12  iter: 2179  total_loss: 3.473  loss_sem_seg: 1.891  loss_center: 0.5858  loss_offset: 0.8601  time: 0.3762  data_time: 0.0275  lr: 0.0017872  max_mem: 8976M
[12/09 11:13:38 d2.utils.events]:  eta: 0:30:03  iter: 2199  total_loss: 3.645  loss_sem_seg: 1.996  loss_center: 0.6144  loss_offset: 0.9468  time: 0.3762  data_time: 0.0271  lr: 0.0017805  max_mem: 8976M
[12/09 11:13:45 d2.utils.events]:  eta: 0:29:56  iter: 2219  total_loss: 3.66  loss_sem_seg: 1.917  loss_center: 0.7489  loss_offset: 0.95  time: 0.3762  data_time: 0.0255  lr: 0.0017739  max_mem: 8976M
[12/09 11:13:53 d2.utils.events]:  eta: 0:29:49  iter: 2239  total_loss: 3.622  loss_sem_seg: 1.913  loss_center: 0.5801  loss_offset: 1.03  time: 0.3762  data_time: 0.0273  lr: 0.0017672  max_mem: 8976M
[12/09 11:14:01 d2.utils.events]:  eta: 0:29:42  iter: 2259  total_loss: 4.078  loss_sem_seg: 2.314  loss_center: 0.7098  loss_offset: 0.9882  time: 0.3762  data_time: 0.0260  lr: 0.0017605  max_mem: 8976M
[12/09 11:14:08 d2.utils.events]:  eta: 0:29:35  iter: 2279  total_loss: 3.99  loss_sem_seg: 2.161  loss_center: 0.5936  loss_offset: 0.9691  time: 0.3762  data_time: 0.0285  lr: 0.0017538  max_mem: 8976M
[12/09 11:14:16 d2.utils.events]:  eta: 0:29:27  iter: 2299  total_loss: 3.856  loss_sem_seg: 2.127  loss_center: 0.619  loss_offset: 0.9226  time: 0.3762  data_time: 0.0251  lr: 0.0017471  max_mem: 8976M
[12/09 11:14:23 d2.utils.events]:  eta: 0:29:19  iter: 2319  total_loss: 3.273  loss_sem_seg: 1.766  loss_center: 0.638  loss_offset: 0.7192  time: 0.3762  data_time: 0.0275  lr: 0.0017404  max_mem: 8976M
[12/09 11:14:31 d2.utils.events]:  eta: 0:29:11  iter: 2339  total_loss: 3.797  loss_sem_seg: 2.004  loss_center: 0.7823  loss_offset: 0.942  time: 0.3762  data_time: 0.0257  lr: 0.0017337  max_mem: 8976M
[12/09 11:14:38 d2.utils.events]:  eta: 0:29:04  iter: 2359  total_loss: 3.36  loss_sem_seg: 1.822  loss_center: 0.6699  loss_offset: 0.928  time: 0.3762  data_time: 0.0263  lr: 0.001727  max_mem: 8976M
[12/09 11:14:46 d2.utils.events]:  eta: 0:28:56  iter: 2379  total_loss: 3.492  loss_sem_seg: 1.734  loss_center: 0.685  loss_offset: 0.8844  time: 0.3762  data_time: 0.0259  lr: 0.0017203  max_mem: 8976M
[12/09 11:14:53 d2.utils.events]:  eta: 0:28:49  iter: 2399  total_loss: 3.75  loss_sem_seg: 1.761  loss_center: 0.8102  loss_offset: 1.074  time: 0.3762  data_time: 0.0265  lr: 0.0017136  max_mem: 8976M
[12/09 11:15:01 d2.utils.events]:  eta: 0:28:42  iter: 2419  total_loss: 3.569  loss_sem_seg: 1.898  loss_center: 0.6005  loss_offset: 0.9939  time: 0.3762  data_time: 0.0276  lr: 0.0017069  max_mem: 8976M
[12/09 11:15:09 d2.utils.events]:  eta: 0:28:34  iter: 2439  total_loss: 3.666  loss_sem_seg: 1.947  loss_center: 0.6539  loss_offset: 1.019  time: 0.3763  data_time: 0.0271  lr: 0.0017002  max_mem: 8976M
[12/09 11:15:16 d2.utils.events]:  eta: 0:28:27  iter: 2459  total_loss: 3.571  loss_sem_seg: 1.878  loss_center: 0.5457  loss_offset: 0.9254  time: 0.3763  data_time: 0.0268  lr: 0.0016935  max_mem: 8976M
[12/09 11:15:24 d2.utils.events]:  eta: 0:28:19  iter: 2479  total_loss: 3.406  loss_sem_seg: 1.749  loss_center: 0.6729  loss_offset: 0.9594  time: 0.3763  data_time: 0.0274  lr: 0.0016868  max_mem: 8976M
[12/09 11:15:31 d2.utils.events]:  eta: 0:28:12  iter: 2499  total_loss: 3.401  loss_sem_seg: 1.95  loss_center: 0.6157  loss_offset: 0.8954  time: 0.3763  data_time: 0.0260  lr: 0.0016801  max_mem: 8976M
[12/09 11:15:39 d2.utils.events]:  eta: 0:28:06  iter: 2519  total_loss: 3.736  loss_sem_seg: 2.022  loss_center: 0.675  loss_offset: 0.9926  time: 0.3763  data_time: 0.0275  lr: 0.0016734  max_mem: 8976M
[12/09 11:15:46 d2.utils.events]:  eta: 0:27:58  iter: 2539  total_loss: 3.522  loss_sem_seg: 1.845  loss_center: 0.5802  loss_offset: 0.9511  time: 0.3763  data_time: 0.0265  lr: 0.0016666  max_mem: 8976M
[12/09 11:15:54 d2.utils.events]:  eta: 0:27:51  iter: 2559  total_loss: 3.415  loss_sem_seg: 1.791  loss_center: 0.7048  loss_offset: 0.9187  time: 0.3763  data_time: 0.0260  lr: 0.0016599  max_mem: 8976M
[12/09 11:16:01 d2.utils.events]:  eta: 0:27:44  iter: 2579  total_loss: 3.686  loss_sem_seg: 1.905  loss_center: 0.6557  loss_offset: 1.003  time: 0.3763  data_time: 0.0249  lr: 0.0016532  max_mem: 8976M
[12/09 11:16:09 d2.utils.events]:  eta: 0:27:37  iter: 2599  total_loss: 3.656  loss_sem_seg: 1.963  loss_center: 0.7307  loss_offset: 0.9125  time: 0.3763  data_time: 0.0256  lr: 0.0016464  max_mem: 8976M
[12/09 11:16:17 d2.utils.events]:  eta: 0:27:29  iter: 2619  total_loss: 3.726  loss_sem_seg: 2.019  loss_center: 0.6626  loss_offset: 1.042  time: 0.3763  data_time: 0.0262  lr: 0.0016397  max_mem: 8976M
[12/09 11:16:24 d2.utils.events]:  eta: 0:27:21  iter: 2639  total_loss: 3.549  loss_sem_seg: 1.838  loss_center: 0.6227  loss_offset: 1.05  time: 0.3763  data_time: 0.0252  lr: 0.001633  max_mem: 8976M
[12/09 11:16:32 d2.utils.events]:  eta: 0:27:13  iter: 2659  total_loss: 3.485  loss_sem_seg: 1.683  loss_center: 0.7505  loss_offset: 0.8283  time: 0.3763  data_time: 0.0299  lr: 0.0016262  max_mem: 8976M
[12/09 11:16:39 d2.utils.events]:  eta: 0:27:06  iter: 2679  total_loss: 3.509  loss_sem_seg: 1.892  loss_center: 0.7193  loss_offset: 0.9328  time: 0.3763  data_time: 0.0272  lr: 0.0016195  max_mem: 8976M
[12/09 11:16:47 d2.utils.events]:  eta: 0:26:58  iter: 2699  total_loss: 3.638  loss_sem_seg: 1.969  loss_center: 0.7549  loss_offset: 0.9217  time: 0.3764  data_time: 0.0279  lr: 0.0016127  max_mem: 8976M
[12/09 11:16:54 d2.utils.events]:  eta: 0:26:51  iter: 2719  total_loss: 3.633  loss_sem_seg: 2.115  loss_center: 0.5034  loss_offset: 0.9725  time: 0.3764  data_time: 0.0264  lr: 0.001606  max_mem: 8976M
[12/09 11:17:02 d2.utils.events]:  eta: 0:26:44  iter: 2739  total_loss: 3.393  loss_sem_seg: 1.636  loss_center: 0.6415  loss_offset: 0.8734  time: 0.3764  data_time: 0.0292  lr: 0.0015992  max_mem: 8976M
[12/09 11:17:10 d2.utils.events]:  eta: 0:26:36  iter: 2759  total_loss: 3.443  loss_sem_seg: 1.777  loss_center: 0.6666  loss_offset: 0.8841  time: 0.3764  data_time: 0.0254  lr: 0.0015925  max_mem: 8976M
[12/09 11:17:17 d2.utils.events]:  eta: 0:26:28  iter: 2779  total_loss: 3.298  loss_sem_seg: 1.719  loss_center: 0.6282  loss_offset: 0.8899  time: 0.3764  data_time: 0.0253  lr: 0.0015857  max_mem: 8976M
[12/09 11:17:25 d2.utils.events]:  eta: 0:26:20  iter: 2799  total_loss: 3.662  loss_sem_seg: 1.905  loss_center: 0.5765  loss_offset: 0.9569  time: 0.3764  data_time: 0.0263  lr: 0.001579  max_mem: 8976M
[12/09 11:17:32 d2.utils.events]:  eta: 0:26:12  iter: 2819  total_loss: 3.285  loss_sem_seg: 1.662  loss_center: 0.7124  loss_offset: 0.9637  time: 0.3764  data_time: 0.0246  lr: 0.0015722  max_mem: 8976M
[12/09 11:17:40 d2.utils.events]:  eta: 0:26:05  iter: 2839  total_loss: 3.392  loss_sem_seg: 1.908  loss_center: 0.5885  loss_offset: 1.013  time: 0.3764  data_time: 0.0275  lr: 0.0015654  max_mem: 8976M
[12/09 11:17:47 d2.utils.events]:  eta: 0:25:57  iter: 2859  total_loss: 3.605  loss_sem_seg: 2.023  loss_center: 0.7966  loss_offset: 0.7785  time: 0.3764  data_time: 0.0264  lr: 0.0015586  max_mem: 8976M
[12/09 11:17:55 d2.utils.events]:  eta: 0:25:50  iter: 2879  total_loss: 3.933  loss_sem_seg: 2.045  loss_center: 0.8282  loss_offset: 0.861  time: 0.3764  data_time: 0.0258  lr: 0.0015519  max_mem: 8976M
[12/09 11:18:02 d2.utils.events]:  eta: 0:25:42  iter: 2899  total_loss: 3.522  loss_sem_seg: 1.675  loss_center: 0.6827  loss_offset: 0.9059  time: 0.3764  data_time: 0.0248  lr: 0.0015451  max_mem: 8976M
[12/09 11:18:10 d2.utils.events]:  eta: 0:25:34  iter: 2919  total_loss: 3.05  loss_sem_seg: 1.694  loss_center: 0.6387  loss_offset: 0.8367  time: 0.3764  data_time: 0.0260  lr: 0.0015383  max_mem: 8976M
[12/09 11:18:17 d2.utils.events]:  eta: 0:25:26  iter: 2939  total_loss: 3.179  loss_sem_seg: 1.662  loss_center: 0.6205  loss_offset: 0.9132  time: 0.3764  data_time: 0.0259  lr: 0.0015315  max_mem: 8976M
[12/09 11:18:25 d2.utils.events]:  eta: 0:25:19  iter: 2959  total_loss: 3.443  loss_sem_seg: 1.859  loss_center: 0.6138  loss_offset: 0.9845  time: 0.3764  data_time: 0.0271  lr: 0.0015247  max_mem: 8976M
[12/09 11:18:32 d2.utils.events]:  eta: 0:25:11  iter: 2979  total_loss: 3.232  loss_sem_seg: 1.69  loss_center: 0.6169  loss_offset: 0.8295  time: 0.3764  data_time: 0.0259  lr: 0.0015179  max_mem: 8976M
[12/09 11:18:40 d2.utils.events]:  eta: 0:25:04  iter: 2999  total_loss: 3.428  loss_sem_seg: 1.762  loss_center: 0.579  loss_offset: 0.8534  time: 0.3764  data_time: 0.0260  lr: 0.0015111  max_mem: 8976M
[12/09 11:18:47 d2.utils.events]:  eta: 0:24:57  iter: 3019  total_loss: 3.564  loss_sem_seg: 2.016  loss_center: 0.5631  loss_offset: 0.8854  time: 0.3764  data_time: 0.0255  lr: 0.0015043  max_mem: 8976M
[12/09 11:18:55 d2.utils.events]:  eta: 0:24:50  iter: 3039  total_loss: 3.936  loss_sem_seg: 2.073  loss_center: 0.7184  loss_offset: 0.9934  time: 0.3764  data_time: 0.0264  lr: 0.0014975  max_mem: 8976M
[12/09 11:19:03 d2.utils.events]:  eta: 0:24:42  iter: 3059  total_loss: 3.871  loss_sem_seg: 2.123  loss_center: 0.6119  loss_offset: 0.9382  time: 0.3764  data_time: 0.0263  lr: 0.0014907  max_mem: 8976M
[12/09 11:19:10 d2.utils.events]:  eta: 0:24:35  iter: 3079  total_loss: 3.463  loss_sem_seg: 1.828  loss_center: 0.7729  loss_offset: 0.8493  time: 0.3764  data_time: 0.0256  lr: 0.0014839  max_mem: 8976M
[12/09 11:19:18 d2.utils.events]:  eta: 0:24:27  iter: 3099  total_loss: 3.345  loss_sem_seg: 1.793  loss_center: 0.6512  loss_offset: 0.9785  time: 0.3763  data_time: 0.0244  lr: 0.0014771  max_mem: 8976M
[12/09 11:19:25 d2.utils.events]:  eta: 0:24:20  iter: 3119  total_loss: 3.381  loss_sem_seg: 1.885  loss_center: 0.5107  loss_offset: 0.9519  time: 0.3763  data_time: 0.0269  lr: 0.0014703  max_mem: 8976M
[12/09 11:19:33 d2.utils.events]:  eta: 0:24:13  iter: 3139  total_loss: 3.399  loss_sem_seg: 1.696  loss_center: 0.654  loss_offset: 0.8839  time: 0.3763  data_time: 0.0242  lr: 0.0014635  max_mem: 8976M
[12/09 11:19:40 d2.utils.events]:  eta: 0:24:06  iter: 3159  total_loss: 3.74  loss_sem_seg: 1.863  loss_center: 0.7738  loss_offset: 0.8728  time: 0.3763  data_time: 0.0262  lr: 0.0014566  max_mem: 8976M
[12/09 11:19:48 d2.utils.events]:  eta: 0:23:58  iter: 3179  total_loss: 3.552  loss_sem_seg: 1.907  loss_center: 0.7154  loss_offset: 0.8302  time: 0.3763  data_time: 0.0276  lr: 0.0014498  max_mem: 8976M
[12/09 11:19:55 d2.utils.events]:  eta: 0:23:50  iter: 3199  total_loss: 3.545  loss_sem_seg: 1.966  loss_center: 0.639  loss_offset: 0.9599  time: 0.3763  data_time: 0.0273  lr: 0.001443  max_mem: 8976M
[12/09 11:20:03 d2.utils.events]:  eta: 0:23:43  iter: 3219  total_loss: 3.475  loss_sem_seg: 1.838  loss_center: 0.7338  loss_offset: 0.8863  time: 0.3763  data_time: 0.0261  lr: 0.0014361  max_mem: 8976M
[12/09 11:20:10 d2.utils.events]:  eta: 0:23:35  iter: 3239  total_loss: 3.39  loss_sem_seg: 1.914  loss_center: 0.6596  loss_offset: 0.8764  time: 0.3763  data_time: 0.0262  lr: 0.0014293  max_mem: 8976M
[12/09 11:20:18 d2.utils.events]:  eta: 0:23:28  iter: 3259  total_loss: 3.267  loss_sem_seg: 1.691  loss_center: 0.6015  loss_offset: 0.8456  time: 0.3763  data_time: 0.0260  lr: 0.0014225  max_mem: 8976M
[12/09 11:20:25 d2.utils.events]:  eta: 0:23:19  iter: 3279  total_loss: 3.447  loss_sem_seg: 1.664  loss_center: 0.7439  loss_offset: 0.9191  time: 0.3763  data_time: 0.0265  lr: 0.0014156  max_mem: 8976M
[12/09 11:20:33 d2.utils.events]:  eta: 0:23:12  iter: 3299  total_loss: 3.473  loss_sem_seg: 1.741  loss_center: 0.6731  loss_offset: 0.8125  time: 0.3763  data_time: 0.0265  lr: 0.0014088  max_mem: 8976M
[12/09 11:20:40 d2.utils.events]:  eta: 0:23:05  iter: 3319  total_loss: 3.579  loss_sem_seg: 1.845  loss_center: 0.731  loss_offset: 0.8445  time: 0.3764  data_time: 0.0288  lr: 0.0014019  max_mem: 8976M
[12/09 11:20:48 d2.utils.events]:  eta: 0:22:58  iter: 3339  total_loss: 3.394  loss_sem_seg: 1.886  loss_center: 0.5549  loss_offset: 0.8699  time: 0.3764  data_time: 0.0261  lr: 0.0013951  max_mem: 8976M
[12/09 11:20:56 d2.utils.events]:  eta: 0:22:50  iter: 3359  total_loss: 3.367  loss_sem_seg: 1.828  loss_center: 0.5482  loss_offset: 0.8694  time: 0.3764  data_time: 0.0264  lr: 0.0013882  max_mem: 8976M
[12/09 11:21:03 d2.utils.events]:  eta: 0:22:43  iter: 3379  total_loss: 3.226  loss_sem_seg: 1.713  loss_center: 0.6154  loss_offset: 0.8415  time: 0.3764  data_time: 0.0280  lr: 0.0013813  max_mem: 8976M
[12/09 11:21:11 d2.utils.events]:  eta: 0:22:34  iter: 3399  total_loss: 3.522  loss_sem_seg: 1.678  loss_center: 0.763  loss_offset: 0.8447  time: 0.3764  data_time: 0.0260  lr: 0.0013745  max_mem: 8976M
[12/09 11:21:18 d2.utils.events]:  eta: 0:22:27  iter: 3419  total_loss: 3.26  loss_sem_seg: 1.747  loss_center: 0.5497  loss_offset: 0.8508  time: 0.3764  data_time: 0.0283  lr: 0.0013676  max_mem: 8976M
[12/09 11:21:26 d2.utils.events]:  eta: 0:22:19  iter: 3439  total_loss: 3.397  loss_sem_seg: 1.799  loss_center: 0.7419  loss_offset: 0.9311  time: 0.3764  data_time: 0.0268  lr: 0.0013607  max_mem: 8976M
[12/09 11:21:33 d2.utils.events]:  eta: 0:22:12  iter: 3459  total_loss: 3.135  loss_sem_seg: 1.65  loss_center: 0.5543  loss_offset: 0.9046  time: 0.3764  data_time: 0.0267  lr: 0.0013538  max_mem: 8976M
[12/09 11:21:41 d2.utils.events]:  eta: 0:22:04  iter: 3479  total_loss: 3.283  loss_sem_seg: 1.728  loss_center: 0.6343  loss_offset: 0.8238  time: 0.3764  data_time: 0.0260  lr: 0.0013469  max_mem: 8976M
[12/09 11:21:49 d2.utils.events]:  eta: 0:21:56  iter: 3499  total_loss: 3.792  loss_sem_seg: 1.986  loss_center: 0.6452  loss_offset: 0.9201  time: 0.3764  data_time: 0.0255  lr: 0.0013401  max_mem: 8976M
[12/09 11:21:56 d2.utils.events]:  eta: 0:21:49  iter: 3519  total_loss: 3.291  loss_sem_seg: 1.73  loss_center: 0.6403  loss_offset: 0.9322  time: 0.3764  data_time: 0.0259  lr: 0.0013332  max_mem: 8976M
[12/09 11:22:04 d2.utils.events]:  eta: 0:21:41  iter: 3539  total_loss: 3.251  loss_sem_seg: 1.638  loss_center: 0.618  loss_offset: 0.912  time: 0.3764  data_time: 0.0261  lr: 0.0013263  max_mem: 8976M
[12/09 11:22:11 d2.utils.events]:  eta: 0:21:33  iter: 3559  total_loss: 3.054  loss_sem_seg: 1.718  loss_center: 0.6378  loss_offset: 0.7106  time: 0.3764  data_time: 0.0270  lr: 0.0013194  max_mem: 8976M
[12/09 11:22:19 d2.utils.events]:  eta: 0:21:26  iter: 3579  total_loss: 3.466  loss_sem_seg: 1.737  loss_center: 0.5543  loss_offset: 0.8821  time: 0.3764  data_time: 0.0283  lr: 0.0013125  max_mem: 8976M
[12/09 11:22:26 d2.utils.events]:  eta: 0:21:18  iter: 3599  total_loss: 3.303  loss_sem_seg: 1.817  loss_center: 0.6469  loss_offset: 0.8401  time: 0.3764  data_time: 0.0253  lr: 0.0013056  max_mem: 8976M
[12/09 11:22:34 d2.utils.events]:  eta: 0:21:11  iter: 3619  total_loss: 3.229  loss_sem_seg: 1.732  loss_center: 0.5695  loss_offset: 0.859  time: 0.3764  data_time: 0.0268  lr: 0.0012987  max_mem: 8976M
[12/09 11:22:41 d2.utils.events]:  eta: 0:21:04  iter: 3639  total_loss: 3.588  loss_sem_seg: 1.864  loss_center: 0.6087  loss_offset: 0.9009  time: 0.3764  data_time: 0.0267  lr: 0.0012917  max_mem: 8976M
[12/09 11:22:49 d2.utils.events]:  eta: 0:20:56  iter: 3659  total_loss: 2.972  loss_sem_seg: 1.553  loss_center: 0.5559  loss_offset: 0.8645  time: 0.3764  data_time: 0.0254  lr: 0.0012848  max_mem: 8976M
[12/09 11:22:56 d2.utils.events]:  eta: 0:20:49  iter: 3679  total_loss: 3.151  loss_sem_seg: 1.605  loss_center: 0.5605  loss_offset: 0.8803  time: 0.3764  data_time: 0.0262  lr: 0.0012779  max_mem: 8976M
[12/09 11:23:04 d2.utils.events]:  eta: 0:20:41  iter: 3699  total_loss: 3.216  loss_sem_seg: 1.518  loss_center: 0.6163  loss_offset: 0.8795  time: 0.3764  data_time: 0.0257  lr: 0.001271  max_mem: 8976M
[12/09 11:23:11 d2.utils.events]:  eta: 0:20:33  iter: 3719  total_loss: 3.387  loss_sem_seg: 1.763  loss_center: 0.704  loss_offset: 0.8394  time: 0.3764  data_time: 0.0256  lr: 0.001264  max_mem: 8976M
[12/09 11:23:19 d2.utils.events]:  eta: 0:20:25  iter: 3739  total_loss: 3.376  loss_sem_seg: 1.898  loss_center: 0.6303  loss_offset: 0.7727  time: 0.3764  data_time: 0.0266  lr: 0.0012571  max_mem: 8976M
[12/09 11:23:27 d2.utils.events]:  eta: 0:20:18  iter: 3759  total_loss: 3.359  loss_sem_seg: 2.091  loss_center: 0.5827  loss_offset: 0.9296  time: 0.3764  data_time: 0.0272  lr: 0.0012502  max_mem: 8976M
[12/09 11:23:34 d2.utils.events]:  eta: 0:20:11  iter: 3779  total_loss: 3.351  loss_sem_seg: 1.717  loss_center: 0.7314  loss_offset: 0.824  time: 0.3765  data_time: 0.0281  lr: 0.0012432  max_mem: 8976M
[12/09 11:23:42 d2.utils.events]:  eta: 0:20:04  iter: 3799  total_loss: 3.445  loss_sem_seg: 1.822  loss_center: 0.579  loss_offset: 0.9155  time: 0.3765  data_time: 0.0258  lr: 0.0012363  max_mem: 8976M
[12/09 11:23:49 d2.utils.events]:  eta: 0:19:56  iter: 3819  total_loss: 3.433  loss_sem_seg: 1.895  loss_center: 0.5742  loss_offset: 0.8707  time: 0.3765  data_time: 0.0254  lr: 0.0012293  max_mem: 8976M
[12/09 11:23:57 d2.utils.events]:  eta: 0:19:49  iter: 3839  total_loss: 3.209  loss_sem_seg: 1.695  loss_center: 0.5737  loss_offset: 0.9515  time: 0.3765  data_time: 0.0265  lr: 0.0012223  max_mem: 8976M
[12/09 11:24:04 d2.utils.events]:  eta: 0:19:41  iter: 3859  total_loss: 2.975  loss_sem_seg: 1.475  loss_center: 0.7436  loss_offset: 0.7421  time: 0.3765  data_time: 0.0259  lr: 0.0012154  max_mem: 8976M
[12/09 11:24:12 d2.utils.events]:  eta: 0:19:33  iter: 3879  total_loss: 3.296  loss_sem_seg: 1.827  loss_center: 0.6656  loss_offset: 0.827  time: 0.3764  data_time: 0.0243  lr: 0.0012084  max_mem: 8976M
[12/09 11:24:19 d2.utils.events]:  eta: 0:19:26  iter: 3899  total_loss: 3.282  loss_sem_seg: 1.721  loss_center: 0.5517  loss_offset: 0.8438  time: 0.3764  data_time: 0.0259  lr: 0.0012014  max_mem: 8976M
[12/09 11:24:27 d2.utils.events]:  eta: 0:19:19  iter: 3919  total_loss: 3.294  loss_sem_seg: 1.703  loss_center: 0.7551  loss_offset: 0.8669  time: 0.3765  data_time: 0.0268  lr: 0.0011945  max_mem: 8976M
[12/09 11:24:35 d2.utils.events]:  eta: 0:19:11  iter: 3939  total_loss: 3.413  loss_sem_seg: 1.774  loss_center: 0.6277  loss_offset: 0.908  time: 0.3765  data_time: 0.0257  lr: 0.0011875  max_mem: 8976M
[12/09 11:24:42 d2.utils.events]:  eta: 0:19:04  iter: 3959  total_loss: 3.52  loss_sem_seg: 1.884  loss_center: 0.6976  loss_offset: 0.861  time: 0.3764  data_time: 0.0262  lr: 0.0011805  max_mem: 8976M
[12/09 11:24:50 d2.utils.events]:  eta: 0:18:56  iter: 3979  total_loss: 3.108  loss_sem_seg: 1.61  loss_center: 0.7497  loss_offset: 0.8712  time: 0.3764  data_time: 0.0253  lr: 0.0011735  max_mem: 8976M
[12/09 11:24:57 d2.utils.events]:  eta: 0:18:49  iter: 3999  total_loss: 3.346  loss_sem_seg: 1.683  loss_center: 0.7808  loss_offset: 0.8197  time: 0.3764  data_time: 0.0264  lr: 0.0011665  max_mem: 8976M
[12/09 11:25:05 d2.utils.events]:  eta: 0:18:41  iter: 4019  total_loss: 2.974  loss_sem_seg: 1.495  loss_center: 0.6124  loss_offset: 0.8792  time: 0.3764  data_time: 0.0268  lr: 0.0011595  max_mem: 8976M
[12/09 11:25:12 d2.utils.events]:  eta: 0:18:33  iter: 4039  total_loss: 3.288  loss_sem_seg: 1.663  loss_center: 0.686  loss_offset: 0.9065  time: 0.3764  data_time: 0.0260  lr: 0.0011525  max_mem: 8976M
[12/09 11:25:20 d2.utils.events]:  eta: 0:18:26  iter: 4059  total_loss: 3.364  loss_sem_seg: 1.799  loss_center: 0.5679  loss_offset: 0.8877  time: 0.3764  data_time: 0.0272  lr: 0.0011455  max_mem: 8976M
[12/09 11:25:27 d2.utils.events]:  eta: 0:18:18  iter: 4079  total_loss: 3.113  loss_sem_seg: 1.514  loss_center: 0.5557  loss_offset: 0.8416  time: 0.3764  data_time: 0.0262  lr: 0.0011385  max_mem: 8976M
[12/09 11:25:35 d2.utils.events]:  eta: 0:18:11  iter: 4099  total_loss: 3.166  loss_sem_seg: 1.68  loss_center: 0.4938  loss_offset: 0.8609  time: 0.3764  data_time: 0.0260  lr: 0.0011315  max_mem: 8976M
[12/09 11:25:42 d2.utils.events]:  eta: 0:18:03  iter: 4119  total_loss: 3.308  loss_sem_seg: 1.772  loss_center: 0.645  loss_offset: 0.8298  time: 0.3764  data_time: 0.0257  lr: 0.0011245  max_mem: 8976M
[12/09 11:25:50 d2.utils.events]:  eta: 0:17:55  iter: 4139  total_loss: 3.042  loss_sem_seg: 1.483  loss_center: 0.6981  loss_offset: 0.8365  time: 0.3764  data_time: 0.0280  lr: 0.0011174  max_mem: 8976M
[12/09 11:25:57 d2.utils.events]:  eta: 0:17:48  iter: 4159  total_loss: 3.103  loss_sem_seg: 1.599  loss_center: 0.6128  loss_offset: 0.8624  time: 0.3764  data_time: 0.0261  lr: 0.0011104  max_mem: 8976M
[12/09 11:26:05 d2.utils.events]:  eta: 0:17:40  iter: 4179  total_loss: 3.057  loss_sem_seg: 1.349  loss_center: 0.7274  loss_offset: 0.8282  time: 0.3764  data_time: 0.0261  lr: 0.0011034  max_mem: 8976M
[12/09 11:26:12 d2.utils.events]:  eta: 0:17:33  iter: 4199  total_loss: 3.278  loss_sem_seg: 1.804  loss_center: 0.7041  loss_offset: 0.8752  time: 0.3764  data_time: 0.0256  lr: 0.0010963  max_mem: 8976M
[12/09 11:26:20 d2.utils.events]:  eta: 0:17:25  iter: 4219  total_loss: 3.379  loss_sem_seg: 1.756  loss_center: 0.5905  loss_offset: 0.8715  time: 0.3764  data_time: 0.0259  lr: 0.0010893  max_mem: 8976M
[12/09 11:26:27 d2.utils.events]:  eta: 0:17:18  iter: 4239  total_loss: 3.116  loss_sem_seg: 1.576  loss_center: 0.584  loss_offset: 0.9085  time: 0.3764  data_time: 0.0263  lr: 0.0010822  max_mem: 8976M
[12/09 11:26:35 d2.utils.events]:  eta: 0:17:10  iter: 4259  total_loss: 3.2  loss_sem_seg: 1.716  loss_center: 0.635  loss_offset: 0.8297  time: 0.3764  data_time: 0.0271  lr: 0.0010752  max_mem: 8976M
[12/09 11:26:43 d2.utils.events]:  eta: 0:17:03  iter: 4279  total_loss: 3.036  loss_sem_seg: 1.566  loss_center: 0.5935  loss_offset: 0.8653  time: 0.3764  data_time: 0.0274  lr: 0.0010681  max_mem: 8976M
[12/09 11:26:50 d2.utils.events]:  eta: 0:16:55  iter: 4299  total_loss: 3.352  loss_sem_seg: 1.866  loss_center: 0.4948  loss_offset: 0.9334  time: 0.3764  data_time: 0.0257  lr: 0.001061  max_mem: 8976M
[12/09 11:26:58 d2.utils.events]:  eta: 0:16:48  iter: 4319  total_loss: 3.142  loss_sem_seg: 1.674  loss_center: 0.5518  loss_offset: 0.9263  time: 0.3764  data_time: 0.0282  lr: 0.0010539  max_mem: 8976M
[12/09 11:27:05 d2.utils.events]:  eta: 0:16:40  iter: 4339  total_loss: 3.135  loss_sem_seg: 1.616  loss_center: 0.617  loss_offset: 0.8861  time: 0.3764  data_time: 0.0252  lr: 0.0010469  max_mem: 8976M
[12/09 11:27:13 d2.utils.events]:  eta: 0:16:33  iter: 4359  total_loss: 3.568  loss_sem_seg: 1.872  loss_center: 0.7343  loss_offset: 0.935  time: 0.3764  data_time: 0.0272  lr: 0.0010398  max_mem: 8976M
[12/09 11:27:20 d2.utils.events]:  eta: 0:16:25  iter: 4379  total_loss: 3.18  loss_sem_seg: 1.687  loss_center: 0.743  loss_offset: 0.8348  time: 0.3764  data_time: 0.0270  lr: 0.0010327  max_mem: 8976M
[12/09 11:27:28 d2.utils.events]:  eta: 0:16:18  iter: 4399  total_loss: 3.416  loss_sem_seg: 1.823  loss_center: 0.6279  loss_offset: 0.8929  time: 0.3764  data_time: 0.0264  lr: 0.0010256  max_mem: 8976M
[12/09 11:27:35 d2.utils.events]:  eta: 0:16:10  iter: 4419  total_loss: 3.106  loss_sem_seg: 1.547  loss_center: 0.6346  loss_offset: 0.821  time: 0.3764  data_time: 0.0259  lr: 0.0010185  max_mem: 8976M
[12/09 11:27:43 d2.utils.events]:  eta: 0:16:02  iter: 4439  total_loss: 3.632  loss_sem_seg: 1.949  loss_center: 0.5279  loss_offset: 0.9941  time: 0.3764  data_time: 0.0279  lr: 0.0010114  max_mem: 8976M
[12/09 11:27:51 d2.utils.events]:  eta: 0:15:55  iter: 4459  total_loss: 3.416  loss_sem_seg: 1.634  loss_center: 0.8524  loss_offset: 0.9835  time: 0.3764  data_time: 0.0253  lr: 0.0010043  max_mem: 8976M
[12/09 11:27:58 d2.utils.events]:  eta: 0:15:47  iter: 4479  total_loss: 3.201  loss_sem_seg: 1.603  loss_center: 0.566  loss_offset: 0.8521  time: 0.3764  data_time: 0.0256  lr: 0.00099717  max_mem: 8976M
[12/09 11:28:06 d2.utils.events]:  eta: 0:15:39  iter: 4499  total_loss: 3.209  loss_sem_seg: 1.61  loss_center: 0.507  loss_offset: 0.816  time: 0.3764  data_time: 0.0263  lr: 0.00099004  max_mem: 8976M
[12/09 11:28:13 d2.utils.events]:  eta: 0:15:31  iter: 4519  total_loss: 3.165  loss_sem_seg: 1.529  loss_center: 0.6288  loss_offset: 0.8204  time: 0.3764  data_time: 0.0266  lr: 0.00098291  max_mem: 8976M
[12/09 11:28:21 d2.utils.events]:  eta: 0:15:24  iter: 4539  total_loss: 3.121  loss_sem_seg: 1.604  loss_center: 0.5889  loss_offset: 0.8797  time: 0.3764  data_time: 0.0260  lr: 0.00097578  max_mem: 8976M
[12/09 11:28:28 d2.utils.events]:  eta: 0:15:16  iter: 4559  total_loss: 3.319  loss_sem_seg: 1.665  loss_center: 0.6892  loss_offset: 0.8278  time: 0.3764  data_time: 0.0260  lr: 0.00096864  max_mem: 8976M
[12/09 11:28:36 d2.utils.events]:  eta: 0:15:09  iter: 4579  total_loss: 3.412  loss_sem_seg: 1.861  loss_center: 0.5945  loss_offset: 0.9205  time: 0.3764  data_time: 0.0262  lr: 0.0009615  max_mem: 8976M
[12/09 11:28:43 d2.utils.events]:  eta: 0:15:01  iter: 4599  total_loss: 3.418  loss_sem_seg: 1.766  loss_center: 0.6993  loss_offset: 0.9377  time: 0.3764  data_time: 0.0257  lr: 0.00095434  max_mem: 8976M
[12/09 11:28:51 d2.utils.events]:  eta: 0:14:53  iter: 4619  total_loss: 3.159  loss_sem_seg: 1.683  loss_center: 0.7319  loss_offset: 0.7896  time: 0.3764  data_time: 0.0254  lr: 0.00094719  max_mem: 8976M
[12/09 11:28:58 d2.utils.events]:  eta: 0:14:46  iter: 4639  total_loss: 3.4  loss_sem_seg: 1.761  loss_center: 0.5453  loss_offset: 0.9169  time: 0.3764  data_time: 0.0261  lr: 0.00094002  max_mem: 8976M
[12/09 11:29:06 d2.utils.events]:  eta: 0:14:38  iter: 4659  total_loss: 3.064  loss_sem_seg: 1.53  loss_center: 0.5529  loss_offset: 0.7812  time: 0.3764  data_time: 0.0254  lr: 0.00093285  max_mem: 8976M
[12/09 11:29:13 d2.utils.events]:  eta: 0:14:30  iter: 4679  total_loss: 3.509  loss_sem_seg: 2.027  loss_center: 0.6852  loss_offset: 0.8008  time: 0.3764  data_time: 0.0275  lr: 0.00092568  max_mem: 8976M
[12/09 11:29:21 d2.utils.events]:  eta: 0:14:23  iter: 4699  total_loss: 3.309  loss_sem_seg: 1.693  loss_center: 0.6922  loss_offset: 0.8818  time: 0.3765  data_time: 0.0276  lr: 0.00091849  max_mem: 8976M
[12/09 11:29:29 d2.utils.events]:  eta: 0:14:16  iter: 4719  total_loss: 3.347  loss_sem_seg: 1.721  loss_center: 0.5289  loss_offset: 0.9208  time: 0.3765  data_time: 0.0252  lr: 0.00091131  max_mem: 8976M
[12/09 11:29:36 d2.utils.events]:  eta: 0:14:09  iter: 4739  total_loss: 3.461  loss_sem_seg: 1.823  loss_center: 0.6065  loss_offset: 0.7694  time: 0.3765  data_time: 0.0282  lr: 0.00090411  max_mem: 8976M
[12/09 11:29:44 d2.utils.events]:  eta: 0:14:01  iter: 4759  total_loss: 3.251  loss_sem_seg: 1.606  loss_center: 0.6433  loss_offset: 0.8292  time: 0.3765  data_time: 0.0264  lr: 0.00089691  max_mem: 8976M
[12/09 11:29:51 d2.utils.events]:  eta: 0:13:53  iter: 4779  total_loss: 3.062  loss_sem_seg: 1.424  loss_center: 0.6996  loss_offset: 0.7897  time: 0.3764  data_time: 0.0253  lr: 0.0008897  max_mem: 8976M
[12/09 11:29:59 d2.utils.events]:  eta: 0:13:45  iter: 4799  total_loss: 3.121  loss_sem_seg: 1.556  loss_center: 0.7804  loss_offset: 0.8247  time: 0.3764  data_time: 0.0261  lr: 0.00088249  max_mem: 8976M
[12/09 11:30:06 d2.utils.events]:  eta: 0:13:38  iter: 4819  total_loss: 3.264  loss_sem_seg: 1.725  loss_center: 0.6281  loss_offset: 0.8126  time: 0.3765  data_time: 0.0279  lr: 0.00087527  max_mem: 8976M
[12/09 11:30:14 d2.utils.events]:  eta: 0:13:30  iter: 4839  total_loss: 3.256  loss_sem_seg: 1.659  loss_center: 0.5401  loss_offset: 0.8577  time: 0.3765  data_time: 0.0269  lr: 0.00086804  max_mem: 8976M
[12/09 11:30:21 d2.utils.events]:  eta: 0:13:23  iter: 4859  total_loss: 2.804  loss_sem_seg: 1.542  loss_center: 0.5246  loss_offset: 0.8104  time: 0.3765  data_time: 0.0248  lr: 0.00086081  max_mem: 8976M
[12/09 11:30:29 d2.utils.events]:  eta: 0:13:16  iter: 4879  total_loss: 3.106  loss_sem_seg: 1.575  loss_center: 0.6614  loss_offset: 0.7673  time: 0.3765  data_time: 0.0257  lr: 0.00085357  max_mem: 8976M
[12/09 11:30:37 d2.utils.events]:  eta: 0:13:08  iter: 4899  total_loss: 2.972  loss_sem_seg: 1.579  loss_center: 0.5525  loss_offset: 0.8843  time: 0.3765  data_time: 0.0276  lr: 0.00084632  max_mem: 8976M
[12/09 11:30:44 d2.utils.events]:  eta: 0:13:00  iter: 4919  total_loss: 3.074  loss_sem_seg: 1.706  loss_center: 0.5746  loss_offset: 0.763  time: 0.3765  data_time: 0.0256  lr: 0.00083907  max_mem: 8976M
[12/09 11:30:52 d2.utils.events]:  eta: 0:12:53  iter: 4939  total_loss: 3.274  loss_sem_seg: 1.576  loss_center: 0.7292  loss_offset: 0.7496  time: 0.3765  data_time: 0.0282  lr: 0.00083181  max_mem: 8976M
[12/09 11:30:59 d2.utils.events]:  eta: 0:12:45  iter: 4959  total_loss: 3.111  loss_sem_seg: 1.549  loss_center: 0.6555  loss_offset: 0.827  time: 0.3765  data_time: 0.0260  lr: 0.00082454  max_mem: 8976M
[12/09 11:31:07 d2.utils.events]:  eta: 0:12:38  iter: 4979  total_loss: 3.061  loss_sem_seg: 1.563  loss_center: 0.5419  loss_offset: 0.7774  time: 0.3765  data_time: 0.0269  lr: 0.00081726  max_mem: 8976M
[12/09 11:31:14 fvcore.common.checkpoint]: Saving checkpoint to ./output/model_0004999.pth
[12/09 11:31:15 d2.utils.events]:  eta: 0:12:30  iter: 4999  total_loss: 3.249  loss_sem_seg: 1.678  loss_center: 0.627  loss_offset: 0.8704  time: 0.3765  data_time: 0.0265  lr: 0.00080998  max_mem: 8976M
[12/09 11:31:23 d2.utils.events]:  eta: 0:12:23  iter: 5019  total_loss: 3.32  loss_sem_seg: 1.739  loss_center: 0.6777  loss_offset: 0.9433  time: 0.3765  data_time: 0.0257  lr: 0.00080269  max_mem: 8976M
[12/09 11:31:31 d2.utils.events]:  eta: 0:12:15  iter: 5039  total_loss: 3.345  loss_sem_seg: 1.739  loss_center: 0.7132  loss_offset: 0.8196  time: 0.3765  data_time: 0.0258  lr: 0.00079539  max_mem: 8976M
[12/09 11:31:38 d2.utils.events]:  eta: 0:12:08  iter: 5059  total_loss: 3.293  loss_sem_seg: 1.715  loss_center: 0.81  loss_offset: 0.8654  time: 0.3765  data_time: 0.0275  lr: 0.00078809  max_mem: 8976M
[12/09 11:31:46 d2.utils.events]:  eta: 0:12:00  iter: 5079  total_loss: 3.112  loss_sem_seg: 1.894  loss_center: 0.5271  loss_offset: 0.7949  time: 0.3765  data_time: 0.0254  lr: 0.00078078  max_mem: 8976M
[12/09 11:31:53 d2.utils.events]:  eta: 0:11:53  iter: 5099  total_loss: 3.153  loss_sem_seg: 1.631  loss_center: 0.6076  loss_offset: 0.8104  time: 0.3765  data_time: 0.0271  lr: 0.00077346  max_mem: 8976M
[12/09 11:32:01 d2.utils.events]:  eta: 0:11:46  iter: 5119  total_loss: 3.124  loss_sem_seg: 1.673  loss_center: 0.6043  loss_offset: 0.7729  time: 0.3765  data_time: 0.0270  lr: 0.00076613  max_mem: 8976M
[12/09 11:32:08 d2.utils.events]:  eta: 0:11:38  iter: 5139  total_loss: 3.086  loss_sem_seg: 1.523  loss_center: 0.6162  loss_offset: 0.8577  time: 0.3765  data_time: 0.0263  lr: 0.00075879  max_mem: 8976M
[12/09 11:32:16 d2.utils.events]:  eta: 0:11:30  iter: 5159  total_loss: 3.07  loss_sem_seg: 1.729  loss_center: 0.6158  loss_offset: 0.7894  time: 0.3765  data_time: 0.0263  lr: 0.00075145  max_mem: 8976M
[12/09 11:32:23 d2.utils.events]:  eta: 0:11:23  iter: 5179  total_loss: 2.879  loss_sem_seg: 1.542  loss_center: 0.4766  loss_offset: 0.7587  time: 0.3765  data_time: 0.0263  lr: 0.0007441  max_mem: 8976M
[12/09 11:32:31 d2.utils.events]:  eta: 0:11:16  iter: 5199  total_loss: 3.35  loss_sem_seg: 1.785  loss_center: 0.5718  loss_offset: 0.9367  time: 0.3765  data_time: 0.0265  lr: 0.00073674  max_mem: 8976M
[12/09 11:32:39 d2.utils.events]:  eta: 0:11:08  iter: 5219  total_loss: 3.13  loss_sem_seg: 1.442  loss_center: 0.7025  loss_offset: 0.8279  time: 0.3765  data_time: 0.0267  lr: 0.00072937  max_mem: 8976M
[12/09 11:32:46 d2.utils.events]:  eta: 0:11:01  iter: 5239  total_loss: 2.846  loss_sem_seg: 1.449  loss_center: 0.6994  loss_offset: 0.8051  time: 0.3765  data_time: 0.0247  lr: 0.000722  max_mem: 8976M
[12/09 11:32:54 d2.utils.events]:  eta: 0:10:53  iter: 5259  total_loss: 3.147  loss_sem_seg: 1.508  loss_center: 0.6924  loss_offset: 0.825  time: 0.3765  data_time: 0.0266  lr: 0.00071461  max_mem: 8976M
[12/09 11:33:01 d2.utils.events]:  eta: 0:10:46  iter: 5279  total_loss: 3.397  loss_sem_seg: 1.934  loss_center: 0.5235  loss_offset: 0.8975  time: 0.3765  data_time: 0.0257  lr: 0.00070722  max_mem: 8976M
[12/09 11:33:09 d2.utils.events]:  eta: 0:10:38  iter: 5299  total_loss: 2.855  loss_sem_seg: 1.511  loss_center: 0.4649  loss_offset: 0.8206  time: 0.3765  data_time: 0.0272  lr: 0.00069982  max_mem: 8976M
[12/09 11:33:16 d2.utils.events]:  eta: 0:10:31  iter: 5319  total_loss: 2.964  loss_sem_seg: 1.469  loss_center: 0.6839  loss_offset: 0.75  time: 0.3765  data_time: 0.0258  lr: 0.00069241  max_mem: 8976M
[12/09 11:33:24 d2.utils.events]:  eta: 0:10:23  iter: 5339  total_loss: 2.924  loss_sem_seg: 1.489  loss_center: 0.5216  loss_offset: 0.7825  time: 0.3765  data_time: 0.0258  lr: 0.00068499  max_mem: 8976M
[12/09 11:33:31 d2.utils.events]:  eta: 0:10:16  iter: 5359  total_loss: 3.117  loss_sem_seg: 1.701  loss_center: 0.56  loss_offset: 0.8407  time: 0.3765  data_time: 0.0266  lr: 0.00067756  max_mem: 8976M
[12/09 11:33:39 d2.utils.events]:  eta: 0:10:08  iter: 5379  total_loss: 3.193  loss_sem_seg: 1.596  loss_center: 0.657  loss_offset: 0.7889  time: 0.3765  data_time: 0.0244  lr: 0.00067013  max_mem: 8976M
[12/09 11:33:46 d2.utils.events]:  eta: 0:10:00  iter: 5399  total_loss: 3.108  loss_sem_seg: 1.602  loss_center: 0.8313  loss_offset: 0.7907  time: 0.3764  data_time: 0.0251  lr: 0.00066268  max_mem: 8976M
[12/09 11:33:54 d2.utils.events]:  eta: 0:09:53  iter: 5419  total_loss: 3.085  loss_sem_seg: 1.676  loss_center: 0.5057  loss_offset: 0.7525  time: 0.3765  data_time: 0.0280  lr: 0.00065522  max_mem: 8976M
[12/09 11:34:01 d2.utils.events]:  eta: 0:09:45  iter: 5439  total_loss: 3.188  loss_sem_seg: 1.542  loss_center: 0.5871  loss_offset: 0.8011  time: 0.3764  data_time: 0.0264  lr: 0.00064776  max_mem: 8976M
[12/09 11:34:09 d2.utils.events]:  eta: 0:09:38  iter: 5459  total_loss: 2.915  loss_sem_seg: 1.467  loss_center: 0.7297  loss_offset: 0.7394  time: 0.3765  data_time: 0.0266  lr: 0.00064029  max_mem: 8976M
[12/09 11:34:16 d2.utils.events]:  eta: 0:09:30  iter: 5479  total_loss: 3.329  loss_sem_seg: 1.699  loss_center: 0.6765  loss_offset: 0.7164  time: 0.3765  data_time: 0.0263  lr: 0.0006328  max_mem: 8976M
[12/09 11:34:24 d2.utils.events]:  eta: 0:09:23  iter: 5499  total_loss: 3.305  loss_sem_seg: 1.572  loss_center: 0.7253  loss_offset: 0.7171  time: 0.3765  data_time: 0.0271  lr: 0.00062531  max_mem: 8976M
[12/09 11:34:32 d2.utils.events]:  eta: 0:09:16  iter: 5519  total_loss: 2.689  loss_sem_seg: 1.332  loss_center: 0.5634  loss_offset: 0.6851  time: 0.3765  data_time: 0.0261  lr: 0.0006178  max_mem: 8976M
[12/09 11:34:39 d2.utils.events]:  eta: 0:09:08  iter: 5539  total_loss: 3.009  loss_sem_seg: 1.561  loss_center: 0.5815  loss_offset: 0.8197  time: 0.3765  data_time: 0.0252  lr: 0.00061029  max_mem: 8976M
[12/09 11:34:47 d2.utils.events]:  eta: 0:09:01  iter: 5559  total_loss: 2.728  loss_sem_seg: 1.53  loss_center: 0.652  loss_offset: 0.6527  time: 0.3765  data_time: 0.0259  lr: 0.00060277  max_mem: 8976M
[12/09 11:34:54 d2.utils.events]:  eta: 0:08:53  iter: 5579  total_loss: 2.884  loss_sem_seg: 1.711  loss_center: 0.4401  loss_offset: 0.7877  time: 0.3765  data_time: 0.0274  lr: 0.00059523  max_mem: 8976M
[12/09 11:35:02 d2.utils.events]:  eta: 0:08:46  iter: 5599  total_loss: 2.958  loss_sem_seg: 1.534  loss_center: 0.6114  loss_offset: 0.7259  time: 0.3765  data_time: 0.0265  lr: 0.00058769  max_mem: 8976M
[12/09 11:35:09 d2.utils.events]:  eta: 0:08:38  iter: 5619  total_loss: 2.923  loss_sem_seg: 1.465  loss_center: 0.6092  loss_offset: 0.6988  time: 0.3765  data_time: 0.0244  lr: 0.00058013  max_mem: 8976M
[12/09 11:35:17 d2.utils.events]:  eta: 0:08:31  iter: 5639  total_loss: 2.855  loss_sem_seg: 1.501  loss_center: 0.6106  loss_offset: 0.6824  time: 0.3764  data_time: 0.0259  lr: 0.00057256  max_mem: 8976M
[12/09 11:35:24 d2.utils.events]:  eta: 0:08:23  iter: 5659  total_loss: 3.397  loss_sem_seg: 1.963  loss_center: 0.5252  loss_offset: 0.7731  time: 0.3764  data_time: 0.0270  lr: 0.00056499  max_mem: 8976M
[12/09 11:35:32 d2.utils.events]:  eta: 0:08:16  iter: 5679  total_loss: 3.133  loss_sem_seg: 1.636  loss_center: 0.6818  loss_offset: 0.7197  time: 0.3764  data_time: 0.0262  lr: 0.0005574  max_mem: 8976M
[12/09 11:35:39 d2.utils.events]:  eta: 0:08:08  iter: 5699  total_loss: 3.153  loss_sem_seg: 1.452  loss_center: 0.6799  loss_offset: 0.7224  time: 0.3764  data_time: 0.0265  lr: 0.0005498  max_mem: 8976M
[12/09 11:35:47 d2.utils.events]:  eta: 0:08:00  iter: 5719  total_loss: 2.969  loss_sem_seg: 1.646  loss_center: 0.6695  loss_offset: 0.7504  time: 0.3764  data_time: 0.0265  lr: 0.00054218  max_mem: 8976M
[12/09 11:35:54 d2.utils.events]:  eta: 0:07:53  iter: 5739  total_loss: 3.031  loss_sem_seg: 1.495  loss_center: 0.57  loss_offset: 0.7521  time: 0.3764  data_time: 0.0267  lr: 0.00053456  max_mem: 8976M
[12/09 11:36:02 d2.utils.events]:  eta: 0:07:45  iter: 5759  total_loss: 3.149  loss_sem_seg: 1.74  loss_center: 0.6414  loss_offset: 0.7316  time: 0.3764  data_time: 0.0263  lr: 0.00052692  max_mem: 8976M
[12/09 11:36:09 d2.utils.events]:  eta: 0:07:38  iter: 5779  total_loss: 3.12  loss_sem_seg: 1.459  loss_center: 0.8321  loss_offset: 0.7366  time: 0.3764  data_time: 0.0271  lr: 0.00051927  max_mem: 8976M
[12/09 11:36:17 d2.utils.events]:  eta: 0:07:30  iter: 5799  total_loss: 3.04  loss_sem_seg: 1.557  loss_center: 0.5069  loss_offset: 0.8246  time: 0.3764  data_time: 0.0246  lr: 0.00051161  max_mem: 8976M
[12/09 11:36:25 d2.utils.events]:  eta: 0:07:23  iter: 5819  total_loss: 2.887  loss_sem_seg: 1.535  loss_center: 0.5648  loss_offset: 0.7217  time: 0.3764  data_time: 0.0269  lr: 0.00050394  max_mem: 8976M
[12/09 11:36:32 d2.utils.events]:  eta: 0:07:15  iter: 5839  total_loss: 2.98  loss_sem_seg: 1.457  loss_center: 0.5836  loss_offset: 0.7895  time: 0.3764  data_time: 0.0247  lr: 0.00049625  max_mem: 8976M
[12/09 11:36:40 d2.utils.events]:  eta: 0:07:08  iter: 5859  total_loss: 2.781  loss_sem_seg: 1.482  loss_center: 0.4945  loss_offset: 0.6945  time: 0.3764  data_time: 0.0262  lr: 0.00048855  max_mem: 8976M
[12/09 11:36:47 d2.utils.events]:  eta: 0:07:00  iter: 5879  total_loss: 2.97  loss_sem_seg: 1.602  loss_center: 0.5137  loss_offset: 0.7536  time: 0.3764  data_time: 0.0257  lr: 0.00048084  max_mem: 8976M
[12/09 11:36:55 d2.utils.events]:  eta: 0:06:53  iter: 5899  total_loss: 3  loss_sem_seg: 1.702  loss_center: 0.4997  loss_offset: 0.6928  time: 0.3764  data_time: 0.0260  lr: 0.00047311  max_mem: 8976M
[12/09 11:37:02 d2.utils.events]:  eta: 0:06:46  iter: 5919  total_loss: 3.012  loss_sem_seg: 1.674  loss_center: 0.6214  loss_offset: 0.7632  time: 0.3764  data_time: 0.0273  lr: 0.00046537  max_mem: 8976M
[12/09 11:37:10 d2.utils.events]:  eta: 0:06:38  iter: 5939  total_loss: 3.363  loss_sem_seg: 1.669  loss_center: 0.7211  loss_offset: 0.8978  time: 0.3764  data_time: 0.0268  lr: 0.00045761  max_mem: 8976M
[12/09 11:37:17 d2.utils.events]:  eta: 0:06:31  iter: 5959  total_loss: 3.035  loss_sem_seg: 1.38  loss_center: 0.6117  loss_offset: 0.8127  time: 0.3764  data_time: 0.0267  lr: 0.00044984  max_mem: 8976M
[12/09 11:37:25 d2.utils.events]:  eta: 0:06:23  iter: 5979  total_loss: 3.001  loss_sem_seg: 1.534  loss_center: 0.6427  loss_offset: 0.6729  time: 0.3764  data_time: 0.0261  lr: 0.00044205  max_mem: 8976M
[12/09 11:37:32 d2.utils.events]:  eta: 0:06:15  iter: 5999  total_loss: 2.934  loss_sem_seg: 1.549  loss_center: 0.6098  loss_offset: 0.777  time: 0.3764  data_time: 0.0271  lr: 0.00043425  max_mem: 8976M
[12/09 11:37:40 d2.utils.events]:  eta: 0:06:08  iter: 6019  total_loss: 3.15  loss_sem_seg: 1.498  loss_center: 0.5466  loss_offset: 0.7593  time: 0.3764  data_time: 0.0249  lr: 0.00042644  max_mem: 8976M
[12/09 11:37:47 d2.utils.events]:  eta: 0:06:00  iter: 6039  total_loss: 3.286  loss_sem_seg: 1.717  loss_center: 0.5902  loss_offset: 0.9032  time: 0.3764  data_time: 0.0268  lr: 0.0004186  max_mem: 8976M
[12/09 11:37:55 d2.utils.events]:  eta: 0:05:53  iter: 6059  total_loss: 3.022  loss_sem_seg: 1.527  loss_center: 0.678  loss_offset: 0.7816  time: 0.3764  data_time: 0.0262  lr: 0.00041075  max_mem: 8976M
[12/09 11:38:02 d2.utils.events]:  eta: 0:05:45  iter: 6079  total_loss: 2.742  loss_sem_seg: 1.397  loss_center: 0.6031  loss_offset: 0.7184  time: 0.3764  data_time: 0.0266  lr: 0.00040289  max_mem: 8976M
[12/09 11:38:10 d2.utils.events]:  eta: 0:05:38  iter: 6099  total_loss: 3.042  loss_sem_seg: 1.671  loss_center: 0.6215  loss_offset: 0.7358  time: 0.3764  data_time: 0.0261  lr: 0.00039501  max_mem: 8976M
[12/09 11:38:17 d2.utils.events]:  eta: 0:05:30  iter: 6119  total_loss: 2.761  loss_sem_seg: 1.546  loss_center: 0.5409  loss_offset: 0.7131  time: 0.3764  data_time: 0.0259  lr: 0.00038711  max_mem: 8976M
[12/09 11:38:25 d2.utils.events]:  eta: 0:05:23  iter: 6139  total_loss: 3.188  loss_sem_seg: 1.648  loss_center: 0.7448  loss_offset: 0.7667  time: 0.3764  data_time: 0.0241  lr: 0.00037919  max_mem: 8976M
[12/09 11:38:33 d2.utils.events]:  eta: 0:05:15  iter: 6159  total_loss: 2.896  loss_sem_seg: 1.527  loss_center: 0.492  loss_offset: 0.8317  time: 0.3764  data_time: 0.0283  lr: 0.00037125  max_mem: 8976M
[12/09 11:38:40 d2.utils.events]:  eta: 0:05:08  iter: 6179  total_loss: 2.95  loss_sem_seg: 1.47  loss_center: 0.5459  loss_offset: 0.6821  time: 0.3764  data_time: 0.0254  lr: 0.0003633  max_mem: 8976M
[12/09 11:38:48 d2.utils.events]:  eta: 0:05:00  iter: 6199  total_loss: 2.825  loss_sem_seg: 1.598  loss_center: 0.482  loss_offset: 0.7077  time: 0.3764  data_time: 0.0264  lr: 0.00035532  max_mem: 8976M
[12/09 11:38:55 d2.utils.events]:  eta: 0:04:52  iter: 6219  total_loss: 3.043  loss_sem_seg: 1.608  loss_center: 0.658  loss_offset: 0.7768  time: 0.3764  data_time: 0.0253  lr: 0.00034733  max_mem: 8976M
[12/09 11:39:03 d2.utils.events]:  eta: 0:04:45  iter: 6239  total_loss: 2.862  loss_sem_seg: 1.305  loss_center: 0.6317  loss_offset: 0.783  time: 0.3764  data_time: 0.0269  lr: 0.00033931  max_mem: 8976M
[12/09 11:39:10 d2.utils.events]:  eta: 0:04:37  iter: 6259  total_loss: 2.855  loss_sem_seg: 1.372  loss_center: 0.6991  loss_offset: 0.8101  time: 0.3764  data_time: 0.0250  lr: 0.00033127  max_mem: 8976M
[12/09 11:39:18 d2.utils.events]:  eta: 0:04:30  iter: 6279  total_loss: 2.806  loss_sem_seg: 1.404  loss_center: 0.6152  loss_offset: 0.7283  time: 0.3764  data_time: 0.0279  lr: 0.00032322  max_mem: 8976M
[12/09 11:39:25 d2.utils.events]:  eta: 0:04:22  iter: 6299  total_loss: 2.73  loss_sem_seg: 1.543  loss_center: 0.5896  loss_offset: 0.7834  time: 0.3764  data_time: 0.0238  lr: 0.00031514  max_mem: 8976M
[12/09 11:39:33 d2.utils.events]:  eta: 0:04:15  iter: 6319  total_loss: 3.024  loss_sem_seg: 1.667  loss_center: 0.5208  loss_offset: 0.6361  time: 0.3764  data_time: 0.0264  lr: 0.00030703  max_mem: 8976M
[12/09 11:39:40 d2.utils.events]:  eta: 0:04:07  iter: 6339  total_loss: 2.796  loss_sem_seg: 1.431  loss_center: 0.5536  loss_offset: 0.6263  time: 0.3764  data_time: 0.0247  lr: 0.0002989  max_mem: 8976M
[12/09 11:39:48 d2.utils.events]:  eta: 0:04:00  iter: 6359  total_loss: 3.232  loss_sem_seg: 1.722  loss_center: 0.5387  loss_offset: 0.77  time: 0.3764  data_time: 0.0260  lr: 0.00029075  max_mem: 8976M
[12/09 11:39:55 d2.utils.events]:  eta: 0:03:52  iter: 6379  total_loss: 2.837  loss_sem_seg: 1.464  loss_center: 0.662  loss_offset: 0.7134  time: 0.3764  data_time: 0.0268  lr: 0.00028258  max_mem: 8976M
[12/09 11:40:03 d2.utils.events]:  eta: 0:03:45  iter: 6399  total_loss: 3.038  loss_sem_seg: 1.522  loss_center: 0.6654  loss_offset: 0.7193  time: 0.3764  data_time: 0.0256  lr: 0.00027437  max_mem: 8976M
[12/09 11:40:10 d2.utils.events]:  eta: 0:03:37  iter: 6419  total_loss: 2.779  loss_sem_seg: 1.442  loss_center: 0.5218  loss_offset: 0.7055  time: 0.3764  data_time: 0.0265  lr: 0.00026614  max_mem: 8976M
[12/09 11:40:18 d2.utils.events]:  eta: 0:03:30  iter: 6439  total_loss: 3.157  loss_sem_seg: 1.631  loss_center: 0.5525  loss_offset: 0.8075  time: 0.3764  data_time: 0.0258  lr: 0.00025788  max_mem: 8976M
[12/09 11:40:25 d2.utils.events]:  eta: 0:03:22  iter: 6459  total_loss: 3.124  loss_sem_seg: 1.54  loss_center: 0.5077  loss_offset: 0.7932  time: 0.3764  data_time: 0.0248  lr: 0.00024959  max_mem: 8976M
[12/09 11:40:33 d2.utils.events]:  eta: 0:03:15  iter: 6479  total_loss: 2.821  loss_sem_seg: 1.49  loss_center: 0.5744  loss_offset: 0.657  time: 0.3764  data_time: 0.0262  lr: 0.00024127  max_mem: 8976M
[12/09 11:40:40 d2.utils.events]:  eta: 0:03:07  iter: 6499  total_loss: 3.09  loss_sem_seg: 1.715  loss_center: 0.5017  loss_offset: 0.8215  time: 0.3764  data_time: 0.0266  lr: 0.00023292  max_mem: 8976M
[12/09 11:40:48 d2.utils.events]:  eta: 0:03:00  iter: 6519  total_loss: 2.994  loss_sem_seg: 1.667  loss_center: 0.4458  loss_offset: 0.7361  time: 0.3764  data_time: 0.0270  lr: 0.00022453  max_mem: 8976M
[12/09 11:40:55 d2.utils.events]:  eta: 0:02:52  iter: 6539  total_loss: 2.975  loss_sem_seg: 1.539  loss_center: 0.5483  loss_offset: 0.6847  time: 0.3764  data_time: 0.0255  lr: 0.00021611  max_mem: 8976M
[12/09 11:41:03 d2.utils.events]:  eta: 0:02:45  iter: 6559  total_loss: 2.867  loss_sem_seg: 1.429  loss_center: 0.608  loss_offset: 0.7798  time: 0.3764  data_time: 0.0250  lr: 0.00020766  max_mem: 8976M
[12/09 11:41:11 d2.utils.events]:  eta: 0:02:37  iter: 6579  total_loss: 2.855  loss_sem_seg: 1.443  loss_center: 0.5571  loss_offset: 0.7424  time: 0.3764  data_time: 0.0266  lr: 0.00019916  max_mem: 8976M
[12/09 11:41:18 d2.utils.events]:  eta: 0:02:30  iter: 6599  total_loss: 2.886  loss_sem_seg: 1.461  loss_center: 0.6782  loss_offset: 0.6571  time: 0.3764  data_time: 0.0266  lr: 0.00019063  max_mem: 8976M
[12/09 11:41:26 d2.utils.events]:  eta: 0:02:22  iter: 6619  total_loss: 2.783  loss_sem_seg: 1.393  loss_center: 0.6577  loss_offset: 0.7069  time: 0.3764  data_time: 0.0246  lr: 0.00018205  max_mem: 8976M
[12/09 11:41:33 d2.utils.events]:  eta: 0:02:15  iter: 6639  total_loss: 2.874  loss_sem_seg: 1.421  loss_center: 0.6334  loss_offset: 0.7806  time: 0.3764  data_time: 0.0250  lr: 0.00017342  max_mem: 8976M
[12/09 11:41:41 d2.utils.events]:  eta: 0:02:07  iter: 6659  total_loss: 3.298  loss_sem_seg: 1.628  loss_center: 0.6188  loss_offset: 0.7254  time: 0.3764  data_time: 0.0258  lr: 0.00016475  max_mem: 8976M
[12/09 11:41:48 d2.utils.events]:  eta: 0:02:00  iter: 6679  total_loss: 2.933  loss_sem_seg: 1.556  loss_center: 0.5418  loss_offset: 0.8164  time: 0.3764  data_time: 0.0259  lr: 0.00015603  max_mem: 8976M
[12/09 11:41:56 d2.utils.events]:  eta: 0:01:52  iter: 6699  total_loss: 2.709  loss_sem_seg: 1.4  loss_center: 0.4512  loss_offset: 0.704  time: 0.3764  data_time: 0.0262  lr: 0.00014725  max_mem: 8976M
[12/09 11:42:03 d2.utils.events]:  eta: 0:01:45  iter: 6719  total_loss: 3.091  loss_sem_seg: 1.457  loss_center: 0.6044  loss_offset: 0.7616  time: 0.3764  data_time: 0.0264  lr: 0.00013842  max_mem: 8976M
[12/09 11:42:11 d2.utils.events]:  eta: 0:01:37  iter: 6739  total_loss: 2.77  loss_sem_seg: 1.558  loss_center: 0.5522  loss_offset: 0.6861  time: 0.3764  data_time: 0.0257  lr: 0.00012952  max_mem: 8976M
[12/09 11:42:18 d2.utils.events]:  eta: 0:01:30  iter: 6759  total_loss: 3.126  loss_sem_seg: 1.49  loss_center: 0.6367  loss_offset: 0.7238  time: 0.3764  data_time: 0.0267  lr: 0.00012055  max_mem: 8976M
[12/09 11:42:26 d2.utils.events]:  eta: 0:01:22  iter: 6779  total_loss: 3.083  loss_sem_seg: 1.598  loss_center: 0.5646  loss_offset: 0.8829  time: 0.3764  data_time: 0.0271  lr: 0.00011151  max_mem: 8976M
[12/09 11:42:33 d2.utils.events]:  eta: 0:01:15  iter: 6799  total_loss: 2.89  loss_sem_seg: 1.352  loss_center: 0.6584  loss_offset: 0.8272  time: 0.3763  data_time: 0.0259  lr: 0.00010238  max_mem: 8976M
[12/09 11:42:41 d2.utils.events]:  eta: 0:01:07  iter: 6819  total_loss: 3.121  loss_sem_seg: 1.576  loss_center: 0.7071  loss_offset: 0.7583  time: 0.3764  data_time: 0.0264  lr: 9.3167e-05  max_mem: 8976M
[12/09 11:42:48 d2.utils.events]:  eta: 0:01:00  iter: 6839  total_loss: 3.105  loss_sem_seg: 1.615  loss_center: 0.4637  loss_offset: 0.8493  time: 0.3763  data_time: 0.0255  lr: 8.3848e-05  max_mem: 8976M
[12/09 11:42:56 d2.utils.events]:  eta: 0:00:52  iter: 6859  total_loss: 2.735  loss_sem_seg: 1.353  loss_center: 0.5716  loss_offset: 0.7876  time: 0.3763  data_time: 0.0271  lr: 7.4413e-05  max_mem: 8976M
[12/09 11:43:03 d2.utils.events]:  eta: 0:00:45  iter: 6879  total_loss: 2.772  loss_sem_seg: 1.467  loss_center: 0.6618  loss_offset: 0.6954  time: 0.3763  data_time: 0.0250  lr: 6.4842e-05  max_mem: 8976M
[12/09 11:43:11 d2.utils.events]:  eta: 0:00:37  iter: 6899  total_loss: 2.738  loss_sem_seg: 1.36  loss_center: 0.5645  loss_offset: 0.6985  time: 0.3763  data_time: 0.0255  lr: 5.5111e-05  max_mem: 8976M
[12/09 11:43:19 d2.utils.events]:  eta: 0:00:29  iter: 6919  total_loss: 2.844  loss_sem_seg: 1.345  loss_center: 0.5449  loss_offset: 0.8671  time: 0.3764  data_time: 0.0279  lr: 4.5184e-05  max_mem: 8976M
[12/09 11:43:26 d2.utils.events]:  eta: 0:00:22  iter: 6939  total_loss: 2.542  loss_sem_seg: 1.286  loss_center: 0.6485  loss_offset: 0.6661  time: 0.3764  data_time: 0.0252  lr: 3.5006e-05  max_mem: 8976M
[12/09 11:43:34 d2.utils.events]:  eta: 0:00:14  iter: 6959  total_loss: 2.83  loss_sem_seg: 1.342  loss_center: 0.581  loss_offset: 0.7048  time: 0.3763  data_time: 0.0269  lr: 2.4483e-05  max_mem: 8976M
[12/09 11:43:41 d2.utils.events]:  eta: 0:00:07  iter: 6979  total_loss: 2.61  loss_sem_seg: 1.333  loss_center: 0.5318  loss_offset: 0.7245  time: 0.3763  data_time: 0.0256  lr: 1.3408e-05  max_mem: 8976M
[12/09 11:43:49 fvcore.common.checkpoint]: Saving checkpoint to ./output/model_final.pth
[12/09 11:43:49 d2.utils.events]:  eta: 0:00:00  iter: 6999  total_loss: 2.961  loss_sem_seg: 1.468  loss_center: 0.6924  loss_offset: 0.8061  time: 0.3763  data_time: 0.0260  lr: 8.6567e-07  max_mem: 8976M
[12/09 11:43:50 d2.engine.hooks]: Overall training speed: 6998 iterations in 0:43:53 (0.3764 s / it)
[12/09 11:43:50 d2.engine.hooks]: Total training time: 0:44:00 (0:00:06 on hooks)
[12/09 11:43:50 d2.data.dataset_mapper]: [DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(640, 640), max_size=640, sample_style='choice')]
[12/09 11:43:50 d2.data.common]: Serializing the dataset using: <class 'detectron2.data.common.NumpySerializedList'>
[12/09 11:43:50 d2.data.common]: Serializing 5000 elements to byte tensors and concatenating them all ...
[12/09 11:43:50 d2.data.common]: Serialized dataset takes 3.40 MiB
/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:481: UserWarning: This DataLoader will create 10 worker processes in total. Our suggested max number of worker in current system is 8, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.
  cpuset_checked))
[12/09 11:43:51 d2.evaluation.evaluator]: Start inference on 5000 batches
/usr/local/lib/python3.7/dist-packages/torch/functional.py:445: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at  ../aten/src/ATen/native/TensorShape.cpp:2157.)
  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]
[12/09 11:43:53 d2.evaluation.evaluator]: Inference done 11/5000. Dataloading: 0.0008 s/iter. Inference: 0.1006 s/iter. Eval: 0.0366 s/iter. Total: 0.1380 s/iter. ETA=0:11:28
[12/09 11:43:58 d2.evaluation.evaluator]: Inference done 72/5000. Dataloading: 0.0011 s/iter. Inference: 0.0550 s/iter. Eval: 0.0320 s/iter. Total: 0.0881 s/iter. ETA=0:07:14
[12/09 11:44:03 d2.evaluation.evaluator]: Inference done 127/5000. Dataloading: 0.0012 s/iter. Inference: 0.0546 s/iter. Eval: 0.0341 s/iter. Total: 0.0900 s/iter. ETA=0:07:18
[12/09 11:44:08 d2.evaluation.evaluator]: Inference done 183/5000. Dataloading: 0.0012 s/iter. Inference: 0.0543 s/iter. Eval: 0.0347 s/iter. Total: 0.0902 s/iter. ETA=0:07:14
[12/09 11:44:13 d2.evaluation.evaluator]: Inference done 244/5000. Dataloading: 0.0012 s/iter. Inference: 0.0530 s/iter. Eval: 0.0340 s/iter. Total: 0.0882 s/iter. ETA=0:06:59
[12/09 11:44:19 d2.evaluation.evaluator]: Inference done 302/5000. Dataloading: 0.0012 s/iter. Inference: 0.0526 s/iter. Eval: 0.0342 s/iter. Total: 0.0880 s/iter. ETA=0:06:53
[12/09 11:44:24 d2.evaluation.evaluator]: Inference done 358/5000. Dataloading: 0.0012 s/iter. Inference: 0.0527 s/iter. Eval: 0.0343 s/iter. Total: 0.0883 s/iter. ETA=0:06:49
[12/09 11:44:29 d2.evaluation.evaluator]: Inference done 418/5000. Dataloading: 0.0012 s/iter. Inference: 0.0523 s/iter. Eval: 0.0342 s/iter. Total: 0.0878 s/iter. ETA=0:06:42
[12/09 11:44:34 d2.evaluation.evaluator]: Inference done 480/5000. Dataloading: 0.0012 s/iter. Inference: 0.0519 s/iter. Eval: 0.0338 s/iter. Total: 0.0870 s/iter. ETA=0:06:33
[12/09 11:44:39 d2.evaluation.evaluator]: Inference done 537/5000. Dataloading: 0.0012 s/iter. Inference: 0.0520 s/iter. Eval: 0.0339 s/iter. Total: 0.0872 s/iter. ETA=0:06:29
[12/09 11:44:44 d2.evaluation.evaluator]: Inference done 593/5000. Dataloading: 0.0012 s/iter. Inference: 0.0521 s/iter. Eval: 0.0341 s/iter. Total: 0.0875 s/iter. ETA=0:06:25
[12/09 11:44:49 d2.evaluation.evaluator]: Inference done 650/5000. Dataloading: 0.0012 s/iter. Inference: 0.0521 s/iter. Eval: 0.0342 s/iter. Total: 0.0876 s/iter. ETA=0:06:20
[12/09 11:44:54 d2.evaluation.evaluator]: Inference done 708/5000. Dataloading: 0.0012 s/iter. Inference: 0.0520 s/iter. Eval: 0.0343 s/iter. Total: 0.0876 s/iter. ETA=0:06:15
[12/09 11:44:59 d2.evaluation.evaluator]: Inference done 766/5000. Dataloading: 0.0012 s/iter. Inference: 0.0520 s/iter. Eval: 0.0343 s/iter. Total: 0.0876 s/iter. ETA=0:06:10
[12/09 11:45:04 d2.evaluation.evaluator]: Inference done 826/5000. Dataloading: 0.0012 s/iter. Inference: 0.0518 s/iter. Eval: 0.0342 s/iter. Total: 0.0873 s/iter. ETA=0:06:04
[12/09 11:45:09 d2.evaluation.evaluator]: Inference done 885/5000. Dataloading: 0.0012 s/iter. Inference: 0.0518 s/iter. Eval: 0.0341 s/iter. Total: 0.0872 s/iter. ETA=0:05:58
[12/09 11:45:14 d2.evaluation.evaluator]: Inference done 946/5000. Dataloading: 0.0012 s/iter. Inference: 0.0516 s/iter. Eval: 0.0340 s/iter. Total: 0.0870 s/iter. ETA=0:05:52
[12/09 11:45:19 d2.evaluation.evaluator]: Inference done 1005/5000. Dataloading: 0.0012 s/iter. Inference: 0.0516 s/iter. Eval: 0.0340 s/iter. Total: 0.0869 s/iter. ETA=0:05:47
[12/09 11:45:24 d2.evaluation.evaluator]: Inference done 1063/5000. Dataloading: 0.0012 s/iter. Inference: 0.0516 s/iter. Eval: 0.0340 s/iter. Total: 0.0869 s/iter. ETA=0:05:42
[12/09 11:45:29 d2.evaluation.evaluator]: Inference done 1122/5000. Dataloading: 0.0012 s/iter. Inference: 0.0516 s/iter. Eval: 0.0339 s/iter. Total: 0.0868 s/iter. ETA=0:05:36
[12/09 11:45:34 d2.evaluation.evaluator]: Inference done 1180/5000. Dataloading: 0.0012 s/iter. Inference: 0.0516 s/iter. Eval: 0.0339 s/iter. Total: 0.0868 s/iter. ETA=0:05:31
[12/09 11:45:39 d2.evaluation.evaluator]: Inference done 1234/5000. Dataloading: 0.0012 s/iter. Inference: 0.0518 s/iter. Eval: 0.0340 s/iter. Total: 0.0871 s/iter. ETA=0:05:27
[12/09 11:45:44 d2.evaluation.evaluator]: Inference done 1291/5000. Dataloading: 0.0012 s/iter. Inference: 0.0519 s/iter. Eval: 0.0340 s/iter. Total: 0.0871 s/iter. ETA=0:05:23
[12/09 11:45:50 d2.evaluation.evaluator]: Inference done 1349/5000. Dataloading: 0.0012 s/iter. Inference: 0.0519 s/iter. Eval: 0.0340 s/iter. Total: 0.0872 s/iter. ETA=0:05:18
[12/09 11:45:55 d2.evaluation.evaluator]: Inference done 1408/5000. Dataloading: 0.0012 s/iter. Inference: 0.0518 s/iter. Eval: 0.0340 s/iter. Total: 0.0871 s/iter. ETA=0:05:12
[12/09 11:46:00 d2.evaluation.evaluator]: Inference done 1466/5000. Dataloading: 0.0012 s/iter. Inference: 0.0518 s/iter. Eval: 0.0340 s/iter. Total: 0.0871 s/iter. ETA=0:05:07
[12/09 11:46:05 d2.evaluation.evaluator]: Inference done 1522/5000. Dataloading: 0.0012 s/iter. Inference: 0.0518 s/iter. Eval: 0.0341 s/iter. Total: 0.0872 s/iter. ETA=0:05:03
[12/09 11:46:10 d2.evaluation.evaluator]: Inference done 1578/5000. Dataloading: 0.0012 s/iter. Inference: 0.0519 s/iter. Eval: 0.0341 s/iter. Total: 0.0873 s/iter. ETA=0:04:58
[12/09 11:46:15 d2.evaluation.evaluator]: Inference done 1635/5000. Dataloading: 0.0012 s/iter. Inference: 0.0519 s/iter. Eval: 0.0342 s/iter. Total: 0.0874 s/iter. ETA=0:04:53
[12/09 11:46:20 d2.evaluation.evaluator]: Inference done 1692/5000. Dataloading: 0.0012 s/iter. Inference: 0.0519 s/iter. Eval: 0.0342 s/iter. Total: 0.0874 s/iter. ETA=0:04:49
[12/09 11:46:25 d2.evaluation.evaluator]: Inference done 1750/5000. Dataloading: 0.0012 s/iter. Inference: 0.0519 s/iter. Eval: 0.0342 s/iter. Total: 0.0874 s/iter. ETA=0:04:43
[12/09 11:46:30 d2.evaluation.evaluator]: Inference done 1810/5000. Dataloading: 0.0012 s/iter. Inference: 0.0518 s/iter. Eval: 0.0342 s/iter. Total: 0.0873 s/iter. ETA=0:04:38
[12/09 11:46:35 d2.evaluation.evaluator]: Inference done 1867/5000. Dataloading: 0.0012 s/iter. Inference: 0.0519 s/iter. Eval: 0.0342 s/iter. Total: 0.0873 s/iter. ETA=0:04:33
[12/09 11:46:40 d2.evaluation.evaluator]: Inference done 1926/5000. Dataloading: 0.0012 s/iter. Inference: 0.0518 s/iter. Eval: 0.0342 s/iter. Total: 0.0873 s/iter. ETA=0:04:28
[12/09 11:46:45 d2.evaluation.evaluator]: Inference done 1985/5000. Dataloading: 0.0012 s/iter. Inference: 0.0518 s/iter. Eval: 0.0342 s/iter. Total: 0.0872 s/iter. ETA=0:04:23
[12/09 11:46:50 d2.evaluation.evaluator]: Inference done 2043/5000. Dataloading: 0.0012 s/iter. Inference: 0.0518 s/iter. Eval: 0.0342 s/iter. Total: 0.0873 s/iter. ETA=0:04:18
[12/09 11:46:55 d2.evaluation.evaluator]: Inference done 2102/5000. Dataloading: 0.0012 s/iter. Inference: 0.0518 s/iter. Eval: 0.0342 s/iter. Total: 0.0872 s/iter. ETA=0:04:12
[12/09 11:47:00 d2.evaluation.evaluator]: Inference done 2161/5000. Dataloading: 0.0012 s/iter. Inference: 0.0517 s/iter. Eval: 0.0341 s/iter. Total: 0.0872 s/iter. ETA=0:04:07
[12/09 11:47:05 d2.evaluation.evaluator]: Inference done 2220/5000. Dataloading: 0.0012 s/iter. Inference: 0.0517 s/iter. Eval: 0.0341 s/iter. Total: 0.0871 s/iter. ETA=0:04:02
[12/09 11:47:10 d2.evaluation.evaluator]: Inference done 2280/5000. Dataloading: 0.0012 s/iter. Inference: 0.0517 s/iter. Eval: 0.0341 s/iter. Total: 0.0870 s/iter. ETA=0:03:56
[12/09 11:47:15 d2.evaluation.evaluator]: Inference done 2341/5000. Dataloading: 0.0012 s/iter. Inference: 0.0516 s/iter. Eval: 0.0340 s/iter. Total: 0.0869 s/iter. ETA=0:03:51
[12/09 11:47:20 d2.evaluation.evaluator]: Inference done 2399/5000. Dataloading: 0.0012 s/iter. Inference: 0.0516 s/iter. Eval: 0.0340 s/iter. Total: 0.0869 s/iter. ETA=0:03:46
[12/09 11:47:26 d2.evaluation.evaluator]: Inference done 2456/5000. Dataloading: 0.0012 s/iter. Inference: 0.0516 s/iter. Eval: 0.0340 s/iter. Total: 0.0870 s/iter. ETA=0:03:41
[12/09 11:47:31 d2.evaluation.evaluator]: Inference done 2514/5000. Dataloading: 0.0012 s/iter. Inference: 0.0516 s/iter. Eval: 0.0340 s/iter. Total: 0.0870 s/iter. ETA=0:03:36
[12/09 11:47:36 d2.evaluation.evaluator]: Inference done 2573/5000. Dataloading: 0.0012 s/iter. Inference: 0.0516 s/iter. Eval: 0.0340 s/iter. Total: 0.0869 s/iter. ETA=0:03:31
[12/09 11:47:41 d2.evaluation.evaluator]: Inference done 2630/5000. Dataloading: 0.0012 s/iter. Inference: 0.0517 s/iter. Eval: 0.0340 s/iter. Total: 0.0870 s/iter. ETA=0:03:26
[12/09 11:47:46 d2.evaluation.evaluator]: Inference done 2690/5000. Dataloading: 0.0012 s/iter. Inference: 0.0516 s/iter. Eval: 0.0340 s/iter. Total: 0.0869 s/iter. ETA=0:03:20
[12/09 11:47:51 d2.evaluation.evaluator]: Inference done 2751/5000. Dataloading: 0.0012 s/iter. Inference: 0.0516 s/iter. Eval: 0.0340 s/iter. Total: 0.0868 s/iter. ETA=0:03:15
[12/09 11:47:56 d2.evaluation.evaluator]: Inference done 2810/5000. Dataloading: 0.0012 s/iter. Inference: 0.0515 s/iter. Eval: 0.0340 s/iter. Total: 0.0868 s/iter. ETA=0:03:10
[12/09 11:48:01 d2.evaluation.evaluator]: Inference done 2869/5000. Dataloading: 0.0012 s/iter. Inference: 0.0515 s/iter. Eval: 0.0340 s/iter. Total: 0.0868 s/iter. ETA=0:03:04
[12/09 11:48:06 d2.evaluation.evaluator]: Inference done 2927/5000. Dataloading: 0.0012 s/iter. Inference: 0.0515 s/iter. Eval: 0.0340 s/iter. Total: 0.0868 s/iter. ETA=0:02:59
[12/09 11:48:11 d2.evaluation.evaluator]: Inference done 2987/5000. Dataloading: 0.0012 s/iter. Inference: 0.0515 s/iter. Eval: 0.0339 s/iter. Total: 0.0867 s/iter. ETA=0:02:54
[12/09 11:48:16 d2.evaluation.evaluator]: Inference done 3048/5000. Dataloading: 0.0012 s/iter. Inference: 0.0514 s/iter. Eval: 0.0339 s/iter. Total: 0.0866 s/iter. ETA=0:02:49
[12/09 11:48:21 d2.evaluation.evaluator]: Inference done 3109/5000. Dataloading: 0.0012 s/iter. Inference: 0.0514 s/iter. Eval: 0.0339 s/iter. Total: 0.0866 s/iter. ETA=0:02:43
[12/09 11:48:26 d2.evaluation.evaluator]: Inference done 3165/5000. Dataloading: 0.0012 s/iter. Inference: 0.0514 s/iter. Eval: 0.0339 s/iter. Total: 0.0866 s/iter. ETA=0:02:38
[12/09 11:48:31 d2.evaluation.evaluator]: Inference done 3221/5000. Dataloading: 0.0012 s/iter. Inference: 0.0514 s/iter. Eval: 0.0340 s/iter. Total: 0.0867 s/iter. ETA=0:02:34
[12/09 11:48:36 d2.evaluation.evaluator]: Inference done 3279/5000. Dataloading: 0.0012 s/iter. Inference: 0.0514 s/iter. Eval: 0.0340 s/iter. Total: 0.0867 s/iter. ETA=0:02:29
[12/09 11:48:41 d2.evaluation.evaluator]: Inference done 3335/5000. Dataloading: 0.0012 s/iter. Inference: 0.0515 s/iter. Eval: 0.0340 s/iter. Total: 0.0868 s/iter. ETA=0:02:24
[12/09 11:48:46 d2.evaluation.evaluator]: Inference done 3392/5000. Dataloading: 0.0012 s/iter. Inference: 0.0515 s/iter. Eval: 0.0340 s/iter. Total: 0.0868 s/iter. ETA=0:02:19
[12/09 11:48:51 d2.evaluation.evaluator]: Inference done 3446/5000. Dataloading: 0.0012 s/iter. Inference: 0.0515 s/iter. Eval: 0.0341 s/iter. Total: 0.0869 s/iter. ETA=0:02:15
[12/09 11:48:56 d2.evaluation.evaluator]: Inference done 3506/5000. Dataloading: 0.0012 s/iter. Inference: 0.0515 s/iter. Eval: 0.0340 s/iter. Total: 0.0868 s/iter. ETA=0:02:09
[12/09 11:49:01 d2.evaluation.evaluator]: Inference done 3562/5000. Dataloading: 0.0012 s/iter. Inference: 0.0515 s/iter. Eval: 0.0340 s/iter. Total: 0.0869 s/iter. ETA=0:02:04
[12/09 11:49:06 d2.evaluation.evaluator]: Inference done 3620/5000. Dataloading: 0.0012 s/iter. Inference: 0.0515 s/iter. Eval: 0.0341 s/iter. Total: 0.0869 s/iter. ETA=0:01:59
[12/09 11:49:12 d2.evaluation.evaluator]: Inference done 3681/5000. Dataloading: 0.0012 s/iter. Inference: 0.0515 s/iter. Eval: 0.0340 s/iter. Total: 0.0868 s/iter. ETA=0:01:54
[12/09 11:49:17 d2.evaluation.evaluator]: Inference done 3740/5000. Dataloading: 0.0012 s/iter. Inference: 0.0515 s/iter. Eval: 0.0340 s/iter. Total: 0.0868 s/iter. ETA=0:01:49
[12/09 11:49:22 d2.evaluation.evaluator]: Inference done 3796/5000. Dataloading: 0.0012 s/iter. Inference: 0.0515 s/iter. Eval: 0.0340 s/iter. Total: 0.0869 s/iter. ETA=0:01:44
[12/09 11:49:27 d2.evaluation.evaluator]: Inference done 3855/5000. Dataloading: 0.0012 s/iter. Inference: 0.0515 s/iter. Eval: 0.0340 s/iter. Total: 0.0868 s/iter. ETA=0:01:39
[12/09 11:49:32 d2.evaluation.evaluator]: Inference done 3916/5000. Dataloading: 0.0012 s/iter. Inference: 0.0515 s/iter. Eval: 0.0340 s/iter. Total: 0.0868 s/iter. ETA=0:01:34
[12/09 11:49:37 d2.evaluation.evaluator]: Inference done 3974/5000. Dataloading: 0.0012 s/iter. Inference: 0.0515 s/iter. Eval: 0.0340 s/iter. Total: 0.0868 s/iter. ETA=0:01:29
[12/09 11:49:42 d2.evaluation.evaluator]: Inference done 4032/5000. Dataloading: 0.0012 s/iter. Inference: 0.0515 s/iter. Eval: 0.0340 s/iter. Total: 0.0868 s/iter. ETA=0:01:23
[12/09 11:49:47 d2.evaluation.evaluator]: Inference done 4088/5000. Dataloading: 0.0012 s/iter. Inference: 0.0515 s/iter. Eval: 0.0340 s/iter. Total: 0.0868 s/iter. ETA=0:01:19
[12/09 11:49:52 d2.evaluation.evaluator]: Inference done 4148/5000. Dataloading: 0.0012 s/iter. Inference: 0.0514 s/iter. Eval: 0.0340 s/iter. Total: 0.0868 s/iter. ETA=0:01:13
[12/09 11:49:57 d2.evaluation.evaluator]: Inference done 4203/5000. Dataloading: 0.0012 s/iter. Inference: 0.0515 s/iter. Eval: 0.0341 s/iter. Total: 0.0868 s/iter. ETA=0:01:09
[12/09 11:50:02 d2.evaluation.evaluator]: Inference done 4263/5000. Dataloading: 0.0012 s/iter. Inference: 0.0515 s/iter. Eval: 0.0341 s/iter. Total: 0.0868 s/iter. ETA=0:01:03
[12/09 11:50:07 d2.evaluation.evaluator]: Inference done 4320/5000. Dataloading: 0.0012 s/iter. Inference: 0.0515 s/iter. Eval: 0.0341 s/iter. Total: 0.0868 s/iter. ETA=0:00:59
[12/09 11:50:12 d2.evaluation.evaluator]: Inference done 4379/5000. Dataloading: 0.0012 s/iter. Inference: 0.0514 s/iter. Eval: 0.0341 s/iter. Total: 0.0868 s/iter. ETA=0:00:53
[12/09 11:50:17 d2.evaluation.evaluator]: Inference done 4435/5000. Dataloading: 0.0012 s/iter. Inference: 0.0514 s/iter. Eval: 0.0341 s/iter. Total: 0.0869 s/iter. ETA=0:00:49
[12/09 11:50:22 d2.evaluation.evaluator]: Inference done 4494/5000. Dataloading: 0.0012 s/iter. Inference: 0.0514 s/iter. Eval: 0.0341 s/iter. Total: 0.0869 s/iter. ETA=0:00:43
[12/09 11:50:27 d2.evaluation.evaluator]: Inference done 4553/5000. Dataloading: 0.0012 s/iter. Inference: 0.0514 s/iter. Eval: 0.0341 s/iter. Total: 0.0868 s/iter. ETA=0:00:38
[12/09 11:50:32 d2.evaluation.evaluator]: Inference done 4612/5000. Dataloading: 0.0012 s/iter. Inference: 0.0514 s/iter. Eval: 0.0341 s/iter. Total: 0.0868 s/iter. ETA=0:00:33
[12/09 11:50:37 d2.evaluation.evaluator]: Inference done 4667/5000. Dataloading: 0.0012 s/iter. Inference: 0.0514 s/iter. Eval: 0.0342 s/iter. Total: 0.0869 s/iter. ETA=0:00:28
[12/09 11:50:42 d2.evaluation.evaluator]: Inference done 4725/5000. Dataloading: 0.0012 s/iter. Inference: 0.0514 s/iter. Eval: 0.0342 s/iter. Total: 0.0869 s/iter. ETA=0:00:23
[12/09 11:50:48 d2.evaluation.evaluator]: Inference done 4784/5000. Dataloading: 0.0012 s/iter. Inference: 0.0514 s/iter. Eval: 0.0342 s/iter. Total: 0.0869 s/iter. ETA=0:00:18
[12/09 11:50:53 d2.evaluation.evaluator]: Inference done 4840/5000. Dataloading: 0.0012 s/iter. Inference: 0.0514 s/iter. Eval: 0.0342 s/iter. Total: 0.0869 s/iter. ETA=0:00:13
[12/09 11:50:58 d2.evaluation.evaluator]: Inference done 4898/5000. Dataloading: 0.0012 s/iter. Inference: 0.0514 s/iter. Eval: 0.0342 s/iter. Total: 0.0869 s/iter. ETA=0:00:08
[12/09 11:51:03 d2.evaluation.evaluator]: Inference done 4950/5000. Dataloading: 0.0012 s/iter. Inference: 0.0515 s/iter. Eval: 0.0342 s/iter. Total: 0.0870 s/iter. ETA=0:00:04
[12/09 11:51:07 d2.evaluation.evaluator]: Total inference time: 0:07:14.819313 (0.087051 s / iter per device, on 1 devices)
[12/09 11:51:07 d2.evaluation.evaluator]: Total inference pure compute time: 0:04:17 (0.051464 s / iter per device, on 1 devices)
[12/09 11:51:07 d2.evaluation.panoptic_evaluation]: Writing all panoptic predictions to /tmp/panoptic_evalozty2ln8 ...
[12/09 11:51:31 d2.evaluation.panoptic_evaluation]: Panoptic Evaluation Results:
|        |  PQ   |   SQ   |   RQ   |  #categories  |
|:------:|:-----:|:------:|:------:|:-------------:|
|  All   | 6.573 | 45.513 | 8.894  |      133      |
| Things | 4.582 | 47.629 | 6.326  |      80       |
| Stuff  | 9.578 | 42.319 | 12.770 |      53       |
[12/09 11:51:32 d2.evaluation.coco_evaluation]: Preparing results for COCO format ...
[12/09 11:51:32 d2.evaluation.coco_evaluation]: Saving results to ./output/inference/coco_instances_results.json
[12/09 11:51:32 d2.evaluation.coco_evaluation]: Evaluating predictions with unofficial COCO API...
Loading and preparing results...
DONE (t=0.03s)
creating index...
index created!
[12/09 11:51:32 d2.evaluation.fast_eval_api]: Evaluate annotation type *bbox*
[12/09 11:51:40 d2.evaluation.fast_eval_api]: COCOeval_opt.evaluate() finished in 7.74 seconds.
[12/09 11:51:40 d2.evaluation.fast_eval_api]: Accumulating evaluation results...
[12/09 11:51:40 d2.evaluation.fast_eval_api]: COCOeval_opt.accumulate() finished in 0.62 seconds.
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.012
 Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.028
 Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.010
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.001
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.009
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.022
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.024
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.034
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.034
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.002
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.018
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.061
[12/09 11:51:40 d2.evaluation.coco_evaluation]: Evaluation results for bbox: 
|  AP   |  AP50  |  AP75  |  APs  |  APm  |  APl  |
|:-----:|:------:|:------:|:-----:|:-----:|:-----:|
| 1.224 | 2.819  | 0.985  | 0.113 | 0.883 | 2.219 |
[12/09 11:51:40 d2.evaluation.coco_evaluation]: Per-category bbox AP: 
| category      | AP    | category     | AP     | category       | AP     |
|:--------------|:------|:-------------|:-------|:---------------|:-------|
| person        | 7.589 | bicycle      | 0.114  | car            | 2.339  |
| motorcycle    | 0.906 | airplane     | 1.150  | bus            | 8.940  |
| train         | 1.358 | truck        | 0.898  | boat           | 0.157  |
| traffic light | 0.149 | fire hydrant | 0.170  | stop sign      | 10.915 |
| parking meter | 0.000 | bench        | 0.009  | bird           | 0.133  |
| cat           | 2.022 | dog          | 0.347  | horse          | 0.693  |
| sheep         | 1.925 | cow          | 2.083  | elephant       | 6.041  |
| bear          | 3.107 | zebra        | 14.928 | giraffe        | 6.181  |
| backpack      | 0.000 | umbrella     | 0.316  | handbag        | 0.000  |
| tie           | 0.000 | suitcase     | 0.000  | frisbee        | 0.000  |
| skis          | 0.053 | snowboard    | 0.000  | sports ball    | 0.693  |
| kite          | 1.786 | baseball bat | 0.000  | baseball glove | 0.000  |
| skateboard    | 0.000 | surfboard    | 0.840  | tennis racket  | 0.297  |
| bottle        | 0.043 | wine glass   | 0.000  | cup            | 0.181  |
| fork          | 0.000 | knife        | 0.000  | spoon          | 0.000  |
| bowl          | 1.135 | banana       | 0.099  | apple          | 0.000  |
| sandwich      | 0.099 | orange       | 1.098  | broccoli       | 0.337  |
| carrot        | 0.030 | hot dog      | 0.000  | pizza          | 1.055  |
| donut         | 0.000 | cake         | 0.000  | chair          | 0.191  |
| couch         | 0.283 | potted plant | 0.797  | bed            | 2.033  |
| dining table  | 1.356 | toilet       | 5.373  | tv             | 3.621  |
| laptop        | 1.075 | mouse        | 0.000  | remote         | 0.000  |
| keyboard      | 0.020 | cell phone   | 0.000  | microwave      | 0.000  |
| oven          | 0.120 | toaster      | 0.000  | sink           | 1.036  |
| refrigerator  | 0.000 | book         | 0.011  | clock          | 1.539  |
| vase          | 0.033 | scissors     | 0.000  | teddy bear     | 0.198  |
| hair drier    | 0.000 | toothbrush   | 0.000  |                |        |
Loading and preparing results...
DONE (t=0.44s)
creating index...
index created!
[12/09 11:51:42 d2.evaluation.fast_eval_api]: Evaluate annotation type *segm*
[12/09 11:51:50 d2.evaluation.fast_eval_api]: COCOeval_opt.evaluate() finished in 8.83 seconds.
[12/09 11:51:50 d2.evaluation.fast_eval_api]: Accumulating evaluation results...
[12/09 11:51:51 d2.evaluation.fast_eval_api]: COCOeval_opt.accumulate() finished in 0.67 seconds.
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.013
 Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.029
 Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.011
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.000
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.009
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.032
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.023
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.029
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.030
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.001
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.017
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.055
[12/09 11:51:54 d2.evaluation.coco_evaluation]: Evaluation results for segm: 
|  AP   |  AP50  |  AP75  |  APs  |  APm  |  APl  |
|:-----:|:------:|:------:|:-----:|:-----:|:-----:|
| 1.334 | 2.884  | 1.102  | 0.050 | 0.868 | 3.235 |
[12/09 11:51:54 d2.evaluation.coco_evaluation]: Per-category segm AP: 
| category      | AP    | category     | AP     | category       | AP     |
|:--------------|:------|:-------------|:-------|:---------------|:-------|
| person        | 4.916 | bicycle      | 0.000  | car            | 2.204  |
| motorcycle    | 0.535 | airplane     | 1.218  | bus            | 9.531  |
| train         | 2.441 | truck        | 0.718  | boat           | 0.080  |
| traffic light | 0.183 | fire hydrant | 0.212  | stop sign      | 14.817 |
| parking meter | 0.000 | bench        | 0.000  | bird           | 0.136  |
| cat           | 1.269 | dog          | 0.495  | horse          | 0.594  |
| sheep         | 2.130 | cow          | 2.143  | elephant       | 6.113  |
| bear          | 6.624 | zebra        | 15.107 | giraffe        | 5.592  |
| backpack      | 0.000 | umbrella     | 0.332  | handbag        | 0.000  |
| tie           | 0.000 | suitcase     | 0.045  | frisbee        | 0.347  |
| skis          | 0.000 | snowboard    | 0.000  | sports ball    | 0.792  |
| kite          | 1.434 | baseball bat | 0.000  | baseball glove | 0.000  |
| skateboard    | 0.000 | surfboard    | 0.911  | tennis racket  | 0.693  |
| bottle        | 0.047 | wine glass   | 0.000  | cup            | 0.317  |
| fork          | 0.000 | knife        | 0.000  | spoon          | 0.000  |
| bowl          | 1.324 | banana       | 0.130  | apple          | 0.000  |
| sandwich      | 0.040 | orange       | 2.097  | broccoli       | 0.215  |
| carrot        | 0.014 | hot dog      | 0.000  | pizza          | 0.476  |
| donut         | 0.099 | cake         | 0.000  | chair          | 0.247  |
| couch         | 0.323 | potted plant | 0.297  | bed            | 2.052  |
| dining table  | 0.205 | toilet       | 7.820  | tv             | 4.105  |
| laptop        | 0.895 | mouse        | 0.000  | remote         | 0.000  |
| keyboard      | 0.010 | cell phone   | 0.000  | microwave      | 0.000  |
| oven          | 0.105 | toaster      | 0.000  | sink           | 0.840  |
| refrigerator  | 0.000 | book         | 0.006  | clock          | 2.582  |
| vase          | 0.693 | scissors     | 0.000  | teddy bear     | 0.156  |
| hair drier    | 0.000 | toothbrush   | 0.000  |                |        |
[12/09 11:51:56 d2.engine.defaults]: Evaluation results for coco_2017_val_panoptic in csv format:
[12/09 11:51:56 d2.evaluation.testing]: copypaste: Task: panoptic_seg
[12/09 11:51:56 d2.evaluation.testing]: copypaste: PQ,SQ,RQ,PQ_th,SQ_th,RQ_th,PQ_st,SQ_st,RQ_st
[12/09 11:51:56 d2.evaluation.testing]: copypaste: 6.5731,45.5133,8.8942,4.5820,47.6295,6.3263,9.5783,42.3191,12.7703
[12/09 11:51:56 d2.evaluation.testing]: copypaste: Task: bbox
[12/09 11:51:56 d2.evaluation.testing]: copypaste: AP,AP50,AP75,APs,APm,APl
[12/09 11:51:56 d2.evaluation.testing]: copypaste: 1.2238,2.8187,0.9845,0.1132,0.8834,2.2190
[12/09 11:51:56 d2.evaluation.testing]: copypaste: Task: segm
[12/09 11:51:56 d2.evaluation.testing]: copypaste: AP,AP50,AP75,APs,APm,APl
[12/09 11:51:56 d2.evaluation.testing]: copypaste: 1.3338,2.8844,1.1025,0.0495,0.8684,3.2345