env: DETECTRON2_DATASETS=/content/datasets
usage: train_net.py [-h] [--config-file FILE] [--resume] [--eval-only]
                    [--num-gpus NUM_GPUS] [--num-machines NUM_MACHINES]
                    [--machine-rank MACHINE_RANK] [--dist-url DIST_URL]
                    ...

positional arguments:
  opts                  Modify config options at the end of the command. For
                        Yacs configs, use space-separated "PATH.KEY VALUE"
                        pairs. For python-based LazyConfig, use
                        "path.key=value".

optional arguments:
  -h, --help            show this help message and exit
  --config-file FILE    path to config file
  --resume              Whether to attempt to resume from the checkpoint
                        directory. See documentation of
                        `DefaultTrainer.resume_or_load()` for what it means.
  --eval-only           perform evaluation only
  --num-gpus NUM_GPUS   number of gpus *per machine*
  --num-machines NUM_MACHINES
                        total number of machines
  --machine-rank MACHINE_RANK
                        the rank of this machine (unique per machine)
  --dist-url DIST_URL   initialization URL for pytorch distributed backend.
                        See https://pytorch.org/docs/stable/distributed.html
                        for details.

Examples:

Run on single machine:
    $ ./detectron2/tools/train_net.py --num-gpus 8 --config-file cfg.yaml

Change some config options:
    $ ./detectron2/tools/train_net.py --config-file cfg.yaml MODEL.WEIGHTS /path/to/weight.pth SOLVER.BASE_LR 0.001

Run on multiple machines:
    (machine0)$ ./detectron2/tools/train_net.py --machine-rank 0 --num-machines 2 --dist-url <URL> [--other-flags]
    (machine1)$ ./detectron2/tools/train_net.py --machine-rank 1 --num-machines 2 --dist-url <URL> [--other-flags]
Command Line Args: Namespace(config_file='./detectron2/configs/COCO-PanopticSegmentation/panoptic_fpn_R_101_3x.yaml', dist_url='tcp://127.0.0.1:49152', eval_only=False, machine_rank=0, num_gpus=1, num_machines=1, opts=['SOLVER.MAX_ITER', '10000', 'SOLVER.IMS_PER_BATCH', '5', 'SOLVER.BASE_LR', '0.0025', 'MODEL.BACKBONE.FREEZE_AT', '4'], resume=False)
[12/13 06:13:30 detectron2]: Rank of current process: 0. World size: 1
[12/13 06:13:31 detectron2]: Environment info:
----------------------  ----------------------------------------------------------------
sys.platform            linux
Python                  3.7.12 (default, Jan 15 2022, 18:48:18) [GCC 7.5.0]
numpy                   1.21.5
detectron2              0.6 @/content/detectron2/detectron2
Compiler                GCC 7.5
CUDA compiler           CUDA 11.1
detectron2 arch flags   7.0
DETECTRON2_ENV_MODULE   <not set>
PyTorch                 1.10.0+cu111 @/usr/local/lib/python3.7/dist-packages/torch
PyTorch debug build     False
GPU available           Yes
GPU 0                   Tesla V100-SXM2-16GB (arch=7.0)
Driver version          460.32.03
CUDA_HOME               /usr/local/cuda
Pillow                  7.1.2
torchvision             0.11.1+cu111 @/usr/local/lib/python3.7/dist-packages/torchvision
torchvision arch flags  3.5, 5.0, 6.0, 7.0, 7.5, 8.0, 8.6
fvcore                  0.1.5.post20221122
iopath                  0.1.9
cv2                     4.1.2
----------------------  ----------------------------------------------------------------
PyTorch built with:
  - GCC 7.3
  - C++ Version: 201402
  - Intel(R) Math Kernel Library Version 2020.0.0 Product Build 20191122 for Intel(R) 64 architecture applications
  - Intel(R) MKL-DNN v2.2.3 (Git Hash 7336ca9f055cf1bfa13efb658fe15dc9b41f0740)
  - OpenMP 201511 (a.k.a. OpenMP 4.5)
  - LAPACK is enabled (usually provided by MKL)
  - NNPACK is enabled
  - CPU capability usage: AVX512
  - CUDA Runtime 11.1
  - NVCC architecture flags: -gencode;arch=compute_37,code=sm_37;-gencode;arch=compute_50,code=sm_50;-gencode;arch=compute_60,code=sm_60;-gencode;arch=compute_70,code=sm_70;-gencode;arch=compute_75,code=sm_75;-gencode;arch=compute_80,code=sm_80;-gencode;arch=compute_86,code=sm_86
  - CuDNN 8.0.5
  - Magma 2.5.2
  - Build settings: BLAS_INFO=mkl, BUILD_TYPE=Release, CUDA_VERSION=11.1, CUDNN_VERSION=8.0.5, CXX_COMPILER=/opt/rh/devtoolset-7/root/usr/bin/c++, CXX_FLAGS= -Wno-deprecated -fvisibility-inlines-hidden -DUSE_PTHREADPOOL -fopenmp -DNDEBUG -DUSE_KINETO -DUSE_FBGEMM -DUSE_QNNPACK -DUSE_PYTORCH_QNNPACK -DUSE_XNNPACK -DSYMBOLICATE_MOBILE_DEBUG_HANDLE -DEDGE_PROFILER_USE_KINETO -O2 -fPIC -Wno-narrowing -Wall -Wextra -Werror=return-type -Wno-missing-field-initializers -Wno-type-limits -Wno-array-bounds -Wno-unknown-pragmas -Wno-sign-compare -Wno-unused-parameter -Wno-unused-variable -Wno-unused-function -Wno-unused-result -Wno-unused-local-typedefs -Wno-strict-overflow -Wno-strict-aliasing -Wno-error=deprecated-declarations -Wno-stringop-overflow -Wno-psabi -Wno-error=pedantic -Wno-error=redundant-decls -Wno-error=old-style-cast -fdiagnostics-color=always -faligned-new -Wno-unused-but-set-variable -Wno-maybe-uninitialized -fno-math-errno -fno-trapping-math -Werror=format -Wno-stringop-overflow, LAPACK_INFO=mkl, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, TORCH_VERSION=1.10.0, USE_CUDA=ON, USE_CUDNN=ON, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_MKL=ON, USE_MKLDNN=ON, USE_MPI=OFF, USE_NCCL=ON, USE_NNPACK=ON, USE_OPENMP=ON, 

[12/13 06:13:31 detectron2]: Command line arguments: Namespace(config_file='./detectron2/configs/COCO-PanopticSegmentation/panoptic_fpn_R_101_3x.yaml', dist_url='tcp://127.0.0.1:49152', eval_only=False, machine_rank=0, num_gpus=1, num_machines=1, opts=['SOLVER.MAX_ITER', '10000', 'SOLVER.IMS_PER_BATCH', '5', 'SOLVER.BASE_LR', '0.0025', 'MODEL.BACKBONE.FREEZE_AT', '4'], resume=False)
[12/13 06:13:31 detectron2]: Contents of args.config_file=./detectron2/configs/COCO-PanopticSegmentation/panoptic_fpn_R_101_3x.yaml:
_BASE_: "Base-Panoptic-FPN.yaml"
MODEL:
  WEIGHTS: "detectron2://ImageNetPretrained/MSRA/R-101.pkl"
  RESNETS:
    DEPTH: 101
SOLVER:
  STEPS: (210000, 250000)
  MAX_ITER: 270000

[12/13 06:13:31 detectron2]: Running with full config:
CUDNN_BENCHMARK: false
DATALOADER:
  ASPECT_RATIO_GROUPING: true
  FILTER_EMPTY_ANNOTATIONS: false
  NUM_WORKERS: 4
  REPEAT_THRESHOLD: 0.0
  SAMPLER_TRAIN: TrainingSampler
DATASETS:
  PRECOMPUTED_PROPOSAL_TOPK_TEST: 1000
  PRECOMPUTED_PROPOSAL_TOPK_TRAIN: 2000
  PROPOSAL_FILES_TEST: []
  PROPOSAL_FILES_TRAIN: []
  TEST:
  - coco_2017_val_panoptic_separated
  TRAIN:
  - coco_2017_train_panoptic_separated
GLOBAL:
  HACK: 1.0
INPUT:
  CROP:
    ENABLED: false
    SIZE:
    - 0.9
    - 0.9
    TYPE: relative_range
  FORMAT: BGR
  MASK_FORMAT: polygon
  MAX_SIZE_TEST: 1333
  MAX_SIZE_TRAIN: 1333
  MIN_SIZE_TEST: 800
  MIN_SIZE_TRAIN:
  - 640
  - 672
  - 704
  - 736
  - 768
  - 800
  MIN_SIZE_TRAIN_SAMPLING: choice
  RANDOM_FLIP: horizontal
MODEL:
  ANCHOR_GENERATOR:
    ANGLES:
    - - -90
      - 0
      - 90
    ASPECT_RATIOS:
    - - 0.5
      - 1.0
      - 2.0
    NAME: DefaultAnchorGenerator
    OFFSET: 0.0
    SIZES:
    - - 32
    - - 64
    - - 128
    - - 256
    - - 512
  BACKBONE:
    FREEZE_AT: 4
    NAME: build_resnet_fpn_backbone
  DEVICE: cuda
  FPN:
    FUSE_TYPE: sum
    IN_FEATURES:
    - res2
    - res3
    - res4
    - res5
    NORM: ''
    OUT_CHANNELS: 256
  KEYPOINT_ON: false
  LOAD_PROPOSALS: false
  MASK_ON: true
  META_ARCHITECTURE: PanopticFPN
  PANOPTIC_FPN:
    COMBINE:
      ENABLED: true
      INSTANCES_CONFIDENCE_THRESH: 0.5
      OVERLAP_THRESH: 0.5
      STUFF_AREA_LIMIT: 4096
    INSTANCE_LOSS_WEIGHT: 1.0
  PIXEL_MEAN:
  - 103.53
  - 116.28
  - 123.675
  PIXEL_STD:
  - 1.0
  - 1.0
  - 1.0
  PROPOSAL_GENERATOR:
    MIN_SIZE: 0
    NAME: RPN
  RESNETS:
    DEFORM_MODULATED: false
    DEFORM_NUM_GROUPS: 1
    DEFORM_ON_PER_STAGE:
    - false
    - false
    - false
    - false
    DEPTH: 101
    NORM: FrozenBN
    NUM_GROUPS: 1
    OUT_FEATURES:
    - res2
    - res3
    - res4
    - res5
    RES2_OUT_CHANNELS: 256
    RES5_DILATION: 1
    STEM_OUT_CHANNELS: 64
    STRIDE_IN_1X1: true
    WIDTH_PER_GROUP: 64
  RETINANET:
    BBOX_REG_LOSS_TYPE: smooth_l1
    BBOX_REG_WEIGHTS: &id001
    - 1.0
    - 1.0
    - 1.0
    - 1.0
    FOCAL_LOSS_ALPHA: 0.25
    FOCAL_LOSS_GAMMA: 2.0
    IN_FEATURES:
    - p3
    - p4
    - p5
    - p6
    - p7
    IOU_LABELS:
    - 0
    - -1
    - 1
    IOU_THRESHOLDS:
    - 0.4
    - 0.5
    NMS_THRESH_TEST: 0.5
    NORM: ''
    NUM_CLASSES: 80
    NUM_CONVS: 4
    PRIOR_PROB: 0.01
    SCORE_THRESH_TEST: 0.05
    SMOOTH_L1_LOSS_BETA: 0.1
    TOPK_CANDIDATES_TEST: 1000
  ROI_BOX_CASCADE_HEAD:
    BBOX_REG_WEIGHTS:
    - - 10.0
      - 10.0
      - 5.0
      - 5.0
    - - 20.0
      - 20.0
      - 10.0
      - 10.0
    - - 30.0
      - 30.0
      - 15.0
      - 15.0
    IOUS:
    - 0.5
    - 0.6
    - 0.7
  ROI_BOX_HEAD:
    BBOX_REG_LOSS_TYPE: smooth_l1
    BBOX_REG_LOSS_WEIGHT: 1.0
    BBOX_REG_WEIGHTS:
    - 10.0
    - 10.0
    - 5.0
    - 5.0
    CLS_AGNOSTIC_BBOX_REG: false
    CONV_DIM: 256
    FC_DIM: 1024
    FED_LOSS_FREQ_WEIGHT_POWER: 0.5
    FED_LOSS_NUM_CLASSES: 50
    NAME: FastRCNNConvFCHead
    NORM: ''
    NUM_CONV: 0
    NUM_FC: 2
    POOLER_RESOLUTION: 7
    POOLER_SAMPLING_RATIO: 0
    POOLER_TYPE: ROIAlignV2
    SMOOTH_L1_BETA: 0.0
    TRAIN_ON_PRED_BOXES: false
    USE_FED_LOSS: false
    USE_SIGMOID_CE: false
  ROI_HEADS:
    BATCH_SIZE_PER_IMAGE: 512
    IN_FEATURES:
    - p2
    - p3
    - p4
    - p5
    IOU_LABELS:
    - 0
    - 1
    IOU_THRESHOLDS:
    - 0.5
    NAME: StandardROIHeads
    NMS_THRESH_TEST: 0.5
    NUM_CLASSES: 80
    POSITIVE_FRACTION: 0.25
    PROPOSAL_APPEND_GT: true
    SCORE_THRESH_TEST: 0.05
  ROI_KEYPOINT_HEAD:
    CONV_DIMS:
    - 512
    - 512
    - 512
    - 512
    - 512
    - 512
    - 512
    - 512
    LOSS_WEIGHT: 1.0
    MIN_KEYPOINTS_PER_IMAGE: 1
    NAME: KRCNNConvDeconvUpsampleHead
    NORMALIZE_LOSS_BY_VISIBLE_KEYPOINTS: true
    NUM_KEYPOINTS: 17
    POOLER_RESOLUTION: 14
    POOLER_SAMPLING_RATIO: 0
    POOLER_TYPE: ROIAlignV2
  ROI_MASK_HEAD:
    CLS_AGNOSTIC_MASK: false
    CONV_DIM: 256
    NAME: MaskRCNNConvUpsampleHead
    NORM: ''
    NUM_CONV: 4
    POOLER_RESOLUTION: 14
    POOLER_SAMPLING_RATIO: 0
    POOLER_TYPE: ROIAlignV2
  RPN:
    BATCH_SIZE_PER_IMAGE: 256
    BBOX_REG_LOSS_TYPE: smooth_l1
    BBOX_REG_LOSS_WEIGHT: 1.0
    BBOX_REG_WEIGHTS: *id001
    BOUNDARY_THRESH: -1
    CONV_DIMS:
    - -1
    HEAD_NAME: StandardRPNHead
    IN_FEATURES:
    - p2
    - p3
    - p4
    - p5
    - p6
    IOU_LABELS:
    - 0
    - -1
    - 1
    IOU_THRESHOLDS:
    - 0.3
    - 0.7
    LOSS_WEIGHT: 1.0
    NMS_THRESH: 0.7
    POSITIVE_FRACTION: 0.5
    POST_NMS_TOPK_TEST: 1000
    POST_NMS_TOPK_TRAIN: 1000
    PRE_NMS_TOPK_TEST: 1000
    PRE_NMS_TOPK_TRAIN: 2000
    SMOOTH_L1_BETA: 0.0
  SEM_SEG_HEAD:
    COMMON_STRIDE: 4
    CONVS_DIM: 128
    IGNORE_VALUE: 255
    IN_FEATURES:
    - p2
    - p3
    - p4
    - p5
    LOSS_WEIGHT: 0.5
    NAME: SemSegFPNHead
    NORM: GN
    NUM_CLASSES: 54
  WEIGHTS: detectron2://ImageNetPretrained/MSRA/R-101.pkl
OUTPUT_DIR: ./output
SEED: -1
SOLVER:
  AMP:
    ENABLED: false
  BASE_LR: 0.0025
  BASE_LR_END: 0.0
  BIAS_LR_FACTOR: 1.0
  CHECKPOINT_PERIOD: 5000
  CLIP_GRADIENTS:
    CLIP_TYPE: value
    CLIP_VALUE: 1.0
    ENABLED: false
    NORM_TYPE: 2.0
  GAMMA: 0.1
  IMS_PER_BATCH: 5
  LR_SCHEDULER_NAME: WarmupMultiStepLR
  MAX_ITER: 10000
  MOMENTUM: 0.9
  NESTEROV: false
  NUM_DECAYS: 3
  REFERENCE_WORLD_SIZE: 0
  RESCALE_INTERVAL: false
  STEPS:
  - 210000
  - 250000
  WARMUP_FACTOR: 0.001
  WARMUP_ITERS: 1000
  WARMUP_METHOD: linear
  WEIGHT_DECAY: 0.0001
  WEIGHT_DECAY_BIAS: null
  WEIGHT_DECAY_NORM: 0.0
TEST:
  AUG:
    ENABLED: false
    FLIP: true
    MAX_SIZE: 4000
    MIN_SIZES:
    - 400
    - 500
    - 600
    - 700
    - 800
    - 900
    - 1000
    - 1100
    - 1200
  DETECTIONS_PER_IMAGE: 100
  EVAL_PERIOD: 0
  EXPECTED_RESULTS: []
  KEYPOINT_OKS_SIGMAS: []
  PRECISE_BN:
    ENABLED: false
    NUM_ITER: 200
VERSION: 2
VIS_PERIOD: 0

[12/13 06:13:31 detectron2]: Full config saved to ./output/config.yaml
[12/13 06:13:31 d2.utils.env]: Using a generated random seed 31451008
[12/13 06:13:36 d2.engine.defaults]: Model:
PanopticFPN(
  (backbone): FPN(
    (fpn_lateral2): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1))
    (fpn_output2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (fpn_lateral3): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1))
    (fpn_output3): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (fpn_lateral4): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1))
    (fpn_output4): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (fpn_lateral5): Conv2d(2048, 256, kernel_size=(1, 1), stride=(1, 1))
    (fpn_output5): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (top_block): LastLevelMaxPool()
    (bottom_up): ResNet(
      (stem): BasicStem(
        (conv1): Conv2d(
          3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False
          (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
        )
      )
      (res2): Sequential(
        (0): BottleneckBlock(
          (shortcut): Conv2d(
            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv1): Conv2d(
            64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
          )
          (conv2): Conv2d(
            64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
          )
          (conv3): Conv2d(
            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
        )
        (1): BottleneckBlock(
          (conv1): Conv2d(
            256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
          )
          (conv2): Conv2d(
            64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
          )
          (conv3): Conv2d(
            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
        )
        (2): BottleneckBlock(
          (conv1): Conv2d(
            256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
          )
          (conv2): Conv2d(
            64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
          )
          (conv3): Conv2d(
            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
        )
      )
      (res3): Sequential(
        (0): BottleneckBlock(
          (shortcut): Conv2d(
            256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
          (conv1): Conv2d(
            256, 128, kernel_size=(1, 1), stride=(2, 2), bias=False
            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
          )
          (conv2): Conv2d(
            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
          )
          (conv3): Conv2d(
            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
        )
        (1): BottleneckBlock(
          (conv1): Conv2d(
            512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
          )
          (conv2): Conv2d(
            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
          )
          (conv3): Conv2d(
            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
        )
        (2): BottleneckBlock(
          (conv1): Conv2d(
            512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
          )
          (conv2): Conv2d(
            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
          )
          (conv3): Conv2d(
            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
        )
        (3): BottleneckBlock(
          (conv1): Conv2d(
            512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
          )
          (conv2): Conv2d(
            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
          )
          (conv3): Conv2d(
            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
        )
      )
      (res4): Sequential(
        (0): BottleneckBlock(
          (shortcut): Conv2d(
            512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
          (conv1): Conv2d(
            512, 256, kernel_size=(1, 1), stride=(2, 2), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (1): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (2): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (3): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (4): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (5): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (6): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (7): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (8): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (9): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (10): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (11): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (12): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (13): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (14): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (15): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (16): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (17): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (18): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (19): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (20): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (21): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (22): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
      )
      (res5): Sequential(
        (0): BottleneckBlock(
          (shortcut): Conv2d(
            1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False
            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)
          )
          (conv1): Conv2d(
            1024, 512, kernel_size=(1, 1), stride=(2, 2), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
          (conv2): Conv2d(
            512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
          (conv3): Conv2d(
            512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)
          )
        )
        (1): BottleneckBlock(
          (conv1): Conv2d(
            2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
          (conv2): Conv2d(
            512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
          (conv3): Conv2d(
            512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)
          )
        )
        (2): BottleneckBlock(
          (conv1): Conv2d(
            2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
          (conv2): Conv2d(
            512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
          (conv3): Conv2d(
            512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)
          )
        )
      )
    )
  )
  (proposal_generator): RPN(
    (rpn_head): StandardRPNHead(
      (conv): Conv2d(
        256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)
        (activation): ReLU()
      )
      (objectness_logits): Conv2d(256, 3, kernel_size=(1, 1), stride=(1, 1))
      (anchor_deltas): Conv2d(256, 12, kernel_size=(1, 1), stride=(1, 1))
    )
    (anchor_generator): DefaultAnchorGenerator(
      (cell_anchors): BufferList()
    )
  )
  (roi_heads): StandardROIHeads(
    (box_pooler): ROIPooler(
      (level_poolers): ModuleList(
        (0): ROIAlign(output_size=(7, 7), spatial_scale=0.25, sampling_ratio=0, aligned=True)
        (1): ROIAlign(output_size=(7, 7), spatial_scale=0.125, sampling_ratio=0, aligned=True)
        (2): ROIAlign(output_size=(7, 7), spatial_scale=0.0625, sampling_ratio=0, aligned=True)
        (3): ROIAlign(output_size=(7, 7), spatial_scale=0.03125, sampling_ratio=0, aligned=True)
      )
    )
    (box_head): FastRCNNConvFCHead(
      (flatten): Flatten(start_dim=1, end_dim=-1)
      (fc1): Linear(in_features=12544, out_features=1024, bias=True)
      (fc_relu1): ReLU()
      (fc2): Linear(in_features=1024, out_features=1024, bias=True)
      (fc_relu2): ReLU()
    )
    (box_predictor): FastRCNNOutputLayers(
      (cls_score): Linear(in_features=1024, out_features=81, bias=True)
      (bbox_pred): Linear(in_features=1024, out_features=320, bias=True)
    )
    (mask_pooler): ROIPooler(
      (level_poolers): ModuleList(
        (0): ROIAlign(output_size=(14, 14), spatial_scale=0.25, sampling_ratio=0, aligned=True)
        (1): ROIAlign(output_size=(14, 14), spatial_scale=0.125, sampling_ratio=0, aligned=True)
        (2): ROIAlign(output_size=(14, 14), spatial_scale=0.0625, sampling_ratio=0, aligned=True)
        (3): ROIAlign(output_size=(14, 14), spatial_scale=0.03125, sampling_ratio=0, aligned=True)
      )
    )
    (mask_head): MaskRCNNConvUpsampleHead(
      (mask_fcn1): Conv2d(
        256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)
        (activation): ReLU()
      )
      (mask_fcn2): Conv2d(
        256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)
        (activation): ReLU()
      )
      (mask_fcn3): Conv2d(
        256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)
        (activation): ReLU()
      )
      (mask_fcn4): Conv2d(
        256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)
        (activation): ReLU()
      )
      (deconv): ConvTranspose2d(256, 256, kernel_size=(2, 2), stride=(2, 2))
      (deconv_relu): ReLU()
      (predictor): Conv2d(256, 80, kernel_size=(1, 1), stride=(1, 1))
    )
  )
  (sem_seg_head): SemSegFPNHead(
    (p2): Sequential(
      (0): Conv2d(
        256, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
        (norm): GroupNorm(32, 128, eps=1e-05, affine=True)
      )
    )
    (p3): Sequential(
      (0): Conv2d(
        256, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
        (norm): GroupNorm(32, 128, eps=1e-05, affine=True)
      )
      (1): Upsample(scale_factor=2.0, mode=bilinear)
    )
    (p4): Sequential(
      (0): Conv2d(
        256, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
        (norm): GroupNorm(32, 128, eps=1e-05, affine=True)
      )
      (1): Upsample(scale_factor=2.0, mode=bilinear)
      (2): Conv2d(
        128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
        (norm): GroupNorm(32, 128, eps=1e-05, affine=True)
      )
      (3): Upsample(scale_factor=2.0, mode=bilinear)
    )
    (p5): Sequential(
      (0): Conv2d(
        256, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
        (norm): GroupNorm(32, 128, eps=1e-05, affine=True)
      )
      (1): Upsample(scale_factor=2.0, mode=bilinear)
      (2): Conv2d(
        128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
        (norm): GroupNorm(32, 128, eps=1e-05, affine=True)
      )
      (3): Upsample(scale_factor=2.0, mode=bilinear)
      (4): Conv2d(
        128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
        (norm): GroupNorm(32, 128, eps=1e-05, affine=True)
      )
      (5): Upsample(scale_factor=2.0, mode=bilinear)
    )
    (predictor): Conv2d(128, 54, kernel_size=(1, 1), stride=(1, 1))
  )
)
[12/13 06:13:52 d2.data.datasets.coco]: Loading /content/datasets/coco/annotations/instances_train2017.json takes 16.47 seconds.
[12/13 06:13:53 d2.data.datasets.coco]: Loaded 118287 images in COCO format from /content/datasets/coco/annotations/instances_train2017.json
[12/13 06:14:05 d2.data.datasets.coco]: Loaded 118287 images with semantic segmentation from /content/datasets/coco/train2017
[12/13 06:14:10 d2.data.build]: Distribution of instances among all 80 categories:
|   category    | #instances   |   category   | #instances   |   category    | #instances   |
|:-------------:|:-------------|:------------:|:-------------|:-------------:|:-------------|
|    person     | 257253       |   bicycle    | 7056         |      car      | 43533        |
|  motorcycle   | 8654         |   airplane   | 5129         |      bus      | 6061         |
|     train     | 4570         |    truck     | 9970         |     boat      | 10576        |
| traffic light | 12842        | fire hydrant | 1865         |   stop sign   | 1983         |
| parking meter | 1283         |    bench     | 9820         |     bird      | 10542        |
|      cat      | 4766         |     dog      | 5500         |     horse     | 6567         |
|     sheep     | 9223         |     cow      | 8014         |   elephant    | 5484         |
|     bear      | 1294         |    zebra     | 5269         |    giraffe    | 5128         |
|   backpack    | 8714         |   umbrella   | 11265        |    handbag    | 12342        |
|      tie      | 6448         |   suitcase   | 6112         |    frisbee    | 2681         |
|     skis      | 6623         |  snowboard   | 2681         |  sports ball  | 6299         |
|     kite      | 8802         | baseball bat | 3273         | baseball gl.. | 3747         |
|  skateboard   | 5536         |  surfboard   | 6095         | tennis racket | 4807         |
|    bottle     | 24070        |  wine glass  | 7839         |      cup      | 20574        |
|     fork      | 5474         |    knife     | 7760         |     spoon     | 6159         |
|     bowl      | 14323        |    banana    | 9195         |     apple     | 5776         |
|   sandwich    | 4356         |    orange    | 6302         |   broccoli    | 7261         |
|    carrot     | 7758         |   hot dog    | 2884         |     pizza     | 5807         |
|     donut     | 7005         |     cake     | 6296         |     chair     | 38073        |
|     couch     | 5779         | potted plant | 8631         |      bed      | 4192         |
| dining table  | 15695        |    toilet    | 4149         |      tv       | 5803         |
|    laptop     | 4960         |    mouse     | 2261         |    remote     | 5700         |
|   keyboard    | 2854         |  cell phone  | 6422         |   microwave   | 1672         |
|     oven      | 3334         |   toaster    | 225          |     sink      | 5609         |
| refrigerator  | 2634         |     book     | 24077        |     clock     | 6320         |
|     vase      | 6577         |   scissors   | 1464         |  teddy bear   | 4729         |
|  hair drier   | 198          |  toothbrush  | 1945         |               |              |
|     total     | 849949       |              |              |               |              |
[12/13 06:14:10 d2.data.dataset_mapper]: [DatasetMapper] Augmentations used in training: [ResizeShortestEdge(short_edge_length=(640, 672, 704, 736, 768, 800), max_size=1333, sample_style='choice'), RandomFlip()]
[12/13 06:14:10 d2.data.build]: Using training sampler TrainingSampler
[12/13 06:14:10 d2.data.common]: Serializing the dataset using: <class 'detectron2.data.common.NumpySerializedList'>
[12/13 06:14:10 d2.data.common]: Serializing 118287 elements to byte tensors and concatenating them all ...
[12/13 06:14:14 d2.data.common]: Serialized dataset takes 462.17 MiB
WARNING [12/13 06:14:17 d2.solver.build]: SOLVER.STEPS contains values larger than SOLVER.MAX_ITER. These values will be ignored.
[12/13 06:14:19 fvcore.common.checkpoint]: [Checkpointer] Loading from detectron2://ImageNetPretrained/MSRA/R-101.pkl ...
[12/13 06:14:19 d2.checkpoint.c2_model_loading]: Renaming Caffe2 weights ......
[12/13 06:14:19 d2.checkpoint.c2_model_loading]: Following weights matched with submodule backbone.bottom_up:
| Names in Model    | Names in Checkpoint       | Shapes                                          |
|:------------------|:--------------------------|:------------------------------------------------|
| res2.0.conv1.*    | res2_0_branch2a_{bn_*,w}  | (64,) (64,) (64,) (64,) (64,64,1,1)             |
| res2.0.conv2.*    | res2_0_branch2b_{bn_*,w}  | (64,) (64,) (64,) (64,) (64,64,3,3)             |
| res2.0.conv3.*    | res2_0_branch2c_{bn_*,w}  | (256,) (256,) (256,) (256,) (256,64,1,1)        |
| res2.0.shortcut.* | res2_0_branch1_{bn_*,w}   | (256,) (256,) (256,) (256,) (256,64,1,1)        |
| res2.1.conv1.*    | res2_1_branch2a_{bn_*,w}  | (64,) (64,) (64,) (64,) (64,256,1,1)            |
| res2.1.conv2.*    | res2_1_branch2b_{bn_*,w}  | (64,) (64,) (64,) (64,) (64,64,3,3)             |
| res2.1.conv3.*    | res2_1_branch2c_{bn_*,w}  | (256,) (256,) (256,) (256,) (256,64,1,1)        |
| res2.2.conv1.*    | res2_2_branch2a_{bn_*,w}  | (64,) (64,) (64,) (64,) (64,256,1,1)            |
| res2.2.conv2.*    | res2_2_branch2b_{bn_*,w}  | (64,) (64,) (64,) (64,) (64,64,3,3)             |
| res2.2.conv3.*    | res2_2_branch2c_{bn_*,w}  | (256,) (256,) (256,) (256,) (256,64,1,1)        |
| res3.0.conv1.*    | res3_0_branch2a_{bn_*,w}  | (128,) (128,) (128,) (128,) (128,256,1,1)       |
| res3.0.conv2.*    | res3_0_branch2b_{bn_*,w}  | (128,) (128,) (128,) (128,) (128,128,3,3)       |
| res3.0.conv3.*    | res3_0_branch2c_{bn_*,w}  | (512,) (512,) (512,) (512,) (512,128,1,1)       |
| res3.0.shortcut.* | res3_0_branch1_{bn_*,w}   | (512,) (512,) (512,) (512,) (512,256,1,1)       |
| res3.1.conv1.*    | res3_1_branch2a_{bn_*,w}  | (128,) (128,) (128,) (128,) (128,512,1,1)       |
| res3.1.conv2.*    | res3_1_branch2b_{bn_*,w}  | (128,) (128,) (128,) (128,) (128,128,3,3)       |
| res3.1.conv3.*    | res3_1_branch2c_{bn_*,w}  | (512,) (512,) (512,) (512,) (512,128,1,1)       |
| res3.2.conv1.*    | res3_2_branch2a_{bn_*,w}  | (128,) (128,) (128,) (128,) (128,512,1,1)       |
| res3.2.conv2.*    | res3_2_branch2b_{bn_*,w}  | (128,) (128,) (128,) (128,) (128,128,3,3)       |
| res3.2.conv3.*    | res3_2_branch2c_{bn_*,w}  | (512,) (512,) (512,) (512,) (512,128,1,1)       |
| res3.3.conv1.*    | res3_3_branch2a_{bn_*,w}  | (128,) (128,) (128,) (128,) (128,512,1,1)       |
| res3.3.conv2.*    | res3_3_branch2b_{bn_*,w}  | (128,) (128,) (128,) (128,) (128,128,3,3)       |
| res3.3.conv3.*    | res3_3_branch2c_{bn_*,w}  | (512,) (512,) (512,) (512,) (512,128,1,1)       |
| res4.0.conv1.*    | res4_0_branch2a_{bn_*,w}  | (256,) (256,) (256,) (256,) (256,512,1,1)       |
| res4.0.conv2.*    | res4_0_branch2b_{bn_*,w}  | (256,) (256,) (256,) (256,) (256,256,3,3)       |
| res4.0.conv3.*    | res4_0_branch2c_{bn_*,w}  | (1024,) (1024,) (1024,) (1024,) (1024,256,1,1)  |
| res4.0.shortcut.* | res4_0_branch1_{bn_*,w}   | (1024,) (1024,) (1024,) (1024,) (1024,512,1,1)  |
| res4.1.conv1.*    | res4_1_branch2a_{bn_*,w}  | (256,) (256,) (256,) (256,) (256,1024,1,1)      |
| res4.1.conv2.*    | res4_1_branch2b_{bn_*,w}  | (256,) (256,) (256,) (256,) (256,256,3,3)       |
| res4.1.conv3.*    | res4_1_branch2c_{bn_*,w}  | (1024,) (1024,) (1024,) (1024,) (1024,256,1,1)  |
| res4.10.conv1.*   | res4_10_branch2a_{bn_*,w} | (256,) (256,) (256,) (256,) (256,1024,1,1)      |
| res4.10.conv2.*   | res4_10_branch2b_{bn_*,w} | (256,) (256,) (256,) (256,) (256,256,3,3)       |
| res4.10.conv3.*   | res4_10_branch2c_{bn_*,w} | (1024,) (1024,) (1024,) (1024,) (1024,256,1,1)  |
| res4.11.conv1.*   | res4_11_branch2a_{bn_*,w} | (256,) (256,) (256,) (256,) (256,1024,1,1)      |
| res4.11.conv2.*   | res4_11_branch2b_{bn_*,w} | (256,) (256,) (256,) (256,) (256,256,3,3)       |
| res4.11.conv3.*   | res4_11_branch2c_{bn_*,w} | (1024,) (1024,) (1024,) (1024,) (1024,256,1,1)  |
| res4.12.conv1.*   | res4_12_branch2a_{bn_*,w} | (256,) (256,) (256,) (256,) (256,1024,1,1)      |
| res4.12.conv2.*   | res4_12_branch2b_{bn_*,w} | (256,) (256,) (256,) (256,) (256,256,3,3)       |
| res4.12.conv3.*   | res4_12_branch2c_{bn_*,w} | (1024,) (1024,) (1024,) (1024,) (1024,256,1,1)  |
| res4.13.conv1.*   | res4_13_branch2a_{bn_*,w} | (256,) (256,) (256,) (256,) (256,1024,1,1)      |
| res4.13.conv2.*   | res4_13_branch2b_{bn_*,w} | (256,) (256,) (256,) (256,) (256,256,3,3)       |
| res4.13.conv3.*   | res4_13_branch2c_{bn_*,w} | (1024,) (1024,) (1024,) (1024,) (1024,256,1,1)  |
| res4.14.conv1.*   | res4_14_branch2a_{bn_*,w} | (256,) (256,) (256,) (256,) (256,1024,1,1)      |
| res4.14.conv2.*   | res4_14_branch2b_{bn_*,w} | (256,) (256,) (256,) (256,) (256,256,3,3)       |
| res4.14.conv3.*   | res4_14_branch2c_{bn_*,w} | (1024,) (1024,) (1024,) (1024,) (1024,256,1,1)  |
| res4.15.conv1.*   | res4_15_branch2a_{bn_*,w} | (256,) (256,) (256,) (256,) (256,1024,1,1)      |
| res4.15.conv2.*   | res4_15_branch2b_{bn_*,w} | (256,) (256,) (256,) (256,) (256,256,3,3)       |
| res4.15.conv3.*   | res4_15_branch2c_{bn_*,w} | (1024,) (1024,) (1024,) (1024,) (1024,256,1,1)  |
| res4.16.conv1.*   | res4_16_branch2a_{bn_*,w} | (256,) (256,) (256,) (256,) (256,1024,1,1)      |
| res4.16.conv2.*   | res4_16_branch2b_{bn_*,w} | (256,) (256,) (256,) (256,) (256,256,3,3)       |
| res4.16.conv3.*   | res4_16_branch2c_{bn_*,w} | (1024,) (1024,) (1024,) (1024,) (1024,256,1,1)  |
| res4.17.conv1.*   | res4_17_branch2a_{bn_*,w} | (256,) (256,) (256,) (256,) (256,1024,1,1)      |
| res4.17.conv2.*   | res4_17_branch2b_{bn_*,w} | (256,) (256,) (256,) (256,) (256,256,3,3)       |
| res4.17.conv3.*   | res4_17_branch2c_{bn_*,w} | (1024,) (1024,) (1024,) (1024,) (1024,256,1,1)  |
| res4.18.conv1.*   | res4_18_branch2a_{bn_*,w} | (256,) (256,) (256,) (256,) (256,1024,1,1)      |
| res4.18.conv2.*   | res4_18_branch2b_{bn_*,w} | (256,) (256,) (256,) (256,) (256,256,3,3)       |
| res4.18.conv3.*   | res4_18_branch2c_{bn_*,w} | (1024,) (1024,) (1024,) (1024,) (1024,256,1,1)  |
| res4.19.conv1.*   | res4_19_branch2a_{bn_*,w} | (256,) (256,) (256,) (256,) (256,1024,1,1)      |
| res4.19.conv2.*   | res4_19_branch2b_{bn_*,w} | (256,) (256,) (256,) (256,) (256,256,3,3)       |
| res4.19.conv3.*   | res4_19_branch2c_{bn_*,w} | (1024,) (1024,) (1024,) (1024,) (1024,256,1,1)  |
| res4.2.conv1.*    | res4_2_branch2a_{bn_*,w}  | (256,) (256,) (256,) (256,) (256,1024,1,1)      |
| res4.2.conv2.*    | res4_2_branch2b_{bn_*,w}  | (256,) (256,) (256,) (256,) (256,256,3,3)       |
| res4.2.conv3.*    | res4_2_branch2c_{bn_*,w}  | (1024,) (1024,) (1024,) (1024,) (1024,256,1,1)  |
| res4.20.conv1.*   | res4_20_branch2a_{bn_*,w} | (256,) (256,) (256,) (256,) (256,1024,1,1)      |
| res4.20.conv2.*   | res4_20_branch2b_{bn_*,w} | (256,) (256,) (256,) (256,) (256,256,3,3)       |
| res4.20.conv3.*   | res4_20_branch2c_{bn_*,w} | (1024,) (1024,) (1024,) (1024,) (1024,256,1,1)  |
| res4.21.conv1.*   | res4_21_branch2a_{bn_*,w} | (256,) (256,) (256,) (256,) (256,1024,1,1)      |
| res4.21.conv2.*   | res4_21_branch2b_{bn_*,w} | (256,) (256,) (256,) (256,) (256,256,3,3)       |
| res4.21.conv3.*   | res4_21_branch2c_{bn_*,w} | (1024,) (1024,) (1024,) (1024,) (1024,256,1,1)  |
| res4.22.conv1.*   | res4_22_branch2a_{bn_*,w} | (256,) (256,) (256,) (256,) (256,1024,1,1)      |
| res4.22.conv2.*   | res4_22_branch2b_{bn_*,w} | (256,) (256,) (256,) (256,) (256,256,3,3)       |
| res4.22.conv3.*   | res4_22_branch2c_{bn_*,w} | (1024,) (1024,) (1024,) (1024,) (1024,256,1,1)  |
| res4.3.conv1.*    | res4_3_branch2a_{bn_*,w}  | (256,) (256,) (256,) (256,) (256,1024,1,1)      |
| res4.3.conv2.*    | res4_3_branch2b_{bn_*,w}  | (256,) (256,) (256,) (256,) (256,256,3,3)       |
| res4.3.conv3.*    | res4_3_branch2c_{bn_*,w}  | (1024,) (1024,) (1024,) (1024,) (1024,256,1,1)  |
| res4.4.conv1.*    | res4_4_branch2a_{bn_*,w}  | (256,) (256,) (256,) (256,) (256,1024,1,1)      |
| res4.4.conv2.*    | res4_4_branch2b_{bn_*,w}  | (256,) (256,) (256,) (256,) (256,256,3,3)       |
| res4.4.conv3.*    | res4_4_branch2c_{bn_*,w}  | (1024,) (1024,) (1024,) (1024,) (1024,256,1,1)  |
| res4.5.conv1.*    | res4_5_branch2a_{bn_*,w}  | (256,) (256,) (256,) (256,) (256,1024,1,1)      |
| res4.5.conv2.*    | res4_5_branch2b_{bn_*,w}  | (256,) (256,) (256,) (256,) (256,256,3,3)       |
| res4.5.conv3.*    | res4_5_branch2c_{bn_*,w}  | (1024,) (1024,) (1024,) (1024,) (1024,256,1,1)  |
| res4.6.conv1.*    | res4_6_branch2a_{bn_*,w}  | (256,) (256,) (256,) (256,) (256,1024,1,1)      |
| res4.6.conv2.*    | res4_6_branch2b_{bn_*,w}  | (256,) (256,) (256,) (256,) (256,256,3,3)       |
| res4.6.conv3.*    | res4_6_branch2c_{bn_*,w}  | (1024,) (1024,) (1024,) (1024,) (1024,256,1,1)  |
| res4.7.conv1.*    | res4_7_branch2a_{bn_*,w}  | (256,) (256,) (256,) (256,) (256,1024,1,1)      |
| res4.7.conv2.*    | res4_7_branch2b_{bn_*,w}  | (256,) (256,) (256,) (256,) (256,256,3,3)       |
| res4.7.conv3.*    | res4_7_branch2c_{bn_*,w}  | (1024,) (1024,) (1024,) (1024,) (1024,256,1,1)  |
| res4.8.conv1.*    | res4_8_branch2a_{bn_*,w}  | (256,) (256,) (256,) (256,) (256,1024,1,1)      |
| res4.8.conv2.*    | res4_8_branch2b_{bn_*,w}  | (256,) (256,) (256,) (256,) (256,256,3,3)       |
| res4.8.conv3.*    | res4_8_branch2c_{bn_*,w}  | (1024,) (1024,) (1024,) (1024,) (1024,256,1,1)  |
| res4.9.conv1.*    | res4_9_branch2a_{bn_*,w}  | (256,) (256,) (256,) (256,) (256,1024,1,1)      |
| res4.9.conv2.*    | res4_9_branch2b_{bn_*,w}  | (256,) (256,) (256,) (256,) (256,256,3,3)       |
| res4.9.conv3.*    | res4_9_branch2c_{bn_*,w}  | (1024,) (1024,) (1024,) (1024,) (1024,256,1,1)  |
| res5.0.conv1.*    | res5_0_branch2a_{bn_*,w}  | (512,) (512,) (512,) (512,) (512,1024,1,1)      |
| res5.0.conv2.*    | res5_0_branch2b_{bn_*,w}  | (512,) (512,) (512,) (512,) (512,512,3,3)       |
| res5.0.conv3.*    | res5_0_branch2c_{bn_*,w}  | (2048,) (2048,) (2048,) (2048,) (2048,512,1,1)  |
| res5.0.shortcut.* | res5_0_branch1_{bn_*,w}   | (2048,) (2048,) (2048,) (2048,) (2048,1024,1,1) |
| res5.1.conv1.*    | res5_1_branch2a_{bn_*,w}  | (512,) (512,) (512,) (512,) (512,2048,1,1)      |
| res5.1.conv2.*    | res5_1_branch2b_{bn_*,w}  | (512,) (512,) (512,) (512,) (512,512,3,3)       |
| res5.1.conv3.*    | res5_1_branch2c_{bn_*,w}  | (2048,) (2048,) (2048,) (2048,) (2048,512,1,1)  |
| res5.2.conv1.*    | res5_2_branch2a_{bn_*,w}  | (512,) (512,) (512,) (512,) (512,2048,1,1)      |
| res5.2.conv2.*    | res5_2_branch2b_{bn_*,w}  | (512,) (512,) (512,) (512,) (512,512,3,3)       |
| res5.2.conv3.*    | res5_2_branch2c_{bn_*,w}  | (2048,) (2048,) (2048,) (2048,) (2048,512,1,1)  |
| stem.conv1.norm.* | res_conv1_bn_*            | (64,) (64,) (64,) (64,)                         |
| stem.conv1.weight | conv1_w                   | (64, 3, 7, 7)                                   |
WARNING [12/13 06:14:20 fvcore.common.checkpoint]: Some model parameters or buffers are not found in the checkpoint:
backbone.fpn_lateral2.{bias, weight}
backbone.fpn_lateral3.{bias, weight}
backbone.fpn_lateral4.{bias, weight}
backbone.fpn_lateral5.{bias, weight}
backbone.fpn_output2.{bias, weight}
backbone.fpn_output3.{bias, weight}
backbone.fpn_output4.{bias, weight}
backbone.fpn_output5.{bias, weight}
proposal_generator.rpn_head.anchor_deltas.{bias, weight}
proposal_generator.rpn_head.conv.{bias, weight}
proposal_generator.rpn_head.objectness_logits.{bias, weight}
roi_heads.box_head.fc1.{bias, weight}
roi_heads.box_head.fc2.{bias, weight}
roi_heads.box_predictor.bbox_pred.{bias, weight}
roi_heads.box_predictor.cls_score.{bias, weight}
roi_heads.mask_head.deconv.{bias, weight}
roi_heads.mask_head.mask_fcn1.{bias, weight}
roi_heads.mask_head.mask_fcn2.{bias, weight}
roi_heads.mask_head.mask_fcn3.{bias, weight}
roi_heads.mask_head.mask_fcn4.{bias, weight}
roi_heads.mask_head.predictor.{bias, weight}
sem_seg_head.p2.0.norm.{bias, weight}
sem_seg_head.p2.0.weight
sem_seg_head.p3.0.norm.{bias, weight}
sem_seg_head.p3.0.weight
sem_seg_head.p4.0.norm.{bias, weight}
sem_seg_head.p4.0.weight
sem_seg_head.p4.2.norm.{bias, weight}
sem_seg_head.p4.2.weight
sem_seg_head.p5.0.norm.{bias, weight}
sem_seg_head.p5.0.weight
sem_seg_head.p5.2.norm.{bias, weight}
sem_seg_head.p5.2.weight
sem_seg_head.p5.4.norm.{bias, weight}
sem_seg_head.p5.4.weight
sem_seg_head.predictor.{bias, weight}
WARNING [12/13 06:14:20 fvcore.common.checkpoint]: The checkpoint state_dict contains keys that are not used by the model:
  fc1000.{bias, weight}
[12/13 06:14:20 d2.engine.train_loop]: Starting training from iteration 0
/usr/local/lib/python3.7/dist-packages/torch/functional.py:445: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at  ../aten/src/ATen/native/TensorShape.cpp:2157.)
  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]
[12/13 06:14:30 d2.utils.events]:  eta: 1:20:15  iter: 19  total_loss: 10.24  loss_sem_seg: 5.586  loss_rpn_cls: 0.7646  loss_rpn_loc: 0.1931  loss_cls: 3.119  loss_box_reg: 0.008127  loss_mask: 0.6923  time: 0.4914  data_time: 0.0339  lr: 4.9952e-05  max_mem: 7924M
[12/13 06:14:40 d2.utils.events]:  eta: 1:20:28  iter: 39  total_loss: 4.879  loss_sem_seg: 3.23  loss_rpn_cls: 0.6963  loss_rpn_loc: 0.1745  loss_cls: 0.1667  loss_box_reg: 0.01052  loss_mask: 0.6912  time: 0.4910  data_time: 0.0184  lr: 9.9902e-05  max_mem: 7926M
[12/13 06:14:50 d2.utils.events]:  eta: 1:21:26  iter: 59  total_loss: 4.189  loss_sem_seg: 2.378  loss_rpn_cls: 0.5531  loss_rpn_loc: 0.1556  loss_cls: 0.3714  loss_box_reg: 0.05378  loss_mask: 0.6915  time: 0.4927  data_time: 0.0161  lr: 0.00014985  max_mem: 7926M
[12/13 06:15:00 d2.utils.events]:  eta: 1:21:48  iter: 79  total_loss: 3.901  loss_sem_seg: 1.977  loss_rpn_cls: 0.4083  loss_rpn_loc: 0.09744  loss_cls: 0.4265  loss_box_reg: 0.0988  loss_mask: 0.6914  time: 0.4958  data_time: 0.0191  lr: 0.0001998  max_mem: 7926M
[12/13 06:15:10 d2.utils.events]:  eta: 1:22:35  iter: 99  total_loss: 3.497  loss_sem_seg: 1.625  loss_rpn_cls: 0.3657  loss_rpn_loc: 0.183  loss_cls: 0.4549  loss_box_reg: 0.137  loss_mask: 0.6894  time: 0.5025  data_time: 0.0193  lr: 0.00024975  max_mem: 7926M
[12/13 06:15:21 d2.utils.events]:  eta: 1:22:37  iter: 119  total_loss: 3.378  loss_sem_seg: 1.595  loss_rpn_cls: 0.3396  loss_rpn_loc: 0.1645  loss_cls: 0.4511  loss_box_reg: 0.1559  loss_mask: 0.6898  time: 0.5040  data_time: 0.0163  lr: 0.0002997  max_mem: 7926M
[12/13 06:15:31 d2.utils.events]:  eta: 1:22:27  iter: 139  total_loss: 3.12  loss_sem_seg: 1.457  loss_rpn_cls: 0.3044  loss_rpn_loc: 0.1276  loss_cls: 0.4137  loss_box_reg: 0.1599  loss_mask: 0.6894  time: 0.5044  data_time: 0.0171  lr: 0.00034965  max_mem: 7926M
[12/13 06:15:41 d2.utils.events]:  eta: 1:22:49  iter: 159  total_loss: 2.979  loss_sem_seg: 1.263  loss_rpn_cls: 0.3017  loss_rpn_loc: 0.129  loss_cls: 0.3971  loss_box_reg: 0.1743  loss_mask: 0.6889  time: 0.5058  data_time: 0.0164  lr: 0.0003996  max_mem: 7926M
[12/13 06:15:52 d2.utils.events]:  eta: 1:23:00  iter: 179  total_loss: 2.889  loss_sem_seg: 1.179  loss_rpn_cls: 0.2976  loss_rpn_loc: 0.1445  loss_cls: 0.3367  loss_box_reg: 0.1273  loss_mask: 0.6869  time: 0.5080  data_time: 0.0177  lr: 0.00044955  max_mem: 7926M
[12/13 06:16:02 d2.utils.events]:  eta: 1:23:13  iter: 199  total_loss: 3.076  loss_sem_seg: 1.366  loss_rpn_cls: 0.2725  loss_rpn_loc: 0.1163  loss_cls: 0.3483  loss_box_reg: 0.1534  loss_mask: 0.6866  time: 0.5092  data_time: 0.0213  lr: 0.0004995  max_mem: 7926M
[12/13 06:16:12 d2.utils.events]:  eta: 1:23:03  iter: 219  total_loss: 2.723  loss_sem_seg: 1.178  loss_rpn_cls: 0.2466  loss_rpn_loc: 0.106  loss_cls: 0.3129  loss_box_reg: 0.1407  loss_mask: 0.6865  time: 0.5098  data_time: 0.0168  lr: 0.00054945  max_mem: 7926M
[12/13 06:16:23 d2.utils.events]:  eta: 1:22:55  iter: 239  total_loss: 2.669  loss_sem_seg: 1.151  loss_rpn_cls: 0.2393  loss_rpn_loc: 0.1288  loss_cls: 0.3427  loss_box_reg: 0.1549  loss_mask: 0.6817  time: 0.5100  data_time: 0.0183  lr: 0.0005994  max_mem: 7926M
[12/13 06:16:33 d2.utils.events]:  eta: 1:23:16  iter: 259  total_loss: 2.776  loss_sem_seg: 0.9862  loss_rpn_cls: 0.2638  loss_rpn_loc: 0.1419  loss_cls: 0.435  loss_box_reg: 0.1978  loss_mask: 0.6809  time: 0.5119  data_time: 0.0171  lr: 0.00064935  max_mem: 7926M
[12/13 06:16:44 d2.utils.events]:  eta: 1:23:12  iter: 279  total_loss: 2.695  loss_sem_seg: 0.9975  loss_rpn_cls: 0.2297  loss_rpn_loc: 0.1114  loss_cls: 0.3101  loss_box_reg: 0.1451  loss_mask: 0.6775  time: 0.5128  data_time: 0.0211  lr: 0.0006993  max_mem: 7926M
[12/13 06:16:54 d2.utils.events]:  eta: 1:23:15  iter: 299  total_loss: 2.511  loss_sem_seg: 0.9075  loss_rpn_cls: 0.2051  loss_rpn_loc: 0.1268  loss_cls: 0.358  loss_box_reg: 0.1813  loss_mask: 0.6781  time: 0.5133  data_time: 0.0176  lr: 0.00074925  max_mem: 7926M
[12/13 06:17:05 d2.utils.events]:  eta: 1:22:59  iter: 319  total_loss: 2.343  loss_sem_seg: 0.841  loss_rpn_cls: 0.2242  loss_rpn_loc: 0.128  loss_cls: 0.3237  loss_box_reg: 0.1419  loss_mask: 0.6691  time: 0.5134  data_time: 0.0179  lr: 0.0007992  max_mem: 7926M
[12/13 06:17:15 d2.utils.events]:  eta: 1:22:45  iter: 339  total_loss: 2.379  loss_sem_seg: 0.8585  loss_rpn_cls: 0.1643  loss_rpn_loc: 0.09391  loss_cls: 0.364  loss_box_reg: 0.1965  loss_mask: 0.6766  time: 0.5132  data_time: 0.0163  lr: 0.00084915  max_mem: 7926M
[12/13 06:17:25 d2.utils.events]:  eta: 1:22:25  iter: 359  total_loss: 2.306  loss_sem_seg: 0.8762  loss_rpn_cls: 0.158  loss_rpn_loc: 0.1122  loss_cls: 0.3117  loss_box_reg: 0.1532  loss_mask: 0.6651  time: 0.5124  data_time: 0.0172  lr: 0.0008991  max_mem: 7926M
[12/13 06:17:35 d2.utils.events]:  eta: 1:22:15  iter: 379  total_loss: 2.22  loss_sem_seg: 0.8212  loss_rpn_cls: 0.172  loss_rpn_loc: 0.1293  loss_cls: 0.2837  loss_box_reg: 0.1406  loss_mask: 0.6683  time: 0.5122  data_time: 0.0181  lr: 0.00094905  max_mem: 7926M
[12/13 06:17:45 d2.utils.events]:  eta: 1:22:04  iter: 399  total_loss: 2.392  loss_sem_seg: 0.7884  loss_rpn_cls: 0.1534  loss_rpn_loc: 0.1215  loss_cls: 0.3567  loss_box_reg: 0.1899  loss_mask: 0.6775  time: 0.5120  data_time: 0.0174  lr: 0.000999  max_mem: 7926M
[12/13 06:17:56 d2.utils.events]:  eta: 1:21:57  iter: 419  total_loss: 2.241  loss_sem_seg: 0.834  loss_rpn_cls: 0.1674  loss_rpn_loc: 0.1345  loss_cls: 0.3101  loss_box_reg: 0.1503  loss_mask: 0.6665  time: 0.5126  data_time: 0.0197  lr: 0.001049  max_mem: 7926M
[12/13 06:18:06 d2.utils.events]:  eta: 1:21:41  iter: 439  total_loss: 2.319  loss_sem_seg: 0.8462  loss_rpn_cls: 0.1413  loss_rpn_loc: 0.1391  loss_cls: 0.338  loss_box_reg: 0.192  loss_mask: 0.6577  time: 0.5124  data_time: 0.0214  lr: 0.0010989  max_mem: 7926M
[12/13 06:18:16 d2.utils.events]:  eta: 1:21:34  iter: 459  total_loss: 2.329  loss_sem_seg: 0.7534  loss_rpn_cls: 0.1265  loss_rpn_loc: 0.1197  loss_cls: 0.3611  loss_box_reg: 0.2214  loss_mask: 0.6656  time: 0.5132  data_time: 0.0173  lr: 0.0011489  max_mem: 7926M
[12/13 06:18:27 d2.utils.events]:  eta: 1:21:23  iter: 479  total_loss: 2.438  loss_sem_seg: 0.807  loss_rpn_cls: 0.1404  loss_rpn_loc: 0.1137  loss_cls: 0.4074  loss_box_reg: 0.2435  loss_mask: 0.654  time: 0.5130  data_time: 0.0170  lr: 0.0011988  max_mem: 7926M
[12/13 06:18:37 d2.utils.events]:  eta: 1:21:19  iter: 499  total_loss: 2.251  loss_sem_seg: 0.7259  loss_rpn_cls: 0.1303  loss_rpn_loc: 0.1501  loss_cls: 0.3535  loss_box_reg: 0.2303  loss_mask: 0.6343  time: 0.5138  data_time: 0.0188  lr: 0.0012488  max_mem: 7926M
[12/13 06:18:48 d2.utils.events]:  eta: 1:21:17  iter: 519  total_loss: 2.246  loss_sem_seg: 0.7854  loss_rpn_cls: 0.119  loss_rpn_loc: 0.1261  loss_cls: 0.3438  loss_box_reg: 0.2097  loss_mask: 0.6563  time: 0.5142  data_time: 0.0174  lr: 0.0012987  max_mem: 7926M
[12/13 06:18:58 d2.utils.events]:  eta: 1:21:10  iter: 539  total_loss: 2.319  loss_sem_seg: 0.7153  loss_rpn_cls: 0.1283  loss_rpn_loc: 0.1094  loss_cls: 0.3987  loss_box_reg: 0.2402  loss_mask: 0.6293  time: 0.5146  data_time: 0.0175  lr: 0.0013487  max_mem: 7926M
[12/13 06:19:09 d2.utils.events]:  eta: 1:21:00  iter: 559  total_loss: 2.371  loss_sem_seg: 0.7517  loss_rpn_cls: 0.1223  loss_rpn_loc: 0.1319  loss_cls: 0.3776  loss_box_reg: 0.2321  loss_mask: 0.6368  time: 0.5146  data_time: 0.0169  lr: 0.0013986  max_mem: 7926M
[12/13 06:19:19 d2.utils.events]:  eta: 1:20:55  iter: 579  total_loss: 2.486  loss_sem_seg: 0.8589  loss_rpn_cls: 0.1279  loss_rpn_loc: 0.1169  loss_cls: 0.3645  loss_box_reg: 0.2181  loss_mask: 0.6219  time: 0.5151  data_time: 0.0181  lr: 0.0014486  max_mem: 7926M
[12/13 06:19:30 d2.utils.events]:  eta: 1:20:46  iter: 599  total_loss: 2.459  loss_sem_seg: 0.8059  loss_rpn_cls: 0.1329  loss_rpn_loc: 0.1152  loss_cls: 0.3702  loss_box_reg: 0.2324  loss_mask: 0.622  time: 0.5154  data_time: 0.0179  lr: 0.0014985  max_mem: 7926M
[12/13 06:19:40 d2.utils.events]:  eta: 1:20:42  iter: 619  total_loss: 2.496  loss_sem_seg: 0.8481  loss_rpn_cls: 0.09336  loss_rpn_loc: 0.09859  loss_cls: 0.4409  loss_box_reg: 0.259  loss_mask: 0.6302  time: 0.5154  data_time: 0.0168  lr: 0.0015485  max_mem: 7926M
[12/13 06:19:51 d2.utils.events]:  eta: 1:20:33  iter: 639  total_loss: 2.403  loss_sem_seg: 0.7775  loss_rpn_cls: 0.1399  loss_rpn_loc: 0.1157  loss_cls: 0.4145  loss_box_reg: 0.2624  loss_mask: 0.621  time: 0.5156  data_time: 0.0182  lr: 0.0015984  max_mem: 7926M
[12/13 06:20:01 d2.utils.events]:  eta: 1:20:29  iter: 659  total_loss: 2.296  loss_sem_seg: 0.7368  loss_rpn_cls: 0.127  loss_rpn_loc: 0.1277  loss_cls: 0.3596  loss_box_reg: 0.2282  loss_mask: 0.6154  time: 0.5160  data_time: 0.0165  lr: 0.0016484  max_mem: 7926M
[12/13 06:20:12 d2.utils.events]:  eta: 1:20:19  iter: 679  total_loss: 2.133  loss_sem_seg: 0.627  loss_rpn_cls: 0.1098  loss_rpn_loc: 0.1183  loss_cls: 0.326  loss_box_reg: 0.222  loss_mask: 0.6183  time: 0.5164  data_time: 0.0167  lr: 0.0016983  max_mem: 7926M
[12/13 06:20:22 d2.utils.events]:  eta: 1:20:08  iter: 699  total_loss: 2.218  loss_sem_seg: 0.6806  loss_rpn_cls: 0.1077  loss_rpn_loc: 0.1308  loss_cls: 0.3868  loss_box_reg: 0.2546  loss_mask: 0.6103  time: 0.5164  data_time: 0.0178  lr: 0.0017483  max_mem: 7926M
[12/13 06:20:33 d2.utils.events]:  eta: 1:20:01  iter: 719  total_loss: 2.321  loss_sem_seg: 0.7164  loss_rpn_cls: 0.0919  loss_rpn_loc: 0.09251  loss_cls: 0.4733  loss_box_reg: 0.2849  loss_mask: 0.6031  time: 0.5167  data_time: 0.0170  lr: 0.0017982  max_mem: 7926M
[12/13 06:20:43 d2.utils.events]:  eta: 1:19:50  iter: 739  total_loss: 2.181  loss_sem_seg: 0.7435  loss_rpn_cls: 0.09427  loss_rpn_loc: 0.09634  loss_cls: 0.3714  loss_box_reg: 0.2275  loss_mask: 0.6101  time: 0.5167  data_time: 0.0176  lr: 0.0018482  max_mem: 7926M
[12/13 06:20:54 d2.utils.events]:  eta: 1:19:45  iter: 759  total_loss: 2.386  loss_sem_seg: 0.6967  loss_rpn_cls: 0.1032  loss_rpn_loc: 0.09032  loss_cls: 0.4692  loss_box_reg: 0.3294  loss_mask: 0.6054  time: 0.5174  data_time: 0.0234  lr: 0.0018981  max_mem: 7926M
[12/13 06:21:05 d2.utils.events]:  eta: 1:19:40  iter: 779  total_loss: 2.216  loss_sem_seg: 0.65  loss_rpn_cls: 0.1352  loss_rpn_loc: 0.1394  loss_cls: 0.3689  loss_box_reg: 0.2729  loss_mask: 0.5991  time: 0.5180  data_time: 0.0187  lr: 0.0019481  max_mem: 7926M
[12/13 06:21:15 d2.utils.events]:  eta: 1:19:33  iter: 799  total_loss: 2.363  loss_sem_seg: 0.7705  loss_rpn_cls: 0.1111  loss_rpn_loc: 0.09328  loss_cls: 0.4343  loss_box_reg: 0.2932  loss_mask: 0.6154  time: 0.5182  data_time: 0.0179  lr: 0.001998  max_mem: 7926M
[12/13 06:21:27 d2.utils.events]:  eta: 1:19:29  iter: 819  total_loss: 2.142  loss_sem_seg: 0.6811  loss_rpn_cls: 0.1033  loss_rpn_loc: 0.1236  loss_cls: 0.4396  loss_box_reg: 0.2908  loss_mask: 0.5999  time: 0.5193  data_time: 0.0193  lr: 0.002048  max_mem: 7926M
[12/13 06:21:37 d2.utils.events]:  eta: 1:19:23  iter: 839  total_loss: 2.31  loss_sem_seg: 0.7214  loss_rpn_cls: 0.114  loss_rpn_loc: 0.1343  loss_cls: 0.4018  loss_box_reg: 0.2784  loss_mask: 0.6053  time: 0.5199  data_time: 0.0207  lr: 0.0020979  max_mem: 7926M
[12/13 06:21:48 d2.utils.events]:  eta: 1:19:16  iter: 859  total_loss: 2.425  loss_sem_seg: 0.7481  loss_rpn_cls: 0.1243  loss_rpn_loc: 0.1006  loss_cls: 0.5184  loss_box_reg: 0.3309  loss_mask: 0.5829  time: 0.5206  data_time: 0.0190  lr: 0.0021479  max_mem: 7926M
[12/13 06:21:59 d2.utils.events]:  eta: 1:19:11  iter: 879  total_loss: 2.152  loss_sem_seg: 0.7489  loss_rpn_cls: 0.08757  loss_rpn_loc: 0.1061  loss_cls: 0.3994  loss_box_reg: 0.3143  loss_mask: 0.5919  time: 0.5211  data_time: 0.0215  lr: 0.0021978  max_mem: 7926M
[12/13 06:22:10 d2.utils.events]:  eta: 1:19:03  iter: 899  total_loss: 2.158  loss_sem_seg: 0.7042  loss_rpn_cls: 0.1164  loss_rpn_loc: 0.1163  loss_cls: 0.4162  loss_box_reg: 0.2637  loss_mask: 0.5679  time: 0.5218  data_time: 0.0218  lr: 0.0022478  max_mem: 7926M
[12/13 06:22:21 d2.utils.events]:  eta: 1:18:55  iter: 919  total_loss: 2.289  loss_sem_seg: 0.744  loss_rpn_cls: 0.101  loss_rpn_loc: 0.1239  loss_cls: 0.4572  loss_box_reg: 0.3047  loss_mask: 0.582  time: 0.5224  data_time: 0.0185  lr: 0.0022977  max_mem: 7926M
[12/13 06:22:32 d2.utils.events]:  eta: 1:18:44  iter: 939  total_loss: 2.154  loss_sem_seg: 0.6666  loss_rpn_cls: 0.1139  loss_rpn_loc: 0.1519  loss_cls: 0.3659  loss_box_reg: 0.2477  loss_mask: 0.5684  time: 0.5227  data_time: 0.0190  lr: 0.0023477  max_mem: 7926M
[12/13 06:22:43 d2.utils.events]:  eta: 1:18:34  iter: 959  total_loss: 2.204  loss_sem_seg: 0.6612  loss_rpn_cls: 0.09647  loss_rpn_loc: 0.1404  loss_cls: 0.388  loss_box_reg: 0.2803  loss_mask: 0.5872  time: 0.5228  data_time: 0.0185  lr: 0.0023976  max_mem: 7926M
[12/13 06:22:54 d2.utils.events]:  eta: 1:18:29  iter: 979  total_loss: 2.04  loss_sem_seg: 0.5794  loss_rpn_cls: 0.107  loss_rpn_loc: 0.1162  loss_cls: 0.3747  loss_box_reg: 0.2712  loss_mask: 0.5733  time: 0.5233  data_time: 0.0211  lr: 0.0024476  max_mem: 7926M
[12/13 06:23:05 d2.utils.events]:  eta: 1:18:22  iter: 999  total_loss: 2.383  loss_sem_seg: 0.6921  loss_rpn_cls: 0.103  loss_rpn_loc: 0.1191  loss_cls: 0.4893  loss_box_reg: 0.3345  loss_mask: 0.5959  time: 0.5239  data_time: 0.0198  lr: 0.0024975  max_mem: 7926M
[12/13 06:23:16 d2.utils.events]:  eta: 1:18:15  iter: 1019  total_loss: 2.083  loss_sem_seg: 0.6362  loss_rpn_cls: 0.0912  loss_rpn_loc: 0.1109  loss_cls: 0.4022  loss_box_reg: 0.3007  loss_mask: 0.5517  time: 0.5243  data_time: 0.0222  lr: 0.0025  max_mem: 7926M
[12/13 06:23:26 d2.utils.events]:  eta: 1:18:20  iter: 1039  total_loss: 2.187  loss_sem_seg: 0.7274  loss_rpn_cls: 0.09609  loss_rpn_loc: 0.08555  loss_cls: 0.351  loss_box_reg: 0.2764  loss_mask: 0.5373  time: 0.5246  data_time: 0.0193  lr: 0.0025  max_mem: 7926M
[12/13 06:23:37 d2.utils.events]:  eta: 1:18:18  iter: 1059  total_loss: 2.149  loss_sem_seg: 0.5893  loss_rpn_cls: 0.1314  loss_rpn_loc: 0.1442  loss_cls: 0.3929  loss_box_reg: 0.2822  loss_mask: 0.5592  time: 0.5249  data_time: 0.0187  lr: 0.0025  max_mem: 7926M
[12/13 06:23:48 d2.utils.events]:  eta: 1:18:09  iter: 1079  total_loss: 2.089  loss_sem_seg: 0.693  loss_rpn_cls: 0.08357  loss_rpn_loc: 0.08543  loss_cls: 0.413  loss_box_reg: 0.3153  loss_mask: 0.5295  time: 0.5251  data_time: 0.0202  lr: 0.0025  max_mem: 7926M
[12/13 06:23:59 d2.utils.events]:  eta: 1:18:00  iter: 1099  total_loss: 2.059  loss_sem_seg: 0.696  loss_rpn_cls: 0.08439  loss_rpn_loc: 0.07061  loss_cls: 0.3619  loss_box_reg: 0.2838  loss_mask: 0.5061  time: 0.5253  data_time: 0.0176  lr: 0.0025  max_mem: 7926M
[12/13 06:24:10 d2.utils.events]:  eta: 1:17:54  iter: 1119  total_loss: 2.123  loss_sem_seg: 0.5833  loss_rpn_cls: 0.1158  loss_rpn_loc: 0.1445  loss_cls: 0.4493  loss_box_reg: 0.3427  loss_mask: 0.5537  time: 0.5257  data_time: 0.0201  lr: 0.0025  max_mem: 7926M
[12/13 06:24:21 d2.utils.events]:  eta: 1:17:52  iter: 1139  total_loss: 2.254  loss_sem_seg: 0.6673  loss_rpn_cls: 0.09964  loss_rpn_loc: 0.1088  loss_cls: 0.4439  loss_box_reg: 0.3609  loss_mask: 0.5478  time: 0.5260  data_time: 0.0169  lr: 0.0025  max_mem: 7926M
[12/13 06:24:32 d2.utils.events]:  eta: 1:17:46  iter: 1159  total_loss: 2.127  loss_sem_seg: 0.574  loss_rpn_cls: 0.08595  loss_rpn_loc: 0.1156  loss_cls: 0.3824  loss_box_reg: 0.32  loss_mask: 0.5357  time: 0.5264  data_time: 0.0197  lr: 0.0025  max_mem: 7926M
[12/13 06:24:42 d2.utils.events]:  eta: 1:17:36  iter: 1179  total_loss: 2.043  loss_sem_seg: 0.6045  loss_rpn_cls: 0.1185  loss_rpn_loc: 0.08143  loss_cls: 0.395  loss_box_reg: 0.3103  loss_mask: 0.527  time: 0.5264  data_time: 0.0201  lr: 0.0025  max_mem: 7926M
[12/13 06:24:53 d2.utils.events]:  eta: 1:17:29  iter: 1199  total_loss: 2.124  loss_sem_seg: 0.6582  loss_rpn_cls: 0.09457  loss_rpn_loc: 0.07991  loss_cls: 0.3908  loss_box_reg: 0.2885  loss_mask: 0.5225  time: 0.5267  data_time: 0.0191  lr: 0.0025  max_mem: 7926M
[12/13 06:25:04 d2.utils.events]:  eta: 1:17:21  iter: 1219  total_loss: 2.132  loss_sem_seg: 0.5015  loss_rpn_cls: 0.08901  loss_rpn_loc: 0.1175  loss_cls: 0.4733  loss_box_reg: 0.3339  loss_mask: 0.534  time: 0.5269  data_time: 0.0178  lr: 0.0025  max_mem: 7926M
[12/13 06:25:14 d2.utils.events]:  eta: 1:17:15  iter: 1239  total_loss: 2.08  loss_sem_seg: 0.5319  loss_rpn_cls: 0.09789  loss_rpn_loc: 0.1438  loss_cls: 0.3967  loss_box_reg: 0.3107  loss_mask: 0.5253  time: 0.5269  data_time: 0.0208  lr: 0.0025  max_mem: 7926M
[12/13 06:25:25 d2.utils.events]:  eta: 1:17:03  iter: 1259  total_loss: 2.171  loss_sem_seg: 0.6844  loss_rpn_cls: 0.1033  loss_rpn_loc: 0.1006  loss_cls: 0.3988  loss_box_reg: 0.2924  loss_mask: 0.5208  time: 0.5272  data_time: 0.0188  lr: 0.0025  max_mem: 7926M
[12/13 06:25:36 d2.utils.events]:  eta: 1:16:56  iter: 1279  total_loss: 2.022  loss_sem_seg: 0.5785  loss_rpn_cls: 0.1016  loss_rpn_loc: 0.1015  loss_cls: 0.3925  loss_box_reg: 0.322  loss_mask: 0.5063  time: 0.5275  data_time: 0.0194  lr: 0.0025  max_mem: 7926M
[12/13 06:25:47 d2.utils.events]:  eta: 1:16:56  iter: 1299  total_loss: 2.163  loss_sem_seg: 0.664  loss_rpn_cls: 0.1096  loss_rpn_loc: 0.1192  loss_cls: 0.3915  loss_box_reg: 0.3334  loss_mask: 0.5105  time: 0.5278  data_time: 0.0166  lr: 0.0025  max_mem: 7926M
[12/13 06:25:58 d2.utils.events]:  eta: 1:16:52  iter: 1319  total_loss: 2.083  loss_sem_seg: 0.5901  loss_rpn_cls: 0.1128  loss_rpn_loc: 0.1146  loss_cls: 0.3883  loss_box_reg: 0.3351  loss_mask: 0.5212  time: 0.5282  data_time: 0.0177  lr: 0.0025  max_mem: 7926M
[12/13 06:26:09 d2.utils.events]:  eta: 1:16:45  iter: 1339  total_loss: 2.025  loss_sem_seg: 0.6114  loss_rpn_cls: 0.09019  loss_rpn_loc: 0.1041  loss_cls: 0.3436  loss_box_reg: 0.2854  loss_mask: 0.5245  time: 0.5282  data_time: 0.0166  lr: 0.0025  max_mem: 7926M
[12/13 06:26:19 d2.utils.events]:  eta: 1:16:39  iter: 1359  total_loss: 2.071  loss_sem_seg: 0.6578  loss_rpn_cls: 0.1076  loss_rpn_loc: 0.09825  loss_cls: 0.3495  loss_box_reg: 0.2719  loss_mask: 0.5089  time: 0.5282  data_time: 0.0194  lr: 0.0025  max_mem: 7926M
[12/13 06:26:30 d2.utils.events]:  eta: 1:16:30  iter: 1379  total_loss: 2.006  loss_sem_seg: 0.6687  loss_rpn_cls: 0.08311  loss_rpn_loc: 0.09248  loss_cls: 0.3648  loss_box_reg: 0.2912  loss_mask: 0.4967  time: 0.5283  data_time: 0.0168  lr: 0.0025  max_mem: 7926M
[12/13 06:26:41 d2.utils.events]:  eta: 1:16:26  iter: 1399  total_loss: 1.921  loss_sem_seg: 0.6138  loss_rpn_cls: 0.09089  loss_rpn_loc: 0.1087  loss_cls: 0.3534  loss_box_reg: 0.3075  loss_mask: 0.5052  time: 0.5285  data_time: 0.0173  lr: 0.0025  max_mem: 7926M
[12/13 06:26:52 d2.utils.events]:  eta: 1:16:16  iter: 1419  total_loss: 2.03  loss_sem_seg: 0.5765  loss_rpn_cls: 0.09235  loss_rpn_loc: 0.1014  loss_cls: 0.3935  loss_box_reg: 0.3078  loss_mask: 0.4862  time: 0.5285  data_time: 0.0163  lr: 0.0025  max_mem: 7926M
[12/13 06:27:02 d2.utils.events]:  eta: 1:16:12  iter: 1439  total_loss: 1.956  loss_sem_seg: 0.5668  loss_rpn_cls: 0.08427  loss_rpn_loc: 0.1117  loss_cls: 0.3862  loss_box_reg: 0.3267  loss_mask: 0.4845  time: 0.5287  data_time: 0.0215  lr: 0.0025  max_mem: 7926M
[12/13 06:27:13 d2.utils.events]:  eta: 1:16:01  iter: 1459  total_loss: 2.105  loss_sem_seg: 0.662  loss_rpn_cls: 0.09698  loss_rpn_loc: 0.09153  loss_cls: 0.3533  loss_box_reg: 0.2973  loss_mask: 0.5189  time: 0.5288  data_time: 0.0178  lr: 0.0025  max_mem: 7926M
[12/13 06:27:24 d2.utils.events]:  eta: 1:15:52  iter: 1479  total_loss: 2.052  loss_sem_seg: 0.621  loss_rpn_cls: 0.08587  loss_rpn_loc: 0.1208  loss_cls: 0.4142  loss_box_reg: 0.3364  loss_mask: 0.487  time: 0.5289  data_time: 0.0208  lr: 0.0025  max_mem: 7926M
[12/13 06:27:35 d2.utils.events]:  eta: 1:15:42  iter: 1499  total_loss: 2.104  loss_sem_seg: 0.5103  loss_rpn_cls: 0.0881  loss_rpn_loc: 0.112  loss_cls: 0.4368  loss_box_reg: 0.3693  loss_mask: 0.4756  time: 0.5291  data_time: 0.0197  lr: 0.0025  max_mem: 7926M
[12/13 06:27:45 d2.utils.events]:  eta: 1:15:31  iter: 1519  total_loss: 2.162  loss_sem_seg: 0.6595  loss_rpn_cls: 0.09594  loss_rpn_loc: 0.08474  loss_cls: 0.4203  loss_box_reg: 0.3002  loss_mask: 0.4664  time: 0.5291  data_time: 0.0172  lr: 0.0025  max_mem: 7926M
[12/13 06:27:56 d2.utils.events]:  eta: 1:15:25  iter: 1539  total_loss: 2.223  loss_sem_seg: 0.6246  loss_rpn_cls: 0.08096  loss_rpn_loc: 0.09948  loss_cls: 0.4128  loss_box_reg: 0.3529  loss_mask: 0.4876  time: 0.5292  data_time: 0.0163  lr: 0.0025  max_mem: 7926M
[12/13 06:28:07 d2.utils.events]:  eta: 1:15:16  iter: 1559  total_loss: 2.202  loss_sem_seg: 0.5959  loss_rpn_cls: 0.09717  loss_rpn_loc: 0.1277  loss_cls: 0.4197  loss_box_reg: 0.3394  loss_mask: 0.4898  time: 0.5292  data_time: 0.0176  lr: 0.0025  max_mem: 7926M
[12/13 06:28:18 d2.utils.events]:  eta: 1:15:08  iter: 1579  total_loss: 2.145  loss_sem_seg: 0.5966  loss_rpn_cls: 0.0905  loss_rpn_loc: 0.09839  loss_cls: 0.4028  loss_box_reg: 0.34  loss_mask: 0.5077  time: 0.5293  data_time: 0.0191  lr: 0.0025  max_mem: 7926M
[12/13 06:28:28 d2.utils.events]:  eta: 1:14:59  iter: 1599  total_loss: 2.017  loss_sem_seg: 0.6676  loss_rpn_cls: 0.1017  loss_rpn_loc: 0.1101  loss_cls: 0.3558  loss_box_reg: 0.2851  loss_mask: 0.4831  time: 0.5293  data_time: 0.0208  lr: 0.0025  max_mem: 7926M
[12/13 06:28:39 d2.utils.events]:  eta: 1:14:55  iter: 1619  total_loss: 2.188  loss_sem_seg: 0.6564  loss_rpn_cls: 0.0966  loss_rpn_loc: 0.1094  loss_cls: 0.4527  loss_box_reg: 0.3401  loss_mask: 0.4847  time: 0.5294  data_time: 0.0171  lr: 0.0025  max_mem: 7926M
[12/13 06:28:50 d2.utils.events]:  eta: 1:14:45  iter: 1639  total_loss: 2.076  loss_sem_seg: 0.6419  loss_rpn_cls: 0.07676  loss_rpn_loc: 0.09248  loss_cls: 0.4083  loss_box_reg: 0.3159  loss_mask: 0.4969  time: 0.5296  data_time: 0.0178  lr: 0.0025  max_mem: 7926M
[12/13 06:29:01 d2.utils.events]:  eta: 1:14:37  iter: 1659  total_loss: 2.154  loss_sem_seg: 0.7604  loss_rpn_cls: 0.09249  loss_rpn_loc: 0.1108  loss_cls: 0.379  loss_box_reg: 0.3029  loss_mask: 0.4781  time: 0.5298  data_time: 0.0173  lr: 0.0025  max_mem: 7926M
[12/13 06:29:11 d2.utils.events]:  eta: 1:14:27  iter: 1679  total_loss: 1.847  loss_sem_seg: 0.5669  loss_rpn_cls: 0.08523  loss_rpn_loc: 0.08138  loss_cls: 0.3137  loss_box_reg: 0.2433  loss_mask: 0.4684  time: 0.5298  data_time: 0.0173  lr: 0.0025  max_mem: 7926M
[12/13 06:29:22 d2.utils.events]:  eta: 1:14:24  iter: 1699  total_loss: 1.92  loss_sem_seg: 0.6234  loss_rpn_cls: 0.0957  loss_rpn_loc: 0.109  loss_cls: 0.4061  loss_box_reg: 0.3236  loss_mask: 0.4991  time: 0.5299  data_time: 0.0185  lr: 0.0025  max_mem: 7926M
[12/13 06:29:33 d2.utils.events]:  eta: 1:14:14  iter: 1719  total_loss: 1.974  loss_sem_seg: 0.5602  loss_rpn_cls: 0.1022  loss_rpn_loc: 0.1112  loss_cls: 0.3808  loss_box_reg: 0.3337  loss_mask: 0.4851  time: 0.5300  data_time: 0.0200  lr: 0.0025  max_mem: 7926M
[12/13 06:29:44 d2.utils.events]:  eta: 1:14:08  iter: 1739  total_loss: 2.028  loss_sem_seg: 0.6575  loss_rpn_cls: 0.08741  loss_rpn_loc: 0.1315  loss_cls: 0.4089  loss_box_reg: 0.3383  loss_mask: 0.4882  time: 0.5302  data_time: 0.0175  lr: 0.0025  max_mem: 7926M
[12/13 06:29:55 d2.utils.events]:  eta: 1:14:01  iter: 1759  total_loss: 2.04  loss_sem_seg: 0.5676  loss_rpn_cls: 0.1037  loss_rpn_loc: 0.0951  loss_cls: 0.3957  loss_box_reg: 0.3114  loss_mask: 0.4698  time: 0.5304  data_time: 0.0174  lr: 0.0025  max_mem: 7926M
[12/13 06:30:06 d2.utils.events]:  eta: 1:13:51  iter: 1779  total_loss: 2.001  loss_sem_seg: 0.5183  loss_rpn_cls: 0.09669  loss_rpn_loc: 0.1528  loss_cls: 0.3598  loss_box_reg: 0.3286  loss_mask: 0.4789  time: 0.5305  data_time: 0.0165  lr: 0.0025  max_mem: 7926M
[12/13 06:30:17 d2.utils.events]:  eta: 1:13:44  iter: 1799  total_loss: 1.982  loss_sem_seg: 0.5457  loss_rpn_cls: 0.1096  loss_rpn_loc: 0.118  loss_cls: 0.3263  loss_box_reg: 0.2995  loss_mask: 0.485  time: 0.5307  data_time: 0.0217  lr: 0.0025  max_mem: 7926M
[12/13 06:30:28 d2.utils.events]:  eta: 1:13:33  iter: 1819  total_loss: 2.006  loss_sem_seg: 0.5093  loss_rpn_cls: 0.07627  loss_rpn_loc: 0.08682  loss_cls: 0.3737  loss_box_reg: 0.333  loss_mask: 0.4694  time: 0.5310  data_time: 0.0173  lr: 0.0025  max_mem: 7926M
[12/13 06:30:39 d2.utils.events]:  eta: 1:13:24  iter: 1839  total_loss: 1.794  loss_sem_seg: 0.5629  loss_rpn_cls: 0.07504  loss_rpn_loc: 0.05676  loss_cls: 0.3349  loss_box_reg: 0.3125  loss_mask: 0.4522  time: 0.5311  data_time: 0.0204  lr: 0.0025  max_mem: 7926M
[12/13 06:30:50 d2.utils.events]:  eta: 1:13:14  iter: 1859  total_loss: 1.961  loss_sem_seg: 0.5692  loss_rpn_cls: 0.07513  loss_rpn_loc: 0.1043  loss_cls: 0.3869  loss_box_reg: 0.3114  loss_mask: 0.4698  time: 0.5314  data_time: 0.0192  lr: 0.0025  max_mem: 7926M
[12/13 06:31:01 d2.utils.events]:  eta: 1:13:08  iter: 1879  total_loss: 1.746  loss_sem_seg: 0.4136  loss_rpn_cls: 0.05677  loss_rpn_loc: 0.09287  loss_cls: 0.3679  loss_box_reg: 0.3272  loss_mask: 0.4557  time: 0.5317  data_time: 0.0239  lr: 0.0025  max_mem: 7926M
[12/13 06:31:12 d2.utils.events]:  eta: 1:12:57  iter: 1899  total_loss: 1.971  loss_sem_seg: 0.4966  loss_rpn_cls: 0.1174  loss_rpn_loc: 0.1228  loss_cls: 0.3475  loss_box_reg: 0.2849  loss_mask: 0.4727  time: 0.5319  data_time: 0.0204  lr: 0.0025  max_mem: 7926M
[12/13 06:31:23 d2.utils.events]:  eta: 1:12:42  iter: 1919  total_loss: 1.9  loss_sem_seg: 0.632  loss_rpn_cls: 0.09274  loss_rpn_loc: 0.1009  loss_cls: 0.3342  loss_box_reg: 0.2804  loss_mask: 0.4255  time: 0.5319  data_time: 0.0183  lr: 0.0025  max_mem: 7926M
[12/13 06:31:34 d2.utils.events]:  eta: 1:12:35  iter: 1939  total_loss: 2.08  loss_sem_seg: 0.5144  loss_rpn_cls: 0.12  loss_rpn_loc: 0.1669  loss_cls: 0.3905  loss_box_reg: 0.3413  loss_mask: 0.4891  time: 0.5320  data_time: 0.0185  lr: 0.0025  max_mem: 7926M
[12/13 06:31:45 d2.utils.events]:  eta: 1:12:31  iter: 1959  total_loss: 2.068  loss_sem_seg: 0.5401  loss_rpn_cls: 0.06804  loss_rpn_loc: 0.08819  loss_cls: 0.4278  loss_box_reg: 0.3586  loss_mask: 0.4892  time: 0.5322  data_time: 0.0180  lr: 0.0025  max_mem: 7926M
[12/13 06:31:55 d2.utils.events]:  eta: 1:12:22  iter: 1979  total_loss: 1.999  loss_sem_seg: 0.5701  loss_rpn_cls: 0.09952  loss_rpn_loc: 0.1226  loss_cls: 0.4228  loss_box_reg: 0.3715  loss_mask: 0.4511  time: 0.5323  data_time: 0.0218  lr: 0.0025  max_mem: 7926M
[12/13 06:32:06 d2.utils.events]:  eta: 1:12:08  iter: 1999  total_loss: 2.117  loss_sem_seg: 0.5875  loss_rpn_cls: 0.09747  loss_rpn_loc: 0.09763  loss_cls: 0.3917  loss_box_reg: 0.3521  loss_mask: 0.4614  time: 0.5325  data_time: 0.0186  lr: 0.0025  max_mem: 7926M
[12/13 06:32:17 d2.utils.events]:  eta: 1:11:57  iter: 2019  total_loss: 1.976  loss_sem_seg: 0.5257  loss_rpn_cls: 0.07925  loss_rpn_loc: 0.09273  loss_cls: 0.3634  loss_box_reg: 0.3265  loss_mask: 0.4506  time: 0.5325  data_time: 0.0195  lr: 0.0025  max_mem: 7926M
[12/13 06:32:28 d2.utils.events]:  eta: 1:11:46  iter: 2039  total_loss: 1.771  loss_sem_seg: 0.5715  loss_rpn_cls: 0.07281  loss_rpn_loc: 0.09528  loss_cls: 0.3787  loss_box_reg: 0.3225  loss_mask: 0.4445  time: 0.5326  data_time: 0.0182  lr: 0.0025  max_mem: 7926M
[12/13 06:32:39 d2.utils.events]:  eta: 1:11:33  iter: 2059  total_loss: 1.987  loss_sem_seg: 0.647  loss_rpn_cls: 0.06838  loss_rpn_loc: 0.08578  loss_cls: 0.3657  loss_box_reg: 0.3035  loss_mask: 0.4646  time: 0.5327  data_time: 0.0181  lr: 0.0025  max_mem: 7926M
[12/13 06:32:50 d2.utils.events]:  eta: 1:11:26  iter: 2079  total_loss: 1.788  loss_sem_seg: 0.568  loss_rpn_cls: 0.0606  loss_rpn_loc: 0.07147  loss_cls: 0.3177  loss_box_reg: 0.2849  loss_mask: 0.4568  time: 0.5329  data_time: 0.0207  lr: 0.0025  max_mem: 7926M
[12/13 06:33:01 d2.utils.events]:  eta: 1:11:18  iter: 2099  total_loss: 2.001  loss_sem_seg: 0.4894  loss_rpn_cls: 0.09151  loss_rpn_loc: 0.125  loss_cls: 0.4043  loss_box_reg: 0.37  loss_mask: 0.455  time: 0.5331  data_time: 0.0182  lr: 0.0025  max_mem: 7926M
[12/13 06:33:12 d2.utils.events]:  eta: 1:11:07  iter: 2119  total_loss: 1.911  loss_sem_seg: 0.5026  loss_rpn_cls: 0.09138  loss_rpn_loc: 0.1267  loss_cls: 0.4056  loss_box_reg: 0.3325  loss_mask: 0.4568  time: 0.5333  data_time: 0.0206  lr: 0.0025  max_mem: 7926M
[12/13 06:33:23 d2.utils.events]:  eta: 1:10:56  iter: 2139  total_loss: 2.102  loss_sem_seg: 0.6561  loss_rpn_cls: 0.08182  loss_rpn_loc: 0.1245  loss_cls: 0.3542  loss_box_reg: 0.3244  loss_mask: 0.4617  time: 0.5333  data_time: 0.0174  lr: 0.0025  max_mem: 7926M
[12/13 06:33:34 d2.utils.events]:  eta: 1:10:46  iter: 2159  total_loss: 1.926  loss_sem_seg: 0.578  loss_rpn_cls: 0.07738  loss_rpn_loc: 0.1164  loss_cls: 0.3472  loss_box_reg: 0.3051  loss_mask: 0.4942  time: 0.5335  data_time: 0.0197  lr: 0.0025  max_mem: 7926M
[12/13 06:33:45 d2.utils.events]:  eta: 1:10:37  iter: 2179  total_loss: 1.9  loss_sem_seg: 0.5107  loss_rpn_cls: 0.08564  loss_rpn_loc: 0.1138  loss_cls: 0.3364  loss_box_reg: 0.3136  loss_mask: 0.4589  time: 0.5336  data_time: 0.0194  lr: 0.0025  max_mem: 7926M
[12/13 06:33:56 d2.utils.events]:  eta: 1:10:26  iter: 2199  total_loss: 1.86  loss_sem_seg: 0.6099  loss_rpn_cls: 0.0929  loss_rpn_loc: 0.09875  loss_cls: 0.3469  loss_box_reg: 0.3026  loss_mask: 0.4417  time: 0.5337  data_time: 0.0181  lr: 0.0025  max_mem: 7926M
[12/13 06:34:07 d2.utils.events]:  eta: 1:10:16  iter: 2219  total_loss: 1.996  loss_sem_seg: 0.5166  loss_rpn_cls: 0.06705  loss_rpn_loc: 0.1187  loss_cls: 0.3994  loss_box_reg: 0.3599  loss_mask: 0.4532  time: 0.5337  data_time: 0.0172  lr: 0.0025  max_mem: 7926M
[12/13 06:34:17 d2.utils.events]:  eta: 1:10:05  iter: 2239  total_loss: 1.87  loss_sem_seg: 0.5984  loss_rpn_cls: 0.08359  loss_rpn_loc: 0.0819  loss_cls: 0.345  loss_box_reg: 0.3362  loss_mask: 0.4382  time: 0.5338  data_time: 0.0198  lr: 0.0025  max_mem: 7926M
[12/13 06:34:28 d2.utils.events]:  eta: 1:09:55  iter: 2259  total_loss: 2.08  loss_sem_seg: 0.5867  loss_rpn_cls: 0.1046  loss_rpn_loc: 0.1166  loss_cls: 0.398  loss_box_reg: 0.3327  loss_mask: 0.4824  time: 0.5339  data_time: 0.0176  lr: 0.0025  max_mem: 7926M
[12/13 06:34:39 d2.utils.events]:  eta: 1:09:43  iter: 2279  total_loss: 1.972  loss_sem_seg: 0.5211  loss_rpn_cls: 0.07296  loss_rpn_loc: 0.09122  loss_cls: 0.3852  loss_box_reg: 0.3065  loss_mask: 0.4509  time: 0.5340  data_time: 0.0171  lr: 0.0025  max_mem: 7926M
[12/13 06:34:50 d2.utils.events]:  eta: 1:09:33  iter: 2299  total_loss: 1.736  loss_sem_seg: 0.4763  loss_rpn_cls: 0.07888  loss_rpn_loc: 0.1102  loss_cls: 0.3377  loss_box_reg: 0.2832  loss_mask: 0.4386  time: 0.5341  data_time: 0.0174  lr: 0.0025  max_mem: 7926M
[12/13 06:35:01 d2.utils.events]:  eta: 1:09:23  iter: 2319  total_loss: 1.812  loss_sem_seg: 0.5651  loss_rpn_cls: 0.08034  loss_rpn_loc: 0.07778  loss_cls: 0.2863  loss_box_reg: 0.2725  loss_mask: 0.4671  time: 0.5342  data_time: 0.0195  lr: 0.0025  max_mem: 7926M
[12/13 06:35:12 d2.utils.events]:  eta: 1:09:15  iter: 2339  total_loss: 1.962  loss_sem_seg: 0.5181  loss_rpn_cls: 0.08906  loss_rpn_loc: 0.1028  loss_cls: 0.3555  loss_box_reg: 0.3533  loss_mask: 0.455  time: 0.5343  data_time: 0.0203  lr: 0.0025  max_mem: 7926M
[12/13 06:35:23 d2.utils.events]:  eta: 1:09:04  iter: 2359  total_loss: 1.96  loss_sem_seg: 0.5326  loss_rpn_cls: 0.09434  loss_rpn_loc: 0.144  loss_cls: 0.3445  loss_box_reg: 0.3338  loss_mask: 0.4582  time: 0.5344  data_time: 0.0198  lr: 0.0025  max_mem: 7926M
[12/13 06:35:34 d2.utils.events]:  eta: 1:08:55  iter: 2379  total_loss: 1.776  loss_sem_seg: 0.4959  loss_rpn_cls: 0.07018  loss_rpn_loc: 0.09905  loss_cls: 0.3188  loss_box_reg: 0.3074  loss_mask: 0.4366  time: 0.5345  data_time: 0.0183  lr: 0.0025  max_mem: 7926M
[12/13 06:35:45 d2.utils.events]:  eta: 1:08:44  iter: 2399  total_loss: 2.104  loss_sem_seg: 0.5813  loss_rpn_cls: 0.09715  loss_rpn_loc: 0.1369  loss_cls: 0.4539  loss_box_reg: 0.3814  loss_mask: 0.473  time: 0.5346  data_time: 0.0186  lr: 0.0025  max_mem: 7926M
[12/13 06:35:56 d2.utils.events]:  eta: 1:08:40  iter: 2419  total_loss: 1.749  loss_sem_seg: 0.4755  loss_rpn_cls: 0.07608  loss_rpn_loc: 0.1047  loss_cls: 0.333  loss_box_reg: 0.3165  loss_mask: 0.4481  time: 0.5348  data_time: 0.0208  lr: 0.0025  max_mem: 7926M
[12/13 06:36:07 d2.utils.events]:  eta: 1:08:28  iter: 2439  total_loss: 1.795  loss_sem_seg: 0.4651  loss_rpn_cls: 0.08622  loss_rpn_loc: 0.115  loss_cls: 0.3376  loss_box_reg: 0.3015  loss_mask: 0.4697  time: 0.5348  data_time: 0.0188  lr: 0.0025  max_mem: 7926M
[12/13 06:36:18 d2.utils.events]:  eta: 1:08:18  iter: 2459  total_loss: 1.891  loss_sem_seg: 0.5355  loss_rpn_cls: 0.07877  loss_rpn_loc: 0.09555  loss_cls: 0.363  loss_box_reg: 0.3325  loss_mask: 0.4411  time: 0.5349  data_time: 0.0191  lr: 0.0025  max_mem: 7926M
[12/13 06:36:28 d2.utils.events]:  eta: 1:08:05  iter: 2479  total_loss: 1.946  loss_sem_seg: 0.5308  loss_rpn_cls: 0.07898  loss_rpn_loc: 0.08527  loss_cls: 0.3976  loss_box_reg: 0.3563  loss_mask: 0.4519  time: 0.5349  data_time: 0.0174  lr: 0.0025  max_mem: 7926M
[12/13 06:36:39 d2.utils.events]:  eta: 1:07:53  iter: 2499  total_loss: 1.796  loss_sem_seg: 0.5041  loss_rpn_cls: 0.07035  loss_rpn_loc: 0.08826  loss_cls: 0.3684  loss_box_reg: 0.339  loss_mask: 0.4497  time: 0.5349  data_time: 0.0213  lr: 0.0025  max_mem: 7926M
[12/13 06:36:50 d2.utils.events]:  eta: 1:07:47  iter: 2519  total_loss: 1.939  loss_sem_seg: 0.4645  loss_rpn_cls: 0.08974  loss_rpn_loc: 0.1173  loss_cls: 0.3874  loss_box_reg: 0.3672  loss_mask: 0.4517  time: 0.5351  data_time: 0.0181  lr: 0.0025  max_mem: 7926M
[12/13 06:37:01 d2.utils.events]:  eta: 1:07:37  iter: 2539  total_loss: 1.9  loss_sem_seg: 0.4985  loss_rpn_cls: 0.09135  loss_rpn_loc: 0.09616  loss_cls: 0.3402  loss_box_reg: 0.2616  loss_mask: 0.4545  time: 0.5352  data_time: 0.0170  lr: 0.0025  max_mem: 7926M
[12/13 06:37:12 d2.utils.events]:  eta: 1:07:28  iter: 2559  total_loss: 1.851  loss_sem_seg: 0.5004  loss_rpn_cls: 0.07773  loss_rpn_loc: 0.08973  loss_cls: 0.3439  loss_box_reg: 0.3136  loss_mask: 0.4363  time: 0.5351  data_time: 0.0169  lr: 0.0025  max_mem: 7926M
[12/13 06:37:23 d2.utils.events]:  eta: 1:07:19  iter: 2579  total_loss: 1.977  loss_sem_seg: 0.4543  loss_rpn_cls: 0.08216  loss_rpn_loc: 0.1273  loss_cls: 0.3854  loss_box_reg: 0.395  loss_mask: 0.4717  time: 0.5354  data_time: 0.0196  lr: 0.0025  max_mem: 7926M
[12/13 06:37:34 d2.utils.events]:  eta: 1:07:10  iter: 2599  total_loss: 1.862  loss_sem_seg: 0.5771  loss_rpn_cls: 0.08248  loss_rpn_loc: 0.07989  loss_cls: 0.3241  loss_box_reg: 0.3258  loss_mask: 0.4465  time: 0.5354  data_time: 0.0172  lr: 0.0025  max_mem: 7926M
[12/13 06:37:45 d2.utils.events]:  eta: 1:07:00  iter: 2619  total_loss: 1.934  loss_sem_seg: 0.4803  loss_rpn_cls: 0.1076  loss_rpn_loc: 0.1526  loss_cls: 0.3351  loss_box_reg: 0.2843  loss_mask: 0.4528  time: 0.5354  data_time: 0.0173  lr: 0.0025  max_mem: 7926M
[12/13 06:37:56 d2.utils.events]:  eta: 1:06:48  iter: 2639  total_loss: 1.816  loss_sem_seg: 0.4757  loss_rpn_cls: 0.08874  loss_rpn_loc: 0.1368  loss_cls: 0.3374  loss_box_reg: 0.3151  loss_mask: 0.4358  time: 0.5354  data_time: 0.0184  lr: 0.0025  max_mem: 7926M
[12/13 06:38:06 d2.utils.events]:  eta: 1:06:35  iter: 2659  total_loss: 1.827  loss_sem_seg: 0.5943  loss_rpn_cls: 0.07547  loss_rpn_loc: 0.09838  loss_cls: 0.3162  loss_box_reg: 0.2883  loss_mask: 0.4456  time: 0.5354  data_time: 0.0171  lr: 0.0025  max_mem: 7926M
[12/13 06:38:17 d2.utils.events]:  eta: 1:06:26  iter: 2679  total_loss: 1.99  loss_sem_seg: 0.559  loss_rpn_cls: 0.07901  loss_rpn_loc: 0.1021  loss_cls: 0.3756  loss_box_reg: 0.3536  loss_mask: 0.4734  time: 0.5354  data_time: 0.0191  lr: 0.0025  max_mem: 7926M
[12/13 06:38:28 d2.utils.events]:  eta: 1:06:13  iter: 2699  total_loss: 1.782  loss_sem_seg: 0.513  loss_rpn_cls: 0.09275  loss_rpn_loc: 0.1329  loss_cls: 0.3241  loss_box_reg: 0.3073  loss_mask: 0.4437  time: 0.5354  data_time: 0.0172  lr: 0.0025  max_mem: 7926M
[12/13 06:38:38 d2.utils.events]:  eta: 1:06:05  iter: 2719  total_loss: 1.859  loss_sem_seg: 0.5565  loss_rpn_cls: 0.09089  loss_rpn_loc: 0.09141  loss_cls: 0.3332  loss_box_reg: 0.3201  loss_mask: 0.4295  time: 0.5354  data_time: 0.0163  lr: 0.0025  max_mem: 7926M
[12/13 06:38:49 d2.utils.events]:  eta: 1:05:55  iter: 2739  total_loss: 1.869  loss_sem_seg: 0.5597  loss_rpn_cls: 0.08232  loss_rpn_loc: 0.09362  loss_cls: 0.3316  loss_box_reg: 0.3479  loss_mask: 0.4548  time: 0.5355  data_time: 0.0196  lr: 0.0025  max_mem: 7926M
[12/13 06:39:00 d2.utils.events]:  eta: 1:05:42  iter: 2759  total_loss: 1.936  loss_sem_seg: 0.6208  loss_rpn_cls: 0.08772  loss_rpn_loc: 0.08533  loss_cls: 0.3929  loss_box_reg: 0.3242  loss_mask: 0.4523  time: 0.5355  data_time: 0.0160  lr: 0.0025  max_mem: 7926M
[12/13 06:39:11 d2.utils.events]:  eta: 1:05:32  iter: 2779  total_loss: 1.936  loss_sem_seg: 0.5347  loss_rpn_cls: 0.08463  loss_rpn_loc: 0.1261  loss_cls: 0.3811  loss_box_reg: 0.362  loss_mask: 0.4459  time: 0.5356  data_time: 0.0210  lr: 0.0025  max_mem: 7926M
[12/13 06:39:22 d2.utils.events]:  eta: 1:05:20  iter: 2799  total_loss: 1.941  loss_sem_seg: 0.5293  loss_rpn_cls: 0.1059  loss_rpn_loc: 0.1189  loss_cls: 0.3842  loss_box_reg: 0.3426  loss_mask: 0.4411  time: 0.5357  data_time: 0.0181  lr: 0.0025  max_mem: 7926M
[12/13 06:39:33 d2.utils.events]:  eta: 1:05:07  iter: 2819  total_loss: 1.952  loss_sem_seg: 0.3815  loss_rpn_cls: 0.07681  loss_rpn_loc: 0.08913  loss_cls: 0.3311  loss_box_reg: 0.3545  loss_mask: 0.4384  time: 0.5358  data_time: 0.0173  lr: 0.0025  max_mem: 7926M
[12/13 06:39:44 d2.utils.events]:  eta: 1:04:57  iter: 2839  total_loss: 2.021  loss_sem_seg: 0.5824  loss_rpn_cls: 0.08401  loss_rpn_loc: 0.1264  loss_cls: 0.3744  loss_box_reg: 0.4063  loss_mask: 0.4533  time: 0.5359  data_time: 0.0197  lr: 0.0025  max_mem: 7926M
[12/13 06:39:55 d2.utils.events]:  eta: 1:04:43  iter: 2859  total_loss: 1.888  loss_sem_seg: 0.5198  loss_rpn_cls: 0.07396  loss_rpn_loc: 0.1146  loss_cls: 0.3161  loss_box_reg: 0.3299  loss_mask: 0.4464  time: 0.5358  data_time: 0.0181  lr: 0.0025  max_mem: 7926M
[12/13 06:40:05 d2.utils.events]:  eta: 1:04:26  iter: 2879  total_loss: 1.78  loss_sem_seg: 0.552  loss_rpn_cls: 0.0702  loss_rpn_loc: 0.0778  loss_cls: 0.2889  loss_box_reg: 0.2737  loss_mask: 0.4454  time: 0.5359  data_time: 0.0178  lr: 0.0025  max_mem: 7926M
[12/13 06:40:16 d2.utils.events]:  eta: 1:04:14  iter: 2899  total_loss: 1.888  loss_sem_seg: 0.5354  loss_rpn_cls: 0.0674  loss_rpn_loc: 0.09693  loss_cls: 0.3407  loss_box_reg: 0.3046  loss_mask: 0.4409  time: 0.5359  data_time: 0.0182  lr: 0.0025  max_mem: 7926M
[12/13 06:40:27 d2.utils.events]:  eta: 1:04:05  iter: 2919  total_loss: 1.992  loss_sem_seg: 0.4667  loss_rpn_cls: 0.08963  loss_rpn_loc: 0.1265  loss_cls: 0.4029  loss_box_reg: 0.3887  loss_mask: 0.4923  time: 0.5360  data_time: 0.0198  lr: 0.0025  max_mem: 7926M
[12/13 06:40:38 d2.utils.events]:  eta: 1:03:52  iter: 2939  total_loss: 1.793  loss_sem_seg: 0.4932  loss_rpn_cls: 0.07499  loss_rpn_loc: 0.0836  loss_cls: 0.3597  loss_box_reg: 0.2969  loss_mask: 0.4485  time: 0.5360  data_time: 0.0173  lr: 0.0025  max_mem: 7926M
[12/13 06:40:49 d2.utils.events]:  eta: 1:03:38  iter: 2959  total_loss: 2.011  loss_sem_seg: 0.582  loss_rpn_cls: 0.08889  loss_rpn_loc: 0.1283  loss_cls: 0.3754  loss_box_reg: 0.3153  loss_mask: 0.4395  time: 0.5360  data_time: 0.0164  lr: 0.0025  max_mem: 7926M
[12/13 06:41:00 d2.utils.events]:  eta: 1:03:27  iter: 2979  total_loss: 1.92  loss_sem_seg: 0.4806  loss_rpn_cls: 0.08778  loss_rpn_loc: 0.1472  loss_cls: 0.3586  loss_box_reg: 0.3673  loss_mask: 0.4442  time: 0.5360  data_time: 0.0178  lr: 0.0025  max_mem: 7926M
[12/13 06:41:10 d2.utils.events]:  eta: 1:03:16  iter: 2999  total_loss: 1.872  loss_sem_seg: 0.5465  loss_rpn_cls: 0.07975  loss_rpn_loc: 0.1025  loss_cls: 0.3215  loss_box_reg: 0.3083  loss_mask: 0.4264  time: 0.5360  data_time: 0.0170  lr: 0.0025  max_mem: 7926M
[12/13 06:41:21 d2.utils.events]:  eta: 1:03:06  iter: 3019  total_loss: 1.883  loss_sem_seg: 0.5182  loss_rpn_cls: 0.09363  loss_rpn_loc: 0.0792  loss_cls: 0.3558  loss_box_reg: 0.3416  loss_mask: 0.443  time: 0.5360  data_time: 0.0187  lr: 0.0025  max_mem: 7926M
[12/13 06:41:32 d2.utils.events]:  eta: 1:02:54  iter: 3039  total_loss: 1.861  loss_sem_seg: 0.4388  loss_rpn_cls: 0.08241  loss_rpn_loc: 0.1085  loss_cls: 0.3621  loss_box_reg: 0.3212  loss_mask: 0.448  time: 0.5360  data_time: 0.0178  lr: 0.0025  max_mem: 7926M
[12/13 06:41:43 d2.utils.events]:  eta: 1:02:47  iter: 3059  total_loss: 1.923  loss_sem_seg: 0.5901  loss_rpn_cls: 0.07236  loss_rpn_loc: 0.08045  loss_cls: 0.3572  loss_box_reg: 0.3551  loss_mask: 0.4384  time: 0.5362  data_time: 0.0194  lr: 0.0025  max_mem: 7926M
[12/13 06:41:54 d2.utils.events]:  eta: 1:02:36  iter: 3079  total_loss: 1.787  loss_sem_seg: 0.4936  loss_rpn_cls: 0.07616  loss_rpn_loc: 0.1288  loss_cls: 0.3556  loss_box_reg: 0.355  loss_mask: 0.4415  time: 0.5362  data_time: 0.0195  lr: 0.0025  max_mem: 7926M
[12/13 06:42:05 d2.utils.events]:  eta: 1:02:23  iter: 3099  total_loss: 1.769  loss_sem_seg: 0.5085  loss_rpn_cls: 0.07729  loss_rpn_loc: 0.1018  loss_cls: 0.3246  loss_box_reg: 0.2837  loss_mask: 0.408  time: 0.5362  data_time: 0.0178  lr: 0.0025  max_mem: 7926M
[12/13 06:42:15 d2.utils.events]:  eta: 1:02:11  iter: 3119  total_loss: 1.852  loss_sem_seg: 0.5502  loss_rpn_cls: 0.08045  loss_rpn_loc: 0.1155  loss_cls: 0.3329  loss_box_reg: 0.3301  loss_mask: 0.4296  time: 0.5362  data_time: 0.0182  lr: 0.0025  max_mem: 7926M
[12/13 06:42:26 d2.utils.events]:  eta: 1:02:02  iter: 3139  total_loss: 1.955  loss_sem_seg: 0.4974  loss_rpn_cls: 0.07416  loss_rpn_loc: 0.1391  loss_cls: 0.3644  loss_box_reg: 0.3824  loss_mask: 0.4177  time: 0.5363  data_time: 0.0198  lr: 0.0025  max_mem: 7926M
[12/13 06:42:37 d2.utils.events]:  eta: 1:01:49  iter: 3159  total_loss: 1.798  loss_sem_seg: 0.5301  loss_rpn_cls: 0.0861  loss_rpn_loc: 0.09239  loss_cls: 0.3336  loss_box_reg: 0.3165  loss_mask: 0.4331  time: 0.5363  data_time: 0.0165  lr: 0.0025  max_mem: 7926M
[12/13 06:42:48 d2.utils.events]:  eta: 1:01:39  iter: 3179  total_loss: 1.805  loss_sem_seg: 0.4797  loss_rpn_cls: 0.07468  loss_rpn_loc: 0.08408  loss_cls: 0.369  loss_box_reg: 0.3477  loss_mask: 0.4217  time: 0.5364  data_time: 0.0193  lr: 0.0025  max_mem: 7926M
[12/13 06:42:59 d2.utils.events]:  eta: 1:01:28  iter: 3199  total_loss: 1.827  loss_sem_seg: 0.4478  loss_rpn_cls: 0.06102  loss_rpn_loc: 0.08248  loss_cls: 0.335  loss_box_reg: 0.3609  loss_mask: 0.4513  time: 0.5365  data_time: 0.0173  lr: 0.0025  max_mem: 7926M
[12/13 06:43:10 d2.utils.events]:  eta: 1:01:16  iter: 3219  total_loss: 1.775  loss_sem_seg: 0.5306  loss_rpn_cls: 0.08834  loss_rpn_loc: 0.1018  loss_cls: 0.3372  loss_box_reg: 0.3152  loss_mask: 0.4549  time: 0.5365  data_time: 0.0176  lr: 0.0025  max_mem: 7926M
[12/13 06:43:21 d2.utils.events]:  eta: 1:01:06  iter: 3239  total_loss: 1.861  loss_sem_seg: 0.4803  loss_rpn_cls: 0.1014  loss_rpn_loc: 0.1143  loss_cls: 0.3228  loss_box_reg: 0.333  loss_mask: 0.4229  time: 0.5366  data_time: 0.0193  lr: 0.0025  max_mem: 7926M
[12/13 06:43:32 d2.utils.events]:  eta: 1:00:57  iter: 3259  total_loss: 2.014  loss_sem_seg: 0.5325  loss_rpn_cls: 0.09834  loss_rpn_loc: 0.1326  loss_cls: 0.3522  loss_box_reg: 0.3803  loss_mask: 0.4379  time: 0.5368  data_time: 0.0198  lr: 0.0025  max_mem: 7926M
[12/13 06:43:43 d2.utils.events]:  eta: 1:00:47  iter: 3279  total_loss: 1.881  loss_sem_seg: 0.5503  loss_rpn_cls: 0.09122  loss_rpn_loc: 0.1096  loss_cls: 0.3529  loss_box_reg: 0.3385  loss_mask: 0.4418  time: 0.5368  data_time: 0.0184  lr: 0.0025  max_mem: 7926M
[12/13 06:43:54 d2.utils.events]:  eta: 1:00:36  iter: 3299  total_loss: 1.808  loss_sem_seg: 0.4809  loss_rpn_cls: 0.06786  loss_rpn_loc: 0.0991  loss_cls: 0.2814  loss_box_reg: 0.3086  loss_mask: 0.4595  time: 0.5367  data_time: 0.0194  lr: 0.0025  max_mem: 7926M
[12/13 06:44:05 d2.utils.events]:  eta: 1:00:24  iter: 3319  total_loss: 1.779  loss_sem_seg: 0.614  loss_rpn_cls: 0.07395  loss_rpn_loc: 0.1006  loss_cls: 0.3247  loss_box_reg: 0.3001  loss_mask: 0.43  time: 0.5367  data_time: 0.0182  lr: 0.0025  max_mem: 7926M
[12/13 06:44:16 d2.utils.events]:  eta: 1:00:11  iter: 3339  total_loss: 1.917  loss_sem_seg: 0.5468  loss_rpn_cls: 0.08182  loss_rpn_loc: 0.09103  loss_cls: 0.3464  loss_box_reg: 0.324  loss_mask: 0.4395  time: 0.5368  data_time: 0.0185  lr: 0.0025  max_mem: 7926M
[12/13 06:44:27 d2.utils.events]:  eta: 1:00:02  iter: 3359  total_loss: 1.84  loss_sem_seg: 0.5907  loss_rpn_cls: 0.06889  loss_rpn_loc: 0.1042  loss_cls: 0.3255  loss_box_reg: 0.3607  loss_mask: 0.4513  time: 0.5369  data_time: 0.0189  lr: 0.0025  max_mem: 7926M
[12/13 06:44:38 d2.utils.events]:  eta: 0:59:50  iter: 3379  total_loss: 1.898  loss_sem_seg: 0.4825  loss_rpn_cls: 0.08862  loss_rpn_loc: 0.1195  loss_cls: 0.3374  loss_box_reg: 0.3159  loss_mask: 0.4411  time: 0.5370  data_time: 0.0180  lr: 0.0025  max_mem: 7926M
[12/13 06:44:49 d2.utils.events]:  eta: 0:59:41  iter: 3399  total_loss: 1.796  loss_sem_seg: 0.4836  loss_rpn_cls: 0.08675  loss_rpn_loc: 0.1058  loss_cls: 0.3755  loss_box_reg: 0.3512  loss_mask: 0.4401  time: 0.5370  data_time: 0.0179  lr: 0.0025  max_mem: 7926M
[12/13 06:45:00 d2.utils.events]:  eta: 0:59:30  iter: 3419  total_loss: 1.866  loss_sem_seg: 0.5327  loss_rpn_cls: 0.07232  loss_rpn_loc: 0.1017  loss_cls: 0.3503  loss_box_reg: 0.3663  loss_mask: 0.4409  time: 0.5372  data_time: 0.0186  lr: 0.0025  max_mem: 7926M
[12/13 06:45:11 d2.utils.events]:  eta: 0:59:18  iter: 3439  total_loss: 1.703  loss_sem_seg: 0.5112  loss_rpn_cls: 0.06969  loss_rpn_loc: 0.08254  loss_cls: 0.2916  loss_box_reg: 0.3203  loss_mask: 0.4203  time: 0.5373  data_time: 0.0182  lr: 0.0025  max_mem: 7926M
[12/13 06:45:22 d2.utils.events]:  eta: 0:59:05  iter: 3459  total_loss: 1.695  loss_sem_seg: 0.5542  loss_rpn_cls: 0.07732  loss_rpn_loc: 0.09382  loss_cls: 0.3294  loss_box_reg: 0.3155  loss_mask: 0.4242  time: 0.5373  data_time: 0.0191  lr: 0.0025  max_mem: 7926M
[12/13 06:45:33 d2.utils.events]:  eta: 0:58:57  iter: 3479  total_loss: 1.713  loss_sem_seg: 0.4764  loss_rpn_cls: 0.06532  loss_rpn_loc: 0.0976  loss_cls: 0.3024  loss_box_reg: 0.307  loss_mask: 0.4084  time: 0.5373  data_time: 0.0192  lr: 0.0025  max_mem: 7926M
[12/13 06:45:44 d2.utils.events]:  eta: 0:58:52  iter: 3499  total_loss: 1.979  loss_sem_seg: 0.4869  loss_rpn_cls: 0.09835  loss_rpn_loc: 0.09343  loss_cls: 0.4104  loss_box_reg: 0.3979  loss_mask: 0.4299  time: 0.5376  data_time: 0.0195  lr: 0.0025  max_mem: 7926M
[12/13 06:45:55 d2.utils.events]:  eta: 0:58:38  iter: 3519  total_loss: 1.931  loss_sem_seg: 0.4069  loss_rpn_cls: 0.08696  loss_rpn_loc: 0.1278  loss_cls: 0.3466  loss_box_reg: 0.3891  loss_mask: 0.4182  time: 0.5377  data_time: 0.0195  lr: 0.0025  max_mem: 7926M
[12/13 06:46:07 d2.utils.events]:  eta: 0:58:31  iter: 3539  total_loss: 1.856  loss_sem_seg: 0.4961  loss_rpn_cls: 0.09042  loss_rpn_loc: 0.1257  loss_cls: 0.3505  loss_box_reg: 0.3471  loss_mask: 0.4293  time: 0.5378  data_time: 0.0185  lr: 0.0025  max_mem: 7926M
[12/13 06:46:18 d2.utils.events]:  eta: 0:58:21  iter: 3559  total_loss: 1.863  loss_sem_seg: 0.451  loss_rpn_cls: 0.09078  loss_rpn_loc: 0.1152  loss_cls: 0.3365  loss_box_reg: 0.3752  loss_mask: 0.4324  time: 0.5379  data_time: 0.0173  lr: 0.0025  max_mem: 7926M
[12/13 06:46:28 d2.utils.events]:  eta: 0:58:05  iter: 3579  total_loss: 1.756  loss_sem_seg: 0.4668  loss_rpn_cls: 0.07194  loss_rpn_loc: 0.1026  loss_cls: 0.3376  loss_box_reg: 0.3393  loss_mask: 0.4211  time: 0.5379  data_time: 0.0167  lr: 0.0025  max_mem: 7926M
[12/13 06:46:40 d2.utils.events]:  eta: 0:57:58  iter: 3599  total_loss: 1.958  loss_sem_seg: 0.5691  loss_rpn_cls: 0.09595  loss_rpn_loc: 0.1247  loss_cls: 0.3741  loss_box_reg: 0.394  loss_mask: 0.4288  time: 0.5381  data_time: 0.0196  lr: 0.0025  max_mem: 7926M
[12/13 06:46:51 d2.utils.events]:  eta: 0:57:50  iter: 3619  total_loss: 1.852  loss_sem_seg: 0.5003  loss_rpn_cls: 0.07256  loss_rpn_loc: 0.09212  loss_cls: 0.3633  loss_box_reg: 0.3548  loss_mask: 0.425  time: 0.5382  data_time: 0.0195  lr: 0.0025  max_mem: 7926M
[12/13 06:47:02 d2.utils.events]:  eta: 0:57:43  iter: 3639  total_loss: 1.772  loss_sem_seg: 0.4837  loss_rpn_cls: 0.06045  loss_rpn_loc: 0.08762  loss_cls: 0.321  loss_box_reg: 0.3578  loss_mask: 0.3992  time: 0.5382  data_time: 0.0171  lr: 0.0025  max_mem: 7926M
[12/13 06:47:13 d2.utils.events]:  eta: 0:57:34  iter: 3659  total_loss: 1.778  loss_sem_seg: 0.43  loss_rpn_cls: 0.06193  loss_rpn_loc: 0.0857  loss_cls: 0.3433  loss_box_reg: 0.3265  loss_mask: 0.4305  time: 0.5383  data_time: 0.0171  lr: 0.0025  max_mem: 7926M
[12/13 06:47:24 d2.utils.events]:  eta: 0:57:23  iter: 3679  total_loss: 1.767  loss_sem_seg: 0.4678  loss_rpn_cls: 0.08649  loss_rpn_loc: 0.09796  loss_cls: 0.3253  loss_box_reg: 0.3096  loss_mask: 0.4312  time: 0.5383  data_time: 0.0164  lr: 0.0025  max_mem: 7926M
[12/13 06:47:34 d2.utils.events]:  eta: 0:57:10  iter: 3699  total_loss: 1.812  loss_sem_seg: 0.5597  loss_rpn_cls: 0.09032  loss_rpn_loc: 0.1106  loss_cls: 0.3123  loss_box_reg: 0.3204  loss_mask: 0.4325  time: 0.5383  data_time: 0.0171  lr: 0.0025  max_mem: 7926M
[12/13 06:47:45 d2.utils.events]:  eta: 0:56:59  iter: 3719  total_loss: 1.655  loss_sem_seg: 0.4551  loss_rpn_cls: 0.07701  loss_rpn_loc: 0.1085  loss_cls: 0.2861  loss_box_reg: 0.3015  loss_mask: 0.4169  time: 0.5383  data_time: 0.0190  lr: 0.0025  max_mem: 7926M
[12/13 06:47:57 d2.utils.events]:  eta: 0:56:49  iter: 3739  total_loss: 1.878  loss_sem_seg: 0.4743  loss_rpn_cls: 0.08312  loss_rpn_loc: 0.1214  loss_cls: 0.3391  loss_box_reg: 0.3464  loss_mask: 0.4299  time: 0.5384  data_time: 0.0251  lr: 0.0025  max_mem: 7926M
[12/13 06:48:08 d2.utils.events]:  eta: 0:56:40  iter: 3759  total_loss: 2.023  loss_sem_seg: 0.6248  loss_rpn_cls: 0.07977  loss_rpn_loc: 0.1079  loss_cls: 0.3539  loss_box_reg: 0.3528  loss_mask: 0.4313  time: 0.5385  data_time: 0.0173  lr: 0.0025  max_mem: 7926M
[12/13 06:48:18 d2.utils.events]:  eta: 0:56:27  iter: 3779  total_loss: 1.899  loss_sem_seg: 0.5071  loss_rpn_cls: 0.07602  loss_rpn_loc: 0.1023  loss_cls: 0.3727  loss_box_reg: 0.3669  loss_mask: 0.4271  time: 0.5385  data_time: 0.0186  lr: 0.0025  max_mem: 7926M
[12/13 06:48:29 d2.utils.events]:  eta: 0:56:15  iter: 3799  total_loss: 1.853  loss_sem_seg: 0.4913  loss_rpn_cls: 0.06362  loss_rpn_loc: 0.0801  loss_cls: 0.3255  loss_box_reg: 0.319  loss_mask: 0.4057  time: 0.5385  data_time: 0.0157  lr: 0.0025  max_mem: 7926M
[12/13 06:48:40 d2.utils.events]:  eta: 0:56:06  iter: 3819  total_loss: 1.856  loss_sem_seg: 0.476  loss_rpn_cls: 0.07144  loss_rpn_loc: 0.08982  loss_cls: 0.4011  loss_box_reg: 0.3912  loss_mask: 0.4367  time: 0.5386  data_time: 0.0171  lr: 0.0025  max_mem: 7926M
[12/13 06:48:51 d2.utils.events]:  eta: 0:55:51  iter: 3839  total_loss: 1.724  loss_sem_seg: 0.5044  loss_rpn_cls: 0.07535  loss_rpn_loc: 0.08958  loss_cls: 0.3101  loss_box_reg: 0.294  loss_mask: 0.4189  time: 0.5386  data_time: 0.0215  lr: 0.0025  max_mem: 7926M
[12/13 06:49:02 d2.utils.events]:  eta: 0:55:38  iter: 3859  total_loss: 1.735  loss_sem_seg: 0.4712  loss_rpn_cls: 0.08424  loss_rpn_loc: 0.1164  loss_cls: 0.3384  loss_box_reg: 0.3308  loss_mask: 0.4008  time: 0.5386  data_time: 0.0171  lr: 0.0025  max_mem: 7926M
[12/13 06:49:12 d2.utils.events]:  eta: 0:55:24  iter: 3879  total_loss: 1.738  loss_sem_seg: 0.6205  loss_rpn_cls: 0.06913  loss_rpn_loc: 0.08992  loss_cls: 0.3016  loss_box_reg: 0.2981  loss_mask: 0.421  time: 0.5385  data_time: 0.0168  lr: 0.0025  max_mem: 7926M
[12/13 06:49:23 d2.utils.events]:  eta: 0:55:14  iter: 3899  total_loss: 1.854  loss_sem_seg: 0.5032  loss_rpn_cls: 0.08648  loss_rpn_loc: 0.1132  loss_cls: 0.3414  loss_box_reg: 0.3322  loss_mask: 0.4375  time: 0.5385  data_time: 0.0167  lr: 0.0025  max_mem: 7926M
[12/13 06:49:34 d2.utils.events]:  eta: 0:55:05  iter: 3919  total_loss: 1.884  loss_sem_seg: 0.5517  loss_rpn_cls: 0.08158  loss_rpn_loc: 0.09391  loss_cls: 0.3757  loss_box_reg: 0.3466  loss_mask: 0.4078  time: 0.5386  data_time: 0.0178  lr: 0.0025  max_mem: 7926M
[12/13 06:49:45 d2.utils.events]:  eta: 0:54:59  iter: 3939  total_loss: 1.778  loss_sem_seg: 0.4504  loss_rpn_cls: 0.09528  loss_rpn_loc: 0.1089  loss_cls: 0.3888  loss_box_reg: 0.3685  loss_mask: 0.4183  time: 0.5386  data_time: 0.0201  lr: 0.0025  max_mem: 7926M
[12/13 06:49:56 d2.utils.events]:  eta: 0:54:50  iter: 3959  total_loss: 1.752  loss_sem_seg: 0.4854  loss_rpn_cls: 0.07209  loss_rpn_loc: 0.1049  loss_cls: 0.3254  loss_box_reg: 0.3423  loss_mask: 0.3986  time: 0.5387  data_time: 0.0181  lr: 0.0025  max_mem: 7926M
[12/13 06:50:07 d2.utils.events]:  eta: 0:54:42  iter: 3979  total_loss: 1.768  loss_sem_seg: 0.5468  loss_rpn_cls: 0.06156  loss_rpn_loc: 0.09884  loss_cls: 0.3542  loss_box_reg: 0.3531  loss_mask: 0.4122  time: 0.5387  data_time: 0.0171  lr: 0.0025  max_mem: 7926M
[12/13 06:50:18 d2.utils.events]:  eta: 0:54:35  iter: 3999  total_loss: 1.818  loss_sem_seg: 0.5204  loss_rpn_cls: 0.07309  loss_rpn_loc: 0.09519  loss_cls: 0.3751  loss_box_reg: 0.3364  loss_mask: 0.4262  time: 0.5388  data_time: 0.0167  lr: 0.0025  max_mem: 7926M
[12/13 06:50:29 d2.utils.events]:  eta: 0:54:21  iter: 4019  total_loss: 1.665  loss_sem_seg: 0.5295  loss_rpn_cls: 0.06305  loss_rpn_loc: 0.1164  loss_cls: 0.2553  loss_box_reg: 0.2652  loss_mask: 0.3978  time: 0.5387  data_time: 0.0166  lr: 0.0025  max_mem: 7926M
[12/13 06:50:40 d2.utils.events]:  eta: 0:54:10  iter: 4039  total_loss: 1.945  loss_sem_seg: 0.5225  loss_rpn_cls: 0.08972  loss_rpn_loc: 0.1072  loss_cls: 0.3535  loss_box_reg: 0.3478  loss_mask: 0.4384  time: 0.5388  data_time: 0.0176  lr: 0.0025  max_mem: 7926M
[12/13 06:50:51 d2.utils.events]:  eta: 0:53:56  iter: 4059  total_loss: 1.731  loss_sem_seg: 0.5963  loss_rpn_cls: 0.06623  loss_rpn_loc: 0.0906  loss_cls: 0.3075  loss_box_reg: 0.2868  loss_mask: 0.4086  time: 0.5388  data_time: 0.0163  lr: 0.0025  max_mem: 7926M
[12/13 06:51:01 d2.utils.events]:  eta: 0:53:44  iter: 4079  total_loss: 1.846  loss_sem_seg: 0.5721  loss_rpn_cls: 0.07598  loss_rpn_loc: 0.1052  loss_cls: 0.2969  loss_box_reg: 0.3283  loss_mask: 0.4194  time: 0.5388  data_time: 0.0160  lr: 0.0025  max_mem: 7926M
[12/13 06:51:12 d2.utils.events]:  eta: 0:53:35  iter: 4099  total_loss: 1.895  loss_sem_seg: 0.5635  loss_rpn_cls: 0.07552  loss_rpn_loc: 0.1126  loss_cls: 0.3883  loss_box_reg: 0.3562  loss_mask: 0.413  time: 0.5388  data_time: 0.0184  lr: 0.0025  max_mem: 7926M
[12/13 06:51:23 d2.utils.events]:  eta: 0:53:30  iter: 4119  total_loss: 1.703  loss_sem_seg: 0.472  loss_rpn_cls: 0.06983  loss_rpn_loc: 0.1017  loss_cls: 0.2845  loss_box_reg: 0.3088  loss_mask: 0.4175  time: 0.5389  data_time: 0.0185  lr: 0.0025  max_mem: 7926M
[12/13 06:51:34 d2.utils.events]:  eta: 0:53:15  iter: 4139  total_loss: 1.92  loss_sem_seg: 0.4691  loss_rpn_cls: 0.09882  loss_rpn_loc: 0.1339  loss_cls: 0.3202  loss_box_reg: 0.317  loss_mask: 0.41  time: 0.5389  data_time: 0.0179  lr: 0.0025  max_mem: 7926M
[12/13 06:51:45 d2.utils.events]:  eta: 0:53:04  iter: 4159  total_loss: 1.684  loss_sem_seg: 0.5008  loss_rpn_cls: 0.07759  loss_rpn_loc: 0.09042  loss_cls: 0.3405  loss_box_reg: 0.2949  loss_mask: 0.4055  time: 0.5389  data_time: 0.0184  lr: 0.0025  max_mem: 7926M
[12/13 06:51:55 d2.utils.events]:  eta: 0:52:51  iter: 4179  total_loss: 1.712  loss_sem_seg: 0.4307  loss_rpn_cls: 0.05912  loss_rpn_loc: 0.08132  loss_cls: 0.329  loss_box_reg: 0.3148  loss_mask: 0.4093  time: 0.5388  data_time: 0.0175  lr: 0.0025  max_mem: 7926M
[12/13 06:52:06 d2.utils.events]:  eta: 0:52:39  iter: 4199  total_loss: 1.867  loss_sem_seg: 0.4963  loss_rpn_cls: 0.07551  loss_rpn_loc: 0.07157  loss_cls: 0.3074  loss_box_reg: 0.3328  loss_mask: 0.4255  time: 0.5388  data_time: 0.0170  lr: 0.0025  max_mem: 7926M
[12/13 06:52:17 d2.utils.events]:  eta: 0:52:28  iter: 4219  total_loss: 1.837  loss_sem_seg: 0.5503  loss_rpn_cls: 0.07843  loss_rpn_loc: 0.09656  loss_cls: 0.327  loss_box_reg: 0.3369  loss_mask: 0.4148  time: 0.5388  data_time: 0.0189  lr: 0.0025  max_mem: 7926M
[12/13 06:52:28 d2.utils.events]:  eta: 0:52:18  iter: 4239  total_loss: 1.91  loss_sem_seg: 0.5327  loss_rpn_cls: 0.07055  loss_rpn_loc: 0.09965  loss_cls: 0.3794  loss_box_reg: 0.3811  loss_mask: 0.4052  time: 0.5389  data_time: 0.0207  lr: 0.0025  max_mem: 7926M
[12/13 06:52:39 d2.utils.events]:  eta: 0:52:05  iter: 4259  total_loss: 1.787  loss_sem_seg: 0.4374  loss_rpn_cls: 0.07138  loss_rpn_loc: 0.1213  loss_cls: 0.3589  loss_box_reg: 0.3467  loss_mask: 0.4066  time: 0.5389  data_time: 0.0165  lr: 0.0025  max_mem: 7926M
[12/13 06:52:50 d2.utils.events]:  eta: 0:51:53  iter: 4279  total_loss: 1.788  loss_sem_seg: 0.5309  loss_rpn_cls: 0.07001  loss_rpn_loc: 0.101  loss_cls: 0.2918  loss_box_reg: 0.3068  loss_mask: 0.4099  time: 0.5389  data_time: 0.0168  lr: 0.0025  max_mem: 7926M
[12/13 06:53:01 d2.utils.events]:  eta: 0:51:43  iter: 4299  total_loss: 1.934  loss_sem_seg: 0.5154  loss_rpn_cls: 0.0773  loss_rpn_loc: 0.1208  loss_cls: 0.3488  loss_box_reg: 0.3819  loss_mask: 0.4241  time: 0.5389  data_time: 0.0166  lr: 0.0025  max_mem: 7926M
[12/13 06:53:12 d2.utils.events]:  eta: 0:51:34  iter: 4319  total_loss: 1.906  loss_sem_seg: 0.504  loss_rpn_cls: 0.09514  loss_rpn_loc: 0.1054  loss_cls: 0.3552  loss_box_reg: 0.3468  loss_mask: 0.4086  time: 0.5390  data_time: 0.0178  lr: 0.0025  max_mem: 7926M
[12/13 06:53:23 d2.utils.events]:  eta: 0:51:24  iter: 4339  total_loss: 1.56  loss_sem_seg: 0.4694  loss_rpn_cls: 0.06899  loss_rpn_loc: 0.1107  loss_cls: 0.2739  loss_box_reg: 0.2807  loss_mask: 0.3932  time: 0.5390  data_time: 0.0173  lr: 0.0025  max_mem: 7926M
[12/13 06:53:34 d2.utils.events]:  eta: 0:51:11  iter: 4359  total_loss: 1.778  loss_sem_seg: 0.4517  loss_rpn_cls: 0.07139  loss_rpn_loc: 0.1184  loss_cls: 0.297  loss_box_reg: 0.3135  loss_mask: 0.4074  time: 0.5391  data_time: 0.0184  lr: 0.0025  max_mem: 7926M
[12/13 06:53:45 d2.utils.events]:  eta: 0:51:03  iter: 4379  total_loss: 1.752  loss_sem_seg: 0.5669  loss_rpn_cls: 0.06195  loss_rpn_loc: 0.08919  loss_cls: 0.3147  loss_box_reg: 0.3012  loss_mask: 0.4027  time: 0.5391  data_time: 0.0190  lr: 0.0025  max_mem: 7926M
[12/13 06:53:55 d2.utils.events]:  eta: 0:50:49  iter: 4399  total_loss: 1.76  loss_sem_seg: 0.4549  loss_rpn_cls: 0.07548  loss_rpn_loc: 0.07168  loss_cls: 0.3248  loss_box_reg: 0.3327  loss_mask: 0.4262  time: 0.5391  data_time: 0.0173  lr: 0.0025  max_mem: 7926M
[12/13 06:54:06 d2.utils.events]:  eta: 0:50:34  iter: 4419  total_loss: 1.77  loss_sem_seg: 0.4433  loss_rpn_cls: 0.06819  loss_rpn_loc: 0.106  loss_cls: 0.3407  loss_box_reg: 0.3527  loss_mask: 0.4262  time: 0.5391  data_time: 0.0177  lr: 0.0025  max_mem: 7926M
[12/13 06:54:17 d2.utils.events]:  eta: 0:50:23  iter: 4439  total_loss: 1.81  loss_sem_seg: 0.4332  loss_rpn_cls: 0.06989  loss_rpn_loc: 0.1053  loss_cls: 0.3504  loss_box_reg: 0.3111  loss_mask: 0.4182  time: 0.5392  data_time: 0.0215  lr: 0.0025  max_mem: 7926M
[12/13 06:54:28 d2.utils.events]:  eta: 0:50:15  iter: 4459  total_loss: 1.824  loss_sem_seg: 0.4054  loss_rpn_cls: 0.08094  loss_rpn_loc: 0.1067  loss_cls: 0.348  loss_box_reg: 0.3662  loss_mask: 0.4166  time: 0.5392  data_time: 0.0191  lr: 0.0025  max_mem: 7926M
[12/13 06:54:39 d2.utils.events]:  eta: 0:49:57  iter: 4479  total_loss: 1.817  loss_sem_seg: 0.5061  loss_rpn_cls: 0.08724  loss_rpn_loc: 0.09074  loss_cls: 0.2809  loss_box_reg: 0.3331  loss_mask: 0.4208  time: 0.5392  data_time: 0.0177  lr: 0.0025  max_mem: 7926M
[12/13 06:54:50 d2.utils.events]:  eta: 0:49:41  iter: 4499  total_loss: 1.853  loss_sem_seg: 0.5153  loss_rpn_cls: 0.08192  loss_rpn_loc: 0.07728  loss_cls: 0.3687  loss_box_reg: 0.3763  loss_mask: 0.4008  time: 0.5392  data_time: 0.0157  lr: 0.0025  max_mem: 7926M
[12/13 06:55:01 d2.utils.events]:  eta: 0:49:31  iter: 4519  total_loss: 1.791  loss_sem_seg: 0.4791  loss_rpn_cls: 0.0664  loss_rpn_loc: 0.09878  loss_cls: 0.3484  loss_box_reg: 0.3293  loss_mask: 0.4004  time: 0.5393  data_time: 0.0174  lr: 0.0025  max_mem: 7926M
[12/13 06:55:12 d2.utils.events]:  eta: 0:49:17  iter: 4539  total_loss: 1.646  loss_sem_seg: 0.4928  loss_rpn_cls: 0.05113  loss_rpn_loc: 0.1143  loss_cls: 0.3062  loss_box_reg: 0.2821  loss_mask: 0.3884  time: 0.5393  data_time: 0.0173  lr: 0.0025  max_mem: 7926M
[12/13 06:55:23 d2.utils.events]:  eta: 0:49:06  iter: 4559  total_loss: 1.847  loss_sem_seg: 0.5322  loss_rpn_cls: 0.06388  loss_rpn_loc: 0.1022  loss_cls: 0.3102  loss_box_reg: 0.3462  loss_mask: 0.4001  time: 0.5393  data_time: 0.0207  lr: 0.0025  max_mem: 7926M
[12/13 06:55:34 d2.utils.events]:  eta: 0:48:59  iter: 4579  total_loss: 1.866  loss_sem_seg: 0.5454  loss_rpn_cls: 0.07778  loss_rpn_loc: 0.124  loss_cls: 0.3547  loss_box_reg: 0.3562  loss_mask: 0.4628  time: 0.5394  data_time: 0.0194  lr: 0.0025  max_mem: 7926M
[12/13 06:55:45 d2.utils.events]:  eta: 0:48:42  iter: 4599  total_loss: 1.644  loss_sem_seg: 0.4354  loss_rpn_cls: 0.06231  loss_rpn_loc: 0.07802  loss_cls: 0.3208  loss_box_reg: 0.285  loss_mask: 0.4102  time: 0.5394  data_time: 0.0164  lr: 0.0025  max_mem: 7926M
[12/13 06:55:55 d2.utils.events]:  eta: 0:48:28  iter: 4619  total_loss: 1.731  loss_sem_seg: 0.4739  loss_rpn_cls: 0.08264  loss_rpn_loc: 0.09928  loss_cls: 0.2922  loss_box_reg: 0.3013  loss_mask: 0.422  time: 0.5394  data_time: 0.0166  lr: 0.0025  max_mem: 7926M
[12/13 06:56:06 d2.utils.events]:  eta: 0:48:17  iter: 4639  total_loss: 1.693  loss_sem_seg: 0.4738  loss_rpn_cls: 0.05404  loss_rpn_loc: 0.05739  loss_cls: 0.3306  loss_box_reg: 0.31  loss_mask: 0.3946  time: 0.5394  data_time: 0.0175  lr: 0.0025  max_mem: 7926M
[12/13 06:56:17 d2.utils.events]:  eta: 0:48:05  iter: 4659  total_loss: 1.789  loss_sem_seg: 0.5249  loss_rpn_cls: 0.0656  loss_rpn_loc: 0.08062  loss_cls: 0.3625  loss_box_reg: 0.3686  loss_mask: 0.4154  time: 0.5394  data_time: 0.0167  lr: 0.0025  max_mem: 7926M
[12/13 06:56:28 d2.utils.events]:  eta: 0:47:54  iter: 4679  total_loss: 1.854  loss_sem_seg: 0.4886  loss_rpn_cls: 0.08254  loss_rpn_loc: 0.1031  loss_cls: 0.333  loss_box_reg: 0.3425  loss_mask: 0.413  time: 0.5394  data_time: 0.0171  lr: 0.0025  max_mem: 7926M
[12/13 06:56:39 d2.utils.events]:  eta: 0:47:50  iter: 4699  total_loss: 1.823  loss_sem_seg: 0.5286  loss_rpn_cls: 0.07142  loss_rpn_loc: 0.08825  loss_cls: 0.3662  loss_box_reg: 0.3881  loss_mask: 0.4217  time: 0.5396  data_time: 0.0176  lr: 0.0025  max_mem: 7926M
[12/13 06:56:50 d2.utils.events]:  eta: 0:47:40  iter: 4719  total_loss: 1.751  loss_sem_seg: 0.5507  loss_rpn_cls: 0.0667  loss_rpn_loc: 0.09049  loss_cls: 0.3141  loss_box_reg: 0.3015  loss_mask: 0.3751  time: 0.5396  data_time: 0.0174  lr: 0.0025  max_mem: 7926M
[12/13 06:57:01 d2.utils.events]:  eta: 0:47:29  iter: 4739  total_loss: 1.776  loss_sem_seg: 0.4949  loss_rpn_cls: 0.07599  loss_rpn_loc: 0.1078  loss_cls: 0.3305  loss_box_reg: 0.3518  loss_mask: 0.3885  time: 0.5396  data_time: 0.0171  lr: 0.0025  max_mem: 7926M
[12/13 06:57:12 d2.utils.events]:  eta: 0:47:18  iter: 4759  total_loss: 1.763  loss_sem_seg: 0.4749  loss_rpn_cls: 0.07286  loss_rpn_loc: 0.09292  loss_cls: 0.3236  loss_box_reg: 0.3569  loss_mask: 0.4135  time: 0.5396  data_time: 0.0179  lr: 0.0025  max_mem: 7926M
[12/13 06:57:23 d2.utils.events]:  eta: 0:47:09  iter: 4779  total_loss: 1.717  loss_sem_seg: 0.5089  loss_rpn_cls: 0.06482  loss_rpn_loc: 0.07943  loss_cls: 0.3096  loss_box_reg: 0.3021  loss_mask: 0.389  time: 0.5396  data_time: 0.0186  lr: 0.0025  max_mem: 7926M
[12/13 06:57:34 d2.utils.events]:  eta: 0:46:59  iter: 4799  total_loss: 1.747  loss_sem_seg: 0.5152  loss_rpn_cls: 0.06802  loss_rpn_loc: 0.07965  loss_cls: 0.322  loss_box_reg: 0.3125  loss_mask: 0.4029  time: 0.5397  data_time: 0.0166  lr: 0.0025  max_mem: 7926M
[12/13 06:57:45 d2.utils.events]:  eta: 0:46:47  iter: 4819  total_loss: 1.977  loss_sem_seg: 0.5116  loss_rpn_cls: 0.09012  loss_rpn_loc: 0.125  loss_cls: 0.4005  loss_box_reg: 0.3869  loss_mask: 0.4365  time: 0.5397  data_time: 0.0184  lr: 0.0025  max_mem: 7926M
[12/13 06:57:55 d2.utils.events]:  eta: 0:46:34  iter: 4839  total_loss: 1.622  loss_sem_seg: 0.5246  loss_rpn_cls: 0.06644  loss_rpn_loc: 0.09802  loss_cls: 0.2527  loss_box_reg: 0.2476  loss_mask: 0.391  time: 0.5396  data_time: 0.0166  lr: 0.0025  max_mem: 7926M
[12/13 06:58:06 d2.utils.events]:  eta: 0:46:26  iter: 4859  total_loss: 1.728  loss_sem_seg: 0.5713  loss_rpn_cls: 0.05902  loss_rpn_loc: 0.09543  loss_cls: 0.3027  loss_box_reg: 0.2976  loss_mask: 0.4064  time: 0.5396  data_time: 0.0162  lr: 0.0025  max_mem: 7926M
[12/13 06:58:17 d2.utils.events]:  eta: 0:46:18  iter: 4879  total_loss: 1.918  loss_sem_seg: 0.5512  loss_rpn_cls: 0.07145  loss_rpn_loc: 0.1085  loss_cls: 0.3173  loss_box_reg: 0.36  loss_mask: 0.4082  time: 0.5397  data_time: 0.0198  lr: 0.0025  max_mem: 7926M
[12/13 06:58:28 d2.utils.events]:  eta: 0:46:08  iter: 4899  total_loss: 1.724  loss_sem_seg: 0.5066  loss_rpn_cls: 0.06954  loss_rpn_loc: 0.09253  loss_cls: 0.2896  loss_box_reg: 0.2769  loss_mask: 0.3955  time: 0.5397  data_time: 0.0187  lr: 0.0025  max_mem: 7926M
[12/13 06:58:39 d2.utils.events]:  eta: 0:45:54  iter: 4919  total_loss: 1.782  loss_sem_seg: 0.4628  loss_rpn_cls: 0.07071  loss_rpn_loc: 0.1139  loss_cls: 0.3433  loss_box_reg: 0.3374  loss_mask: 0.3959  time: 0.5397  data_time: 0.0173  lr: 0.0025  max_mem: 7926M
[12/13 06:58:50 d2.utils.events]:  eta: 0:45:43  iter: 4939  total_loss: 1.702  loss_sem_seg: 0.4295  loss_rpn_cls: 0.07507  loss_rpn_loc: 0.1231  loss_cls: 0.3096  loss_box_reg: 0.2684  loss_mask: 0.3915  time: 0.5397  data_time: 0.0208  lr: 0.0025  max_mem: 7926M
[12/13 06:59:01 d2.utils.events]:  eta: 0:45:31  iter: 4959  total_loss: 1.777  loss_sem_seg: 0.5269  loss_rpn_cls: 0.08373  loss_rpn_loc: 0.1248  loss_cls: 0.3083  loss_box_reg: 0.2729  loss_mask: 0.4245  time: 0.5397  data_time: 0.0189  lr: 0.0025  max_mem: 7926M
[12/13 06:59:12 d2.utils.events]:  eta: 0:45:19  iter: 4979  total_loss: 1.842  loss_sem_seg: 0.4696  loss_rpn_cls: 0.07021  loss_rpn_loc: 0.1028  loss_cls: 0.3339  loss_box_reg: 0.3468  loss_mask: 0.4333  time: 0.5397  data_time: 0.0170  lr: 0.0025  max_mem: 7926M
[12/13 06:59:23 fvcore.common.checkpoint]: Saving checkpoint to ./output/model_0004999.pth
[12/13 06:59:24 d2.utils.events]:  eta: 0:45:08  iter: 4999  total_loss: 1.848  loss_sem_seg: 0.4692  loss_rpn_cls: 0.06601  loss_rpn_loc: 0.09312  loss_cls: 0.3333  loss_box_reg: 0.3368  loss_mask: 0.4099  time: 0.5398  data_time: 0.0179  lr: 0.0025  max_mem: 7926M
[12/13 06:59:35 d2.utils.events]:  eta: 0:44:57  iter: 5019  total_loss: 1.775  loss_sem_seg: 0.4642  loss_rpn_cls: 0.1128  loss_rpn_loc: 0.1333  loss_cls: 0.3416  loss_box_reg: 0.3527  loss_mask: 0.3916  time: 0.5398  data_time: 0.0167  lr: 0.0025  max_mem: 7926M
[12/13 06:59:46 d2.utils.events]:  eta: 0:44:45  iter: 5039  total_loss: 1.654  loss_sem_seg: 0.4644  loss_rpn_cls: 0.07572  loss_rpn_loc: 0.07827  loss_cls: 0.3235  loss_box_reg: 0.3313  loss_mask: 0.3799  time: 0.5398  data_time: 0.0163  lr: 0.0025  max_mem: 7926M
[12/13 06:59:56 d2.utils.events]:  eta: 0:44:33  iter: 5059  total_loss: 1.664  loss_sem_seg: 0.4409  loss_rpn_cls: 0.07145  loss_rpn_loc: 0.07736  loss_cls: 0.2698  loss_box_reg: 0.2932  loss_mask: 0.3965  time: 0.5397  data_time: 0.0173  lr: 0.0025  max_mem: 7926M
[12/13 07:00:07 d2.utils.events]:  eta: 0:44:24  iter: 5079  total_loss: 1.806  loss_sem_seg: 0.4735  loss_rpn_cls: 0.08395  loss_rpn_loc: 0.1101  loss_cls: 0.3256  loss_box_reg: 0.3359  loss_mask: 0.3884  time: 0.5397  data_time: 0.0184  lr: 0.0025  max_mem: 7926M
[12/13 07:00:18 d2.utils.events]:  eta: 0:44:12  iter: 5099  total_loss: 1.803  loss_sem_seg: 0.4389  loss_rpn_cls: 0.0852  loss_rpn_loc: 0.09832  loss_cls: 0.3171  loss_box_reg: 0.3283  loss_mask: 0.3841  time: 0.5397  data_time: 0.0186  lr: 0.0025  max_mem: 7926M
[12/13 07:00:29 d2.utils.events]:  eta: 0:43:59  iter: 5119  total_loss: 1.689  loss_sem_seg: 0.4838  loss_rpn_cls: 0.07654  loss_rpn_loc: 0.1082  loss_cls: 0.2917  loss_box_reg: 0.3344  loss_mask: 0.3954  time: 0.5398  data_time: 0.0181  lr: 0.0025  max_mem: 7926M
[12/13 07:00:40 d2.utils.events]:  eta: 0:43:50  iter: 5139  total_loss: 1.538  loss_sem_seg: 0.4578  loss_rpn_cls: 0.06016  loss_rpn_loc: 0.07295  loss_cls: 0.3013  loss_box_reg: 0.299  loss_mask: 0.3674  time: 0.5398  data_time: 0.0197  lr: 0.0025  max_mem: 7926M
[12/13 07:00:51 d2.utils.events]:  eta: 0:43:43  iter: 5159  total_loss: 1.867  loss_sem_seg: 0.5964  loss_rpn_cls: 0.07799  loss_rpn_loc: 0.1156  loss_cls: 0.3429  loss_box_reg: 0.3486  loss_mask: 0.4156  time: 0.5399  data_time: 0.0197  lr: 0.0025  max_mem: 7926M
[12/13 07:01:02 d2.utils.events]:  eta: 0:43:32  iter: 5179  total_loss: 1.712  loss_sem_seg: 0.5433  loss_rpn_cls: 0.0697  loss_rpn_loc: 0.07907  loss_cls: 0.3269  loss_box_reg: 0.3199  loss_mask: 0.3827  time: 0.5399  data_time: 0.0163  lr: 0.0025  max_mem: 7926M
[12/13 07:01:13 d2.utils.events]:  eta: 0:43:22  iter: 5199  total_loss: 1.914  loss_sem_seg: 0.5102  loss_rpn_cls: 0.07379  loss_rpn_loc: 0.116  loss_cls: 0.3107  loss_box_reg: 0.3357  loss_mask: 0.4316  time: 0.5399  data_time: 0.0167  lr: 0.0025  max_mem: 7926M
[12/13 07:01:24 d2.utils.events]:  eta: 0:43:11  iter: 5219  total_loss: 1.696  loss_sem_seg: 0.4823  loss_rpn_cls: 0.06248  loss_rpn_loc: 0.09007  loss_cls: 0.3069  loss_box_reg: 0.3048  loss_mask: 0.3859  time: 0.5399  data_time: 0.0192  lr: 0.0025  max_mem: 7926M
[12/13 07:01:35 d2.utils.events]:  eta: 0:43:00  iter: 5239  total_loss: 1.862  loss_sem_seg: 0.5579  loss_rpn_cls: 0.07292  loss_rpn_loc: 0.1021  loss_cls: 0.3662  loss_box_reg: 0.4092  loss_mask: 0.3941  time: 0.5400  data_time: 0.0184  lr: 0.0025  max_mem: 7926M
[12/13 07:01:46 d2.utils.events]:  eta: 0:42:50  iter: 5259  total_loss: 1.768  loss_sem_seg: 0.5228  loss_rpn_cls: 0.05825  loss_rpn_loc: 0.09398  loss_cls: 0.2906  loss_box_reg: 0.3101  loss_mask: 0.3911  time: 0.5400  data_time: 0.0178  lr: 0.0025  max_mem: 7926M
[12/13 07:01:56 d2.utils.events]:  eta: 0:42:39  iter: 5279  total_loss: 1.577  loss_sem_seg: 0.4329  loss_rpn_cls: 0.05907  loss_rpn_loc: 0.09957  loss_cls: 0.2761  loss_box_reg: 0.2739  loss_mask: 0.3953  time: 0.5400  data_time: 0.0170  lr: 0.0025  max_mem: 7926M
[12/13 07:02:07 d2.utils.events]:  eta: 0:42:28  iter: 5299  total_loss: 1.611  loss_sem_seg: 0.491  loss_rpn_cls: 0.08376  loss_rpn_loc: 0.09725  loss_cls: 0.2753  loss_box_reg: 0.3009  loss_mask: 0.3943  time: 0.5400  data_time: 0.0172  lr: 0.0025  max_mem: 7926M
[12/13 07:02:18 d2.utils.events]:  eta: 0:42:16  iter: 5319  total_loss: 1.728  loss_sem_seg: 0.4416  loss_rpn_cls: 0.06405  loss_rpn_loc: 0.09172  loss_cls: 0.3533  loss_box_reg: 0.3515  loss_mask: 0.3801  time: 0.5400  data_time: 0.0194  lr: 0.0025  max_mem: 7926M
[12/13 07:02:29 d2.utils.events]:  eta: 0:42:02  iter: 5339  total_loss: 1.858  loss_sem_seg: 0.4895  loss_rpn_cls: 0.07094  loss_rpn_loc: 0.1125  loss_cls: 0.3435  loss_box_reg: 0.361  loss_mask: 0.4021  time: 0.5400  data_time: 0.0174  lr: 0.0025  max_mem: 7926M
[12/13 07:02:40 d2.utils.events]:  eta: 0:41:51  iter: 5359  total_loss: 1.581  loss_sem_seg: 0.4477  loss_rpn_cls: 0.07702  loss_rpn_loc: 0.07342  loss_cls: 0.3183  loss_box_reg: 0.3128  loss_mask: 0.3663  time: 0.5400  data_time: 0.0171  lr: 0.0025  max_mem: 7926M
[12/13 07:02:51 d2.utils.events]:  eta: 0:41:40  iter: 5379  total_loss: 1.793  loss_sem_seg: 0.6066  loss_rpn_cls: 0.05764  loss_rpn_loc: 0.07547  loss_cls: 0.3141  loss_box_reg: 0.3283  loss_mask: 0.3709  time: 0.5401  data_time: 0.0189  lr: 0.0025  max_mem: 7926M
[12/13 07:03:02 d2.utils.events]:  eta: 0:41:29  iter: 5399  total_loss: 1.681  loss_sem_seg: 0.4824  loss_rpn_cls: 0.0841  loss_rpn_loc: 0.09045  loss_cls: 0.3117  loss_box_reg: 0.3134  loss_mask: 0.3743  time: 0.5401  data_time: 0.0170  lr: 0.0025  max_mem: 7926M
[12/13 07:03:13 d2.utils.events]:  eta: 0:41:18  iter: 5419  total_loss: 1.637  loss_sem_seg: 0.4911  loss_rpn_cls: 0.07419  loss_rpn_loc: 0.07475  loss_cls: 0.3159  loss_box_reg: 0.2933  loss_mask: 0.3987  time: 0.5401  data_time: 0.0173  lr: 0.0025  max_mem: 7926M
[12/13 07:03:24 d2.utils.events]:  eta: 0:41:09  iter: 5439  total_loss: 1.569  loss_sem_seg: 0.4729  loss_rpn_cls: 0.06149  loss_rpn_loc: 0.07587  loss_cls: 0.3037  loss_box_reg: 0.311  loss_mask: 0.3846  time: 0.5401  data_time: 0.0163  lr: 0.0025  max_mem: 7926M
[12/13 07:03:35 d2.utils.events]:  eta: 0:40:59  iter: 5459  total_loss: 1.719  loss_sem_seg: 0.4495  loss_rpn_cls: 0.06029  loss_rpn_loc: 0.08085  loss_cls: 0.3204  loss_box_reg: 0.3676  loss_mask: 0.4035  time: 0.5401  data_time: 0.0176  lr: 0.0025  max_mem: 7926M
[12/13 07:03:45 d2.utils.events]:  eta: 0:40:49  iter: 5479  total_loss: 1.661  loss_sem_seg: 0.4858  loss_rpn_cls: 0.06706  loss_rpn_loc: 0.07988  loss_cls: 0.294  loss_box_reg: 0.2902  loss_mask: 0.3953  time: 0.5401  data_time: 0.0196  lr: 0.0025  max_mem: 7926M
[12/13 07:03:56 d2.utils.events]:  eta: 0:40:39  iter: 5499  total_loss: 1.739  loss_sem_seg: 0.466  loss_rpn_cls: 0.086  loss_rpn_loc: 0.1193  loss_cls: 0.3214  loss_box_reg: 0.3161  loss_mask: 0.385  time: 0.5401  data_time: 0.0178  lr: 0.0025  max_mem: 7926M
[12/13 07:04:07 d2.utils.events]:  eta: 0:40:27  iter: 5519  total_loss: 1.683  loss_sem_seg: 0.4811  loss_rpn_cls: 0.0842  loss_rpn_loc: 0.09814  loss_cls: 0.2901  loss_box_reg: 0.2901  loss_mask: 0.3928  time: 0.5401  data_time: 0.0188  lr: 0.0025  max_mem: 7926M
[12/13 07:04:18 d2.utils.events]:  eta: 0:40:16  iter: 5539  total_loss: 1.612  loss_sem_seg: 0.4646  loss_rpn_cls: 0.0689  loss_rpn_loc: 0.1144  loss_cls: 0.3101  loss_box_reg: 0.3311  loss_mask: 0.3958  time: 0.5401  data_time: 0.0174  lr: 0.0025  max_mem: 7926M
[12/13 07:04:29 d2.utils.events]:  eta: 0:40:05  iter: 5559  total_loss: 1.819  loss_sem_seg: 0.4718  loss_rpn_cls: 0.08113  loss_rpn_loc: 0.1011  loss_cls: 0.3414  loss_box_reg: 0.3586  loss_mask: 0.3943  time: 0.5401  data_time: 0.0163  lr: 0.0025  max_mem: 7926M
[12/13 07:04:39 d2.utils.events]:  eta: 0:39:51  iter: 5579  total_loss: 1.593  loss_sem_seg: 0.4379  loss_rpn_cls: 0.08347  loss_rpn_loc: 0.07869  loss_cls: 0.2903  loss_box_reg: 0.3106  loss_mask: 0.3959  time: 0.5401  data_time: 0.0164  lr: 0.0025  max_mem: 7926M
[12/13 07:04:50 d2.utils.events]:  eta: 0:39:42  iter: 5599  total_loss: 1.755  loss_sem_seg: 0.4307  loss_rpn_cls: 0.07613  loss_rpn_loc: 0.08848  loss_cls: 0.3311  loss_box_reg: 0.3454  loss_mask: 0.3894  time: 0.5401  data_time: 0.0168  lr: 0.0025  max_mem: 7926M
[12/13 07:05:01 d2.utils.events]:  eta: 0:39:32  iter: 5619  total_loss: 1.718  loss_sem_seg: 0.4779  loss_rpn_cls: 0.06364  loss_rpn_loc: 0.0861  loss_cls: 0.3058  loss_box_reg: 0.332  loss_mask: 0.381  time: 0.5402  data_time: 0.0180  lr: 0.0025  max_mem: 7926M
[12/13 07:05:13 d2.utils.events]:  eta: 0:39:22  iter: 5639  total_loss: 1.871  loss_sem_seg: 0.4316  loss_rpn_cls: 0.07674  loss_rpn_loc: 0.1158  loss_cls: 0.3491  loss_box_reg: 0.3769  loss_mask: 0.3869  time: 0.5403  data_time: 0.0230  lr: 0.0025  max_mem: 7926M
[12/13 07:05:24 d2.utils.events]:  eta: 0:39:12  iter: 5659  total_loss: 1.745  loss_sem_seg: 0.4786  loss_rpn_cls: 0.08541  loss_rpn_loc: 0.121  loss_cls: 0.3181  loss_box_reg: 0.3772  loss_mask: 0.3903  time: 0.5403  data_time: 0.0169  lr: 0.0025  max_mem: 7926M
[12/13 07:05:35 d2.utils.events]:  eta: 0:39:02  iter: 5679  total_loss: 1.817  loss_sem_seg: 0.4564  loss_rpn_cls: 0.08766  loss_rpn_loc: 0.1344  loss_cls: 0.3404  loss_box_reg: 0.3634  loss_mask: 0.405  time: 0.5404  data_time: 0.0179  lr: 0.0025  max_mem: 7926M
[12/13 07:05:46 d2.utils.events]:  eta: 0:38:49  iter: 5699  total_loss: 1.62  loss_sem_seg: 0.4825  loss_rpn_cls: 0.05767  loss_rpn_loc: 0.08718  loss_cls: 0.3059  loss_box_reg: 0.2887  loss_mask: 0.374  time: 0.5404  data_time: 0.0208  lr: 0.0025  max_mem: 7926M
[12/13 07:05:57 d2.utils.events]:  eta: 0:38:38  iter: 5719  total_loss: 1.816  loss_sem_seg: 0.498  loss_rpn_cls: 0.06285  loss_rpn_loc: 0.09794  loss_cls: 0.3337  loss_box_reg: 0.3174  loss_mask: 0.3831  time: 0.5403  data_time: 0.0162  lr: 0.0025  max_mem: 7926M
[12/13 07:06:08 d2.utils.events]:  eta: 0:38:25  iter: 5739  total_loss: 1.814  loss_sem_seg: 0.5306  loss_rpn_cls: 0.06556  loss_rpn_loc: 0.1114  loss_cls: 0.3405  loss_box_reg: 0.356  loss_mask: 0.3832  time: 0.5404  data_time: 0.0173  lr: 0.0025  max_mem: 7926M
[12/13 07:06:18 d2.utils.events]:  eta: 0:38:14  iter: 5759  total_loss: 1.722  loss_sem_seg: 0.5107  loss_rpn_cls: 0.07786  loss_rpn_loc: 0.1076  loss_cls: 0.3165  loss_box_reg: 0.3227  loss_mask: 0.4  time: 0.5404  data_time: 0.0167  lr: 0.0025  max_mem: 7926M
[12/13 07:06:29 d2.utils.events]:  eta: 0:38:02  iter: 5779  total_loss: 1.59  loss_sem_seg: 0.4585  loss_rpn_cls: 0.07063  loss_rpn_loc: 0.1063  loss_cls: 0.2723  loss_box_reg: 0.3018  loss_mask: 0.3847  time: 0.5404  data_time: 0.0170  lr: 0.0025  max_mem: 7926M
[12/13 07:06:40 d2.utils.events]:  eta: 0:37:50  iter: 5799  total_loss: 1.705  loss_sem_seg: 0.4363  loss_rpn_cls: 0.07614  loss_rpn_loc: 0.1109  loss_cls: 0.3192  loss_box_reg: 0.3104  loss_mask: 0.4032  time: 0.5404  data_time: 0.0179  lr: 0.0025  max_mem: 7926M
[12/13 07:06:51 d2.utils.events]:  eta: 0:37:40  iter: 5819  total_loss: 1.642  loss_sem_seg: 0.4819  loss_rpn_cls: 0.06839  loss_rpn_loc: 0.08153  loss_cls: 0.2737  loss_box_reg: 0.3065  loss_mask: 0.3811  time: 0.5404  data_time: 0.0167  lr: 0.0025  max_mem: 7926M
[12/13 07:07:02 d2.utils.events]:  eta: 0:37:31  iter: 5839  total_loss: 1.674  loss_sem_seg: 0.5079  loss_rpn_cls: 0.06368  loss_rpn_loc: 0.1095  loss_cls: 0.2885  loss_box_reg: 0.308  loss_mask: 0.3955  time: 0.5404  data_time: 0.0191  lr: 0.0025  max_mem: 7926M
[12/13 07:07:12 d2.utils.events]:  eta: 0:37:20  iter: 5859  total_loss: 1.753  loss_sem_seg: 0.5249  loss_rpn_cls: 0.08965  loss_rpn_loc: 0.09005  loss_cls: 0.3218  loss_box_reg: 0.3456  loss_mask: 0.3792  time: 0.5404  data_time: 0.0165  lr: 0.0025  max_mem: 7926M
[12/13 07:07:23 d2.utils.events]:  eta: 0:37:10  iter: 5879  total_loss: 1.828  loss_sem_seg: 0.4892  loss_rpn_cls: 0.07208  loss_rpn_loc: 0.1008  loss_cls: 0.3517  loss_box_reg: 0.3926  loss_mask: 0.408  time: 0.5404  data_time: 0.0190  lr: 0.0025  max_mem: 7926M
[12/13 07:07:34 d2.utils.events]:  eta: 0:36:59  iter: 5899  total_loss: 1.774  loss_sem_seg: 0.4497  loss_rpn_cls: 0.08464  loss_rpn_loc: 0.1007  loss_cls: 0.3379  loss_box_reg: 0.375  loss_mask: 0.4022  time: 0.5404  data_time: 0.0176  lr: 0.0025  max_mem: 7926M
[12/13 07:07:46 d2.utils.events]:  eta: 0:36:50  iter: 5919  total_loss: 1.849  loss_sem_seg: 0.4786  loss_rpn_cls: 0.07491  loss_rpn_loc: 0.1063  loss_cls: 0.3382  loss_box_reg: 0.3576  loss_mask: 0.4066  time: 0.5405  data_time: 0.0174  lr: 0.0025  max_mem: 7926M
[12/13 07:07:56 d2.utils.events]:  eta: 0:36:41  iter: 5939  total_loss: 1.646  loss_sem_seg: 0.4412  loss_rpn_cls: 0.05906  loss_rpn_loc: 0.09068  loss_cls: 0.3008  loss_box_reg: 0.3132  loss_mask: 0.3886  time: 0.5405  data_time: 0.0165  lr: 0.0025  max_mem: 7926M
[12/13 07:08:07 d2.utils.events]:  eta: 0:36:31  iter: 5959  total_loss: 1.792  loss_sem_seg: 0.4973  loss_rpn_cls: 0.08647  loss_rpn_loc: 0.09751  loss_cls: 0.3404  loss_box_reg: 0.3487  loss_mask: 0.3819  time: 0.5405  data_time: 0.0169  lr: 0.0025  max_mem: 7926M
[12/13 07:08:18 d2.utils.events]:  eta: 0:36:21  iter: 5979  total_loss: 1.757  loss_sem_seg: 0.4821  loss_rpn_cls: 0.08443  loss_rpn_loc: 0.1061  loss_cls: 0.308  loss_box_reg: 0.3338  loss_mask: 0.3848  time: 0.5406  data_time: 0.0168  lr: 0.0025  max_mem: 7926M
[12/13 07:08:29 d2.utils.events]:  eta: 0:36:10  iter: 5999  total_loss: 1.602  loss_sem_seg: 0.4689  loss_rpn_cls: 0.05598  loss_rpn_loc: 0.08102  loss_cls: 0.2817  loss_box_reg: 0.3119  loss_mask: 0.3948  time: 0.5405  data_time: 0.0168  lr: 0.0025  max_mem: 7926M
[12/13 07:08:40 d2.utils.events]:  eta: 0:36:00  iter: 6019  total_loss: 1.593  loss_sem_seg: 0.4334  loss_rpn_cls: 0.05726  loss_rpn_loc: 0.07999  loss_cls: 0.3037  loss_box_reg: 0.321  loss_mask: 0.3722  time: 0.5406  data_time: 0.0174  lr: 0.0025  max_mem: 7926M
[12/13 07:08:51 d2.utils.events]:  eta: 0:35:50  iter: 6039  total_loss: 1.653  loss_sem_seg: 0.3853  loss_rpn_cls: 0.06638  loss_rpn_loc: 0.09761  loss_cls: 0.3125  loss_box_reg: 0.3174  loss_mask: 0.3845  time: 0.5406  data_time: 0.0166  lr: 0.0025  max_mem: 7926M
[12/13 07:09:02 d2.utils.events]:  eta: 0:35:41  iter: 6059  total_loss: 1.805  loss_sem_seg: 0.5155  loss_rpn_cls: 0.07636  loss_rpn_loc: 0.09699  loss_cls: 0.334  loss_box_reg: 0.3547  loss_mask: 0.4148  time: 0.5407  data_time: 0.0169  lr: 0.0025  max_mem: 7926M
[12/13 07:09:13 d2.utils.events]:  eta: 0:35:30  iter: 6079  total_loss: 1.731  loss_sem_seg: 0.4197  loss_rpn_cls: 0.08608  loss_rpn_loc: 0.1087  loss_cls: 0.3302  loss_box_reg: 0.3497  loss_mask: 0.3876  time: 0.5407  data_time: 0.0167  lr: 0.0025  max_mem: 7926M
[12/13 07:09:24 d2.utils.events]:  eta: 0:35:19  iter: 6099  total_loss: 1.518  loss_sem_seg: 0.403  loss_rpn_cls: 0.07879  loss_rpn_loc: 0.09174  loss_cls: 0.3043  loss_box_reg: 0.3156  loss_mask: 0.3697  time: 0.5406  data_time: 0.0176  lr: 0.0025  max_mem: 7926M
[12/13 07:09:35 d2.utils.events]:  eta: 0:35:08  iter: 6119  total_loss: 1.575  loss_sem_seg: 0.4606  loss_rpn_cls: 0.0687  loss_rpn_loc: 0.06416  loss_cls: 0.2861  loss_box_reg: 0.2813  loss_mask: 0.3816  time: 0.5406  data_time: 0.0166  lr: 0.0025  max_mem: 7926M
[12/13 07:09:46 d2.utils.events]:  eta: 0:34:57  iter: 6139  total_loss: 1.687  loss_sem_seg: 0.3788  loss_rpn_cls: 0.06643  loss_rpn_loc: 0.106  loss_cls: 0.3096  loss_box_reg: 0.3174  loss_mask: 0.3794  time: 0.5407  data_time: 0.0171  lr: 0.0025  max_mem: 7926M
[12/13 07:09:57 d2.utils.events]:  eta: 0:34:46  iter: 6159  total_loss: 1.802  loss_sem_seg: 0.4805  loss_rpn_cls: 0.07345  loss_rpn_loc: 0.1026  loss_cls: 0.379  loss_box_reg: 0.391  loss_mask: 0.4006  time: 0.5407  data_time: 0.0171  lr: 0.0025  max_mem: 7926M
[12/13 07:10:07 d2.utils.events]:  eta: 0:34:36  iter: 6179  total_loss: 1.805  loss_sem_seg: 0.545  loss_rpn_cls: 0.08425  loss_rpn_loc: 0.09422  loss_cls: 0.3084  loss_box_reg: 0.3229  loss_mask: 0.3974  time: 0.5407  data_time: 0.0186  lr: 0.0025  max_mem: 7926M
[12/13 07:10:18 d2.utils.events]:  eta: 0:34:23  iter: 6199  total_loss: 1.699  loss_sem_seg: 0.4756  loss_rpn_cls: 0.0709  loss_rpn_loc: 0.07619  loss_cls: 0.2571  loss_box_reg: 0.2663  loss_mask: 0.417  time: 0.5406  data_time: 0.0178  lr: 0.0025  max_mem: 7926M
[12/13 07:10:29 d2.utils.events]:  eta: 0:34:14  iter: 6219  total_loss: 1.81  loss_sem_seg: 0.4822  loss_rpn_cls: 0.06894  loss_rpn_loc: 0.09078  loss_cls: 0.3638  loss_box_reg: 0.3654  loss_mask: 0.3966  time: 0.5407  data_time: 0.0170  lr: 0.0025  max_mem: 7926M
[12/13 07:10:40 d2.utils.events]:  eta: 0:34:02  iter: 6239  total_loss: 1.785  loss_sem_seg: 0.4239  loss_rpn_cls: 0.08388  loss_rpn_loc: 0.1035  loss_cls: 0.334  loss_box_reg: 0.3366  loss_mask: 0.3894  time: 0.5407  data_time: 0.0166  lr: 0.0025  max_mem: 7926M
[12/13 07:10:51 d2.utils.events]:  eta: 0:33:53  iter: 6259  total_loss: 1.782  loss_sem_seg: 0.5133  loss_rpn_cls: 0.07609  loss_rpn_loc: 0.104  loss_cls: 0.3292  loss_box_reg: 0.3603  loss_mask: 0.3785  time: 0.5408  data_time: 0.0166  lr: 0.0025  max_mem: 7926M
[12/13 07:11:03 d2.utils.events]:  eta: 0:33:43  iter: 6279  total_loss: 1.666  loss_sem_seg: 0.4123  loss_rpn_cls: 0.07574  loss_rpn_loc: 0.1051  loss_cls: 0.3201  loss_box_reg: 0.3444  loss_mask: 0.4007  time: 0.5408  data_time: 0.0192  lr: 0.0025  max_mem: 7926M
[12/13 07:11:13 d2.utils.events]:  eta: 0:33:34  iter: 6299  total_loss: 1.722  loss_sem_seg: 0.3802  loss_rpn_cls: 0.07204  loss_rpn_loc: 0.1095  loss_cls: 0.3258  loss_box_reg: 0.3273  loss_mask: 0.3979  time: 0.5409  data_time: 0.0180  lr: 0.0025  max_mem: 7926M
[12/13 07:11:24 d2.utils.events]:  eta: 0:33:24  iter: 6319  total_loss: 1.733  loss_sem_seg: 0.4505  loss_rpn_cls: 0.06855  loss_rpn_loc: 0.08787  loss_cls: 0.3397  loss_box_reg: 0.3434  loss_mask: 0.4036  time: 0.5409  data_time: 0.0170  lr: 0.0025  max_mem: 7926M
[12/13 07:11:36 d2.utils.events]:  eta: 0:33:15  iter: 6339  total_loss: 1.795  loss_sem_seg: 0.5153  loss_rpn_cls: 0.09518  loss_rpn_loc: 0.1032  loss_cls: 0.3539  loss_box_reg: 0.378  loss_mask: 0.3893  time: 0.5409  data_time: 0.0210  lr: 0.0025  max_mem: 7926M
[12/13 07:11:46 d2.utils.events]:  eta: 0:33:05  iter: 6359  total_loss: 1.564  loss_sem_seg: 0.4444  loss_rpn_cls: 0.0664  loss_rpn_loc: 0.07376  loss_cls: 0.2571  loss_box_reg: 0.3027  loss_mask: 0.354  time: 0.5409  data_time: 0.0178  lr: 0.0025  max_mem: 7926M
[12/13 07:11:57 d2.utils.events]:  eta: 0:32:51  iter: 6379  total_loss: 1.659  loss_sem_seg: 0.5214  loss_rpn_cls: 0.07767  loss_rpn_loc: 0.08425  loss_cls: 0.2769  loss_box_reg: 0.3233  loss_mask: 0.3723  time: 0.5409  data_time: 0.0170  lr: 0.0025  max_mem: 7926M
[12/13 07:12:08 d2.utils.events]:  eta: 0:32:40  iter: 6399  total_loss: 1.766  loss_sem_seg: 0.5835  loss_rpn_cls: 0.06491  loss_rpn_loc: 0.109  loss_cls: 0.3103  loss_box_reg: 0.3289  loss_mask: 0.4019  time: 0.5409  data_time: 0.0168  lr: 0.0025  max_mem: 7926M
[12/13 07:12:18 d2.utils.events]:  eta: 0:32:29  iter: 6419  total_loss: 1.679  loss_sem_seg: 0.4794  loss_rpn_cls: 0.06984  loss_rpn_loc: 0.0855  loss_cls: 0.3009  loss_box_reg: 0.304  loss_mask: 0.4202  time: 0.5408  data_time: 0.0178  lr: 0.0025  max_mem: 7926M
[12/13 07:12:29 d2.utils.events]:  eta: 0:32:19  iter: 6439  total_loss: 1.617  loss_sem_seg: 0.3945  loss_rpn_cls: 0.08396  loss_rpn_loc: 0.1091  loss_cls: 0.3331  loss_box_reg: 0.3267  loss_mask: 0.393  time: 0.5409  data_time: 0.0188  lr: 0.0025  max_mem: 7926M
[12/13 07:12:41 d2.utils.events]:  eta: 0:32:10  iter: 6459  total_loss: 1.741  loss_sem_seg: 0.4995  loss_rpn_cls: 0.06905  loss_rpn_loc: 0.09955  loss_cls: 0.3292  loss_box_reg: 0.3636  loss_mask: 0.3834  time: 0.5409  data_time: 0.0186  lr: 0.0025  max_mem: 7926M
[12/13 07:12:51 d2.utils.events]:  eta: 0:31:59  iter: 6479  total_loss: 1.76  loss_sem_seg: 0.4765  loss_rpn_cls: 0.08451  loss_rpn_loc: 0.1243  loss_cls: 0.3044  loss_box_reg: 0.3269  loss_mask: 0.3761  time: 0.5409  data_time: 0.0212  lr: 0.0025  max_mem: 7926M
[12/13 07:13:02 d2.utils.events]:  eta: 0:31:48  iter: 6499  total_loss: 1.598  loss_sem_seg: 0.5015  loss_rpn_cls: 0.05879  loss_rpn_loc: 0.07519  loss_cls: 0.311  loss_box_reg: 0.288  loss_mask: 0.369  time: 0.5410  data_time: 0.0180  lr: 0.0025  max_mem: 7926M
[12/13 07:13:13 d2.utils.events]:  eta: 0:31:38  iter: 6519  total_loss: 1.463  loss_sem_seg: 0.4397  loss_rpn_cls: 0.06565  loss_rpn_loc: 0.09507  loss_cls: 0.2471  loss_box_reg: 0.301  loss_mask: 0.3499  time: 0.5410  data_time: 0.0179  lr: 0.0025  max_mem: 7926M
[12/13 07:13:24 d2.utils.events]:  eta: 0:31:29  iter: 6539  total_loss: 1.768  loss_sem_seg: 0.4308  loss_rpn_cls: 0.08208  loss_rpn_loc: 0.1519  loss_cls: 0.3428  loss_box_reg: 0.3168  loss_mask: 0.3945  time: 0.5410  data_time: 0.0166  lr: 0.0025  max_mem: 7926M
[12/13 07:13:35 d2.utils.events]:  eta: 0:31:18  iter: 6559  total_loss: 1.684  loss_sem_seg: 0.4984  loss_rpn_cls: 0.08566  loss_rpn_loc: 0.1292  loss_cls: 0.2625  loss_box_reg: 0.2886  loss_mask: 0.3893  time: 0.5410  data_time: 0.0188  lr: 0.0025  max_mem: 7926M
[12/13 07:13:46 d2.utils.events]:  eta: 0:31:08  iter: 6579  total_loss: 1.669  loss_sem_seg: 0.4288  loss_rpn_cls: 0.0821  loss_rpn_loc: 0.09947  loss_cls: 0.3185  loss_box_reg: 0.3424  loss_mask: 0.3847  time: 0.5410  data_time: 0.0168  lr: 0.0025  max_mem: 7926M
[12/13 07:13:57 d2.utils.events]:  eta: 0:30:57  iter: 6599  total_loss: 1.706  loss_sem_seg: 0.4519  loss_rpn_cls: 0.06455  loss_rpn_loc: 0.0929  loss_cls: 0.3101  loss_box_reg: 0.3154  loss_mask: 0.3799  time: 0.5410  data_time: 0.0180  lr: 0.0025  max_mem: 7926M
[12/13 07:14:08 d2.utils.events]:  eta: 0:30:44  iter: 6619  total_loss: 1.503  loss_sem_seg: 0.4973  loss_rpn_cls: 0.06308  loss_rpn_loc: 0.08481  loss_cls: 0.2984  loss_box_reg: 0.3063  loss_mask: 0.3657  time: 0.5410  data_time: 0.0202  lr: 0.0025  max_mem: 7926M
[12/13 07:14:19 d2.utils.events]:  eta: 0:30:32  iter: 6639  total_loss: 1.523  loss_sem_seg: 0.4184  loss_rpn_cls: 0.07491  loss_rpn_loc: 0.08466  loss_cls: 0.2618  loss_box_reg: 0.3008  loss_mask: 0.3656  time: 0.5411  data_time: 0.0172  lr: 0.0025  max_mem: 7926M
[12/13 07:14:30 d2.utils.events]:  eta: 0:30:20  iter: 6659  total_loss: 1.729  loss_sem_seg: 0.5275  loss_rpn_cls: 0.06925  loss_rpn_loc: 0.1044  loss_cls: 0.2769  loss_box_reg: 0.2821  loss_mask: 0.329  time: 0.5411  data_time: 0.0187  lr: 0.0025  max_mem: 7926M
[12/13 07:14:41 d2.utils.events]:  eta: 0:30:08  iter: 6679  total_loss: 1.797  loss_sem_seg: 0.4841  loss_rpn_cls: 0.08662  loss_rpn_loc: 0.08079  loss_cls: 0.3464  loss_box_reg: 0.3286  loss_mask: 0.3795  time: 0.5411  data_time: 0.0170  lr: 0.0025  max_mem: 7926M
[12/13 07:14:51 d2.utils.events]:  eta: 0:29:57  iter: 6699  total_loss: 1.548  loss_sem_seg: 0.377  loss_rpn_cls: 0.07458  loss_rpn_loc: 0.09689  loss_cls: 0.2869  loss_box_reg: 0.26  loss_mask: 0.3722  time: 0.5410  data_time: 0.0183  lr: 0.0025  max_mem: 7926M
[12/13 07:15:02 d2.utils.events]:  eta: 0:29:46  iter: 6719  total_loss: 1.782  loss_sem_seg: 0.4069  loss_rpn_cls: 0.07811  loss_rpn_loc: 0.09198  loss_cls: 0.3324  loss_box_reg: 0.3845  loss_mask: 0.3876  time: 0.5411  data_time: 0.0170  lr: 0.0025  max_mem: 7926M
[12/13 07:15:13 d2.utils.events]:  eta: 0:29:34  iter: 6739  total_loss: 1.732  loss_sem_seg: 0.4715  loss_rpn_cls: 0.06514  loss_rpn_loc: 0.09786  loss_cls: 0.3257  loss_box_reg: 0.3471  loss_mask: 0.3764  time: 0.5411  data_time: 0.0168  lr: 0.0025  max_mem: 7926M
[12/13 07:15:24 d2.utils.events]:  eta: 0:29:25  iter: 6759  total_loss: 1.634  loss_sem_seg: 0.3749  loss_rpn_cls: 0.06047  loss_rpn_loc: 0.08426  loss_cls: 0.3519  loss_box_reg: 0.3775  loss_mask: 0.3847  time: 0.5411  data_time: 0.0160  lr: 0.0025  max_mem: 7926M
[12/13 07:15:35 d2.utils.events]:  eta: 0:29:15  iter: 6779  total_loss: 1.82  loss_sem_seg: 0.4855  loss_rpn_cls: 0.08141  loss_rpn_loc: 0.1131  loss_cls: 0.3292  loss_box_reg: 0.3574  loss_mask: 0.3675  time: 0.5411  data_time: 0.0196  lr: 0.0025  max_mem: 7926M
[12/13 07:15:46 d2.utils.events]:  eta: 0:29:05  iter: 6799  total_loss: 1.719  loss_sem_seg: 0.5048  loss_rpn_cls: 0.07757  loss_rpn_loc: 0.1267  loss_cls: 0.3554  loss_box_reg: 0.345  loss_mask: 0.3878  time: 0.5411  data_time: 0.0167  lr: 0.0025  max_mem: 7926M
[12/13 07:15:57 d2.utils.events]:  eta: 0:28:54  iter: 6819  total_loss: 1.827  loss_sem_seg: 0.5276  loss_rpn_cls: 0.05224  loss_rpn_loc: 0.1115  loss_cls: 0.3128  loss_box_reg: 0.3054  loss_mask: 0.3944  time: 0.5412  data_time: 0.0217  lr: 0.0025  max_mem: 7926M
[12/13 07:16:08 d2.utils.events]:  eta: 0:28:43  iter: 6839  total_loss: 1.693  loss_sem_seg: 0.4779  loss_rpn_cls: 0.06955  loss_rpn_loc: 0.09959  loss_cls: 0.2879  loss_box_reg: 0.3197  loss_mask: 0.3786  time: 0.5412  data_time: 0.0195  lr: 0.0025  max_mem: 7926M
[12/13 07:16:19 d2.utils.events]:  eta: 0:28:32  iter: 6859  total_loss: 1.623  loss_sem_seg: 0.4045  loss_rpn_cls: 0.06539  loss_rpn_loc: 0.09484  loss_cls: 0.2984  loss_box_reg: 0.2628  loss_mask: 0.3942  time: 0.5412  data_time: 0.0154  lr: 0.0025  max_mem: 7926M
[12/13 07:16:30 d2.utils.events]:  eta: 0:28:21  iter: 6879  total_loss: 1.583  loss_sem_seg: 0.4911  loss_rpn_cls: 0.06395  loss_rpn_loc: 0.06983  loss_cls: 0.2882  loss_box_reg: 0.2901  loss_mask: 0.3751  time: 0.5412  data_time: 0.0170  lr: 0.0025  max_mem: 7926M
[12/13 07:16:41 d2.utils.events]:  eta: 0:28:10  iter: 6899  total_loss: 1.662  loss_sem_seg: 0.4344  loss_rpn_cls: 0.06377  loss_rpn_loc: 0.1115  loss_cls: 0.303  loss_box_reg: 0.301  loss_mask: 0.3858  time: 0.5413  data_time: 0.0190  lr: 0.0025  max_mem: 7926M
[12/13 07:16:52 d2.utils.events]:  eta: 0:27:59  iter: 6919  total_loss: 1.86  loss_sem_seg: 0.5054  loss_rpn_cls: 0.06448  loss_rpn_loc: 0.136  loss_cls: 0.3244  loss_box_reg: 0.3212  loss_mask: 0.3767  time: 0.5413  data_time: 0.0167  lr: 0.0025  max_mem: 7926M
[12/13 07:17:03 d2.utils.events]:  eta: 0:27:46  iter: 6939  total_loss: 1.681  loss_sem_seg: 0.4757  loss_rpn_cls: 0.05954  loss_rpn_loc: 0.1075  loss_cls: 0.2992  loss_box_reg: 0.315  loss_mask: 0.3929  time: 0.5413  data_time: 0.0169  lr: 0.0025  max_mem: 7926M
[12/13 07:17:14 d2.utils.events]:  eta: 0:27:34  iter: 6959  total_loss: 1.798  loss_sem_seg: 0.4573  loss_rpn_cls: 0.06575  loss_rpn_loc: 0.09033  loss_cls: 0.3433  loss_box_reg: 0.3759  loss_mask: 0.3863  time: 0.5413  data_time: 0.0178  lr: 0.0025  max_mem: 7926M
[12/13 07:17:25 d2.utils.events]:  eta: 0:27:22  iter: 6979  total_loss: 1.756  loss_sem_seg: 0.4834  loss_rpn_cls: 0.08848  loss_rpn_loc: 0.09882  loss_cls: 0.2935  loss_box_reg: 0.3361  loss_mask: 0.3781  time: 0.5413  data_time: 0.0169  lr: 0.0025  max_mem: 7926M
[12/13 07:17:36 d2.utils.events]:  eta: 0:27:11  iter: 6999  total_loss: 1.548  loss_sem_seg: 0.4603  loss_rpn_cls: 0.06515  loss_rpn_loc: 0.1017  loss_cls: 0.2794  loss_box_reg: 0.2784  loss_mask: 0.3618  time: 0.5413  data_time: 0.0184  lr: 0.0025  max_mem: 7926M
[12/13 07:17:47 d2.utils.events]:  eta: 0:26:59  iter: 7019  total_loss: 1.818  loss_sem_seg: 0.5591  loss_rpn_cls: 0.07866  loss_rpn_loc: 0.1087  loss_cls: 0.308  loss_box_reg: 0.3407  loss_mask: 0.3942  time: 0.5413  data_time: 0.0174  lr: 0.0025  max_mem: 7926M
[12/13 07:17:58 d2.utils.events]:  eta: 0:26:49  iter: 7039  total_loss: 1.534  loss_sem_seg: 0.4949  loss_rpn_cls: 0.05492  loss_rpn_loc: 0.08412  loss_cls: 0.2944  loss_box_reg: 0.3181  loss_mask: 0.3539  time: 0.5413  data_time: 0.0174  lr: 0.0025  max_mem: 7926M
[12/13 07:18:09 d2.utils.events]:  eta: 0:26:37  iter: 7059  total_loss: 1.745  loss_sem_seg: 0.4976  loss_rpn_cls: 0.07574  loss_rpn_loc: 0.1061  loss_cls: 0.3097  loss_box_reg: 0.2903  loss_mask: 0.3793  time: 0.5414  data_time: 0.0186  lr: 0.0025  max_mem: 7926M
[12/13 07:18:20 d2.utils.events]:  eta: 0:26:26  iter: 7079  total_loss: 1.708  loss_sem_seg: 0.4813  loss_rpn_cls: 0.08451  loss_rpn_loc: 0.1213  loss_cls: 0.3306  loss_box_reg: 0.3209  loss_mask: 0.3637  time: 0.5414  data_time: 0.0210  lr: 0.0025  max_mem: 7926M
[12/13 07:18:31 d2.utils.events]:  eta: 0:26:17  iter: 7099  total_loss: 1.845  loss_sem_seg: 0.5054  loss_rpn_cls: 0.07894  loss_rpn_loc: 0.1071  loss_cls: 0.3368  loss_box_reg: 0.3374  loss_mask: 0.3646  time: 0.5414  data_time: 0.0185  lr: 0.0025  max_mem: 7926M
[12/13 07:18:42 d2.utils.events]:  eta: 0:26:07  iter: 7119  total_loss: 1.678  loss_sem_seg: 0.4405  loss_rpn_cls: 0.06372  loss_rpn_loc: 0.1116  loss_cls: 0.3493  loss_box_reg: 0.3589  loss_mask: 0.3929  time: 0.5414  data_time: 0.0178  lr: 0.0025  max_mem: 7926M
[12/13 07:18:52 d2.utils.events]:  eta: 0:25:55  iter: 7139  total_loss: 1.646  loss_sem_seg: 0.4169  loss_rpn_cls: 0.07857  loss_rpn_loc: 0.1122  loss_cls: 0.2908  loss_box_reg: 0.3239  loss_mask: 0.3874  time: 0.5414  data_time: 0.0166  lr: 0.0025  max_mem: 7926M
[12/13 07:19:04 d2.utils.events]:  eta: 0:25:47  iter: 7159  total_loss: 1.712  loss_sem_seg: 0.4221  loss_rpn_cls: 0.08476  loss_rpn_loc: 0.1167  loss_cls: 0.3198  loss_box_reg: 0.3439  loss_mask: 0.3843  time: 0.5415  data_time: 0.0220  lr: 0.0025  max_mem: 7926M
[12/13 07:19:14 d2.utils.events]:  eta: 0:25:33  iter: 7179  total_loss: 1.527  loss_sem_seg: 0.4553  loss_rpn_cls: 0.0709  loss_rpn_loc: 0.07928  loss_cls: 0.2575  loss_box_reg: 0.2921  loss_mask: 0.3745  time: 0.5415  data_time: 0.0170  lr: 0.0025  max_mem: 7926M
[12/13 07:19:25 d2.utils.events]:  eta: 0:25:25  iter: 7199  total_loss: 1.652  loss_sem_seg: 0.4681  loss_rpn_cls: 0.08453  loss_rpn_loc: 0.1095  loss_cls: 0.3011  loss_box_reg: 0.2975  loss_mask: 0.3942  time: 0.5415  data_time: 0.0179  lr: 0.0025  max_mem: 7926M
[12/13 07:19:36 d2.utils.events]:  eta: 0:25:14  iter: 7219  total_loss: 1.596  loss_sem_seg: 0.4034  loss_rpn_cls: 0.05817  loss_rpn_loc: 0.07611  loss_cls: 0.283  loss_box_reg: 0.3079  loss_mask: 0.3629  time: 0.5415  data_time: 0.0189  lr: 0.0025  max_mem: 7926M
[12/13 07:19:47 d2.utils.events]:  eta: 0:25:04  iter: 7239  total_loss: 1.707  loss_sem_seg: 0.4187  loss_rpn_cls: 0.06735  loss_rpn_loc: 0.0957  loss_cls: 0.3151  loss_box_reg: 0.3518  loss_mask: 0.3625  time: 0.5415  data_time: 0.0168  lr: 0.0025  max_mem: 7926M
[12/13 07:19:58 d2.utils.events]:  eta: 0:24:53  iter: 7259  total_loss: 1.677  loss_sem_seg: 0.4438  loss_rpn_cls: 0.07979  loss_rpn_loc: 0.08639  loss_cls: 0.3305  loss_box_reg: 0.3488  loss_mask: 0.3676  time: 0.5415  data_time: 0.0167  lr: 0.0025  max_mem: 7926M
[12/13 07:20:09 d2.utils.events]:  eta: 0:24:40  iter: 7279  total_loss: 1.714  loss_sem_seg: 0.4346  loss_rpn_cls: 0.07105  loss_rpn_loc: 0.1075  loss_cls: 0.2926  loss_box_reg: 0.3453  loss_mask: 0.3637  time: 0.5415  data_time: 0.0171  lr: 0.0025  max_mem: 7926M
[12/13 07:20:20 d2.utils.events]:  eta: 0:24:29  iter: 7299  total_loss: 1.661  loss_sem_seg: 0.5461  loss_rpn_cls: 0.05943  loss_rpn_loc: 0.08332  loss_cls: 0.2662  loss_box_reg: 0.2684  loss_mask: 0.4097  time: 0.5415  data_time: 0.0159  lr: 0.0025  max_mem: 7926M
[12/13 07:20:30 d2.utils.events]:  eta: 0:24:16  iter: 7319  total_loss: 1.553  loss_sem_seg: 0.5018  loss_rpn_cls: 0.07618  loss_rpn_loc: 0.09109  loss_cls: 0.2584  loss_box_reg: 0.3045  loss_mask: 0.377  time: 0.5415  data_time: 0.0168  lr: 0.0025  max_mem: 7926M
[12/13 07:20:41 d2.utils.events]:  eta: 0:24:04  iter: 7339  total_loss: 1.501  loss_sem_seg: 0.4117  loss_rpn_cls: 0.06347  loss_rpn_loc: 0.07691  loss_cls: 0.2995  loss_box_reg: 0.2992  loss_mask: 0.369  time: 0.5415  data_time: 0.0169  lr: 0.0025  max_mem: 7926M
[12/13 07:20:52 d2.utils.events]:  eta: 0:23:54  iter: 7359  total_loss: 1.616  loss_sem_seg: 0.493  loss_rpn_cls: 0.06835  loss_rpn_loc: 0.09283  loss_cls: 0.3093  loss_box_reg: 0.3287  loss_mask: 0.3689  time: 0.5415  data_time: 0.0185  lr: 0.0025  max_mem: 7926M
[12/13 07:21:03 d2.utils.events]:  eta: 0:23:44  iter: 7379  total_loss: 1.851  loss_sem_seg: 0.5017  loss_rpn_cls: 0.07253  loss_rpn_loc: 0.1138  loss_cls: 0.3129  loss_box_reg: 0.3338  loss_mask: 0.3756  time: 0.5416  data_time: 0.0164  lr: 0.0025  max_mem: 7926M
[12/13 07:21:14 d2.utils.events]:  eta: 0:23:35  iter: 7399  total_loss: 1.597  loss_sem_seg: 0.4429  loss_rpn_cls: 0.08177  loss_rpn_loc: 0.07395  loss_cls: 0.2525  loss_box_reg: 0.284  loss_mask: 0.3697  time: 0.5416  data_time: 0.0180  lr: 0.0025  max_mem: 7926M
[12/13 07:21:25 d2.utils.events]:  eta: 0:23:25  iter: 7419  total_loss: 1.606  loss_sem_seg: 0.4776  loss_rpn_cls: 0.04888  loss_rpn_loc: 0.06274  loss_cls: 0.3091  loss_box_reg: 0.2979  loss_mask: 0.3714  time: 0.5416  data_time: 0.0165  lr: 0.0025  max_mem: 7926M
[12/13 07:21:36 d2.utils.events]:  eta: 0:23:12  iter: 7439  total_loss: 1.7  loss_sem_seg: 0.5559  loss_rpn_cls: 0.07282  loss_rpn_loc: 0.09294  loss_cls: 0.3083  loss_box_reg: 0.2968  loss_mask: 0.3539  time: 0.5416  data_time: 0.0166  lr: 0.0025  max_mem: 7926M
[12/13 07:21:47 d2.utils.events]:  eta: 0:23:01  iter: 7459  total_loss: 1.734  loss_sem_seg: 0.3868  loss_rpn_cls: 0.06246  loss_rpn_loc: 0.08475  loss_cls: 0.3207  loss_box_reg: 0.3822  loss_mask: 0.3765  time: 0.5416  data_time: 0.0199  lr: 0.0025  max_mem: 7926M
[12/13 07:21:58 d2.utils.events]:  eta: 0:22:50  iter: 7479  total_loss: 1.755  loss_sem_seg: 0.44  loss_rpn_cls: 0.0749  loss_rpn_loc: 0.08525  loss_cls: 0.3355  loss_box_reg: 0.3123  loss_mask: 0.375  time: 0.5416  data_time: 0.0169  lr: 0.0025  max_mem: 7926M
[12/13 07:22:09 d2.utils.events]:  eta: 0:22:41  iter: 7499  total_loss: 1.603  loss_sem_seg: 0.4706  loss_rpn_cls: 0.07031  loss_rpn_loc: 0.08199  loss_cls: 0.3047  loss_box_reg: 0.3237  loss_mask: 0.3541  time: 0.5417  data_time: 0.0161  lr: 0.0025  max_mem: 7926M
[12/13 07:22:20 d2.utils.events]:  eta: 0:22:28  iter: 7519  total_loss: 1.596  loss_sem_seg: 0.4698  loss_rpn_cls: 0.06591  loss_rpn_loc: 0.1056  loss_cls: 0.2662  loss_box_reg: 0.2892  loss_mask: 0.3713  time: 0.5416  data_time: 0.0175  lr: 0.0025  max_mem: 7926M
[12/13 07:22:31 d2.utils.events]:  eta: 0:22:16  iter: 7539  total_loss: 1.716  loss_sem_seg: 0.5259  loss_rpn_cls: 0.06684  loss_rpn_loc: 0.1279  loss_cls: 0.3019  loss_box_reg: 0.2724  loss_mask: 0.3621  time: 0.5416  data_time: 0.0174  lr: 0.0025  max_mem: 7926M
[12/13 07:22:42 d2.utils.events]:  eta: 0:22:05  iter: 7559  total_loss: 1.626  loss_sem_seg: 0.5181  loss_rpn_cls: 0.07404  loss_rpn_loc: 0.07096  loss_cls: 0.262  loss_box_reg: 0.2915  loss_mask: 0.366  time: 0.5416  data_time: 0.0173  lr: 0.0025  max_mem: 7926M
[12/13 07:22:53 d2.utils.events]:  eta: 0:21:55  iter: 7579  total_loss: 1.644  loss_sem_seg: 0.4298  loss_rpn_cls: 0.07012  loss_rpn_loc: 0.1092  loss_cls: 0.2964  loss_box_reg: 0.3323  loss_mask: 0.3515  time: 0.5417  data_time: 0.0173  lr: 0.0025  max_mem: 7926M
[12/13 07:23:04 d2.utils.events]:  eta: 0:21:45  iter: 7599  total_loss: 1.632  loss_sem_seg: 0.4455  loss_rpn_cls: 0.06722  loss_rpn_loc: 0.09317  loss_cls: 0.2772  loss_box_reg: 0.3129  loss_mask: 0.388  time: 0.5417  data_time: 0.0187  lr: 0.0025  max_mem: 7926M
[12/13 07:23:15 d2.utils.events]:  eta: 0:21:36  iter: 7619  total_loss: 1.731  loss_sem_seg: 0.5048  loss_rpn_cls: 0.06691  loss_rpn_loc: 0.07921  loss_cls: 0.3463  loss_box_reg: 0.3588  loss_mask: 0.3896  time: 0.5417  data_time: 0.0181  lr: 0.0025  max_mem: 7926M
[12/13 07:23:26 d2.utils.events]:  eta: 0:21:25  iter: 7639  total_loss: 1.714  loss_sem_seg: 0.4224  loss_rpn_cls: 0.07588  loss_rpn_loc: 0.1318  loss_cls: 0.3428  loss_box_reg: 0.364  loss_mask: 0.3754  time: 0.5417  data_time: 0.0183  lr: 0.0025  max_mem: 7926M
[12/13 07:23:37 d2.utils.events]:  eta: 0:21:15  iter: 7659  total_loss: 1.721  loss_sem_seg: 0.4249  loss_rpn_cls: 0.09002  loss_rpn_loc: 0.1248  loss_cls: 0.3354  loss_box_reg: 0.3507  loss_mask: 0.3817  time: 0.5418  data_time: 0.0179  lr: 0.0025  max_mem: 7926M
[12/13 07:23:48 d2.utils.events]:  eta: 0:21:05  iter: 7679  total_loss: 1.74  loss_sem_seg: 0.4119  loss_rpn_cls: 0.08271  loss_rpn_loc: 0.1268  loss_cls: 0.3226  loss_box_reg: 0.3356  loss_mask: 0.375  time: 0.5418  data_time: 0.0162  lr: 0.0025  max_mem: 7926M
[12/13 07:23:58 d2.utils.events]:  eta: 0:20:54  iter: 7699  total_loss: 1.714  loss_sem_seg: 0.421  loss_rpn_cls: 0.08123  loss_rpn_loc: 0.1122  loss_cls: 0.3056  loss_box_reg: 0.3468  loss_mask: 0.378  time: 0.5418  data_time: 0.0164  lr: 0.0025  max_mem: 7926M
[12/13 07:24:09 d2.utils.events]:  eta: 0:20:43  iter: 7719  total_loss: 1.563  loss_sem_seg: 0.4622  loss_rpn_cls: 0.05863  loss_rpn_loc: 0.07542  loss_cls: 0.2678  loss_box_reg: 0.3214  loss_mask: 0.3526  time: 0.5418  data_time: 0.0194  lr: 0.0025  max_mem: 7926M
[12/13 07:24:20 d2.utils.events]:  eta: 0:20:32  iter: 7739  total_loss: 1.618  loss_sem_seg: 0.5163  loss_rpn_cls: 0.05067  loss_rpn_loc: 0.08959  loss_cls: 0.3249  loss_box_reg: 0.3224  loss_mask: 0.3651  time: 0.5418  data_time: 0.0181  lr: 0.0025  max_mem: 7926M
[12/13 07:24:31 d2.utils.events]:  eta: 0:20:21  iter: 7759  total_loss: 1.78  loss_sem_seg: 0.4503  loss_rpn_cls: 0.07907  loss_rpn_loc: 0.117  loss_cls: 0.2856  loss_box_reg: 0.3184  loss_mask: 0.3673  time: 0.5418  data_time: 0.0178  lr: 0.0025  max_mem: 7926M
[12/13 07:24:42 d2.utils.events]:  eta: 0:20:11  iter: 7779  total_loss: 1.581  loss_sem_seg: 0.4053  loss_rpn_cls: 0.07391  loss_rpn_loc: 0.09239  loss_cls: 0.3161  loss_box_reg: 0.3177  loss_mask: 0.35  time: 0.5418  data_time: 0.0189  lr: 0.0025  max_mem: 7926M
[12/13 07:24:53 d2.utils.events]:  eta: 0:19:59  iter: 7799  total_loss: 1.615  loss_sem_seg: 0.4174  loss_rpn_cls: 0.0629  loss_rpn_loc: 0.08669  loss_cls: 0.3055  loss_box_reg: 0.3406  loss_mask: 0.3773  time: 0.5418  data_time: 0.0178  lr: 0.0025  max_mem: 7926M
[12/13 07:25:04 d2.utils.events]:  eta: 0:19:48  iter: 7819  total_loss: 1.789  loss_sem_seg: 0.4699  loss_rpn_cls: 0.08244  loss_rpn_loc: 0.1071  loss_cls: 0.3154  loss_box_reg: 0.3567  loss_mask: 0.3747  time: 0.5419  data_time: 0.0179  lr: 0.0025  max_mem: 7926M
[12/13 07:25:15 d2.utils.events]:  eta: 0:19:37  iter: 7839  total_loss: 1.745  loss_sem_seg: 0.4445  loss_rpn_cls: 0.05957  loss_rpn_loc: 0.07363  loss_cls: 0.3481  loss_box_reg: 0.3531  loss_mask: 0.3716  time: 0.5419  data_time: 0.0212  lr: 0.0025  max_mem: 7926M
[12/13 07:25:26 d2.utils.events]:  eta: 0:19:27  iter: 7859  total_loss: 1.824  loss_sem_seg: 0.5121  loss_rpn_cls: 0.08079  loss_rpn_loc: 0.09352  loss_cls: 0.3666  loss_box_reg: 0.3678  loss_mask: 0.3763  time: 0.5419  data_time: 0.0159  lr: 0.0025  max_mem: 7926M
[12/13 07:25:37 d2.utils.events]:  eta: 0:19:16  iter: 7879  total_loss: 1.685  loss_sem_seg: 0.4418  loss_rpn_cls: 0.06711  loss_rpn_loc: 0.09212  loss_cls: 0.3096  loss_box_reg: 0.3345  loss_mask: 0.3493  time: 0.5419  data_time: 0.0191  lr: 0.0025  max_mem: 7926M
[12/13 07:25:48 d2.utils.events]:  eta: 0:19:05  iter: 7899  total_loss: 1.64  loss_sem_seg: 0.414  loss_rpn_cls: 0.06838  loss_rpn_loc: 0.1045  loss_cls: 0.2752  loss_box_reg: 0.3133  loss_mask: 0.3702  time: 0.5419  data_time: 0.0167  lr: 0.0025  max_mem: 7926M
[12/13 07:26:00 d2.utils.events]:  eta: 0:18:54  iter: 7919  total_loss: 1.668  loss_sem_seg: 0.4566  loss_rpn_cls: 0.05752  loss_rpn_loc: 0.08058  loss_cls: 0.3345  loss_box_reg: 0.3178  loss_mask: 0.3877  time: 0.5420  data_time: 0.0175  lr: 0.0025  max_mem: 7926M
[12/13 07:26:11 d2.utils.events]:  eta: 0:18:44  iter: 7939  total_loss: 1.698  loss_sem_seg: 0.514  loss_rpn_cls: 0.07431  loss_rpn_loc: 0.1101  loss_cls: 0.3175  loss_box_reg: 0.2782  loss_mask: 0.3666  time: 0.5420  data_time: 0.0211  lr: 0.0025  max_mem: 7926M
[12/13 07:26:22 d2.utils.events]:  eta: 0:18:33  iter: 7959  total_loss: 1.576  loss_sem_seg: 0.4475  loss_rpn_cls: 0.06333  loss_rpn_loc: 0.07448  loss_cls: 0.3053  loss_box_reg: 0.2961  loss_mask: 0.3644  time: 0.5420  data_time: 0.0184  lr: 0.0025  max_mem: 7926M
[12/13 07:26:33 d2.utils.events]:  eta: 0:18:22  iter: 7979  total_loss: 1.676  loss_sem_seg: 0.4464  loss_rpn_cls: 0.07361  loss_rpn_loc: 0.1027  loss_cls: 0.3453  loss_box_reg: 0.3485  loss_mask: 0.3739  time: 0.5421  data_time: 0.0168  lr: 0.0025  max_mem: 7926M
[12/13 07:26:44 d2.utils.events]:  eta: 0:18:13  iter: 7999  total_loss: 1.504  loss_sem_seg: 0.3477  loss_rpn_cls: 0.05607  loss_rpn_loc: 0.0781  loss_cls: 0.2524  loss_box_reg: 0.274  loss_mask: 0.3642  time: 0.5421  data_time: 0.0221  lr: 0.0025  max_mem: 7926M
[12/13 07:26:55 d2.utils.events]:  eta: 0:18:02  iter: 8019  total_loss: 1.726  loss_sem_seg: 0.533  loss_rpn_cls: 0.07416  loss_rpn_loc: 0.1159  loss_cls: 0.326  loss_box_reg: 0.3061  loss_mask: 0.3879  time: 0.5421  data_time: 0.0203  lr: 0.0025  max_mem: 7926M
[12/13 07:27:06 d2.utils.events]:  eta: 0:17:51  iter: 8039  total_loss: 1.695  loss_sem_seg: 0.5389  loss_rpn_cls: 0.07241  loss_rpn_loc: 0.1055  loss_cls: 0.2784  loss_box_reg: 0.3068  loss_mask: 0.3753  time: 0.5422  data_time: 0.0193  lr: 0.0025  max_mem: 7926M
[12/13 07:27:17 d2.utils.events]:  eta: 0:17:41  iter: 8059  total_loss: 1.669  loss_sem_seg: 0.4032  loss_rpn_cls: 0.06453  loss_rpn_loc: 0.07893  loss_cls: 0.3046  loss_box_reg: 0.3437  loss_mask: 0.3691  time: 0.5422  data_time: 0.0200  lr: 0.0025  max_mem: 7926M
[12/13 07:27:28 d2.utils.events]:  eta: 0:17:30  iter: 8079  total_loss: 1.624  loss_sem_seg: 0.4628  loss_rpn_cls: 0.05931  loss_rpn_loc: 0.09503  loss_cls: 0.2828  loss_box_reg: 0.2869  loss_mask: 0.3676  time: 0.5422  data_time: 0.0177  lr: 0.0025  max_mem: 7926M
[12/13 07:27:39 d2.utils.events]:  eta: 0:17:19  iter: 8099  total_loss: 1.614  loss_sem_seg: 0.473  loss_rpn_cls: 0.0606  loss_rpn_loc: 0.08693  loss_cls: 0.2504  loss_box_reg: 0.2918  loss_mask: 0.3778  time: 0.5422  data_time: 0.0211  lr: 0.0025  max_mem: 7926M
[12/13 07:27:50 d2.utils.events]:  eta: 0:17:08  iter: 8119  total_loss: 1.696  loss_sem_seg: 0.4838  loss_rpn_cls: 0.06684  loss_rpn_loc: 0.1013  loss_cls: 0.323  loss_box_reg: 0.3462  loss_mask: 0.3714  time: 0.5422  data_time: 0.0183  lr: 0.0025  max_mem: 7926M
[12/13 07:28:01 d2.utils.events]:  eta: 0:16:57  iter: 8139  total_loss: 1.588  loss_sem_seg: 0.4609  loss_rpn_cls: 0.05863  loss_rpn_loc: 0.08957  loss_cls: 0.3313  loss_box_reg: 0.3342  loss_mask: 0.3663  time: 0.5422  data_time: 0.0182  lr: 0.0025  max_mem: 7926M
[12/13 07:28:12 d2.utils.events]:  eta: 0:16:46  iter: 8159  total_loss: 1.681  loss_sem_seg: 0.4742  loss_rpn_cls: 0.08486  loss_rpn_loc: 0.1181  loss_cls: 0.3162  loss_box_reg: 0.3772  loss_mask: 0.3906  time: 0.5422  data_time: 0.0175  lr: 0.0025  max_mem: 7926M
[12/13 07:28:23 d2.utils.events]:  eta: 0:16:35  iter: 8179  total_loss: 1.664  loss_sem_seg: 0.4379  loss_rpn_cls: 0.07777  loss_rpn_loc: 0.1059  loss_cls: 0.3169  loss_box_reg: 0.3172  loss_mask: 0.3832  time: 0.5423  data_time: 0.0188  lr: 0.0025  max_mem: 7926M
[12/13 07:28:34 d2.utils.events]:  eta: 0:16:24  iter: 8199  total_loss: 1.615  loss_sem_seg: 0.4348  loss_rpn_cls: 0.07722  loss_rpn_loc: 0.09495  loss_cls: 0.3376  loss_box_reg: 0.3644  loss_mask: 0.3544  time: 0.5423  data_time: 0.0182  lr: 0.0025  max_mem: 7926M
[12/13 07:28:45 d2.utils.events]:  eta: 0:16:13  iter: 8219  total_loss: 1.6  loss_sem_seg: 0.4157  loss_rpn_cls: 0.0704  loss_rpn_loc: 0.08198  loss_cls: 0.2876  loss_box_reg: 0.2824  loss_mask: 0.3478  time: 0.5423  data_time: 0.0203  lr: 0.0025  max_mem: 7926M
[12/13 07:28:56 d2.utils.events]:  eta: 0:16:02  iter: 8239  total_loss: 1.624  loss_sem_seg: 0.4272  loss_rpn_cls: 0.06551  loss_rpn_loc: 0.07335  loss_cls: 0.3076  loss_box_reg: 0.3202  loss_mask: 0.3606  time: 0.5423  data_time: 0.0186  lr: 0.0025  max_mem: 7926M
[12/13 07:29:07 d2.utils.events]:  eta: 0:15:51  iter: 8259  total_loss: 1.791  loss_sem_seg: 0.4986  loss_rpn_cls: 0.06932  loss_rpn_loc: 0.12  loss_cls: 0.3007  loss_box_reg: 0.3003  loss_mask: 0.3838  time: 0.5423  data_time: 0.0185  lr: 0.0025  max_mem: 7926M
[12/13 07:29:18 d2.utils.events]:  eta: 0:15:41  iter: 8279  total_loss: 1.699  loss_sem_seg: 0.3848  loss_rpn_cls: 0.07538  loss_rpn_loc: 0.1132  loss_cls: 0.3207  loss_box_reg: 0.3655  loss_mask: 0.3785  time: 0.5423  data_time: 0.0185  lr: 0.0025  max_mem: 7926M
[12/13 07:29:29 d2.utils.events]:  eta: 0:15:30  iter: 8299  total_loss: 1.761  loss_sem_seg: 0.4206  loss_rpn_cls: 0.08671  loss_rpn_loc: 0.08434  loss_cls: 0.2857  loss_box_reg: 0.2968  loss_mask: 0.3612  time: 0.5423  data_time: 0.0169  lr: 0.0025  max_mem: 7926M
[12/13 07:29:40 d2.utils.events]:  eta: 0:15:19  iter: 8319  total_loss: 1.693  loss_sem_seg: 0.4932  loss_rpn_cls: 0.07951  loss_rpn_loc: 0.1029  loss_cls: 0.3162  loss_box_reg: 0.3132  loss_mask: 0.3703  time: 0.5424  data_time: 0.0174  lr: 0.0025  max_mem: 7926M
[12/13 07:29:51 d2.utils.events]:  eta: 0:15:09  iter: 8339  total_loss: 1.677  loss_sem_seg: 0.4116  loss_rpn_cls: 0.09093  loss_rpn_loc: 0.09321  loss_cls: 0.3084  loss_box_reg: 0.3446  loss_mask: 0.3767  time: 0.5424  data_time: 0.0176  lr: 0.0025  max_mem: 7926M
[12/13 07:30:02 d2.utils.events]:  eta: 0:14:58  iter: 8359  total_loss: 1.654  loss_sem_seg: 0.4787  loss_rpn_cls: 0.07204  loss_rpn_loc: 0.08659  loss_cls: 0.3179  loss_box_reg: 0.3233  loss_mask: 0.385  time: 0.5424  data_time: 0.0181  lr: 0.0025  max_mem: 7926M
[12/13 07:30:13 d2.utils.events]:  eta: 0:14:46  iter: 8379  total_loss: 1.558  loss_sem_seg: 0.3984  loss_rpn_cls: 0.05871  loss_rpn_loc: 0.08517  loss_cls: 0.2826  loss_box_reg: 0.3145  loss_mask: 0.348  time: 0.5424  data_time: 0.0170  lr: 0.0025  max_mem: 7926M
[12/13 07:30:24 d2.utils.events]:  eta: 0:14:35  iter: 8399  total_loss: 1.679  loss_sem_seg: 0.4532  loss_rpn_cls: 0.06609  loss_rpn_loc: 0.09118  loss_cls: 0.3149  loss_box_reg: 0.3077  loss_mask: 0.369  time: 0.5424  data_time: 0.0194  lr: 0.0025  max_mem: 7926M
[12/13 07:30:35 d2.utils.events]:  eta: 0:14:24  iter: 8419  total_loss: 1.569  loss_sem_seg: 0.4684  loss_rpn_cls: 0.06918  loss_rpn_loc: 0.09698  loss_cls: 0.2697  loss_box_reg: 0.2763  loss_mask: 0.3695  time: 0.5424  data_time: 0.0169  lr: 0.0025  max_mem: 7926M
[12/13 07:30:45 d2.utils.events]:  eta: 0:14:13  iter: 8439  total_loss: 1.475  loss_sem_seg: 0.414  loss_rpn_cls: 0.06215  loss_rpn_loc: 0.08426  loss_cls: 0.2695  loss_box_reg: 0.2966  loss_mask: 0.3466  time: 0.5424  data_time: 0.0173  lr: 0.0025  max_mem: 7926M
[12/13 07:30:57 d2.utils.events]:  eta: 0:14:02  iter: 8459  total_loss: 1.626  loss_sem_seg: 0.4295  loss_rpn_cls: 0.07516  loss_rpn_loc: 0.1152  loss_cls: 0.3157  loss_box_reg: 0.29  loss_mask: 0.3708  time: 0.5425  data_time: 0.0178  lr: 0.0025  max_mem: 7926M
[12/13 07:31:08 d2.utils.events]:  eta: 0:13:52  iter: 8479  total_loss: 1.536  loss_sem_seg: 0.401  loss_rpn_cls: 0.06248  loss_rpn_loc: 0.07106  loss_cls: 0.2905  loss_box_reg: 0.3  loss_mask: 0.3887  time: 0.5425  data_time: 0.0208  lr: 0.0025  max_mem: 7926M
[12/13 07:31:19 d2.utils.events]:  eta: 0:13:41  iter: 8499  total_loss: 1.775  loss_sem_seg: 0.5002  loss_rpn_cls: 0.07464  loss_rpn_loc: 0.09005  loss_cls: 0.3019  loss_box_reg: 0.3422  loss_mask: 0.3922  time: 0.5425  data_time: 0.0182  lr: 0.0025  max_mem: 7926M
[12/13 07:31:30 d2.utils.events]:  eta: 0:13:30  iter: 8519  total_loss: 1.672  loss_sem_seg: 0.5063  loss_rpn_cls: 0.05848  loss_rpn_loc: 0.09652  loss_cls: 0.2921  loss_box_reg: 0.3328  loss_mask: 0.3537  time: 0.5425  data_time: 0.0188  lr: 0.0025  max_mem: 7926M
[12/13 07:31:41 d2.utils.events]:  eta: 0:13:20  iter: 8539  total_loss: 1.62  loss_sem_seg: 0.4122  loss_rpn_cls: 0.0736  loss_rpn_loc: 0.1031  loss_cls: 0.3212  loss_box_reg: 0.3272  loss_mask: 0.3699  time: 0.5425  data_time: 0.0183  lr: 0.0025  max_mem: 7926M
[12/13 07:31:52 d2.utils.events]:  eta: 0:13:09  iter: 8559  total_loss: 1.698  loss_sem_seg: 0.45  loss_rpn_cls: 0.07333  loss_rpn_loc: 0.1052  loss_cls: 0.2972  loss_box_reg: 0.3152  loss_mask: 0.3732  time: 0.5426  data_time: 0.0181  lr: 0.0025  max_mem: 7926M
[12/13 07:32:03 d2.utils.events]:  eta: 0:12:57  iter: 8579  total_loss: 1.639  loss_sem_seg: 0.5011  loss_rpn_cls: 0.06415  loss_rpn_loc: 0.09891  loss_cls: 0.3048  loss_box_reg: 0.2881  loss_mask: 0.3823  time: 0.5426  data_time: 0.0186  lr: 0.0025  max_mem: 7926M
[12/13 07:32:14 d2.utils.events]:  eta: 0:12:46  iter: 8599  total_loss: 1.615  loss_sem_seg: 0.4087  loss_rpn_cls: 0.06309  loss_rpn_loc: 0.09534  loss_cls: 0.3133  loss_box_reg: 0.3378  loss_mask: 0.3669  time: 0.5426  data_time: 0.0197  lr: 0.0025  max_mem: 7926M
[12/13 07:32:25 d2.utils.events]:  eta: 0:12:36  iter: 8619  total_loss: 1.531  loss_sem_seg: 0.439  loss_rpn_cls: 0.0572  loss_rpn_loc: 0.07409  loss_cls: 0.293  loss_box_reg: 0.3002  loss_mask: 0.3467  time: 0.5426  data_time: 0.0199  lr: 0.0025  max_mem: 7926M
[12/13 07:32:36 d2.utils.events]:  eta: 0:12:24  iter: 8639  total_loss: 1.737  loss_sem_seg: 0.4765  loss_rpn_cls: 0.08843  loss_rpn_loc: 0.1387  loss_cls: 0.3261  loss_box_reg: 0.3715  loss_mask: 0.3582  time: 0.5426  data_time: 0.0189  lr: 0.0025  max_mem: 7926M
[12/13 07:32:47 d2.utils.events]:  eta: 0:12:14  iter: 8659  total_loss: 1.702  loss_sem_seg: 0.4637  loss_rpn_cls: 0.07332  loss_rpn_loc: 0.08471  loss_cls: 0.3203  loss_box_reg: 0.2934  loss_mask: 0.3893  time: 0.5426  data_time: 0.0190  lr: 0.0025  max_mem: 7926M
[12/13 07:32:58 d2.utils.events]:  eta: 0:12:03  iter: 8679  total_loss: 1.481  loss_sem_seg: 0.4411  loss_rpn_cls: 0.06847  loss_rpn_loc: 0.06473  loss_cls: 0.2396  loss_box_reg: 0.2681  loss_mask: 0.3557  time: 0.5427  data_time: 0.0190  lr: 0.0025  max_mem: 7926M
[12/13 07:33:09 d2.utils.events]:  eta: 0:11:52  iter: 8699  total_loss: 1.715  loss_sem_seg: 0.4976  loss_rpn_cls: 0.06927  loss_rpn_loc: 0.07881  loss_cls: 0.3149  loss_box_reg: 0.3355  loss_mask: 0.3466  time: 0.5427  data_time: 0.0195  lr: 0.0025  max_mem: 7926M
[12/13 07:33:20 d2.utils.events]:  eta: 0:11:41  iter: 8719  total_loss: 1.653  loss_sem_seg: 0.4501  loss_rpn_cls: 0.07429  loss_rpn_loc: 0.07724  loss_cls: 0.3076  loss_box_reg: 0.3049  loss_mask: 0.3503  time: 0.5427  data_time: 0.0179  lr: 0.0025  max_mem: 7926M
[12/13 07:33:31 d2.utils.events]:  eta: 0:11:30  iter: 8739  total_loss: 1.687  loss_sem_seg: 0.5121  loss_rpn_cls: 0.06823  loss_rpn_loc: 0.08932  loss_cls: 0.2906  loss_box_reg: 0.3115  loss_mask: 0.3623  time: 0.5428  data_time: 0.0219  lr: 0.0025  max_mem: 7926M
[12/13 07:33:43 d2.utils.events]:  eta: 0:11:19  iter: 8759  total_loss: 1.582  loss_sem_seg: 0.4603  loss_rpn_cls: 0.06944  loss_rpn_loc: 0.1178  loss_cls: 0.3319  loss_box_reg: 0.3148  loss_mask: 0.368  time: 0.5428  data_time: 0.0210  lr: 0.0025  max_mem: 7926M
[12/13 07:33:54 d2.utils.events]:  eta: 0:11:09  iter: 8779  total_loss: 1.791  loss_sem_seg: 0.4888  loss_rpn_cls: 0.0792  loss_rpn_loc: 0.09396  loss_cls: 0.2935  loss_box_reg: 0.3249  loss_mask: 0.3612  time: 0.5428  data_time: 0.0195  lr: 0.0025  max_mem: 7926M
[12/13 07:34:05 d2.utils.events]:  eta: 0:10:58  iter: 8799  total_loss: 1.579  loss_sem_seg: 0.4499  loss_rpn_cls: 0.05842  loss_rpn_loc: 0.07964  loss_cls: 0.2974  loss_box_reg: 0.3077  loss_mask: 0.3544  time: 0.5429  data_time: 0.0191  lr: 0.0025  max_mem: 7926M
[12/13 07:34:16 d2.utils.events]:  eta: 0:10:47  iter: 8819  total_loss: 1.632  loss_sem_seg: 0.3848  loss_rpn_cls: 0.09345  loss_rpn_loc: 0.1132  loss_cls: 0.2994  loss_box_reg: 0.3191  loss_mask: 0.3789  time: 0.5429  data_time: 0.0192  lr: 0.0025  max_mem: 7926M
[12/13 07:34:27 d2.utils.events]:  eta: 0:10:36  iter: 8839  total_loss: 1.7  loss_sem_seg: 0.4731  loss_rpn_cls: 0.07334  loss_rpn_loc: 0.1092  loss_cls: 0.3096  loss_box_reg: 0.3398  loss_mask: 0.3895  time: 0.5429  data_time: 0.0187  lr: 0.0025  max_mem: 7926M
[12/13 07:34:38 d2.utils.events]:  eta: 0:10:26  iter: 8859  total_loss: 1.638  loss_sem_seg: 0.393  loss_rpn_cls: 0.06328  loss_rpn_loc: 0.08658  loss_cls: 0.3135  loss_box_reg: 0.3221  loss_mask: 0.3599  time: 0.5430  data_time: 0.0178  lr: 0.0025  max_mem: 7926M
[12/13 07:34:49 d2.utils.events]:  eta: 0:10:15  iter: 8879  total_loss: 1.65  loss_sem_seg: 0.4319  loss_rpn_cls: 0.04477  loss_rpn_loc: 0.07902  loss_cls: 0.3088  loss_box_reg: 0.3056  loss_mask: 0.3474  time: 0.5430  data_time: 0.0192  lr: 0.0025  max_mem: 7926M
[12/13 07:35:00 d2.utils.events]:  eta: 0:10:03  iter: 8899  total_loss: 1.48  loss_sem_seg: 0.4512  loss_rpn_cls: 0.07177  loss_rpn_loc: 0.08596  loss_cls: 0.2614  loss_box_reg: 0.2613  loss_mask: 0.3781  time: 0.5430  data_time: 0.0198  lr: 0.0025  max_mem: 7926M
[12/13 07:35:11 d2.utils.events]:  eta: 0:09:52  iter: 8919  total_loss: 1.638  loss_sem_seg: 0.4094  loss_rpn_cls: 0.08672  loss_rpn_loc: 0.1073  loss_cls: 0.2612  loss_box_reg: 0.3033  loss_mask: 0.3646  time: 0.5430  data_time: 0.0194  lr: 0.0025  max_mem: 7926M
[12/13 07:35:22 d2.utils.events]:  eta: 0:09:41  iter: 8939  total_loss: 1.602  loss_sem_seg: 0.4594  loss_rpn_cls: 0.08747  loss_rpn_loc: 0.1011  loss_cls: 0.3178  loss_box_reg: 0.3031  loss_mask: 0.3923  time: 0.5430  data_time: 0.0174  lr: 0.0025  max_mem: 7926M
[12/13 07:35:33 d2.utils.events]:  eta: 0:09:30  iter: 8959  total_loss: 1.512  loss_sem_seg: 0.3972  loss_rpn_cls: 0.05961  loss_rpn_loc: 0.08716  loss_cls: 0.3023  loss_box_reg: 0.3598  loss_mask: 0.3481  time: 0.5430  data_time: 0.0213  lr: 0.0025  max_mem: 7926M
[12/13 07:35:44 d2.utils.events]:  eta: 0:09:19  iter: 8979  total_loss: 1.561  loss_sem_seg: 0.4062  loss_rpn_cls: 0.05696  loss_rpn_loc: 0.1018  loss_cls: 0.2896  loss_box_reg: 0.2913  loss_mask: 0.3562  time: 0.5430  data_time: 0.0200  lr: 0.0025  max_mem: 7926M
[12/13 07:35:55 d2.utils.events]:  eta: 0:09:08  iter: 8999  total_loss: 1.743  loss_sem_seg: 0.5247  loss_rpn_cls: 0.07242  loss_rpn_loc: 0.08035  loss_cls: 0.3214  loss_box_reg: 0.3244  loss_mask: 0.3662  time: 0.5431  data_time: 0.0181  lr: 0.0025  max_mem: 7926M
[12/13 07:36:06 d2.utils.events]:  eta: 0:08:57  iter: 9019  total_loss: 1.867  loss_sem_seg: 0.506  loss_rpn_cls: 0.07965  loss_rpn_loc: 0.1316  loss_cls: 0.347  loss_box_reg: 0.3365  loss_mask: 0.3738  time: 0.5431  data_time: 0.0181  lr: 0.0025  max_mem: 7926M
[12/13 07:36:17 d2.utils.events]:  eta: 0:08:46  iter: 9039  total_loss: 1.718  loss_sem_seg: 0.4978  loss_rpn_cls: 0.0815  loss_rpn_loc: 0.1193  loss_cls: 0.2852  loss_box_reg: 0.3123  loss_mask: 0.3719  time: 0.5431  data_time: 0.0185  lr: 0.0025  max_mem: 7926M
[12/13 07:36:28 d2.utils.events]:  eta: 0:08:35  iter: 9059  total_loss: 1.687  loss_sem_seg: 0.537  loss_rpn_cls: 0.06863  loss_rpn_loc: 0.09511  loss_cls: 0.3051  loss_box_reg: 0.336  loss_mask: 0.3763  time: 0.5431  data_time: 0.0168  lr: 0.0025  max_mem: 7926M
[12/13 07:36:39 d2.utils.events]:  eta: 0:08:24  iter: 9079  total_loss: 1.66  loss_sem_seg: 0.4698  loss_rpn_cls: 0.08815  loss_rpn_loc: 0.09514  loss_cls: 0.3014  loss_box_reg: 0.3087  loss_mask: 0.3501  time: 0.5431  data_time: 0.0178  lr: 0.0025  max_mem: 7926M
[12/13 07:36:50 d2.utils.events]:  eta: 0:08:14  iter: 9099  total_loss: 1.698  loss_sem_seg: 0.447  loss_rpn_cls: 0.06795  loss_rpn_loc: 0.1083  loss_cls: 0.3254  loss_box_reg: 0.3712  loss_mask: 0.3716  time: 0.5431  data_time: 0.0176  lr: 0.0025  max_mem: 7926M
[12/13 07:37:01 d2.utils.events]:  eta: 0:08:03  iter: 9119  total_loss: 1.489  loss_sem_seg: 0.4752  loss_rpn_cls: 0.06636  loss_rpn_loc: 0.08176  loss_cls: 0.2427  loss_box_reg: 0.2704  loss_mask: 0.3555  time: 0.5431  data_time: 0.0207  lr: 0.0025  max_mem: 7926M
[12/13 07:37:12 d2.utils.events]:  eta: 0:07:52  iter: 9139  total_loss: 1.554  loss_sem_seg: 0.467  loss_rpn_cls: 0.05972  loss_rpn_loc: 0.07126  loss_cls: 0.2751  loss_box_reg: 0.3093  loss_mask: 0.3648  time: 0.5432  data_time: 0.0198  lr: 0.0025  max_mem: 7926M
[12/13 07:37:23 d2.utils.events]:  eta: 0:07:41  iter: 9159  total_loss: 1.561  loss_sem_seg: 0.3991  loss_rpn_cls: 0.06077  loss_rpn_loc: 0.103  loss_cls: 0.2848  loss_box_reg: 0.3288  loss_mask: 0.3505  time: 0.5431  data_time: 0.0193  lr: 0.0025  max_mem: 7926M
[12/13 07:37:34 d2.utils.events]:  eta: 0:07:30  iter: 9179  total_loss: 1.521  loss_sem_seg: 0.3714  loss_rpn_cls: 0.07215  loss_rpn_loc: 0.09304  loss_cls: 0.281  loss_box_reg: 0.3259  loss_mask: 0.3616  time: 0.5431  data_time: 0.0174  lr: 0.0025  max_mem: 7926M
[12/13 07:37:45 d2.utils.events]:  eta: 0:07:19  iter: 9199  total_loss: 1.674  loss_sem_seg: 0.4457  loss_rpn_cls: 0.05918  loss_rpn_loc: 0.1032  loss_cls: 0.3043  loss_box_reg: 0.3236  loss_mask: 0.3869  time: 0.5431  data_time: 0.0168  lr: 0.0025  max_mem: 7926M
[12/13 07:37:56 d2.utils.events]:  eta: 0:07:08  iter: 9219  total_loss: 1.644  loss_sem_seg: 0.4178  loss_rpn_cls: 0.07293  loss_rpn_loc: 0.0998  loss_cls: 0.2841  loss_box_reg: 0.3239  loss_mask: 0.3609  time: 0.5432  data_time: 0.0180  lr: 0.0025  max_mem: 7926M
[12/13 07:38:07 d2.utils.events]:  eta: 0:06:57  iter: 9239  total_loss: 1.52  loss_sem_seg: 0.4271  loss_rpn_cls: 0.06342  loss_rpn_loc: 0.04706  loss_cls: 0.2972  loss_box_reg: 0.2982  loss_mask: 0.3636  time: 0.5432  data_time: 0.0209  lr: 0.0025  max_mem: 7926M
[12/13 07:38:18 d2.utils.events]:  eta: 0:06:46  iter: 9259  total_loss: 1.473  loss_sem_seg: 0.3943  loss_rpn_cls: 0.06705  loss_rpn_loc: 0.07702  loss_cls: 0.2655  loss_box_reg: 0.2614  loss_mask: 0.3464  time: 0.5432  data_time: 0.0196  lr: 0.0025  max_mem: 7926M
[12/13 07:38:29 d2.utils.events]:  eta: 0:06:34  iter: 9279  total_loss: 1.789  loss_sem_seg: 0.4569  loss_rpn_cls: 0.08869  loss_rpn_loc: 0.1083  loss_cls: 0.3366  loss_box_reg: 0.33  loss_mask: 0.3651  time: 0.5432  data_time: 0.0194  lr: 0.0025  max_mem: 7926M
[12/13 07:38:40 d2.utils.events]:  eta: 0:06:24  iter: 9299  total_loss: 1.579  loss_sem_seg: 0.4607  loss_rpn_cls: 0.06889  loss_rpn_loc: 0.09787  loss_cls: 0.2943  loss_box_reg: 0.3412  loss_mask: 0.3576  time: 0.5432  data_time: 0.0195  lr: 0.0025  max_mem: 7926M
[12/13 07:38:51 d2.utils.events]:  eta: 0:06:13  iter: 9319  total_loss: 1.672  loss_sem_seg: 0.3668  loss_rpn_cls: 0.0757  loss_rpn_loc: 0.09681  loss_cls: 0.3307  loss_box_reg: 0.3261  loss_mask: 0.3716  time: 0.5433  data_time: 0.0177  lr: 0.0025  max_mem: 7926M
[12/13 07:39:02 d2.utils.events]:  eta: 0:06:02  iter: 9339  total_loss: 1.582  loss_sem_seg: 0.4721  loss_rpn_cls: 0.06095  loss_rpn_loc: 0.08772  loss_cls: 0.3065  loss_box_reg: 0.3415  loss_mask: 0.3618  time: 0.5432  data_time: 0.0195  lr: 0.0025  max_mem: 7926M
[12/13 07:39:13 d2.utils.events]:  eta: 0:05:51  iter: 9359  total_loss: 1.777  loss_sem_seg: 0.4696  loss_rpn_cls: 0.07478  loss_rpn_loc: 0.08723  loss_cls: 0.3233  loss_box_reg: 0.3448  loss_mask: 0.3665  time: 0.5433  data_time: 0.0171  lr: 0.0025  max_mem: 7926M
[12/13 07:39:24 d2.utils.events]:  eta: 0:05:40  iter: 9379  total_loss: 1.506  loss_sem_seg: 0.377  loss_rpn_cls: 0.06037  loss_rpn_loc: 0.08544  loss_cls: 0.298  loss_box_reg: 0.3139  loss_mask: 0.3763  time: 0.5433  data_time: 0.0204  lr: 0.0025  max_mem: 7926M
[12/13 07:39:35 d2.utils.events]:  eta: 0:05:29  iter: 9399  total_loss: 1.737  loss_sem_seg: 0.5074  loss_rpn_cls: 0.07116  loss_rpn_loc: 0.09341  loss_cls: 0.3206  loss_box_reg: 0.3189  loss_mask: 0.3511  time: 0.5433  data_time: 0.0182  lr: 0.0025  max_mem: 7926M
[12/13 07:39:46 d2.utils.events]:  eta: 0:05:18  iter: 9419  total_loss: 1.521  loss_sem_seg: 0.4617  loss_rpn_cls: 0.04861  loss_rpn_loc: 0.09626  loss_cls: 0.2888  loss_box_reg: 0.31  loss_mask: 0.3644  time: 0.5433  data_time: 0.0191  lr: 0.0025  max_mem: 7926M
[12/13 07:39:57 d2.utils.events]:  eta: 0:05:08  iter: 9439  total_loss: 1.645  loss_sem_seg: 0.4311  loss_rpn_cls: 0.06248  loss_rpn_loc: 0.0988  loss_cls: 0.3108  loss_box_reg: 0.3308  loss_mask: 0.3515  time: 0.5433  data_time: 0.0168  lr: 0.0025  max_mem: 7926M
[12/13 07:40:09 d2.utils.events]:  eta: 0:04:57  iter: 9459  total_loss: 1.663  loss_sem_seg: 0.4894  loss_rpn_cls: 0.0778  loss_rpn_loc: 0.1202  loss_cls: 0.3021  loss_box_reg: 0.3457  loss_mask: 0.3758  time: 0.5434  data_time: 0.0184  lr: 0.0025  max_mem: 7926M
[12/13 07:40:19 d2.utils.events]:  eta: 0:04:45  iter: 9479  total_loss: 1.527  loss_sem_seg: 0.3956  loss_rpn_cls: 0.07348  loss_rpn_loc: 0.08358  loss_cls: 0.3271  loss_box_reg: 0.3365  loss_mask: 0.3498  time: 0.5434  data_time: 0.0178  lr: 0.0025  max_mem: 7926M
[12/13 07:40:30 d2.utils.events]:  eta: 0:04:35  iter: 9499  total_loss: 1.611  loss_sem_seg: 0.466  loss_rpn_cls: 0.05375  loss_rpn_loc: 0.08882  loss_cls: 0.3074  loss_box_reg: 0.3054  loss_mask: 0.3877  time: 0.5434  data_time: 0.0192  lr: 0.0025  max_mem: 7926M
[12/13 07:40:41 d2.utils.events]:  eta: 0:04:24  iter: 9519  total_loss: 1.776  loss_sem_seg: 0.5288  loss_rpn_cls: 0.07251  loss_rpn_loc: 0.09077  loss_cls: 0.2992  loss_box_reg: 0.3301  loss_mask: 0.3673  time: 0.5434  data_time: 0.0177  lr: 0.0025  max_mem: 7926M
[12/13 07:40:52 d2.utils.events]:  eta: 0:04:12  iter: 9539  total_loss: 1.731  loss_sem_seg: 0.4577  loss_rpn_cls: 0.07102  loss_rpn_loc: 0.09657  loss_cls: 0.3503  loss_box_reg: 0.3485  loss_mask: 0.3924  time: 0.5434  data_time: 0.0184  lr: 0.0025  max_mem: 7926M
[12/13 07:41:03 d2.utils.events]:  eta: 0:04:01  iter: 9559  total_loss: 1.63  loss_sem_seg: 0.4728  loss_rpn_cls: 0.06352  loss_rpn_loc: 0.06601  loss_cls: 0.3028  loss_box_reg: 0.3186  loss_mask: 0.3654  time: 0.5434  data_time: 0.0182  lr: 0.0025  max_mem: 7926M
[12/13 07:41:14 d2.utils.events]:  eta: 0:03:50  iter: 9579  total_loss: 1.571  loss_sem_seg: 0.4544  loss_rpn_cls: 0.06296  loss_rpn_loc: 0.07682  loss_cls: 0.2964  loss_box_reg: 0.2819  loss_mask: 0.3665  time: 0.5434  data_time: 0.0169  lr: 0.0025  max_mem: 7926M
[12/13 07:41:25 d2.utils.events]:  eta: 0:03:39  iter: 9599  total_loss: 1.627  loss_sem_seg: 0.4059  loss_rpn_cls: 0.07937  loss_rpn_loc: 0.08904  loss_cls: 0.309  loss_box_reg: 0.296  loss_mask: 0.3546  time: 0.5434  data_time: 0.0187  lr: 0.0025  max_mem: 7926M
[12/13 07:41:36 d2.utils.events]:  eta: 0:03:28  iter: 9619  total_loss: 1.643  loss_sem_seg: 0.4387  loss_rpn_cls: 0.06654  loss_rpn_loc: 0.1064  loss_cls: 0.2719  loss_box_reg: 0.302  loss_mask: 0.3555  time: 0.5434  data_time: 0.0194  lr: 0.0025  max_mem: 7926M
[12/13 07:41:47 d2.utils.events]:  eta: 0:03:18  iter: 9639  total_loss: 1.621  loss_sem_seg: 0.4457  loss_rpn_cls: 0.06758  loss_rpn_loc: 0.1148  loss_cls: 0.2726  loss_box_reg: 0.3147  loss_mask: 0.3707  time: 0.5434  data_time: 0.0182  lr: 0.0025  max_mem: 7926M
[12/13 07:41:57 d2.utils.events]:  eta: 0:03:06  iter: 9659  total_loss: 1.459  loss_sem_seg: 0.3699  loss_rpn_cls: 0.05751  loss_rpn_loc: 0.07707  loss_cls: 0.2813  loss_box_reg: 0.306  loss_mask: 0.3692  time: 0.5434  data_time: 0.0177  lr: 0.0025  max_mem: 7926M
[12/13 07:42:08 d2.utils.events]:  eta: 0:02:56  iter: 9679  total_loss: 1.633  loss_sem_seg: 0.3794  loss_rpn_cls: 0.08291  loss_rpn_loc: 0.1092  loss_cls: 0.326  loss_box_reg: 0.3277  loss_mask: 0.377  time: 0.5434  data_time: 0.0167  lr: 0.0025  max_mem: 7926M
[12/13 07:42:19 d2.utils.events]:  eta: 0:02:45  iter: 9699  total_loss: 1.673  loss_sem_seg: 0.4311  loss_rpn_cls: 0.07109  loss_rpn_loc: 0.1091  loss_cls: 0.3478  loss_box_reg: 0.3645  loss_mask: 0.3829  time: 0.5434  data_time: 0.0164  lr: 0.0025  max_mem: 7926M
[12/13 07:42:30 d2.utils.events]:  eta: 0:02:33  iter: 9719  total_loss: 1.503  loss_sem_seg: 0.3743  loss_rpn_cls: 0.06677  loss_rpn_loc: 0.1053  loss_cls: 0.2868  loss_box_reg: 0.3359  loss_mask: 0.3799  time: 0.5434  data_time: 0.0198  lr: 0.0025  max_mem: 7926M
[12/13 07:42:42 d2.utils.events]:  eta: 0:02:22  iter: 9739  total_loss: 1.661  loss_sem_seg: 0.4246  loss_rpn_cls: 0.07597  loss_rpn_loc: 0.08338  loss_cls: 0.3282  loss_box_reg: 0.4028  loss_mask: 0.3694  time: 0.5435  data_time: 0.0204  lr: 0.0025  max_mem: 7926M
[12/13 07:42:53 d2.utils.events]:  eta: 0:02:11  iter: 9759  total_loss: 1.677  loss_sem_seg: 0.4354  loss_rpn_cls: 0.08926  loss_rpn_loc: 0.09602  loss_cls: 0.3059  loss_box_reg: 0.3397  loss_mask: 0.3701  time: 0.5435  data_time: 0.0193  lr: 0.0025  max_mem: 7926M
[12/13 07:43:04 d2.utils.events]:  eta: 0:02:00  iter: 9779  total_loss: 1.598  loss_sem_seg: 0.4081  loss_rpn_cls: 0.07273  loss_rpn_loc: 0.09202  loss_cls: 0.298  loss_box_reg: 0.332  loss_mask: 0.3652  time: 0.5435  data_time: 0.0191  lr: 0.0025  max_mem: 7926M
[12/13 07:43:15 d2.utils.events]:  eta: 0:01:49  iter: 9799  total_loss: 1.656  loss_sem_seg: 0.378  loss_rpn_cls: 0.0726  loss_rpn_loc: 0.1237  loss_cls: 0.3546  loss_box_reg: 0.3649  loss_mask: 0.3755  time: 0.5435  data_time: 0.0175  lr: 0.0025  max_mem: 7926M
[12/13 07:43:26 d2.utils.events]:  eta: 0:01:38  iter: 9819  total_loss: 1.609  loss_sem_seg: 0.4296  loss_rpn_cls: 0.07396  loss_rpn_loc: 0.08297  loss_cls: 0.2456  loss_box_reg: 0.315  loss_mask: 0.3451  time: 0.5435  data_time: 0.0181  lr: 0.0025  max_mem: 7926M
[12/13 07:43:36 d2.utils.events]:  eta: 0:01:27  iter: 9839  total_loss: 1.678  loss_sem_seg: 0.4886  loss_rpn_cls: 0.0661  loss_rpn_loc: 0.08918  loss_cls: 0.3394  loss_box_reg: 0.328  loss_mask: 0.3556  time: 0.5435  data_time: 0.0223  lr: 0.0025  max_mem: 7926M
[12/13 07:43:48 d2.utils.events]:  eta: 0:01:16  iter: 9859  total_loss: 1.757  loss_sem_seg: 0.4398  loss_rpn_cls: 0.06532  loss_rpn_loc: 0.08838  loss_cls: 0.3003  loss_box_reg: 0.3703  loss_mask: 0.3712  time: 0.5435  data_time: 0.0200  lr: 0.0025  max_mem: 7926M
[12/13 07:43:59 d2.utils.events]:  eta: 0:01:05  iter: 9879  total_loss: 1.571  loss_sem_seg: 0.3977  loss_rpn_cls: 0.06113  loss_rpn_loc: 0.0678  loss_cls: 0.3023  loss_box_reg: 0.3538  loss_mask: 0.3602  time: 0.5436  data_time: 0.0176  lr: 0.0025  max_mem: 7926M
[12/13 07:44:10 d2.utils.events]:  eta: 0:00:54  iter: 9899  total_loss: 1.466  loss_sem_seg: 0.3001  loss_rpn_cls: 0.05821  loss_rpn_loc: 0.1018  loss_cls: 0.283  loss_box_reg: 0.29  loss_mask: 0.3874  time: 0.5436  data_time: 0.0209  lr: 0.0025  max_mem: 7926M
[12/13 07:44:21 d2.utils.events]:  eta: 0:00:43  iter: 9919  total_loss: 1.605  loss_sem_seg: 0.4786  loss_rpn_cls: 0.06491  loss_rpn_loc: 0.08762  loss_cls: 0.2885  loss_box_reg: 0.2887  loss_mask: 0.373  time: 0.5436  data_time: 0.0192  lr: 0.0025  max_mem: 7926M
[12/13 07:44:32 d2.utils.events]:  eta: 0:00:32  iter: 9939  total_loss: 1.711  loss_sem_seg: 0.4491  loss_rpn_cls: 0.07911  loss_rpn_loc: 0.1062  loss_cls: 0.3043  loss_box_reg: 0.3408  loss_mask: 0.3385  time: 0.5436  data_time: 0.0201  lr: 0.0025  max_mem: 7926M
[12/13 07:44:43 d2.utils.events]:  eta: 0:00:21  iter: 9959  total_loss: 1.495  loss_sem_seg: 0.4749  loss_rpn_cls: 0.05862  loss_rpn_loc: 0.08289  loss_cls: 0.2777  loss_box_reg: 0.2639  loss_mask: 0.365  time: 0.5436  data_time: 0.0170  lr: 0.0025  max_mem: 7926M
[12/13 07:44:54 d2.utils.events]:  eta: 0:00:10  iter: 9979  total_loss: 1.591  loss_sem_seg: 0.4517  loss_rpn_cls: 0.07942  loss_rpn_loc: 0.1025  loss_cls: 0.3046  loss_box_reg: 0.3663  loss_mask: 0.3541  time: 0.5436  data_time: 0.0208  lr: 0.0025  max_mem: 7926M
[12/13 07:45:05 fvcore.common.checkpoint]: Saving checkpoint to ./output/model_0009999.pth
[12/13 07:45:06 fvcore.common.checkpoint]: Saving checkpoint to ./output/model_final.pth
[12/13 07:45:07 d2.utils.events]:  eta: 0:00:00  iter: 9999  total_loss: 1.57  loss_sem_seg: 0.3762  loss_rpn_cls: 0.08325  loss_rpn_loc: 0.0783  loss_cls: 0.3054  loss_box_reg: 0.3066  loss_mask: 0.354  time: 0.5436  data_time: 0.0172  lr: 0.0025  max_mem: 7926M
[12/13 07:45:07 d2.engine.hooks]: Overall training speed: 9998 iterations in 1:30:35 (0.5437 s / it)
[12/13 07:45:07 d2.engine.hooks]: Total training time: 1:30:45 (0:00:10 on hooks)
[12/13 07:45:08 d2.data.datasets.coco]: Loaded 5000 images in COCO format from /content/datasets/coco/annotations/instances_val2017.json
[12/13 07:45:08 d2.data.datasets.coco]: Loaded 5000 images with semantic segmentation from /content/datasets/coco/val2017
[12/13 07:45:09 d2.data.build]: Distribution of instances among all 80 categories:
|   category    | #instances   |   category   | #instances   |   category    | #instances   |
|:-------------:|:-------------|:------------:|:-------------|:-------------:|:-------------|
|    person     | 10777        |   bicycle    | 314          |      car      | 1918         |
|  motorcycle   | 367          |   airplane   | 143          |      bus      | 283          |
|     train     | 190          |    truck     | 414          |     boat      | 424          |
| traffic light | 634          | fire hydrant | 101          |   stop sign   | 75           |
| parking meter | 60           |    bench     | 411          |     bird      | 427          |
|      cat      | 202          |     dog      | 218          |     horse     | 272          |
|     sheep     | 354          |     cow      | 372          |   elephant    | 252          |
|     bear      | 71           |    zebra     | 266          |    giraffe    | 232          |
|   backpack    | 371          |   umbrella   | 407          |    handbag    | 540          |
|      tie      | 252          |   suitcase   | 299          |    frisbee    | 115          |
|     skis      | 241          |  snowboard   | 69           |  sports ball  | 260          |
|     kite      | 327          | baseball bat | 145          | baseball gl.. | 148          |
|  skateboard   | 179          |  surfboard   | 267          | tennis racket | 225          |
|    bottle     | 1013         |  wine glass  | 341          |      cup      | 895          |
|     fork      | 215          |    knife     | 325          |     spoon     | 253          |
|     bowl      | 623          |    banana    | 370          |     apple     | 236          |
|   sandwich    | 177          |    orange    | 285          |   broccoli    | 312          |
|    carrot     | 365          |   hot dog    | 125          |     pizza     | 284          |
|     donut     | 328          |     cake     | 310          |     chair     | 1771         |
|     couch     | 261          | potted plant | 342          |      bed      | 163          |
| dining table  | 695          |    toilet    | 179          |      tv       | 288          |
|    laptop     | 231          |    mouse     | 106          |    remote     | 283          |
|   keyboard    | 153          |  cell phone  | 262          |   microwave   | 55           |
|     oven      | 143          |   toaster    | 9            |     sink      | 225          |
| refrigerator  | 126          |     book     | 1129         |     clock     | 267          |
|     vase      | 274          |   scissors   | 36           |  teddy bear   | 190          |
|  hair drier   | 11           |  toothbrush  | 57           |               |              |
|     total     | 36335        |              |              |               |              |
[12/13 07:45:09 d2.data.dataset_mapper]: [DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]
[12/13 07:45:09 d2.data.common]: Serializing the dataset using: <class 'detectron2.data.common.NumpySerializedList'>
[12/13 07:45:09 d2.data.common]: Serializing 5000 elements to byte tensors and concatenating them all ...
[12/13 07:45:09 d2.data.common]: Serialized dataset takes 19.55 MiB
[12/13 07:45:10 d2.data.datasets.coco]: Loaded 5000 images in COCO format from /content/datasets/coco/annotations/instances_val2017.json
[12/13 07:45:10 d2.data.datasets.coco]: Loaded 5000 images with semantic segmentation from /content/datasets/coco/val2017
[12/13 07:45:11 d2.evaluation.evaluator]: Start inference on 5000 batches
[12/13 07:45:13 d2.evaluation.evaluator]: Inference done 11/5000. Dataloading: 0.0020 s/iter. Inference: 0.0686 s/iter. Eval: 0.0823 s/iter. Total: 0.1530 s/iter. ETA=0:12:43
[12/13 07:45:18 d2.evaluation.evaluator]: Inference done 48/5000. Dataloading: 0.0024 s/iter. Inference: 0.0687 s/iter. Eval: 0.0702 s/iter. Total: 0.1414 s/iter. ETA=0:11:40
[12/13 07:45:23 d2.evaluation.evaluator]: Inference done 85/5000. Dataloading: 0.0024 s/iter. Inference: 0.0682 s/iter. Eval: 0.0680 s/iter. Total: 0.1387 s/iter. ETA=0:11:21
[12/13 07:45:28 d2.evaluation.evaluator]: Inference done 117/5000. Dataloading: 0.0025 s/iter. Inference: 0.0705 s/iter. Eval: 0.0711 s/iter. Total: 0.1441 s/iter. ETA=0:11:43
[12/13 07:45:33 d2.evaluation.evaluator]: Inference done 151/5000. Dataloading: 0.0025 s/iter. Inference: 0.0698 s/iter. Eval: 0.0730 s/iter. Total: 0.1453 s/iter. ETA=0:11:44
[12/13 07:45:38 d2.evaluation.evaluator]: Inference done 185/5000. Dataloading: 0.0025 s/iter. Inference: 0.0691 s/iter. Eval: 0.0748 s/iter. Total: 0.1465 s/iter. ETA=0:11:45
[12/13 07:45:43 d2.evaluation.evaluator]: Inference done 224/5000. Dataloading: 0.0025 s/iter. Inference: 0.0685 s/iter. Eval: 0.0725 s/iter. Total: 0.1435 s/iter. ETA=0:11:25
[12/13 07:45:48 d2.evaluation.evaluator]: Inference done 260/5000. Dataloading: 0.0025 s/iter. Inference: 0.0683 s/iter. Eval: 0.0724 s/iter. Total: 0.1432 s/iter. ETA=0:11:18
[12/13 07:45:53 d2.evaluation.evaluator]: Inference done 295/5000. Dataloading: 0.0025 s/iter. Inference: 0.0680 s/iter. Eval: 0.0727 s/iter. Total: 0.1433 s/iter. ETA=0:11:14
[12/13 07:45:59 d2.evaluation.evaluator]: Inference done 331/5000. Dataloading: 0.0025 s/iter. Inference: 0.0679 s/iter. Eval: 0.0727 s/iter. Total: 0.1431 s/iter. ETA=0:11:08
[12/13 07:46:04 d2.evaluation.evaluator]: Inference done 366/5000. Dataloading: 0.0025 s/iter. Inference: 0.0679 s/iter. Eval: 0.0727 s/iter. Total: 0.1432 s/iter. ETA=0:11:03
[12/13 07:46:09 d2.evaluation.evaluator]: Inference done 404/5000. Dataloading: 0.0025 s/iter. Inference: 0.0677 s/iter. Eval: 0.0719 s/iter. Total: 0.1422 s/iter. ETA=0:10:53
[12/13 07:46:14 d2.evaluation.evaluator]: Inference done 442/5000. Dataloading: 0.0025 s/iter. Inference: 0.0676 s/iter. Eval: 0.0714 s/iter. Total: 0.1415 s/iter. ETA=0:10:44
[12/13 07:46:19 d2.evaluation.evaluator]: Inference done 480/5000. Dataloading: 0.0025 s/iter. Inference: 0.0674 s/iter. Eval: 0.0708 s/iter. Total: 0.1408 s/iter. ETA=0:10:36
[12/13 07:46:24 d2.evaluation.evaluator]: Inference done 516/5000. Dataloading: 0.0025 s/iter. Inference: 0.0674 s/iter. Eval: 0.0710 s/iter. Total: 0.1409 s/iter. ETA=0:10:32
[12/13 07:46:29 d2.evaluation.evaluator]: Inference done 550/5000. Dataloading: 0.0025 s/iter. Inference: 0.0674 s/iter. Eval: 0.0715 s/iter. Total: 0.1415 s/iter. ETA=0:10:29
[12/13 07:46:34 d2.evaluation.evaluator]: Inference done 585/5000. Dataloading: 0.0025 s/iter. Inference: 0.0673 s/iter. Eval: 0.0717 s/iter. Total: 0.1416 s/iter. ETA=0:10:24
[12/13 07:46:39 d2.evaluation.evaluator]: Inference done 621/5000. Dataloading: 0.0025 s/iter. Inference: 0.0673 s/iter. Eval: 0.0717 s/iter. Total: 0.1415 s/iter. ETA=0:10:19
[12/13 07:46:44 d2.evaluation.evaluator]: Inference done 656/5000. Dataloading: 0.0025 s/iter. Inference: 0.0672 s/iter. Eval: 0.0720 s/iter. Total: 0.1418 s/iter. ETA=0:10:15
[12/13 07:46:49 d2.evaluation.evaluator]: Inference done 693/5000. Dataloading: 0.0025 s/iter. Inference: 0.0671 s/iter. Eval: 0.0719 s/iter. Total: 0.1416 s/iter. ETA=0:10:09
[12/13 07:46:54 d2.evaluation.evaluator]: Inference done 727/5000. Dataloading: 0.0025 s/iter. Inference: 0.0671 s/iter. Eval: 0.0721 s/iter. Total: 0.1418 s/iter. ETA=0:10:06
[12/13 07:46:59 d2.evaluation.evaluator]: Inference done 764/5000. Dataloading: 0.0025 s/iter. Inference: 0.0670 s/iter. Eval: 0.0720 s/iter. Total: 0.1416 s/iter. ETA=0:09:59
[12/13 07:47:04 d2.evaluation.evaluator]: Inference done 797/5000. Dataloading: 0.0025 s/iter. Inference: 0.0674 s/iter. Eval: 0.0721 s/iter. Total: 0.1420 s/iter. ETA=0:09:56
[12/13 07:47:09 d2.evaluation.evaluator]: Inference done 835/5000. Dataloading: 0.0025 s/iter. Inference: 0.0673 s/iter. Eval: 0.0718 s/iter. Total: 0.1417 s/iter. ETA=0:09:50
[12/13 07:47:15 d2.evaluation.evaluator]: Inference done 873/5000. Dataloading: 0.0025 s/iter. Inference: 0.0673 s/iter. Eval: 0.0715 s/iter. Total: 0.1413 s/iter. ETA=0:09:43
[12/13 07:47:20 d2.evaluation.evaluator]: Inference done 910/5000. Dataloading: 0.0025 s/iter. Inference: 0.0672 s/iter. Eval: 0.0714 s/iter. Total: 0.1411 s/iter. ETA=0:09:37
[12/13 07:47:25 d2.evaluation.evaluator]: Inference done 947/5000. Dataloading: 0.0025 s/iter. Inference: 0.0671 s/iter. Eval: 0.0712 s/iter. Total: 0.1409 s/iter. ETA=0:09:31
[12/13 07:47:30 d2.evaluation.evaluator]: Inference done 983/5000. Dataloading: 0.0025 s/iter. Inference: 0.0671 s/iter. Eval: 0.0713 s/iter. Total: 0.1410 s/iter. ETA=0:09:26
[12/13 07:47:35 d2.evaluation.evaluator]: Inference done 1020/5000. Dataloading: 0.0025 s/iter. Inference: 0.0670 s/iter. Eval: 0.0712 s/iter. Total: 0.1408 s/iter. ETA=0:09:20
[12/13 07:47:40 d2.evaluation.evaluator]: Inference done 1058/5000. Dataloading: 0.0025 s/iter. Inference: 0.0670 s/iter. Eval: 0.0710 s/iter. Total: 0.1406 s/iter. ETA=0:09:14
[12/13 07:47:45 d2.evaluation.evaluator]: Inference done 1095/5000. Dataloading: 0.0025 s/iter. Inference: 0.0669 s/iter. Eval: 0.0709 s/iter. Total: 0.1404 s/iter. ETA=0:09:08
[12/13 07:47:50 d2.evaluation.evaluator]: Inference done 1132/5000. Dataloading: 0.0025 s/iter. Inference: 0.0669 s/iter. Eval: 0.0708 s/iter. Total: 0.1403 s/iter. ETA=0:09:02
[12/13 07:47:55 d2.evaluation.evaluator]: Inference done 1169/5000. Dataloading: 0.0025 s/iter. Inference: 0.0669 s/iter. Eval: 0.0707 s/iter. Total: 0.1402 s/iter. ETA=0:08:57
[12/13 07:48:00 d2.evaluation.evaluator]: Inference done 1204/5000. Dataloading: 0.0025 s/iter. Inference: 0.0669 s/iter. Eval: 0.0709 s/iter. Total: 0.1403 s/iter. ETA=0:08:52
[12/13 07:48:05 d2.evaluation.evaluator]: Inference done 1238/5000. Dataloading: 0.0025 s/iter. Inference: 0.0669 s/iter. Eval: 0.0711 s/iter. Total: 0.1406 s/iter. ETA=0:08:48
[12/13 07:48:10 d2.evaluation.evaluator]: Inference done 1272/5000. Dataloading: 0.0025 s/iter. Inference: 0.0669 s/iter. Eval: 0.0713 s/iter. Total: 0.1408 s/iter. ETA=0:08:44
[12/13 07:48:15 d2.evaluation.evaluator]: Inference done 1309/5000. Dataloading: 0.0025 s/iter. Inference: 0.0668 s/iter. Eval: 0.0713 s/iter. Total: 0.1407 s/iter. ETA=0:08:39
[12/13 07:48:20 d2.evaluation.evaluator]: Inference done 1346/5000. Dataloading: 0.0025 s/iter. Inference: 0.0668 s/iter. Eval: 0.0712 s/iter. Total: 0.1406 s/iter. ETA=0:08:33
[12/13 07:48:25 d2.evaluation.evaluator]: Inference done 1382/5000. Dataloading: 0.0025 s/iter. Inference: 0.0668 s/iter. Eval: 0.0712 s/iter. Total: 0.1405 s/iter. ETA=0:08:28
[12/13 07:48:30 d2.evaluation.evaluator]: Inference done 1419/5000. Dataloading: 0.0025 s/iter. Inference: 0.0667 s/iter. Eval: 0.0711 s/iter. Total: 0.1404 s/iter. ETA=0:08:22
[12/13 07:48:36 d2.evaluation.evaluator]: Inference done 1456/5000. Dataloading: 0.0025 s/iter. Inference: 0.0667 s/iter. Eval: 0.0711 s/iter. Total: 0.1404 s/iter. ETA=0:08:17
[12/13 07:48:41 d2.evaluation.evaluator]: Inference done 1491/5000. Dataloading: 0.0025 s/iter. Inference: 0.0666 s/iter. Eval: 0.0712 s/iter. Total: 0.1404 s/iter. ETA=0:08:12
[12/13 07:48:46 d2.evaluation.evaluator]: Inference done 1527/5000. Dataloading: 0.0025 s/iter. Inference: 0.0666 s/iter. Eval: 0.0713 s/iter. Total: 0.1404 s/iter. ETA=0:08:07
[12/13 07:48:51 d2.evaluation.evaluator]: Inference done 1562/5000. Dataloading: 0.0025 s/iter. Inference: 0.0666 s/iter. Eval: 0.0714 s/iter. Total: 0.1406 s/iter. ETA=0:08:03
[12/13 07:48:56 d2.evaluation.evaluator]: Inference done 1595/5000. Dataloading: 0.0025 s/iter. Inference: 0.0668 s/iter. Eval: 0.0715 s/iter. Total: 0.1409 s/iter. ETA=0:07:59
[12/13 07:49:01 d2.evaluation.evaluator]: Inference done 1631/5000. Dataloading: 0.0025 s/iter. Inference: 0.0668 s/iter. Eval: 0.0715 s/iter. Total: 0.1409 s/iter. ETA=0:07:54
[12/13 07:49:06 d2.evaluation.evaluator]: Inference done 1667/5000. Dataloading: 0.0025 s/iter. Inference: 0.0668 s/iter. Eval: 0.0715 s/iter. Total: 0.1409 s/iter. ETA=0:07:49
[12/13 07:49:11 d2.evaluation.evaluator]: Inference done 1702/5000. Dataloading: 0.0025 s/iter. Inference: 0.0668 s/iter. Eval: 0.0715 s/iter. Total: 0.1409 s/iter. ETA=0:07:44
[12/13 07:49:16 d2.evaluation.evaluator]: Inference done 1738/5000. Dataloading: 0.0025 s/iter. Inference: 0.0668 s/iter. Eval: 0.0716 s/iter. Total: 0.1410 s/iter. ETA=0:07:39
[12/13 07:49:21 d2.evaluation.evaluator]: Inference done 1776/5000. Dataloading: 0.0025 s/iter. Inference: 0.0668 s/iter. Eval: 0.0714 s/iter. Total: 0.1408 s/iter. ETA=0:07:33
[12/13 07:49:26 d2.evaluation.evaluator]: Inference done 1812/5000. Dataloading: 0.0025 s/iter. Inference: 0.0668 s/iter. Eval: 0.0714 s/iter. Total: 0.1408 s/iter. ETA=0:07:28
[12/13 07:49:31 d2.evaluation.evaluator]: Inference done 1847/5000. Dataloading: 0.0025 s/iter. Inference: 0.0668 s/iter. Eval: 0.0715 s/iter. Total: 0.1409 s/iter. ETA=0:07:24
[12/13 07:49:36 d2.evaluation.evaluator]: Inference done 1882/5000. Dataloading: 0.0025 s/iter. Inference: 0.0668 s/iter. Eval: 0.0716 s/iter. Total: 0.1409 s/iter. ETA=0:07:19
[12/13 07:49:42 d2.evaluation.evaluator]: Inference done 1921/5000. Dataloading: 0.0025 s/iter. Inference: 0.0667 s/iter. Eval: 0.0714 s/iter. Total: 0.1407 s/iter. ETA=0:07:13
[12/13 07:49:47 d2.evaluation.evaluator]: Inference done 1958/5000. Dataloading: 0.0025 s/iter. Inference: 0.0667 s/iter. Eval: 0.0713 s/iter. Total: 0.1406 s/iter. ETA=0:07:07
[12/13 07:49:52 d2.evaluation.evaluator]: Inference done 1993/5000. Dataloading: 0.0025 s/iter. Inference: 0.0667 s/iter. Eval: 0.0714 s/iter. Total: 0.1407 s/iter. ETA=0:07:03
[12/13 07:49:57 d2.evaluation.evaluator]: Inference done 2028/5000. Dataloading: 0.0025 s/iter. Inference: 0.0667 s/iter. Eval: 0.0714 s/iter. Total: 0.1408 s/iter. ETA=0:06:58
[12/13 07:50:02 d2.evaluation.evaluator]: Inference done 2065/5000. Dataloading: 0.0025 s/iter. Inference: 0.0667 s/iter. Eval: 0.0714 s/iter. Total: 0.1407 s/iter. ETA=0:06:53
[12/13 07:50:07 d2.evaluation.evaluator]: Inference done 2101/5000. Dataloading: 0.0025 s/iter. Inference: 0.0667 s/iter. Eval: 0.0714 s/iter. Total: 0.1407 s/iter. ETA=0:06:48
[12/13 07:50:12 d2.evaluation.evaluator]: Inference done 2138/5000. Dataloading: 0.0025 s/iter. Inference: 0.0667 s/iter. Eval: 0.0714 s/iter. Total: 0.1407 s/iter. ETA=0:06:42
[12/13 07:50:17 d2.evaluation.evaluator]: Inference done 2173/5000. Dataloading: 0.0025 s/iter. Inference: 0.0667 s/iter. Eval: 0.0715 s/iter. Total: 0.1408 s/iter. ETA=0:06:37
[12/13 07:50:22 d2.evaluation.evaluator]: Inference done 2211/5000. Dataloading: 0.0025 s/iter. Inference: 0.0667 s/iter. Eval: 0.0713 s/iter. Total: 0.1406 s/iter. ETA=0:06:32
[12/13 07:50:27 d2.evaluation.evaluator]: Inference done 2246/5000. Dataloading: 0.0025 s/iter. Inference: 0.0667 s/iter. Eval: 0.0714 s/iter. Total: 0.1407 s/iter. ETA=0:06:27
[12/13 07:50:32 d2.evaluation.evaluator]: Inference done 2283/5000. Dataloading: 0.0025 s/iter. Inference: 0.0667 s/iter. Eval: 0.0713 s/iter. Total: 0.1406 s/iter. ETA=0:06:21
[12/13 07:50:37 d2.evaluation.evaluator]: Inference done 2319/5000. Dataloading: 0.0025 s/iter. Inference: 0.0667 s/iter. Eval: 0.0713 s/iter. Total: 0.1406 s/iter. ETA=0:06:16
[12/13 07:50:42 d2.evaluation.evaluator]: Inference done 2358/5000. Dataloading: 0.0025 s/iter. Inference: 0.0667 s/iter. Eval: 0.0711 s/iter. Total: 0.1404 s/iter. ETA=0:06:10
[12/13 07:50:47 d2.evaluation.evaluator]: Inference done 2394/5000. Dataloading: 0.0025 s/iter. Inference: 0.0667 s/iter. Eval: 0.0712 s/iter. Total: 0.1404 s/iter. ETA=0:06:05
[12/13 07:50:52 d2.evaluation.evaluator]: Inference done 2428/5000. Dataloading: 0.0025 s/iter. Inference: 0.0667 s/iter. Eval: 0.0713 s/iter. Total: 0.1406 s/iter. ETA=0:06:01
[12/13 07:50:57 d2.evaluation.evaluator]: Inference done 2464/5000. Dataloading: 0.0025 s/iter. Inference: 0.0667 s/iter. Eval: 0.0713 s/iter. Total: 0.1405 s/iter. ETA=0:05:56
[12/13 07:51:03 d2.evaluation.evaluator]: Inference done 2499/5000. Dataloading: 0.0025 s/iter. Inference: 0.0667 s/iter. Eval: 0.0713 s/iter. Total: 0.1406 s/iter. ETA=0:05:51
[12/13 07:51:08 d2.evaluation.evaluator]: Inference done 2535/5000. Dataloading: 0.0025 s/iter. Inference: 0.0667 s/iter. Eval: 0.0714 s/iter. Total: 0.1406 s/iter. ETA=0:05:46
[12/13 07:51:13 d2.evaluation.evaluator]: Inference done 2571/5000. Dataloading: 0.0025 s/iter. Inference: 0.0667 s/iter. Eval: 0.0714 s/iter. Total: 0.1407 s/iter. ETA=0:05:41
[12/13 07:51:18 d2.evaluation.evaluator]: Inference done 2607/5000. Dataloading: 0.0025 s/iter. Inference: 0.0667 s/iter. Eval: 0.0714 s/iter. Total: 0.1407 s/iter. ETA=0:05:36
[12/13 07:51:23 d2.evaluation.evaluator]: Inference done 2639/5000. Dataloading: 0.0025 s/iter. Inference: 0.0667 s/iter. Eval: 0.0716 s/iter. Total: 0.1409 s/iter. ETA=0:05:32
[12/13 07:51:28 d2.evaluation.evaluator]: Inference done 2676/5000. Dataloading: 0.0025 s/iter. Inference: 0.0667 s/iter. Eval: 0.0715 s/iter. Total: 0.1408 s/iter. ETA=0:05:27
[12/13 07:51:33 d2.evaluation.evaluator]: Inference done 2714/5000. Dataloading: 0.0025 s/iter. Inference: 0.0667 s/iter. Eval: 0.0714 s/iter. Total: 0.1407 s/iter. ETA=0:05:21
[12/13 07:51:38 d2.evaluation.evaluator]: Inference done 2751/5000. Dataloading: 0.0025 s/iter. Inference: 0.0667 s/iter. Eval: 0.0714 s/iter. Total: 0.1407 s/iter. ETA=0:05:16
[12/13 07:51:43 d2.evaluation.evaluator]: Inference done 2787/5000. Dataloading: 0.0025 s/iter. Inference: 0.0667 s/iter. Eval: 0.0714 s/iter. Total: 0.1407 s/iter. ETA=0:05:11
[12/13 07:51:49 d2.evaluation.evaluator]: Inference done 2824/5000. Dataloading: 0.0025 s/iter. Inference: 0.0667 s/iter. Eval: 0.0714 s/iter. Total: 0.1407 s/iter. ETA=0:05:06
[12/13 07:51:54 d2.evaluation.evaluator]: Inference done 2861/5000. Dataloading: 0.0025 s/iter. Inference: 0.0667 s/iter. Eval: 0.0713 s/iter. Total: 0.1406 s/iter. ETA=0:05:00
[12/13 07:51:59 d2.evaluation.evaluator]: Inference done 2898/5000. Dataloading: 0.0025 s/iter. Inference: 0.0667 s/iter. Eval: 0.0713 s/iter. Total: 0.1406 s/iter. ETA=0:04:55
[12/13 07:52:04 d2.evaluation.evaluator]: Inference done 2933/5000. Dataloading: 0.0025 s/iter. Inference: 0.0667 s/iter. Eval: 0.0714 s/iter. Total: 0.1407 s/iter. ETA=0:04:50
[12/13 07:52:09 d2.evaluation.evaluator]: Inference done 2972/5000. Dataloading: 0.0025 s/iter. Inference: 0.0667 s/iter. Eval: 0.0713 s/iter. Total: 0.1406 s/iter. ETA=0:04:45
[12/13 07:52:14 d2.evaluation.evaluator]: Inference done 3009/5000. Dataloading: 0.0025 s/iter. Inference: 0.0667 s/iter. Eval: 0.0712 s/iter. Total: 0.1405 s/iter. ETA=0:04:39
[12/13 07:52:19 d2.evaluation.evaluator]: Inference done 3046/5000. Dataloading: 0.0025 s/iter. Inference: 0.0667 s/iter. Eval: 0.0712 s/iter. Total: 0.1405 s/iter. ETA=0:04:34
[12/13 07:52:24 d2.evaluation.evaluator]: Inference done 3083/5000. Dataloading: 0.0025 s/iter. Inference: 0.0667 s/iter. Eval: 0.0711 s/iter. Total: 0.1404 s/iter. ETA=0:04:29
[12/13 07:52:29 d2.evaluation.evaluator]: Inference done 3121/5000. Dataloading: 0.0025 s/iter. Inference: 0.0667 s/iter. Eval: 0.0711 s/iter. Total: 0.1404 s/iter. ETA=0:04:23
[12/13 07:52:34 d2.evaluation.evaluator]: Inference done 3157/5000. Dataloading: 0.0025 s/iter. Inference: 0.0667 s/iter. Eval: 0.0711 s/iter. Total: 0.1404 s/iter. ETA=0:04:18
[12/13 07:52:39 d2.evaluation.evaluator]: Inference done 3193/5000. Dataloading: 0.0025 s/iter. Inference: 0.0667 s/iter. Eval: 0.0711 s/iter. Total: 0.1404 s/iter. ETA=0:04:13
[12/13 07:52:45 d2.evaluation.evaluator]: Inference done 3228/5000. Dataloading: 0.0025 s/iter. Inference: 0.0667 s/iter. Eval: 0.0712 s/iter. Total: 0.1405 s/iter. ETA=0:04:08
[12/13 07:52:50 d2.evaluation.evaluator]: Inference done 3264/5000. Dataloading: 0.0025 s/iter. Inference: 0.0667 s/iter. Eval: 0.0712 s/iter. Total: 0.1405 s/iter. ETA=0:04:03
[12/13 07:52:55 d2.evaluation.evaluator]: Inference done 3299/5000. Dataloading: 0.0025 s/iter. Inference: 0.0667 s/iter. Eval: 0.0712 s/iter. Total: 0.1405 s/iter. ETA=0:03:58
[12/13 07:53:00 d2.evaluation.evaluator]: Inference done 3334/5000. Dataloading: 0.0025 s/iter. Inference: 0.0667 s/iter. Eval: 0.0713 s/iter. Total: 0.1405 s/iter. ETA=0:03:54
[12/13 07:53:05 d2.evaluation.evaluator]: Inference done 3368/5000. Dataloading: 0.0025 s/iter. Inference: 0.0667 s/iter. Eval: 0.0713 s/iter. Total: 0.1406 s/iter. ETA=0:03:49
[12/13 07:53:10 d2.evaluation.evaluator]: Inference done 3404/5000. Dataloading: 0.0025 s/iter. Inference: 0.0667 s/iter. Eval: 0.0714 s/iter. Total: 0.1406 s/iter. ETA=0:03:44
[12/13 07:53:15 d2.evaluation.evaluator]: Inference done 3439/5000. Dataloading: 0.0025 s/iter. Inference: 0.0667 s/iter. Eval: 0.0714 s/iter. Total: 0.1407 s/iter. ETA=0:03:39
[12/13 07:53:20 d2.evaluation.evaluator]: Inference done 3478/5000. Dataloading: 0.0025 s/iter. Inference: 0.0666 s/iter. Eval: 0.0713 s/iter. Total: 0.1405 s/iter. ETA=0:03:33
[12/13 07:53:25 d2.evaluation.evaluator]: Inference done 3516/5000. Dataloading: 0.0025 s/iter. Inference: 0.0666 s/iter. Eval: 0.0713 s/iter. Total: 0.1405 s/iter. ETA=0:03:28
[12/13 07:53:30 d2.evaluation.evaluator]: Inference done 3551/5000. Dataloading: 0.0025 s/iter. Inference: 0.0666 s/iter. Eval: 0.0713 s/iter. Total: 0.1405 s/iter. ETA=0:03:23
[12/13 07:53:35 d2.evaluation.evaluator]: Inference done 3587/5000. Dataloading: 0.0025 s/iter. Inference: 0.0666 s/iter. Eval: 0.0713 s/iter. Total: 0.1405 s/iter. ETA=0:03:18
[12/13 07:53:40 d2.evaluation.evaluator]: Inference done 3625/5000. Dataloading: 0.0025 s/iter. Inference: 0.0666 s/iter. Eval: 0.0712 s/iter. Total: 0.1404 s/iter. ETA=0:03:13
[12/13 07:53:45 d2.evaluation.evaluator]: Inference done 3663/5000. Dataloading: 0.0025 s/iter. Inference: 0.0666 s/iter. Eval: 0.0712 s/iter. Total: 0.1404 s/iter. ETA=0:03:07
[12/13 07:53:50 d2.evaluation.evaluator]: Inference done 3699/5000. Dataloading: 0.0025 s/iter. Inference: 0.0666 s/iter. Eval: 0.0712 s/iter. Total: 0.1404 s/iter. ETA=0:03:02
[12/13 07:53:55 d2.evaluation.evaluator]: Inference done 3736/5000. Dataloading: 0.0025 s/iter. Inference: 0.0666 s/iter. Eval: 0.0711 s/iter. Total: 0.1403 s/iter. ETA=0:02:57
[12/13 07:54:01 d2.evaluation.evaluator]: Inference done 3772/5000. Dataloading: 0.0025 s/iter. Inference: 0.0666 s/iter. Eval: 0.0712 s/iter. Total: 0.1403 s/iter. ETA=0:02:52
[12/13 07:54:06 d2.evaluation.evaluator]: Inference done 3807/5000. Dataloading: 0.0025 s/iter. Inference: 0.0666 s/iter. Eval: 0.0712 s/iter. Total: 0.1404 s/iter. ETA=0:02:47
[12/13 07:54:11 d2.evaluation.evaluator]: Inference done 3845/5000. Dataloading: 0.0025 s/iter. Inference: 0.0666 s/iter. Eval: 0.0711 s/iter. Total: 0.1403 s/iter. ETA=0:02:42
[12/13 07:54:16 d2.evaluation.evaluator]: Inference done 3883/5000. Dataloading: 0.0025 s/iter. Inference: 0.0666 s/iter. Eval: 0.0710 s/iter. Total: 0.1402 s/iter. ETA=0:02:36
[12/13 07:54:21 d2.evaluation.evaluator]: Inference done 3920/5000. Dataloading: 0.0025 s/iter. Inference: 0.0666 s/iter. Eval: 0.0710 s/iter. Total: 0.1402 s/iter. ETA=0:02:31
[12/13 07:54:26 d2.evaluation.evaluator]: Inference done 3953/5000. Dataloading: 0.0025 s/iter. Inference: 0.0667 s/iter. Eval: 0.0710 s/iter. Total: 0.1403 s/iter. ETA=0:02:26
[12/13 07:54:31 d2.evaluation.evaluator]: Inference done 3991/5000. Dataloading: 0.0025 s/iter. Inference: 0.0667 s/iter. Eval: 0.0710 s/iter. Total: 0.1402 s/iter. ETA=0:02:21
[12/13 07:54:36 d2.evaluation.evaluator]: Inference done 4025/5000. Dataloading: 0.0025 s/iter. Inference: 0.0667 s/iter. Eval: 0.0711 s/iter. Total: 0.1403 s/iter. ETA=0:02:16
[12/13 07:54:41 d2.evaluation.evaluator]: Inference done 4060/5000. Dataloading: 0.0025 s/iter. Inference: 0.0667 s/iter. Eval: 0.0711 s/iter. Total: 0.1404 s/iter. ETA=0:02:11
[12/13 07:54:46 d2.evaluation.evaluator]: Inference done 4095/5000. Dataloading: 0.0025 s/iter. Inference: 0.0667 s/iter. Eval: 0.0711 s/iter. Total: 0.1404 s/iter. ETA=0:02:07
[12/13 07:54:51 d2.evaluation.evaluator]: Inference done 4132/5000. Dataloading: 0.0025 s/iter. Inference: 0.0666 s/iter. Eval: 0.0711 s/iter. Total: 0.1404 s/iter. ETA=0:02:01
[12/13 07:54:56 d2.evaluation.evaluator]: Inference done 4165/5000. Dataloading: 0.0025 s/iter. Inference: 0.0667 s/iter. Eval: 0.0712 s/iter. Total: 0.1405 s/iter. ETA=0:01:57
[12/13 07:55:01 d2.evaluation.evaluator]: Inference done 4201/5000. Dataloading: 0.0025 s/iter. Inference: 0.0666 s/iter. Eval: 0.0712 s/iter. Total: 0.1405 s/iter. ETA=0:01:52
[12/13 07:55:06 d2.evaluation.evaluator]: Inference done 4239/5000. Dataloading: 0.0025 s/iter. Inference: 0.0666 s/iter. Eval: 0.0712 s/iter. Total: 0.1404 s/iter. ETA=0:01:46
[12/13 07:55:11 d2.evaluation.evaluator]: Inference done 4276/5000. Dataloading: 0.0025 s/iter. Inference: 0.0666 s/iter. Eval: 0.0711 s/iter. Total: 0.1404 s/iter. ETA=0:01:41
[12/13 07:55:16 d2.evaluation.evaluator]: Inference done 4311/5000. Dataloading: 0.0025 s/iter. Inference: 0.0666 s/iter. Eval: 0.0712 s/iter. Total: 0.1404 s/iter. ETA=0:01:36
[12/13 07:55:22 d2.evaluation.evaluator]: Inference done 4349/5000. Dataloading: 0.0025 s/iter. Inference: 0.0666 s/iter. Eval: 0.0711 s/iter. Total: 0.1403 s/iter. ETA=0:01:31
[12/13 07:55:27 d2.evaluation.evaluator]: Inference done 4387/5000. Dataloading: 0.0025 s/iter. Inference: 0.0666 s/iter. Eval: 0.0711 s/iter. Total: 0.1403 s/iter. ETA=0:01:25
[12/13 07:55:32 d2.evaluation.evaluator]: Inference done 4423/5000. Dataloading: 0.0025 s/iter. Inference: 0.0666 s/iter. Eval: 0.0711 s/iter. Total: 0.1403 s/iter. ETA=0:01:20
[12/13 07:55:37 d2.evaluation.evaluator]: Inference done 4460/5000. Dataloading: 0.0025 s/iter. Inference: 0.0666 s/iter. Eval: 0.0711 s/iter. Total: 0.1403 s/iter. ETA=0:01:15
[12/13 07:55:42 d2.evaluation.evaluator]: Inference done 4496/5000. Dataloading: 0.0025 s/iter. Inference: 0.0666 s/iter. Eval: 0.0711 s/iter. Total: 0.1403 s/iter. ETA=0:01:10
[12/13 07:55:47 d2.evaluation.evaluator]: Inference done 4534/5000. Dataloading: 0.0025 s/iter. Inference: 0.0666 s/iter. Eval: 0.0710 s/iter. Total: 0.1402 s/iter. ETA=0:01:05
[12/13 07:55:52 d2.evaluation.evaluator]: Inference done 4569/5000. Dataloading: 0.0025 s/iter. Inference: 0.0666 s/iter. Eval: 0.0711 s/iter. Total: 0.1402 s/iter. ETA=0:01:00
[12/13 07:55:57 d2.evaluation.evaluator]: Inference done 4606/5000. Dataloading: 0.0025 s/iter. Inference: 0.0666 s/iter. Eval: 0.0711 s/iter. Total: 0.1402 s/iter. ETA=0:00:55
[12/13 07:56:02 d2.evaluation.evaluator]: Inference done 4642/5000. Dataloading: 0.0025 s/iter. Inference: 0.0666 s/iter. Eval: 0.0710 s/iter. Total: 0.1402 s/iter. ETA=0:00:50
[12/13 07:56:07 d2.evaluation.evaluator]: Inference done 4677/5000. Dataloading: 0.0025 s/iter. Inference: 0.0666 s/iter. Eval: 0.0711 s/iter. Total: 0.1402 s/iter. ETA=0:00:45
[12/13 07:56:12 d2.evaluation.evaluator]: Inference done 4714/5000. Dataloading: 0.0025 s/iter. Inference: 0.0666 s/iter. Eval: 0.0710 s/iter. Total: 0.1402 s/iter. ETA=0:00:40
[12/13 07:56:17 d2.evaluation.evaluator]: Inference done 4751/5000. Dataloading: 0.0025 s/iter. Inference: 0.0665 s/iter. Eval: 0.0710 s/iter. Total: 0.1402 s/iter. ETA=0:00:34
[12/13 07:56:22 d2.evaluation.evaluator]: Inference done 4790/5000. Dataloading: 0.0025 s/iter. Inference: 0.0665 s/iter. Eval: 0.0710 s/iter. Total: 0.1401 s/iter. ETA=0:00:29
[12/13 07:56:27 d2.evaluation.evaluator]: Inference done 4825/5000. Dataloading: 0.0025 s/iter. Inference: 0.0665 s/iter. Eval: 0.0710 s/iter. Total: 0.1401 s/iter. ETA=0:00:24
[12/13 07:56:32 d2.evaluation.evaluator]: Inference done 4863/5000. Dataloading: 0.0025 s/iter. Inference: 0.0665 s/iter. Eval: 0.0709 s/iter. Total: 0.1401 s/iter. ETA=0:00:19
[12/13 07:56:37 d2.evaluation.evaluator]: Inference done 4900/5000. Dataloading: 0.0025 s/iter. Inference: 0.0665 s/iter. Eval: 0.0709 s/iter. Total: 0.1401 s/iter. ETA=0:00:14
[12/13 07:56:43 d2.evaluation.evaluator]: Inference done 4935/5000. Dataloading: 0.0025 s/iter. Inference: 0.0665 s/iter. Eval: 0.0710 s/iter. Total: 0.1401 s/iter. ETA=0:00:09
[12/13 07:56:48 d2.evaluation.evaluator]: Inference done 4972/5000. Dataloading: 0.0025 s/iter. Inference: 0.0665 s/iter. Eval: 0.0709 s/iter. Total: 0.1401 s/iter. ETA=0:00:03
[12/13 07:56:52 d2.evaluation.evaluator]: Total inference time: 0:11:39.783056 (0.140097 s / iter per device, on 1 devices)
[12/13 07:56:52 d2.evaluation.evaluator]: Total inference pure compute time: 0:05:32 (0.066527 s / iter per device, on 1 devices)
[12/13 07:56:52 d2.evaluation.sem_seg_evaluation]: OrderedDict([('sem_seg', {'mIoU': 27.982735832136846, 'fwIoU': 58.57678658891743, 'IoU-things': 74.8154939651096, 'BoundaryIoU-things': 80.20225638460815, 'min(IoU, B-Iou)-things': 74.8154939651096, 'IoU-banner': 10.542106783394468, 'BoundaryIoU-banner': 1.7680250011093457, 'min(IoU, B-Iou)-banner': 1.7680250011093457, 'IoU-blanket': 0.02065378621453651, 'BoundaryIoU-blanket': 2.534718418946013, 'min(IoU, B-Iou)-blanket': 0.02065378621453651, 'IoU-bridge': 14.364969483179497, 'BoundaryIoU-bridge': 5.460752321859764, 'min(IoU, B-Iou)-bridge': 5.460752321859764, 'IoU-cardboard': 1.790508826458043, 'BoundaryIoU-cardboard': 5.596348066016149, 'min(IoU, B-Iou)-cardboard': 1.790508826458043, 'IoU-counter': 11.001787147206038, 'BoundaryIoU-counter': 0.0, 'min(IoU, B-Iou)-counter': 0.0, 'IoU-curtain': 36.76549644281433, 'BoundaryIoU-curtain': 0.0, 'min(IoU, B-Iou)-curtain': 0.0, 'IoU-door-stuff': 13.808874907642588, 'BoundaryIoU-door-stuff': 0.0, 'min(IoU, B-Iou)-door-stuff': 0.0, 'IoU-floor-wood': 37.294919700780824, 'BoundaryIoU-floor-wood': 0.0, 'min(IoU, B-Iou)-floor-wood': 0.0, 'IoU-flower': 10.446004787299335, 'BoundaryIoU-flower': 0.0, 'min(IoU, B-Iou)-flower': 0.0, 'IoU-fruit': 2.4409477281384944, 'BoundaryIoU-fruit': 0.0, 'min(IoU, B-Iou)-fruit': 0.0, 'IoU-gravel': 15.56205101784821, 'BoundaryIoU-gravel': 0.0, 'min(IoU, B-Iou)-gravel': 0.0, 'IoU-house': 9.392442133625499, 'BoundaryIoU-house': 0.0, 'min(IoU, B-Iou)-house': 0.0, 'IoU-light': 16.463711806354663, 'BoundaryIoU-light': 0.0, 'min(IoU, B-Iou)-light': 0.0, 'IoU-mirror-stuff': 9.996055380249715, 'BoundaryIoU-mirror-stuff': 0.0, 'min(IoU, B-Iou)-mirror-stuff': 0.0, 'IoU-net': 28.131154527590407, 'BoundaryIoU-net': 0.0, 'min(IoU, B-Iou)-net': 0.0, 'IoU-pillow': 0.0, 'BoundaryIoU-pillow': 0.0, 'min(IoU, B-Iou)-pillow': 0.0, 'IoU-platform': 15.19541848489542, 'BoundaryIoU-platform': 0.0, 'min(IoU, B-Iou)-platform': 0.0, 'IoU-playingfield': 64.11687824678123, 'BoundaryIoU-playingfield': 0.0, 'min(IoU, B-Iou)-playingfield': 0.0, 'IoU-railroad': 48.28135768435562, 'BoundaryIoU-railroad': 0.0, 'min(IoU, B-Iou)-railroad': 0.0, 'IoU-river': 29.965198376314767, 'BoundaryIoU-river': 0.0, 'min(IoU, B-Iou)-river': 0.0, 'IoU-road': 46.91580725283644, 'BoundaryIoU-road': 0.0, 'min(IoU, B-Iou)-road': 0.0, 'IoU-roof': 10.409709828971348, 'BoundaryIoU-roof': 0.0, 'min(IoU, B-Iou)-roof': 0.0, 'IoU-sand': 27.821760420090126, 'BoundaryIoU-sand': 0.0, 'min(IoU, B-Iou)-sand': 0.0, 'IoU-sea': 70.8549535124529, 'BoundaryIoU-sea': 0.0, 'min(IoU, B-Iou)-sea': 0.0, 'IoU-shelf': 8.295631557013907, 'BoundaryIoU-shelf': 0.0, 'min(IoU, B-Iou)-shelf': 0.0, 'IoU-snow': 72.03715052297511, 'BoundaryIoU-snow': 0.0, 'min(IoU, B-Iou)-snow': 0.0, 'IoU-stairs': 1.4702360717341902, 'BoundaryIoU-stairs': 0.0, 'min(IoU, B-Iou)-stairs': 0.0, 'IoU-tent': 0.16579222637047328, 'BoundaryIoU-tent': 0.0, 'min(IoU, B-Iou)-tent': 0.0, 'IoU-towel': 9.30481613737402, 'BoundaryIoU-towel': 0.0, 'min(IoU, B-Iou)-towel': 0.0, 'IoU-wall-brick': 25.28745400143085, 'BoundaryIoU-wall-brick': 0.0, 'min(IoU, B-Iou)-wall-brick': 0.0, 'IoU-wall-stone': 15.547182699994044, 'BoundaryIoU-wall-stone': 0.0, 'min(IoU, B-Iou)-wall-stone': 0.0, 'IoU-wall-tile': 40.288433605321444, 'BoundaryIoU-wall-tile': 0.0, 'min(IoU, B-Iou)-wall-tile': 0.0, 'IoU-wall-wood': 17.11038419569948, 'BoundaryIoU-wall-wood': 0.0, 'min(IoU, B-Iou)-wall-wood': 0.0, 'IoU-water': 10.576526385914036, 'BoundaryIoU-water': 0.0, 'min(IoU, B-Iou)-water': 0.0, 'IoU-window-blind': 27.09497014751011, 'BoundaryIoU-window-blind': 0.0, 'min(IoU, B-Iou)-window-blind': 0.0, 'IoU-window': 21.134105564243022, 'BoundaryIoU-window': 0.0, 'min(IoU, B-Iou)-window': 0.0, 'IoU-tree': 71.82348128063843, 'BoundaryIoU-tree': 0.0, 'min(IoU, B-Iou)-tree': 0.0, 'IoU-fence': 33.8144394802568, 'BoundaryIoU-fence': 0.0, 'min(IoU, B-Iou)-fence': 0.0, 'IoU-ceiling': 41.95802876044685, 'BoundaryIoU-ceiling': 0.0, 'min(IoU, B-Iou)-ceiling': 0.0, 'IoU-sky': 87.99676065016352, 'BoundaryIoU-sky': 0.0, 'min(IoU, B-Iou)-sky': 0.0, 'IoU-cabinet': 36.518502471201245, 'BoundaryIoU-cabinet': 0.0, 'min(IoU, B-Iou)-cabinet': 0.0, 'IoU-table': 11.60718772448118, 'BoundaryIoU-table': 0.0, 'min(IoU, B-Iou)-table': 0.0, 'IoU-floor': 29.557950803477013, 'BoundaryIoU-floor': 0.0, 'min(IoU, B-Iou)-floor': 0.0, 'IoU-pavement': 38.79899942290833, 'BoundaryIoU-pavement': 0.0, 'min(IoU, B-Iou)-pavement': 0.0, 'IoU-mountain': 35.1229737677795, 'BoundaryIoU-mountain': 0.0, 'min(IoU, B-Iou)-mountain': 0.0, 'IoU-grass': 66.26053699152179, 'BoundaryIoU-grass': 0.0, 'min(IoU, B-Iou)-grass': 0.0, 'IoU-dirt': 29.59196892856927, 'BoundaryIoU-dirt': 0.0, 'min(IoU, B-Iou)-dirt': 0.0, 'IoU-paper': 5.737954449703135, 'BoundaryIoU-paper': 0.0, 'min(IoU, B-Iou)-paper': 0.0, 'IoU-food': 6.334230912508956, 'BoundaryIoU-food': 0.0, 'min(IoU, B-Iou)-food': 0.0, 'IoU-building': 46.30417223315844, 'BoundaryIoU-building': 0.0, 'min(IoU, B-Iou)-building': 0.0, 'IoU-rock': 33.598766204533455, 'BoundaryIoU-rock': 0.0, 'min(IoU, B-Iou)-rock': 0.0, 'IoU-wall': 47.083581048186716, 'BoundaryIoU-wall': 0.0, 'min(IoU, B-Iou)-wall': 0.0, 'IoU-rug': 34.24725445966986, 'BoundaryIoU-rug': 0.0, 'min(IoU, B-Iou)-rug': 0.0, 'mACC': 37.37161350888972, 'pACC': 72.98791892644952, 'ACC-things': 93.77775645646382, 'ACC-banner': 16.177674912227435, 'ACC-blanket': 0.020683080325562864, 'ACC-bridge': 20.4401912782016, 'ACC-cardboard': 1.8088992293151085, 'ACC-counter': 16.420556778930134, 'ACC-curtain': 61.742580007257565, 'ACC-door-stuff': 22.86375815036386, 'ACC-floor-wood': 43.532737817355724, 'ACC-flower': 12.305718668330291, 'ACC-fruit': 2.537661960740329, 'ACC-gravel': 32.758924568365245, 'ACC-house': 10.597987966103554, 'ACC-light': 20.367288883359493, 'ACC-mirror-stuff': 11.624965300596608, 'ACC-net': 42.58501772518972, 'ACC-pillow': 0.0, 'ACC-platform': 18.91215873857459, 'ACC-playingfield': 83.80315932077963, 'ACC-railroad': 64.16941993536452, 'ACC-river': 60.275757130320216, 'ACC-road': 61.06112856899082, 'ACC-roof': 17.760841309228407, 'ACC-sand': 28.59244626535218, 'ACC-sea': 75.98052362447288, 'ACC-shelf': 9.208087581786819, 'ACC-snow': 77.018896643745, 'ACC-stairs': 1.487164850093546, 'ACC-tent': 0.1677045388961612, 'ACC-towel': 10.062029610293017, 'ACC-wall-brick': 41.60015559889222, 'ACC-wall-stone': 22.951536922995945, 'ACC-wall-tile': 78.35282676430727, 'ACC-wall-wood': 22.28648888445867, 'ACC-water': 19.877683237695322, 'ACC-window-blind': 41.60822091530497, 'ACC-window': 27.524224957132276, 'ACC-tree': 88.99247095028892, 'ACC-fence': 39.78175834040727, 'ACC-ceiling': 61.55322699357642, 'ACC-sky': 93.60370518810211, 'ACC-cabinet': 52.325565549067, 'ACC-table': 12.165886172975673, 'ACC-floor': 37.454620219733044, 'ACC-pavement': 62.236789095116784, 'ACC-mountain': 40.730759231519926, 'ACC-grass': 77.75159799402377, 'ACC-dirt': 37.586521969447055, 'ACC-paper': 6.062566982117875, 'ACC-food': 6.758676450217556, 'ACC-building': 55.463036775513395, 'ACC-rock': 40.7740084931419, 'ACC-wall': 71.45227029396042, 'ACC-rug': 61.11081059902552})])
[12/13 07:56:55 d2.evaluation.coco_evaluation]: Preparing results for COCO format ...
[12/13 07:56:55 d2.evaluation.coco_evaluation]: Saving results to ./output/inference/coco_instances_results.json
[12/13 07:56:57 d2.evaluation.coco_evaluation]: Evaluating predictions with unofficial COCO API...
Loading and preparing results...
DONE (t=0.21s)
creating index...
index created!
[12/13 07:56:57 d2.evaluation.fast_eval_api]: Evaluate annotation type *bbox*
[12/13 07:57:07 d2.evaluation.fast_eval_api]: COCOeval_opt.evaluate() finished in 9.98 seconds.
[12/13 07:57:07 d2.evaluation.fast_eval_api]: Accumulating evaluation results...
[12/13 07:57:09 d2.evaluation.fast_eval_api]: COCOeval_opt.accumulate() finished in 1.27 seconds.
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.155
 Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.343
 Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.119
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.086
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.181
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.212
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.163
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.282
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.300
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.153
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.331
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.399
[12/13 07:57:09 d2.evaluation.coco_evaluation]: Evaluation results for bbox: 
|   AP   |  AP50  |  AP75  |  APs  |  APm   |  APl   |
|:------:|:------:|:------:|:-----:|:------:|:------:|
| 15.499 | 34.268 | 11.876 | 8.556 | 18.113 | 21.169 |
[12/13 07:57:09 d2.evaluation.coco_evaluation]: Per-category bbox AP: 
| category      | AP     | category     | AP     | category       | AP     |
|:--------------|:-------|:-------------|:-------|:---------------|:-------|
| person        | 30.397 | bicycle      | 10.929 | car            | 19.623 |
| motorcycle    | 15.303 | airplane     | 28.436 | bus            | 30.459 |
| train         | 21.584 | truck        | 12.614 | boat           | 6.331  |
| traffic light | 11.256 | fire hydrant | 33.423 | stop sign      | 32.939 |
| parking meter | 23.291 | bench        | 7.102  | bird           | 14.324 |
| cat           | 30.964 | dog          | 30.244 | horse          | 21.213 |
| sheep         | 21.474 | cow          | 24.084 | elephant       | 31.865 |
| bear          | 39.475 | zebra        | 32.875 | giraffe        | 33.655 |
| backpack      | 4.382  | umbrella     | 14.066 | handbag        | 2.730  |
| tie           | 6.076  | suitcase     | 6.834  | frisbee        | 31.658 |
| skis          | 2.807  | snowboard    | 2.353  | sports ball    | 31.640 |
| kite          | 16.381 | baseball bat | 3.495  | baseball glove | 18.062 |
| skateboard    | 11.490 | surfboard    | 5.703  | tennis racket  | 16.954 |
| bottle        | 16.291 | wine glass   | 13.414 | cup            | 18.636 |
| fork          | 2.585  | knife        | 1.107  | spoon          | 0.808  |
| bowl          | 16.292 | banana       | 7.221  | apple          | 5.775  |
| sandwich      | 12.856 | orange       | 15.544 | broccoli       | 9.423  |
| carrot        | 4.061  | hot dog      | 8.528  | pizza          | 23.586 |
| donut         | 16.893 | cake         | 12.281 | chair          | 8.152  |
| couch         | 11.928 | potted plant | 8.408  | bed            | 12.256 |
| dining table  | 6.197  | toilet       | 28.256 | tv             | 28.410 |
| laptop        | 25.468 | mouse        | 30.077 | remote         | 5.467  |
| keyboard      | 16.565 | cell phone   | 12.284 | microwave      | 16.222 |
| oven          | 7.798  | toaster      | 0.000  | sink           | 12.188 |
| refrigerator  | 11.849 | book         | 2.047  | clock          | 32.583 |
| vase          | 16.174 | scissors     | 2.835  | teddy bear     | 20.618 |
| hair drier    | 0.000  | toothbrush   | 0.347  |                |        |
Loading and preparing results...
DONE (t=2.51s)
creating index...
index created!
[12/13 07:57:17 d2.evaluation.fast_eval_api]: Evaluate annotation type *segm*
[12/13 07:57:29 d2.evaluation.fast_eval_api]: COCOeval_opt.evaluate() finished in 12.31 seconds.
[12/13 07:57:29 d2.evaluation.fast_eval_api]: Accumulating evaluation results...
[12/13 07:57:31 d2.evaluation.fast_eval_api]: COCOeval_opt.accumulate() finished in 1.27 seconds.
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.161
 Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.318
 Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.147
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.062
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.181
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.246
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.172
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.277
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.291
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.137
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.320
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.400
[12/13 07:57:33 d2.evaluation.coco_evaluation]: Evaluation results for segm: 
|   AP   |  AP50  |  AP75  |  APs  |  APm   |  APl   |
|:------:|:------:|:------:|:-----:|:------:|:------:|
| 16.098 | 31.803 | 14.664 | 6.158 | 18.075 | 24.597 |
[12/13 07:57:33 d2.evaluation.coco_evaluation]: Per-category segm AP: 
| category      | AP     | category     | AP     | category       | AP     |
|:--------------|:-------|:-------------|:-------|:---------------|:-------|
| person        | 26.083 | bicycle      | 4.340  | car            | 18.758 |
| motorcycle    | 10.456 | airplane     | 24.027 | bus            | 34.688 |
| train         | 29.882 | truck        | 14.315 | boat           | 6.394  |
| traffic light | 12.086 | fire hydrant | 38.070 | stop sign      | 43.768 |
| parking meter | 28.282 | bench        | 4.498  | bird           | 12.551 |
| cat           | 40.745 | dog          | 34.136 | horse          | 15.005 |
| sheep         | 17.725 | cow          | 20.522 | elephant       | 27.438 |
| bear          | 46.856 | zebra        | 24.906 | giraffe        | 20.939 |
| backpack      | 4.456  | umbrella     | 20.781 | handbag        | 4.209  |
| tie           | 6.072  | suitcase     | 7.540  | frisbee        | 36.974 |
| skis          | 0.001  | snowboard    | 1.071  | sports ball    | 33.536 |
| kite          | 8.772  | baseball bat | 0.687  | baseball glove | 23.909 |
| skateboard    | 4.645  | surfboard    | 5.186  | tennis racket  | 27.003 |
| bottle        | 17.825 | wine glass   | 12.124 | cup            | 20.674 |
| fork          | 0.015  | knife        | 0.182  | spoon          | 0.231  |
| bowl          | 17.288 | banana       | 4.857  | apple          | 6.825  |
| sandwich      | 15.800 | orange       | 17.465 | broccoli       | 10.614 |
| carrot        | 3.560  | hot dog      | 6.831  | pizza          | 26.450 |
| donut         | 19.305 | cake         | 13.556 | chair          | 4.973  |
| couch         | 12.610 | potted plant | 7.524  | bed            | 9.353  |
| dining table  | 1.982  | toilet       | 34.548 | tv             | 33.880 |
| laptop        | 28.860 | mouse        | 38.493 | remote         | 6.840  |
| keyboard      | 19.826 | cell phone   | 14.330 | microwave      | 26.132 |
| oven          | 7.999  | toaster      | 0.000  | sink           | 13.856 |
| refrigerator  | 15.304 | book         | 1.580  | clock          | 36.268 |
| vase          | 17.937 | scissors     | 1.112  | teddy bear     | 19.512 |
| hair drier    | 0.000  | toothbrush   | 0.033  |                |        |
[12/13 07:57:37 d2.evaluation.panoptic_evaluation]: Writing all panoptic predictions to /tmp/panoptic_evalopvd352r ...
[12/13 07:57:59 d2.evaluation.panoptic_evaluation]: Panoptic Evaluation Results:
|        |   PQ   |   SQ   |   RQ   |  #categories  |
|:------:|:------:|:------:|:------:|:-------------:|
|  All   | 23.119 | 65.988 | 30.099 |      133      |
| Things | 26.958 | 69.633 | 34.735 |      80       |
| Stuff  | 17.324 | 60.487 | 23.101 |      53       |
[12/13 07:57:59 d2.engine.defaults]: Evaluation results for coco_2017_val_panoptic_separated in csv format:
[12/13 07:57:59 d2.evaluation.testing]: copypaste: Task: sem_seg
[12/13 07:57:59 d2.evaluation.testing]: copypaste: mIoU,fwIoU,mACC,pACC
[12/13 07:57:59 d2.evaluation.testing]: copypaste: 27.9827,58.5768,37.3716,72.9879
[12/13 07:57:59 d2.evaluation.testing]: copypaste: Task: bbox
[12/13 07:57:59 d2.evaluation.testing]: copypaste: AP,AP50,AP75,APs,APm,APl
[12/13 07:57:59 d2.evaluation.testing]: copypaste: 15.4990,34.2680,11.8760,8.5563,18.1131,21.1687
[12/13 07:57:59 d2.evaluation.testing]: copypaste: Task: segm
[12/13 07:57:59 d2.evaluation.testing]: copypaste: AP,AP50,AP75,APs,APm,APl
[12/13 07:57:59 d2.evaluation.testing]: copypaste: 16.0984,31.8034,14.6641,6.1577,18.0749,24.5975
[12/13 07:57:59 d2.evaluation.testing]: copypaste: Task: panoptic_seg
[12/13 07:57:59 d2.evaluation.testing]: copypaste: PQ,SQ,RQ,PQ_th,SQ_th,RQ_th,PQ_st,SQ_st,RQ_st
[12/13 07:57:59 d2.evaluation.testing]: copypaste: 23.1187,65.9883,30.0991,26.9579,69.6333,34.7353,17.3238,60.4866,23.1011