env: DETECTRON2_DATASETS=/content/datasets
Command Line Args: Namespace(config_file='./detectron2/configs/quick_schedules/panoptic_fpn_R_50_training_acc_test.yaml', dist_url='tcp://127.0.0.1:49152', eval_only=False, machine_rank=0, num_gpus=1, num_machines=1, opts=['SOLVER.IMS_PER_BATCH', '5', 'SOLVER.BASE_LR', '0.0025'], resume=False)
[12/08 20:48:32 detectron2]: Rank of current process: 0. World size: 1
[12/08 20:48:33 detectron2]: Environment info:
----------------------  ----------------------------------------------------------------
sys.platform            linux
Python                  3.7.12 (default, Jan 15 2022, 18:48:18) [GCC 7.5.0]
numpy                   1.21.5
detectron2              0.6 @/content/detectron2/detectron2
Compiler                GCC 7.5
CUDA compiler           CUDA 11.1
detectron2 arch flags   7.0
DETECTRON2_ENV_MODULE   <not set>
PyTorch                 1.10.0+cu111 @/usr/local/lib/python3.7/dist-packages/torch
PyTorch debug build     False
GPU available           Yes
GPU 0                   Tesla V100-SXM2-16GB (arch=7.0)
Driver version          460.32.03
CUDA_HOME               /usr/local/cuda
Pillow                  7.1.2
torchvision             0.11.1+cu111 @/usr/local/lib/python3.7/dist-packages/torchvision
torchvision arch flags  3.5, 5.0, 6.0, 7.0, 7.5, 8.0, 8.6
fvcore                  0.1.5.post20221122
iopath                  0.1.9
cv2                     4.1.2
----------------------  ----------------------------------------------------------------
PyTorch built with:
  - GCC 7.3
  - C++ Version: 201402
  - Intel(R) Math Kernel Library Version 2020.0.0 Product Build 20191122 for Intel(R) 64 architecture applications
  - Intel(R) MKL-DNN v2.2.3 (Git Hash 7336ca9f055cf1bfa13efb658fe15dc9b41f0740)
  - OpenMP 201511 (a.k.a. OpenMP 4.5)
  - LAPACK is enabled (usually provided by MKL)
  - NNPACK is enabled
  - CPU capability usage: AVX2
  - CUDA Runtime 11.1
  - NVCC architecture flags: -gencode;arch=compute_37,code=sm_37;-gencode;arch=compute_50,code=sm_50;-gencode;arch=compute_60,code=sm_60;-gencode;arch=compute_70,code=sm_70;-gencode;arch=compute_75,code=sm_75;-gencode;arch=compute_80,code=sm_80;-gencode;arch=compute_86,code=sm_86
  - CuDNN 8.0.5
  - Magma 2.5.2
  - Build settings: BLAS_INFO=mkl, BUILD_TYPE=Release, CUDA_VERSION=11.1, CUDNN_VERSION=8.0.5, CXX_COMPILER=/opt/rh/devtoolset-7/root/usr/bin/c++, CXX_FLAGS= -Wno-deprecated -fvisibility-inlines-hidden -DUSE_PTHREADPOOL -fopenmp -DNDEBUG -DUSE_KINETO -DUSE_FBGEMM -DUSE_QNNPACK -DUSE_PYTORCH_QNNPACK -DUSE_XNNPACK -DSYMBOLICATE_MOBILE_DEBUG_HANDLE -DEDGE_PROFILER_USE_KINETO -O2 -fPIC -Wno-narrowing -Wall -Wextra -Werror=return-type -Wno-missing-field-initializers -Wno-type-limits -Wno-array-bounds -Wno-unknown-pragmas -Wno-sign-compare -Wno-unused-parameter -Wno-unused-variable -Wno-unused-function -Wno-unused-result -Wno-unused-local-typedefs -Wno-strict-overflow -Wno-strict-aliasing -Wno-error=deprecated-declarations -Wno-stringop-overflow -Wno-psabi -Wno-error=pedantic -Wno-error=redundant-decls -Wno-error=old-style-cast -fdiagnostics-color=always -faligned-new -Wno-unused-but-set-variable -Wno-maybe-uninitialized -fno-math-errno -fno-trapping-math -Werror=format -Wno-stringop-overflow, LAPACK_INFO=mkl, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, TORCH_VERSION=1.10.0, USE_CUDA=ON, USE_CUDNN=ON, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_MKL=ON, USE_MKLDNN=ON, USE_MPI=OFF, USE_NCCL=ON, USE_NNPACK=ON, USE_OPENMP=ON, 

[12/08 20:48:33 detectron2]: Command line arguments: Namespace(config_file='./detectron2/configs/quick_schedules/panoptic_fpn_R_50_training_acc_test.yaml', dist_url='tcp://127.0.0.1:49152', eval_only=False, machine_rank=0, num_gpus=1, num_machines=1, opts=['SOLVER.IMS_PER_BATCH', '5', 'SOLVER.BASE_LR', '0.0025'], resume=False)
[12/08 20:48:33 detectron2]: Contents of args.config_file=./detectron2/configs/quick_schedules/panoptic_fpn_R_50_training_acc_test.yaml:
_BASE_: "../Base-RCNN-FPN.yaml"
MODEL:
  META_ARCHITECTURE: "PanopticFPN"
  WEIGHTS: "detectron2://ImageNetPretrained/MSRA/R-50.pkl"
  MASK_ON: True
  RESNETS:
    DEPTH: 50
  SEM_SEG_HEAD:
    LOSS_WEIGHT: 0.5
DATASETS:
  TRAIN: ("coco_2017_val_panoptic_separated",)
  TEST: ("coco_2017_val_panoptic_separated",)
SOLVER:
  BASE_LR: 0.01
  WARMUP_FACTOR: 0.001
  WARMUP_ITERS: 500
  STEPS: (5500,)
  MAX_ITER: 7000
TEST:
  EXPECTED_RESULTS: [["bbox", "AP", 46.70, 1.1], ["segm", "AP", 39.0, 0.7], ["sem_seg", "mIoU", 64.73, 1.3], ["panoptic_seg", "PQ", 48.13, 0.8]]

[12/08 20:48:33 detectron2]: Running with full config:
CUDNN_BENCHMARK: false
DATALOADER:
  ASPECT_RATIO_GROUPING: true
  FILTER_EMPTY_ANNOTATIONS: true
  NUM_WORKERS: 4
  REPEAT_THRESHOLD: 0.0
  SAMPLER_TRAIN: TrainingSampler
DATASETS:
  PRECOMPUTED_PROPOSAL_TOPK_TEST: 1000
  PRECOMPUTED_PROPOSAL_TOPK_TRAIN: 2000
  PROPOSAL_FILES_TEST: []
  PROPOSAL_FILES_TRAIN: []
  TEST:
  - coco_2017_val_panoptic_separated
  TRAIN:
  - coco_2017_val_panoptic_separated
GLOBAL:
  HACK: 1.0
INPUT:
  CROP:
    ENABLED: false
    SIZE:
    - 0.9
    - 0.9
    TYPE: relative_range
  FORMAT: BGR
  MASK_FORMAT: polygon
  MAX_SIZE_TEST: 1333
  MAX_SIZE_TRAIN: 1333
  MIN_SIZE_TEST: 800
  MIN_SIZE_TRAIN:
  - 640
  - 672
  - 704
  - 736
  - 768
  - 800
  MIN_SIZE_TRAIN_SAMPLING: choice
  RANDOM_FLIP: horizontal
MODEL:
  ANCHOR_GENERATOR:
    ANGLES:
    - - -90
      - 0
      - 90
    ASPECT_RATIOS:
    - - 0.5
      - 1.0
      - 2.0
    NAME: DefaultAnchorGenerator
    OFFSET: 0.0
    SIZES:
    - - 32
    - - 64
    - - 128
    - - 256
    - - 512
  BACKBONE:
    FREEZE_AT: 2
    NAME: build_resnet_fpn_backbone
  DEVICE: cuda
  FPN:
    FUSE_TYPE: sum
    IN_FEATURES:
    - res2
    - res3
    - res4
    - res5
    NORM: ''
    OUT_CHANNELS: 256
  KEYPOINT_ON: false
  LOAD_PROPOSALS: false
  MASK_ON: true
  META_ARCHITECTURE: PanopticFPN
  PANOPTIC_FPN:
    COMBINE:
      ENABLED: true
      INSTANCES_CONFIDENCE_THRESH: 0.5
      OVERLAP_THRESH: 0.5
      STUFF_AREA_LIMIT: 4096
    INSTANCE_LOSS_WEIGHT: 1.0
  PIXEL_MEAN:
  - 103.53
  - 116.28
  - 123.675
  PIXEL_STD:
  - 1.0
  - 1.0
  - 1.0
  PROPOSAL_GENERATOR:
    MIN_SIZE: 0
    NAME: RPN
  RESNETS:
    DEFORM_MODULATED: false
    DEFORM_NUM_GROUPS: 1
    DEFORM_ON_PER_STAGE:
    - false
    - false
    - false
    - false
    DEPTH: 50
    NORM: FrozenBN
    NUM_GROUPS: 1
    OUT_FEATURES:
    - res2
    - res3
    - res4
    - res5
    RES2_OUT_CHANNELS: 256
    RES5_DILATION: 1
    STEM_OUT_CHANNELS: 64
    STRIDE_IN_1X1: true
    WIDTH_PER_GROUP: 64
  RETINANET:
    BBOX_REG_LOSS_TYPE: smooth_l1
    BBOX_REG_WEIGHTS: &id001
    - 1.0
    - 1.0
    - 1.0
    - 1.0
    FOCAL_LOSS_ALPHA: 0.25
    FOCAL_LOSS_GAMMA: 2.0
    IN_FEATURES:
    - p3
    - p4
    - p5
    - p6
    - p7
    IOU_LABELS:
    - 0
    - -1
    - 1
    IOU_THRESHOLDS:
    - 0.4
    - 0.5
    NMS_THRESH_TEST: 0.5
    NORM: ''
    NUM_CLASSES: 80
    NUM_CONVS: 4
    PRIOR_PROB: 0.01
    SCORE_THRESH_TEST: 0.05
    SMOOTH_L1_LOSS_BETA: 0.1
    TOPK_CANDIDATES_TEST: 1000
  ROI_BOX_CASCADE_HEAD:
    BBOX_REG_WEIGHTS:
    - - 10.0
      - 10.0
      - 5.0
      - 5.0
    - - 20.0
      - 20.0
      - 10.0
      - 10.0
    - - 30.0
      - 30.0
      - 15.0
      - 15.0
    IOUS:
    - 0.5
    - 0.6
    - 0.7
  ROI_BOX_HEAD:
    BBOX_REG_LOSS_TYPE: smooth_l1
    BBOX_REG_LOSS_WEIGHT: 1.0
    BBOX_REG_WEIGHTS:
    - 10.0
    - 10.0
    - 5.0
    - 5.0
    CLS_AGNOSTIC_BBOX_REG: false
    CONV_DIM: 256
    FC_DIM: 1024
    FED_LOSS_FREQ_WEIGHT_POWER: 0.5
    FED_LOSS_NUM_CLASSES: 50
    NAME: FastRCNNConvFCHead
    NORM: ''
    NUM_CONV: 0
    NUM_FC: 2
    POOLER_RESOLUTION: 7
    POOLER_SAMPLING_RATIO: 0
    POOLER_TYPE: ROIAlignV2
    SMOOTH_L1_BETA: 0.0
    TRAIN_ON_PRED_BOXES: false
    USE_FED_LOSS: false
    USE_SIGMOID_CE: false
  ROI_HEADS:
    BATCH_SIZE_PER_IMAGE: 512
    IN_FEATURES:
    - p2
    - p3
    - p4
    - p5
    IOU_LABELS:
    - 0
    - 1
    IOU_THRESHOLDS:
    - 0.5
    NAME: StandardROIHeads
    NMS_THRESH_TEST: 0.5
    NUM_CLASSES: 80
    POSITIVE_FRACTION: 0.25
    PROPOSAL_APPEND_GT: true
    SCORE_THRESH_TEST: 0.05
  ROI_KEYPOINT_HEAD:
    CONV_DIMS:
    - 512
    - 512
    - 512
    - 512
    - 512
    - 512
    - 512
    - 512
    LOSS_WEIGHT: 1.0
    MIN_KEYPOINTS_PER_IMAGE: 1
    NAME: KRCNNConvDeconvUpsampleHead
    NORMALIZE_LOSS_BY_VISIBLE_KEYPOINTS: true
    NUM_KEYPOINTS: 17
    POOLER_RESOLUTION: 14
    POOLER_SAMPLING_RATIO: 0
    POOLER_TYPE: ROIAlignV2
  ROI_MASK_HEAD:
    CLS_AGNOSTIC_MASK: false
    CONV_DIM: 256
    NAME: MaskRCNNConvUpsampleHead
    NORM: ''
    NUM_CONV: 4
    POOLER_RESOLUTION: 14
    POOLER_SAMPLING_RATIO: 0
    POOLER_TYPE: ROIAlignV2
  RPN:
    BATCH_SIZE_PER_IMAGE: 256
    BBOX_REG_LOSS_TYPE: smooth_l1
    BBOX_REG_LOSS_WEIGHT: 1.0
    BBOX_REG_WEIGHTS: *id001
    BOUNDARY_THRESH: -1
    CONV_DIMS:
    - -1
    HEAD_NAME: StandardRPNHead
    IN_FEATURES:
    - p2
    - p3
    - p4
    - p5
    - p6
    IOU_LABELS:
    - 0
    - -1
    - 1
    IOU_THRESHOLDS:
    - 0.3
    - 0.7
    LOSS_WEIGHT: 1.0
    NMS_THRESH: 0.7
    POSITIVE_FRACTION: 0.5
    POST_NMS_TOPK_TEST: 1000
    POST_NMS_TOPK_TRAIN: 1000
    PRE_NMS_TOPK_TEST: 1000
    PRE_NMS_TOPK_TRAIN: 2000
    SMOOTH_L1_BETA: 0.0
  SEM_SEG_HEAD:
    COMMON_STRIDE: 4
    CONVS_DIM: 128
    IGNORE_VALUE: 255
    IN_FEATURES:
    - p2
    - p3
    - p4
    - p5
    LOSS_WEIGHT: 0.5
    NAME: SemSegFPNHead
    NORM: GN
    NUM_CLASSES: 54
  WEIGHTS: detectron2://ImageNetPretrained/MSRA/R-50.pkl
OUTPUT_DIR: ./output
SEED: -1
SOLVER:
  AMP:
    ENABLED: false
  BASE_LR: 0.0025
  BASE_LR_END: 0.0
  BIAS_LR_FACTOR: 1.0
  CHECKPOINT_PERIOD: 5000
  CLIP_GRADIENTS:
    CLIP_TYPE: value
    CLIP_VALUE: 1.0
    ENABLED: false
    NORM_TYPE: 2.0
  GAMMA: 0.1
  IMS_PER_BATCH: 5
  LR_SCHEDULER_NAME: WarmupMultiStepLR
  MAX_ITER: 7000
  MOMENTUM: 0.9
  NESTEROV: false
  NUM_DECAYS: 3
  REFERENCE_WORLD_SIZE: 0
  RESCALE_INTERVAL: false
  STEPS:
  - 5500
  WARMUP_FACTOR: 0.001
  WARMUP_ITERS: 500
  WARMUP_METHOD: linear
  WEIGHT_DECAY: 0.0001
  WEIGHT_DECAY_BIAS: null
  WEIGHT_DECAY_NORM: 0.0
TEST:
  AUG:
    ENABLED: false
    FLIP: true
    MAX_SIZE: 4000
    MIN_SIZES:
    - 400
    - 500
    - 600
    - 700
    - 800
    - 900
    - 1000
    - 1100
    - 1200
  DETECTIONS_PER_IMAGE: 100
  EVAL_PERIOD: 0
  EXPECTED_RESULTS:
  - - bbox
    - AP
    - 46.7
    - 1.1
  - - segm
    - AP
    - 39.0
    - 0.7
  - - sem_seg
    - mIoU
    - 64.73
    - 1.3
  - - panoptic_seg
    - PQ
    - 48.13
    - 0.8
  KEYPOINT_OKS_SIGMAS: []
  PRECISE_BN:
    ENABLED: false
    NUM_ITER: 200
VERSION: 2
VIS_PERIOD: 0

[12/08 20:48:33 detectron2]: Full config saved to ./output/config.yaml
[12/08 20:48:33 d2.utils.env]: Using a generated random seed 33573108
[12/08 20:48:38 d2.engine.defaults]: Model:
PanopticFPN(
  (backbone): FPN(
    (fpn_lateral2): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1))
    (fpn_output2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (fpn_lateral3): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1))
    (fpn_output3): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (fpn_lateral4): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1))
    (fpn_output4): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (fpn_lateral5): Conv2d(2048, 256, kernel_size=(1, 1), stride=(1, 1))
    (fpn_output5): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (top_block): LastLevelMaxPool()
    (bottom_up): ResNet(
      (stem): BasicStem(
        (conv1): Conv2d(
          3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False
          (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
        )
      )
      (res2): Sequential(
        (0): BottleneckBlock(
          (shortcut): Conv2d(
            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv1): Conv2d(
            64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
          )
          (conv2): Conv2d(
            64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
          )
          (conv3): Conv2d(
            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
        )
        (1): BottleneckBlock(
          (conv1): Conv2d(
            256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
          )
          (conv2): Conv2d(
            64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
          )
          (conv3): Conv2d(
            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
        )
        (2): BottleneckBlock(
          (conv1): Conv2d(
            256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
          )
          (conv2): Conv2d(
            64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
          )
          (conv3): Conv2d(
            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
        )
      )
      (res3): Sequential(
        (0): BottleneckBlock(
          (shortcut): Conv2d(
            256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
          (conv1): Conv2d(
            256, 128, kernel_size=(1, 1), stride=(2, 2), bias=False
            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
          )
          (conv2): Conv2d(
            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
          )
          (conv3): Conv2d(
            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
        )
        (1): BottleneckBlock(
          (conv1): Conv2d(
            512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
          )
          (conv2): Conv2d(
            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
          )
          (conv3): Conv2d(
            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
        )
        (2): BottleneckBlock(
          (conv1): Conv2d(
            512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
          )
          (conv2): Conv2d(
            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
          )
          (conv3): Conv2d(
            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
        )
        (3): BottleneckBlock(
          (conv1): Conv2d(
            512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
          )
          (conv2): Conv2d(
            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
          )
          (conv3): Conv2d(
            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
        )
      )
      (res4): Sequential(
        (0): BottleneckBlock(
          (shortcut): Conv2d(
            512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
          (conv1): Conv2d(
            512, 256, kernel_size=(1, 1), stride=(2, 2), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (1): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (2): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (3): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (4): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (5): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
      )
      (res5): Sequential(
        (0): BottleneckBlock(
          (shortcut): Conv2d(
            1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False
            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)
          )
          (conv1): Conv2d(
            1024, 512, kernel_size=(1, 1), stride=(2, 2), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
          (conv2): Conv2d(
            512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
          (conv3): Conv2d(
            512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)
          )
        )
        (1): BottleneckBlock(
          (conv1): Conv2d(
            2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
          (conv2): Conv2d(
            512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
          (conv3): Conv2d(
            512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)
          )
        )
        (2): BottleneckBlock(
          (conv1): Conv2d(
            2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
          (conv2): Conv2d(
            512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
          (conv3): Conv2d(
            512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)
          )
        )
      )
    )
  )
  (proposal_generator): RPN(
    (rpn_head): StandardRPNHead(
      (conv): Conv2d(
        256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)
        (activation): ReLU()
      )
      (objectness_logits): Conv2d(256, 3, kernel_size=(1, 1), stride=(1, 1))
      (anchor_deltas): Conv2d(256, 12, kernel_size=(1, 1), stride=(1, 1))
    )
    (anchor_generator): DefaultAnchorGenerator(
      (cell_anchors): BufferList()
    )
  )
  (roi_heads): StandardROIHeads(
    (box_pooler): ROIPooler(
      (level_poolers): ModuleList(
        (0): ROIAlign(output_size=(7, 7), spatial_scale=0.25, sampling_ratio=0, aligned=True)
        (1): ROIAlign(output_size=(7, 7), spatial_scale=0.125, sampling_ratio=0, aligned=True)
        (2): ROIAlign(output_size=(7, 7), spatial_scale=0.0625, sampling_ratio=0, aligned=True)
        (3): ROIAlign(output_size=(7, 7), spatial_scale=0.03125, sampling_ratio=0, aligned=True)
      )
    )
    (box_head): FastRCNNConvFCHead(
      (flatten): Flatten(start_dim=1, end_dim=-1)
      (fc1): Linear(in_features=12544, out_features=1024, bias=True)
      (fc_relu1): ReLU()
      (fc2): Linear(in_features=1024, out_features=1024, bias=True)
      (fc_relu2): ReLU()
    )
    (box_predictor): FastRCNNOutputLayers(
      (cls_score): Linear(in_features=1024, out_features=81, bias=True)
      (bbox_pred): Linear(in_features=1024, out_features=320, bias=True)
    )
    (mask_pooler): ROIPooler(
      (level_poolers): ModuleList(
        (0): ROIAlign(output_size=(14, 14), spatial_scale=0.25, sampling_ratio=0, aligned=True)
        (1): ROIAlign(output_size=(14, 14), spatial_scale=0.125, sampling_ratio=0, aligned=True)
        (2): ROIAlign(output_size=(14, 14), spatial_scale=0.0625, sampling_ratio=0, aligned=True)
        (3): ROIAlign(output_size=(14, 14), spatial_scale=0.03125, sampling_ratio=0, aligned=True)
      )
    )
    (mask_head): MaskRCNNConvUpsampleHead(
      (mask_fcn1): Conv2d(
        256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)
        (activation): ReLU()
      )
      (mask_fcn2): Conv2d(
        256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)
        (activation): ReLU()
      )
      (mask_fcn3): Conv2d(
        256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)
        (activation): ReLU()
      )
      (mask_fcn4): Conv2d(
        256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)
        (activation): ReLU()
      )
      (deconv): ConvTranspose2d(256, 256, kernel_size=(2, 2), stride=(2, 2))
      (deconv_relu): ReLU()
      (predictor): Conv2d(256, 80, kernel_size=(1, 1), stride=(1, 1))
    )
  )
  (sem_seg_head): SemSegFPNHead(
    (p2): Sequential(
      (0): Conv2d(
        256, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
        (norm): GroupNorm(32, 128, eps=1e-05, affine=True)
      )
    )
    (p3): Sequential(
      (0): Conv2d(
        256, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
        (norm): GroupNorm(32, 128, eps=1e-05, affine=True)
      )
      (1): Upsample(scale_factor=2.0, mode=bilinear)
    )
    (p4): Sequential(
      (0): Conv2d(
        256, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
        (norm): GroupNorm(32, 128, eps=1e-05, affine=True)
      )
      (1): Upsample(scale_factor=2.0, mode=bilinear)
      (2): Conv2d(
        128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
        (norm): GroupNorm(32, 128, eps=1e-05, affine=True)
      )
      (3): Upsample(scale_factor=2.0, mode=bilinear)
    )
    (p5): Sequential(
      (0): Conv2d(
        256, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
        (norm): GroupNorm(32, 128, eps=1e-05, affine=True)
      )
      (1): Upsample(scale_factor=2.0, mode=bilinear)
      (2): Conv2d(
        128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
        (norm): GroupNorm(32, 128, eps=1e-05, affine=True)
      )
      (3): Upsample(scale_factor=2.0, mode=bilinear)
      (4): Conv2d(
        128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
        (norm): GroupNorm(32, 128, eps=1e-05, affine=True)
      )
      (5): Upsample(scale_factor=2.0, mode=bilinear)
    )
    (predictor): Conv2d(128, 54, kernel_size=(1, 1), stride=(1, 1))
  )
)
[12/08 20:48:39 d2.data.datasets.coco]: Loaded 5000 images in COCO format from /content/datasets/coco/annotations/instances_val2017.json
[12/08 20:48:39 d2.data.datasets.coco]: Loaded 5000 images with semantic segmentation from /content/datasets/coco/val2017
[12/08 20:48:39 d2.data.build]: Removed 48 images with no usable annotations. 4952 images left.
[12/08 20:48:40 d2.data.build]: Distribution of instances among all 80 categories:
|   category    | #instances   |   category   | #instances   |   category    | #instances   |
|:-------------:|:-------------|:------------:|:-------------|:-------------:|:-------------|
|    person     | 10777        |   bicycle    | 314          |      car      | 1918         |
|  motorcycle   | 367          |   airplane   | 143          |      bus      | 283          |
|     train     | 190          |    truck     | 414          |     boat      | 424          |
| traffic light | 634          | fire hydrant | 101          |   stop sign   | 75           |
| parking meter | 60           |    bench     | 411          |     bird      | 427          |
|      cat      | 202          |     dog      | 218          |     horse     | 272          |
|     sheep     | 354          |     cow      | 372          |   elephant    | 252          |
|     bear      | 71           |    zebra     | 266          |    giraffe    | 232          |
|   backpack    | 371          |   umbrella   | 407          |    handbag    | 540          |
|      tie      | 252          |   suitcase   | 299          |    frisbee    | 115          |
|     skis      | 241          |  snowboard   | 69           |  sports ball  | 260          |
|     kite      | 327          | baseball bat | 145          | baseball gl.. | 148          |
|  skateboard   | 179          |  surfboard   | 267          | tennis racket | 225          |
|    bottle     | 1013         |  wine glass  | 341          |      cup      | 895          |
|     fork      | 215          |    knife     | 325          |     spoon     | 253          |
|     bowl      | 623          |    banana    | 370          |     apple     | 236          |
|   sandwich    | 177          |    orange    | 285          |   broccoli    | 312          |
|    carrot     | 365          |   hot dog    | 125          |     pizza     | 284          |
|     donut     | 328          |     cake     | 310          |     chair     | 1771         |
|     couch     | 261          | potted plant | 342          |      bed      | 163          |
| dining table  | 695          |    toilet    | 179          |      tv       | 288          |
|    laptop     | 231          |    mouse     | 106          |    remote     | 283          |
|   keyboard    | 153          |  cell phone  | 262          |   microwave   | 55           |
|     oven      | 143          |   toaster    | 9            |     sink      | 225          |
| refrigerator  | 126          |     book     | 1129         |     clock     | 267          |
|     vase      | 274          |   scissors   | 36           |  teddy bear   | 190          |
|  hair drier   | 11           |  toothbrush  | 57           |               |              |
|     total     | 36335        |              |              |               |              |
[12/08 20:48:40 d2.data.dataset_mapper]: [DatasetMapper] Augmentations used in training: [ResizeShortestEdge(short_edge_length=(640, 672, 704, 736, 768, 800), max_size=1333, sample_style='choice'), RandomFlip()]
[12/08 20:48:40 d2.data.build]: Using training sampler TrainingSampler
[12/08 20:48:40 d2.data.common]: Serializing the dataset using: <class 'detectron2.data.common.NumpySerializedList'>
[12/08 20:48:40 d2.data.common]: Serializing 4952 elements to byte tensors and concatenating them all ...
[12/08 20:48:40 d2.data.common]: Serialized dataset takes 19.54 MiB
[12/08 20:48:42 fvcore.common.checkpoint]: [Checkpointer] Loading from detectron2://ImageNetPretrained/MSRA/R-50.pkl ...
[12/08 20:48:43 d2.checkpoint.c2_model_loading]: Renaming Caffe2 weights ......
[12/08 20:48:43 d2.checkpoint.c2_model_loading]: Following weights matched with submodule backbone.bottom_up:
| Names in Model    | Names in Checkpoint      | Shapes                                          |
|:------------------|:-------------------------|:------------------------------------------------|
| res2.0.conv1.*    | res2_0_branch2a_{bn_*,w} | (64,) (64,) (64,) (64,) (64,64,1,1)             |
| res2.0.conv2.*    | res2_0_branch2b_{bn_*,w} | (64,) (64,) (64,) (64,) (64,64,3,3)             |
| res2.0.conv3.*    | res2_0_branch2c_{bn_*,w} | (256,) (256,) (256,) (256,) (256,64,1,1)        |
| res2.0.shortcut.* | res2_0_branch1_{bn_*,w}  | (256,) (256,) (256,) (256,) (256,64,1,1)        |
| res2.1.conv1.*    | res2_1_branch2a_{bn_*,w} | (64,) (64,) (64,) (64,) (64,256,1,1)            |
| res2.1.conv2.*    | res2_1_branch2b_{bn_*,w} | (64,) (64,) (64,) (64,) (64,64,3,3)             |
| res2.1.conv3.*    | res2_1_branch2c_{bn_*,w} | (256,) (256,) (256,) (256,) (256,64,1,1)        |
| res2.2.conv1.*    | res2_2_branch2a_{bn_*,w} | (64,) (64,) (64,) (64,) (64,256,1,1)            |
| res2.2.conv2.*    | res2_2_branch2b_{bn_*,w} | (64,) (64,) (64,) (64,) (64,64,3,3)             |
| res2.2.conv3.*    | res2_2_branch2c_{bn_*,w} | (256,) (256,) (256,) (256,) (256,64,1,1)        |
| res3.0.conv1.*    | res3_0_branch2a_{bn_*,w} | (128,) (128,) (128,) (128,) (128,256,1,1)       |
| res3.0.conv2.*    | res3_0_branch2b_{bn_*,w} | (128,) (128,) (128,) (128,) (128,128,3,3)       |
| res3.0.conv3.*    | res3_0_branch2c_{bn_*,w} | (512,) (512,) (512,) (512,) (512,128,1,1)       |
| res3.0.shortcut.* | res3_0_branch1_{bn_*,w}  | (512,) (512,) (512,) (512,) (512,256,1,1)       |
| res3.1.conv1.*    | res3_1_branch2a_{bn_*,w} | (128,) (128,) (128,) (128,) (128,512,1,1)       |
| res3.1.conv2.*    | res3_1_branch2b_{bn_*,w} | (128,) (128,) (128,) (128,) (128,128,3,3)       |
| res3.1.conv3.*    | res3_1_branch2c_{bn_*,w} | (512,) (512,) (512,) (512,) (512,128,1,1)       |
| res3.2.conv1.*    | res3_2_branch2a_{bn_*,w} | (128,) (128,) (128,) (128,) (128,512,1,1)       |
| res3.2.conv2.*    | res3_2_branch2b_{bn_*,w} | (128,) (128,) (128,) (128,) (128,128,3,3)       |
| res3.2.conv3.*    | res3_2_branch2c_{bn_*,w} | (512,) (512,) (512,) (512,) (512,128,1,1)       |
| res3.3.conv1.*    | res3_3_branch2a_{bn_*,w} | (128,) (128,) (128,) (128,) (128,512,1,1)       |
| res3.3.conv2.*    | res3_3_branch2b_{bn_*,w} | (128,) (128,) (128,) (128,) (128,128,3,3)       |
| res3.3.conv3.*    | res3_3_branch2c_{bn_*,w} | (512,) (512,) (512,) (512,) (512,128,1,1)       |
| res4.0.conv1.*    | res4_0_branch2a_{bn_*,w} | (256,) (256,) (256,) (256,) (256,512,1,1)       |
| res4.0.conv2.*    | res4_0_branch2b_{bn_*,w} | (256,) (256,) (256,) (256,) (256,256,3,3)       |
| res4.0.conv3.*    | res4_0_branch2c_{bn_*,w} | (1024,) (1024,) (1024,) (1024,) (1024,256,1,1)  |
| res4.0.shortcut.* | res4_0_branch1_{bn_*,w}  | (1024,) (1024,) (1024,) (1024,) (1024,512,1,1)  |
| res4.1.conv1.*    | res4_1_branch2a_{bn_*,w} | (256,) (256,) (256,) (256,) (256,1024,1,1)      |
| res4.1.conv2.*    | res4_1_branch2b_{bn_*,w} | (256,) (256,) (256,) (256,) (256,256,3,3)       |
| res4.1.conv3.*    | res4_1_branch2c_{bn_*,w} | (1024,) (1024,) (1024,) (1024,) (1024,256,1,1)  |
| res4.2.conv1.*    | res4_2_branch2a_{bn_*,w} | (256,) (256,) (256,) (256,) (256,1024,1,1)      |
| res4.2.conv2.*    | res4_2_branch2b_{bn_*,w} | (256,) (256,) (256,) (256,) (256,256,3,3)       |
| res4.2.conv3.*    | res4_2_branch2c_{bn_*,w} | (1024,) (1024,) (1024,) (1024,) (1024,256,1,1)  |
| res4.3.conv1.*    | res4_3_branch2a_{bn_*,w} | (256,) (256,) (256,) (256,) (256,1024,1,1)      |
| res4.3.conv2.*    | res4_3_branch2b_{bn_*,w} | (256,) (256,) (256,) (256,) (256,256,3,3)       |
| res4.3.conv3.*    | res4_3_branch2c_{bn_*,w} | (1024,) (1024,) (1024,) (1024,) (1024,256,1,1)  |
| res4.4.conv1.*    | res4_4_branch2a_{bn_*,w} | (256,) (256,) (256,) (256,) (256,1024,1,1)      |
| res4.4.conv2.*    | res4_4_branch2b_{bn_*,w} | (256,) (256,) (256,) (256,) (256,256,3,3)       |
| res4.4.conv3.*    | res4_4_branch2c_{bn_*,w} | (1024,) (1024,) (1024,) (1024,) (1024,256,1,1)  |
| res4.5.conv1.*    | res4_5_branch2a_{bn_*,w} | (256,) (256,) (256,) (256,) (256,1024,1,1)      |
| res4.5.conv2.*    | res4_5_branch2b_{bn_*,w} | (256,) (256,) (256,) (256,) (256,256,3,3)       |
| res4.5.conv3.*    | res4_5_branch2c_{bn_*,w} | (1024,) (1024,) (1024,) (1024,) (1024,256,1,1)  |
| res5.0.conv1.*    | res5_0_branch2a_{bn_*,w} | (512,) (512,) (512,) (512,) (512,1024,1,1)      |
| res5.0.conv2.*    | res5_0_branch2b_{bn_*,w} | (512,) (512,) (512,) (512,) (512,512,3,3)       |
| res5.0.conv3.*    | res5_0_branch2c_{bn_*,w} | (2048,) (2048,) (2048,) (2048,) (2048,512,1,1)  |
| res5.0.shortcut.* | res5_0_branch1_{bn_*,w}  | (2048,) (2048,) (2048,) (2048,) (2048,1024,1,1) |
| res5.1.conv1.*    | res5_1_branch2a_{bn_*,w} | (512,) (512,) (512,) (512,) (512,2048,1,1)      |
| res5.1.conv2.*    | res5_1_branch2b_{bn_*,w} | (512,) (512,) (512,) (512,) (512,512,3,3)       |
| res5.1.conv3.*    | res5_1_branch2c_{bn_*,w} | (2048,) (2048,) (2048,) (2048,) (2048,512,1,1)  |
| res5.2.conv1.*    | res5_2_branch2a_{bn_*,w} | (512,) (512,) (512,) (512,) (512,2048,1,1)      |
| res5.2.conv2.*    | res5_2_branch2b_{bn_*,w} | (512,) (512,) (512,) (512,) (512,512,3,3)       |
| res5.2.conv3.*    | res5_2_branch2c_{bn_*,w} | (2048,) (2048,) (2048,) (2048,) (2048,512,1,1)  |
| stem.conv1.norm.* | res_conv1_bn_*           | (64,) (64,) (64,) (64,)                         |
| stem.conv1.weight | conv1_w                  | (64, 3, 7, 7)                                   |
WARNING [12/08 20:48:43 fvcore.common.checkpoint]: Some model parameters or buffers are not found in the checkpoint:
backbone.fpn_lateral2.{bias, weight}
backbone.fpn_lateral3.{bias, weight}
backbone.fpn_lateral4.{bias, weight}
backbone.fpn_lateral5.{bias, weight}
backbone.fpn_output2.{bias, weight}
backbone.fpn_output3.{bias, weight}
backbone.fpn_output4.{bias, weight}
backbone.fpn_output5.{bias, weight}
proposal_generator.rpn_head.anchor_deltas.{bias, weight}
proposal_generator.rpn_head.conv.{bias, weight}
proposal_generator.rpn_head.objectness_logits.{bias, weight}
roi_heads.box_head.fc1.{bias, weight}
roi_heads.box_head.fc2.{bias, weight}
roi_heads.box_predictor.bbox_pred.{bias, weight}
roi_heads.box_predictor.cls_score.{bias, weight}
roi_heads.mask_head.deconv.{bias, weight}
roi_heads.mask_head.mask_fcn1.{bias, weight}
roi_heads.mask_head.mask_fcn2.{bias, weight}
roi_heads.mask_head.mask_fcn3.{bias, weight}
roi_heads.mask_head.mask_fcn4.{bias, weight}
roi_heads.mask_head.predictor.{bias, weight}
sem_seg_head.p2.0.norm.{bias, weight}
sem_seg_head.p2.0.weight
sem_seg_head.p3.0.norm.{bias, weight}
sem_seg_head.p3.0.weight
sem_seg_head.p4.0.norm.{bias, weight}
sem_seg_head.p4.0.weight
sem_seg_head.p4.2.norm.{bias, weight}
sem_seg_head.p4.2.weight
sem_seg_head.p5.0.norm.{bias, weight}
sem_seg_head.p5.0.weight
sem_seg_head.p5.2.norm.{bias, weight}
sem_seg_head.p5.2.weight
sem_seg_head.p5.4.norm.{bias, weight}
sem_seg_head.p5.4.weight
sem_seg_head.predictor.{bias, weight}
WARNING [12/08 20:48:43 fvcore.common.checkpoint]: The checkpoint state_dict contains keys that are not used by the model:
  fc1000.{bias, weight}
  stem.conv1.bias
[12/08 20:48:43 d2.engine.train_loop]: Starting training from iteration 0
/usr/local/lib/python3.7/dist-packages/torch/functional.py:445: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at  ../aten/src/ATen/native/TensorShape.cpp:2157.)
  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]
[12/08 20:48:54 d2.utils.events]:  eta: 1:01:12  iter: 19  total_loss: 8.774  loss_sem_seg: 3.946  loss_rpn_cls: 0.7127  loss_rpn_loc: 0.1362  loss_cls: 2.919  loss_box_reg: 0.009999  loss_mask: 0.6929  time: 0.5251  data_time: 0.0330  lr: 9.7405e-05  max_mem: 9398M
[12/08 20:49:05 d2.utils.events]:  eta: 1:01:11  iter: 39  total_loss: 4.027  loss_sem_seg: 2.365  loss_rpn_cls: 0.6198  loss_rpn_loc: 0.1483  loss_cls: 0.3061  loss_box_reg: 0.02757  loss_mask: 0.6919  time: 0.5266  data_time: 0.0212  lr: 0.00019731  max_mem: 9398M
[12/08 20:49:16 d2.utils.events]:  eta: 1:01:01  iter: 59  total_loss: 3.292  loss_sem_seg: 1.607  loss_rpn_cls: 0.4468  loss_rpn_loc: 0.1912  loss_cls: 0.3471  loss_box_reg: 0.02154  loss_mask: 0.6882  time: 0.5310  data_time: 0.0174  lr: 0.00029721  max_mem: 9398M
[12/08 20:49:27 d2.utils.events]:  eta: 1:01:13  iter: 79  total_loss: 2.859  loss_sem_seg: 1.339  loss_rpn_cls: 0.3419  loss_rpn_loc: 0.13  loss_cls: 0.2955  loss_box_reg: 0.053  loss_mask: 0.6885  time: 0.5344  data_time: 0.0186  lr: 0.00039711  max_mem: 9398M
[12/08 20:49:38 d2.utils.events]:  eta: 1:01:27  iter: 99  total_loss: 2.985  loss_sem_seg: 1.438  loss_rpn_cls: 0.316  loss_rpn_loc: 0.1284  loss_cls: 0.3341  loss_box_reg: 0.09091  loss_mask: 0.6873  time: 0.5398  data_time: 0.0232  lr: 0.00049701  max_mem: 9399M
[12/08 20:49:49 d2.utils.events]:  eta: 1:01:33  iter: 119  total_loss: 2.61  loss_sem_seg: 1.22  loss_rpn_cls: 0.2109  loss_rpn_loc: 0.08355  loss_cls: 0.3243  loss_box_reg: 0.1164  loss_mask: 0.6893  time: 0.5419  data_time: 0.0209  lr: 0.00059691  max_mem: 9399M
[12/08 20:50:00 d2.utils.events]:  eta: 1:01:30  iter: 139  total_loss: 2.781  loss_sem_seg: 1.199  loss_rpn_cls: 0.2164  loss_rpn_loc: 0.09256  loss_cls: 0.394  loss_box_reg: 0.186  loss_mask: 0.688  time: 0.5424  data_time: 0.0192  lr: 0.00069681  max_mem: 9399M
[12/08 20:50:11 d2.utils.events]:  eta: 1:01:48  iter: 159  total_loss: 2.866  loss_sem_seg: 0.9693  loss_rpn_cls: 0.2292  loss_rpn_loc: 0.1192  loss_cls: 0.472  loss_box_reg: 0.2254  loss_mask: 0.688  time: 0.5463  data_time: 0.0181  lr: 0.00079671  max_mem: 9399M
[12/08 20:50:22 d2.utils.events]:  eta: 1:01:40  iter: 179  total_loss: 2.708  loss_sem_seg: 1.167  loss_rpn_cls: 0.2254  loss_rpn_loc: 0.1703  loss_cls: 0.3417  loss_box_reg: 0.1464  loss_mask: 0.6801  time: 0.5466  data_time: 0.0180  lr: 0.00089661  max_mem: 9399M
[12/08 20:50:33 d2.utils.events]:  eta: 1:01:28  iter: 199  total_loss: 2.411  loss_sem_seg: 0.9967  loss_rpn_cls: 0.1759  loss_rpn_loc: 0.1186  loss_cls: 0.2721  loss_box_reg: 0.1195  loss_mask: 0.6778  time: 0.5459  data_time: 0.0183  lr: 0.0009965  max_mem: 9399M
[12/08 20:50:44 d2.utils.events]:  eta: 1:01:17  iter: 219  total_loss: 2.641  loss_sem_seg: 1.041  loss_rpn_cls: 0.2029  loss_rpn_loc: 0.1282  loss_cls: 0.3489  loss_box_reg: 0.1714  loss_mask: 0.6782  time: 0.5461  data_time: 0.0179  lr: 0.0010964  max_mem: 9399M
[12/08 20:50:55 d2.utils.events]:  eta: 1:01:10  iter: 239  total_loss: 2.284  loss_sem_seg: 0.9644  loss_rpn_cls: 0.1529  loss_rpn_loc: 0.1136  loss_cls: 0.289  loss_box_reg: 0.1276  loss_mask: 0.6728  time: 0.5467  data_time: 0.0201  lr: 0.0011963  max_mem: 9399M
[12/08 20:51:06 d2.utils.events]:  eta: 1:01:11  iter: 259  total_loss: 2.564  loss_sem_seg: 1.071  loss_rpn_cls: 0.194  loss_rpn_loc: 0.1487  loss_cls: 0.3334  loss_box_reg: 0.1151  loss_mask: 0.6718  time: 0.5471  data_time: 0.0179  lr: 0.0012962  max_mem: 9399M
[12/08 20:51:17 d2.utils.events]:  eta: 1:01:06  iter: 279  total_loss: 2.394  loss_sem_seg: 0.9743  loss_rpn_cls: 0.1651  loss_rpn_loc: 0.1506  loss_cls: 0.3222  loss_box_reg: 0.1484  loss_mask: 0.6567  time: 0.5473  data_time: 0.0189  lr: 0.0013961  max_mem: 9399M
[12/08 20:51:28 d2.utils.events]:  eta: 1:01:00  iter: 299  total_loss: 2.41  loss_sem_seg: 0.7769  loss_rpn_cls: 0.1589  loss_rpn_loc: 0.1483  loss_cls: 0.41  loss_box_reg: 0.2033  loss_mask: 0.673  time: 0.5477  data_time: 0.0204  lr: 0.001496  max_mem: 9399M
[12/08 20:51:39 d2.utils.events]:  eta: 1:00:52  iter: 319  total_loss: 2.473  loss_sem_seg: 0.8997  loss_rpn_cls: 0.1722  loss_rpn_loc: 0.16  loss_cls: 0.3778  loss_box_reg: 0.2055  loss_mask: 0.6586  time: 0.5481  data_time: 0.0184  lr: 0.0015959  max_mem: 9399M
[12/08 20:51:51 d2.utils.events]:  eta: 1:00:45  iter: 339  total_loss: 2.462  loss_sem_seg: 0.929  loss_rpn_cls: 0.1215  loss_rpn_loc: 0.1023  loss_cls: 0.4001  loss_box_reg: 0.2296  loss_mask: 0.6666  time: 0.5491  data_time: 0.0197  lr: 0.0016958  max_mem: 9399M
[12/08 20:52:02 d2.utils.events]:  eta: 1:00:38  iter: 359  total_loss: 2.476  loss_sem_seg: 0.8511  loss_rpn_cls: 0.1424  loss_rpn_loc: 0.1085  loss_cls: 0.424  loss_box_reg: 0.2473  loss_mask: 0.6546  time: 0.5493  data_time: 0.0188  lr: 0.0017957  max_mem: 9399M
[12/08 20:52:13 d2.utils.events]:  eta: 1:00:32  iter: 379  total_loss: 2.615  loss_sem_seg: 1.055  loss_rpn_cls: 0.149  loss_rpn_loc: 0.1243  loss_cls: 0.4129  loss_box_reg: 0.2299  loss_mask: 0.6495  time: 0.5504  data_time: 0.0187  lr: 0.0018956  max_mem: 9399M
[12/08 20:52:24 d2.utils.events]:  eta: 1:00:22  iter: 399  total_loss: 2.574  loss_sem_seg: 0.9647  loss_rpn_cls: 0.1356  loss_rpn_loc: 0.132  loss_cls: 0.417  loss_box_reg: 0.2463  loss_mask: 0.6392  time: 0.5506  data_time: 0.0178  lr: 0.0019955  max_mem: 9399M
[12/08 20:52:36 d2.utils.events]:  eta: 1:00:14  iter: 419  total_loss: 2.532  loss_sem_seg: 0.8835  loss_rpn_cls: 0.147  loss_rpn_loc: 0.146  loss_cls: 0.4668  loss_box_reg: 0.2756  loss_mask: 0.6423  time: 0.5514  data_time: 0.0195  lr: 0.0020954  max_mem: 9399M
[12/08 20:52:47 d2.utils.events]:  eta: 1:00:08  iter: 439  total_loss: 2.563  loss_sem_seg: 0.9623  loss_rpn_cls: 0.1106  loss_rpn_loc: 0.0895  loss_cls: 0.3917  loss_box_reg: 0.2437  loss_mask: 0.6096  time: 0.5525  data_time: 0.0188  lr: 0.0021953  max_mem: 9399M
[12/08 20:52:58 d2.utils.events]:  eta: 1:00:01  iter: 459  total_loss: 2.461  loss_sem_seg: 0.8298  loss_rpn_cls: 0.1198  loss_rpn_loc: 0.1156  loss_cls: 0.4305  loss_box_reg: 0.2562  loss_mask: 0.6559  time: 0.5525  data_time: 0.0186  lr: 0.0022952  max_mem: 9399M
[12/08 20:53:09 d2.utils.events]:  eta: 0:59:51  iter: 479  total_loss: 2.517  loss_sem_seg: 0.8649  loss_rpn_cls: 0.1375  loss_rpn_loc: 0.1335  loss_cls: 0.3914  loss_box_reg: 0.2494  loss_mask: 0.6159  time: 0.5530  data_time: 0.0210  lr: 0.0023951  max_mem: 9399M
[12/08 20:53:21 d2.utils.events]:  eta: 0:59:41  iter: 499  total_loss: 2.399  loss_sem_seg: 0.9767  loss_rpn_cls: 0.1149  loss_rpn_loc: 0.102  loss_cls: 0.4008  loss_box_reg: 0.2352  loss_mask: 0.6152  time: 0.5532  data_time: 0.0209  lr: 0.002495  max_mem: 9399M
[12/08 20:53:32 d2.utils.events]:  eta: 0:59:35  iter: 519  total_loss: 2.716  loss_sem_seg: 0.9777  loss_rpn_cls: 0.1308  loss_rpn_loc: 0.1007  loss_cls: 0.512  loss_box_reg: 0.3142  loss_mask: 0.6109  time: 0.5546  data_time: 0.0211  lr: 0.0025  max_mem: 9399M
[12/08 20:53:44 d2.utils.events]:  eta: 0:59:25  iter: 539  total_loss: 2.377  loss_sem_seg: 0.8045  loss_rpn_cls: 0.1191  loss_rpn_loc: 0.129  loss_cls: 0.405  loss_box_reg: 0.2325  loss_mask: 0.5971  time: 0.5552  data_time: 0.0206  lr: 0.0025  max_mem: 9399M
[12/08 20:53:55 d2.utils.events]:  eta: 0:59:14  iter: 559  total_loss: 2.319  loss_sem_seg: 0.6666  loss_rpn_cls: 0.1342  loss_rpn_loc: 0.1219  loss_cls: 0.3633  loss_box_reg: 0.2442  loss_mask: 0.6012  time: 0.5552  data_time: 0.0223  lr: 0.0025  max_mem: 9399M
[12/08 20:54:06 d2.utils.events]:  eta: 0:59:05  iter: 579  total_loss: 2.343  loss_sem_seg: 0.7719  loss_rpn_cls: 0.1211  loss_rpn_loc: 0.104  loss_cls: 0.4002  loss_box_reg: 0.2591  loss_mask: 0.5801  time: 0.5556  data_time: 0.0203  lr: 0.0025  max_mem: 9399M
[12/08 20:54:18 d2.utils.events]:  eta: 0:58:57  iter: 599  total_loss: 2.591  loss_sem_seg: 0.9045  loss_rpn_cls: 0.1269  loss_rpn_loc: 0.0906  loss_cls: 0.4348  loss_box_reg: 0.2919  loss_mask: 0.6016  time: 0.5562  data_time: 0.0199  lr: 0.0025  max_mem: 9399M
[12/08 20:54:29 d2.utils.events]:  eta: 0:58:53  iter: 619  total_loss: 2.604  loss_sem_seg: 0.9516  loss_rpn_cls: 0.141  loss_rpn_loc: 0.1325  loss_cls: 0.4397  loss_box_reg: 0.2681  loss_mask: 0.5898  time: 0.5570  data_time: 0.0238  lr: 0.0025  max_mem: 9399M
[12/08 20:54:41 d2.utils.events]:  eta: 0:58:43  iter: 639  total_loss: 2.474  loss_sem_seg: 0.8978  loss_rpn_cls: 0.1282  loss_rpn_loc: 0.1339  loss_cls: 0.4357  loss_box_reg: 0.2953  loss_mask: 0.5856  time: 0.5572  data_time: 0.0189  lr: 0.0025  max_mem: 9399M
[12/08 20:54:52 d2.utils.events]:  eta: 0:58:33  iter: 659  total_loss: 2.525  loss_sem_seg: 0.911  loss_rpn_cls: 0.1184  loss_rpn_loc: 0.1475  loss_cls: 0.4359  loss_box_reg: 0.2891  loss_mask: 0.5751  time: 0.5575  data_time: 0.0193  lr: 0.0025  max_mem: 9399M
[12/08 20:55:03 d2.utils.events]:  eta: 0:58:23  iter: 679  total_loss: 2.355  loss_sem_seg: 0.7324  loss_rpn_cls: 0.1153  loss_rpn_loc: 0.1134  loss_cls: 0.4738  loss_box_reg: 0.3271  loss_mask: 0.5739  time: 0.5578  data_time: 0.0189  lr: 0.0025  max_mem: 9399M
[12/08 20:55:15 d2.utils.events]:  eta: 0:58:16  iter: 699  total_loss: 2.298  loss_sem_seg: 0.7352  loss_rpn_cls: 0.114  loss_rpn_loc: 0.1148  loss_cls: 0.4216  loss_box_reg: 0.2858  loss_mask: 0.5627  time: 0.5585  data_time: 0.0197  lr: 0.0025  max_mem: 9399M
[12/08 20:55:27 d2.utils.events]:  eta: 0:58:07  iter: 719  total_loss: 2.462  loss_sem_seg: 0.8096  loss_rpn_cls: 0.1435  loss_rpn_loc: 0.1426  loss_cls: 0.4555  loss_box_reg: 0.3124  loss_mask: 0.5516  time: 0.5591  data_time: 0.0222  lr: 0.0025  max_mem: 9399M
[12/08 20:55:38 d2.utils.events]:  eta: 0:58:02  iter: 739  total_loss: 2.342  loss_sem_seg: 0.7763  loss_rpn_cls: 0.0957  loss_rpn_loc: 0.09755  loss_cls: 0.4682  loss_box_reg: 0.3274  loss_mask: 0.5556  time: 0.5598  data_time: 0.0190  lr: 0.0025  max_mem: 9399M
[12/08 20:55:50 d2.utils.events]:  eta: 0:57:54  iter: 759  total_loss: 2.431  loss_sem_seg: 0.8551  loss_rpn_cls: 0.09555  loss_rpn_loc: 0.08429  loss_cls: 0.4279  loss_box_reg: 0.3061  loss_mask: 0.552  time: 0.5603  data_time: 0.0241  lr: 0.0025  max_mem: 9399M
[12/08 20:56:02 d2.utils.events]:  eta: 0:57:46  iter: 779  total_loss: 2.407  loss_sem_seg: 0.7433  loss_rpn_cls: 0.09715  loss_rpn_loc: 0.1084  loss_cls: 0.4811  loss_box_reg: 0.3409  loss_mask: 0.5414  time: 0.5608  data_time: 0.0213  lr: 0.0025  max_mem: 9399M
[12/08 20:56:13 d2.utils.events]:  eta: 0:57:36  iter: 799  total_loss: 2.287  loss_sem_seg: 0.8062  loss_rpn_cls: 0.1035  loss_rpn_loc: 0.1355  loss_cls: 0.3981  loss_box_reg: 0.2749  loss_mask: 0.5377  time: 0.5607  data_time: 0.0199  lr: 0.0025  max_mem: 9399M
[12/08 20:56:24 d2.utils.events]:  eta: 0:57:29  iter: 819  total_loss: 2.361  loss_sem_seg: 0.7677  loss_rpn_cls: 0.1042  loss_rpn_loc: 0.1136  loss_cls: 0.4562  loss_box_reg: 0.3503  loss_mask: 0.5523  time: 0.5612  data_time: 0.0215  lr: 0.0025  max_mem: 9399M
[12/08 20:56:36 d2.utils.events]:  eta: 0:57:19  iter: 839  total_loss: 2.352  loss_sem_seg: 0.6774  loss_rpn_cls: 0.1124  loss_rpn_loc: 0.1218  loss_cls: 0.4515  loss_box_reg: 0.3328  loss_mask: 0.5428  time: 0.5618  data_time: 0.0196  lr: 0.0025  max_mem: 9399M
[12/08 20:56:48 d2.utils.events]:  eta: 0:57:10  iter: 859  total_loss: 2.475  loss_sem_seg: 0.8714  loss_rpn_cls: 0.113  loss_rpn_loc: 0.1268  loss_cls: 0.419  loss_box_reg: 0.3443  loss_mask: 0.5354  time: 0.5623  data_time: 0.0246  lr: 0.0025  max_mem: 9399M
[12/08 20:56:59 d2.utils.events]:  eta: 0:57:03  iter: 879  total_loss: 2.354  loss_sem_seg: 0.7535  loss_rpn_cls: 0.1151  loss_rpn_loc: 0.1267  loss_cls: 0.4527  loss_box_reg: 0.3488  loss_mask: 0.5291  time: 0.5627  data_time: 0.0205  lr: 0.0025  max_mem: 9399M
[12/08 20:57:11 d2.utils.events]:  eta: 0:56:56  iter: 899  total_loss: 2.44  loss_sem_seg: 0.7588  loss_rpn_cls: 0.1028  loss_rpn_loc: 0.1019  loss_cls: 0.4737  loss_box_reg: 0.3957  loss_mask: 0.5312  time: 0.5632  data_time: 0.0196  lr: 0.0025  max_mem: 9399M
[12/08 20:57:23 d2.utils.events]:  eta: 0:56:46  iter: 919  total_loss: 2.191  loss_sem_seg: 0.7066  loss_rpn_cls: 0.08107  loss_rpn_loc: 0.09984  loss_cls: 0.4036  loss_box_reg: 0.3152  loss_mask: 0.5174  time: 0.5634  data_time: 0.0205  lr: 0.0025  max_mem: 9399M
[12/08 20:57:34 d2.utils.events]:  eta: 0:56:36  iter: 939  total_loss: 2.199  loss_sem_seg: 0.6469  loss_rpn_cls: 0.09192  loss_rpn_loc: 0.123  loss_cls: 0.4823  loss_box_reg: 0.3626  loss_mask: 0.5133  time: 0.5637  data_time: 0.0220  lr: 0.0025  max_mem: 9399M
[12/08 20:57:46 d2.utils.events]:  eta: 0:56:26  iter: 959  total_loss: 2.597  loss_sem_seg: 0.7992  loss_rpn_cls: 0.1007  loss_rpn_loc: 0.1207  loss_cls: 0.5206  loss_box_reg: 0.3704  loss_mask: 0.5354  time: 0.5640  data_time: 0.0191  lr: 0.0025  max_mem: 9399M
[12/08 20:57:57 d2.utils.events]:  eta: 0:56:16  iter: 979  total_loss: 2.265  loss_sem_seg: 0.7458  loss_rpn_cls: 0.1116  loss_rpn_loc: 0.1132  loss_cls: 0.4626  loss_box_reg: 0.3334  loss_mask: 0.52  time: 0.5642  data_time: 0.0234  lr: 0.0025  max_mem: 9399M
[12/08 20:58:09 d2.utils.events]:  eta: 0:56:06  iter: 999  total_loss: 2.447  loss_sem_seg: 0.7779  loss_rpn_cls: 0.1044  loss_rpn_loc: 0.1112  loss_cls: 0.4384  loss_box_reg: 0.3657  loss_mask: 0.4979  time: 0.5646  data_time: 0.0204  lr: 0.0025  max_mem: 9399M
[12/08 20:58:21 d2.utils.events]:  eta: 0:56:06  iter: 1019  total_loss: 2.302  loss_sem_seg: 0.7479  loss_rpn_cls: 0.1155  loss_rpn_loc: 0.1239  loss_cls: 0.5095  loss_box_reg: 0.3952  loss_mask: 0.5324  time: 0.5652  data_time: 0.0194  lr: 0.0025  max_mem: 9399M
[12/08 20:58:33 d2.utils.events]:  eta: 0:56:04  iter: 1039  total_loss: 2.363  loss_sem_seg: 0.7057  loss_rpn_cls: 0.1087  loss_rpn_loc: 0.1281  loss_cls: 0.5113  loss_box_reg: 0.3974  loss_mask: 0.5037  time: 0.5657  data_time: 0.0202  lr: 0.0025  max_mem: 9399M
[12/08 20:58:44 d2.utils.events]:  eta: 0:55:58  iter: 1059  total_loss: 2.199  loss_sem_seg: 0.7328  loss_rpn_cls: 0.09523  loss_rpn_loc: 0.1025  loss_cls: 0.5052  loss_box_reg: 0.36  loss_mask: 0.4977  time: 0.5661  data_time: 0.0219  lr: 0.0025  max_mem: 9399M
[12/08 20:58:56 d2.utils.events]:  eta: 0:55:56  iter: 1079  total_loss: 2.179  loss_sem_seg: 0.662  loss_rpn_cls: 0.09721  loss_rpn_loc: 0.1036  loss_cls: 0.4721  loss_box_reg: 0.3476  loss_mask: 0.4864  time: 0.5664  data_time: 0.0200  lr: 0.0025  max_mem: 9399M
[12/08 20:59:08 d2.utils.events]:  eta: 0:55:47  iter: 1099  total_loss: 2.252  loss_sem_seg: 0.7098  loss_rpn_cls: 0.09812  loss_rpn_loc: 0.1102  loss_cls: 0.4734  loss_box_reg: 0.3574  loss_mask: 0.4998  time: 0.5666  data_time: 0.0222  lr: 0.0025  max_mem: 9399M
[12/08 20:59:19 d2.utils.events]:  eta: 0:55:38  iter: 1119  total_loss: 2.159  loss_sem_seg: 0.6902  loss_rpn_cls: 0.08507  loss_rpn_loc: 0.1083  loss_cls: 0.4193  loss_box_reg: 0.3572  loss_mask: 0.4933  time: 0.5668  data_time: 0.0204  lr: 0.0025  max_mem: 9399M
[12/08 20:59:31 d2.utils.events]:  eta: 0:55:29  iter: 1139  total_loss: 2.213  loss_sem_seg: 0.6209  loss_rpn_cls: 0.08821  loss_rpn_loc: 0.08878  loss_cls: 0.3864  loss_box_reg: 0.3206  loss_mask: 0.5091  time: 0.5671  data_time: 0.0227  lr: 0.0025  max_mem: 9399M
[12/08 20:59:42 d2.utils.events]:  eta: 0:55:17  iter: 1159  total_loss: 2.028  loss_sem_seg: 0.6366  loss_rpn_cls: 0.08689  loss_rpn_loc: 0.09245  loss_cls: 0.3865  loss_box_reg: 0.3106  loss_mask: 0.4901  time: 0.5671  data_time: 0.0177  lr: 0.0025  max_mem: 9399M
[12/08 20:59:54 d2.utils.events]:  eta: 0:55:12  iter: 1179  total_loss: 2.258  loss_sem_seg: 0.6935  loss_rpn_cls: 0.1075  loss_rpn_loc: 0.1416  loss_cls: 0.435  loss_box_reg: 0.3415  loss_mask: 0.4881  time: 0.5673  data_time: 0.0208  lr: 0.0025  max_mem: 9399M
[12/08 21:00:05 d2.utils.events]:  eta: 0:55:06  iter: 1199  total_loss: 1.994  loss_sem_seg: 0.5757  loss_rpn_cls: 0.106  loss_rpn_loc: 0.1198  loss_cls: 0.4166  loss_box_reg: 0.3271  loss_mask: 0.4862  time: 0.5676  data_time: 0.0220  lr: 0.0025  max_mem: 9399M
[12/08 21:00:17 d2.utils.events]:  eta: 0:54:57  iter: 1219  total_loss: 2.19  loss_sem_seg: 0.6401  loss_rpn_cls: 0.09493  loss_rpn_loc: 0.1007  loss_cls: 0.4576  loss_box_reg: 0.3904  loss_mask: 0.5201  time: 0.5677  data_time: 0.0207  lr: 0.0025  max_mem: 9399M
[12/08 21:00:29 d2.utils.events]:  eta: 0:54:48  iter: 1239  total_loss: 2.21  loss_sem_seg: 0.598  loss_rpn_cls: 0.0911  loss_rpn_loc: 0.1119  loss_cls: 0.4553  loss_box_reg: 0.377  loss_mask: 0.4918  time: 0.5680  data_time: 0.0206  lr: 0.0025  max_mem: 9399M
[12/08 21:00:40 d2.utils.events]:  eta: 0:54:37  iter: 1259  total_loss: 2.119  loss_sem_seg: 0.6923  loss_rpn_cls: 0.09841  loss_rpn_loc: 0.1168  loss_cls: 0.4148  loss_box_reg: 0.3162  loss_mask: 0.4849  time: 0.5682  data_time: 0.0220  lr: 0.0025  max_mem: 9399M
[12/08 21:00:52 d2.utils.events]:  eta: 0:54:33  iter: 1279  total_loss: 2.245  loss_sem_seg: 0.7195  loss_rpn_cls: 0.07614  loss_rpn_loc: 0.1106  loss_cls: 0.4856  loss_box_reg: 0.3574  loss_mask: 0.4797  time: 0.5688  data_time: 0.0220  lr: 0.0025  max_mem: 9399M
[12/08 21:01:04 d2.utils.events]:  eta: 0:54:27  iter: 1299  total_loss: 2.109  loss_sem_seg: 0.7019  loss_rpn_cls: 0.08317  loss_rpn_loc: 0.09221  loss_cls: 0.408  loss_box_reg: 0.354  loss_mask: 0.4867  time: 0.5691  data_time: 0.0206  lr: 0.0025  max_mem: 9399M
[12/08 21:01:16 d2.utils.events]:  eta: 0:54:22  iter: 1319  total_loss: 2.269  loss_sem_seg: 0.6778  loss_rpn_cls: 0.1091  loss_rpn_loc: 0.1367  loss_cls: 0.4271  loss_box_reg: 0.3517  loss_mask: 0.4854  time: 0.5696  data_time: 0.0243  lr: 0.0025  max_mem: 9399M
[12/08 21:01:28 d2.utils.events]:  eta: 0:54:08  iter: 1339  total_loss: 2.115  loss_sem_seg: 0.6228  loss_rpn_cls: 0.09652  loss_rpn_loc: 0.1054  loss_cls: 0.4063  loss_box_reg: 0.321  loss_mask: 0.4937  time: 0.5695  data_time: 0.0223  lr: 0.0025  max_mem: 9399M
[12/08 21:01:39 d2.utils.events]:  eta: 0:54:02  iter: 1359  total_loss: 2.087  loss_sem_seg: 0.6164  loss_rpn_cls: 0.07296  loss_rpn_loc: 0.107  loss_cls: 0.4507  loss_box_reg: 0.3564  loss_mask: 0.4838  time: 0.5698  data_time: 0.0232  lr: 0.0025  max_mem: 9399M
[12/08 21:01:51 d2.utils.events]:  eta: 0:53:54  iter: 1379  total_loss: 2.044  loss_sem_seg: 0.6596  loss_rpn_cls: 0.0972  loss_rpn_loc: 0.1041  loss_cls: 0.3985  loss_box_reg: 0.3216  loss_mask: 0.4897  time: 0.5700  data_time: 0.0202  lr: 0.0025  max_mem: 9399M
[12/08 21:02:03 d2.utils.events]:  eta: 0:53:46  iter: 1399  total_loss: 2.034  loss_sem_seg: 0.6584  loss_rpn_cls: 0.07576  loss_rpn_loc: 0.08714  loss_cls: 0.3854  loss_box_reg: 0.3142  loss_mask: 0.4695  time: 0.5701  data_time: 0.0195  lr: 0.0025  max_mem: 9399M
[12/08 21:02:14 d2.utils.events]:  eta: 0:53:36  iter: 1419  total_loss: 2.05  loss_sem_seg: 0.6128  loss_rpn_cls: 0.09303  loss_rpn_loc: 0.116  loss_cls: 0.3751  loss_box_reg: 0.3032  loss_mask: 0.4754  time: 0.5704  data_time: 0.0246  lr: 0.0025  max_mem: 9399M
[12/08 21:02:26 d2.utils.events]:  eta: 0:53:27  iter: 1439  total_loss: 2.151  loss_sem_seg: 0.6938  loss_rpn_cls: 0.08187  loss_rpn_loc: 0.1139  loss_cls: 0.4354  loss_box_reg: 0.3492  loss_mask: 0.494  time: 0.5707  data_time: 0.0228  lr: 0.0025  max_mem: 9399M
[12/08 21:02:38 d2.utils.events]:  eta: 0:53:18  iter: 1459  total_loss: 2.129  loss_sem_seg: 0.6035  loss_rpn_cls: 0.1195  loss_rpn_loc: 0.113  loss_cls: 0.4384  loss_box_reg: 0.3676  loss_mask: 0.4634  time: 0.5711  data_time: 0.0216  lr: 0.0025  max_mem: 9399M
[12/08 21:02:50 d2.utils.events]:  eta: 0:53:08  iter: 1479  total_loss: 2.187  loss_sem_seg: 0.7149  loss_rpn_cls: 0.07534  loss_rpn_loc: 0.09261  loss_cls: 0.4283  loss_box_reg: 0.3949  loss_mask: 0.4734  time: 0.5714  data_time: 0.0243  lr: 0.0025  max_mem: 9399M
[12/08 21:03:02 d2.utils.events]:  eta: 0:53:01  iter: 1499  total_loss: 2.051  loss_sem_seg: 0.5471  loss_rpn_cls: 0.06242  loss_rpn_loc: 0.09539  loss_cls: 0.4662  loss_box_reg: 0.3204  loss_mask: 0.4961  time: 0.5717  data_time: 0.0221  lr: 0.0025  max_mem: 9399M
[12/08 21:03:14 d2.utils.events]:  eta: 0:52:52  iter: 1519  total_loss: 2.274  loss_sem_seg: 0.7055  loss_rpn_cls: 0.08584  loss_rpn_loc: 0.1112  loss_cls: 0.4241  loss_box_reg: 0.3273  loss_mask: 0.4711  time: 0.5721  data_time: 0.0191  lr: 0.0025  max_mem: 9399M
[12/08 21:03:26 d2.utils.events]:  eta: 0:52:40  iter: 1539  total_loss: 2.108  loss_sem_seg: 0.6216  loss_rpn_cls: 0.07104  loss_rpn_loc: 0.06967  loss_cls: 0.4573  loss_box_reg: 0.367  loss_mask: 0.472  time: 0.5724  data_time: 0.0200  lr: 0.0025  max_mem: 9399M
[12/08 21:03:38 d2.utils.events]:  eta: 0:52:34  iter: 1559  total_loss: 2.191  loss_sem_seg: 0.6949  loss_rpn_cls: 0.1033  loss_rpn_loc: 0.1022  loss_cls: 0.43  loss_box_reg: 0.3505  loss_mask: 0.4759  time: 0.5726  data_time: 0.0189  lr: 0.0025  max_mem: 9399M
[12/08 21:03:49 d2.utils.events]:  eta: 0:52:24  iter: 1579  total_loss: 1.95  loss_sem_seg: 0.56  loss_rpn_cls: 0.09078  loss_rpn_loc: 0.1051  loss_cls: 0.3984  loss_box_reg: 0.326  loss_mask: 0.4713  time: 0.5726  data_time: 0.0217  lr: 0.0025  max_mem: 9399M
[12/08 21:04:01 d2.utils.events]:  eta: 0:52:14  iter: 1599  total_loss: 2.109  loss_sem_seg: 0.5507  loss_rpn_cls: 0.08297  loss_rpn_loc: 0.09981  loss_cls: 0.4753  loss_box_reg: 0.3615  loss_mask: 0.4699  time: 0.5727  data_time: 0.0198  lr: 0.0025  max_mem: 9399M
[12/08 21:04:12 d2.utils.events]:  eta: 0:52:02  iter: 1619  total_loss: 2.134  loss_sem_seg: 0.7057  loss_rpn_cls: 0.07811  loss_rpn_loc: 0.07574  loss_cls: 0.4329  loss_box_reg: 0.3749  loss_mask: 0.4717  time: 0.5727  data_time: 0.0211  lr: 0.0025  max_mem: 9399M
[12/08 21:04:24 d2.utils.events]:  eta: 0:51:54  iter: 1639  total_loss: 2.183  loss_sem_seg: 0.6553  loss_rpn_cls: 0.07819  loss_rpn_loc: 0.07541  loss_cls: 0.4445  loss_box_reg: 0.3759  loss_mask: 0.4707  time: 0.5730  data_time: 0.0214  lr: 0.0025  max_mem: 9399M
[12/08 21:04:36 d2.utils.events]:  eta: 0:51:45  iter: 1659  total_loss: 2.18  loss_sem_seg: 0.6691  loss_rpn_cls: 0.09561  loss_rpn_loc: 0.1169  loss_cls: 0.4422  loss_box_reg: 0.4046  loss_mask: 0.4606  time: 0.5734  data_time: 0.0194  lr: 0.0025  max_mem: 9399M
[12/08 21:04:48 d2.utils.events]:  eta: 0:51:36  iter: 1679  total_loss: 2.134  loss_sem_seg: 0.6424  loss_rpn_cls: 0.07895  loss_rpn_loc: 0.09897  loss_cls: 0.3777  loss_box_reg: 0.3414  loss_mask: 0.4888  time: 0.5736  data_time: 0.0203  lr: 0.0025  max_mem: 9399M
[12/08 21:05:00 d2.utils.events]:  eta: 0:51:25  iter: 1699  total_loss: 2.059  loss_sem_seg: 0.6594  loss_rpn_cls: 0.08597  loss_rpn_loc: 0.09335  loss_cls: 0.3882  loss_box_reg: 0.3489  loss_mask: 0.4597  time: 0.5737  data_time: 0.0222  lr: 0.0025  max_mem: 9399M
[12/08 21:05:12 d2.utils.events]:  eta: 0:51:17  iter: 1719  total_loss: 2.283  loss_sem_seg: 0.5931  loss_rpn_cls: 0.09739  loss_rpn_loc: 0.1516  loss_cls: 0.5132  loss_box_reg: 0.4551  loss_mask: 0.4685  time: 0.5742  data_time: 0.0209  lr: 0.0025  max_mem: 9399M
[12/08 21:05:24 d2.utils.events]:  eta: 0:51:07  iter: 1739  total_loss: 2.13  loss_sem_seg: 0.6433  loss_rpn_cls: 0.08983  loss_rpn_loc: 0.07541  loss_cls: 0.461  loss_box_reg: 0.3522  loss_mask: 0.4708  time: 0.5744  data_time: 0.0225  lr: 0.0025  max_mem: 9399M
[12/08 21:05:36 d2.utils.events]:  eta: 0:51:00  iter: 1759  total_loss: 2.077  loss_sem_seg: 0.6117  loss_rpn_cls: 0.08516  loss_rpn_loc: 0.1092  loss_cls: 0.4092  loss_box_reg: 0.3766  loss_mask: 0.4732  time: 0.5745  data_time: 0.0207  lr: 0.0025  max_mem: 9399M
[12/08 21:05:48 d2.utils.events]:  eta: 0:50:50  iter: 1779  total_loss: 1.948  loss_sem_seg: 0.5774  loss_rpn_cls: 0.0899  loss_rpn_loc: 0.1176  loss_cls: 0.3895  loss_box_reg: 0.3585  loss_mask: 0.4562  time: 0.5747  data_time: 0.0208  lr: 0.0025  max_mem: 9399M
[12/08 21:05:59 d2.utils.events]:  eta: 0:50:40  iter: 1799  total_loss: 1.957  loss_sem_seg: 0.5938  loss_rpn_cls: 0.08527  loss_rpn_loc: 0.07654  loss_cls: 0.3927  loss_box_reg: 0.3543  loss_mask: 0.4514  time: 0.5748  data_time: 0.0193  lr: 0.0025  max_mem: 9399M
[12/08 21:06:11 d2.utils.events]:  eta: 0:50:27  iter: 1819  total_loss: 1.948  loss_sem_seg: 0.6278  loss_rpn_cls: 0.08286  loss_rpn_loc: 0.0786  loss_cls: 0.3402  loss_box_reg: 0.3082  loss_mask: 0.4488  time: 0.5747  data_time: 0.0195  lr: 0.0025  max_mem: 9399M
[12/08 21:06:22 d2.utils.events]:  eta: 0:50:15  iter: 1839  total_loss: 1.945  loss_sem_seg: 0.5948  loss_rpn_cls: 0.07451  loss_rpn_loc: 0.07865  loss_cls: 0.3824  loss_box_reg: 0.3006  loss_mask: 0.4535  time: 0.5748  data_time: 0.0221  lr: 0.0025  max_mem: 9399M
[12/08 21:06:34 d2.utils.events]:  eta: 0:50:02  iter: 1859  total_loss: 2.088  loss_sem_seg: 0.6752  loss_rpn_cls: 0.06421  loss_rpn_loc: 0.07048  loss_cls: 0.3651  loss_box_reg: 0.3628  loss_mask: 0.4505  time: 0.5749  data_time: 0.0229  lr: 0.0025  max_mem: 9399M
[12/08 21:06:46 d2.utils.events]:  eta: 0:49:52  iter: 1879  total_loss: 2.056  loss_sem_seg: 0.5423  loss_rpn_cls: 0.09594  loss_rpn_loc: 0.0972  loss_cls: 0.4405  loss_box_reg: 0.3898  loss_mask: 0.4795  time: 0.5750  data_time: 0.0189  lr: 0.0025  max_mem: 9399M
[12/08 21:06:57 d2.utils.events]:  eta: 0:49:40  iter: 1899  total_loss: 2.176  loss_sem_seg: 0.7377  loss_rpn_cls: 0.0788  loss_rpn_loc: 0.103  loss_cls: 0.4128  loss_box_reg: 0.3354  loss_mask: 0.4478  time: 0.5751  data_time: 0.0183  lr: 0.0025  max_mem: 9399M
[12/08 21:07:09 d2.utils.events]:  eta: 0:49:28  iter: 1919  total_loss: 2.015  loss_sem_seg: 0.6194  loss_rpn_cls: 0.06853  loss_rpn_loc: 0.08646  loss_cls: 0.4228  loss_box_reg: 0.3728  loss_mask: 0.4265  time: 0.5752  data_time: 0.0229  lr: 0.0025  max_mem: 9399M
[12/08 21:07:21 d2.utils.events]:  eta: 0:49:19  iter: 1939  total_loss: 1.98  loss_sem_seg: 0.6408  loss_rpn_cls: 0.1008  loss_rpn_loc: 0.1308  loss_cls: 0.366  loss_box_reg: 0.3378  loss_mask: 0.4539  time: 0.5753  data_time: 0.0183  lr: 0.0025  max_mem: 9399M
[12/08 21:07:32 d2.utils.events]:  eta: 0:49:05  iter: 1959  total_loss: 2.05  loss_sem_seg: 0.6462  loss_rpn_cls: 0.1063  loss_rpn_loc: 0.1163  loss_cls: 0.3474  loss_box_reg: 0.2974  loss_mask: 0.4608  time: 0.5753  data_time: 0.0214  lr: 0.0025  max_mem: 9399M
[12/08 21:07:44 d2.utils.events]:  eta: 0:48:53  iter: 1979  total_loss: 2.019  loss_sem_seg: 0.5603  loss_rpn_cls: 0.08329  loss_rpn_loc: 0.09183  loss_cls: 0.3924  loss_box_reg: 0.3298  loss_mask: 0.4584  time: 0.5752  data_time: 0.0197  lr: 0.0025  max_mem: 9399M
[12/08 21:07:55 d2.utils.events]:  eta: 0:48:41  iter: 1999  total_loss: 2.025  loss_sem_seg: 0.6584  loss_rpn_cls: 0.08059  loss_rpn_loc: 0.08306  loss_cls: 0.4161  loss_box_reg: 0.3563  loss_mask: 0.4463  time: 0.5753  data_time: 0.0191  lr: 0.0025  max_mem: 9399M
[12/08 21:08:07 d2.utils.events]:  eta: 0:48:31  iter: 2019  total_loss: 1.974  loss_sem_seg: 0.5831  loss_rpn_cls: 0.07111  loss_rpn_loc: 0.08952  loss_cls: 0.4204  loss_box_reg: 0.3611  loss_mask: 0.4381  time: 0.5755  data_time: 0.0229  lr: 0.0025  max_mem: 9399M
[12/08 21:08:19 d2.utils.events]:  eta: 0:48:20  iter: 2039  total_loss: 1.777  loss_sem_seg: 0.5045  loss_rpn_cls: 0.06999  loss_rpn_loc: 0.08102  loss_cls: 0.3345  loss_box_reg: 0.321  loss_mask: 0.4462  time: 0.5757  data_time: 0.0199  lr: 0.0025  max_mem: 9399M
[12/08 21:08:31 d2.utils.events]:  eta: 0:48:08  iter: 2059  total_loss: 1.874  loss_sem_seg: 0.6083  loss_rpn_cls: 0.07358  loss_rpn_loc: 0.08091  loss_cls: 0.3318  loss_box_reg: 0.3185  loss_mask: 0.4625  time: 0.5756  data_time: 0.0204  lr: 0.0025  max_mem: 9399M
[12/08 21:08:42 d2.utils.events]:  eta: 0:47:57  iter: 2079  total_loss: 1.939  loss_sem_seg: 0.5729  loss_rpn_cls: 0.07259  loss_rpn_loc: 0.1081  loss_cls: 0.4025  loss_box_reg: 0.3464  loss_mask: 0.4448  time: 0.5757  data_time: 0.0199  lr: 0.0025  max_mem: 9399M
[12/08 21:08:54 d2.utils.events]:  eta: 0:47:45  iter: 2099  total_loss: 1.971  loss_sem_seg: 0.6871  loss_rpn_cls: 0.05994  loss_rpn_loc: 0.07847  loss_cls: 0.376  loss_box_reg: 0.353  loss_mask: 0.4411  time: 0.5757  data_time: 0.0188  lr: 0.0025  max_mem: 9399M
[12/08 21:09:06 d2.utils.events]:  eta: 0:47:36  iter: 2119  total_loss: 1.891  loss_sem_seg: 0.5024  loss_rpn_cls: 0.06025  loss_rpn_loc: 0.08901  loss_cls: 0.3431  loss_box_reg: 0.3278  loss_mask: 0.4188  time: 0.5758  data_time: 0.0200  lr: 0.0025  max_mem: 9399M
[12/08 21:09:18 d2.utils.events]:  eta: 0:47:27  iter: 2139  total_loss: 2.047  loss_sem_seg: 0.5443  loss_rpn_cls: 0.08178  loss_rpn_loc: 0.114  loss_cls: 0.4229  loss_box_reg: 0.3608  loss_mask: 0.4496  time: 0.5760  data_time: 0.0198  lr: 0.0025  max_mem: 9399M
[12/08 21:09:29 d2.utils.events]:  eta: 0:47:16  iter: 2159  total_loss: 1.975  loss_sem_seg: 0.6005  loss_rpn_cls: 0.08694  loss_rpn_loc: 0.09954  loss_cls: 0.3545  loss_box_reg: 0.3382  loss_mask: 0.4495  time: 0.5761  data_time: 0.0257  lr: 0.0025  max_mem: 9399M
[12/08 21:09:41 d2.utils.events]:  eta: 0:47:04  iter: 2179  total_loss: 1.904  loss_sem_seg: 0.6051  loss_rpn_cls: 0.0666  loss_rpn_loc: 0.0775  loss_cls: 0.3228  loss_box_reg: 0.3459  loss_mask: 0.444  time: 0.5761  data_time: 0.0228  lr: 0.0025  max_mem: 9399M
[12/08 21:09:53 d2.utils.events]:  eta: 0:46:55  iter: 2199  total_loss: 2.002  loss_sem_seg: 0.5069  loss_rpn_cls: 0.07933  loss_rpn_loc: 0.1095  loss_cls: 0.4183  loss_box_reg: 0.3809  loss_mask: 0.4392  time: 0.5763  data_time: 0.0205  lr: 0.0025  max_mem: 9399M
[12/08 21:10:05 d2.utils.events]:  eta: 0:46:44  iter: 2219  total_loss: 1.896  loss_sem_seg: 0.5657  loss_rpn_cls: 0.06904  loss_rpn_loc: 0.08238  loss_cls: 0.3516  loss_box_reg: 0.2946  loss_mask: 0.4171  time: 0.5764  data_time: 0.0254  lr: 0.0025  max_mem: 9399M
[12/08 21:10:16 d2.utils.events]:  eta: 0:46:31  iter: 2239  total_loss: 1.858  loss_sem_seg: 0.5035  loss_rpn_cls: 0.08704  loss_rpn_loc: 0.07661  loss_cls: 0.3734  loss_box_reg: 0.3271  loss_mask: 0.4326  time: 0.5765  data_time: 0.0227  lr: 0.0025  max_mem: 9399M
[12/08 21:10:28 d2.utils.events]:  eta: 0:46:19  iter: 2259  total_loss: 2.077  loss_sem_seg: 0.6224  loss_rpn_cls: 0.07557  loss_rpn_loc: 0.09527  loss_cls: 0.41  loss_box_reg: 0.3658  loss_mask: 0.459  time: 0.5766  data_time: 0.0214  lr: 0.0025  max_mem: 9399M
[12/08 21:10:40 d2.utils.events]:  eta: 0:46:07  iter: 2279  total_loss: 1.974  loss_sem_seg: 0.6203  loss_rpn_cls: 0.06778  loss_rpn_loc: 0.1102  loss_cls: 0.363  loss_box_reg: 0.3436  loss_mask: 0.4255  time: 0.5767  data_time: 0.0209  lr: 0.0025  max_mem: 9399M
[12/08 21:10:52 d2.utils.events]:  eta: 0:45:56  iter: 2299  total_loss: 1.823  loss_sem_seg: 0.5194  loss_rpn_cls: 0.07336  loss_rpn_loc: 0.117  loss_cls: 0.3969  loss_box_reg: 0.3467  loss_mask: 0.4486  time: 0.5769  data_time: 0.0193  lr: 0.0025  max_mem: 9399M
[12/08 21:11:04 d2.utils.events]:  eta: 0:45:43  iter: 2319  total_loss: 1.895  loss_sem_seg: 0.5255  loss_rpn_cls: 0.07297  loss_rpn_loc: 0.08725  loss_cls: 0.3696  loss_box_reg: 0.3451  loss_mask: 0.4435  time: 0.5770  data_time: 0.0211  lr: 0.0025  max_mem: 9399M
[12/08 21:11:15 d2.utils.events]:  eta: 0:45:32  iter: 2339  total_loss: 1.914  loss_sem_seg: 0.5725  loss_rpn_cls: 0.07167  loss_rpn_loc: 0.08862  loss_cls: 0.3394  loss_box_reg: 0.2707  loss_mask: 0.4396  time: 0.5770  data_time: 0.0195  lr: 0.0025  max_mem: 9399M
[12/08 21:11:27 d2.utils.events]:  eta: 0:45:24  iter: 2359  total_loss: 2.064  loss_sem_seg: 0.6203  loss_rpn_cls: 0.08612  loss_rpn_loc: 0.1158  loss_cls: 0.4241  loss_box_reg: 0.3821  loss_mask: 0.4603  time: 0.5773  data_time: 0.0229  lr: 0.0025  max_mem: 9399M
[12/08 21:11:39 d2.utils.events]:  eta: 0:45:12  iter: 2379  total_loss: 2.041  loss_sem_seg: 0.5804  loss_rpn_cls: 0.06341  loss_rpn_loc: 0.07975  loss_cls: 0.4237  loss_box_reg: 0.388  loss_mask: 0.4683  time: 0.5773  data_time: 0.0202  lr: 0.0025  max_mem: 9399M
[12/08 21:11:51 d2.utils.events]:  eta: 0:45:01  iter: 2399  total_loss: 1.885  loss_sem_seg: 0.509  loss_rpn_cls: 0.07984  loss_rpn_loc: 0.08636  loss_cls: 0.4181  loss_box_reg: 0.3568  loss_mask: 0.4322  time: 0.5774  data_time: 0.0213  lr: 0.0025  max_mem: 9399M
[12/08 21:12:03 d2.utils.events]:  eta: 0:44:51  iter: 2419  total_loss: 2.101  loss_sem_seg: 0.6303  loss_rpn_cls: 0.081  loss_rpn_loc: 0.09271  loss_cls: 0.4031  loss_box_reg: 0.3581  loss_mask: 0.4422  time: 0.5776  data_time: 0.0227  lr: 0.0025  max_mem: 9399M
[12/08 21:12:15 d2.utils.events]:  eta: 0:44:37  iter: 2439  total_loss: 1.924  loss_sem_seg: 0.754  loss_rpn_cls: 0.06849  loss_rpn_loc: 0.09994  loss_cls: 0.4367  loss_box_reg: 0.3156  loss_mask: 0.4241  time: 0.5777  data_time: 0.0226  lr: 0.0025  max_mem: 9399M
[12/08 21:12:26 d2.utils.events]:  eta: 0:44:24  iter: 2459  total_loss: 1.986  loss_sem_seg: 0.5847  loss_rpn_cls: 0.07714  loss_rpn_loc: 0.09949  loss_cls: 0.3781  loss_box_reg: 0.3208  loss_mask: 0.4473  time: 0.5777  data_time: 0.0193  lr: 0.0025  max_mem: 9399M
[12/08 21:12:38 d2.utils.events]:  eta: 0:44:11  iter: 2479  total_loss: 1.882  loss_sem_seg: 0.5595  loss_rpn_cls: 0.07157  loss_rpn_loc: 0.1153  loss_cls: 0.3507  loss_box_reg: 0.336  loss_mask: 0.4303  time: 0.5777  data_time: 0.0218  lr: 0.0025  max_mem: 9399M
[12/08 21:12:50 d2.utils.events]:  eta: 0:44:00  iter: 2499  total_loss: 1.911  loss_sem_seg: 0.6233  loss_rpn_cls: 0.06515  loss_rpn_loc: 0.1067  loss_cls: 0.3626  loss_box_reg: 0.3406  loss_mask: 0.4256  time: 0.5779  data_time: 0.0202  lr: 0.0025  max_mem: 9399M
[12/08 21:13:02 d2.utils.events]:  eta: 0:43:47  iter: 2519  total_loss: 1.98  loss_sem_seg: 0.5734  loss_rpn_cls: 0.09365  loss_rpn_loc: 0.1066  loss_cls: 0.3714  loss_box_reg: 0.3927  loss_mask: 0.4412  time: 0.5781  data_time: 0.0237  lr: 0.0025  max_mem: 9399M
[12/08 21:13:14 d2.utils.events]:  eta: 0:43:36  iter: 2539  total_loss: 1.946  loss_sem_seg: 0.6128  loss_rpn_cls: 0.07789  loss_rpn_loc: 0.1047  loss_cls: 0.368  loss_box_reg: 0.3678  loss_mask: 0.4316  time: 0.5781  data_time: 0.0233  lr: 0.0025  max_mem: 9399M
[12/08 21:13:26 d2.utils.events]:  eta: 0:43:23  iter: 2559  total_loss: 1.914  loss_sem_seg: 0.5682  loss_rpn_cls: 0.076  loss_rpn_loc: 0.08451  loss_cls: 0.3421  loss_box_reg: 0.3348  loss_mask: 0.4442  time: 0.5783  data_time: 0.0242  lr: 0.0025  max_mem: 9399M
[12/08 21:13:37 d2.utils.events]:  eta: 0:43:12  iter: 2579  total_loss: 1.973  loss_sem_seg: 0.5788  loss_rpn_cls: 0.08555  loss_rpn_loc: 0.09996  loss_cls: 0.369  loss_box_reg: 0.3759  loss_mask: 0.4629  time: 0.5784  data_time: 0.0208  lr: 0.0025  max_mem: 9399M
[12/08 21:13:49 d2.utils.events]:  eta: 0:43:01  iter: 2599  total_loss: 2.053  loss_sem_seg: 0.6544  loss_rpn_cls: 0.08706  loss_rpn_loc: 0.109  loss_cls: 0.3976  loss_box_reg: 0.3291  loss_mask: 0.4439  time: 0.5785  data_time: 0.0206  lr: 0.0025  max_mem: 9399M
[12/08 21:14:01 d2.utils.events]:  eta: 0:42:51  iter: 2619  total_loss: 1.917  loss_sem_seg: 0.5857  loss_rpn_cls: 0.07176  loss_rpn_loc: 0.07229  loss_cls: 0.4125  loss_box_reg: 0.358  loss_mask: 0.4454  time: 0.5786  data_time: 0.0223  lr: 0.0025  max_mem: 9399M
[12/08 21:14:13 d2.utils.events]:  eta: 0:42:39  iter: 2639  total_loss: 2.089  loss_sem_seg: 0.5289  loss_rpn_cls: 0.08198  loss_rpn_loc: 0.108  loss_cls: 0.4609  loss_box_reg: 0.4398  loss_mask: 0.456  time: 0.5787  data_time: 0.0223  lr: 0.0025  max_mem: 9399M
[12/08 21:14:25 d2.utils.events]:  eta: 0:42:27  iter: 2659  total_loss: 1.901  loss_sem_seg: 0.5203  loss_rpn_cls: 0.06209  loss_rpn_loc: 0.08069  loss_cls: 0.3254  loss_box_reg: 0.3197  loss_mask: 0.4259  time: 0.5788  data_time: 0.0226  lr: 0.0025  max_mem: 9399M
[12/08 21:14:37 d2.utils.events]:  eta: 0:42:14  iter: 2679  total_loss: 1.84  loss_sem_seg: 0.5777  loss_rpn_cls: 0.07646  loss_rpn_loc: 0.09018  loss_cls: 0.347  loss_box_reg: 0.3326  loss_mask: 0.4419  time: 0.5789  data_time: 0.0195  lr: 0.0025  max_mem: 9399M
[12/08 21:14:48 d2.utils.events]:  eta: 0:42:02  iter: 2699  total_loss: 1.914  loss_sem_seg: 0.5593  loss_rpn_cls: 0.07443  loss_rpn_loc: 0.1182  loss_cls: 0.3367  loss_box_reg: 0.3658  loss_mask: 0.4313  time: 0.5789  data_time: 0.0225  lr: 0.0025  max_mem: 9399M
[12/08 21:15:00 d2.utils.events]:  eta: 0:41:48  iter: 2719  total_loss: 1.891  loss_sem_seg: 0.5391  loss_rpn_cls: 0.08113  loss_rpn_loc: 0.1209  loss_cls: 0.3923  loss_box_reg: 0.3354  loss_mask: 0.4307  time: 0.5789  data_time: 0.0206  lr: 0.0025  max_mem: 9399M
[12/08 21:15:11 d2.utils.events]:  eta: 0:41:35  iter: 2739  total_loss: 1.832  loss_sem_seg: 0.5023  loss_rpn_cls: 0.07137  loss_rpn_loc: 0.08014  loss_cls: 0.3272  loss_box_reg: 0.2613  loss_mask: 0.4191  time: 0.5789  data_time: 0.0203  lr: 0.0025  max_mem: 9399M
[12/08 21:15:23 d2.utils.events]:  eta: 0:41:21  iter: 2759  total_loss: 1.877  loss_sem_seg: 0.5391  loss_rpn_cls: 0.07665  loss_rpn_loc: 0.09904  loss_cls: 0.3816  loss_box_reg: 0.3366  loss_mask: 0.4341  time: 0.5789  data_time: 0.0231  lr: 0.0025  max_mem: 9399M
[12/08 21:15:35 d2.utils.events]:  eta: 0:41:10  iter: 2779  total_loss: 1.908  loss_sem_seg: 0.5675  loss_rpn_cls: 0.07542  loss_rpn_loc: 0.08722  loss_cls: 0.3729  loss_box_reg: 0.3505  loss_mask: 0.4053  time: 0.5790  data_time: 0.0255  lr: 0.0025  max_mem: 9399M
[12/08 21:15:47 d2.utils.events]:  eta: 0:41:00  iter: 2799  total_loss: 1.932  loss_sem_seg: 0.5618  loss_rpn_cls: 0.07828  loss_rpn_loc: 0.1042  loss_cls: 0.376  loss_box_reg: 0.3432  loss_mask: 0.4119  time: 0.5792  data_time: 0.0245  lr: 0.0025  max_mem: 9399M
[12/08 21:15:59 d2.utils.events]:  eta: 0:40:51  iter: 2819  total_loss: 1.981  loss_sem_seg: 0.5071  loss_rpn_cls: 0.06924  loss_rpn_loc: 0.0934  loss_cls: 0.4015  loss_box_reg: 0.3577  loss_mask: 0.4231  time: 0.5793  data_time: 0.0194  lr: 0.0025  max_mem: 9399M
[12/08 21:16:11 d2.utils.events]:  eta: 0:40:40  iter: 2839  total_loss: 2.033  loss_sem_seg: 0.5252  loss_rpn_cls: 0.08852  loss_rpn_loc: 0.1345  loss_cls: 0.4082  loss_box_reg: 0.3872  loss_mask: 0.4381  time: 0.5793  data_time: 0.0215  lr: 0.0025  max_mem: 9399M
[12/08 21:16:22 d2.utils.events]:  eta: 0:40:28  iter: 2859  total_loss: 1.75  loss_sem_seg: 0.6004  loss_rpn_cls: 0.07683  loss_rpn_loc: 0.09679  loss_cls: 0.3237  loss_box_reg: 0.3132  loss_mask: 0.4304  time: 0.5794  data_time: 0.0210  lr: 0.0025  max_mem: 9399M
[12/08 21:16:34 d2.utils.events]:  eta: 0:40:18  iter: 2879  total_loss: 1.891  loss_sem_seg: 0.6002  loss_rpn_cls: 0.06421  loss_rpn_loc: 0.07888  loss_cls: 0.3212  loss_box_reg: 0.3218  loss_mask: 0.427  time: 0.5794  data_time: 0.0240  lr: 0.0025  max_mem: 9399M
[12/08 21:16:46 d2.utils.events]:  eta: 0:40:08  iter: 2899  total_loss: 1.977  loss_sem_seg: 0.54  loss_rpn_cls: 0.09288  loss_rpn_loc: 0.09859  loss_cls: 0.4256  loss_box_reg: 0.4001  loss_mask: 0.4271  time: 0.5796  data_time: 0.0197  lr: 0.0025  max_mem: 9399M
[12/08 21:16:58 d2.utils.events]:  eta: 0:39:58  iter: 2919  total_loss: 1.835  loss_sem_seg: 0.4931  loss_rpn_cls: 0.06696  loss_rpn_loc: 0.1166  loss_cls: 0.39  loss_box_reg: 0.3588  loss_mask: 0.4138  time: 0.5797  data_time: 0.0236  lr: 0.0025  max_mem: 9399M
[12/08 21:17:10 d2.utils.events]:  eta: 0:39:49  iter: 2939  total_loss: 1.948  loss_sem_seg: 0.552  loss_rpn_cls: 0.0869  loss_rpn_loc: 0.1124  loss_cls: 0.3625  loss_box_reg: 0.3747  loss_mask: 0.4435  time: 0.5799  data_time: 0.0231  lr: 0.0025  max_mem: 9399M
[12/08 21:17:22 d2.utils.events]:  eta: 0:39:41  iter: 2959  total_loss: 1.967  loss_sem_seg: 0.5003  loss_rpn_cls: 0.09829  loss_rpn_loc: 0.1255  loss_cls: 0.3979  loss_box_reg: 0.3304  loss_mask: 0.4296  time: 0.5800  data_time: 0.0200  lr: 0.0025  max_mem: 9399M
[12/08 21:17:34 d2.utils.events]:  eta: 0:39:30  iter: 2979  total_loss: 2.037  loss_sem_seg: 0.5939  loss_rpn_cls: 0.08901  loss_rpn_loc: 0.1098  loss_cls: 0.3952  loss_box_reg: 0.3819  loss_mask: 0.4337  time: 0.5801  data_time: 0.0212  lr: 0.0025  max_mem: 9399M
[12/08 21:17:46 d2.utils.events]:  eta: 0:39:18  iter: 2999  total_loss: 1.873  loss_sem_seg: 0.5108  loss_rpn_cls: 0.06534  loss_rpn_loc: 0.09005  loss_cls: 0.3575  loss_box_reg: 0.3603  loss_mask: 0.4118  time: 0.5802  data_time: 0.0211  lr: 0.0025  max_mem: 9399M
[12/08 21:17:58 d2.utils.events]:  eta: 0:39:06  iter: 3019  total_loss: 1.998  loss_sem_seg: 0.5693  loss_rpn_cls: 0.06889  loss_rpn_loc: 0.09142  loss_cls: 0.3719  loss_box_reg: 0.3756  loss_mask: 0.4012  time: 0.5803  data_time: 0.0212  lr: 0.0025  max_mem: 9399M
[12/08 21:18:09 d2.utils.events]:  eta: 0:38:54  iter: 3039  total_loss: 1.796  loss_sem_seg: 0.5042  loss_rpn_cls: 0.07032  loss_rpn_loc: 0.1266  loss_cls: 0.3484  loss_box_reg: 0.3237  loss_mask: 0.415  time: 0.5802  data_time: 0.0208  lr: 0.0025  max_mem: 9399M
[12/08 21:18:21 d2.utils.events]:  eta: 0:38:42  iter: 3059  total_loss: 1.864  loss_sem_seg: 0.5629  loss_rpn_cls: 0.06276  loss_rpn_loc: 0.0898  loss_cls: 0.311  loss_box_reg: 0.3327  loss_mask: 0.4058  time: 0.5803  data_time: 0.0204  lr: 0.0025  max_mem: 9399M
[12/08 21:18:33 d2.utils.events]:  eta: 0:38:31  iter: 3079  total_loss: 1.825  loss_sem_seg: 0.5674  loss_rpn_cls: 0.08853  loss_rpn_loc: 0.1274  loss_cls: 0.3327  loss_box_reg: 0.3284  loss_mask: 0.4072  time: 0.5804  data_time: 0.0214  lr: 0.0025  max_mem: 9399M
[12/08 21:18:45 d2.utils.events]:  eta: 0:38:20  iter: 3099  total_loss: 1.803  loss_sem_seg: 0.4421  loss_rpn_cls: 0.07314  loss_rpn_loc: 0.115  loss_cls: 0.3304  loss_box_reg: 0.3691  loss_mask: 0.4226  time: 0.5805  data_time: 0.0208  lr: 0.0025  max_mem: 9399M
[12/08 21:18:57 d2.utils.events]:  eta: 0:38:08  iter: 3119  total_loss: 1.699  loss_sem_seg: 0.5311  loss_rpn_cls: 0.06305  loss_rpn_loc: 0.08143  loss_cls: 0.3252  loss_box_reg: 0.3125  loss_mask: 0.3928  time: 0.5805  data_time: 0.0189  lr: 0.0025  max_mem: 9399M
[12/08 21:19:08 d2.utils.events]:  eta: 0:37:56  iter: 3139  total_loss: 1.778  loss_sem_seg: 0.4379  loss_rpn_cls: 0.06674  loss_rpn_loc: 0.09609  loss_cls: 0.3686  loss_box_reg: 0.382  loss_mask: 0.4106  time: 0.5806  data_time: 0.0209  lr: 0.0025  max_mem: 9399M
[12/08 21:19:21 d2.utils.events]:  eta: 0:37:45  iter: 3159  total_loss: 1.719  loss_sem_seg: 0.4435  loss_rpn_cls: 0.06944  loss_rpn_loc: 0.08373  loss_cls: 0.3283  loss_box_reg: 0.3242  loss_mask: 0.4129  time: 0.5807  data_time: 0.0215  lr: 0.0025  max_mem: 9399M
[12/08 21:19:32 d2.utils.events]:  eta: 0:37:33  iter: 3179  total_loss: 1.814  loss_sem_seg: 0.512  loss_rpn_cls: 0.06505  loss_rpn_loc: 0.09056  loss_cls: 0.4101  loss_box_reg: 0.3988  loss_mask: 0.4192  time: 0.5808  data_time: 0.0206  lr: 0.0025  max_mem: 9399M
[12/08 21:19:44 d2.utils.events]:  eta: 0:37:21  iter: 3199  total_loss: 1.839  loss_sem_seg: 0.4684  loss_rpn_cls: 0.06808  loss_rpn_loc: 0.08248  loss_cls: 0.3506  loss_box_reg: 0.3704  loss_mask: 0.4295  time: 0.5809  data_time: 0.0200  lr: 0.0025  max_mem: 9399M
[12/08 21:19:56 d2.utils.events]:  eta: 0:37:08  iter: 3219  total_loss: 1.885  loss_sem_seg: 0.5636  loss_rpn_cls: 0.07533  loss_rpn_loc: 0.1095  loss_cls: 0.3462  loss_box_reg: 0.3607  loss_mask: 0.4121  time: 0.5809  data_time: 0.0199  lr: 0.0025  max_mem: 9399M
[12/08 21:20:08 d2.utils.events]:  eta: 0:36:57  iter: 3239  total_loss: 1.833  loss_sem_seg: 0.5479  loss_rpn_cls: 0.07033  loss_rpn_loc: 0.1559  loss_cls: 0.3524  loss_box_reg: 0.3281  loss_mask: 0.4155  time: 0.5810  data_time: 0.0201  lr: 0.0025  max_mem: 9399M
[12/08 21:20:20 d2.utils.events]:  eta: 0:36:45  iter: 3259  total_loss: 1.742  loss_sem_seg: 0.5531  loss_rpn_cls: 0.05773  loss_rpn_loc: 0.06682  loss_cls: 0.3125  loss_box_reg: 0.2822  loss_mask: 0.4039  time: 0.5810  data_time: 0.0195  lr: 0.0025  max_mem: 9399M
[12/08 21:20:32 d2.utils.events]:  eta: 0:36:34  iter: 3279  total_loss: 1.799  loss_sem_seg: 0.5372  loss_rpn_cls: 0.06438  loss_rpn_loc: 0.1228  loss_cls: 0.3258  loss_box_reg: 0.3189  loss_mask: 0.4143  time: 0.5811  data_time: 0.0213  lr: 0.0025  max_mem: 9399M
[12/08 21:20:43 d2.utils.events]:  eta: 0:36:21  iter: 3299  total_loss: 1.745  loss_sem_seg: 0.508  loss_rpn_cls: 0.05335  loss_rpn_loc: 0.08681  loss_cls: 0.3413  loss_box_reg: 0.2979  loss_mask: 0.4023  time: 0.5811  data_time: 0.0200  lr: 0.0025  max_mem: 9399M
[12/08 21:20:55 d2.utils.events]:  eta: 0:36:10  iter: 3319  total_loss: 1.918  loss_sem_seg: 0.5019  loss_rpn_cls: 0.07735  loss_rpn_loc: 0.1091  loss_cls: 0.3625  loss_box_reg: 0.382  loss_mask: 0.4325  time: 0.5812  data_time: 0.0203  lr: 0.0025  max_mem: 9399M
[12/08 21:21:07 d2.utils.events]:  eta: 0:35:59  iter: 3339  total_loss: 1.731  loss_sem_seg: 0.46  loss_rpn_cls: 0.06965  loss_rpn_loc: 0.09863  loss_cls: 0.366  loss_box_reg: 0.3207  loss_mask: 0.4007  time: 0.5813  data_time: 0.0222  lr: 0.0025  max_mem: 9399M
[12/08 21:21:19 d2.utils.events]:  eta: 0:35:45  iter: 3359  total_loss: 1.926  loss_sem_seg: 0.5099  loss_rpn_cls: 0.07503  loss_rpn_loc: 0.09444  loss_cls: 0.3895  loss_box_reg: 0.3552  loss_mask: 0.4077  time: 0.5813  data_time: 0.0220  lr: 0.0025  max_mem: 9399M
[12/08 21:21:31 d2.utils.events]:  eta: 0:35:33  iter: 3379  total_loss: 2  loss_sem_seg: 0.5874  loss_rpn_cls: 0.06881  loss_rpn_loc: 0.09149  loss_cls: 0.3362  loss_box_reg: 0.3474  loss_mask: 0.4231  time: 0.5813  data_time: 0.0198  lr: 0.0025  max_mem: 9399M
[12/08 21:21:42 d2.utils.events]:  eta: 0:35:21  iter: 3399  total_loss: 1.787  loss_sem_seg: 0.5118  loss_rpn_cls: 0.06114  loss_rpn_loc: 0.1031  loss_cls: 0.3577  loss_box_reg: 0.3188  loss_mask: 0.3951  time: 0.5813  data_time: 0.0194  lr: 0.0025  max_mem: 9399M
[12/08 21:21:54 d2.utils.events]:  eta: 0:35:09  iter: 3419  total_loss: 1.639  loss_sem_seg: 0.4119  loss_rpn_cls: 0.05567  loss_rpn_loc: 0.08562  loss_cls: 0.3032  loss_box_reg: 0.2961  loss_mask: 0.362  time: 0.5813  data_time: 0.0215  lr: 0.0025  max_mem: 9399M
[12/08 21:22:06 d2.utils.events]:  eta: 0:34:58  iter: 3439  total_loss: 1.832  loss_sem_seg: 0.5051  loss_rpn_cls: 0.07322  loss_rpn_loc: 0.0977  loss_cls: 0.3642  loss_box_reg: 0.3669  loss_mask: 0.4027  time: 0.5814  data_time: 0.0198  lr: 0.0025  max_mem: 9399M
[12/08 21:22:18 d2.utils.events]:  eta: 0:34:47  iter: 3459  total_loss: 1.849  loss_sem_seg: 0.4446  loss_rpn_cls: 0.07151  loss_rpn_loc: 0.1246  loss_cls: 0.3503  loss_box_reg: 0.3621  loss_mask: 0.4305  time: 0.5815  data_time: 0.0232  lr: 0.0025  max_mem: 9399M
[12/08 21:22:30 d2.utils.events]:  eta: 0:34:36  iter: 3479  total_loss: 1.877  loss_sem_seg: 0.5723  loss_rpn_cls: 0.06073  loss_rpn_loc: 0.08539  loss_cls: 0.3566  loss_box_reg: 0.3659  loss_mask: 0.4029  time: 0.5817  data_time: 0.0205  lr: 0.0025  max_mem: 9399M
[12/08 21:22:41 d2.utils.events]:  eta: 0:34:24  iter: 3499  total_loss: 1.713  loss_sem_seg: 0.5481  loss_rpn_cls: 0.06742  loss_rpn_loc: 0.09132  loss_cls: 0.3435  loss_box_reg: 0.324  loss_mask: 0.399  time: 0.5817  data_time: 0.0192  lr: 0.0025  max_mem: 9399M
[12/08 21:22:53 d2.utils.events]:  eta: 0:34:12  iter: 3519  total_loss: 1.883  loss_sem_seg: 0.513  loss_rpn_cls: 0.07184  loss_rpn_loc: 0.09477  loss_cls: 0.3449  loss_box_reg: 0.3613  loss_mask: 0.4148  time: 0.5817  data_time: 0.0201  lr: 0.0025  max_mem: 9399M
[12/08 21:23:05 d2.utils.events]:  eta: 0:34:00  iter: 3539  total_loss: 1.968  loss_sem_seg: 0.5213  loss_rpn_cls: 0.07658  loss_rpn_loc: 0.1117  loss_cls: 0.388  loss_box_reg: 0.3658  loss_mask: 0.4201  time: 0.5818  data_time: 0.0201  lr: 0.0025  max_mem: 9399M
[12/08 21:23:17 d2.utils.events]:  eta: 0:33:48  iter: 3559  total_loss: 1.984  loss_sem_seg: 0.6184  loss_rpn_cls: 0.05851  loss_rpn_loc: 0.106  loss_cls: 0.3518  loss_box_reg: 0.3592  loss_mask: 0.4073  time: 0.5818  data_time: 0.0192  lr: 0.0025  max_mem: 9399M
[12/08 21:23:29 d2.utils.events]:  eta: 0:33:36  iter: 3579  total_loss: 1.862  loss_sem_seg: 0.4491  loss_rpn_cls: 0.08095  loss_rpn_loc: 0.09343  loss_cls: 0.3868  loss_box_reg: 0.3915  loss_mask: 0.3825  time: 0.5819  data_time: 0.0203  lr: 0.0025  max_mem: 9399M
[12/08 21:23:41 d2.utils.events]:  eta: 0:33:25  iter: 3599  total_loss: 1.996  loss_sem_seg: 0.539  loss_rpn_cls: 0.06855  loss_rpn_loc: 0.08966  loss_cls: 0.3862  loss_box_reg: 0.3945  loss_mask: 0.4007  time: 0.5820  data_time: 0.0205  lr: 0.0025  max_mem: 9399M
[12/08 21:23:53 d2.utils.events]:  eta: 0:33:13  iter: 3619  total_loss: 1.73  loss_sem_seg: 0.5001  loss_rpn_cls: 0.08012  loss_rpn_loc: 0.1211  loss_cls: 0.3131  loss_box_reg: 0.314  loss_mask: 0.4052  time: 0.5820  data_time: 0.0210  lr: 0.0025  max_mem: 9399M
[12/08 21:24:05 d2.utils.events]:  eta: 0:33:02  iter: 3639  total_loss: 2.011  loss_sem_seg: 0.6278  loss_rpn_cls: 0.07334  loss_rpn_loc: 0.1147  loss_cls: 0.367  loss_box_reg: 0.3523  loss_mask: 0.4218  time: 0.5821  data_time: 0.0215  lr: 0.0025  max_mem: 9399M
[12/08 21:24:16 d2.utils.events]:  eta: 0:32:50  iter: 3659  total_loss: 1.788  loss_sem_seg: 0.4912  loss_rpn_cls: 0.07737  loss_rpn_loc: 0.09386  loss_cls: 0.3896  loss_box_reg: 0.3655  loss_mask: 0.3961  time: 0.5821  data_time: 0.0190  lr: 0.0025  max_mem: 9399M
[12/08 21:24:28 d2.utils.events]:  eta: 0:32:39  iter: 3679  total_loss: 1.925  loss_sem_seg: 0.5055  loss_rpn_cls: 0.09004  loss_rpn_loc: 0.1353  loss_cls: 0.4376  loss_box_reg: 0.3711  loss_mask: 0.411  time: 0.5822  data_time: 0.0214  lr: 0.0025  max_mem: 9399M
[12/08 21:24:40 d2.utils.events]:  eta: 0:32:28  iter: 3699  total_loss: 1.75  loss_sem_seg: 0.4944  loss_rpn_cls: 0.06615  loss_rpn_loc: 0.09848  loss_cls: 0.3079  loss_box_reg: 0.3227  loss_mask: 0.4053  time: 0.5822  data_time: 0.0227  lr: 0.0025  max_mem: 9399M
[12/08 21:24:52 d2.utils.events]:  eta: 0:32:16  iter: 3719  total_loss: 1.783  loss_sem_seg: 0.4899  loss_rpn_cls: 0.06721  loss_rpn_loc: 0.1074  loss_cls: 0.3534  loss_box_reg: 0.3444  loss_mask: 0.4065  time: 0.5823  data_time: 0.0203  lr: 0.0025  max_mem: 9399M
[12/08 21:25:04 d2.utils.events]:  eta: 0:32:04  iter: 3739  total_loss: 1.934  loss_sem_seg: 0.51  loss_rpn_cls: 0.08288  loss_rpn_loc: 0.1178  loss_cls: 0.3725  loss_box_reg: 0.3852  loss_mask: 0.4028  time: 0.5823  data_time: 0.0194  lr: 0.0025  max_mem: 9399M
[12/08 21:25:15 d2.utils.events]:  eta: 0:31:53  iter: 3759  total_loss: 1.664  loss_sem_seg: 0.4388  loss_rpn_cls: 0.05634  loss_rpn_loc: 0.07783  loss_cls: 0.323  loss_box_reg: 0.298  loss_mask: 0.4096  time: 0.5823  data_time: 0.0181  lr: 0.0025  max_mem: 9399M
[12/08 21:25:27 d2.utils.events]:  eta: 0:31:40  iter: 3779  total_loss: 1.796  loss_sem_seg: 0.5717  loss_rpn_cls: 0.07362  loss_rpn_loc: 0.07791  loss_cls: 0.3577  loss_box_reg: 0.3517  loss_mask: 0.4122  time: 0.5822  data_time: 0.0182  lr: 0.0025  max_mem: 9399M
[12/08 21:25:38 d2.utils.events]:  eta: 0:31:27  iter: 3799  total_loss: 1.874  loss_sem_seg: 0.4821  loss_rpn_cls: 0.07548  loss_rpn_loc: 0.112  loss_cls: 0.3812  loss_box_reg: 0.3502  loss_mask: 0.4044  time: 0.5823  data_time: 0.0201  lr: 0.0025  max_mem: 9399M
[12/08 21:25:50 d2.utils.events]:  eta: 0:31:15  iter: 3819  total_loss: 1.804  loss_sem_seg: 0.4952  loss_rpn_cls: 0.0793  loss_rpn_loc: 0.1055  loss_cls: 0.3386  loss_box_reg: 0.3567  loss_mask: 0.4084  time: 0.5823  data_time: 0.0228  lr: 0.0025  max_mem: 9399M
[12/08 21:26:03 d2.utils.events]:  eta: 0:31:05  iter: 3839  total_loss: 1.813  loss_sem_seg: 0.4979  loss_rpn_cls: 0.0675  loss_rpn_loc: 0.1218  loss_cls: 0.3402  loss_box_reg: 0.3535  loss_mask: 0.4369  time: 0.5825  data_time: 0.0197  lr: 0.0025  max_mem: 9399M
[12/08 21:26:15 d2.utils.events]:  eta: 0:30:54  iter: 3859  total_loss: 1.881  loss_sem_seg: 0.4696  loss_rpn_cls: 0.07158  loss_rpn_loc: 0.1025  loss_cls: 0.3893  loss_box_reg: 0.3905  loss_mask: 0.398  time: 0.5826  data_time: 0.0214  lr: 0.0025  max_mem: 9399M
[12/08 21:26:26 d2.utils.events]:  eta: 0:30:42  iter: 3879  total_loss: 1.774  loss_sem_seg: 0.4622  loss_rpn_cls: 0.0619  loss_rpn_loc: 0.09361  loss_cls: 0.3444  loss_box_reg: 0.3019  loss_mask: 0.3921  time: 0.5826  data_time: 0.0208  lr: 0.0025  max_mem: 9399M
[12/08 21:26:38 d2.utils.events]:  eta: 0:30:30  iter: 3899  total_loss: 1.929  loss_sem_seg: 0.5405  loss_rpn_cls: 0.07176  loss_rpn_loc: 0.1114  loss_cls: 0.3546  loss_box_reg: 0.3997  loss_mask: 0.4195  time: 0.5827  data_time: 0.0230  lr: 0.0025  max_mem: 9399M
[12/08 21:26:50 d2.utils.events]:  eta: 0:30:16  iter: 3919  total_loss: 1.742  loss_sem_seg: 0.438  loss_rpn_cls: 0.0543  loss_rpn_loc: 0.09526  loss_cls: 0.31  loss_box_reg: 0.3198  loss_mask: 0.4062  time: 0.5826  data_time: 0.0193  lr: 0.0025  max_mem: 9399M
[12/08 21:27:02 d2.utils.events]:  eta: 0:30:03  iter: 3939  total_loss: 1.839  loss_sem_seg: 0.495  loss_rpn_cls: 0.07308  loss_rpn_loc: 0.09325  loss_cls: 0.3362  loss_box_reg: 0.3365  loss_mask: 0.4054  time: 0.5827  data_time: 0.0209  lr: 0.0025  max_mem: 9399M
[12/08 21:27:14 d2.utils.events]:  eta: 0:29:50  iter: 3959  total_loss: 1.814  loss_sem_seg: 0.5669  loss_rpn_cls: 0.07487  loss_rpn_loc: 0.08253  loss_cls: 0.3297  loss_box_reg: 0.3106  loss_mask: 0.3834  time: 0.5827  data_time: 0.0223  lr: 0.0025  max_mem: 9399M
[12/08 21:27:25 d2.utils.events]:  eta: 0:29:39  iter: 3979  total_loss: 1.699  loss_sem_seg: 0.5134  loss_rpn_cls: 0.06483  loss_rpn_loc: 0.09198  loss_cls: 0.3297  loss_box_reg: 0.3263  loss_mask: 0.4086  time: 0.5827  data_time: 0.0202  lr: 0.0025  max_mem: 9399M
[12/08 21:27:37 d2.utils.events]:  eta: 0:29:28  iter: 3999  total_loss: 1.691  loss_sem_seg: 0.4417  loss_rpn_cls: 0.05142  loss_rpn_loc: 0.09436  loss_cls: 0.3491  loss_box_reg: 0.3659  loss_mask: 0.4239  time: 0.5829  data_time: 0.0241  lr: 0.0025  max_mem: 9399M
[12/08 21:27:50 d2.utils.events]:  eta: 0:29:16  iter: 4019  total_loss: 1.709  loss_sem_seg: 0.4175  loss_rpn_cls: 0.05487  loss_rpn_loc: 0.0935  loss_cls: 0.3727  loss_box_reg: 0.3936  loss_mask: 0.3899  time: 0.5830  data_time: 0.0204  lr: 0.0025  max_mem: 9399M
[12/08 21:28:01 d2.utils.events]:  eta: 0:29:05  iter: 4039  total_loss: 1.713  loss_sem_seg: 0.4789  loss_rpn_cls: 0.06129  loss_rpn_loc: 0.08751  loss_cls: 0.3492  loss_box_reg: 0.3485  loss_mask: 0.3963  time: 0.5830  data_time: 0.0201  lr: 0.0025  max_mem: 9399M
[12/08 21:28:13 d2.utils.events]:  eta: 0:28:54  iter: 4059  total_loss: 1.576  loss_sem_seg: 0.4362  loss_rpn_cls: 0.05897  loss_rpn_loc: 0.1014  loss_cls: 0.3113  loss_box_reg: 0.3287  loss_mask: 0.3855  time: 0.5831  data_time: 0.0215  lr: 0.0025  max_mem: 9399M
[12/08 21:28:25 d2.utils.events]:  eta: 0:28:42  iter: 4079  total_loss: 1.869  loss_sem_seg: 0.5311  loss_rpn_cls: 0.06794  loss_rpn_loc: 0.1355  loss_cls: 0.3404  loss_box_reg: 0.3062  loss_mask: 0.4005  time: 0.5830  data_time: 0.0202  lr: 0.0025  max_mem: 9399M
[12/08 21:28:37 d2.utils.events]:  eta: 0:28:29  iter: 4099  total_loss: 1.773  loss_sem_seg: 0.5351  loss_rpn_cls: 0.06942  loss_rpn_loc: 0.09149  loss_cls: 0.3787  loss_box_reg: 0.3747  loss_mask: 0.3959  time: 0.5831  data_time: 0.0235  lr: 0.0025  max_mem: 9399M
[12/08 21:28:48 d2.utils.events]:  eta: 0:28:17  iter: 4119  total_loss: 1.765  loss_sem_seg: 0.5046  loss_rpn_cls: 0.06356  loss_rpn_loc: 0.08411  loss_cls: 0.3289  loss_box_reg: 0.3342  loss_mask: 0.3873  time: 0.5831  data_time: 0.0176  lr: 0.0025  max_mem: 9399M
[12/08 21:29:00 d2.utils.events]:  eta: 0:28:05  iter: 4139  total_loss: 1.741  loss_sem_seg: 0.4767  loss_rpn_cls: 0.05988  loss_rpn_loc: 0.09131  loss_cls: 0.2709  loss_box_reg: 0.3242  loss_mask: 0.3959  time: 0.5832  data_time: 0.0225  lr: 0.0025  max_mem: 9399M
[12/08 21:29:12 d2.utils.events]:  eta: 0:27:53  iter: 4159  total_loss: 1.696  loss_sem_seg: 0.4887  loss_rpn_cls: 0.0589  loss_rpn_loc: 0.1075  loss_cls: 0.3069  loss_box_reg: 0.2903  loss_mask: 0.3911  time: 0.5832  data_time: 0.0217  lr: 0.0025  max_mem: 9399M
[12/08 21:29:24 d2.utils.events]:  eta: 0:27:41  iter: 4179  total_loss: 1.541  loss_sem_seg: 0.4018  loss_rpn_cls: 0.05053  loss_rpn_loc: 0.08173  loss_cls: 0.3294  loss_box_reg: 0.3514  loss_mask: 0.4014  time: 0.5832  data_time: 0.0228  lr: 0.0025  max_mem: 9399M
[12/08 21:29:36 d2.utils.events]:  eta: 0:27:31  iter: 4199  total_loss: 1.666  loss_sem_seg: 0.494  loss_rpn_cls: 0.05367  loss_rpn_loc: 0.06923  loss_cls: 0.3268  loss_box_reg: 0.2991  loss_mask: 0.375  time: 0.5832  data_time: 0.0219  lr: 0.0025  max_mem: 9399M
[12/08 21:29:48 d2.utils.events]:  eta: 0:27:20  iter: 4219  total_loss: 1.847  loss_sem_seg: 0.4717  loss_rpn_cls: 0.07146  loss_rpn_loc: 0.1136  loss_cls: 0.3812  loss_box_reg: 0.3971  loss_mask: 0.4057  time: 0.5833  data_time: 0.0202  lr: 0.0025  max_mem: 9399M
[12/08 21:30:00 d2.utils.events]:  eta: 0:27:09  iter: 4239  total_loss: 1.831  loss_sem_seg: 0.4465  loss_rpn_cls: 0.05647  loss_rpn_loc: 0.08302  loss_cls: 0.3457  loss_box_reg: 0.3636  loss_mask: 0.4154  time: 0.5834  data_time: 0.0226  lr: 0.0025  max_mem: 9399M
[12/08 21:30:11 d2.utils.events]:  eta: 0:26:58  iter: 4259  total_loss: 1.826  loss_sem_seg: 0.5347  loss_rpn_cls: 0.07682  loss_rpn_loc: 0.08166  loss_cls: 0.3392  loss_box_reg: 0.3402  loss_mask: 0.4132  time: 0.5834  data_time: 0.0197  lr: 0.0025  max_mem: 9399M
[12/08 21:30:23 d2.utils.events]:  eta: 0:26:46  iter: 4279  total_loss: 1.568  loss_sem_seg: 0.4928  loss_rpn_cls: 0.07404  loss_rpn_loc: 0.09359  loss_cls: 0.2644  loss_box_reg: 0.2853  loss_mask: 0.3791  time: 0.5834  data_time: 0.0207  lr: 0.0025  max_mem: 9399M
[12/08 21:30:35 d2.utils.events]:  eta: 0:26:34  iter: 4299  total_loss: 1.827  loss_sem_seg: 0.4684  loss_rpn_cls: 0.07628  loss_rpn_loc: 0.1294  loss_cls: 0.3544  loss_box_reg: 0.3423  loss_mask: 0.3998  time: 0.5834  data_time: 0.0207  lr: 0.0025  max_mem: 9399M
[12/08 21:30:47 d2.utils.events]:  eta: 0:26:23  iter: 4319  total_loss: 1.744  loss_sem_seg: 0.4321  loss_rpn_cls: 0.07236  loss_rpn_loc: 0.09576  loss_cls: 0.3295  loss_box_reg: 0.3407  loss_mask: 0.4023  time: 0.5835  data_time: 0.0196  lr: 0.0025  max_mem: 9399M
[12/08 21:30:59 d2.utils.events]:  eta: 0:26:11  iter: 4339  total_loss: 1.861  loss_sem_seg: 0.4987  loss_rpn_cls: 0.06714  loss_rpn_loc: 0.09026  loss_cls: 0.3664  loss_box_reg: 0.3845  loss_mask: 0.389  time: 0.5836  data_time: 0.0212  lr: 0.0025  max_mem: 9399M
[12/08 21:31:11 d2.utils.events]:  eta: 0:26:00  iter: 4359  total_loss: 1.732  loss_sem_seg: 0.5068  loss_rpn_cls: 0.06347  loss_rpn_loc: 0.09637  loss_cls: 0.3433  loss_box_reg: 0.354  loss_mask: 0.3833  time: 0.5836  data_time: 0.0212  lr: 0.0025  max_mem: 9399M
[12/08 21:31:22 d2.utils.events]:  eta: 0:25:48  iter: 4379  total_loss: 1.705  loss_sem_seg: 0.4688  loss_rpn_cls: 0.05971  loss_rpn_loc: 0.07609  loss_cls: 0.3493  loss_box_reg: 0.3481  loss_mask: 0.3833  time: 0.5836  data_time: 0.0192  lr: 0.0025  max_mem: 9399M
[12/08 21:31:34 d2.utils.events]:  eta: 0:25:36  iter: 4399  total_loss: 1.67  loss_sem_seg: 0.4826  loss_rpn_cls: 0.06324  loss_rpn_loc: 0.0867  loss_cls: 0.3284  loss_box_reg: 0.3298  loss_mask: 0.3918  time: 0.5836  data_time: 0.0213  lr: 0.0025  max_mem: 9399M
[12/08 21:31:46 d2.utils.events]:  eta: 0:25:24  iter: 4419  total_loss: 1.837  loss_sem_seg: 0.5825  loss_rpn_cls: 0.07013  loss_rpn_loc: 0.1094  loss_cls: 0.346  loss_box_reg: 0.3442  loss_mask: 0.3898  time: 0.5836  data_time: 0.0188  lr: 0.0025  max_mem: 9399M
[12/08 21:31:58 d2.utils.events]:  eta: 0:25:12  iter: 4439  total_loss: 1.815  loss_sem_seg: 0.489  loss_rpn_cls: 0.06978  loss_rpn_loc: 0.109  loss_cls: 0.3547  loss_box_reg: 0.3599  loss_mask: 0.3799  time: 0.5836  data_time: 0.0213  lr: 0.0025  max_mem: 9399M
[12/08 21:32:09 d2.utils.events]:  eta: 0:25:00  iter: 4459  total_loss: 1.688  loss_sem_seg: 0.5499  loss_rpn_cls: 0.04248  loss_rpn_loc: 0.05971  loss_cls: 0.2738  loss_box_reg: 0.3112  loss_mask: 0.3807  time: 0.5836  data_time: 0.0217  lr: 0.0025  max_mem: 9399M
[12/08 21:32:21 d2.utils.events]:  eta: 0:24:49  iter: 4479  total_loss: 1.777  loss_sem_seg: 0.5332  loss_rpn_cls: 0.06569  loss_rpn_loc: 0.0841  loss_cls: 0.3489  loss_box_reg: 0.3582  loss_mask: 0.3956  time: 0.5837  data_time: 0.0222  lr: 0.0025  max_mem: 9399M
[12/08 21:32:33 d2.utils.events]:  eta: 0:24:37  iter: 4499  total_loss: 1.809  loss_sem_seg: 0.5127  loss_rpn_cls: 0.06463  loss_rpn_loc: 0.1008  loss_cls: 0.3276  loss_box_reg: 0.3563  loss_mask: 0.4188  time: 0.5838  data_time: 0.0212  lr: 0.0025  max_mem: 9399M
[12/08 21:32:45 d2.utils.events]:  eta: 0:24:25  iter: 4519  total_loss: 1.786  loss_sem_seg: 0.4937  loss_rpn_cls: 0.06406  loss_rpn_loc: 0.1084  loss_cls: 0.3284  loss_box_reg: 0.3097  loss_mask: 0.3881  time: 0.5839  data_time: 0.0204  lr: 0.0025  max_mem: 9399M
[12/08 21:32:57 d2.utils.events]:  eta: 0:24:13  iter: 4539  total_loss: 1.55  loss_sem_seg: 0.4582  loss_rpn_cls: 0.05132  loss_rpn_loc: 0.07646  loss_cls: 0.2876  loss_box_reg: 0.3049  loss_mask: 0.3912  time: 0.5839  data_time: 0.0206  lr: 0.0025  max_mem: 9399M
[12/08 21:33:09 d2.utils.events]:  eta: 0:24:01  iter: 4559  total_loss: 1.754  loss_sem_seg: 0.4562  loss_rpn_cls: 0.0669  loss_rpn_loc: 0.1067  loss_cls: 0.3364  loss_box_reg: 0.3781  loss_mask: 0.3901  time: 0.5839  data_time: 0.0209  lr: 0.0025  max_mem: 9399M
[12/08 21:33:21 d2.utils.events]:  eta: 0:23:50  iter: 4579  total_loss: 1.77  loss_sem_seg: 0.5512  loss_rpn_cls: 0.05717  loss_rpn_loc: 0.0819  loss_cls: 0.3027  loss_box_reg: 0.3245  loss_mask: 0.3886  time: 0.5839  data_time: 0.0194  lr: 0.0025  max_mem: 9399M
[12/08 21:33:33 d2.utils.events]:  eta: 0:23:38  iter: 4599  total_loss: 1.707  loss_sem_seg: 0.5081  loss_rpn_cls: 0.06141  loss_rpn_loc: 0.08709  loss_cls: 0.3192  loss_box_reg: 0.3388  loss_mask: 0.3843  time: 0.5840  data_time: 0.0199  lr: 0.0025  max_mem: 9399M
[12/08 21:33:44 d2.utils.events]:  eta: 0:23:26  iter: 4619  total_loss: 1.756  loss_sem_seg: 0.4477  loss_rpn_cls: 0.05392  loss_rpn_loc: 0.09719  loss_cls: 0.3261  loss_box_reg: 0.3199  loss_mask: 0.3792  time: 0.5840  data_time: 0.0238  lr: 0.0025  max_mem: 9399M
[12/08 21:33:56 d2.utils.events]:  eta: 0:23:14  iter: 4639  total_loss: 1.866  loss_sem_seg: 0.4865  loss_rpn_cls: 0.06259  loss_rpn_loc: 0.1177  loss_cls: 0.3742  loss_box_reg: 0.3786  loss_mask: 0.4079  time: 0.5841  data_time: 0.0214  lr: 0.0025  max_mem: 9399M
[12/08 21:34:09 d2.utils.events]:  eta: 0:23:03  iter: 4659  total_loss: 1.848  loss_sem_seg: 0.5288  loss_rpn_cls: 0.06954  loss_rpn_loc: 0.08874  loss_cls: 0.3653  loss_box_reg: 0.3946  loss_mask: 0.3954  time: 0.5842  data_time: 0.0228  lr: 0.0025  max_mem: 9399M
[12/08 21:34:20 d2.utils.events]:  eta: 0:22:51  iter: 4679  total_loss: 1.746  loss_sem_seg: 0.5142  loss_rpn_cls: 0.06184  loss_rpn_loc: 0.09547  loss_cls: 0.3358  loss_box_reg: 0.3475  loss_mask: 0.3901  time: 0.5842  data_time: 0.0226  lr: 0.0025  max_mem: 9399M
[12/08 21:34:32 d2.utils.events]:  eta: 0:22:39  iter: 4699  total_loss: 1.727  loss_sem_seg: 0.5644  loss_rpn_cls: 0.05584  loss_rpn_loc: 0.08317  loss_cls: 0.3561  loss_box_reg: 0.3484  loss_mask: 0.4009  time: 0.5842  data_time: 0.0217  lr: 0.0025  max_mem: 9399M
[12/08 21:34:44 d2.utils.events]:  eta: 0:22:28  iter: 4719  total_loss: 1.829  loss_sem_seg: 0.4857  loss_rpn_cls: 0.06384  loss_rpn_loc: 0.09621  loss_cls: 0.3355  loss_box_reg: 0.3294  loss_mask: 0.3889  time: 0.5843  data_time: 0.0236  lr: 0.0025  max_mem: 9399M
[12/08 21:34:56 d2.utils.events]:  eta: 0:22:16  iter: 4739  total_loss: 1.613  loss_sem_seg: 0.5602  loss_rpn_cls: 0.0594  loss_rpn_loc: 0.09246  loss_cls: 0.2454  loss_box_reg: 0.2679  loss_mask: 0.3707  time: 0.5842  data_time: 0.0198  lr: 0.0025  max_mem: 9399M
[12/08 21:35:07 d2.utils.events]:  eta: 0:22:04  iter: 4759  total_loss: 1.767  loss_sem_seg: 0.465  loss_rpn_cls: 0.06727  loss_rpn_loc: 0.1171  loss_cls: 0.3507  loss_box_reg: 0.363  loss_mask: 0.3614  time: 0.5842  data_time: 0.0215  lr: 0.0025  max_mem: 9399M
[12/08 21:35:19 d2.utils.events]:  eta: 0:21:53  iter: 4779  total_loss: 1.65  loss_sem_seg: 0.5015  loss_rpn_cls: 0.04842  loss_rpn_loc: 0.0677  loss_cls: 0.3371  loss_box_reg: 0.3448  loss_mask: 0.4031  time: 0.5843  data_time: 0.0250  lr: 0.0025  max_mem: 9399M
[12/08 21:35:32 d2.utils.events]:  eta: 0:21:41  iter: 4799  total_loss: 1.668  loss_sem_seg: 0.4486  loss_rpn_cls: 0.06172  loss_rpn_loc: 0.08552  loss_cls: 0.3288  loss_box_reg: 0.2989  loss_mask: 0.3683  time: 0.5844  data_time: 0.0214  lr: 0.0025  max_mem: 9399M
[12/08 21:35:43 d2.utils.events]:  eta: 0:21:29  iter: 4819  total_loss: 1.747  loss_sem_seg: 0.4811  loss_rpn_cls: 0.06291  loss_rpn_loc: 0.09741  loss_cls: 0.3185  loss_box_reg: 0.3474  loss_mask: 0.3913  time: 0.5844  data_time: 0.0190  lr: 0.0025  max_mem: 9399M
[12/08 21:35:55 d2.utils.events]:  eta: 0:21:17  iter: 4839  total_loss: 1.611  loss_sem_seg: 0.4177  loss_rpn_cls: 0.06818  loss_rpn_loc: 0.08518  loss_cls: 0.3049  loss_box_reg: 0.3022  loss_mask: 0.3862  time: 0.5845  data_time: 0.0236  lr: 0.0025  max_mem: 9399M
[12/08 21:36:07 d2.utils.events]:  eta: 0:21:05  iter: 4859  total_loss: 1.691  loss_sem_seg: 0.4684  loss_rpn_cls: 0.06786  loss_rpn_loc: 0.07828  loss_cls: 0.3292  loss_box_reg: 0.3356  loss_mask: 0.3928  time: 0.5845  data_time: 0.0215  lr: 0.0025  max_mem: 9399M
[12/08 21:36:19 d2.utils.events]:  eta: 0:20:53  iter: 4879  total_loss: 1.58  loss_sem_seg: 0.48  loss_rpn_cls: 0.06598  loss_rpn_loc: 0.09588  loss_cls: 0.3073  loss_box_reg: 0.2929  loss_mask: 0.3694  time: 0.5845  data_time: 0.0205  lr: 0.0025  max_mem: 9399M
[12/08 21:36:31 d2.utils.events]:  eta: 0:20:42  iter: 4899  total_loss: 1.822  loss_sem_seg: 0.5042  loss_rpn_cls: 0.0642  loss_rpn_loc: 0.1179  loss_cls: 0.3373  loss_box_reg: 0.3213  loss_mask: 0.3912  time: 0.5845  data_time: 0.0191  lr: 0.0025  max_mem: 9399M
[12/08 21:36:43 d2.utils.events]:  eta: 0:20:31  iter: 4919  total_loss: 1.682  loss_sem_seg: 0.463  loss_rpn_cls: 0.06475  loss_rpn_loc: 0.1069  loss_cls: 0.293  loss_box_reg: 0.3655  loss_mask: 0.3817  time: 0.5846  data_time: 0.0202  lr: 0.0025  max_mem: 9399M
[12/08 21:36:54 d2.utils.events]:  eta: 0:20:18  iter: 4939  total_loss: 1.676  loss_sem_seg: 0.4463  loss_rpn_cls: 0.06926  loss_rpn_loc: 0.07586  loss_cls: 0.3347  loss_box_reg: 0.3401  loss_mask: 0.3892  time: 0.5846  data_time: 0.0232  lr: 0.0025  max_mem: 9399M
[12/08 21:37:07 d2.utils.events]:  eta: 0:20:07  iter: 4959  total_loss: 1.782  loss_sem_seg: 0.4966  loss_rpn_cls: 0.06619  loss_rpn_loc: 0.08146  loss_cls: 0.3433  loss_box_reg: 0.3784  loss_mask: 0.4007  time: 0.5847  data_time: 0.0215  lr: 0.0025  max_mem: 9399M
[12/08 21:37:19 d2.utils.events]:  eta: 0:19:55  iter: 4979  total_loss: 1.9  loss_sem_seg: 0.4563  loss_rpn_cls: 0.06995  loss_rpn_loc: 0.08405  loss_cls: 0.3838  loss_box_reg: 0.3916  loss_mask: 0.3781  time: 0.5848  data_time: 0.0225  lr: 0.0025  max_mem: 9399M
[12/08 21:37:31 fvcore.common.checkpoint]: Saving checkpoint to ./output/model_0004999.pth
[12/08 21:37:31 d2.utils.events]:  eta: 0:19:43  iter: 4999  total_loss: 1.571  loss_sem_seg: 0.481  loss_rpn_cls: 0.05564  loss_rpn_loc: 0.06351  loss_cls: 0.3117  loss_box_reg: 0.3248  loss_mask: 0.3592  time: 0.5848  data_time: 0.0204  lr: 0.0025  max_mem: 9399M
[12/08 21:37:44 d2.utils.events]:  eta: 0:19:31  iter: 5019  total_loss: 1.767  loss_sem_seg: 0.5474  loss_rpn_cls: 0.06883  loss_rpn_loc: 0.1035  loss_cls: 0.3249  loss_box_reg: 0.3291  loss_mask: 0.3871  time: 0.5849  data_time: 0.0192  lr: 0.0025  max_mem: 9399M
[12/08 21:37:56 d2.utils.events]:  eta: 0:19:20  iter: 5039  total_loss: 1.694  loss_sem_seg: 0.3933  loss_rpn_cls: 0.06722  loss_rpn_loc: 0.1092  loss_cls: 0.3259  loss_box_reg: 0.3466  loss_mask: 0.3737  time: 0.5849  data_time: 0.0207  lr: 0.0025  max_mem: 9399M
[12/08 21:38:08 d2.utils.events]:  eta: 0:19:08  iter: 5059  total_loss: 1.658  loss_sem_seg: 0.3831  loss_rpn_cls: 0.0559  loss_rpn_loc: 0.1063  loss_cls: 0.3216  loss_box_reg: 0.3441  loss_mask: 0.3973  time: 0.5849  data_time: 0.0201  lr: 0.0025  max_mem: 9399M
[12/08 21:38:20 d2.utils.events]:  eta: 0:18:57  iter: 5079  total_loss: 1.661  loss_sem_seg: 0.4265  loss_rpn_cls: 0.0667  loss_rpn_loc: 0.09525  loss_cls: 0.3368  loss_box_reg: 0.372  loss_mask: 0.3579  time: 0.5850  data_time: 0.0200  lr: 0.0025  max_mem: 9399M
[12/08 21:38:32 d2.utils.events]:  eta: 0:18:46  iter: 5099  total_loss: 1.711  loss_sem_seg: 0.4769  loss_rpn_cls: 0.05986  loss_rpn_loc: 0.077  loss_cls: 0.2846  loss_box_reg: 0.341  loss_mask: 0.3978  time: 0.5851  data_time: 0.0203  lr: 0.0025  max_mem: 9399M
[12/08 21:38:44 d2.utils.events]:  eta: 0:18:34  iter: 5119  total_loss: 1.578  loss_sem_seg: 0.409  loss_rpn_cls: 0.05204  loss_rpn_loc: 0.07443  loss_cls: 0.3026  loss_box_reg: 0.344  loss_mask: 0.361  time: 0.5851  data_time: 0.0260  lr: 0.0025  max_mem: 9399M
[12/08 21:38:56 d2.utils.events]:  eta: 0:18:23  iter: 5139  total_loss: 1.746  loss_sem_seg: 0.4419  loss_rpn_cls: 0.06442  loss_rpn_loc: 0.1001  loss_cls: 0.3371  loss_box_reg: 0.3771  loss_mask: 0.393  time: 0.5852  data_time: 0.0205  lr: 0.0025  max_mem: 9399M
[12/08 21:39:08 d2.utils.events]:  eta: 0:18:11  iter: 5159  total_loss: 1.814  loss_sem_seg: 0.4331  loss_rpn_cls: 0.06274  loss_rpn_loc: 0.09345  loss_cls: 0.3769  loss_box_reg: 0.3809  loss_mask: 0.4013  time: 0.5853  data_time: 0.0223  lr: 0.0025  max_mem: 9399M
[12/08 21:39:20 d2.utils.events]:  eta: 0:17:59  iter: 5179  total_loss: 1.742  loss_sem_seg: 0.5394  loss_rpn_cls: 0.0623  loss_rpn_loc: 0.07062  loss_cls: 0.3384  loss_box_reg: 0.326  loss_mask: 0.3766  time: 0.5853  data_time: 0.0197  lr: 0.0025  max_mem: 9399M
[12/08 21:39:32 d2.utils.events]:  eta: 0:17:47  iter: 5199  total_loss: 1.737  loss_sem_seg: 0.5001  loss_rpn_cls: 0.04612  loss_rpn_loc: 0.06406  loss_cls: 0.3084  loss_box_reg: 0.3042  loss_mask: 0.3909  time: 0.5853  data_time: 0.0189  lr: 0.0025  max_mem: 9399M
[12/08 21:39:44 d2.utils.events]:  eta: 0:17:35  iter: 5219  total_loss: 1.609  loss_sem_seg: 0.4314  loss_rpn_cls: 0.06597  loss_rpn_loc: 0.09266  loss_cls: 0.2853  loss_box_reg: 0.3134  loss_mask: 0.394  time: 0.5853  data_time: 0.0203  lr: 0.0025  max_mem: 9399M
[12/08 21:39:56 d2.utils.events]:  eta: 0:17:23  iter: 5239  total_loss: 1.778  loss_sem_seg: 0.466  loss_rpn_cls: 0.07056  loss_rpn_loc: 0.1147  loss_cls: 0.3398  loss_box_reg: 0.3699  loss_mask: 0.3741  time: 0.5854  data_time: 0.0200  lr: 0.0025  max_mem: 9399M
[12/08 21:40:07 d2.utils.events]:  eta: 0:17:11  iter: 5259  total_loss: 1.563  loss_sem_seg: 0.386  loss_rpn_cls: 0.05476  loss_rpn_loc: 0.08794  loss_cls: 0.2867  loss_box_reg: 0.3484  loss_mask: 0.3581  time: 0.5854  data_time: 0.0217  lr: 0.0025  max_mem: 9399M
[12/08 21:40:19 d2.utils.events]:  eta: 0:16:59  iter: 5279  total_loss: 1.786  loss_sem_seg: 0.4892  loss_rpn_cls: 0.05063  loss_rpn_loc: 0.09124  loss_cls: 0.2907  loss_box_reg: 0.318  loss_mask: 0.3608  time: 0.5854  data_time: 0.0199  lr: 0.0025  max_mem: 9399M
[12/08 21:40:31 d2.utils.events]:  eta: 0:16:48  iter: 5299  total_loss: 1.806  loss_sem_seg: 0.4962  loss_rpn_cls: 0.05548  loss_rpn_loc: 0.1119  loss_cls: 0.3119  loss_box_reg: 0.3559  loss_mask: 0.365  time: 0.5854  data_time: 0.0202  lr: 0.0025  max_mem: 9399M
[12/08 21:40:43 d2.utils.events]:  eta: 0:16:35  iter: 5319  total_loss: 1.52  loss_sem_seg: 0.4625  loss_rpn_cls: 0.06684  loss_rpn_loc: 0.08596  loss_cls: 0.2667  loss_box_reg: 0.3125  loss_mask: 0.3638  time: 0.5854  data_time: 0.0187  lr: 0.0025  max_mem: 9399M
[12/08 21:40:55 d2.utils.events]:  eta: 0:16:23  iter: 5339  total_loss: 1.591  loss_sem_seg: 0.4502  loss_rpn_cls: 0.06687  loss_rpn_loc: 0.08182  loss_cls: 0.3167  loss_box_reg: 0.3089  loss_mask: 0.3846  time: 0.5855  data_time: 0.0217  lr: 0.0025  max_mem: 9399M
[12/08 21:41:06 d2.utils.events]:  eta: 0:16:11  iter: 5359  total_loss: 1.633  loss_sem_seg: 0.4077  loss_rpn_cls: 0.05441  loss_rpn_loc: 0.08665  loss_cls: 0.3347  loss_box_reg: 0.3432  loss_mask: 0.3857  time: 0.5855  data_time: 0.0205  lr: 0.0025  max_mem: 9399M
[12/08 21:41:18 d2.utils.events]:  eta: 0:16:00  iter: 5379  total_loss: 1.601  loss_sem_seg: 0.4315  loss_rpn_cls: 0.05531  loss_rpn_loc: 0.09256  loss_cls: 0.3118  loss_box_reg: 0.3319  loss_mask: 0.3765  time: 0.5855  data_time: 0.0205  lr: 0.0025  max_mem: 9399M
[12/08 21:41:30 d2.utils.events]:  eta: 0:15:49  iter: 5399  total_loss: 1.559  loss_sem_seg: 0.3611  loss_rpn_cls: 0.05539  loss_rpn_loc: 0.09779  loss_cls: 0.3152  loss_box_reg: 0.3356  loss_mask: 0.3766  time: 0.5856  data_time: 0.0217  lr: 0.0025  max_mem: 9399M
[12/08 21:41:42 d2.utils.events]:  eta: 0:15:37  iter: 5419  total_loss: 1.65  loss_sem_seg: 0.4391  loss_rpn_cls: 0.05691  loss_rpn_loc: 0.08001  loss_cls: 0.3143  loss_box_reg: 0.3264  loss_mask: 0.3712  time: 0.5856  data_time: 0.0237  lr: 0.0025  max_mem: 9399M
[12/08 21:41:55 d2.utils.events]:  eta: 0:15:25  iter: 5439  total_loss: 1.748  loss_sem_seg: 0.4534  loss_rpn_cls: 0.05696  loss_rpn_loc: 0.103  loss_cls: 0.3506  loss_box_reg: 0.3611  loss_mask: 0.3738  time: 0.5857  data_time: 0.0201  lr: 0.0025  max_mem: 9399M
[12/08 21:42:07 d2.utils.events]:  eta: 0:15:14  iter: 5459  total_loss: 1.715  loss_sem_seg: 0.4139  loss_rpn_cls: 0.05776  loss_rpn_loc: 0.07277  loss_cls: 0.3221  loss_box_reg: 0.3967  loss_mask: 0.3935  time: 0.5858  data_time: 0.0219  lr: 0.0025  max_mem: 9399M
[12/08 21:42:19 d2.utils.events]:  eta: 0:15:01  iter: 5479  total_loss: 1.608  loss_sem_seg: 0.4383  loss_rpn_cls: 0.06994  loss_rpn_loc: 0.1049  loss_cls: 0.2864  loss_box_reg: 0.3406  loss_mask: 0.3779  time: 0.5858  data_time: 0.0183  lr: 0.0025  max_mem: 9399M
[12/08 21:42:30 d2.utils.events]:  eta: 0:14:49  iter: 5499  total_loss: 1.554  loss_sem_seg: 0.4014  loss_rpn_cls: 0.05328  loss_rpn_loc: 0.08454  loss_cls: 0.3032  loss_box_reg: 0.2947  loss_mask: 0.3759  time: 0.5858  data_time: 0.0195  lr: 0.0025  max_mem: 9399M
[12/08 21:42:42 d2.utils.events]:  eta: 0:14:38  iter: 5519  total_loss: 1.591  loss_sem_seg: 0.437  loss_rpn_cls: 0.04486  loss_rpn_loc: 0.07666  loss_cls: 0.2971  loss_box_reg: 0.3257  loss_mask: 0.388  time: 0.5858  data_time: 0.0211  lr: 0.00025  max_mem: 9399M
[12/08 21:42:54 d2.utils.events]:  eta: 0:14:26  iter: 5539  total_loss: 1.544  loss_sem_seg: 0.3934  loss_rpn_cls: 0.04107  loss_rpn_loc: 0.0817  loss_cls: 0.2739  loss_box_reg: 0.3045  loss_mask: 0.3703  time: 0.5859  data_time: 0.0243  lr: 0.00025  max_mem: 9399M
[12/08 21:43:06 d2.utils.events]:  eta: 0:14:14  iter: 5559  total_loss: 1.624  loss_sem_seg: 0.416  loss_rpn_cls: 0.05492  loss_rpn_loc: 0.08841  loss_cls: 0.2933  loss_box_reg: 0.3293  loss_mask: 0.378  time: 0.5859  data_time: 0.0209  lr: 0.00025  max_mem: 9399M
[12/08 21:43:18 d2.utils.events]:  eta: 0:14:03  iter: 5579  total_loss: 1.603  loss_sem_seg: 0.4584  loss_rpn_cls: 0.04606  loss_rpn_loc: 0.07488  loss_cls: 0.3092  loss_box_reg: 0.35  loss_mask: 0.3834  time: 0.5859  data_time: 0.0203  lr: 0.00025  max_mem: 9399M
[12/08 21:43:30 d2.utils.events]:  eta: 0:13:51  iter: 5599  total_loss: 1.66  loss_sem_seg: 0.3544  loss_rpn_cls: 0.05406  loss_rpn_loc: 0.08946  loss_cls: 0.3208  loss_box_reg: 0.3389  loss_mask: 0.3875  time: 0.5860  data_time: 0.0203  lr: 0.00025  max_mem: 9399M
[12/08 21:43:42 d2.utils.events]:  eta: 0:13:39  iter: 5619  total_loss: 1.493  loss_sem_seg: 0.3327  loss_rpn_cls: 0.05141  loss_rpn_loc: 0.09134  loss_cls: 0.3199  loss_box_reg: 0.3515  loss_mask: 0.3601  time: 0.5860  data_time: 0.0226  lr: 0.00025  max_mem: 9399M
[12/08 21:43:54 d2.utils.events]:  eta: 0:13:27  iter: 5639  total_loss: 1.569  loss_sem_seg: 0.4446  loss_rpn_cls: 0.05139  loss_rpn_loc: 0.08976  loss_cls: 0.2763  loss_box_reg: 0.3044  loss_mask: 0.3712  time: 0.5861  data_time: 0.0214  lr: 0.00025  max_mem: 9399M
[12/08 21:44:06 d2.utils.events]:  eta: 0:13:15  iter: 5659  total_loss: 1.421  loss_sem_seg: 0.3355  loss_rpn_cls: 0.04894  loss_rpn_loc: 0.08502  loss_cls: 0.2774  loss_box_reg: 0.2977  loss_mask: 0.3593  time: 0.5862  data_time: 0.0242  lr: 0.00025  max_mem: 9399M
[12/08 21:44:18 d2.utils.events]:  eta: 0:13:04  iter: 5679  total_loss: 1.479  loss_sem_seg: 0.3879  loss_rpn_cls: 0.04985  loss_rpn_loc: 0.08226  loss_cls: 0.281  loss_box_reg: 0.3211  loss_mask: 0.3692  time: 0.5862  data_time: 0.0203  lr: 0.00025  max_mem: 9399M
[12/08 21:44:30 d2.utils.events]:  eta: 0:12:52  iter: 5699  total_loss: 1.558  loss_sem_seg: 0.3494  loss_rpn_cls: 0.04897  loss_rpn_loc: 0.08414  loss_cls: 0.3024  loss_box_reg: 0.3375  loss_mask: 0.3596  time: 0.5863  data_time: 0.0223  lr: 0.00025  max_mem: 9399M
[12/08 21:44:42 d2.utils.events]:  eta: 0:12:40  iter: 5719  total_loss: 1.642  loss_sem_seg: 0.4141  loss_rpn_cls: 0.05302  loss_rpn_loc: 0.08805  loss_cls: 0.3275  loss_box_reg: 0.3353  loss_mask: 0.3761  time: 0.5863  data_time: 0.0215  lr: 0.00025  max_mem: 9399M
[12/08 21:44:54 d2.utils.events]:  eta: 0:12:28  iter: 5739  total_loss: 1.504  loss_sem_seg: 0.3753  loss_rpn_cls: 0.05226  loss_rpn_loc: 0.08004  loss_cls: 0.3041  loss_box_reg: 0.328  loss_mask: 0.365  time: 0.5863  data_time: 0.0212  lr: 0.00025  max_mem: 9399M
[12/08 21:45:05 d2.utils.events]:  eta: 0:12:17  iter: 5759  total_loss: 1.478  loss_sem_seg: 0.3849  loss_rpn_cls: 0.05297  loss_rpn_loc: 0.07024  loss_cls: 0.2844  loss_box_reg: 0.3143  loss_mask: 0.3507  time: 0.5863  data_time: 0.0191  lr: 0.00025  max_mem: 9399M
[12/08 21:45:17 d2.utils.events]:  eta: 0:12:05  iter: 5779  total_loss: 1.593  loss_sem_seg: 0.3992  loss_rpn_cls: 0.05003  loss_rpn_loc: 0.08423  loss_cls: 0.293  loss_box_reg: 0.3204  loss_mask: 0.3745  time: 0.5863  data_time: 0.0208  lr: 0.00025  max_mem: 9399M
[12/08 21:45:29 d2.utils.events]:  eta: 0:11:52  iter: 5799  total_loss: 1.443  loss_sem_seg: 0.3264  loss_rpn_cls: 0.05366  loss_rpn_loc: 0.07828  loss_cls: 0.2752  loss_box_reg: 0.31  loss_mask: 0.3547  time: 0.5863  data_time: 0.0255  lr: 0.00025  max_mem: 9399M
[12/08 21:45:41 d2.utils.events]:  eta: 0:11:41  iter: 5819  total_loss: 1.315  loss_sem_seg: 0.3286  loss_rpn_cls: 0.04097  loss_rpn_loc: 0.06811  loss_cls: 0.2432  loss_box_reg: 0.268  loss_mask: 0.359  time: 0.5864  data_time: 0.0218  lr: 0.00025  max_mem: 9399M
[12/08 21:45:53 d2.utils.events]:  eta: 0:11:29  iter: 5839  total_loss: 1.738  loss_sem_seg: 0.4633  loss_rpn_cls: 0.06192  loss_rpn_loc: 0.1107  loss_cls: 0.327  loss_box_reg: 0.3955  loss_mask: 0.3832  time: 0.5865  data_time: 0.0189  lr: 0.00025  max_mem: 9399M
[12/08 21:46:05 d2.utils.events]:  eta: 0:11:17  iter: 5859  total_loss: 1.594  loss_sem_seg: 0.3938  loss_rpn_cls: 0.05659  loss_rpn_loc: 0.1182  loss_cls: 0.3165  loss_box_reg: 0.3762  loss_mask: 0.3618  time: 0.5865  data_time: 0.0211  lr: 0.00025  max_mem: 9399M
[12/08 21:46:17 d2.utils.events]:  eta: 0:11:05  iter: 5879  total_loss: 1.556  loss_sem_seg: 0.3657  loss_rpn_cls: 0.04455  loss_rpn_loc: 0.07707  loss_cls: 0.2741  loss_box_reg: 0.3375  loss_mask: 0.3592  time: 0.5865  data_time: 0.0211  lr: 0.00025  max_mem: 9399M
[12/08 21:46:29 d2.utils.events]:  eta: 0:10:53  iter: 5899  total_loss: 1.593  loss_sem_seg: 0.3718  loss_rpn_cls: 0.06207  loss_rpn_loc: 0.08792  loss_cls: 0.2591  loss_box_reg: 0.2945  loss_mask: 0.3731  time: 0.5866  data_time: 0.0186  lr: 0.00025  max_mem: 9399M
[12/08 21:46:41 d2.utils.events]:  eta: 0:10:41  iter: 5919  total_loss: 1.512  loss_sem_seg: 0.3917  loss_rpn_cls: 0.06558  loss_rpn_loc: 0.1221  loss_cls: 0.3176  loss_box_reg: 0.3281  loss_mask: 0.3904  time: 0.5866  data_time: 0.0224  lr: 0.00025  max_mem: 9399M
[12/08 21:46:53 d2.utils.events]:  eta: 0:10:30  iter: 5939  total_loss: 1.628  loss_sem_seg: 0.3758  loss_rpn_cls: 0.05861  loss_rpn_loc: 0.08574  loss_cls: 0.3196  loss_box_reg: 0.3663  loss_mask: 0.3731  time: 0.5866  data_time: 0.0247  lr: 0.00025  max_mem: 9399M
[12/08 21:47:05 d2.utils.events]:  eta: 0:10:18  iter: 5959  total_loss: 1.519  loss_sem_seg: 0.3356  loss_rpn_cls: 0.05933  loss_rpn_loc: 0.07445  loss_cls: 0.3033  loss_box_reg: 0.3077  loss_mask: 0.3825  time: 0.5867  data_time: 0.0249  lr: 0.00025  max_mem: 9399M
[12/08 21:47:17 d2.utils.events]:  eta: 0:10:06  iter: 5979  total_loss: 1.507  loss_sem_seg: 0.3746  loss_rpn_cls: 0.04388  loss_rpn_loc: 0.06742  loss_cls: 0.2733  loss_box_reg: 0.3357  loss_mask: 0.3457  time: 0.5868  data_time: 0.0244  lr: 0.00025  max_mem: 9399M
[12/08 21:47:29 d2.utils.events]:  eta: 0:09:54  iter: 5999  total_loss: 1.409  loss_sem_seg: 0.2946  loss_rpn_cls: 0.04767  loss_rpn_loc: 0.076  loss_cls: 0.2692  loss_box_reg: 0.3277  loss_mask: 0.3656  time: 0.5868  data_time: 0.0209  lr: 0.00025  max_mem: 9399M
[12/08 21:47:42 d2.utils.events]:  eta: 0:09:43  iter: 6019  total_loss: 1.627  loss_sem_seg: 0.3442  loss_rpn_cls: 0.05032  loss_rpn_loc: 0.09295  loss_cls: 0.3336  loss_box_reg: 0.3818  loss_mask: 0.3656  time: 0.5869  data_time: 0.0204  lr: 0.00025  max_mem: 9399M
[12/08 21:47:54 d2.utils.events]:  eta: 0:09:31  iter: 6039  total_loss: 1.654  loss_sem_seg: 0.3301  loss_rpn_cls: 0.0555  loss_rpn_loc: 0.1037  loss_cls: 0.3214  loss_box_reg: 0.3949  loss_mask: 0.3975  time: 0.5870  data_time: 0.0218  lr: 0.00025  max_mem: 9399M
[12/08 21:48:06 d2.utils.events]:  eta: 0:09:20  iter: 6059  total_loss: 1.502  loss_sem_seg: 0.357  loss_rpn_cls: 0.04608  loss_rpn_loc: 0.08222  loss_cls: 0.2588  loss_box_reg: 0.318  loss_mask: 0.3495  time: 0.5870  data_time: 0.0239  lr: 0.00025  max_mem: 9399M
[12/08 21:48:18 d2.utils.events]:  eta: 0:09:08  iter: 6079  total_loss: 1.501  loss_sem_seg: 0.3497  loss_rpn_cls: 0.04554  loss_rpn_loc: 0.09468  loss_cls: 0.2549  loss_box_reg: 0.3342  loss_mask: 0.3497  time: 0.5871  data_time: 0.0215  lr: 0.00025  max_mem: 9399M
[12/08 21:48:30 d2.utils.events]:  eta: 0:08:56  iter: 6099  total_loss: 1.529  loss_sem_seg: 0.394  loss_rpn_cls: 0.03901  loss_rpn_loc: 0.06386  loss_cls: 0.291  loss_box_reg: 0.3249  loss_mask: 0.3647  time: 0.5872  data_time: 0.0214  lr: 0.00025  max_mem: 9399M
[12/08 21:48:42 d2.utils.events]:  eta: 0:08:44  iter: 6119  total_loss: 1.462  loss_sem_seg: 0.3651  loss_rpn_cls: 0.04634  loss_rpn_loc: 0.08031  loss_cls: 0.2909  loss_box_reg: 0.3501  loss_mask: 0.354  time: 0.5872  data_time: 0.0205  lr: 0.00025  max_mem: 9399M
[12/08 21:48:54 d2.utils.events]:  eta: 0:08:32  iter: 6139  total_loss: 1.485  loss_sem_seg: 0.361  loss_rpn_cls: 0.05087  loss_rpn_loc: 0.08706  loss_cls: 0.2675  loss_box_reg: 0.3076  loss_mask: 0.3465  time: 0.5873  data_time: 0.0233  lr: 0.00025  max_mem: 9399M
[12/08 21:49:07 d2.utils.events]:  eta: 0:08:21  iter: 6159  total_loss: 1.617  loss_sem_seg: 0.3927  loss_rpn_cls: 0.05817  loss_rpn_loc: 0.1106  loss_cls: 0.3243  loss_box_reg: 0.3394  loss_mask: 0.3535  time: 0.5873  data_time: 0.0215  lr: 0.00025  max_mem: 9399M
[12/08 21:49:19 d2.utils.events]:  eta: 0:08:09  iter: 6179  total_loss: 1.443  loss_sem_seg: 0.2983  loss_rpn_cls: 0.05449  loss_rpn_loc: 0.08169  loss_cls: 0.2806  loss_box_reg: 0.3226  loss_mask: 0.367  time: 0.5874  data_time: 0.0212  lr: 0.00025  max_mem: 9399M
[12/08 21:49:31 d2.utils.events]:  eta: 0:07:57  iter: 6199  total_loss: 1.572  loss_sem_seg: 0.3368  loss_rpn_cls: 0.05933  loss_rpn_loc: 0.09042  loss_cls: 0.2892  loss_box_reg: 0.3551  loss_mask: 0.3697  time: 0.5874  data_time: 0.0230  lr: 0.00025  max_mem: 9399M
[12/08 21:49:43 d2.utils.events]:  eta: 0:07:46  iter: 6219  total_loss: 1.51  loss_sem_seg: 0.3237  loss_rpn_cls: 0.0478  loss_rpn_loc: 0.09456  loss_cls: 0.3033  loss_box_reg: 0.3289  loss_mask: 0.3426  time: 0.5875  data_time: 0.0191  lr: 0.00025  max_mem: 9399M
[12/08 21:49:55 d2.utils.events]:  eta: 0:07:34  iter: 6239  total_loss: 1.489  loss_sem_seg: 0.3521  loss_rpn_cls: 0.04448  loss_rpn_loc: 0.08684  loss_cls: 0.2714  loss_box_reg: 0.3251  loss_mask: 0.3617  time: 0.5875  data_time: 0.0208  lr: 0.00025  max_mem: 9399M
[12/08 21:50:07 d2.utils.events]:  eta: 0:07:22  iter: 6259  total_loss: 1.385  loss_sem_seg: 0.329  loss_rpn_cls: 0.04117  loss_rpn_loc: 0.0682  loss_cls: 0.2533  loss_box_reg: 0.3152  loss_mask: 0.3582  time: 0.5875  data_time: 0.0214  lr: 0.00025  max_mem: 9399M
[12/08 21:50:19 d2.utils.events]:  eta: 0:07:10  iter: 6279  total_loss: 1.503  loss_sem_seg: 0.3518  loss_rpn_cls: 0.04191  loss_rpn_loc: 0.08836  loss_cls: 0.2757  loss_box_reg: 0.3604  loss_mask: 0.3594  time: 0.5876  data_time: 0.0192  lr: 0.00025  max_mem: 9399M
[12/08 21:50:31 d2.utils.events]:  eta: 0:06:58  iter: 6299  total_loss: 1.352  loss_sem_seg: 0.3689  loss_rpn_cls: 0.04503  loss_rpn_loc: 0.05769  loss_cls: 0.2429  loss_box_reg: 0.2754  loss_mask: 0.3347  time: 0.5876  data_time: 0.0203  lr: 0.00025  max_mem: 9399M
[12/08 21:50:43 d2.utils.events]:  eta: 0:06:46  iter: 6319  total_loss: 1.524  loss_sem_seg: 0.3368  loss_rpn_cls: 0.0439  loss_rpn_loc: 0.08219  loss_cls: 0.3173  loss_box_reg: 0.3802  loss_mask: 0.3811  time: 0.5876  data_time: 0.0216  lr: 0.00025  max_mem: 9399M
[12/08 21:50:55 d2.utils.events]:  eta: 0:06:34  iter: 6339  total_loss: 1.458  loss_sem_seg: 0.3497  loss_rpn_cls: 0.05086  loss_rpn_loc: 0.08014  loss_cls: 0.27  loss_box_reg: 0.3147  loss_mask: 0.3582  time: 0.5877  data_time: 0.0221  lr: 0.00025  max_mem: 9399M
[12/08 21:51:07 d2.utils.events]:  eta: 0:06:22  iter: 6359  total_loss: 1.364  loss_sem_seg: 0.35  loss_rpn_cls: 0.0364  loss_rpn_loc: 0.08023  loss_cls: 0.2453  loss_box_reg: 0.3108  loss_mask: 0.3579  time: 0.5877  data_time: 0.0228  lr: 0.00025  max_mem: 9399M
[12/08 21:51:18 d2.utils.events]:  eta: 0:06:10  iter: 6379  total_loss: 1.376  loss_sem_seg: 0.4184  loss_rpn_cls: 0.04255  loss_rpn_loc: 0.06456  loss_cls: 0.2493  loss_box_reg: 0.3079  loss_mask: 0.3437  time: 0.5877  data_time: 0.0215  lr: 0.00025  max_mem: 9399M
[12/08 21:51:30 d2.utils.events]:  eta: 0:05:58  iter: 6399  total_loss: 1.423  loss_sem_seg: 0.3591  loss_rpn_cls: 0.05426  loss_rpn_loc: 0.0803  loss_cls: 0.2685  loss_box_reg: 0.3168  loss_mask: 0.3501  time: 0.5877  data_time: 0.0199  lr: 0.00025  max_mem: 9399M
[12/08 21:51:43 d2.utils.events]:  eta: 0:05:46  iter: 6419  total_loss: 1.453  loss_sem_seg: 0.3232  loss_rpn_cls: 0.05168  loss_rpn_loc: 0.1008  loss_cls: 0.2781  loss_box_reg: 0.3026  loss_mask: 0.3834  time: 0.5878  data_time: 0.0220  lr: 0.00025  max_mem: 9399M
[12/08 21:51:54 d2.utils.events]:  eta: 0:05:34  iter: 6439  total_loss: 1.575  loss_sem_seg: 0.3977  loss_rpn_cls: 0.05644  loss_rpn_loc: 0.08974  loss_cls: 0.2817  loss_box_reg: 0.3123  loss_mask: 0.3858  time: 0.5878  data_time: 0.0211  lr: 0.00025  max_mem: 9399M
[12/08 21:52:07 d2.utils.events]:  eta: 0:05:22  iter: 6459  total_loss: 1.647  loss_sem_seg: 0.3614  loss_rpn_cls: 0.05348  loss_rpn_loc: 0.1105  loss_cls: 0.3283  loss_box_reg: 0.3797  loss_mask: 0.3786  time: 0.5879  data_time: 0.0216  lr: 0.00025  max_mem: 9399M
[12/08 21:52:19 d2.utils.events]:  eta: 0:05:11  iter: 6479  total_loss: 1.649  loss_sem_seg: 0.348  loss_rpn_cls: 0.05367  loss_rpn_loc: 0.11  loss_cls: 0.3192  loss_box_reg: 0.3798  loss_mask: 0.363  time: 0.5880  data_time: 0.0218  lr: 0.00025  max_mem: 9399M
[12/08 21:52:31 d2.utils.events]:  eta: 0:04:59  iter: 6499  total_loss: 1.555  loss_sem_seg: 0.3502  loss_rpn_cls: 0.05847  loss_rpn_loc: 0.1147  loss_cls: 0.2733  loss_box_reg: 0.3531  loss_mask: 0.3608  time: 0.5880  data_time: 0.0216  lr: 0.00025  max_mem: 9399M
[12/08 21:52:43 d2.utils.events]:  eta: 0:04:47  iter: 6519  total_loss: 1.335  loss_sem_seg: 0.2997  loss_rpn_cls: 0.0359  loss_rpn_loc: 0.04977  loss_cls: 0.2421  loss_box_reg: 0.2884  loss_mask: 0.3332  time: 0.5880  data_time: 0.0192  lr: 0.00025  max_mem: 9399M
[12/08 21:52:55 d2.utils.events]:  eta: 0:04:35  iter: 6539  total_loss: 1.448  loss_sem_seg: 0.3456  loss_rpn_cls: 0.04105  loss_rpn_loc: 0.07665  loss_cls: 0.2771  loss_box_reg: 0.3244  loss_mask: 0.3563  time: 0.5881  data_time: 0.0208  lr: 0.00025  max_mem: 9399M
[12/08 21:53:07 d2.utils.events]:  eta: 0:04:23  iter: 6559  total_loss: 1.639  loss_sem_seg: 0.3632  loss_rpn_cls: 0.06521  loss_rpn_loc: 0.1047  loss_cls: 0.3226  loss_box_reg: 0.3965  loss_mask: 0.3657  time: 0.5882  data_time: 0.0223  lr: 0.00025  max_mem: 9399M
[12/08 21:53:19 d2.utils.events]:  eta: 0:04:11  iter: 6579  total_loss: 1.466  loss_sem_seg: 0.3563  loss_rpn_cls: 0.04214  loss_rpn_loc: 0.09326  loss_cls: 0.2678  loss_box_reg: 0.3011  loss_mask: 0.3677  time: 0.5882  data_time: 0.0239  lr: 0.00025  max_mem: 9399M
[12/08 21:53:32 d2.utils.events]:  eta: 0:04:00  iter: 6599  total_loss: 1.601  loss_sem_seg: 0.4109  loss_rpn_cls: 0.05363  loss_rpn_loc: 0.08092  loss_cls: 0.2871  loss_box_reg: 0.3374  loss_mask: 0.357  time: 0.5883  data_time: 0.0246  lr: 0.00025  max_mem: 9399M
[12/08 21:53:44 d2.utils.events]:  eta: 0:03:48  iter: 6619  total_loss: 1.376  loss_sem_seg: 0.3278  loss_rpn_cls: 0.05466  loss_rpn_loc: 0.09423  loss_cls: 0.2846  loss_box_reg: 0.3076  loss_mask: 0.3443  time: 0.5884  data_time: 0.0225  lr: 0.00025  max_mem: 9399M
[12/08 21:53:56 d2.utils.events]:  eta: 0:03:36  iter: 6639  total_loss: 1.475  loss_sem_seg: 0.3739  loss_rpn_cls: 0.04859  loss_rpn_loc: 0.1044  loss_cls: 0.2614  loss_box_reg: 0.3279  loss_mask: 0.3819  time: 0.5884  data_time: 0.0219  lr: 0.00025  max_mem: 9399M
[12/08 21:54:08 d2.utils.events]:  eta: 0:03:24  iter: 6659  total_loss: 1.543  loss_sem_seg: 0.3454  loss_rpn_cls: 0.05127  loss_rpn_loc: 0.1116  loss_cls: 0.2807  loss_box_reg: 0.3479  loss_mask: 0.3737  time: 0.5885  data_time: 0.0220  lr: 0.00025  max_mem: 9399M
[12/08 21:54:20 d2.utils.events]:  eta: 0:03:11  iter: 6679  total_loss: 1.33  loss_sem_seg: 0.2661  loss_rpn_cls: 0.03958  loss_rpn_loc: 0.073  loss_cls: 0.2399  loss_box_reg: 0.3173  loss_mask: 0.3387  time: 0.5885  data_time: 0.0215  lr: 0.00025  max_mem: 9399M
[12/08 21:54:32 d2.utils.events]:  eta: 0:02:59  iter: 6699  total_loss: 1.538  loss_sem_seg: 0.3548  loss_rpn_cls: 0.05253  loss_rpn_loc: 0.1  loss_cls: 0.3018  loss_box_reg: 0.3685  loss_mask: 0.3578  time: 0.5885  data_time: 0.0197  lr: 0.00025  max_mem: 9399M
[12/08 21:54:44 d2.utils.events]:  eta: 0:02:47  iter: 6719  total_loss: 1.455  loss_sem_seg: 0.3468  loss_rpn_cls: 0.05875  loss_rpn_loc: 0.08343  loss_cls: 0.2671  loss_box_reg: 0.3187  loss_mask: 0.3463  time: 0.5886  data_time: 0.0196  lr: 0.00025  max_mem: 9399M
[12/08 21:54:56 d2.utils.events]:  eta: 0:02:35  iter: 6739  total_loss: 1.613  loss_sem_seg: 0.3576  loss_rpn_cls: 0.04659  loss_rpn_loc: 0.08442  loss_cls: 0.3158  loss_box_reg: 0.3668  loss_mask: 0.3622  time: 0.5886  data_time: 0.0208  lr: 0.00025  max_mem: 9399M
[12/08 21:55:08 d2.utils.events]:  eta: 0:02:24  iter: 6759  total_loss: 1.588  loss_sem_seg: 0.3852  loss_rpn_cls: 0.04993  loss_rpn_loc: 0.09643  loss_cls: 0.3286  loss_box_reg: 0.3017  loss_mask: 0.3801  time: 0.5886  data_time: 0.0216  lr: 0.00025  max_mem: 9399M
[12/08 21:55:20 d2.utils.events]:  eta: 0:02:12  iter: 6779  total_loss: 1.387  loss_sem_seg: 0.3233  loss_rpn_cls: 0.03644  loss_rpn_loc: 0.08096  loss_cls: 0.2459  loss_box_reg: 0.3002  loss_mask: 0.3596  time: 0.5887  data_time: 0.0219  lr: 0.00025  max_mem: 9399M
[12/08 21:55:33 d2.utils.events]:  eta: 0:02:00  iter: 6799  total_loss: 1.719  loss_sem_seg: 0.3477  loss_rpn_cls: 0.05084  loss_rpn_loc: 0.08289  loss_cls: 0.3457  loss_box_reg: 0.4026  loss_mask: 0.3819  time: 0.5888  data_time: 0.0200  lr: 0.00025  max_mem: 9399M
[12/08 21:55:45 d2.utils.events]:  eta: 0:01:48  iter: 6819  total_loss: 1.479  loss_sem_seg: 0.3528  loss_rpn_cls: 0.04671  loss_rpn_loc: 0.1111  loss_cls: 0.284  loss_box_reg: 0.3559  loss_mask: 0.3606  time: 0.5888  data_time: 0.0192  lr: 0.00025  max_mem: 9399M
[12/08 21:55:57 d2.utils.events]:  eta: 0:01:36  iter: 6839  total_loss: 1.638  loss_sem_seg: 0.4182  loss_rpn_cls: 0.05991  loss_rpn_loc: 0.1003  loss_cls: 0.2807  loss_box_reg: 0.329  loss_mask: 0.3573  time: 0.5888  data_time: 0.0234  lr: 0.00025  max_mem: 9399M
[12/08 21:56:09 d2.utils.events]:  eta: 0:01:24  iter: 6859  total_loss: 1.414  loss_sem_seg: 0.3897  loss_rpn_cls: 0.04251  loss_rpn_loc: 0.07052  loss_cls: 0.2526  loss_box_reg: 0.3058  loss_mask: 0.3491  time: 0.5888  data_time: 0.0211  lr: 0.00025  max_mem: 9399M
[12/08 21:56:20 d2.utils.events]:  eta: 0:01:12  iter: 6879  total_loss: 1.456  loss_sem_seg: 0.3472  loss_rpn_cls: 0.04572  loss_rpn_loc: 0.09008  loss_cls: 0.2504  loss_box_reg: 0.2932  loss_mask: 0.3653  time: 0.5889  data_time: 0.0203  lr: 0.00025  max_mem: 9399M
[12/08 21:56:33 d2.utils.events]:  eta: 0:01:00  iter: 6899  total_loss: 1.487  loss_sem_seg: 0.3706  loss_rpn_cls: 0.04358  loss_rpn_loc: 0.0801  loss_cls: 0.3168  loss_box_reg: 0.3125  loss_mask: 0.3544  time: 0.5889  data_time: 0.0220  lr: 0.00025  max_mem: 9399M
[12/08 21:56:45 d2.utils.events]:  eta: 0:00:48  iter: 6919  total_loss: 1.494  loss_sem_seg: 0.3523  loss_rpn_cls: 0.04794  loss_rpn_loc: 0.07733  loss_cls: 0.2791  loss_box_reg: 0.3435  loss_mask: 0.3612  time: 0.5889  data_time: 0.0216  lr: 0.00025  max_mem: 9399M
[12/08 21:56:56 d2.utils.events]:  eta: 0:00:36  iter: 6939  total_loss: 1.354  loss_sem_seg: 0.3248  loss_rpn_cls: 0.05134  loss_rpn_loc: 0.09383  loss_cls: 0.257  loss_box_reg: 0.297  loss_mask: 0.3562  time: 0.5889  data_time: 0.0195  lr: 0.00025  max_mem: 9399M
[12/08 21:57:09 d2.utils.events]:  eta: 0:00:24  iter: 6959  total_loss: 1.586  loss_sem_seg: 0.316  loss_rpn_cls: 0.05194  loss_rpn_loc: 0.098  loss_cls: 0.3129  loss_box_reg: 0.3695  loss_mask: 0.3684  time: 0.5890  data_time: 0.0192  lr: 0.00025  max_mem: 9399M
[12/08 21:57:21 d2.utils.events]:  eta: 0:00:12  iter: 6979  total_loss: 1.493  loss_sem_seg: 0.318  loss_rpn_cls: 0.04124  loss_rpn_loc: 0.09446  loss_cls: 0.2773  loss_box_reg: 0.35  loss_mask: 0.3616  time: 0.5890  data_time: 0.0199  lr: 0.00025  max_mem: 9399M
[12/08 21:57:33 fvcore.common.checkpoint]: Saving checkpoint to ./output/model_final.pth
[12/08 21:57:33 d2.utils.events]:  eta: 0:00:00  iter: 6999  total_loss: 1.444  loss_sem_seg: 0.3571  loss_rpn_cls: 0.0413  loss_rpn_loc: 0.07693  loss_cls: 0.2724  loss_box_reg: 0.3177  loss_mask: 0.3388  time: 0.5891  data_time: 0.0208  lr: 0.00025  max_mem: 9399M
[12/08 21:57:34 d2.engine.hooks]: Overall training speed: 6998 iterations in 1:08:42 (0.5891 s / it)
[12/08 21:57:34 d2.engine.hooks]: Total training time: 1:08:49 (0:00:06 on hooks)
[12/08 21:57:35 d2.data.datasets.coco]: Loaded 5000 images in COCO format from /content/datasets/coco/annotations/instances_val2017.json
[12/08 21:57:35 d2.data.datasets.coco]: Loaded 5000 images with semantic segmentation from /content/datasets/coco/val2017
[12/08 21:57:35 d2.data.dataset_mapper]: [DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]
[12/08 21:57:35 d2.data.common]: Serializing the dataset using: <class 'detectron2.data.common.NumpySerializedList'>
[12/08 21:57:35 d2.data.common]: Serializing 5000 elements to byte tensors and concatenating them all ...
[12/08 21:57:36 d2.data.common]: Serialized dataset takes 19.55 MiB
[12/08 21:57:37 d2.data.datasets.coco]: Loaded 5000 images in COCO format from /content/datasets/coco/annotations/instances_val2017.json
[12/08 21:57:37 d2.data.datasets.coco]: Loaded 5000 images with semantic segmentation from /content/datasets/coco/val2017
[12/08 21:57:38 d2.evaluation.evaluator]: Start inference on 5000 batches
[12/08 21:57:40 d2.evaluation.evaluator]: Inference done 11/5000. Dataloading: 0.0017 s/iter. Inference: 0.0595 s/iter. Eval: 0.0974 s/iter. Total: 0.1586 s/iter. ETA=0:13:11
[12/08 21:57:45 d2.evaluation.evaluator]: Inference done 48/5000. Dataloading: 0.0025 s/iter. Inference: 0.0582 s/iter. Eval: 0.0793 s/iter. Total: 0.1402 s/iter. ETA=0:11:34
[12/08 21:57:50 d2.evaluation.evaluator]: Inference done 86/5000. Dataloading: 0.0026 s/iter. Inference: 0.0574 s/iter. Eval: 0.0778 s/iter. Total: 0.1379 s/iter. ETA=0:11:17
[12/08 21:57:55 d2.evaluation.evaluator]: Inference done 121/5000. Dataloading: 0.0026 s/iter. Inference: 0.0569 s/iter. Eval: 0.0810 s/iter. Total: 0.1406 s/iter. ETA=0:11:26
[12/08 21:58:00 d2.evaluation.evaluator]: Inference done 156/5000. Dataloading: 0.0027 s/iter. Inference: 0.0568 s/iter. Eval: 0.0821 s/iter. Total: 0.1416 s/iter. ETA=0:11:26
[12/08 21:58:06 d2.evaluation.evaluator]: Inference done 190/5000. Dataloading: 0.0027 s/iter. Inference: 0.0568 s/iter. Eval: 0.0836 s/iter. Total: 0.1431 s/iter. ETA=0:11:28
[12/08 21:58:11 d2.evaluation.evaluator]: Inference done 231/5000. Dataloading: 0.0027 s/iter. Inference: 0.0562 s/iter. Eval: 0.0806 s/iter. Total: 0.1396 s/iter. ETA=0:11:05
[12/08 21:58:16 d2.evaluation.evaluator]: Inference done 267/5000. Dataloading: 0.0027 s/iter. Inference: 0.0563 s/iter. Eval: 0.0808 s/iter. Total: 0.1398 s/iter. ETA=0:11:01
[12/08 21:58:21 d2.evaluation.evaluator]: Inference done 302/5000. Dataloading: 0.0027 s/iter. Inference: 0.0563 s/iter. Eval: 0.0813 s/iter. Total: 0.1403 s/iter. ETA=0:10:59
[12/08 21:58:26 d2.evaluation.evaluator]: Inference done 337/5000. Dataloading: 0.0027 s/iter. Inference: 0.0562 s/iter. Eval: 0.0816 s/iter. Total: 0.1407 s/iter. ETA=0:10:55
[12/08 21:58:31 d2.evaluation.evaluator]: Inference done 373/5000. Dataloading: 0.0027 s/iter. Inference: 0.0563 s/iter. Eval: 0.0815 s/iter. Total: 0.1406 s/iter. ETA=0:10:50
[12/08 21:58:36 d2.evaluation.evaluator]: Inference done 412/5000. Dataloading: 0.0027 s/iter. Inference: 0.0561 s/iter. Eval: 0.0806 s/iter. Total: 0.1395 s/iter. ETA=0:10:40
[12/08 21:58:41 d2.evaluation.evaluator]: Inference done 446/5000. Dataloading: 0.0027 s/iter. Inference: 0.0560 s/iter. Eval: 0.0814 s/iter. Total: 0.1402 s/iter. ETA=0:10:38
[12/08 21:58:46 d2.evaluation.evaluator]: Inference done 484/5000. Dataloading: 0.0027 s/iter. Inference: 0.0559 s/iter. Eval: 0.0810 s/iter. Total: 0.1397 s/iter. ETA=0:10:31
[12/08 21:58:51 d2.evaluation.evaluator]: Inference done 521/5000. Dataloading: 0.0027 s/iter. Inference: 0.0559 s/iter. Eval: 0.0810 s/iter. Total: 0.1397 s/iter. ETA=0:10:25
[12/08 21:58:56 d2.evaluation.evaluator]: Inference done 555/5000. Dataloading: 0.0027 s/iter. Inference: 0.0560 s/iter. Eval: 0.0816 s/iter. Total: 0.1404 s/iter. ETA=0:10:24
[12/08 21:59:01 d2.evaluation.evaluator]: Inference done 591/5000. Dataloading: 0.0027 s/iter. Inference: 0.0560 s/iter. Eval: 0.0818 s/iter. Total: 0.1405 s/iter. ETA=0:10:19
[12/08 21:59:06 d2.evaluation.evaluator]: Inference done 628/5000. Dataloading: 0.0027 s/iter. Inference: 0.0560 s/iter. Eval: 0.0816 s/iter. Total: 0.1404 s/iter. ETA=0:10:13
[12/08 21:59:12 d2.evaluation.evaluator]: Inference done 661/5000. Dataloading: 0.0027 s/iter. Inference: 0.0560 s/iter. Eval: 0.0821 s/iter. Total: 0.1410 s/iter. ETA=0:10:11
[12/08 21:59:17 d2.evaluation.evaluator]: Inference done 697/5000. Dataloading: 0.0027 s/iter. Inference: 0.0560 s/iter. Eval: 0.0821 s/iter. Total: 0.1409 s/iter. ETA=0:10:06
[12/08 21:59:22 d2.evaluation.evaluator]: Inference done 731/5000. Dataloading: 0.0027 s/iter. Inference: 0.0560 s/iter. Eval: 0.0824 s/iter. Total: 0.1413 s/iter. ETA=0:10:03
[12/08 21:59:27 d2.evaluation.evaluator]: Inference done 768/5000. Dataloading: 0.0028 s/iter. Inference: 0.0560 s/iter. Eval: 0.0822 s/iter. Total: 0.1410 s/iter. ETA=0:09:56
[12/08 21:59:32 d2.evaluation.evaluator]: Inference done 805/5000. Dataloading: 0.0028 s/iter. Inference: 0.0560 s/iter. Eval: 0.0822 s/iter. Total: 0.1410 s/iter. ETA=0:09:51
[12/08 21:59:37 d2.evaluation.evaluator]: Inference done 844/5000. Dataloading: 0.0028 s/iter. Inference: 0.0560 s/iter. Eval: 0.0818 s/iter. Total: 0.1406 s/iter. ETA=0:09:44
[12/08 21:59:42 d2.evaluation.evaluator]: Inference done 882/5000. Dataloading: 0.0028 s/iter. Inference: 0.0559 s/iter. Eval: 0.0815 s/iter. Total: 0.1403 s/iter. ETA=0:09:37
[12/08 21:59:47 d2.evaluation.evaluator]: Inference done 918/5000. Dataloading: 0.0028 s/iter. Inference: 0.0559 s/iter. Eval: 0.0815 s/iter. Total: 0.1403 s/iter. ETA=0:09:32
[12/08 21:59:52 d2.evaluation.evaluator]: Inference done 955/5000. Dataloading: 0.0028 s/iter. Inference: 0.0559 s/iter. Eval: 0.0815 s/iter. Total: 0.1402 s/iter. ETA=0:09:27
[12/08 21:59:57 d2.evaluation.evaluator]: Inference done 991/5000. Dataloading: 0.0028 s/iter. Inference: 0.0559 s/iter. Eval: 0.0815 s/iter. Total: 0.1402 s/iter. ETA=0:09:22
[12/08 22:00:02 d2.evaluation.evaluator]: Inference done 1024/5000. Dataloading: 0.0028 s/iter. Inference: 0.0559 s/iter. Eval: 0.0819 s/iter. Total: 0.1406 s/iter. ETA=0:09:18
[12/08 22:00:07 d2.evaluation.evaluator]: Inference done 1058/5000. Dataloading: 0.0028 s/iter. Inference: 0.0559 s/iter. Eval: 0.0822 s/iter. Total: 0.1409 s/iter. ETA=0:09:15
[12/08 22:00:12 d2.evaluation.evaluator]: Inference done 1091/5000. Dataloading: 0.0028 s/iter. Inference: 0.0559 s/iter. Eval: 0.0825 s/iter. Total: 0.1412 s/iter. ETA=0:09:12
[12/08 22:00:18 d2.evaluation.evaluator]: Inference done 1124/5000. Dataloading: 0.0028 s/iter. Inference: 0.0559 s/iter. Eval: 0.0831 s/iter. Total: 0.1418 s/iter. ETA=0:09:09
[12/08 22:00:23 d2.evaluation.evaluator]: Inference done 1156/5000. Dataloading: 0.0028 s/iter. Inference: 0.0559 s/iter. Eval: 0.0835 s/iter. Total: 0.1422 s/iter. ETA=0:09:06
[12/08 22:00:28 d2.evaluation.evaluator]: Inference done 1192/5000. Dataloading: 0.0028 s/iter. Inference: 0.0559 s/iter. Eval: 0.0834 s/iter. Total: 0.1421 s/iter. ETA=0:09:01
[12/08 22:00:33 d2.evaluation.evaluator]: Inference done 1226/5000. Dataloading: 0.0028 s/iter. Inference: 0.0559 s/iter. Eval: 0.0835 s/iter. Total: 0.1423 s/iter. ETA=0:08:57
[12/08 22:00:38 d2.evaluation.evaluator]: Inference done 1259/5000. Dataloading: 0.0028 s/iter. Inference: 0.0560 s/iter. Eval: 0.0839 s/iter. Total: 0.1427 s/iter. ETA=0:08:53
[12/08 22:00:43 d2.evaluation.evaluator]: Inference done 1294/5000. Dataloading: 0.0028 s/iter. Inference: 0.0559 s/iter. Eval: 0.0839 s/iter. Total: 0.1427 s/iter. ETA=0:08:48
[12/08 22:00:48 d2.evaluation.evaluator]: Inference done 1328/5000. Dataloading: 0.0028 s/iter. Inference: 0.0559 s/iter. Eval: 0.0841 s/iter. Total: 0.1429 s/iter. ETA=0:08:44
[12/08 22:00:53 d2.evaluation.evaluator]: Inference done 1363/5000. Dataloading: 0.0028 s/iter. Inference: 0.0559 s/iter. Eval: 0.0842 s/iter. Total: 0.1430 s/iter. ETA=0:08:39
[12/08 22:00:58 d2.evaluation.evaluator]: Inference done 1398/5000. Dataloading: 0.0028 s/iter. Inference: 0.0559 s/iter. Eval: 0.0842 s/iter. Total: 0.1430 s/iter. ETA=0:08:34
[12/08 22:01:03 d2.evaluation.evaluator]: Inference done 1433/5000. Dataloading: 0.0028 s/iter. Inference: 0.0559 s/iter. Eval: 0.0843 s/iter. Total: 0.1431 s/iter. ETA=0:08:30
[12/08 22:01:08 d2.evaluation.evaluator]: Inference done 1467/5000. Dataloading: 0.0028 s/iter. Inference: 0.0559 s/iter. Eval: 0.0844 s/iter. Total: 0.1432 s/iter. ETA=0:08:25
[12/08 22:01:13 d2.evaluation.evaluator]: Inference done 1501/5000. Dataloading: 0.0028 s/iter. Inference: 0.0559 s/iter. Eval: 0.0846 s/iter. Total: 0.1433 s/iter. ETA=0:08:21
[12/08 22:01:19 d2.evaluation.evaluator]: Inference done 1536/5000. Dataloading: 0.0028 s/iter. Inference: 0.0558 s/iter. Eval: 0.0847 s/iter. Total: 0.1434 s/iter. ETA=0:08:16
[12/08 22:01:24 d2.evaluation.evaluator]: Inference done 1569/5000. Dataloading: 0.0028 s/iter. Inference: 0.0558 s/iter. Eval: 0.0849 s/iter. Total: 0.1436 s/iter. ETA=0:08:12
[12/08 22:01:29 d2.evaluation.evaluator]: Inference done 1601/5000. Dataloading: 0.0028 s/iter. Inference: 0.0558 s/iter. Eval: 0.0851 s/iter. Total: 0.1439 s/iter. ETA=0:08:08
[12/08 22:01:34 d2.evaluation.evaluator]: Inference done 1637/5000. Dataloading: 0.0028 s/iter. Inference: 0.0558 s/iter. Eval: 0.0851 s/iter. Total: 0.1438 s/iter. ETA=0:08:03
[12/08 22:01:39 d2.evaluation.evaluator]: Inference done 1674/5000. Dataloading: 0.0028 s/iter. Inference: 0.0558 s/iter. Eval: 0.0849 s/iter. Total: 0.1437 s/iter. ETA=0:07:57
[12/08 22:01:44 d2.evaluation.evaluator]: Inference done 1712/5000. Dataloading: 0.0028 s/iter. Inference: 0.0558 s/iter. Eval: 0.0847 s/iter. Total: 0.1434 s/iter. ETA=0:07:51
[12/08 22:01:49 d2.evaluation.evaluator]: Inference done 1747/5000. Dataloading: 0.0028 s/iter. Inference: 0.0558 s/iter. Eval: 0.0847 s/iter. Total: 0.1434 s/iter. ETA=0:07:46
[12/08 22:01:54 d2.evaluation.evaluator]: Inference done 1784/5000. Dataloading: 0.0028 s/iter. Inference: 0.0558 s/iter. Eval: 0.0846 s/iter. Total: 0.1433 s/iter. ETA=0:07:40
[12/08 22:01:59 d2.evaluation.evaluator]: Inference done 1821/5000. Dataloading: 0.0028 s/iter. Inference: 0.0558 s/iter. Eval: 0.0845 s/iter. Total: 0.1431 s/iter. ETA=0:07:35
[12/08 22:02:04 d2.evaluation.evaluator]: Inference done 1856/5000. Dataloading: 0.0028 s/iter. Inference: 0.0558 s/iter. Eval: 0.0845 s/iter. Total: 0.1432 s/iter. ETA=0:07:30
[12/08 22:02:09 d2.evaluation.evaluator]: Inference done 1890/5000. Dataloading: 0.0028 s/iter. Inference: 0.0558 s/iter. Eval: 0.0846 s/iter. Total: 0.1433 s/iter. ETA=0:07:25
[12/08 22:02:14 d2.evaluation.evaluator]: Inference done 1928/5000. Dataloading: 0.0028 s/iter. Inference: 0.0558 s/iter. Eval: 0.0845 s/iter. Total: 0.1431 s/iter. ETA=0:07:19
[12/08 22:02:19 d2.evaluation.evaluator]: Inference done 1966/5000. Dataloading: 0.0028 s/iter. Inference: 0.0557 s/iter. Eval: 0.0844 s/iter. Total: 0.1430 s/iter. ETA=0:07:13
[12/08 22:02:24 d2.evaluation.evaluator]: Inference done 2001/5000. Dataloading: 0.0028 s/iter. Inference: 0.0557 s/iter. Eval: 0.0844 s/iter. Total: 0.1430 s/iter. ETA=0:07:08
[12/08 22:02:29 d2.evaluation.evaluator]: Inference done 2034/5000. Dataloading: 0.0028 s/iter. Inference: 0.0557 s/iter. Eval: 0.0845 s/iter. Total: 0.1431 s/iter. ETA=0:07:04
[12/08 22:02:34 d2.evaluation.evaluator]: Inference done 2070/5000. Dataloading: 0.0028 s/iter. Inference: 0.0557 s/iter. Eval: 0.0845 s/iter. Total: 0.1431 s/iter. ETA=0:06:59
[12/08 22:02:40 d2.evaluation.evaluator]: Inference done 2106/5000. Dataloading: 0.0028 s/iter. Inference: 0.0557 s/iter. Eval: 0.0845 s/iter. Total: 0.1431 s/iter. ETA=0:06:54
[12/08 22:02:45 d2.evaluation.evaluator]: Inference done 2144/5000. Dataloading: 0.0028 s/iter. Inference: 0.0557 s/iter. Eval: 0.0843 s/iter. Total: 0.1429 s/iter. ETA=0:06:48
[12/08 22:02:50 d2.evaluation.evaluator]: Inference done 2179/5000. Dataloading: 0.0028 s/iter. Inference: 0.0557 s/iter. Eval: 0.0844 s/iter. Total: 0.1429 s/iter. ETA=0:06:43
[12/08 22:02:55 d2.evaluation.evaluator]: Inference done 2217/5000. Dataloading: 0.0028 s/iter. Inference: 0.0557 s/iter. Eval: 0.0843 s/iter. Total: 0.1428 s/iter. ETA=0:06:37
[12/08 22:03:00 d2.evaluation.evaluator]: Inference done 2251/5000. Dataloading: 0.0028 s/iter. Inference: 0.0557 s/iter. Eval: 0.0843 s/iter. Total: 0.1429 s/iter. ETA=0:06:32
[12/08 22:03:05 d2.evaluation.evaluator]: Inference done 2287/5000. Dataloading: 0.0028 s/iter. Inference: 0.0557 s/iter. Eval: 0.0843 s/iter. Total: 0.1429 s/iter. ETA=0:06:27
[12/08 22:03:10 d2.evaluation.evaluator]: Inference done 2322/5000. Dataloading: 0.0028 s/iter. Inference: 0.0557 s/iter. Eval: 0.0843 s/iter. Total: 0.1429 s/iter. ETA=0:06:22
[12/08 22:03:15 d2.evaluation.evaluator]: Inference done 2360/5000. Dataloading: 0.0028 s/iter. Inference: 0.0557 s/iter. Eval: 0.0841 s/iter. Total: 0.1427 s/iter. ETA=0:06:16
[12/08 22:03:20 d2.evaluation.evaluator]: Inference done 2395/5000. Dataloading: 0.0028 s/iter. Inference: 0.0557 s/iter. Eval: 0.0841 s/iter. Total: 0.1427 s/iter. ETA=0:06:11
[12/08 22:03:25 d2.evaluation.evaluator]: Inference done 2428/5000. Dataloading: 0.0028 s/iter. Inference: 0.0558 s/iter. Eval: 0.0842 s/iter. Total: 0.1429 s/iter. ETA=0:06:07
[12/08 22:03:30 d2.evaluation.evaluator]: Inference done 2464/5000. Dataloading: 0.0028 s/iter. Inference: 0.0558 s/iter. Eval: 0.0842 s/iter. Total: 0.1428 s/iter. ETA=0:06:02
[12/08 22:03:35 d2.evaluation.evaluator]: Inference done 2499/5000. Dataloading: 0.0028 s/iter. Inference: 0.0558 s/iter. Eval: 0.0842 s/iter. Total: 0.1428 s/iter. ETA=0:05:57
[12/08 22:03:40 d2.evaluation.evaluator]: Inference done 2534/5000. Dataloading: 0.0028 s/iter. Inference: 0.0558 s/iter. Eval: 0.0842 s/iter. Total: 0.1428 s/iter. ETA=0:05:52
[12/08 22:03:45 d2.evaluation.evaluator]: Inference done 2569/5000. Dataloading: 0.0028 s/iter. Inference: 0.0558 s/iter. Eval: 0.0842 s/iter. Total: 0.1429 s/iter. ETA=0:05:47
[12/08 22:03:50 d2.evaluation.evaluator]: Inference done 2606/5000. Dataloading: 0.0028 s/iter. Inference: 0.0558 s/iter. Eval: 0.0842 s/iter. Total: 0.1428 s/iter. ETA=0:05:41
[12/08 22:03:56 d2.evaluation.evaluator]: Inference done 2642/5000. Dataloading: 0.0028 s/iter. Inference: 0.0558 s/iter. Eval: 0.0841 s/iter. Total: 0.1428 s/iter. ETA=0:05:36
[12/08 22:04:01 d2.evaluation.evaluator]: Inference done 2681/5000. Dataloading: 0.0028 s/iter. Inference: 0.0557 s/iter. Eval: 0.0840 s/iter. Total: 0.1426 s/iter. ETA=0:05:30
[12/08 22:04:06 d2.evaluation.evaluator]: Inference done 2719/5000. Dataloading: 0.0028 s/iter. Inference: 0.0557 s/iter. Eval: 0.0839 s/iter. Total: 0.1425 s/iter. ETA=0:05:24
[12/08 22:04:11 d2.evaluation.evaluator]: Inference done 2755/5000. Dataloading: 0.0028 s/iter. Inference: 0.0557 s/iter. Eval: 0.0839 s/iter. Total: 0.1425 s/iter. ETA=0:05:19
[12/08 22:04:16 d2.evaluation.evaluator]: Inference done 2791/5000. Dataloading: 0.0028 s/iter. Inference: 0.0557 s/iter. Eval: 0.0838 s/iter. Total: 0.1424 s/iter. ETA=0:05:14
[12/08 22:04:21 d2.evaluation.evaluator]: Inference done 2827/5000. Dataloading: 0.0028 s/iter. Inference: 0.0557 s/iter. Eval: 0.0838 s/iter. Total: 0.1424 s/iter. ETA=0:05:09
[12/08 22:04:26 d2.evaluation.evaluator]: Inference done 2865/5000. Dataloading: 0.0028 s/iter. Inference: 0.0557 s/iter. Eval: 0.0837 s/iter. Total: 0.1423 s/iter. ETA=0:05:03
[12/08 22:04:31 d2.evaluation.evaluator]: Inference done 2901/5000. Dataloading: 0.0028 s/iter. Inference: 0.0557 s/iter. Eval: 0.0837 s/iter. Total: 0.1423 s/iter. ETA=0:04:58
[12/08 22:04:36 d2.evaluation.evaluator]: Inference done 2936/5000. Dataloading: 0.0028 s/iter. Inference: 0.0557 s/iter. Eval: 0.0837 s/iter. Total: 0.1423 s/iter. ETA=0:04:53
[12/08 22:04:41 d2.evaluation.evaluator]: Inference done 2976/5000. Dataloading: 0.0028 s/iter. Inference: 0.0557 s/iter. Eval: 0.0835 s/iter. Total: 0.1421 s/iter. ETA=0:04:47
[12/08 22:04:46 d2.evaluation.evaluator]: Inference done 3013/5000. Dataloading: 0.0028 s/iter. Inference: 0.0557 s/iter. Eval: 0.0835 s/iter. Total: 0.1420 s/iter. ETA=0:04:42
[12/08 22:04:51 d2.evaluation.evaluator]: Inference done 3052/5000. Dataloading: 0.0028 s/iter. Inference: 0.0557 s/iter. Eval: 0.0833 s/iter. Total: 0.1418 s/iter. ETA=0:04:36
[12/08 22:04:56 d2.evaluation.evaluator]: Inference done 3090/5000. Dataloading: 0.0028 s/iter. Inference: 0.0557 s/iter. Eval: 0.0832 s/iter. Total: 0.1417 s/iter. ETA=0:04:30
[12/08 22:05:01 d2.evaluation.evaluator]: Inference done 3127/5000. Dataloading: 0.0028 s/iter. Inference: 0.0557 s/iter. Eval: 0.0831 s/iter. Total: 0.1417 s/iter. ETA=0:04:25
[12/08 22:05:06 d2.evaluation.evaluator]: Inference done 3160/5000. Dataloading: 0.0028 s/iter. Inference: 0.0556 s/iter. Eval: 0.0832 s/iter. Total: 0.1418 s/iter. ETA=0:04:20
[12/08 22:05:11 d2.evaluation.evaluator]: Inference done 3197/5000. Dataloading: 0.0028 s/iter. Inference: 0.0556 s/iter. Eval: 0.0832 s/iter. Total: 0.1417 s/iter. ETA=0:04:15
[12/08 22:05:17 d2.evaluation.evaluator]: Inference done 3231/5000. Dataloading: 0.0028 s/iter. Inference: 0.0556 s/iter. Eval: 0.0833 s/iter. Total: 0.1418 s/iter. ETA=0:04:10
[12/08 22:05:22 d2.evaluation.evaluator]: Inference done 3268/5000. Dataloading: 0.0028 s/iter. Inference: 0.0556 s/iter. Eval: 0.0833 s/iter. Total: 0.1418 s/iter. ETA=0:04:05
[12/08 22:05:27 d2.evaluation.evaluator]: Inference done 3303/5000. Dataloading: 0.0028 s/iter. Inference: 0.0557 s/iter. Eval: 0.0833 s/iter. Total: 0.1418 s/iter. ETA=0:04:00
[12/08 22:05:32 d2.evaluation.evaluator]: Inference done 3340/5000. Dataloading: 0.0028 s/iter. Inference: 0.0556 s/iter. Eval: 0.0832 s/iter. Total: 0.1418 s/iter. ETA=0:03:55
[12/08 22:05:37 d2.evaluation.evaluator]: Inference done 3373/5000. Dataloading: 0.0028 s/iter. Inference: 0.0557 s/iter. Eval: 0.0833 s/iter. Total: 0.1419 s/iter. ETA=0:03:50
[12/08 22:05:42 d2.evaluation.evaluator]: Inference done 3411/5000. Dataloading: 0.0028 s/iter. Inference: 0.0556 s/iter. Eval: 0.0833 s/iter. Total: 0.1418 s/iter. ETA=0:03:45
[12/08 22:05:47 d2.evaluation.evaluator]: Inference done 3446/5000. Dataloading: 0.0028 s/iter. Inference: 0.0556 s/iter. Eval: 0.0833 s/iter. Total: 0.1418 s/iter. ETA=0:03:40
[12/08 22:05:52 d2.evaluation.evaluator]: Inference done 3484/5000. Dataloading: 0.0028 s/iter. Inference: 0.0556 s/iter. Eval: 0.0832 s/iter. Total: 0.1417 s/iter. ETA=0:03:34
[12/08 22:05:57 d2.evaluation.evaluator]: Inference done 3522/5000. Dataloading: 0.0028 s/iter. Inference: 0.0556 s/iter. Eval: 0.0831 s/iter. Total: 0.1416 s/iter. ETA=0:03:29
[12/08 22:06:02 d2.evaluation.evaluator]: Inference done 3558/5000. Dataloading: 0.0028 s/iter. Inference: 0.0556 s/iter. Eval: 0.0832 s/iter. Total: 0.1416 s/iter. ETA=0:03:24
[12/08 22:06:07 d2.evaluation.evaluator]: Inference done 3592/5000. Dataloading: 0.0028 s/iter. Inference: 0.0556 s/iter. Eval: 0.0832 s/iter. Total: 0.1417 s/iter. ETA=0:03:19
[12/08 22:06:12 d2.evaluation.evaluator]: Inference done 3629/5000. Dataloading: 0.0028 s/iter. Inference: 0.0556 s/iter. Eval: 0.0832 s/iter. Total: 0.1417 s/iter. ETA=0:03:14
[12/08 22:06:18 d2.evaluation.evaluator]: Inference done 3667/5000. Dataloading: 0.0028 s/iter. Inference: 0.0556 s/iter. Eval: 0.0831 s/iter. Total: 0.1416 s/iter. ETA=0:03:08
[12/08 22:06:23 d2.evaluation.evaluator]: Inference done 3703/5000. Dataloading: 0.0028 s/iter. Inference: 0.0556 s/iter. Eval: 0.0831 s/iter. Total: 0.1416 s/iter. ETA=0:03:03
[12/08 22:06:28 d2.evaluation.evaluator]: Inference done 3742/5000. Dataloading: 0.0028 s/iter. Inference: 0.0556 s/iter. Eval: 0.0830 s/iter. Total: 0.1414 s/iter. ETA=0:02:57
[12/08 22:06:33 d2.evaluation.evaluator]: Inference done 3777/5000. Dataloading: 0.0028 s/iter. Inference: 0.0556 s/iter. Eval: 0.0830 s/iter. Total: 0.1415 s/iter. ETA=0:02:53
[12/08 22:06:38 d2.evaluation.evaluator]: Inference done 3812/5000. Dataloading: 0.0028 s/iter. Inference: 0.0556 s/iter. Eval: 0.0830 s/iter. Total: 0.1415 s/iter. ETA=0:02:48
[12/08 22:06:43 d2.evaluation.evaluator]: Inference done 3850/5000. Dataloading: 0.0028 s/iter. Inference: 0.0556 s/iter. Eval: 0.0830 s/iter. Total: 0.1414 s/iter. ETA=0:02:42
[12/08 22:06:48 d2.evaluation.evaluator]: Inference done 3889/5000. Dataloading: 0.0028 s/iter. Inference: 0.0555 s/iter. Eval: 0.0829 s/iter. Total: 0.1413 s/iter. ETA=0:02:36
[12/08 22:06:53 d2.evaluation.evaluator]: Inference done 3926/5000. Dataloading: 0.0028 s/iter. Inference: 0.0555 s/iter. Eval: 0.0828 s/iter. Total: 0.1413 s/iter. ETA=0:02:31
[12/08 22:06:58 d2.evaluation.evaluator]: Inference done 3961/5000. Dataloading: 0.0028 s/iter. Inference: 0.0555 s/iter. Eval: 0.0829 s/iter. Total: 0.1413 s/iter. ETA=0:02:26
[12/08 22:07:03 d2.evaluation.evaluator]: Inference done 3999/5000. Dataloading: 0.0028 s/iter. Inference: 0.0555 s/iter. Eval: 0.0828 s/iter. Total: 0.1412 s/iter. ETA=0:02:21
[12/08 22:07:08 d2.evaluation.evaluator]: Inference done 4032/5000. Dataloading: 0.0028 s/iter. Inference: 0.0555 s/iter. Eval: 0.0829 s/iter. Total: 0.1413 s/iter. ETA=0:02:16
[12/08 22:07:13 d2.evaluation.evaluator]: Inference done 4067/5000. Dataloading: 0.0028 s/iter. Inference: 0.0555 s/iter. Eval: 0.0829 s/iter. Total: 0.1414 s/iter. ETA=0:02:11
[12/08 22:07:18 d2.evaluation.evaluator]: Inference done 4101/5000. Dataloading: 0.0028 s/iter. Inference: 0.0555 s/iter. Eval: 0.0830 s/iter. Total: 0.1414 s/iter. ETA=0:02:07
[12/08 22:07:23 d2.evaluation.evaluator]: Inference done 4138/5000. Dataloading: 0.0028 s/iter. Inference: 0.0555 s/iter. Eval: 0.0830 s/iter. Total: 0.1414 s/iter. ETA=0:02:01
[12/08 22:07:28 d2.evaluation.evaluator]: Inference done 4172/5000. Dataloading: 0.0028 s/iter. Inference: 0.0555 s/iter. Eval: 0.0830 s/iter. Total: 0.1414 s/iter. ETA=0:01:57
[12/08 22:07:33 d2.evaluation.evaluator]: Inference done 4210/5000. Dataloading: 0.0028 s/iter. Inference: 0.0555 s/iter. Eval: 0.0830 s/iter. Total: 0.1414 s/iter. ETA=0:01:51
[12/08 22:07:39 d2.evaluation.evaluator]: Inference done 4246/5000. Dataloading: 0.0028 s/iter. Inference: 0.0555 s/iter. Eval: 0.0830 s/iter. Total: 0.1414 s/iter. ETA=0:01:46
[12/08 22:07:44 d2.evaluation.evaluator]: Inference done 4280/5000. Dataloading: 0.0028 s/iter. Inference: 0.0555 s/iter. Eval: 0.0830 s/iter. Total: 0.1414 s/iter. ETA=0:01:41
[12/08 22:07:49 d2.evaluation.evaluator]: Inference done 4314/5000. Dataloading: 0.0028 s/iter. Inference: 0.0555 s/iter. Eval: 0.0831 s/iter. Total: 0.1415 s/iter. ETA=0:01:37
[12/08 22:07:54 d2.evaluation.evaluator]: Inference done 4354/5000. Dataloading: 0.0028 s/iter. Inference: 0.0555 s/iter. Eval: 0.0830 s/iter. Total: 0.1414 s/iter. ETA=0:01:31
[12/08 22:07:59 d2.evaluation.evaluator]: Inference done 4392/5000. Dataloading: 0.0028 s/iter. Inference: 0.0555 s/iter. Eval: 0.0830 s/iter. Total: 0.1413 s/iter. ETA=0:01:25
[12/08 22:08:04 d2.evaluation.evaluator]: Inference done 4428/5000. Dataloading: 0.0028 s/iter. Inference: 0.0555 s/iter. Eval: 0.0830 s/iter. Total: 0.1413 s/iter. ETA=0:01:20
[12/08 22:08:09 d2.evaluation.evaluator]: Inference done 4464/5000. Dataloading: 0.0028 s/iter. Inference: 0.0555 s/iter. Eval: 0.0830 s/iter. Total: 0.1413 s/iter. ETA=0:01:15
[12/08 22:08:14 d2.evaluation.evaluator]: Inference done 4499/5000. Dataloading: 0.0028 s/iter. Inference: 0.0555 s/iter. Eval: 0.0830 s/iter. Total: 0.1413 s/iter. ETA=0:01:10
[12/08 22:08:19 d2.evaluation.evaluator]: Inference done 4533/5000. Dataloading: 0.0028 s/iter. Inference: 0.0556 s/iter. Eval: 0.0830 s/iter. Total: 0.1414 s/iter. ETA=0:01:06
[12/08 22:08:24 d2.evaluation.evaluator]: Inference done 4567/5000. Dataloading: 0.0028 s/iter. Inference: 0.0556 s/iter. Eval: 0.0830 s/iter. Total: 0.1415 s/iter. ETA=0:01:01
[12/08 22:08:29 d2.evaluation.evaluator]: Inference done 4603/5000. Dataloading: 0.0028 s/iter. Inference: 0.0556 s/iter. Eval: 0.0830 s/iter. Total: 0.1415 s/iter. ETA=0:00:56
[12/08 22:08:35 d2.evaluation.evaluator]: Inference done 4639/5000. Dataloading: 0.0028 s/iter. Inference: 0.0556 s/iter. Eval: 0.0830 s/iter. Total: 0.1415 s/iter. ETA=0:00:51
[12/08 22:08:40 d2.evaluation.evaluator]: Inference done 4672/5000. Dataloading: 0.0028 s/iter. Inference: 0.0556 s/iter. Eval: 0.0831 s/iter. Total: 0.1415 s/iter. ETA=0:00:46
[12/08 22:08:45 d2.evaluation.evaluator]: Inference done 4710/5000. Dataloading: 0.0028 s/iter. Inference: 0.0555 s/iter. Eval: 0.0830 s/iter. Total: 0.1415 s/iter. ETA=0:00:41
[12/08 22:08:50 d2.evaluation.evaluator]: Inference done 4746/5000. Dataloading: 0.0028 s/iter. Inference: 0.0555 s/iter. Eval: 0.0830 s/iter. Total: 0.1415 s/iter. ETA=0:00:35
[12/08 22:08:55 d2.evaluation.evaluator]: Inference done 4783/5000. Dataloading: 0.0028 s/iter. Inference: 0.0555 s/iter. Eval: 0.0830 s/iter. Total: 0.1414 s/iter. ETA=0:00:30
[12/08 22:09:00 d2.evaluation.evaluator]: Inference done 4820/5000. Dataloading: 0.0028 s/iter. Inference: 0.0555 s/iter. Eval: 0.0830 s/iter. Total: 0.1414 s/iter. ETA=0:00:25
[12/08 22:09:05 d2.evaluation.evaluator]: Inference done 4857/5000. Dataloading: 0.0028 s/iter. Inference: 0.0555 s/iter. Eval: 0.0830 s/iter. Total: 0.1414 s/iter. ETA=0:00:20
[12/08 22:09:10 d2.evaluation.evaluator]: Inference done 4894/5000. Dataloading: 0.0028 s/iter. Inference: 0.0555 s/iter. Eval: 0.0830 s/iter. Total: 0.1414 s/iter. ETA=0:00:14
[12/08 22:09:15 d2.evaluation.evaluator]: Inference done 4928/5000. Dataloading: 0.0028 s/iter. Inference: 0.0555 s/iter. Eval: 0.0830 s/iter. Total: 0.1414 s/iter. ETA=0:00:10
[12/08 22:09:20 d2.evaluation.evaluator]: Inference done 4969/5000. Dataloading: 0.0028 s/iter. Inference: 0.0555 s/iter. Eval: 0.0829 s/iter. Total: 0.1413 s/iter. ETA=0:00:04
[12/08 22:09:25 d2.evaluation.evaluator]: Total inference time: 0:11:45.791384 (0.141300 s / iter per device, on 1 devices)
[12/08 22:09:25 d2.evaluation.evaluator]: Total inference pure compute time: 0:04:37 (0.055504 s / iter per device, on 1 devices)
[12/08 22:09:26 d2.evaluation.sem_seg_evaluation]: OrderedDict([('sem_seg', {'mIoU': 36.86851404968443, 'fwIoU': 65.6716378510654, 'IoU-things': 79.84894237912003, 'BoundaryIoU-things': 80.21493827588482, 'min(IoU, B-Iou)-things': 79.84894237912003, 'IoU-banner': 17.260596365318833, 'BoundaryIoU-banner': 2.2402182958395596, 'min(IoU, B-Iou)-banner': 2.2402182958395596, 'IoU-blanket': 10.603996618238703, 'BoundaryIoU-blanket': 3.996717716619062, 'min(IoU, B-Iou)-blanket': 3.996717716619062, 'IoU-bridge': 19.7547675294982, 'BoundaryIoU-bridge': 5.487795577909136, 'min(IoU, B-Iou)-bridge': 5.487795577909136, 'IoU-cardboard': 13.32379127797594, 'BoundaryIoU-cardboard': 3.0884282197278865, 'min(IoU, B-Iou)-cardboard': 3.0884282197278865, 'IoU-counter': 9.751578581115544, 'BoundaryIoU-counter': 0.0, 'min(IoU, B-Iou)-counter': 0.0, 'IoU-curtain': 44.818095444927934, 'BoundaryIoU-curtain': 0.0, 'min(IoU, B-Iou)-curtain': 0.0, 'IoU-door-stuff': 13.43587390376453, 'BoundaryIoU-door-stuff': 0.0, 'min(IoU, B-Iou)-door-stuff': 0.0, 'IoU-floor-wood': 40.80816148548415, 'BoundaryIoU-floor-wood': 0.0, 'min(IoU, B-Iou)-floor-wood': 0.0, 'IoU-flower': 35.143988396057736, 'BoundaryIoU-flower': 0.0, 'min(IoU, B-Iou)-flower': 0.0, 'IoU-fruit': 20.523465028729166, 'BoundaryIoU-fruit': 0.0, 'min(IoU, B-Iou)-fruit': 0.0, 'IoU-gravel': 22.03513743638408, 'BoundaryIoU-gravel': 0.0, 'min(IoU, B-Iou)-gravel': 0.0, 'IoU-house': 13.506666463911241, 'BoundaryIoU-house': 0.0, 'min(IoU, B-Iou)-house': 0.0, 'IoU-light': 18.8444052750829, 'BoundaryIoU-light': 0.0, 'min(IoU, B-Iou)-light': 0.0, 'IoU-mirror-stuff': 6.963414513910685, 'BoundaryIoU-mirror-stuff': 0.0, 'min(IoU, B-Iou)-mirror-stuff': 0.0, 'IoU-net': 49.65724831706545, 'BoundaryIoU-net': 0.0, 'min(IoU, B-Iou)-net': 0.0, 'IoU-pillow': 0.19641566591206117, 'BoundaryIoU-pillow': 0.0, 'min(IoU, B-Iou)-pillow': 0.0, 'IoU-platform': 18.866634220114733, 'BoundaryIoU-platform': 0.0, 'min(IoU, B-Iou)-platform': 0.0, 'IoU-playingfield': 72.60954201806847, 'BoundaryIoU-playingfield': 0.0, 'min(IoU, B-Iou)-playingfield': 0.0, 'IoU-railroad': 53.94649365614671, 'BoundaryIoU-railroad': 0.0, 'min(IoU, B-Iou)-railroad': 0.0, 'IoU-river': 45.638341151307074, 'BoundaryIoU-river': 0.0, 'min(IoU, B-Iou)-river': 0.0, 'IoU-road': 54.022781295340074, 'BoundaryIoU-road': 0.0, 'min(IoU, B-Iou)-road': 0.0, 'IoU-roof': 19.873569881110548, 'BoundaryIoU-roof': 0.0, 'min(IoU, B-Iou)-roof': 0.0, 'IoU-sand': 51.387384645369195, 'BoundaryIoU-sand': 0.0, 'min(IoU, B-Iou)-sand': 0.0, 'IoU-sea': 84.30068850941204, 'BoundaryIoU-sea': 0.0, 'min(IoU, B-Iou)-sea': 0.0, 'IoU-shelf': 15.1502737476783, 'BoundaryIoU-shelf': 0.0, 'min(IoU, B-Iou)-shelf': 0.0, 'IoU-snow': 83.03225728809468, 'BoundaryIoU-snow': 0.0, 'min(IoU, B-Iou)-snow': 0.0, 'IoU-stairs': 2.9085074975921703, 'BoundaryIoU-stairs': 0.0, 'min(IoU, B-Iou)-stairs': 0.0, 'IoU-tent': 0.988339108058274, 'BoundaryIoU-tent': 0.0, 'min(IoU, B-Iou)-tent': 0.0, 'IoU-towel': 11.855556692797258, 'BoundaryIoU-towel': 0.0, 'min(IoU, B-Iou)-towel': 0.0, 'IoU-wall-brick': 34.73543329959538, 'BoundaryIoU-wall-brick': 0.0, 'min(IoU, B-Iou)-wall-brick': 0.0, 'IoU-wall-stone': 24.93925636024835, 'BoundaryIoU-wall-stone': 0.0, 'min(IoU, B-Iou)-wall-stone': 0.0, 'IoU-wall-tile': 54.44113443168711, 'BoundaryIoU-wall-tile': 0.0, 'min(IoU, B-Iou)-wall-tile': 0.0, 'IoU-wall-wood': 28.316067586080006, 'BoundaryIoU-wall-wood': 0.0, 'min(IoU, B-Iou)-wall-wood': 0.0, 'IoU-water': 30.649846027344502, 'BoundaryIoU-water': 0.0, 'min(IoU, B-Iou)-water': 0.0, 'IoU-window-blind': 32.112540768739734, 'BoundaryIoU-window-blind': 0.0, 'min(IoU, B-Iou)-window-blind': 0.0, 'IoU-window': 29.15701760750032, 'BoundaryIoU-window': 0.0, 'min(IoU, B-Iou)-window': 0.0, 'IoU-tree': 76.23746981183466, 'BoundaryIoU-tree': 0.0, 'min(IoU, B-Iou)-tree': 0.0, 'IoU-fence': 49.54335840008804, 'BoundaryIoU-fence': 0.0, 'min(IoU, B-Iou)-fence': 0.0, 'IoU-ceiling': 54.66642375893325, 'BoundaryIoU-ceiling': 0.0, 'min(IoU, B-Iou)-ceiling': 0.0, 'IoU-sky': 90.6050847015527, 'BoundaryIoU-sky': 0.0, 'min(IoU, B-Iou)-sky': 0.0, 'IoU-cabinet': 38.2083343392625, 'BoundaryIoU-cabinet': 0.0, 'min(IoU, B-Iou)-cabinet': 0.0, 'IoU-table': 33.91885738714707, 'BoundaryIoU-table': 0.0, 'min(IoU, B-Iou)-table': 0.0, 'IoU-floor': 37.04763639887651, 'BoundaryIoU-floor': 0.0, 'min(IoU, B-Iou)-floor': 0.0, 'IoU-pavement': 46.77693035619589, 'BoundaryIoU-pavement': 0.0, 'min(IoU, B-Iou)-pavement': 0.0, 'IoU-mountain': 46.070530239769866, 'BoundaryIoU-mountain': 0.0, 'min(IoU, B-Iou)-mountain': 0.0, 'IoU-grass': 71.11927025229453, 'BoundaryIoU-grass': 0.0, 'min(IoU, B-Iou)-grass': 0.0, 'IoU-dirt': 40.47507831518155, 'BoundaryIoU-dirt': 0.0, 'min(IoU, B-Iou)-dirt': 0.0, 'IoU-paper': 20.441471333711398, 'BoundaryIoU-paper': 0.0, 'min(IoU, B-Iou)-paper': 0.0, 'IoU-food': 18.68664637773076, 'BoundaryIoU-food': 0.0, 'min(IoU, B-Iou)-food': 0.0, 'IoU-building': 56.5004635223602, 'BoundaryIoU-building': 0.0, 'min(IoU, B-Iou)-building': 0.0, 'IoU-rock': 48.9037065546629, 'BoundaryIoU-rock': 0.0, 'min(IoU, B-Iou)-rock': 0.0, 'IoU-wall': 54.80835367104139, 'BoundaryIoU-wall': 0.0, 'min(IoU, B-Iou)-wall': 0.0, 'IoU-rug': 41.4819327875338, 'BoundaryIoU-rug': 0.0, 'min(IoU, B-Iou)-rug': 0.0, 'mACC': 45.69392153903022, 'pACC': 78.47362010832806, 'ACC-things': 92.98583440075065, 'ACC-banner': 20.56909594935363, 'ACC-blanket': 11.198998674656671, 'ACC-bridge': 23.763243704478736, 'ACC-cardboard': 15.531394503417188, 'ACC-counter': 11.568582323241483, 'ACC-curtain': 56.22295921887248, 'ACC-door-stuff': 16.709211717384107, 'ACC-floor-wood': 54.594425359523605, 'ACC-flower': 42.663992147155476, 'ACC-fruit': 24.42365940648554, 'ACC-gravel': 27.258970560518918, 'ACC-house': 15.399021309764505, 'ACC-light': 23.63482371856219, 'ACC-mirror-stuff': 7.51664462755678, 'ACC-net': 56.699822415547615, 'ACC-pillow': 0.2059172159992397, 'ACC-platform': 24.155994269799013, 'ACC-playingfield': 87.59015218661891, 'ACC-railroad': 68.87437906046682, 'ACC-river': 67.11321418584404, 'ACC-road': 71.913784875978, 'ACC-roof': 23.67840539141985, 'ACC-sand': 69.4833769968524, 'ACC-sea': 94.02968689488007, 'ACC-shelf': 19.61493672398237, 'ACC-snow': 90.00552247812873, 'ACC-stairs': 2.938757672335888, 'ACC-tent': 1.0199760780557983, 'ACC-towel': 13.278416547969144, 'ACC-wall-brick': 43.679359183480656, 'ACC-wall-stone': 30.895346166544652, 'ACC-wall-tile': 65.36409419423316, 'ACC-wall-wood': 35.78514937426196, 'ACC-water': 38.9366374315407, 'ACC-window-blind': 41.38477660616082, 'ACC-window': 35.23038994117963, 'ACC-tree': 87.15877438683962, 'ACC-fence': 63.00870695502614, 'ACC-ceiling': 69.84411328199397, 'ACC-sky': 95.87065395627545, 'ACC-cabinet': 48.52748756131801, 'ACC-table': 44.55847743806731, 'ACC-floor': 45.6577559967782, 'ACC-pavement': 64.78925619023848, 'ACC-mountain': 59.41289902526874, 'ACC-grass': 82.81848207354142, 'ACC-dirt': 54.687078207785675, 'ACC-paper': 25.6661256136273, 'ACC-food': 20.94502499756852, 'ACC-building': 78.34448842073812, 'ACC-rock': 59.11619716818636, 'ACC-wall': 81.79306995038806, 'ACC-rug': 59.35421837098929})])
[12/08 22:09:28 d2.evaluation.coco_evaluation]: Preparing results for COCO format ...
[12/08 22:09:28 d2.evaluation.coco_evaluation]: Saving results to ./output/inference/coco_instances_results.json
[12/08 22:09:31 d2.evaluation.coco_evaluation]: Evaluating predictions with unofficial COCO API...
Loading and preparing results...
DONE (t=0.21s)
creating index...
index created!
[12/08 22:09:31 d2.evaluation.fast_eval_api]: Evaluate annotation type *bbox*
[12/08 22:09:42 d2.evaluation.fast_eval_api]: COCOeval_opt.evaluate() finished in 10.16 seconds.
[12/08 22:09:42 d2.evaluation.fast_eval_api]: Accumulating evaluation results...
[12/08 22:09:43 d2.evaluation.fast_eval_api]: COCOeval_opt.accumulate() finished in 1.41 seconds.
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.216
 Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.432
 Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.189
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.139
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.255
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.262
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.200
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.341
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.365
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.212
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.399
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.457
[12/08 22:09:43 d2.evaluation.coco_evaluation]: Evaluation results for bbox: 
|   AP   |  AP50  |  AP75  |  APs   |  APm   |  APl   |
|:------:|:------:|:------:|:------:|:------:|:------:|
| 21.563 | 43.192 | 18.854 | 13.941 | 25.479 | 26.237 |
[12/08 22:09:43 d2.evaluation.coco_evaluation]: Per-category bbox AP: 
| category      | AP     | category     | AP     | category       | AP     |
|:--------------|:-------|:-------------|:-------|:---------------|:-------|
| person        | 35.701 | bicycle      | 12.974 | car            | 24.817 |
| motorcycle    | 22.741 | airplane     | 28.428 | bus            | 29.798 |
| train         | 28.443 | truck        | 15.394 | boat           | 8.668  |
| traffic light | 17.624 | fire hydrant | 40.425 | stop sign      | 46.089 |
| parking meter | 32.987 | bench        | 8.162  | bird           | 23.908 |
| cat           | 37.783 | dog          | 38.204 | horse          | 31.859 |
| sheep         | 30.716 | cow          | 36.488 | elephant       | 40.916 |
| bear          | 53.530 | zebra        | 43.574 | giraffe        | 38.027 |
| backpack      | 6.500  | umbrella     | 15.725 | handbag        | 4.898  |
| tie           | 12.949 | suitcase     | 12.786 | frisbee        | 47.451 |
| skis          | 4.451  | snowboard    | 2.076  | sports ball    | 40.371 |
| kite          | 24.433 | baseball bat | 4.838  | baseball glove | 23.569 |
| skateboard    | 12.811 | surfboard    | 13.214 | tennis racket  | 23.256 |
| bottle        | 24.841 | wine glass   | 14.364 | cup            | 28.260 |
| fork          | 2.413  | knife        | 2.591  | spoon          | 3.107  |
| bowl          | 29.097 | banana       | 13.615 | apple          | 14.809 |
| sandwich      | 18.535 | orange       | 20.819 | broccoli       | 14.234 |
| carrot        | 10.457 | hot dog      | 12.274 | pizza          | 31.173 |
| donut         | 26.374 | cake         | 24.476 | chair          | 12.226 |
| couch         | 18.238 | potted plant | 11.484 | bed            | 16.074 |
| dining table  | 10.397 | toilet       | 41.051 | tv             | 36.478 |
| laptop        | 29.525 | mouse        | 46.750 | remote         | 9.604  |
| keyboard      | 21.508 | cell phone   | 21.260 | microwave      | 26.050 |
| oven          | 14.363 | toaster      | 0.000  | sink           | 20.852 |
| refrigerator  | 17.382 | book         | 7.831  | clock          | 41.811 |
| vase          | 23.848 | scissors     | 5.282  | teddy bear     | 23.466 |
| hair drier    | 0.000  | toothbrush   | 1.502  |                |        |
Loading and preparing results...
DONE (t=2.55s)
creating index...
index created!
[12/08 22:09:53 d2.evaluation.fast_eval_api]: Evaluate annotation type *segm*
[12/08 22:10:06 d2.evaluation.fast_eval_api]: COCOeval_opt.evaluate() finished in 13.40 seconds.
[12/08 22:10:06 d2.evaluation.fast_eval_api]: Accumulating evaluation results...
[12/08 22:10:07 d2.evaluation.fast_eval_api]: COCOeval_opt.accumulate() finished in 1.42 seconds.
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.198
 Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.388
 Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.188
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.093
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.224
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.283
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.190
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.305
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.322
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.170
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.347
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.427
[12/08 22:10:09 d2.evaluation.coco_evaluation]: Evaluation results for segm: 
|   AP   |  AP50  |  AP75  |  APs  |  APm   |  APl   |
|:------:|:------:|:------:|:-----:|:------:|:------:|
| 19.816 | 38.811 | 18.759 | 9.317 | 22.440 | 28.337 |
[12/08 22:10:09 d2.evaluation.coco_evaluation]: Per-category segm AP: 
| category      | AP     | category     | AP     | category       | AP     |
|:--------------|:-------|:-------------|:-------|:---------------|:-------|
| person        | 28.285 | bicycle      | 5.534  | car            | 21.392 |
| motorcycle    | 13.507 | airplane     | 20.004 | bus            | 33.288 |
| train         | 35.474 | truck        | 15.852 | boat           | 8.456  |
| traffic light | 18.453 | fire hydrant | 43.569 | stop sign      | 48.284 |
| parking meter | 36.542 | bench        | 5.981  | bird           | 17.338 |
| cat           | 43.696 | dog          | 38.298 | horse          | 17.257 |
| sheep         | 20.696 | cow          | 30.080 | elephant       | 33.190 |
| bear          | 60.013 | zebra        | 32.173 | giraffe        | 23.537 |
| backpack      | 6.142  | umbrella     | 19.073 | handbag        | 6.056  |
| tie           | 8.457  | suitcase     | 13.323 | frisbee        | 48.864 |
| skis          | 0.000  | snowboard    | 0.292  | sports ball    | 40.090 |
| kite          | 17.625 | baseball bat | 0.859  | baseball glove | 26.175 |
| skateboard    | 4.205  | surfboard    | 9.942  | tennis racket  | 29.426 |
| bottle        | 23.918 | wine glass   | 9.432  | cup            | 29.688 |
| fork          | 0.009  | knife        | 0.154  | spoon          | 1.586  |
| bowl          | 27.989 | banana       | 8.171  | apple          | 15.125 |
| sandwich      | 20.885 | orange       | 22.347 | broccoli       | 13.362 |
| carrot        | 7.709  | hot dog      | 8.584  | pizza          | 31.821 |
| donut         | 26.674 | cake         | 25.659 | chair          | 6.218  |
| couch         | 14.695 | potted plant | 9.182  | bed            | 13.555 |
| dining table  | 4.675  | toilet       | 42.255 | tv             | 38.580 |
| laptop        | 32.707 | mouse        | 46.861 | remote         | 8.595  |
| keyboard      | 22.062 | cell phone   | 20.714 | microwave      | 26.461 |
| oven          | 11.662 | toaster      | 0.000  | sink           | 20.995 |
| refrigerator  | 16.980 | book         | 2.783  | clock          | 45.588 |
| vase          | 24.721 | scissors     | 0.594  | teddy bear     | 20.329 |
| hair drier    | 0.000  | toothbrush   | 0.495  |                |        |
[12/08 22:10:12 d2.evaluation.panoptic_evaluation]: Writing all panoptic predictions to /tmp/panoptic_evalv1qh_23_ ...
[12/08 22:10:38 d2.evaluation.panoptic_evaluation]: Panoptic Evaluation Results:
|        |   PQ   |   SQ   |   RQ   |  #categories  |
|:------:|:------:|:------:|:------:|:-------------:|
|  All   | 28.471 | 66.798 | 37.005 |      133      |
| Things | 33.345 | 68.564 | 42.945 |      80       |
| Stuff  | 21.113 | 64.132 | 28.039 |      53       |
[12/08 22:10:38 d2.engine.defaults]: Evaluation results for coco_2017_val_panoptic_separated in csv format:
[12/08 22:10:38 d2.evaluation.testing]: copypaste: Task: sem_seg
[12/08 22:10:38 d2.evaluation.testing]: copypaste: mIoU,fwIoU,mACC,pACC
[12/08 22:10:38 d2.evaluation.testing]: copypaste: 36.8685,65.6716,45.6939,78.4736
[12/08 22:10:38 d2.evaluation.testing]: copypaste: Task: bbox
[12/08 22:10:38 d2.evaluation.testing]: copypaste: AP,AP50,AP75,APs,APm,APl
[12/08 22:10:38 d2.evaluation.testing]: copypaste: 21.5625,43.1918,18.8544,13.9407,25.4791,26.2375
[12/08 22:10:38 d2.evaluation.testing]: copypaste: Task: segm
[12/08 22:10:38 d2.evaluation.testing]: copypaste: AP,AP50,AP75,APs,APm,APl
[12/08 22:10:38 d2.evaluation.testing]: copypaste: 19.8156,38.8111,18.7593,9.3174,22.4402,28.3366
[12/08 22:10:38 d2.evaluation.testing]: copypaste: Task: panoptic_seg
[12/08 22:10:38 d2.evaluation.testing]: copypaste: PQ,SQ,RQ,PQ_th,SQ_th,RQ_th,PQ_st,SQ_st,RQ_st
[12/08 22:10:38 d2.evaluation.testing]: copypaste: 28.4708,66.7979,37.0052,33.3453,68.5644,42.9454,21.1131,64.1316,28.0390
ERROR [12/08 22:10:39 d2.evaluation.testing]: Result verification failed!
ERROR [12/08 22:10:39 d2.evaluation.testing]: Expected Results: [['bbox', 'AP', 46.7, 1.1], ['segm', 'AP', 39.0, 0.7], ['sem_seg', 'mIoU', 64.73, 1.3], ['panoptic_seg', 'PQ', 48.13, 0.8]]
ERROR [12/08 22:10:39 d2.evaluation.testing]: Actual Results: OrderedDict([('sem_seg',
              {'ACC-banner': 20.56909594935363,
               'ACC-blanket': 11.198998674656671,
               'ACC-bridge': 23.763243704478736,
               'ACC-building': 78.34448842073812,
               'ACC-cabinet': 48.52748756131801,
               'ACC-cardboard': 15.531394503417188,
               'ACC-ceiling': 69.84411328199397,
               'ACC-counter': 11.568582323241483,
               'ACC-curtain': 56.22295921887248,
               'ACC-dirt': 54.687078207785675,
               'ACC-door-stuff': 16.709211717384107,
               'ACC-fence': 63.00870695502614,
               'ACC-floor': 45.6577559967782,
               'ACC-floor-wood': 54.594425359523605,
               'ACC-flower': 42.663992147155476,
               'ACC-food': 20.94502499756852,
               'ACC-fruit': 24.42365940648554,
               'ACC-grass': 82.81848207354142,
               'ACC-gravel': 27.258970560518918,
               'ACC-house': 15.399021309764505,
               'ACC-light': 23.63482371856219,
               'ACC-mirror-stuff': 7.51664462755678,
               'ACC-mountain': 59.41289902526874,
               'ACC-net': 56.699822415547615,
               'ACC-paper': 25.6661256136273,
               'ACC-pavement': 64.78925619023848,
               'ACC-pillow': 0.2059172159992397,
               'ACC-platform': 24.155994269799013,
               'ACC-playingfield': 87.59015218661891,
               'ACC-railroad': 68.87437906046682,
               'ACC-river': 67.11321418584404,
               'ACC-road': 71.913784875978,
               'ACC-rock': 59.11619716818636,
               'ACC-roof': 23.67840539141985,
               'ACC-rug': 59.35421837098929,
               'ACC-sand': 69.4833769968524,
               'ACC-sea': 94.02968689488007,
               'ACC-shelf': 19.61493672398237,
               'ACC-sky': 95.87065395627545,
               'ACC-snow': 90.00552247812873,
               'ACC-stairs': 2.938757672335888,
               'ACC-table': 44.55847743806731,
               'ACC-tent': 1.0199760780557983,
               'ACC-things': 92.98583440075065,
               'ACC-towel': 13.278416547969144,
               'ACC-tree': 87.15877438683962,
               'ACC-wall': 81.79306995038806,
               'ACC-wall-brick': 43.679359183480656,
               'ACC-wall-stone': 30.895346166544652,
               'ACC-wall-tile': 65.36409419423316,
               'ACC-wall-wood': 35.78514937426196,
               'ACC-water': 38.9366374315407,
               'ACC-window': 35.23038994117963,
               'ACC-window-blind': 41.38477660616082,
               'BoundaryIoU-banner': 2.2402182958395596,
               'BoundaryIoU-blanket': 3.996717716619062,
               'BoundaryIoU-bridge': 5.487795577909136,
               'BoundaryIoU-building': 0.0,
               'BoundaryIoU-cabinet': 0.0,
               'BoundaryIoU-cardboard': 3.0884282197278865,
               'BoundaryIoU-ceiling': 0.0,
               'BoundaryIoU-counter': 0.0,
               'BoundaryIoU-curtain': 0.0,
               'BoundaryIoU-dirt': 0.0,
               'BoundaryIoU-door-stuff': 0.0,
               'BoundaryIoU-fence': 0.0,
               'BoundaryIoU-floor': 0.0,
               'BoundaryIoU-floor-wood': 0.0,
               'BoundaryIoU-flower': 0.0,
               'BoundaryIoU-food': 0.0,
               'BoundaryIoU-fruit': 0.0,
               'BoundaryIoU-grass': 0.0,
               'BoundaryIoU-gravel': 0.0,
               'BoundaryIoU-house': 0.0,
               'BoundaryIoU-light': 0.0,
               'BoundaryIoU-mirror-stuff': 0.0,
               'BoundaryIoU-mountain': 0.0,
               'BoundaryIoU-net': 0.0,
               'BoundaryIoU-paper': 0.0,
               'BoundaryIoU-pavement': 0.0,
               'BoundaryIoU-pillow': 0.0,
               'BoundaryIoU-platform': 0.0,
               'BoundaryIoU-playingfield': 0.0,
               'BoundaryIoU-railroad': 0.0,
               'BoundaryIoU-river': 0.0,
               'BoundaryIoU-road': 0.0,
               'BoundaryIoU-rock': 0.0,
               'BoundaryIoU-roof': 0.0,
               'BoundaryIoU-rug': 0.0,
               'BoundaryIoU-sand': 0.0,
               'BoundaryIoU-sea': 0.0,
               'BoundaryIoU-shelf': 0.0,
               'BoundaryIoU-sky': 0.0,
               'BoundaryIoU-snow': 0.0,
               'BoundaryIoU-stairs': 0.0,
               'BoundaryIoU-table': 0.0,
               'BoundaryIoU-tent': 0.0,
               'BoundaryIoU-things': 80.21493827588482,
               'BoundaryIoU-towel': 0.0,
               'BoundaryIoU-tree': 0.0,
               'BoundaryIoU-wall': 0.0,
               'BoundaryIoU-wall-brick': 0.0,
               'BoundaryIoU-wall-stone': 0.0,
               'BoundaryIoU-wall-tile': 0.0,
               'BoundaryIoU-wall-wood': 0.0,
               'BoundaryIoU-water': 0.0,
               'BoundaryIoU-window': 0.0,
               'BoundaryIoU-window-blind': 0.0,
               'IoU-banner': 17.260596365318833,
               'IoU-blanket': 10.603996618238703,
               'IoU-bridge': 19.7547675294982,
               'IoU-building': 56.5004635223602,
               'IoU-cabinet': 38.2083343392625,
               'IoU-cardboard': 13.32379127797594,
               'IoU-ceiling': 54.66642375893325,
               'IoU-counter': 9.751578581115544,
               'IoU-curtain': 44.818095444927934,
               'IoU-dirt': 40.47507831518155,
               'IoU-door-stuff': 13.43587390376453,
               'IoU-fence': 49.54335840008804,
               'IoU-floor': 37.04763639887651,
               'IoU-floor-wood': 40.80816148548415,
               'IoU-flower': 35.143988396057736,
               'IoU-food': 18.68664637773076,
               'IoU-fruit': 20.523465028729166,
               'IoU-grass': 71.11927025229453,
               'IoU-gravel': 22.03513743638408,
               'IoU-house': 13.506666463911241,
               'IoU-light': 18.8444052750829,
               'IoU-mirror-stuff': 6.963414513910685,
               'IoU-mountain': 46.070530239769866,
               'IoU-net': 49.65724831706545,
               'IoU-paper': 20.441471333711398,
               'IoU-pavement': 46.77693035619589,
               'IoU-pillow': 0.19641566591206117,
               'IoU-platform': 18.866634220114733,
               'IoU-playingfield': 72.60954201806847,
               'IoU-railroad': 53.94649365614671,
               'IoU-river': 45.638341151307074,
               'IoU-road': 54.022781295340074,
               'IoU-rock': 48.9037065546629,
               'IoU-roof': 19.873569881110548,
               'IoU-rug': 41.4819327875338,
               'IoU-sand': 51.387384645369195,
               'IoU-sea': 84.30068850941204,
               'IoU-shelf': 15.1502737476783,
               'IoU-sky': 90.6050847015527,
               'IoU-snow': 83.03225728809468,
               'IoU-stairs': 2.9085074975921703,
               'IoU-table': 33.91885738714707,
               'IoU-tent': 0.988339108058274,
               'IoU-things': 79.84894237912003,
               'IoU-towel': 11.855556692797258,
               'IoU-tree': 76.23746981183466,
               'IoU-wall': 54.80835367104139,
               'IoU-wall-brick': 34.73543329959538,
               'IoU-wall-stone': 24.93925636024835,
               'IoU-wall-tile': 54.44113443168711,
               'IoU-wall-wood': 28.316067586080006,
               'IoU-water': 30.649846027344502,
               'IoU-window': 29.15701760750032,
               'IoU-window-blind': 32.112540768739734,
               'fwIoU': 65.6716378510654,
               'mACC': 45.69392153903022,
               'mIoU': 36.86851404968443,
               'min(IoU, B-Iou)-banner': 2.2402182958395596,
               'min(IoU, B-Iou)-blanket': 3.996717716619062,
               'min(IoU, B-Iou)-bridge': 5.487795577909136,
               'min(IoU, B-Iou)-building': 0.0,
               'min(IoU, B-Iou)-cabinet': 0.0,
               'min(IoU, B-Iou)-cardboard': 3.0884282197278865,
               'min(IoU, B-Iou)-ceiling': 0.0,
               'min(IoU, B-Iou)-counter': 0.0,
               'min(IoU, B-Iou)-curtain': 0.0,
               'min(IoU, B-Iou)-dirt': 0.0,
               'min(IoU, B-Iou)-door-stuff': 0.0,
               'min(IoU, B-Iou)-fence': 0.0,
               'min(IoU, B-Iou)-floor': 0.0,
               'min(IoU, B-Iou)-floor-wood': 0.0,
               'min(IoU, B-Iou)-flower': 0.0,
               'min(IoU, B-Iou)-food': 0.0,
               'min(IoU, B-Iou)-fruit': 0.0,
               'min(IoU, B-Iou)-grass': 0.0,
               'min(IoU, B-Iou)-gravel': 0.0,
               'min(IoU, B-Iou)-house': 0.0,
               'min(IoU, B-Iou)-light': 0.0,
               'min(IoU, B-Iou)-mirror-stuff': 0.0,
               'min(IoU, B-Iou)-mountain': 0.0,
               'min(IoU, B-Iou)-net': 0.0,
               'min(IoU, B-Iou)-paper': 0.0,
               'min(IoU, B-Iou)-pavement': 0.0,
               'min(IoU, B-Iou)-pillow': 0.0,
               'min(IoU, B-Iou)-platform': 0.0,
               'min(IoU, B-Iou)-playingfield': 0.0,
               'min(IoU, B-Iou)-railroad': 0.0,
               'min(IoU, B-Iou)-river': 0.0,
               'min(IoU, B-Iou)-road': 0.0,
               'min(IoU, B-Iou)-rock': 0.0,
               'min(IoU, B-Iou)-roof': 0.0,
               'min(IoU, B-Iou)-rug': 0.0,
               'min(IoU, B-Iou)-sand': 0.0,
               'min(IoU, B-Iou)-sea': 0.0,
               'min(IoU, B-Iou)-shelf': 0.0,
               'min(IoU, B-Iou)-sky': 0.0,
               'min(IoU, B-Iou)-snow': 0.0,
               'min(IoU, B-Iou)-stairs': 0.0,
               'min(IoU, B-Iou)-table': 0.0,
               'min(IoU, B-Iou)-tent': 0.0,
               'min(IoU, B-Iou)-things': 79.84894237912003,
               'min(IoU, B-Iou)-towel': 0.0,
               'min(IoU, B-Iou)-tree': 0.0,
               'min(IoU, B-Iou)-wall': 0.0,
               'min(IoU, B-Iou)-wall-brick': 0.0,
               'min(IoU, B-Iou)-wall-stone': 0.0,
               'min(IoU, B-Iou)-wall-tile': 0.0,
               'min(IoU, B-Iou)-wall-wood': 0.0,
               'min(IoU, B-Iou)-water': 0.0,
               'min(IoU, B-Iou)-window': 0.0,
               'min(IoU, B-Iou)-window-blind': 0.0,
               'pACC': 78.47362010832806}),
             ('bbox',
              {'AP': 21.562547780206607,
               'AP-airplane': 28.428184501159485,
               'AP-apple': 14.808685277594623,
               'AP-backpack': 6.500404382641191,
               'AP-banana': 13.615193618111057,
               'AP-baseball bat': 4.8378452612793525,
               'AP-baseball glove': 23.5689993609049,
               'AP-bear': 53.529670461120226,
               'AP-bed': 16.07417396855423,
               'AP-bench': 8.16152468942531,
               'AP-bicycle': 12.973574414870656,
               'AP-bird': 23.908125467646922,
               'AP-boat': 8.668246376806584,
               'AP-book': 7.830526155110568,
               'AP-bottle': 24.84061810757589,
               'AP-bowl': 29.097488793561332,
               'AP-broccoli': 14.233769791900619,
               'AP-bus': 29.797557818409743,
               'AP-cake': 24.476088404709174,
               'AP-car': 24.81702286952704,
               'AP-carrot': 10.45677115267277,
               'AP-cat': 37.78297702077239,
               'AP-cell phone': 21.25954199978297,
               'AP-chair': 12.22550167439783,
               'AP-clock': 41.811342177222386,
               'AP-couch': 18.23834623509209,
               'AP-cow': 36.488183230744156,
               'AP-cup': 28.259676371099257,
               'AP-dining table': 10.397486200960344,
               'AP-dog': 38.204105806304824,
               'AP-donut': 26.374387846932823,
               'AP-elephant': 40.91558342908876,
               'AP-fire hydrant': 40.42549454186643,
               'AP-fork': 2.4131659774196477,
               'AP-frisbee': 47.45054602308561,
               'AP-giraffe': 38.02692847374708,
               'AP-hair drier': 0.0,
               'AP-handbag': 4.8981350364732545,
               'AP-horse': 31.859452458262773,
               'AP-hot dog': 12.273632670081703,
               'AP-keyboard': 21.508188554362192,
               'AP-kite': 24.432896681193785,
               'AP-knife': 2.590803882260072,
               'AP-laptop': 29.5249716343047,
               'AP-microwave': 26.05041627743492,
               'AP-motorcycle': 22.74084608778198,
               'AP-mouse': 46.74952721364313,
               'AP-orange': 20.81891993969758,
               'AP-oven': 14.363146019393913,
               'AP-parking meter': 32.987445942173096,
               'AP-person': 35.70107398722844,
               'AP-pizza': 31.17317645577751,
               'AP-potted plant': 11.48371260695251,
               'AP-refrigerator': 17.382331128445873,
               'AP-remote': 9.603930464471985,
               'AP-sandwich': 18.535180225020984,
               'AP-scissors': 5.281628162816281,
               'AP-sheep': 30.716018854824235,
               'AP-sink': 20.85178385702954,
               'AP-skateboard': 12.810707706582953,
               'AP-skis': 4.450775873329879,
               'AP-snowboard': 2.0759068938829173,
               'AP-spoon': 3.1073704447311403,
               'AP-sports ball': 40.37093511571672,
               'AP-stop sign': 46.08919780987872,
               'AP-suitcase': 12.785856760993685,
               'AP-surfboard': 13.213927541757291,
               'AP-teddy bear': 23.466246496353243,
               'AP-tennis racket': 23.256087126955233,
               'AP-tie': 12.948738941281032,
               'AP-toaster': 0.0,
               'AP-toilet': 41.05106271727928,
               'AP-toothbrush': 1.5016501650165013,
               'AP-traffic light': 17.62449773817427,
               'AP-train': 28.442895533265755,
               'AP-truck': 15.394119842998569,
               'AP-tv': 36.47798407089718,
               'AP-umbrella': 15.724814181846872,
               'AP-vase': 23.84847255313882,
               'AP-wine glass': 14.363801767527335,
               'AP-zebra': 43.57381711319221,
               'AP50': 43.191817166129525,
               'AP75': 18.854384972451733,
               'APl': 26.237479120393743,
               'APm': 25.479065260855936,
               'APs': 13.940667221115973}),
             ('segm',
              {'AP': 19.81555310244967,
               'AP-airplane': 20.003761919826943,
               'AP-apple': 15.124915832561339,
               'AP-backpack': 6.141622896419626,
               'AP-banana': 8.170863724926955,
               'AP-baseball bat': 0.859017987029787,
               'AP-baseball glove': 26.175193018083494,
               'AP-bear': 60.01345158413073,
               'AP-bed': 13.554509152096598,
               'AP-bench': 5.980561354221396,
               'AP-bicycle': 5.534245169820351,
               'AP-bird': 17.33835944533486,
               'AP-boat': 8.45635933905971,
               'AP-book': 2.782796867827136,
               'AP-bottle': 23.918051841457846,
               'AP-bowl': 27.988750983701717,
               'AP-broccoli': 13.361969699265794,
               'AP-bus': 33.287689081381814,
               'AP-cake': 25.659351259677344,
               'AP-car': 21.392487218476436,
               'AP-carrot': 7.70940239362377,
               'AP-cat': 43.69565115108438,
               'AP-cell phone': 20.713547004957864,
               'AP-chair': 6.2176371414600515,
               'AP-clock': 45.58763662658213,
               'AP-couch': 14.695324355549522,
               'AP-cow': 30.079717958450903,
               'AP-cup': 29.687641320269737,
               'AP-dining table': 4.674587053164796,
               'AP-dog': 38.29804352653857,
               'AP-donut': 26.674459913194887,
               'AP-elephant': 33.19027741043229,
               'AP-fire hydrant': 43.568655884729175,
               'AP-fork': 0.009148542892995931,
               'AP-frisbee': 48.86381437125231,
               'AP-giraffe': 23.536540762950974,
               'AP-hair drier': 0.0,
               'AP-handbag': 6.056231560522087,
               'AP-horse': 17.2565113153322,
               'AP-hot dog': 8.5843176809046,
               'AP-keyboard': 22.06169107142312,
               'AP-kite': 17.624600742157973,
               'AP-knife': 0.15350433558380572,
               'AP-laptop': 32.70650354563326,
               'AP-microwave': 26.461146321105556,
               'AP-motorcycle': 13.507151894001638,
               'AP-mouse': 46.86111395726017,
               'AP-orange': 22.346777353880245,
               'AP-oven': 11.661969727189442,
               'AP-parking meter': 36.54179594599688,
               'AP-person': 28.285484285521168,
               'AP-pizza': 31.821154129512948,
               'AP-potted plant': 9.18155953123599,
               'AP-refrigerator': 16.979749787659724,
               'AP-remote': 8.594721881860615,
               'AP-sandwich': 20.88482113926461,
               'AP-scissors': 0.594059405940594,
               'AP-sheep': 20.69607961342791,
               'AP-sink': 20.99526594693218,
               'AP-skateboard': 4.205179508291081,
               'AP-skis': 0.00011957717510881522,
               'AP-snowboard': 0.29167545337458195,
               'AP-spoon': 1.5857872212919975,
               'AP-sports ball': 40.08956317895686,
               'AP-stop sign': 48.283645861255806,
               'AP-suitcase': 13.32345581324755,
               'AP-surfboard': 9.94188020431511,
               'AP-teddy bear': 20.329149066491063,
               'AP-tennis racket': 29.426388498543655,
               'AP-tie': 8.456869617941715,
               'AP-toaster': 0.0,
               'AP-toilet': 42.25523275125493,
               'AP-toothbrush': 0.49504950495049505,
               'AP-traffic light': 18.453168584200753,
               'AP-train': 35.47392174563181,
               'AP-truck': 15.852000330306184,
               'AP-tv': 38.57971041807381,
               'AP-umbrella': 19.072894967822617,
               'AP-vase': 24.721208891046757,
               'AP-wine glass': 9.431930242965462,
               'AP-zebra': 32.17316179405526,
               'AP50': 38.81106938973839,
               'AP75': 18.759289874430028,
               'APl': 28.33657136036146,
               'APm': 22.440154701798797,
               'APs': 9.317435604341467}),
             ('panoptic_seg',
              {'PQ': 28.470776477664206,
               'PQ_st': 21.113052559472568,
               'PQ_th': 33.345268573466164,
               'RQ': 37.00524944586882,
               'RQ_st': 28.038957751256945,
               'RQ_th': 42.94541769354917,
               'SQ': 66.7979364869457,
               'SQ_st': 64.13159847719822,
               'SQ_th': 68.56438541840335})])